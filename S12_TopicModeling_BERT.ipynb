{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Install required packages\n",
    "install(\"sentence-transformers\")\n",
    "install(\"bertopic\")\n",
    "install(\"pandas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "2024-06-14 22:05:27.257330: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 stories saved to cluster_0.txt\n",
      "119 stories saved to cluster_1.txt\n",
      "185 stories saved to cluster_2.txt\n",
      "168 stories saved to cluster_3.txt\n",
      "Topic modeling completed for all clusters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from bertopic import BERTopic\n",
    "import pickle\n",
    "\n",
    "# TASK 1: Read the Clustered Data\n",
    "def read_clustered_data(clustered_file_path, tokenized_data_path):\n",
    "    # Load clustered data\n",
    "    clustered_data = pd.read_csv(clustered_file_path)\n",
    "\n",
    "    # Read tokenized data\n",
    "    with open(tokenized_data_path, 'r') as file:\n",
    "        tokenized_data = [line.strip().strip('\"') for line in file.readlines()]\n",
    "\n",
    "    # Map clusters to original text data\n",
    "    merged_data = pd.concat([clustered_data, pd.DataFrame(tokenized_data, columns=['text'])], axis=1)\n",
    "\n",
    "    # Group data by cluster label\n",
    "    grouped_data = merged_data.groupby('Cluster')\n",
    "\n",
    "    # Iterate over groups and access member stories\n",
    "    for cluster_label, cluster_group in grouped_data:\n",
    "        # Ensure cluster label is an integer\n",
    "        cluster_label = int(cluster_label)\n",
    "        \n",
    "        # Save clustered stories to individual files\n",
    "        cluster_file_name = f\"cluster_{cluster_label}.txt\"\n",
    "        cluster_group['text'].to_csv(cluster_file_name, index=False, header=False)\n",
    "        \n",
    "        # Print number of stories saved\n",
    "        num_stories = cluster_group.shape[0]\n",
    "        print(f\"{num_stories} stories saved to {cluster_file_name}\")\n",
    "\n",
    "# TASK 2: Perform the Documents by Topics:\n",
    "def perform_topic_modeling(cluster_directory):\n",
    "    # Load a pre-trained BERT model from sentence-transformers\n",
    "    model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "    \n",
    "    # Dictionary to store documents and embeddings by cluster\n",
    "    clustered_data = {}\n",
    "\n",
    "    # Read the cluster files and encode the documents\n",
    "    for cluster_num in range(4):\n",
    "        cluster_file = os.path.join(cluster_directory, f'cluster_{cluster_num}.txt')\n",
    "        with open(cluster_file, 'r', encoding='utf-8') as file:\n",
    "            documents = [line.strip() for line in file.readlines()]\n",
    "            embeddings = model.encode(documents)\n",
    "            clustered_data[f'cluster_{cluster_num}'] = (documents, embeddings)\n",
    "\n",
    "    # Dictionary to store topic models and topics for each cluster\n",
    "    topics_per_cluster = {}\n",
    "\n",
    "    # Perform topic modeling on the documents and embeddings for each cluster\n",
    "    for cluster_label, (documents, embeddings) in clustered_data.items():\n",
    "        topic_model = BERTopic()\n",
    "        topics, probabilities = topic_model.fit_transform(documents, embeddings)\n",
    "        topics_per_cluster[cluster_label] = {\n",
    "            'topic_model': topic_model,\n",
    "            'topics': topics,\n",
    "            'probabilities': probabilities\n",
    "        }\n",
    "\n",
    "    # Save the topic models and topics for all clusters\n",
    "    with open('topics_per_cluster.pkl', 'wb') as f:\n",
    "        pickle.dump(topics_per_cluster, f)\n",
    "\n",
    "    print(\"Topic modeling completed for all clusters.\")\n",
    "\n",
    "# Example usage\n",
    "clustered_file_path = 'clustered_BERT_500.csv'  # Update with your file path\n",
    "tokenized_data_path = 'tokenizedFine_500.json'  # Update with your tokenized data file path\n",
    "cluster_directory = '.'  # Directory where the cluster files will be saved\n",
    "\n",
    "read_clustered_data(clustered_file_path, tokenized_data_path)\n",
    "perform_topic_modeling(cluster_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Showcase the Topic Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(topics_per_cluster):\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topic_model = data['topic_model']\n",
    "        topics = topic_model.get_topics()\n",
    "        print(f\"\\nTopics for {cluster_label}:\")\n",
    "        for topic_num, topic in topics.items():\n",
    "            print(f\"Topic {topic_num}: {topic[:10]}\")  # Print top 10 words for each topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cluster_0': {'topic_model': <bertopic._bertopic.BERTopic object at 0x1b4dd89b0>, 'topics': [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], 'probabilities': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}, 'cluster_1': {'topic_model': <bertopic._bertopic.BERTopic object at 0x1b3921400>, 'topics': [-1, 0, -1, -1, -1, -1, -1, 2, 2, -1, -1, 1, 1, 0, -1, -1, -1, 1, -1, 0, -1, 1, 0, -1, 2, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 2, -1, -1, 0, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, 2, -1, 0, -1, -1, -1, -1, 2, -1, 1, 0, 2, 2, 0, -1, -1, -1, -1, -1, 1, 0, -1, -1, 0, 0, 1, -1, -1, -1, -1, 0, 2, -1, -1, 1, 0, -1, -1, -1, -1, 0, 2, 1, -1], 'probabilities': array([0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.97402862, 1.        , 0.        ,\n",
      "       0.        , 0.91538583, 0.89536339, 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.98372194, 0.        , 0.9914283 ,\n",
      "       0.        , 1.        , 1.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.98954987, 0.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "       0.99113248, 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 1.        , 1.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 0.        , 1.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.93296637,\n",
      "       1.        , 0.        , 0.        , 1.        , 1.        ,\n",
      "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 0.        , 0.        , 1.        ,\n",
      "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 0.97179028, 0.        ])}, 'cluster_2': {'topic_model': <bertopic._bertopic.BERTopic object at 0x1b60c8bf0>, 'topics': [0, 1, 1, 1, 0, -1, -1, 0, -1, 1, -1, 0, 1, -1, 0, 1, 1, 0, 0, 1, 1, -1, -1, -1, 2, -1, 1, -1, -1, -1, 0, -1, 1, -1, 0, 2, -1, 0, 1, 1, 2, 0, -1, -1, 2, 0, -1, -1, 0, -1, 0, -1, -1, 2, -1, -1, -1, 1, -1, -1, -1, -1, 2, 1, -1, -1, 1, 1, -1, 1, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, 0, -1, 2, -1, -1, -1, 2, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, 0, 2, 0, 1, -1, 2, -1, -1, 1, -1, 1, -1, 0, 1, 0, 2, 1, 1, -1, 0, 1, 0, -1, -1, 0, 2, 1, -1, 0, -1, -1, 0, -1, 0, 0, 1, 2, 2, 0, 0, 1, -1, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, -1, -1, 0, 2, 0, 1, 1, 1, 2, -1, -1, 1, 0, 0, 0, 0, 2, 2, -1, 1, -1, 2, 1, -1, 1, 0, -1, -1, 1, -1, 0, 0, 2, -1, -1, -1], 'probabilities': array([0.74764438, 1.        , 0.80633824, 1.        , 0.75219721,\n",
      "       0.        , 0.        , 0.74239414, 0.        , 0.77398646,\n",
      "       0.        , 0.75219721, 1.        , 0.        , 0.74383836,\n",
      "       0.76258944, 0.77601124, 0.68723025, 0.82677236, 1.        ,\n",
      "       1.        , 0.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.73063162, 0.        , 0.72411254, 0.        , 0.98363875,\n",
      "       1.        , 0.        , 0.88272573, 0.7572668 , 0.75425161,\n",
      "       1.        , 1.        , 0.        , 0.        , 0.85768009,\n",
      "       0.74239414, 0.        , 0.        , 0.73500875, 0.        ,\n",
      "       1.        , 0.        , 0.        , 0.865343  , 0.        ,\n",
      "       0.        , 0.        , 0.82107761, 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.85768009, 1.        , 0.        ,\n",
      "       0.        , 0.95986485, 0.77980919, 0.        , 0.88954671,\n",
      "       0.93662532, 0.        , 0.        , 0.99417263, 0.        ,\n",
      "       0.93662532, 0.75219721, 0.67780248, 0.        , 0.8175137 ,\n",
      "       0.74867482, 0.        , 0.85768009, 0.        , 0.        ,\n",
      "       0.        , 0.91527457, 0.        , 0.6758248 , 0.75219721,\n",
      "       0.        , 0.        , 0.        , 0.93662532, 0.        ,\n",
      "       0.        , 0.        , 0.84474461, 0.85190708, 0.68515122,\n",
      "       0.99856901, 0.        , 1.        , 0.        , 0.        ,\n",
      "       1.        , 0.        , 0.83911222, 0.        , 0.88959462,\n",
      "       0.99677704, 0.82827012, 0.97843715, 0.77037504, 0.75610998,\n",
      "       0.        , 0.81866443, 0.7572668 , 0.92335161, 0.        ,\n",
      "       0.        , 1.        , 1.        , 0.95439432, 0.        ,\n",
      "       1.        , 0.        , 0.        , 0.75219721, 0.        ,\n",
      "       0.68432653, 0.69340814, 1.        , 0.9865442 , 1.        ,\n",
      "       0.987613  , 1.        , 0.90088095, 0.        , 1.        ,\n",
      "       0.75219721, 0.72678371, 0.98953908, 0.82120239, 0.9265069 ,\n",
      "       0.79824454, 0.70904503, 0.74239414, 1.        , 0.        ,\n",
      "       0.        , 0.85117649, 1.        , 0.79879313, 0.99800537,\n",
      "       0.93325088, 0.84655105, 1.        , 0.        , 0.        ,\n",
      "       0.7572668 , 1.        , 0.8115993 , 1.        , 0.73815872,\n",
      "       1.        , 0.95428067, 0.        , 1.        , 0.        ,\n",
      "       0.93249504, 0.98732071, 0.        , 0.84825151, 1.        ,\n",
      "       0.        , 0.        , 0.98185635, 0.        , 0.93662532,\n",
      "       0.74790826, 1.        , 0.        , 0.        , 0.        ])}, 'cluster_3': {'topic_model': <bertopic._bertopic.BERTopic object at 0x1b61be1b0>, 'topics': [0, 2, 0, 1, 0, -1, -1, 1, 2, 3, -1, 4, -1, -1, -1, 2, -1, 3, -1, 4, -1, 4, 4, 0, 4, -1, 0, -1, 0, -1, 1, 2, -1, -1, -1, 4, 2, 0, 1, 0, -1, 0, 0, -1, 0, -1, -1, -1, -1, 1, -1, 0, 0, 1, 3, -1, -1, -1, -1, 0, 0, -1, 1, -1, 1, -1, 0, -1, 0, -1, 2, 0, -1, -1, -1, 4, 3, -1, -1, -1, 0, 2, -1, 1, 4, -1, 2, 3, -1, 1, 1, 2, 3, 1, 1, -1, -1, 3, 1, -1, -1, 4, 0, -1, 0, 3, -1, 2, -1, -1, 0, -1, 4, -1, 1, 2, 1, -1, -1, 0, -1, -1, -1, 1, -1, 0, 1, 1, -1, -1, 1, -1, 4, 2, -1, -1, 3, 0, 3, -1, -1, -1, 2, 0, 3, -1, 0, -1, -1, 3, -1, -1, 3, 4, 4, -1, 1, -1, -1, -1, -1, -1, 0, 1, 0, -1, -1, -1], 'probabilities': array([1.        , 1.        , 1.        , 0.94690274, 0.80365234,\n",
      "       0.        , 0.        , 1.        , 1.        , 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 0.        , 1.        , 0.        , 1.        ,\n",
      "       0.        , 1.        , 0.89613352, 0.68638099, 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.93000481, 0.        ,\n",
      "       0.92648268, 1.        , 0.        , 0.        , 0.        ,\n",
      "       1.        , 1.        , 0.7501487 , 1.        , 0.74970943,\n",
      "       0.        , 0.82499488, 0.78703658, 0.        , 0.80806475,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.9545506 ,\n",
      "       0.        , 0.99389836, 0.7087828 , 1.        , 1.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.69359948,\n",
      "       0.65965318, 0.        , 1.        , 0.        , 1.        ,\n",
      "       0.        , 0.86981327, 0.        , 0.9699916 , 0.        ,\n",
      "       1.        , 1.        , 0.        , 0.        , 0.        ,\n",
      "       0.95937294, 0.95333272, 0.        , 0.        , 0.        ,\n",
      "       0.92716042, 1.        , 0.        , 0.98094541, 1.        ,\n",
      "       0.        , 1.        , 1.        , 0.        , 0.96919753,\n",
      "       1.        , 1.        , 1.        , 1.        , 0.90851962,\n",
      "       0.        , 0.        , 1.        , 0.94812116, 0.        ,\n",
      "       0.        , 1.        , 1.        , 0.        , 1.        ,\n",
      "       0.97111975, 0.        , 1.        , 0.        , 0.        ,\n",
      "       0.65173347, 0.        , 0.83749111, 0.        , 1.        ,\n",
      "       1.        , 0.95744299, 0.        , 0.        , 0.82545048,\n",
      "       0.        , 0.        , 0.        , 1.        , 0.        ,\n",
      "       0.77527934, 1.        , 0.94812116, 0.        , 0.        ,\n",
      "       0.94791473, 0.        , 1.        , 1.        , 0.        ,\n",
      "       0.        , 1.        , 1.        , 1.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.79002996, 1.        ,\n",
      "       0.        , 1.        , 0.        , 0.        , 1.        ,\n",
      "       0.        , 0.        , 0.97233725, 1.        , 1.        ,\n",
      "       0.        , 0.90338868, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 1.        , 0.98882485, 1.        ,\n",
      "       0.        , 0.        , 0.        ])}}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def load_topic_models(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        topics_per_cluster = pickle.load(f)\n",
    "    return topics_per_cluster\n",
    "\n",
    "# Load the topic models\n",
    "file_path = 'topics_per_cluster.pkl'\n",
    "topics_per_cluster = load_topic_models(file_path)\n",
    "\n",
    "# Print loaded topics_per_cluster to verify content\n",
    "print(topics_per_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(topics_per_cluster):\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topic_model = data['topic_model']\n",
    "        topics = topic_model.get_topics()\n",
    "        print(f\"\\nTopics for {cluster_label}:\")\n",
    "        print(f\"Number of topics: {len(topics)}\")  # Print number of topics\n",
    "        for topic_num, topic in topics.items():\n",
    "            print(f\"Topic {topic_num}: {topic[:10]}\")  # Print top 10 words for each topic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error visualizing topics for cluster_0: zero-size array to reduction operation maximum which has no identity\n",
      "Error visualizing topics for cluster_1: zero-size array to reduction operation maximum which has no identity\n",
      "Error visualizing topics for cluster_2: arrays used as indices must be of integer (or boolean) type\n",
      "Error visualizing topics for cluster_3: arrays used as indices must be of integer (or boolean) type\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_topics(topics_per_cluster):\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topic_model = data['topic_model']\n",
    "        try:\n",
    "            fig = topic_model.visualize_topics()\n",
    "            plt.title(f\"Topics for {cluster_label}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing topics for {cluster_label}: {str(e)}\")\n",
    "\n",
    "# Assuming topics_per_cluster is already loaded from topics_per_cluster.pkl\n",
    "visualize_topics(topics_per_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: cluster_0\n",
      "Topics: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "Error visualizing topics for cluster_0: arrays used as indices must be of integer (or boolean) type\n",
      "Cluster: cluster_1\n",
      "Topics: [-1, 0, -1, -1, -1, -1, -1, 2, 2, -1, -1, 1, 1, 0, -1, -1, -1, 1, -1, 0, -1, 1, 0, -1, 2, -1, -1, -1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 0, -1, -1, 1, -1, -1, -1, -1, -1, 2, -1, -1, 0, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 1, 2, -1, -1, -1, 2, -1, 0, -1, -1, -1, -1, 2, -1, 1, 0, 2, 2, 0, -1, -1, -1, -1, -1, 1, 0, -1, -1, 0, 0, 1, -1, -1, -1, -1, 0, 2, -1, -1, 1, 0, -1, -1, -1, -1, 0, 2, 1, -1]\n",
      "Probabilities: [0.         1.         0.         0.         0.         0.\n",
      " 0.         0.97402862 1.         0.         0.         0.91538583\n",
      " 0.89536339 1.         0.         0.         0.         0.98372194\n",
      " 0.         0.9914283  0.         1.         1.         0.\n",
      " 1.         0.         0.         0.         0.         1.\n",
      " 0.         0.         1.         0.         0.         0.\n",
      " 0.         1.         0.98954987 0.         0.         1.\n",
      " 0.         0.         0.         0.         0.         1.\n",
      " 0.         0.         0.99113248 0.         0.         0.\n",
      " 0.         0.         1.         1.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         1.         1.\n",
      " 0.         0.         0.         1.         0.         1.\n",
      " 0.         0.         0.         0.         1.         0.\n",
      " 1.         1.         1.         1.         1.         0.\n",
      " 0.         0.         0.         0.         0.93296637 1.\n",
      " 0.         0.         1.         1.         1.         0.\n",
      " 0.         0.         0.         1.         1.         0.\n",
      " 0.         1.         1.         0.         0.         0.\n",
      " 0.         1.         1.         0.97179028 0.        ]\n",
      "Error visualizing topics for cluster_1: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n",
      "Cluster: cluster_2\n",
      "Topics: [0, 1, 1, 1, 0, -1, -1, 0, -1, 1, -1, 0, 1, -1, 0, 1, 1, 0, 0, 1, 1, -1, -1, -1, 2, -1, 1, -1, -1, -1, 0, -1, 1, -1, 0, 2, -1, 0, 1, 1, 2, 0, -1, -1, 2, 0, -1, -1, 0, -1, 0, -1, -1, 2, -1, -1, -1, 1, -1, -1, -1, -1, 2, 1, -1, -1, 1, 1, -1, 1, 0, -1, -1, 0, -1, 0, 0, 0, -1, 0, 0, -1, 2, -1, -1, -1, 2, -1, 0, 0, -1, -1, -1, 0, -1, -1, -1, 0, 2, 0, 1, -1, 2, -1, -1, 1, -1, 1, -1, 0, 1, 0, 2, 1, 1, -1, 0, 1, 0, -1, -1, 0, 2, 1, -1, 0, -1, -1, 0, -1, 0, 0, 1, 2, 2, 0, 0, 1, -1, 0, 0, 1, 0, 1, 2, 1, 0, 0, 0, -1, -1, 0, 2, 0, 1, 1, 1, 2, -1, -1, 1, 0, 0, 0, 0, 2, 2, -1, 1, -1, 2, 1, -1, 1, 0, -1, -1, 1, -1, 0, 0, 2, -1, -1, -1]\n",
      "Probabilities: [0.74764438 1.         0.80633824 1.         0.75219721 0.\n",
      " 0.         0.74239414 0.         0.77398646 0.         0.75219721\n",
      " 1.         0.         0.74383836 0.76258944 0.77601124 0.68723025\n",
      " 0.82677236 1.         1.         0.         0.         0.\n",
      " 1.         0.         1.         0.         0.         0.\n",
      " 0.73063162 0.         0.72411254 0.         0.98363875 1.\n",
      " 0.         0.88272573 0.7572668  0.75425161 1.         1.\n",
      " 0.         0.         0.85768009 0.74239414 0.         0.\n",
      " 0.73500875 0.         1.         0.         0.         0.865343\n",
      " 0.         0.         0.         0.82107761 0.         0.\n",
      " 0.         0.         0.85768009 1.         0.         0.\n",
      " 0.95986485 0.77980919 0.         0.88954671 0.93662532 0.\n",
      " 0.         0.99417263 0.         0.93662532 0.75219721 0.67780248\n",
      " 0.         0.8175137  0.74867482 0.         0.85768009 0.\n",
      " 0.         0.         0.91527457 0.         0.6758248  0.75219721\n",
      " 0.         0.         0.         0.93662532 0.         0.\n",
      " 0.         0.84474461 0.85190708 0.68515122 0.99856901 0.\n",
      " 1.         0.         0.         1.         0.         0.83911222\n",
      " 0.         0.88959462 0.99677704 0.82827012 0.97843715 0.77037504\n",
      " 0.75610998 0.         0.81866443 0.7572668  0.92335161 0.\n",
      " 0.         1.         1.         0.95439432 0.         1.\n",
      " 0.         0.         0.75219721 0.         0.68432653 0.69340814\n",
      " 1.         0.9865442  1.         0.987613   1.         0.90088095\n",
      " 0.         1.         0.75219721 0.72678371 0.98953908 0.82120239\n",
      " 0.9265069  0.79824454 0.70904503 0.74239414 1.         0.\n",
      " 0.         0.85117649 1.         0.79879313 0.99800537 0.93325088\n",
      " 0.84655105 1.         0.         0.         0.7572668  1.\n",
      " 0.8115993  1.         0.73815872 1.         0.95428067 0.\n",
      " 1.         0.         0.93249504 0.98732071 0.         0.84825151\n",
      " 1.         0.         0.         0.98185635 0.         0.93662532\n",
      " 0.74790826 1.         0.         0.         0.        ]\n",
      "Error visualizing topics for cluster_2: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n",
      "Cluster: cluster_3\n",
      "Topics: [0, 2, 0, 1, 0, -1, -1, 1, 2, 3, -1, 4, -1, -1, -1, 2, -1, 3, -1, 4, -1, 4, 4, 0, 4, -1, 0, -1, 0, -1, 1, 2, -1, -1, -1, 4, 2, 0, 1, 0, -1, 0, 0, -1, 0, -1, -1, -1, -1, 1, -1, 0, 0, 1, 3, -1, -1, -1, -1, 0, 0, -1, 1, -1, 1, -1, 0, -1, 0, -1, 2, 0, -1, -1, -1, 4, 3, -1, -1, -1, 0, 2, -1, 1, 4, -1, 2, 3, -1, 1, 1, 2, 3, 1, 1, -1, -1, 3, 1, -1, -1, 4, 0, -1, 0, 3, -1, 2, -1, -1, 0, -1, 4, -1, 1, 2, 1, -1, -1, 0, -1, -1, -1, 1, -1, 0, 1, 1, -1, -1, 1, -1, 4, 2, -1, -1, 3, 0, 3, -1, -1, -1, 2, 0, 3, -1, 0, -1, -1, 3, -1, -1, 3, 4, 4, -1, 1, -1, -1, -1, -1, -1, 0, 1, 0, -1, -1, -1]\n",
      "Probabilities: [1.         1.         1.         0.94690274 0.80365234 0.\n",
      " 0.         1.         1.         1.         0.         1.\n",
      " 0.         0.         0.         1.         0.         1.\n",
      " 0.         1.         0.         1.         0.89613352 0.68638099\n",
      " 1.         0.         1.         0.         0.93000481 0.\n",
      " 0.92648268 1.         0.         0.         0.         1.\n",
      " 1.         0.7501487  1.         0.74970943 0.         0.82499488\n",
      " 0.78703658 0.         0.80806475 0.         0.         0.\n",
      " 0.         0.9545506  0.         0.99389836 0.7087828  1.\n",
      " 1.         0.         0.         0.         0.         0.69359948\n",
      " 0.65965318 0.         1.         0.         1.         0.\n",
      " 0.86981327 0.         0.9699916  0.         1.         1.\n",
      " 0.         0.         0.         0.95937294 0.95333272 0.\n",
      " 0.         0.         0.92716042 1.         0.         0.98094541\n",
      " 1.         0.         1.         1.         0.         0.96919753\n",
      " 1.         1.         1.         1.         0.90851962 0.\n",
      " 0.         1.         0.94812116 0.         0.         1.\n",
      " 1.         0.         1.         0.97111975 0.         1.\n",
      " 0.         0.         0.65173347 0.         0.83749111 0.\n",
      " 1.         1.         0.95744299 0.         0.         0.82545048\n",
      " 0.         0.         0.         1.         0.         0.77527934\n",
      " 1.         0.94812116 0.         0.         0.94791473 0.\n",
      " 1.         1.         0.         0.         1.         1.\n",
      " 1.         0.         0.         0.         1.         0.79002996\n",
      " 1.         0.         1.         0.         0.         1.\n",
      " 0.         0.         0.97233725 1.         1.         0.\n",
      " 0.90338868 0.         0.         0.         0.         0.\n",
      " 1.         0.98882485 1.         0.         0.         0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1600: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1600: RuntimeWarning: k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "  warnings.warn(\"k >= N for N * N square matrix. \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_topics(topics_per_cluster):\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topic_model = data['topic_model']\n",
    "        topics = data['topics']\n",
    "        probabilities = data['probabilities']\n",
    "        \n",
    "        try:\n",
    "            # Check topics and probabilities before visualization\n",
    "            print(f\"Cluster: {cluster_label}\")\n",
    "            print(f\"Topics: {topics}\")\n",
    "            print(f\"Probabilities: {probabilities}\")\n",
    "            \n",
    "            # Visualize topics\n",
    "            fig = topic_model.visualize_topics()\n",
    "            plt.title(f\"Topics for {cluster_label}\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(f\"Error visualizing topics for {cluster_label}: {str(e)}\")\n",
    "\n",
    "# Assuming topics_per_cluster is already loaded from topics_per_cluster.pkl\n",
    "visualize_topics(topics_per_cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pickle file loaded successfully.\n",
      "Keys in the loaded data: dict_keys(['cluster_0', 'cluster_1', 'cluster_2', 'cluster_3'])\n",
      "Cluster: cluster_0\n",
      "Number of topics: 98\n",
      "Number of probabilities: 98\n",
      "Example topics: [0, 1, 1, -1, -1, 0, 0, 0, -1, 0]\n",
      "Example probabilities: [1.         1.         0.95181343 0.         0.         1.\n",
      " 0.91357558 0.92984099 0.         0.88086612]\n",
      "\n",
      "Cluster: cluster_1\n",
      "Number of topics: 123\n",
      "Number of probabilities: 123\n",
      "Example topics: [1, -1, 0, -1, 0, -1, 1, 1, -1, 0]\n",
      "Example probabilities: [1.         0.         1.         0.         0.7741955  0.\n",
      " 1.         1.         0.         0.86117789]\n",
      "\n",
      "Cluster: cluster_2\n",
      "Number of topics: 58\n",
      "Number of probabilities: 58\n",
      "Example topics: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Example probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Cluster: cluster_3\n",
      "Number of topics: 21\n",
      "Number of probabilities: 21\n",
      "Example topics: [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1]\n",
      "Example probabilities: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Function to load the topic models from the pickle file\n",
    "def load_topic_models(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        topics_per_cluster = pickle.load(file)\n",
    "    return topics_per_cluster\n",
    "\n",
    "# File path to the pickle file\n",
    "file_path = 'topics_per_cluster.pkl'\n",
    "\n",
    "# Load the topic models\n",
    "try:\n",
    "    topics_per_cluster = load_topic_models(file_path)\n",
    "    print(\"Pickle file loaded successfully.\")\n",
    "    \n",
    "    # Print the keys to verify the structure\n",
    "    print(\"Keys in the loaded data:\", topics_per_cluster.keys())\n",
    "    \n",
    "    # Example: Print some information from the loaded data\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        print(f\"Cluster: {cluster_label}\")\n",
    "        print(f\"Number of topics: {len(data['topics'])}\")\n",
    "        print(f\"Number of probabilities: {len(data['probabilities'])}\")\n",
    "        print(f\"Example topics: {data['topics'][:10]}\")\n",
    "        print(f\"Example probabilities: {data['probabilities'][:10]}\")\n",
    "        print()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading pickle file: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: cluster_0\n",
      "Topic topic_0: 36 documents\n",
      "Topic topic_1: 22 documents\n",
      "Topic topic_-1: 0 documents\n",
      "Cluster: cluster_1\n",
      "Topic topic_0: 46 documents\n",
      "Topic topic_1: 37 documents\n",
      "Topic topic_-1: 0 documents\n",
      "Cluster: cluster_2\n",
      "Topic topic_-1: 0 documents\n",
      "Cluster: cluster_3\n",
      "Topic topic_-1: 0 documents\n"
     ]
    }
   ],
   "source": [
    "def assign_documents_to_topics(topics_per_cluster):\n",
    "    classified_documents = {}\n",
    "\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topics = data['topics']\n",
    "        probabilities = data['probabilities']\n",
    "\n",
    "        # Create a dictionary to store document classifications by topics\n",
    "        classified_documents[cluster_label] = {f'topic_{topic}': [] for topic in set(topics)}\n",
    "\n",
    "        # Iterate through documents and assign them to topics based on probabilities\n",
    "        for doc_index in range(len(probabilities)):\n",
    "            max_topic_idx = topics[doc_index]\n",
    "            if max_topic_idx != -1:\n",
    "                topic_key = f'topic_{max_topic_idx}'\n",
    "                classified_documents[cluster_label][topic_key].append(doc_index)\n",
    "\n",
    "    return classified_documents\n",
    "\n",
    "# Example usage\n",
    "classified_docs = assign_documents_to_topics(topics_per_cluster)\n",
    "\n",
    "# Print the classified documents for each cluster\n",
    "for cluster_label, topics_dict in classified_docs.items():\n",
    "    print(f\"Cluster: {cluster_label}\")\n",
    "    for topic_key, doc_indices in topics_dict.items():\n",
    "        print(f\"Topic {topic_key}: {len(doc_indices)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: cluster_0\n",
      "Topic topic_-1: [('school', 0.033373692121562874), ('company', 0.031216665033610414), ('ai', 0.029117901302526526), ('new', 0.02767346700028996), ('year', 0.02734000623352968), ('technology', 0.02628171783550857), ('tool', 0.023919292084424035), ('time', 0.019901565581084642), ('one', 0.01989954742980924), ('chatgpt', 0.019265406462875372)]\n",
      "Topic topic_0: [('company', 0.03390097855673611), ('ai', 0.028230041150001575), ('new', 0.027593570930056252), ('google', 0.02579257479740746), ('technology', 0.023782677122833433), ('year', 0.023709284164320357), ('generative', 0.021080608720773032), ('one', 0.019926807181321702), ('openai', 0.019866057967612743), ('tool', 0.019394945953819773)]\n",
      "Topic topic_1: [('company', 0.035909256220474126), ('new', 0.03288411642871309), ('image', 0.03261165271780897), ('technology', 0.03064174947313116), ('ai', 0.027058740022584772), ('openai', 0.026101025572528205), ('microsoft', 0.02490968491208882), ('time', 0.024299148372854063), ('artificial', 0.021152880299625098), ('use', 0.02011381288186803)]\n",
      "Cluster: cluster_1\n",
      "Topic topic_-1: [('ai', 0.03546244540260965), ('company', 0.031309330697299645), ('apple', 0.02524423470010913), ('new', 0.02480928455300536), ('google', 0.022271904976658763), ('year', 0.021543789164750863), ('technology', 0.019631520083172555), ('generative', 0.017150914002374184), ('india', 0.017054582618377133), ('data', 0.016917428713123364)]\n",
      "Topic topic_0: [('company', 0.031270099864802454), ('technology', 0.030189042755368403), ('new', 0.027088460672530783), ('openai', 0.02680921447947811), ('time', 0.023735792000246603), ('ai', 0.021255698401666686), ('google', 0.020653093604320594), ('people', 0.0202874032370233), ('one', 0.019696109413307506), ('intelligence', 0.017848400943736277)]\n",
      "Topic topic_1: [('year', 0.037017034501257415), ('ai', 0.03612830463721428), ('company', 0.03363405975143703), ('metaverse', 0.02609049673969627), ('new', 0.02558025376221878), ('technology', 0.02455442385707205), ('china', 0.02442973543996782), ('generative', 0.02352240184495559), ('billion', 0.021896261301224004), ('world', 0.019390052972867146)]\n",
      "Cluster: cluster_2\n",
      "Topic topic_-1: [('company', 0.038198420284233786), ('ai', 0.03458191660856269), ('new', 0.02931125453508708), ('technology', 0.025370772954298893), ('one', 0.024832620625982686), ('people', 0.022646581896603818), ('generative', 0.021812146185845573), ('intelligence', 0.020827758998777254), ('year', 0.02040213529621379), ('time', 0.020259746184595445)]\n",
      "Cluster: cluster_3\n",
      "Topic topic_-1: [('company', 0.07354154943668899), ('microsoft', 0.0558972498694438), ('ai', 0.038960260630600325), ('google', 0.03648280628540389), ('tech', 0.034589383475087915), ('union', 0.03004018431031731), ('year', 0.028703089961623567), ('employee', 0.02700580590960198), ('time', 0.026662716576016834), ('worker', 0.025625831878925316)]\n"
     ]
    }
   ],
   "source": [
    "def get_topic_keywords(topics_per_cluster):\n",
    "    topic_keywords = {}\n",
    "\n",
    "    for cluster_label, data in topics_per_cluster.items():\n",
    "        topics = data['topics']\n",
    "        topic_model = data['topic_model']  # Assuming you have access to the BERTopic object\n",
    "\n",
    "        # Get topics with keywords from BERTopic\n",
    "        topics_keywords = topic_model.get_topics()\n",
    "\n",
    "        # Store topics and keywords\n",
    "        topic_keywords[cluster_label] = {\n",
    "            f'topic_{topic_num}': keywords[:10]  # Assuming you want to get top 10 keywords per topic\n",
    "            for topic_num, keywords in topics_keywords.items() if topic_num in set(topics)\n",
    "        }\n",
    "\n",
    "    return topic_keywords\n",
    "\n",
    "# Example usage\n",
    "topic_keywords = get_topic_keywords(topics_per_cluster)\n",
    "\n",
    "# Print or use topic_keywords dictionary as needed\n",
    "for cluster_label, topics_data in topic_keywords.items():\n",
    "    print(f\"Cluster: {cluster_label}\")\n",
    "    for topic_key, keywords in topics_data.items():\n",
    "        print(f\"Topic {topic_key}: {keywords}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
