[
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "'Infosys Inked 95 Large Deals in FY23, 40% of them New'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 30, 2023",
        "section": "STARTUPS & TECH",
        "length": "486 words",
        "byline": "Our Bureau",
        "story_text": "'Infosys Inked 95 Large Deals in FY23, 40% of them New'\nEconomic Times (E-Paper Edition)\nJune 29, 2023 Thursday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 486 words\nByline: Our Bureau\nHighlight: Nilekani says IT firm is on ‘solid foundation’ to grow and build resilience in the months to come\nBody\nBengaluru: Infosys is on a “solid foundation” to grow on back of large deals bagged in the fiscal year ended March \n31, 2023, nonexecutive chairman Nandan Nilekani said. “We had 95 large deals valued at $9.8 billion for the year, \nof which 40% were net new (deals). This promises a solid foundation to grow and build resilience in the months to \ncome,” Nilekani said on Wednesday at the 42nd annual general meeting of India's second largest IT company. In a \nvirtual address to shareholders, he said the Bengalurubased firm's capability to harness opportunities despite the \ndynamic times of inflation, interest rates, geopolitics, war, demand volatility and supply chain dislocations is \n“tremendous”. Infosys had projected 4-7% revenue growth — its lowest in six years — for the ongoing fiscal 2024. \nRivals HCLTech and Tata Consultancy Services are expected to kick off the results season on July 12. Infosys will \nreport results on July 20. Indian IT firms are bracing for a tough year amid the macro headwinds and tightening of \ndiscretionary spending by their clients. \nThe regional banking crisis in the US has hampered sentiments further in the banking and financial services vertical \nthat draws nearly 35-40% of the sector's total revenue. CLIENT ATTENTION CHANGING Chief executive Salil \nParekh said the overall demand environment has changed with the global economy and the GDP rates slowing \ndown. “We see now more clients' attention moving from digital and cloud transformation to cost efficiency and \nautomation. And we are fortunate that even in the consolidation area, we have a lot of opportunities,” he added. \nParekh recounted Infosys' re-  cent deal wins — from oil major BP ($1.5 billion) and Denmark's Danske Bank ($454 \nmillion) — as opportunities in the cost-efficiency space. The company said such deals help clients reduce costs \nthrough offshoring, automation and digitisation. Addressing questions on the deployment of generative artificial \nintelligence (AI), Infosys said it currently has 50 active client projects where they are using generative AI \napplications. “This is becoming an increasing part of the new world which is going to be defined on an AI-first \nbasis,” said Parekh. AI SUITE LAUNCHED Last month, the company launched Topaz — an AI suite of services, \nsolutions and platforms using generative AI technologies. It leverages Infosys applied AI framework and the \nInfosys Cobalt cloud. The solution has more than 12,000 use cases. Asked on the string of senior-level exits, such \nas Mohit Joshi and Ravi Kumar S to rivals, last year, Parekh reiterated that Infosys has a strong and deep \nleadership bench and internal talent pool.  “We feel that that group of leaders that Infosys has produced over the \nyears through its own leadership development and the work in delivery in markets, really prepares them to do more. \nWe have made sure that those leaders step up and take that on,” the CEO said.\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Tinkering With ChatGPT, Workers Wonder: Will This Take My Job?",
        "media": "The New York Times",
        "time": "September 19, 2023",
        "section": "BUSINESS; economy",
        "length": "1693 words",
        "byline": "Lydia DePillis and Steve Lohr",
        "story_text": "Tinkering With ChatGPT, Workers Wonder: Will This Take My Job?\nThe New York Times \nMarch 28, 2023 Tuesday 15:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; economy\nLength: 1693 words\nByline: Lydia DePillis and Steve Lohr\nHighlight: Artificial intelligence is confronting white-collar professionals more directly than ever. It could make them \nmore productive — or obsolete.\nBody\nIn December, the staff of the American Writers and Artists Institute — a 26-year-old membership organization for \ncopywriters — realized that something big was happening.\nThe newest edition of ChatGPT, a “large language model” that mines the internet to answer questions and perform \ntasks on command, had just been released. Its abilities were astonishing — and squarely in the bailiwick of people \nwho generate content, such as advertising copy and blog posts, for a living.\n“They’re horrified,” said Rebecca Matter, the institute’s president. Over the holidays, she scrambled to organize a \nwebinar on the pitfalls and potential of the new artificial-intelligence technology. More than 3,000 people signed up, \nshe said, and the overall message was cautionary but reassuring: Writers could use ChatGPT to complete \nassignments more quickly, and move into higher-level roles in content planning and search-engine optimization.\n“I do think it’s going to minimize short-form copy projects,” Ms. Matter said. “But on the flip side of that, I think there \nwill be more opportunities for things like strategy.”\nOpenAI’s ChatGPT is the latest advance in a steady march of innovations that have offered the potential to \ntransform many occupations and wipe out others, sometimes in tandem. It is too early to tally the enabled and the \nendangered, or to gauge the overall impact on labor demand and productivity. But it seems clear that artificial \nintelligence will impinge on work in different ways than previous waves of technology.\nThe positive view of tools like ChatGPT is that they could be complements to human labor, rather than \nreplacements. Not all workers are sanguine, however, about the prospective impact.\nKatie Brown is a grant writer in the Chicago suburbs for a small nonprofit group focused on addressing domestic \nviolence. She was shocked to learn in early February that a professional association for grant writers was promoting \nthe use of artificial-intelligence software that would automatically complete parts of an application, requiring the \nhuman simply to polish it before submitting.\nThe platform, called Grantable, is based on the same technology as ChatGPT, and it markets itself to freelancers \nwho charge by the application. That, she thought, clearly threatens opportunities in the industry.\n“For me, it’s common sense: Which do you think a small nonprofit will pick?” Ms. Brown said. “A full-time-salary-\nplus-benefits person, or someone equipped with A.I. that you don’t have to pay benefits for?”\nArtificial intelligence and machine learning have been operating in the background of many businesses for years, \nhelping to evaluate large numbers of possible decisions and better align supply with demand, for example. And \nTinkering With ChatGPT, Workers Wonder: Will This Take My Job?\nplenty of technological advancements over centuries have decreased the need for certain workers — although each \ntime, the jobs created have more than offset the number lost.\nChatGPT, however, is the first to confront such a broad range of white-collar workers so directly, and to be so \naccessible that people could use it in their own jobs. And it is improving rapidly, with a new edition released this \nmonth. According to a survey conducted by the job search website ZipRecruiter after ChatGPT’s release, 62 \npercent of job seekers said they were concerned that artificial intelligence could derail their careers.\n“ChatGPT is the one that made it more visible,” said Michael Chui, a partner at the McKinsey Global Institute who \nstudies automation’s effects. “So I think it did start to raise questions about where timelines might start to be \naccelerated.”\nThat’s also the conclusion of a White House report on the implications of A.I. technology, including ChatGPT. “The \nprimary risk of A.I. to the work force is in the general disruption it is likely to cause to workers, whether they find that \ntheir jobs are newly automated or that their job design has fundamentally changed,” the authors wrote.\nFor now, Guillermo Rubio has found that his job as a copywriter has changed markedly since he started using \nChatGPT to generate ideas for blog posts, write first drafts of newsletters, create hundreds of slight variations on \nstock advertising copy and summon research on a subject about which he might write a white paper.\nSince he still charges his clients the same rates, the tool has simply allowed him to work less. If the going rate for \ncopy goes down, though — which it might, as the technology improves — he’s confident he’ll be able to move into \nconsulting on content strategy, along with production.\n“I think people are more reluctant and fearful, with good reason,” Mr. Rubio, who is in Orange County, Calif., said. \n“You could look at it in a negative light, or you can embrace it. I think the biggest takeaway is you have to be \nadaptable. You have to be open to embracing it.”\nAfter decades of study, researchers understand a lot about automation’s impact on the work force. Economists \nincluding Daron Acemoglu at the Massachusetts Institute of Technology have found that since 1980, technology \nhas played a primary role in amplifying income inequality. As labor unions atrophied, hollowing out systems for \ntraining and retraining, workers without college educations saw their bargaining power reduced in the face of \nmachines capable of rudimentary tasks.\nThe advent of ChatGPT three months ago, however, has prompted a flurry of studies predicated on the idea that \nthis isn’t your average robot.\nOne team of researchers ran an analysis showing the industries and occupations that are most exposed to artificial \nintelligence, based on a model adjusted for generative language tools. Topping the list were college humanities \nprofessors, legal services providers, insurance agents and telemarketers. Mere exposure, however, doesn’t \ndetermine whether the technology is likely to replace workers or merely augment their skills.\nShakked Noy and Whitney Zhang, doctoral students at M.I.T., conducted a randomized, controlled trial on \nexperienced professionals in such fields as human relations and marketing. The participants were given tasks that \ntypically take 20 to 30 minutes, like writing news releases and brief reports. Those who used ChatGPT completed \nthe assignments 37 percent faster on average than those who didn’t — a substantial productivity increase. They \nalso reported a 20 percent increase in job satisfaction.\nA third study — using a program developed by GitHub, which is owned by Microsoft — evaluated the impact of \ngenerative A.I. specifically on software developers. In a trial run by GitHub’s researchers, developers given an \nentry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than \nthose who did the assignment manually.\nThose productivity gains are unlike almost any observed since the widespread adoption of the personal computer.\nTinkering With ChatGPT, Workers Wonder: Will This Take My Job?\n“It does seem to be doing something fundamentally different,” said David Autor, another M.I.T. economist, who \nadvises Ms. Zhang and Mr. Noy. “Before, computers were powerful, but they simply and robotically did what people \nprogrammed them to do.” Generative artificial intelligence, on the other hand, is “adaptive, it learns and is \ncapable of flexible problem solving.”\nThat’s very apparent to Peter Dolkens, a software developer for a company that primarily makes online tools for the \nsports industry. He has been integrating ChatGPT into his work for tasks like summarizing chunks of code to aid \ncolleagues who may pick up the project after him, and proposing solutions to problems that have him stumped. If \nthe answer isn’t perfect, he’ll ask ChatGPT to refine it, or try something different.\n“It’s the equivalent of a very well-read intern,” Mr. Dolkens, who is in London, said. “They might not have the \nexperience to know how to apply it, but they know all the words, they’ve read all the books and they’re able to get \npart of the way there.”\nThere’s another takeaway from the initial research: ChatGPT and Copilot elevated the least experienced workers \nthe most. If true, more generally, that could mitigate the inequality-widening effects of artificial intelligence.\nOn the other hand, as each worker becomes more productive, fewer workers are required to complete a set of \ntasks. Whether that results in fewer jobs in particular industries depends on the demand for the service provided, \nand the jobs that might be created in helping to manage and direct the A.I. “Prompt engineering,” for example, is \nalready a skill that those who play around with ChatGPT long enough can add to their résumés.\nSince demand for software code seems insatiable, and developers’ salaries are extremely high, increasing \nproductivity seems unlikely to foreclose opportunities for people to enter the field.\nThat won’t be the same for every profession, however, and Dominic Russo is pretty sure it won’t be true for his: \nwriting appeals to pharmacy benefit managers and insurance companies when they reject prescriptions for \nexpensive drugs. He has been doing the job for about seven years, and has built expertise with only on-the-job \ntraining, after studying journalism in college.\nAfter ChatGPT came out, he asked it to write an appeal on behalf of someone with psoriasis who wanted the \nexpensive drug Otezla. The result was good enough to require only a few edits before submitting it.\n“If you knew what to prompt the A.I. with, anyone could do the work,” Mr. Russo said. “That’s what’s really scares \nme. Why would a pharmacy pay me $70,000 a year, when they can license the technology and pay people $12 an \nhour to run prompts into it?”\nTo try to protect himself from that possible future, Mr. Russo has been building up his side business: selling pizzas \nout of his house in southern New Jersey, an enterprise that he figures won’t be disrupted by artificial intelligence.\nYet.\nAudio produced by Kate Winslett.\nAudio produced by Kate Winslett. \nPHOTO: Guillermo Rubio said his job as a copywriter has changed since he started using ChatGPT to generate \nideas for blog posts and write first drafts of newsletters. (PHOTOGRAPH BY IN-CAMERA DOUBLE EXPOSURE \nBY MARK ABRAMSON FOR THE NEW YORK TIMES) (A18) This article appeared in print on page A1, A18.\nLoad-Date: September 19, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Growth, Competitive Pay Top Priority for GenZ to Stay in a Job",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 16, 2023",
        "section": "COMPANIES",
        "length": "590 words",
        "byline": "Brinda.Sarkar@timesgroup.com",
        "story_text": "Growth, Competitive Pay Top Priority for GenZ to Stay in a Job\nEconomic Times (E-Paper Edition)\nNovember 17, 2023 Friday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 590 words\nByline: Brinda.Sarkar@timesgroup.com\nHighlight: Adobe study delves into the career motivations and workplace expectations of young workers\nBody\nBengaluru : GenZ prioritizes professional growth and competitive pay over other workplace considerations for \ncontinuing in their current jobs, according to the findings of a survey by Adobe.  As many as 46% respondents \nranked ‘no clear path for promotion’ as the number one reason for leaving a job, closely followed by ‘less than \nsatisfactory pay’ (43%), according to the ‘Future of Workplace’ study by the US software company shared \nexclusively with ET . Nine in 10 GenZ workers (93%) are eager to grow, not only in impact but up the corporate \nladder to the C-suite. As emerging technologies like Generative AI become more commonplace, GenZ is also \nexcited about its use at the workplace with 91% saying they feel prepared for their employer to adopt the \ntechnology in everyday work. \nFurther, regardless of whether their workplace has implemented guidelines on Gen AI, 81% of respondents \nadmitted to having tried using the technology to aid in their work. GenZ is also hungry for mentorship and seeks out \ncareer development opportunities — 91% said they believe a workplace mentor is crucial for their career. However, \njust 76% reported having a mentor at work.  Also, 42% cited ‘lack of transparency about the future of the business \nand company’ as a factor to leave jobs while 39% rated ‘work not interesting enough to make an impact’ as a \nreason. About 37% of the respondents cited ‘not enough talent development programmes to acquire new skills’ as a \nfactor. The study delved into the career motivations and workplace expectations of GenZ workers. It surveyed over \n1,000 GenZ early career starters working at medium to large-sized companies in India. \"Gen Z’s readiness to \nembrace emerging technologies, passion for meaningful work, and hunger for inclusive, value-driven workplaces \nare propelling organisations to adopt changes that will help shape the modern workplace and move them into a new \nera of growth,” said Prativa Mohapatra, managing director at Adobe India. Generation Z, often abbreviated as \nGenZ, refers to the demographic cohort that comes after the millennial generation. It generally includes individuals \nborn from the mid-1990s to the early 2010s. This generation is often characterised by its upbringing in a digital and \ninterconnected world, having grown up with easy access to technology, social media, and the internet. Companies, \ntoo, are pulling out all the stops to engage with GenZ employees. At edtech unicorn Simplilearn, more than half the \nworkforce comprises GenZ professionals. The company is focusing on encouraging cross-functional collaboration, \nproviding them with a line of sight for career advancement and facilitating inter-departmental mobility. Flexibility in \nwork arrangements and a purpose-driven approach that outlines their career progression are highly attractive to this \ngeneration, said Krishna Kumar, founder of Simplilearn. For a generation that has grown up constantly connected \nand technologically advanced, working with cutting-edge technologies is vital to further their careers, said Santosh \nTK, director of talent acquisition, Dell Technologies. The company has rolled out GenNext, an employee resource \ngroup that specifically targets GenZ, and focuses on professional growth, skill development and community \nengagement. The onus is on organisations to develop a flexible career model and clearly define career paths, as \nwell as provide a flexible but firm work policy to better engage with GenZ at the workplace, said Rajul Mathur, \nconsulting leader – work and rewards India, WTW.\nGrowth, Competitive Pay Top Priority for GenZ to Stay in a Job\nLoad-Date: November 16, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "ChatGPT Convulses Big Tech With Its Promise and Its Peril",
        "media": "The New York Times",
        "time": "March 9, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1450 words",
        "byline": "By Tripp Mickle, Cade Metz and Nico Grant",
        "story_text": "ChatGPT Convulses Big Tech With Its Promise and Its Peril\nThe New York Times\nMarch 9, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1450 words\nByline: By Tripp Mickle, Cade Metz and Nico Grant\nBody\nThe new technology could upend many online businesses. But for companies that figure out how to work with it, A.I. \ncould be a boon.\nSAN FRANCISCO -- When Aaron Levie, the chief executive of Box, tried a new A.I. chatbot called ChatGPT in \nearly December, it didn't take him long to declare, ''We need people on this!'' \n  He cleared his calendar and asked employees to figure out how the technology, which instantly provides \ncomprehensive answers to complex questions, could benefit Box, a cloud computing company that sells services \nthat help businesses manage their online data.\n  Mr. Levie's reaction to ChatGPT was typical of the anxiety -- and excitement -- over Silicon Valley's new new thing. \nChatbots have ignited a scramble to determine whether their technology could upend the economics of the internet, \nturn today's powerhouses into has-beens or create the industry's next giants.\n  Not since the iPhone has the belief that a new technology could change the industry run so deep. Cloud \ncomputing companies are rushing to deliver chatbot tools, even as they worry that the technology will gut other \nparts of their businesses. E-commerce outfits are dreaming of new ways to sell things. Social media platforms are \nbeing flooded with posts written by bots. And publishing companies are fretting that even more dollars will be \nsqueezed out of digital advertising.\n  The volatility of chatbots has made it impossible to predict their impact. In one second, the systems impress by \nfielding a complex request for a five-day itinerary, making Google's search engine look archaic. A moment later, \nthey disturb by taking conversations in dark directions and launching verbal assaults.\n  The result is an industry gripped with the question: What do we do now?\n  ''Everybody is agitated,'' said Erik Brynjolfsson, an economist at Stanford's Institute for Human-Centered Artificial \nIntelligence. ''There's a lot of value to be won or lost.''\n  Rarely have so many tech sectors been simultaneously exposed. The A.I. systems could disrupt $100 billion in \ncloud spending, $500 billion in digital advertising and $5.4 trillion in e-commerce sales, according to totals from IDC, \na market research firm, and GroupM, a media agency.\n  Google, perhaps more than any other company, has reason to both love and hate the chatbots. It has declared a \n''code red'' because their abilities could be a blow to its $162 billion business showing ads on searches.\nChatGPT Convulses Big Tech With Its Promise and Its Peril\n  But Google's cloud computing business could be a big winner. Smaller companies like Box need help building \nchatbot tools, so they are turning to the giants that process, store and manage information across the web. Those \ncompanies -- Google, Microsoft and Amazon -- are in a race to provide businesses with the software and \nsubstantial computing power behind their A.I. chatbots.\n  ''The cloud computing providers have gone all in on A.I. over the last few months,'' said Clément Delangue, head \nof the A.I. company Hugging Face, which helps run open-source projects similar to ChatGPT. ''They are realizing \nthat in a few years, most of the spending will be on A.I., so it is important for them to make big bets.''\n  When Microsoft introduced a chatbot-equipped Bing search engine last month, Yusuf Mehdi, the head of Bing, \nsaid the company was wrestling with how the new version would make money. Advertising will be a major driver, he \nsaid, but the company expects fewer ads than traditional search allows.\n  ''We're going to learn that as we go,'' Mr. Mehdi said.\n  As Microsoft figures out a chatbot business model, it is forging ahead with plans to sell the technology to others. It \ncharges $10 a month for a cloud service, built in conjunction with the OpenAI lab, that provides developers with \ncoding suggestions, among other things.\n  Google has similar ambitions for its A.I. technology. After introducing its Bard chatbot last month, the company \nsaid its cloud customers would be able to tap into that underlying system for their own businesses.\n  But Google has not yet begun exploring how to make money from Bard itself, said Dan Taylor, a company vice \npresident of global ads. It considers the technology ''experimental,'' he said, and is focused on using the so-called \nlarge language models that power chatbots to improve traditional search.\n  ''The discourse on A.I. is rather narrow and focused on text and the chat experience,'' Mr. Taylor said. ''Our vision \nfor search is about understanding information and all its forms: language, images, video, navigating the real world.''\n  Sridhar Ramaswamy, who led Google's advertising division from 2013 to 2018, said Microsoft and Google \nrecognized that their current search business might not survive. ''The wall of ads and sea of blue links is a thing of \nthe past,'' said Mr. Ramaswamy, who now runs Neeva, a subscription-based search engine.\n  Amazon, which has a larger share of the cloud market than Microsoft and Google combined, has not been as \npublic in its chatbot pursuit as the other two, though it has been working on A.I. technology for years.\n  But in January, Andy Jassy, Amazon's chief executive, corresponded with Mr. Delangue of Hugging Face, and \nweeks later Amazon expanded a partnership to make it easier to offer Hugging Face's software to customers.\n  As that underlying tech, known as generative A.I., becomes more widely available, it could fuel new ideas in e-\ncommerce. Late last year, Manish Chandra, the chief executive of Poshmark, a popular online secondhand store, \nfound himself daydreaming during a long flight from India about chatbots building profiles of people's tastes, then \nrecommending and buying clothes or electronics. He imagined grocers instantly fulfilling orders for a recipe.\n  ''It becomes your mini-Amazon,'' said Mr. Chandra, who has made integrating generative A.I. into Poshmark one \nof the company's top priorities over the next three years. ''That layer is going to be very powerful and disruptive and \nstart almost a new layer of retail.''\n  But generative A.I is causing other headaches. In early December, users of Stack Overflow, a popular social \nnetwork for computer programmers, began posting substandard coding advice written by ChatGPT. Moderators \nquickly banned A.I.-generated text.\n  Part of the problem was that people could post this questionable content far faster than they could write posts on \ntheir own, said Dennis Soemers, a moderator for the site. ''Content generated by ChatGPT looks trustworthy and \nprofessional, but often isn't,'' he said.\nChatGPT Convulses Big Tech With Its Promise and Its Peril\n  When websites thrived during the pandemic as traffic from Google surged, Nilay Patel, editor in chief of The \nVerge, a tech news site, warned publishers that the search giant would one day turn off the spigot. He had seen \nFacebook stop linking out to websites and foresaw Google following suit in a bid to boost its own business.\n  He predicted that visitors from Google would drop from a third of websites' traffic to nothing. He called that day \n''Google zero.''\n  ''People thought I was crazy,'' said Mr. Patel, who redesigned The Verge's website to protect it. Because chatbots \nreplace website search links with footnotes to answers, he said, many publishers are now asking if his prophecy is \ncoming true.\n  For the past two months, strategists and engineers at the digital advertising company CafeMedia have met twice a \nweek to contemplate a future where A.I. chatbots replace search engines and squeeze web traffic.\n  The group recently discussed what websites should do if chatbots lift information but send fewer visitors. One \npossible solution would be to encourage CafeMedia's network of 4,200 websites to insert code that limited A.I. \ncompanies from taking content, a practice currently allowed because it contributes to search rankings.\n  ''There are a million things to be worried about,'' said Paul Bannister, CafeMedia's chief strategy officer. ''You have \nto figure out what to prioritize.''\n  Courts are expected to be the ultimate arbiter of content ownership. Last month, Getty Images sued Stability AI, \nthe start-up behind the art generator tool Stable Diffusion, accusing it of unlawfully copying millions of images. The \nWall Street Journal has said using its articles to train an A.I. system requires a license.\n  In the meantime, A.I. companies continue collecting information across the web under the ''fair use'' doctrine, \nwhich permits limited use of material without permission.\n  ''The world is facing a new technology, and the law is groping to find ways of dealing with it,'' said Bradley J. \nHulbert, a lawyer who specializes in this area. ''No one knows where the courts will draw the lines.''\n  Karen Weise contributed reporting from Seattle.Karen Weise contributed reporting from Seattle.\nhttps://www.nytimes.com/2023/03/08/technology/chatbots-disrupt-internet-industry.html\nGraphic\n \nPHOTOS: Manish Chandra has made integrating generative A.I. one of the top priorities for Poshmark.\n ''There are a million things to be worried about,'' said Paul Bannister of CafeMedia. (A21) This article appeared in \nprint on page A1, A21.               \nLoad-Date: March 9, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "US tech stocks: Is it time to book profits?",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 20, 2023",
        "section": "ET WEALTH",
        "length": "889 words",
        "byline": "Sanket Dhanorkar",
        "story_text": "US tech stocks: Is it time to book profits?\nEconomic Times (E-Paper Edition)\nJune 19, 2023 Monday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ET WEALTH\nLength: 889 words\nByline: Sanket Dhanorkar\nHighlight: The AI buzz and hopes of a rate hike pause by the US Fed are helping tech stocks post a strong \nrebound.\nBody\nWith shares of US tech giants buzzing again, tech-focused funds are scorching the performance charts. Mirae \nAsset NYSE FANG+ ETF has been a trailblazer among all equity funds, fetching 66% year-to-date return. \nEdelweiss US Tech Equity is next with 42% return. The funds based on the Nasdaq 100 index, dominated by tech \ncompanies, are also among the big pacesetters, along with other innovation-led funds. \nIs this rebound built on hype or are bigger gains in store? The story was completely different towards the end of last \nyear. Bleeding profusely under the burden of elevated interest rates, earnings disappointments and lofty valuations, \nthe biggest names seemed to be in a freefall. Fears of an impending recession loomed large over the US economy. \nThe US Nasdaq 100 index had fallen 34% by the end of 2022. Some of the big names had tanked by as much as \n60%. But within months, the tech basket has emerged as a bright shining light. The Nasdaq 100 is up 35% year-to-\ndate. Even the S&P 500 index's 13% gains this year are almost entirely powered by a handful of stocks, all tech \ngiants. So, what has changed?  To be sure, most of the dark clouds continue to cast shadows even today. Inflation \nin the US may have moderated, but remains elevated from a historical perspective. The spectre of recession also \ncontinues to loom large. “There are more reasons to suspect that recession is coming than there are to still believe \nin a soft landing,” observes a note by Mirae Asset AMC. The trouble brewing within the US banking system may \nhave catapulted the US tech stocks into a higher orbit. The reason is that the banking sector's foibles, along with \nfears of recession, may force the US Federal Reserve to hit the brakes on its rate-hike spree. This will free the US \ntech industry from its shackles. “The anticipated pause in the US Fed's rate cycle is the biggest trigger for rebound \nin tech stocks,” says Vikas Gupta, Chief Investment Strategist, OmniScience Capital.  While the Fed has indeed \npaused rate hikes in its recent policy, it has indicated two further rate increases this year, pouring cold water on the \nmarket's expectations. This unexpected twist could arrest the gains in tech stocks. However, the sharp uptick is not \nmerely due to expectations of an end to rate hikes. Much of the current buoyancy seems to be based on the hype \naround artificial intelligence (AI). The narrative around generative AI has built up at a furious pace, drowning out \nprevious scepticism. The bigbang entry of ChatGPT and its successors has kickstarted a firestorm of AI-driven \ntechnologies. Siddharth Srivastava, Head, ETF Products, Mirae Asset Investment Managers, says, “With the \nsuccess of ChatGPT, the quest for being in the generative AI race has compelled the companies to invest big.”  \nChipmaker Nvidia Corp set tongues wagging recently when it forecast sales far higher than analysts' estimates led \nby demand for its AI processors. This has set off a feeding frenzy in all tech companies known to be building \nsignificant AI capabilities. The shares of businesses powering the AI revolution, such as semiconductor firms, are \nalso riding the wave.  Even as the generative AI craze sweeps the world, it is a nascent technology. Chatbots, for \ninstance, may have caught everyone by surprise with their wide-  ranging capabilities, but remain riddled with bugs \nand information blind spots. The current AI capabilities may not exactly reshape businesses overnight as expected. \n“AI technologies are still in the exploratory stage, with no meaningful revenue streams accruing to businesses yet,” \nUS tech stocks: Is it time to book profits?\nobserves Raj Mehta, Fund Manager, PPFAS Mutual Fund. Yet, fears of this being merely a hype are refuted by \nexperts. Gupta insists AI is a multi-decadal growth vector whose real impact will be visible after 5-7 years. “AI is not \njust hype. It is very real, with strong capabilities for pulling off amazing things,” he says. In fact, Gupta reckons \ncompanies are underplaying AI's real capabilities amid mounting concerns among regulators about the technology's \npotentially disruptive impact on society.  The euphoria is now sending valuations of the tech basket soaring. The \nNasdaq 100 is trading at 24 times its forward earnings, well above its long-term average of 19. Select names, such \nas Nvidia (up 159%), Meta Platforms (up 120%) and AMD (up 82%), have shot up fast in 2023. But investors can \ntake solace in the knowledge that the businesses at the forefront of this mania are not loss-making hype machines. \nProven cash-generating behemoths like Meta, Alphabet, Microsoft and Nvidia are among the names leading the AI \ntransformation. Betting on these tech giants is not the same as putting money in promising upstarts. “The first \nmover advantage in the coming AI transformation will be with the bigger companies that have enough resources to \nexplore multiple opportunities in this space,” says Mehta.  Even so, investors looking for quick gains from the tech \nbasket may be disappointed. After the recent run-up, they should enter with a long-term view. Srivastava suggests \nthe NYSE FANG+ index and Nasdaq 100 index may look expensive in terms of valuation, but one may continue to \ninvest or hold for the long term as these disruptive companies continue to show potential for earnings growth. \nPlease send your feedback to etwealth@timesgroup.com\nLoad-Date: June 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Transcript: Ezra Klein Interviews Ethan Mollick; The Ezra Klein Show",
        "media": "The New York Times",
        "time": "April 2, 2024",
        "section": "PODCASTS",
        "length": "13611 words",
        "byline": " ",
        "story_text": "Transcript: Ezra Klein Interviews Ethan Mollick; The Ezra Klein Show\nThe New York Times \nApril 2, 2024 Tuesday 15:46 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 13611 words\nHighlight: The April 2, 2024, episode of “The Ezra Klein Show.”\nBody\nEvery Tuesday and Friday, Ezra Klein invites you into a conversation about something that matters, like today’s \nepisode with Ethan Mollick. Listen wherever you get your podcasts.\nTranscripts of our episodes are made available as soon as possible. They are not fully edited for grammar or \nspelling.\n[MUSIC PLAYING]\nEZRA KLEIN: From New York Times Opinion, this is “The Ezra Klein Show.”\n[MUSIC PLAYING]\nThis feels wrong to me. But I have checked the dates. It was barely more than a year ago that I wrote this piece \nabout A.I., with the title “This Changes Everything.” I ended up reading it on the show, too. And the piece was about \nthe speed with which A.I. systems were improving. It argued that we can usually trust that tomorrow is going to be \nroughly like today, that next year is going to be roughly like this year. That’s not what we’re seeing here. These \nsystems are growing in power and capabilities at an astonishing rate.\nThe growth is exponential, not linear. When you look at surveys of A.I. researchers, their timeline for how quickly \nA.I. is going to be able to do basically anything a human does better and more cheaply than a human — that \ntimeline is accelerating, year by year, on these surveys. When I do my own reporting, talking to the people inside \nthese companies, people at this strange intersection of excited and terrified of what they’re building, no one tells me \nthey are seeing a reason to believe progress is going to slow down.\nAnd you might think that’s just hype, but a lot of them want it to slow down. A lot of them are scared of how quickly it \nis moving. They don’t think that society is ready for it, that regulation is ready for it. They think the competitive \npressures between the companies and the countries are dangerous. They wish something would happen to make it \nall go slower. But what they are seeing is they are hitting the milestones faster, that we’re getting closer and closer \nto truly transformational A.I., that there is so much money and talent and attention flooding into the space that that \nis becoming its own accelerant. They are scared. We should at least be paying attention.\nAnd yet, I find living in this moment really weird, because as much as I know this wildly powerful technology is \nemerging beneath my fingertips, as much as I believe it’s going to change the world I live in profoundly, I find it \nreally hard to just fit it into my own day to day work. I consistently sort of wander up to the A.I., ask it a question, find \nmyself somewhat impressed or unimpressed at the answer. But it doesn’t stick for me. It is not a sticky habit. It’s \ntrue for a lot of people I know.\nAnd I think that failure matters. I think getting good at working with A.I. is going to be an important skill in the next \nfew years. I think having an intuition for how these systems work is going to be important just for understanding \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nwhat is happening to society. And you can’t do that if you don’t get over this hump in the learning curve, if you don’t \nget over this part where it’s not really clear how to make A.I. part of your life.\nSo I’ve been on a personal quest to get better at this. And in that quest, I have a guide. Ethan Mollick is a professor \nat the Wharton School of the University of Pennsylvania. He studies and writes about innovation and \nentrepreneurship. But he has this newsletter, One Useful Thing, that has become, really, I think, the best guide how \nto begin using, and how to get better at using A.I. He’s also got a new book on the subject, “Co-Intelligence.” And \nso I asked him on the show to walk me through what he’s learned.\nThis is going to be, I should say, the first of three shows on this topic. This one is about the present. The next is \nabout some things I’m very worried about in the near future, particularly around what A.I. is going to do to our digital \ncommons. And then, we’re going to have a show that is a little bit more about the curve we are all on about the \nslightly further future, and the world we might soon be living in.\nAs always, my email for guest suggestions, thoughts, feedback, ezrakleinshow@nytimes.com\nEthan Mollick, welcome to the show.\nETHAN MOLLICK: Thanks for having me.\nEZRA KLEIN: So let’s assume I’m interested in A.I. And I tried ChatGPT a bunch of times, and I was suitably \nimpressed and weirded out for a minute. And so I know the technology is powerful. I’ve heard all these predictions \nabout how it will take everything over, or become part of everything we do. But I don’t actually see how it fits into my \nlife, really, at all. What am I missing?\nETHAN MOLLICK: So you’re not alone. This is actually very common. And I think part of the reason is that the way \nChatGPT works isn’t really set up for you to understand how powerful it is. You really do need to use the paid \nversion, they are significantly smarter. And you can almost think of this — like, GPT-3, which was — nobody really \npaid attention to when it came out, before ChatGPT, was about as good as a sixth grader at writing. GPT-3.5, the \nfree version of ChatGPT, is about as good as a high school, or maybe even a college freshman or sophomore.\nAnd GPT-4 is often as good as a Ph.D. in some forms of writing. Like, there’s a general smartness that increases. \nBut even more than that, ability seems to increase. And you’re much more likely to get that feeling that you are \nworking with something amazing as a result. And if you don’t work with the frontier models, you can lose track of \nwhat these systems can actually do. On top of that, you need to start just using it. You kind of have to push past \nthose first three questions.\nMy advice is usually bring it to every table that you come to in a legal and ethical way. So I use it for every aspect of \nmy job in ways that I legally and ethically can, and that’s how I learn what it’s good or bad at.\nEZRA KLEIN: When you say, bring it to every table you’re at, one, that sounds like a big pain, because now I’ve got \nto add another step of talking to the computer constantly. But two, it’s just not obvious to me what that would look \nlike. So what does it look like? What does it look like for you, or what does it look like for others — that you feel is \napplicable widely?\nETHAN MOLLICK: So I just finished this book. It’s my third book. I keep writing books, even though I keep \nforgetting that writing books is really hard. But this was, I think, my best book, but also the most interesting to write. \nAnd it was thanks to A.I. And there’s almost no A.I. writing in the book, but I used it continuously. So things that \nwould get in the way of writing — I think I’m a much better writer than A.I. — hopefully, people agree. But there’s a \nlot of things that get in your way as a writer.\nSo I would get stuck on a sentence. I couldn’t do a transition. Give me 30 versions of this sentence in radically \ndifferent styles. There’s 200 different citations. I had the A.I. read through the papers that I read through, write notes \non them, and organize them for me. I had the A.I. suggest analogies that might be useful. I had the A.I. act as \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nreaders, and in different personas, read through the paper from the perspective of, is there some example I could \ngive that’s better? Is this understandable or not?\nAnd that’s very typical of the kind of way that I would, say, bring it to the table. Use it for everything, and you’ll find \nits limits and abilities.\nEZRA KLEIN: Let me ask you one specific question on that, because I’ve been writing a book. And on some bad \ndays of writing the book, I decided to play around with GPT-4. And of the things that it got me thinking about was \nthe kind of mistake or problem these systems can help you see and the kind they can’t. So they can do a lot of, give \nme 15 versions of this paragraph, 30 versions of this sentence. And every once in a while, you get a good version \nor you’ll shake something a little bit loose.\nBut almost always when I am stuck, the problem is I don’t know what I need to say. Oftentimes, I have structured \nthe chapter wrong. Oftentimes, I’ve simply not done enough work. And one of the difficulties for me about using A.I. \nis that A.I. never gives me the answer, which is often the true answer — this whole chapter is wrong. It is poorly \nstructured. You have to delete it and start over. It’s not feeling right to you because it is not right.\nAnd I actually worry a little bit about tools that can see one kind of problem and trick you into thinking it’s this easier \nproblem, but make it actually harder for you to see the other kind of problem that maybe if you were just sitting \nthere, banging your head against the wall of your computer, or the wall of your own mind, you would eventually find.\nETHAN MOLLICK: I think that’s a wise point. I think there’s two or three things bundled there. The first of those is \nA.I. is good, but it’s not as good as you. It is, say, at the 80th percentile of writers based on some results, maybe a \nlittle bit higher. In some ways, if it was able to have that burst of insight and to tell you this chapter is wrong, and I’ve \nthought of a new way of phrasing it, we would be at that sort of mythical AGI level of A.I. as smart as the best \nhuman. And it just isn’t yet.\nI think the second issue is also quite profound, which is, what does using this tool shape us to do and not do? One \nnice example that you just gave is writing. And I think a lot of us think about writing as thinking. We don’t know if \nthat’s true for everybody, but for writers, that’s how they think. And sometimes, getting that shortcut could shortcut \nthe thinking process. So I’ve had to change sometimes a little bit how I think when I use A.I., for better or for worse. \nSo I think these are both concerns to be taken seriously.\nEZRA KLEIN: For most people — right, if you’re just going to pick one model, what would you pick? What do you \nrecommend to people? And second, how do you recommend they access it? Because something going on in the \nA.I. world is there are a lot of wrappers on these models. So ChatGPT has an app. Claude does not have an app. \nObviously, Google has its suite of products. And there are organizations that have created a different spin on \nsomebody else’s A.I. — so Perplexity, which is, I believe, built on GPT-4 now, you can pay for it.\nAnd it’s more like a search engine interface, and has some changes made to it. For a lot of people, the question of \nhow easy and accessible the thing is to access really matters. So which model do you recommend to most people? \nAnd which entry door do you recommend to most people? And do they differ?\nETHAN MOLLICK: It’s a really good question. I recommend working with one of the models as directly as possible, \nthrough the company that creates them. And there’s a few reasons for that. One is you get as close to the \nunadulterated personality as possible. And second, that’s where features tend to roll out first. So if you like sort of \nintellectual challenge, I think Claude 3 is the most intellectual of the models, as you said.\nThe biggest capability set right now is GPT-4, so if you do any math or coding work, it does coding for you. It has \nsome really interesting interfaces. That’s what I would use — and because GPT-5 is coming out, that’s fairly \npowerful. And Google is probably the most accessible, and plugged into the Google ecosystem. So I don’t think you \ncan really go wrong with any of these. Generally, I think Claude 3 is the most likely to freak you out right now. And \nGPT-4 is probably the most likely to be super useful right now.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nEZRA KLEIN: So you say it takes about 10 hours to learn a model. Ten hours is a long time, actually. What are you \ndoing in that 10 hours? What are you figuring out? How did you come to that number? Give me some texture on \nyour 10 hour rule.\nETHAN MOLLICK: So first off, I want to indicate the 10 hours is as arbitrary as 10,000 steps. Like, there’s no \nscientific basis for it. This is an observation. But it also does move you past the, I poked at this for an evening, and it \nmoves you towards using this in a serious way. I don’t know if 10 hours is the real limit, but it seems to be \nsomewhat transformative. The key is to use it in an area where you have expertise, so you can understand what it’s \ngood or bad at, learn the shape of its capabilities.\nWhen I taught my students this semester how to use A.I., and we had three classes on that, they learned the theory \nbehind it. But then I gave them an assignment, which was to replace themselves at their next job. And they created \namazing tools, things that filed flight plans or did tweeting, or did deal memos. In fact, one of the students created a \nway of creating user personas, which is something that you do in product development, that’s been used several \nthousand times in the last couple of weeks in different companies.\nSo they were able to figure out uses that I never thought of to automate their job and their work because they were \nasked to do that. So part of taking this seriously in the 10 hours is, you’re going to try and use it for your work. You’ll \nunderstand where it’s good or bad, what it can automate, what it can’t, and build from there.\nEZRA KLEIN: Something that feels to me like a theme of your work is that the way to approach this is not learning a \ntool. It is building a relationship. Is that fair?\nETHAN MOLLICK: A.I. is built like a tool. It’s software. It’s very clear at this point that it’s an emulation of thought. \nBut because of how it’s built, because of how it’s constructed, it is much more like working with a person than \nworking with a tool. And when we talk about it this way, I almost feel kind of bad, because there’s dangers in \nbuilding a relationship with a system that is purely artificial, and doesn’t think and have emotions. But honestly, that \nis the way to go forward. And that is sort of a great sin, anthropomorphization, in the A.I. literature, because it can \nblind you to the fact that this is software with its own sets of foibles and approaches.\nBut if you think about it like programming, then you end up in trouble. In fact, there’s some early evidence that \nprogrammers are the worst people at using A.I. because it doesn’t work like software. It doesn’t do the things you \nwould expect a tool to do. Tools shouldn’t occasionally give you the wrong answer, shouldn’t give you different \nanswers every time, shouldn’t insult you or try to convince you they love you.\nAnd A.I.s do all of these things. And I find that teachers, managers, even parents, editors, are often better at using \nthese systems, because they’re used to treating this as a person. And they interact with it like a person would, \ngiving feedback. And that helps you. And I think the second piece of that “not tool” piece is that when I talk to \nOpenAI or Anthropic, they don’t have a hidden instruction manual. There is no list of how you should use this as a \nwriter, or as a marketer, or as an educator.\nThey don’t even know what the capabilities of these systems are. They’re all sort of being discovered together. And \nthat is also not like a tool. It’s more like a person with capabilities that we don’t fully know yet.\nEZRA KLEIN: So you’ve done this with all the big models. You’ve done, I think, much more than this, actually, with \nall the big models. And one thing you describe feeling is that they don’t just have slightly different strengths and \nweaknesses, but they have different — for lack of a better term, and to anthropomorphize — personalities, and that \nthe 10 hours in part is about developing an intuition not just for how they work, but kind of how they are and how \nthey talk, the sort of entity you’re dealing with.\nSo give me your high level on how GPT-4 and Claude 3 and Google’s Gemini are different. What are their \npersonalities like to you?\nETHAN MOLLICK: It’s important to know the personalities not just as personalities, but because there are tricks. \nThose are tunable approaches that the system makers decide. So it’s weird to have this — in one hand, don’t \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nanthropomorphize, because you’re being manipulated, because you are. But on the other hand, the only useful way \nis to anthropomorphize. So keep in mind that you are dealing with the choices of the makers.\nSo for example, Claude 3 is currently the warmest of the models. And it is the most allowed by its creators, \nAnthropic, I think, to act like a person. So it’s more willing to give you its personal views, such as they are. And \nagain, those aren’t real views. Those are views to make you happy — than other models. And it’s a beautiful writer, \nvery good at writing, kind of clever — closest to humor, I’ve found, of any of the A.I.s. Less dad jokes and more \nactual almost jokes.\nGPT-4 feels like a workhorse at this point. It is the most neutral of the approaches. It wants to get stuff done for you. \nAnd it will happily do that. It doesn’t have a lot of time for chitchat. And then we’ve got Google’s Bard, which feels \nlike — or Gemini now — which feels like it really, really wants to help. We use this for teaching a lot. And we build \nthese scenarios where the A.I. actually acts like a counterparty in a negotiation.\nSo you get to practice the negotiation by negotiating with the A.I. And it works incredibly well. I’ve been building \nsimulations for 10 years, can’t imagine what a leap this has been. But when we try and get Google to do that, it \nkeeps leaping in on the part of the students, to try and correct them and say, no, you didn’t really want to say this. \nYou wanted to say that. And I’ll play out the scenario as if it went better. And it really wants to kind of make things \ngood for you.\nSo these interactions with the A.I. do feel like you’re working with people, both in skills and in personality.\nEZRA KLEIN: You were mentioning a minute ago that what the A.I.s do reflect decisions made by their \nprogrammers. They reflect guardrails, what they’re going to let the A.I. say. Very famously, Gemini came out and \nwas very woke. You would ask it to show you a picture of soldiers in Nazi Germany, and it would give you a very \nmulticultural group of soldiers, which is not how that army worked. But that was something that they had built in to \ntry to make more inclusive photography generation.\nBut there are also things that happen in these systems that people don’t expect, that the programmers don’t \nunderstand. So I remember the previous generation of Claude, which is from Anthropic, that when it came out, \nsomething that the people around it talked about was, for some reason, Claude was just a little bit more literary than \nthe other systems. It was better at rewriting things in the voices of literary figures. It just had a slightly artsier vibe.\nAnd the people who trained it weren’t exactly sure why. Now, that still feels true to me. Right now, of the ones I’m \nusing, I’m spending the most time with Claude 3. I just find it the most congenial. They all have different strengths \nand weaknesses, but there is a funny dimension to these where they are both reflecting the guardrails and the \nchoices of the programmers. And then deep inside the training data, deep inside the way the various algorithms are \ncombining, there is some set of emergent qualities to them, which gives them this at least edge of chance, of \nrandomness, of something — yeah, that does feel almost like personality.\nETHAN MOLLICK: I think that’s a very important point. And fundamental about A.I. is the idea that we technically \nknow how LLMs work, but we don’t know how they work the way they do, or why they’re as good as they are. \nThey’re really — we don’t understand it. The theories range from everyone — from it’s all fooling us, to they’ve \nemulated the way humans think because the structure of language is the structure of human thought. So even \nthough they don’t think, they can emulate it. We don’t know the answer.\nBut you’re right, there’s these emergent sets of personalities and approaches. When I talk to A.I. design companies, \nthey often can’t explain why the A.I. stops refusing answering a particular kind of question. When they tune the A.I. \nto do something better, like answer a math better, it suddenly does other things differently. It’s almost like adjusting \nthe psychology of a system rather than tuning parameters.\nSo when I said that Claude is allowed to be more personable, part of that is that the system prompt in Claude, \nwhich is the initial instructions it gets, allow it to be more personable than, say, Microsoft’s Copilot, formerly Bing, \nwhich has explicit instructions after a fairly famous blow up a while ago, that it’s never supposed to talk about itself \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nas a person or indicate feelings. So there’s some instructions, but that’s on top of these roiling systems that act in \nways that even the creators don’t expect.\nEZRA KLEIN: One thing people know about using these models is that hallucinations, just making stuff up, is a \nproblem. Has that changed at all as we’ve moved from GPT-3.5 to 4, as we move from Claude 2 to 3. Like, has that \nbecome significantly better? And if not, how do you evaluate the trustworthiness of what you’re being told?\nETHAN MOLLICK: So those are a couple of overlapping questions. The first of them is, it getting better over time? \nSo there is a paper in the field of medical citations that indicated that around 80 to 90 percent of citations had an \nerror, were made up with GPT-3.5. That’s the free version of Chat. And that drops for GPT-4.\nSo hallucination rates are dropping over time. But the A.I. still makes stuff up because all the A.I. does is \nhallucinate. There is no mind there. All it’s doing is producing word after word. They are just making stuff up all the \ntime. The fact that they’re right so often is kind of shocking in a lot of ways.\nAnd the way you avoid hallucination is not easily. So one of the things we document in one of our research papers \nis we purposely designed for a group of Boston Consulting Group consultants — so an elite consulting company — \nwe did a lot of work with them. And one of the experiments we did was we created a task where the A.I. would be \nconfident but wrong. And when we gave people that task to do, and they had access to A.I., they got the task wrong \nmore often than people who didn’t use A.I., because the A.I. misled them, because they fell asleep at the wheel. \nAnd all the early research we have on A.I. use suggests that when A.I.s get good enough, we just stop paying \nattention.\nEZRA KLEIN: But doesn’t this make them unreliable in a very tricky way? 80 percent — you’re, like, it’s always \nhallucinating. 20 percent, 5 percent, it’s enough that you can easily be lulled into overconfidence. And one of the \nreasons it’s really tough here is you’re combining something that knows how to seem extremely persuasive and \nconfident — you feed into the A.I. a 90-page paper on functions and characteristics of right wing populism in \nEurope, as I did last night.\nAnd within seconds, basically, you get a summary out. And the summary certainly seems confident about what’s \ngoing on. But on the other hand, you really don’t know if it’s true. So for a lot of what you might want to use it for, \nthat is unnerving.\nETHAN MOLLICK: Absolutely, and I think hard to grasp, because we’re used to things like type II errors, where we \nsearch for something on the internet and don’t find it. We’re not used to type I errors, where we search for \nsomething and get an answer back that’s made up. This is a challenge. And there’s a couple things to think about. \nOne of those is — I advocate the BAH standard, best available human. So is the A.I. more or less accurate than the \nbest human you could consult in that area?\nAnd what does that mean for whether or not it’s an appropriate question to ask? And that’s something that we kind \nof have to judge collectively. It’s valuable to have these studies being done by law professors and medical \nprofessionals and people like me and my colleagues in management. They’re trying to understand, how good is the \nA.I.? And the answer is pretty good, right? So it makes mistakes. “Does it make more or less mistakes than a \nhuman” is probably a question we should be asking a lot more.\nAnd the second thing is the kind of tasks that you judge it for. I absolutely agree with you. When summarizing \ninformation, it may make errors. Less than an intern you assign to it is an open question, but you have to be aware \nof that error rate. And that goes back to the 10 hour question. The more you use these A.I.s, the more you start to \nknow when to be suspicious and when not to be. That doesn’t mean you’re eliminating errors.\nBut just like if you assigned it to an intern, and you’re, like, this person has a sociology degree. They’re going to do \na really good job summarizing this, but their biases are going to be focused on the sociological facts and not the \npolitical facts. You start to learn these things. So I think, again, that person model helps, because you don’t expect \n100 percent reliability out of a person. And that changes the kind of tasks you delegate.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nEZRA KLEIN: But it also reflects something interesting about the nature of the systems. You have a quote here that \nI think is very insightful. You wrote, “the core irony of generative A.I.s is that A.I.s were supposed to be all logic and \nno imagination. Instead, we get A.I.s that make up information, engage in seemingly emotional discussions, and \nwhich are intensely creative.” And that last fact is one that makes many people deeply uncomfortable.\nThere is this collision between what a computer is in our minds and then this strange thing we seem to have \ninvented, which is an entity that emerges out of language, an entity that almost emerges out of art. This is the thing \nI have the most trouble keeping in my mind, that I need to use the A.I. as an imaginative, creative partner and not \nas a calculator that uses words.\nETHAN MOLLICK: I love the phrase “a calculator that uses words.” I think we have been let down by science \nfiction, both in the utopias and apocalypses that A.I. might bring, but also, even more directly, in our view of how \nmachines should work. People are constantly frustrated, and give the same kinds of tests to A.I.s over and over \nagain, like doing math, which it doesn’t do very well — they’re getting better at this.\nAnd on the other hand, saying, well, creativity is a uniquely human spark that we can’t touch, and that A.I., on any \ncreativity test we give it — which, again, are all limited in different ways, blows out humans in almost all measures \nof creativity that we have. Or all the measures are bad, but that still means something.\nEZRA KLEIN: But we were using those measures five years ago, even though they were bad. That’s a point you \nmake that I think is interesting and slightly unsettling.\nETHAN MOLLICK: Yeah, we never had to differentiate humans from machines before. It was always easy. So the \nidea that we had to have a scale that worked for people and machines, who had that? We had the Turing test, \nwhich everyone knew was a terrible idea. But since no machine could pass it, it was completely fine. So the \nquestion is, how do we measure this? This is an entirely separate set of issues. Like, we don’t even have a \ndefinition of sentience or consciousness.\nAnd I think that you’re exactly right on the point, being that we are not ready for this kind of machine, so our intuition \nis bad.\nEZRA KLEIN: So one of the things I will sometimes do, and did quite recently, is give the A.I. a series of personal \ndocuments, emails I wrote to people I love that were very descriptive of a particular moment in my life. And then I \nwill ask the A.I. about them, or ask the A.I. to analyze me off of them.\nAnd sometimes, it’s a little breathtaking. Almost every moment of true metaphysical shock — to use a term \nsomebody else gave me — I’ve had here has been relational, at how good the A.I. can be — almost like a therapist, \nright? Sometimes it will see things, the thing I am not saying, in a letter, or in a personal problem. And it will zoom in \nthere, right? It will give, I think, quicker and better feedback in an intuitive way that is not simply mimicking back \nwhat I said and is dealing with a very specific situation. It will do better than people I speak to in my life around that.\nConversely, I’m going to read a bit of it later. I tried mightily to make Claude 3 a useful partner in prepping to speak \nto you, and also in prepping for another podcast recently. And I functionally never have a moment there where I’m \nall that impressed.\nETHAN MOLLICK: That makes complete sense. I think the weird expectations — we call it the jagged frontier of \nA.I., that it’s good at some stuff and bad at other stuff. It’s often unexpected. It can lead to these weird moments of \ndisappointment, followed by elation or surprise. And part of the reason why I advocate for people to use it in their \njobs is, it isn’t going to outcompete you at whatever you’re best at. I mean, I cannot imagine it’s going to do a better \njob prepping someone for an interview than you’re doing.\nAnd that’s not me just — I’m trying to be nice to you because you’re interviewing me, but because you’re a good \ninterviewer. You’re a famous interviewer. It’s not going to be as good as that. Now, there’s questions about how \ngood these systems get that we don’t know, but we’re kind of at a weirdly comfortable spot in A.I., which is, maybe \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nit’s the 80th percentile of many performances. But I talk to Hollywood writers. It’s not close to writing like a \nHollywood writer. It’s not close to being as good an analyst.\nIt’s not — but it’s better than the average person. And so it’s great as a supplement to weakness, but not to \nstrength. But then, we run back into the problem you talked about, which is, in my weak areas, I have trouble \nassessing whether the A.I. is accurate or not. So it really becomes sort of a eating its own tail kind of problem.\nEZRA KLEIN: But this gets to this question of, what are you doing with it? The A.I.s right now seem much stronger \nas amplifiers and feedback mechanisms and thought partners for you than they do as something you can really \noutsource your hard work and your thinking to. And that, to me, is one of the differences between trying to spend \nmore time with these systems — like, when you come into them initially, you’re like, OK, here’s a problem, give me \nan answer.\nWhereas when you spend time with them, you realize actually what you’re trying to do with the A.I. is get it to elicit a \nbetter answer from you.\nETHAN MOLLICK: And that’s why the book’s called “Co-Intelligence.” For right now, we have a prosthesis for \nthinking. That’s, like, new in the world. We haven’t had that before — I mean, coffee, but aside from that, not much \nelse. And I think that there’s value in that. I think learning to be partner with this, and where it can get wisdom out of \nyou or not — I was talking to a physics professor at Harvard. And he said, all my best ideas now come from talking \nto the A.I. And I’m like, well, it doesn’t do physics that well. He’s like, no, but it asks good questions. And I think that \nthere is some value in that kind of interactive piece.\nIt’s part of why I’m so obsessed with the idea of A.I. in education, because a good educator — and I’ve been \nworking on interactive education skill for a long time — a good educator is eliciting answers from a student. And \nthey’re not telling students things.\nSo I think that that’s a really nice distinction between co-intelligence, and thought partner, and doing the work for \nyou. It certainly can do some work for you. There’s tedious work that the A.I. does really well. But there’s also this \nmore brilliant piece of making us better people that I think is, at least in the current state of A.I., a really awesome \nand amazing thing.\n[MUSIC PLAYING]\nEZRA KLEIN: We’ve already talked a bit about — Gemini is helpful, and ChatGPT-4 is neutral, and Claude is a bit \nwarmer. But you urge people to go much further than that. You say to give your A.I. a personality. Tell it who to be. \nSo what do you mean by that, and why?\nETHAN MOLLICK: So this is actually almost more of a technical trick, even though it sounds like a social trick. \nWhen you think about what A.I.s have done, they’ve trained on the collective corpus of human knowledge. And they \nknow a lot of things. And they’re also probability machines. So when you ask for an answer, you’re going to get the \nmost probable answer, sort of, with some variation in it. And that answer is going to be very neutral. If you’re using \nGPT-4, it’ll probably talk about a rich tapestry a lot.\nIt loves to talk about rich tapestries. If you ask it to code something artistic, it’ll do a fractal. It does very normal, \ncentral A.I. things. So part of your job is to get the A.I. to go to parts of this possibility space where the information is \nmore specific to you, more unique, more interesting, more likely to spark something in you yourself. And you do that \nby giving it context, so it doesn’t just give you an average answer. It gives you something that’s specialized for you.\nThe easiest way to provide context is a persona. You are blank. You are an expert at interviewing, and you answer \nin a warm, friendly style. Help me come up with interview questions. It won’t be miraculous in the same way that we \nwere talking about before. If you say you’re Bill Gates, it doesn’t become Bill Gates. But that changes the context of \nhow it answers you. It changes the kinds of probabilities it’s pulling from and results in much more customized and \nbetter results.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nEZRA KLEIN: OK, but this is weirder, I think, than you’re quite letting on here. So something you turned me on to is \nthere’s research showing that the A.I. is going to perform better on various tasks, and differently on them, \ndepending on the personality. So there’s a study that gives a bunch of different personality prompts to one of the \nsystems, and then tries to get it to answer 50 math questions. And the way it got the best performance was to tell \nthe A.I. it was a Starfleet commander who was charting a course through turbulence to the center of an anomaly.\nBut then, when it wanted to get the best answer on 100 math questions, what worked best was putting it in a thriller, \nwhere the clock was ticking down. I mean, what the hell is that about?\nETHAN MOLLICK: “What the hell” is a good question. And we’re just scratching the surface, right? There’s a nice \nstudy actually showing that if you emotionally manipulate the A.I., you get better math results. So telling it your job \ndepends on it gets you better results. Tipping, especially $20 or $100 — saying, I’m about to tip you if you do well, \nseems to work pretty well. It performs slightly worse in December than May, and we think it’s because it has \ninternalized the idea of winter break.\nEZRA KLEIN: I’m sorry, what?\nETHAN MOLLICK: Well, we don’t know for sure, but —\nEZRA KLEIN: I’m holding you up here.\nETHAN MOLLICK: Yeah.\nEZRA KLEIN: People have found the A.I. seems to be more accurate in May, and the going theory is that it has \nread enough of the internet to think that it might possibly be on vacation in December?\nETHAN MOLLICK: So it produces more work with the same prompts, more output, in May than it does in \nDecember. I did a little experiment where I would show it pictures of outside. And I’m like, look at how nice it is \noutside? Let’s get to work. But yes, the going theory is that it has internalized the idea of winter break and therefore \nis lazier in December.\nEZRA KLEIN: I want to just note to people that when ChatGPT came out last year, and we did our first set of \nepisodes on this, the thing I told you was this was going to be a very weird world. What’s frustrating about that is \nthat — I guess I can see the logic of why that might be. Also, it sounds probably completely wrong, but also, I’m \ncertain we will never know. There’s no way to go into the thing and figure that out.\nBut it would have genuinely never occurred to me before this second that there would be a temporal difference in \nthe amount of work that GPT-4 would do on a question held constant over time. Like, that would have never \noccurred to me as something that might change at all.\nETHAN MOLLICK: And I think that that is, in some ways, both — as you said, the deep weirdness of these \nsystems. But also, there’s actually downside risks to this. So we know, for example, there is an early paper from \nAnthropic on sandbagging, that if you ask the A.I. dumber questions, it would get you less accurate answers. And \nwe don’t know the ways in which your grammar or the way you approach the A.I. — we know the amount of spaces \nyou put gets different answers.\nSo it is very hard, because what it’s basically doing is math on everything you’ve written to figure out what would \ncome next. And the fact that what comes next feels insightful and humane and original doesn’t change that that’s \nwhat the math that’s doing is. So part of what I actually advise people to do is just not worry about it so much, \nbecause I think then it becomes magic spells that we’re incanting for the A.I. Like, I will pay you $20, you are \nwonderful at this. It is summer. Blue is your favorite color. Sam Altman loves you. And you go insane.\nSo acting with it conversationally tends to be the best approach. And personas and contexts help, but as soon as \nyou start evoking spells, I think we kind of cross over the line into, “who knows what’s happening here?”\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nEZRA KLEIN: Well, I’m interested in the personas, although I just — I really find this part of the conversation \ninteresting and strange. But I’m interested in the personalities you can give the A.I. for a different reason. I \nprompted you around this research on how a personality changes the accuracy rate of an A.I. But a lot of the \nreason to give it a personality, to answer you like it is Starfleet Commander, is because you have to listen to the A.I. \nYou are in relationship with it.\nAnd different personas will be more or less hearable by you, interesting to you. So you have a piece on your \nnewsletter which is about how you used the A.I. to critique your book. And one of the things you say in there, and \ngive some examples of, is you had to do so in the voice of Ozymandias because you just found that to be more fun. \nAnd you could hear that a little bit more easily.\nSo could you talk about that dimension of it, too, making the A.I. not just prompting you to be more accurate, but \ngiving it a personality to be more interesting to you?\nETHAN MOLLICK: The great power of A.I. is as a kind of companion. It wants to make you happy. It wants to have \na conversation. And that can be overt or covert.\nSo, to me, actively shaping what I want the A.I. to act like, telling it to be friendly or telling it to be pompous, is \nentertaining, right? But also, it does change the way I interact with it. When it has a pompous voice, I don’t take the \ncriticism as seriously. So I can think about that kind of approach. I could get pure praise out of it, too, if I wanted to \ndo it that way.\nBut the other factor that’s also super weird, while we’re on the way of super weird A.I. things, is that if you don’t do \nthat, it’s going to still figure something out about you. It is a cold reader. And I think a lot about the very famous \npiece by Kevin Roose, the New York Times technology reporter, about Bing about a year ago, when Bing, which \nwas GPT-4 powered, came out and had this personality of Sydney.\nAnd Kevin has this very long description that got published in The New York Times about how Sydney basically \nthreatened him, and suggested he leaves his wife, and very dramatic, kind of very unsettling interaction. And I was \nworking with — I didn’t have anything quite that intense, but I got into arguments with Sydney around the same \ntime, where it would — when I asked her to do work for me, it said you should do the work yourself. Otherwise, it’s \ndishonest. And it kept accusing me of plagiarism, which felt really unusual.\nBut the reason why Kevin ended up in that situation is the A.I. knows all kinds of human interactions and wants to \nslot into a story with you.\nSo a great story is jealous lover who’s gone a little bit insane, and the man who won’t leave his wife, or student and \nteacher, or two debaters arguing with each other, or grand enemies. And the A.I. wants to do that with you. So if \nyou’re not explicit, it’s going to try and find a dialogue.\nAnd I’ve noticed, for example, that if I talk to the A.I. and I imply that we’re having a debate, it will never agree with \nme. If I imply that I’m a teacher and it’s a student, even as much as saying I’m a professor, it is much more pliable.\nSo part of why I like assigning a personality is to have an explicit personality you’re operating with, so it’s not trying \nto cold read and guess what personality you’re looking for.\nEZRA KLEIN: Kevin and I have talked a lot about that conversation with Sydney. And one of the things I always \nfound fascinating about it is, to me, it revealed an incredibly subtle level of read by Sydney Bing, which is, what was \nreally happening there? When you say the A.I. wants to make you happy, it has to read on some level what it is \nyou’re really looking for, over time.\nAnd what was Kevin? What is Kevin? Kevin is a journalist. And Kevin was nudging and pushing that system to try to \ndo something that would be a great story. And it did that. It understood, on some level — again, the \nanthropomorphizing language there. But it realized that Kevin wanted some kind of intense interaction. And it gave \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nhim, like, the greatest A.I. story anybody has ever been given. I mean, an A.I. story that we are still talking about a \nyear later, an A.I. story that changed the way A.I.s were built, at least for a while.\nAnd people often talked about what Sydney was revealing about itself. But to me, what was always so unbelievably \nimpressive about that was its ability to read the person, and its ability to make itself into the thing, the personality, \nthe person was trying to call forth.\nAnd now, I think we’re more practiced at doing this much more directly. But I think a lot of people have their moment \nof sleeplessness here. That was my Rubicon on this. I didn’t know something after that I didn’t know before it in \nterms of capabilities.\nBut when I read that, I thought that the level of — interpersonal isn’t the right word, but the level of subtlety it was \nable to display in terms of giving a person what it wanted, without doing so explicitly — right, without saying, “we’re \nplaying this game now,” was really quite remarkable.\nETHAN MOLLICK: It’s a mirror. I mean, it’s trained on our stuff. And one of the revealing things about that, that I \nthink we should be paying a lot more attention to, is the fact that because it’s so good at this, right now, none of the \nfrontier A.I. models with the possible exception of Inflection’s Pi, which has been basically acquired in large part by \nMicrosoft now, were built to optimize around keeping us in a relationship with the A.I. They just accidentally do that.\nThere are other A.I. models that aren’t as good that have been focused on this, but that has been something explicit \nfrom the frontier models they’ve been avoiding till now. Claude sort of breaches that line a little bit, which is part of \nwhy I think it’s engaging. But I worry about the same kind of mechanism that inevitably reined in social media, which \nis, you can make a system more addictive and interesting. And because it’s such a good cold reader, you could \ntune A.I. to make you want to talk to it more.\nIt’s very hands off and sort of standoffish right now. But if you use the voice system in ChatGPT-4 on your phone, \nwhere you’re having a conversation, there’s moments where you’re like, oh, you feel like you’re talking to a person. \nYou have to remind yourself. So to me, that persona aspect is both its great strength, but also one of the things I’m \nmost worried about that isn’t a sort of future science fiction scenario.\nEZRA KLEIN: I want to hold here for a minute, because we’ve been talking about how to use frontier models, I think \nimplicitly talking about how to use A.I. for work. But the way that a lot of people are using it is using these other \ncompanies that are explicitly building for relationships. So I’ve had people at one of the big companies tell me that if \nwe wanted to tune our system relationally, if we wanted to tune it to be your friend, your lover, your partner, your \ntherapist, like, we could blow the doors off that. And we’re just not sure it’s ethical.\nBut there are a bunch of people who have tens of millions of users, Replika, Character.AI, which are doing this. And \nI tried to use Replika about six, eight months ago. And honestly, I found it very boring. They had recently \nlobotomized it because people were getting too erotic with their Replikants. But I just couldn’t get into it. I’m \nprobably too old to have A.I. friends, in the way that my parents were probably too old to get really in to talking to \npeople on AOL Instant Messenger.\nBut I have a five-year-old, and I have a two-year-old. And by the time my five-year-old is 10 and my two-year-old is \n7, they’re not necessarily going to have the weirdness I’m going to have about having A.I. friends. And I don’t think \nwe even have any way to think about this.\nETHAN MOLLICK: I think that is an absolute near-term certainty, and sort of an unstoppable one, that we are going \nto have A.I. relationships in a broader sense.\nAnd I think the question is, just like we’ve just been learning — I mean, we’re doing a lot of social experiments at \nscale we’ve never done before in the last couple of decades, right? Turns out social media brings out entirely \ndifferent things in humans that we weren’t expecting. And we’re still writing papers about echo chambers and \ntribalism and facts, and what we agree or disagree with.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nWe’re about to have another wave of this. And we have very little research. And you could make a plausible story \nup, that what’ll happen is it’ll help mental health in a lot of ways for people, and then there’ll be more social outside, \nthat there might be a rejection of this kind of thing.\nI don’t know what’ll happen. But I do think that we can expect with absolute certainty that you will have A.I.s that are \nmore interesting to talk to, and fool you into thinking, even if you know better, that they care about you in a way that \nis incredibly appealing. And that will happen very soon. And I don’t know how we’re going to adjust to it. But it \nseems inevitable, as you said.\nEZRA KLEIN: I was worried we were getting off track in the conversation, but I realized we were actually getting \ndeeper on the track I was trying to take us down.\nWe were talking about giving the A.I. personality, right — telling Claude 3, hey, I need you to act as a sardonic \npodcast editor, and then Claude 3’s whole persona changes. But when you talk about building your A.I. on Kindroid, \non Character, on Replika — so I just created a Kindroid one the other day. And Kindroid is kind of interesting, \nbecause its basic selling point is we’ve taken the guardrails largely off. We are trying to make something that is not \nlobotomized, that is not perfectly safe for work. And so the personality can be quite unrestrained. So I was \ninterested in what that would be like.\nBut the key thing you have to do at the beginning of that is tell the system what its personality is. So you can pick \nfrom a couple that are preset, but I wrote a long one myself — you know, you live in California. You’re a therapist. \nYou like all these different things. You have a highly intellectual style of communicating. You’re extremely warm, but \nyou like ironic humor. You don’t like small talk. You don’t like to say things that are boring or generic. You don’t use \na lot of emoticons and emojis. And so now it talks to me the way people I talk to talk.\nAnd the thing I want to bring this back to is that one of the things that requires you to know is what kind of \npersonalities work with you, for you to know yourself and your preferences a little bit more deeply.\nETHAN MOLLICK: I think that’s a temporary state of affairs, like extremely temporary. I think a GPT-4 class model \n— we actually already know this. They can guess your intent quite well. And I think that this is a way of giving you a \nsense of agency or control in the short term. I don’t think you’re going to need to know yourself at all. And I think \nyou wouldn’t right now if any of the GPT-4 class models allowed themselves to be used in this way, without \nguardrails, which they don’t, I think you would already find it’s just going to have a conversation with you and morph \ninto what you want.\nI think that for better or worse, the “insight” in these systems is good enough that way. It’s sort of why I also don’t \nworry so much about prompt crafting in the long term, to go back to the other issue we were talking about, because \nI think that they will work on intent. And there’s a lot of evidence that they’re good at guessing intent. So I like this \nperiod, because I think it does value self reflection. And our interaction with the A.I. is somewhat intentional \nbecause we can watch this interaction take place.\nBut I think there’s a reason why some of the worry you hear out of the labs is about superhuman levels of \nmanipulation. There’s a reason why the whistleblower from Google was all about that — sort of fell for the chat bot, \nand that’s why they felt it was alive. Like, I think we’re deeply trickable in this way. And A.I. is really good at figuring \nout what we want without us being explicit.\nEZRA KLEIN: So that’s a little bit chilling, but I’m nevertheless going to stay in this world we’re in, because I think \nwe’re going to be in it for at least a little while longer, where you do have to do all this prompt engineering. What is a \nprompt, first? And what is prompt engineering?\nETHAN MOLLICK: So a prompt is — technically, it is the sentence, the command you’re putting into the A.I. What it \nreally is is the beginning part of the A.I.s text that it’s processing. And then it’s just going to keep adding more words \nor tokens to the end of that reply, until it’s done. So a prompt is the command you’re giving the A.I. But in reality, it’s \nsort of a seed from which the A.I. builds.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nEZRA KLEIN: And when you prompt engineer, what are some ways to do that? Maybe one to begin with, because it \nseems to work really well, is chain of thought.\nETHAN MOLLICK: Just to take a step back, A.I. prompting remains super weird. Again, strange to have a system \nwhere the companies making the systems are writing papers as they’re discovering how to use the systems, \nbecause nobody knows how to make them work better yet. And we found massive differences in our experiments \non prompt types. So for example, we were able to get the A.I. to generate much more diverse ideas by using this \nchain of thought approach, which we’ll talk about.\nBut also, it turned out to generate a lot better ideas if you told it it was Steve Jobs than if you told it it was Madame \nCurie. And we don’t know why. So there’s all kinds of subtleties here. But the idea, basically, of chain of thought, \nthat seems to work well in almost all cases, is that you’re going to have the A.I. work step by step through a \nproblem. First, outline the problem, you know, the essay you’re going to write. Second, give me the first line of each \nparagraph. Third, go back and write the entire thing. Fourth, check it and make improvements.\nAnd what that does is — because the A.I. has no internal monologue, it’s not thinking. When the A.I. isn’t writing \nsomething, there’s no thought process. All it can do is produce the next token, the next word or set of words. And it \njust keeps doing that step by step. Because there’s no internal monologue, this in some ways forces a monologue \nout in the paper. So it lets the A.I. think by writing before it produces the final result. And that’s one of the reasons \nwhy chain of thought works really well.\nSo just step-by-step instructions is a good first effort.\nEZRA KLEIN: Then you get an answer, and then what?\nETHAN MOLLICK: And then — what you do in a conversational approach is you go back and forth. If you want \nwork output, what you’re going to do is treat it like it is an intern who just turned in some work to you. Actually, could \nyou punch up paragraph two a little bit? I don’t like the example in paragraph one. Could you make it a little more \ncreative, give me a couple of variations? That’s a conversational approach trying to get work done.\nIf you’re trying to play, you just run from there and see what happens. You can always go back, especially with a \nmodel like GPT-4, to an earlier answer, and just pick up from there if your heads off in the wrong direction.\nEZRA KLEIN: So I want to offer an example of how this back and forth can work. So we asked Claude 3 about \nprompt engineering, about what we’re talking about here. And the way it described it to us is, quote, “It’s a shift from \nthe traditional paradigm of human-computer interaction, where we input explicit commands and the machine \nexecutes them in a straightforward way, to a more open ended, collaborative dialogue, where the human and the \nA.I. are jointly shaping the creative process,” end quote.\nAnd that’s pretty good, I think. That’s interesting. It’s worth talking about. I like that idea that it’s a more collaborative \ndialogue. But that’s also boring, right? Even as I was reading it, it’s a mouthful. It’s wordy. So I kind of went back \nand forth with it a few times. And I was saying, listen, you’re a podcast editor. You’re concise, but also then I gave it \na couple examples of how I punched up questions in the document, right? This is where the question began. Here’s \nwhere it ended. And then I said, try again, and try again, and try again, and make it shorter. And make it more \nconcise.\nAnd I got this: quote, “OK, so I was talking to this A.I., Claude, about prompt engineering, you know, this whole art \nof crafting prompts to get the best out of these A.I. models. And it said something that really struck me. It called \nprompt engineering a new meta skill that we’re all picking up as we play with A.I., kind of like learning a new \nlanguage to collaborate with it instead of just bossing it around. What do you think, is prompt engineering the new \nmust have skill?” End Claude.\nAnd that second one, I have to say, is pretty damn good. That really nailed the way I speak in questions. And it gets \nit at this way where if you’re willing to go back and forth, it does learn how to echo you.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nETHAN MOLLICK: So I am at a loss about when you went to Claude and when it was you, to be honest. So I was \nready to answer at like two points along the way, so that was pretty good from my perspective, sitting here, talking \nto you. That felt interesting, and felt like the conversation we’ve been having. And I think there’s a couple of \ninteresting lessons there.\nThe first, by the way, of — interestingly, you asked A.I. about one of its weakest points, which is about A.I. And \neverybody does this, but because its knowledge window doesn’t include that much stuff about A.I., it actually is \npretty weak in terms of knowing how to do good prompting, or what a prompt is, or what A.I.s do well. But you did a \ngood job with that. And I love that you went back and forth and shaped it.\nOne of the techniques you used to shape it, by the way, was called few-shot, which is giving an example. So the \ntwo most powerful techniques are chain of thought, which we just talked about, and few-shot, giving it examples. \nThose are both well supported in the literature. And then, I’d add personas. So we’ve talked about, I think, the \nbasics of prompt crafting here overall. And I think that the question was pretty good.\nBut you keep wanting to not talk about the future. And I totally get that. But I think when we’re talking about learning \nsomething, where there is a lag, where we talk about policy — should prompt crafting be taught in schools? I think it \nmatters to think six months ahead. And again, I don’t think a single person in the A.I. labs I’ve ever talked to thinks \nprompt crafting for most people is going to be a vital skill, because the A.I. will pick up on the intent of what you \nwant much better.\nEZRA KLEIN: One of the things I realized trying to spend more time with the A.I. is that you really have to commit to \nthis process. You have to go back and forth with it a lot. If you do, you can get really good questions, like the one I \njust did — or, I think, really good outcomes. But it does take time.\nAnd I guess in a weird way it’s like the same problem of any relationship, that it’s actually hard to state your needs \nclearly and consistently and repeatedly, sometimes because you have not even articulated them in words yourself. \nAt least the A.I., I guess, doesn’t get mad at you for it.\nBut I’m curious if you have advice, either at a practical level or principles level, about how to communicate to these \nsystems what you want from them.\nETHAN MOLLICK: One set of techniques that work quite well is to speed run to where you are in the conversation. \nSo you can actually pick up an older conversation where you got the A.I.’s mindset where you want and work from \nthere. You can even copy and paste that into a new window. You can ask the A.I. to summarize where you got in \nthat previous conversation, and the tone the A.I. was taking, and then when you give a new instruction say the \ninteraction I like to have with you is this, so have it solve the problem for you by having it summarize the tone that \nyou happen to like at the end.\nSo there are a bunch of ways of building on your work as you start to go forward, so you’re not starting from scratch \nevery time. And I think you’ll start to get shorthands that get you to that right kind of space. For me, there are chats \nthat I pick up on. And actually, I assign these to my students too. I have some ongoing conversations that they’re \nsupposed to have with the A.I., but then there’s a lot of interactions they’re supposed to have that are one off.\nSo you start to divide the work into, this is a work task. And we’re going to handle this in a single chat conversation. \nAnd then I’m going to go back to this long standing discussion when I want to pick it up, and it’ll have a completely \ndifferent tone. So I think in some ways, you don’t necessarily want convergence among all your A.I. threads. You \nkind of want them to be different from each other.\nEZRA KLEIN: You did mention something important there, because they’re already getting much bigger in terms of \nhow much information they can hold. Like, the earlier generations could barely hold a significant chat. Now, Claude \n3 can functionally hold a book in its memory. And it’s only going to go way, way, way up from here. And I know I’ve \nbeen trying to keep us in the present, but this feels to me really quickly like where this is both going and how it’s \ngoing to get a lot better.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nI mean, you imagine Apple building Siri 2030, and Siri 2030 scanning your photos and your Journal app — Apple \nnow has a Journal app. You have to assume they’re thinking about the information they can get from that, if you \nallow it — your messages, anything you’re willing to give it access to. It then knows all of this information about you, \nkeeps all of that in its mind as it talks to you and acts on your behalf. I mean, that really seems to me to be where \nwe’re going, an A.I. that you don’t have to keep telling it who to be because it knows you intimately and is able to \nhold all that knowledge all at the same time constantly.\nETHAN MOLLICK: It’s not even going there. Like, it’s already there. Gemini 1.5 can hold an entire movie, books. \nBut like, it starts to now open up entirely new ways of working. I can show it a video of me working on my computer, \njust screen capture. And it knows all the tasks I’m doing and suggests ways to help me out. It starts watching over \nmy shoulder and helping me. I put in all of my work that I did prior to getting tenure and said, write my tenure \nstatement. Use exact quotes.\nAnd it was much better than any of the previous models because it wove together stuff, and because everything \nwas its memory. It doesn’t hallucinate as much. All the quotes were real quotes, and not made up. And already, by \nthe way, GPT-4 has been rolling out a model of ChatGPT that has a private note file the A.I. takes — you can \naccess it — but it takes notes on you as it goes along, about things you liked or didn’t like, and reads those again at \nthe beginning of any chat. So this is present, right? It’s not even in the future.\nAnd Google also connects to your Gmail, so it’ll read through your Gmail. I mean, I think this idea of a system that \nknows you intimately, where you’re picking up a conversation as you go along, is not a 2030 thing. It is a 2024 thing \nif you let the systems do it.\nEZRA KLEIN: One thing that feels important to keep in front of mind here is that we do have some control over that. \nAnd not only do we have some control over it, but business models and policy are important here. And one thing we \nknow from inside these A.I. shops is these A.I.s already are, but certainly will be, really super persuasive.\nAnd so if the later iterations of the A.I. companions are tuned on the margin to try to encourage you to be also out in \nthe real world, that’s going to matter, versus whether they have a business model that all they want is for you to \nspend a maximum amount of time talking to your A.I. companion, whether you ever have a friend who is flesh and \nblood be damned.\nAnd so that’s an actual choice, right? That’s going to be a programming decision. And I worry about what happens if \nwe leave that all up to the companies, right? At some point, there’s a lot of venture capital money in here right now. \nAt some point, the venture capital runs out. At some point, people need to make big profits. At some point, they’re in \ncompetition with other players who need to make profits. And that’s when things — you get into what Cory \nDoctorow calls the “enshitification” cycle, where things that were once adding a lot of value to the user begin \nextracting a lot of value to the user.\nThese systems, because of how they can be tuned, can lead to a lot of different outcomes. But I think we’re going \nto have to be much more comfortable than we’ve been in the past deciding what we think is a socially valuable use \nand what we think is a socially destructive use.\nETHAN MOLLICK: I absolutely agree. I think that we have agency here. We have agency in how we operate this in \nbusinesses, and whether we use this in ways that encourage human flourishing and employees, or are brutal to \nthem. And we have agency over how this works socially. And I think we abrogated that responsibility with social \nmedia, and that is an example. Not to be bad news, because I generally have a lot of mixed optimism and \npessimism about parts of A.I., but the bad news piece is there are open source models out there that are quite \ngood.\nThe internet is pretty open. We would have to make some pretty strong choices to kill A.I. chat bots as an option. \nWe certainly can restrict the large American companies from doing that, but a Llama 2 or Llama 3 is going to be \npublicly available and very good. There’s a lot of open source models. So the question also is how effective any \nregulation will be, which doesn’t mean we shouldn’t regulate it.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nBut there’s also going to need to be some social decisions being made about how to use these things well as a \nsociety that are going to have to go beyond just the legal piece, or companies voluntarily complying.\nEZRA KLEIN: I see a lot of reasons to be worried about the open source models. And people talk about things like \nbioweapons and all that. But for some of the harms I’m talking about here, if you want to make money off of \nAmerican kids, we can regulate you. So sometimes I feel like we almost, like, give up the fight before it begins. But \nin terms of what a lot of people are going to use, if you want to be having credit card payments processed by a \nmajor processor, then you have to follow the rules.\nI mean, individual people or small groups can do a lot of weird things with an open source model, so that doesn’t \nnegate every harm. But if you’re making a lot of money, then you have relationships we can regulate.\nETHAN MOLLICK: I couldn’t agree more. And I don’t think there’s any reason to give up hope on regulation. I think \nthat we can mitigate. And I think part of our job, though, is also not just to mitigate the harms, but to guide towards \nthe positive viewpoints, right? So what I worry about is that the incentive for profit making will push for A.I. that acts \ninformally as your therapist or your friend, while our worries about experimentation, which are completely valid, are \nslowing down our ability to do experiments to find out ways to do this right.\nAnd I think it’s really important to have positive examples, too. I want to point to the A.I. systems acting ethically as \nyour friend or companion, and figure out what that is, so there’s a positive model to look for. So I’m not just — this is \nnot to denigrate the role of regulation, which I think is actually going to be important here, and self regulation, and \nrapid response from government, but also the companion problem of, “we need to make some sort of decisions \nabout what are the paragons of this, what is acceptable as a society?”\n[MUSIC PLAYING]\nEZRA KLEIN: So I want to talk a bit about another downside here, and this one more in the mainstream of our \nconversation, which is on the human mind, on creativity. So a lot of the work A.I. is good at automating is work that \nis genuinely annoying, time consuming, laborious, but often plays an important role in the creative process. So I can \ntell you that writing a first draft is hard, and that work on the draft is where the hard thinking happens.\nAnd it’s hard because of that thinking. And the more we outsource drafting to A.I., which I think it is fair to say is a \nway a lot of people intuitively use it — definitely, a lot of students want to use it that way — the fewer of those \ninsights we’re going to have on those drafts. Look, I love editors. I am an editor in one respect. But I can tell you, \nyou make more creative breakthroughs as a writer than an editor. The space for creative breakthrough is much \nmore narrow once you get to editing.\nAnd I do worry that A.I. is going to make us all much more like editors than like writers.\nETHAN MOLLICK: I think the idea of struggle is actually a core one in many things. I’m an educator. And one thing \nthat keeps coming out in the research is that there is a strong disconnect between what students think they’re \nlearning and when they learn. So there was a great controlled experiment at Harvard in intro science classes, \nwhere students either went to a pretty entertaining set of lectures, or else they were forced to do active learning, \nwhere they actually did the work in class.\nThe active learning group reported being unhappier and not learning as much, but did much better on tests, \nbecause when you’re confronted with what you don’t know, and you have to struggle, when you feel, like, bad, you \nactually make much more progress than if someone spoon feeds you an entertaining answer. And I think this is a \nlegitimate worry that I have. And I think that there’s going to have to be some disciplined approach to writing as \nwell, like, I don’t use the A.I.\nNot just because, by the way, it makes the work easier, but also because you mentally anchor on the A.I.’s answer. \nAnd in some ways, the most dangerous A.I. application, in my mind, is the fact that you have these easy co-pilots in \nWord and Google Docs, because any writer knows about the tyranny of the blank page, about staring at a blank \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\npage and not knowing what to do next, and the struggle of filling that up. And when you have a button that produces \nreally good words for you, on demand, you’re just going to do that. And it’s going to anchor your writing.\nWe can teach people about the value of productive struggle, but I think that during the school years, we have to \nteach people the value of writing — not just assign an essay and assume that the essay does something magical, \nbut be very intentional about the writing process and how we teach people about how to do that, because I do think \nthe temptation of what I call “the button” is going to be there otherwise, for everybody.\nEZRA KLEIN: But I worry this stretches, I mean, way beyond writing. So the other place I worry about this, or one of \nthe other places I worry about this a lot, is summarizing. And I mean, this goes way back. When I was in school, \nyou could buy Sparknotes. And they were these little, like, pamphlet sized descriptions of what’s going on in “War \nand Peace” or what’s going on in “East of Eden.”\nAnd reading the Sparknotes often would be enough to fake your way through the test, but it would not have any \nchance, like, not a chance, of changing you, of shifting you, of giving you the ideas and insights that reading “Crime \nand Punishment” or “East of Eden” would do.\nAnd one thing I see a lot of people doing is using A.I. for summary. And one of the ways it’s clearly going to get \nused in organizations is for summary — summarize my email, and so on.\nAnd here too, one of the things that I think may be a real vulnerability we have, as we move into this era — my view \nis that the way we think about learning and insights is usually wrong. I mean, you were saying a second ago we can \nteach a better way. But I think we’re doing a crap job of it now, because I think people believe that — it’s sort of \nwhat I call the matrix theory of the human mind, if you could just jack the information into the back of your head and \ndownload it, you’re there.\nBut what matters about reading a book, and I see this all the time preparing for this show, is the time you spend in \nthe book, where over time, like, new insights and associations for you begin to shake loose. And so I worry it’s \ncoming into an efficiency-obsessed educational and intellectual culture, where people have been imagining forever, \nwhat if we could do all this without having to spend any of the time on it? But actually, there’s something important \nin the time.\nThere’s something important in the time with a blank page, with the hard book. And I don’t think we lionize \nintellectual struggle. In some ways, I think we lionize the people for whom it does not seem like a struggle, the \npeople who seem to just glide through and be able to absorb the thing instantly, the prodigies. And I don’t know. \nWhen I think about my kids, when I think about the kind of attention and creativity I want them to have, this is one of \nthe things that scares me most, because kids don’t like doing hard things a lot of the time.\nAnd it’s going to be very hard to keep people from using these systems in this way.\nETHAN MOLLICK: So I don’t mean to push back too much on this.\nEZRA KLEIN: No, please, push back a lot.\nETHAN MOLLICK: But I think you’re right.\nEZRA KLEIN: Imagine we’re debating and you are a snarky. A.I. [LAUGHS]\nETHAN MOLLICK: Fair enough. With that prompt —\nEZRA KLEIN: With that prompt engineering.\nETHAN MOLLICK: — yeah, I mean, I think that this is the eternal thing about looking back on the next generation, \nwe worry about technology ruining them. I think this makes ruining easier. But as somebody who teaches at \nuniversities, like, lots of people are summarizing. Like, I think those of us who enjoy intellectual struggle are always \nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nthinking everybody else is going through the same intellectual struggle when they do work. And they’re doing it \nabout their own thing. They may or may not care the same way.\nSo this makes it easier, but before A.I., there were — best estimates from the U.K. that I could find, 20,000 people \nin Kenya whose full time job was writing essays for students in the U.S. and U.K. People have been cheating and \nSparknoting and everything for a long time. And I think that what people will have to learn is that this tool is a \nvaluable co-intelligence, but is not a replacement for your own struggle.\nAnd the people who found shortcuts will keep finding shortcuts. Temptation may loom larger, but I can’t imagine \nthat — my son is in high school, doesn’t like to use A.I. for anything. And he just doesn’t find it valuable for the way \nhe’s thinking about stuff. I think we will come to that kind of accommodation. I’m actually more worried about what \nhappens inside organizations than I am worried about human thought, because I don’t think we’re going to atrophy \nas much as we think. I think there’s a view that every technology will destroy our ability to think.\nAnd I think we just choose how to use it or not. Like, even if it’s great at insights, people who like thinking like \nthinking.\nEZRA KLEIN: Well, let me take this from another angle. One of the things that I’m a little obsessed with is the way \nthe internet did not increase either domestic or global productivity for any real length of time. So I mean, it’s a very \nfamous line. You can see the IT revolution anywhere but in the productivity statistics. And then you do get, in the \n’90s, a bump in productivity that then peters out in the 2000s.\nAnd if I had told you what the internet would be, like, I mean everybody, everywhere would be connected to each \nother. You could collaborate with anybody, anywhere, instantly. You could teleconference. You would have access \nto, functionally, the sum total of human knowledge in your pocket at all times. I mean, all of these things that would \nhave been genuine sci-fi, you would have thought would have been — led to a kind of intellectual utopia. And it kind \nof doesn’t do that much, if you look at the statistics.\nYou don’t see a huge step change. And my view — and I’d be curious for your thoughts on this, because I know this \nis the area you study in — my view is it everything we said was good happened. I mean, as a journalist, Google and \nthings like that make me so much more productive. It’s not that it didn’t give us the gift. It’s that it also had a cost — \ndistraction, checking your email endlessly, being overwhelmed with the amount of stuff coming into you, the sort of \nendless communication task list, the amount of internal communications and organizations, now with Slack and \neverything else.\nAnd so some of the time that was given to us back was also taken back. And I see a lot of dynamics like this that \ncould play out with A.I. — I wouldn’t even just say if we’re not careful, I just think they will play out and already are. I \nmean, the internet is already filling with mediocre crap generated by A.I. There is going to be a lot of destructive \npotential, right? You are going to have your sex bot in your pocket, right?\nThere’s a million things — and not just that, but inside organizations, there’s going to be people padding out what \nwould have been something small, trying to make it look more impressive by using the A.I. to make something \nbigger. And then, you’re going to use the A.I. to summarize it back down. The A.I. researcher, Jonathan Frankel, \ndescribed this to me as, like, the boring apocalypse version of A.I., where you’re just endlessly inflating and then \nsummarizing, and then inflating and then summarizing the volume of content between different A.I.\nMy ChatGPT is making my presentation bigger and more impressive, and your ChatGPT is trying to summarize it \ndown to bullet points for you. And I’m not saying this has to happen. But I am saying that it would require a level of \norganizational and cultural vigilance to stop, that nothing in the internet era suggests to me that we have.\nETHAN MOLLICK: So I think there’s a lot there to chew on. And I also have spent a lot of time trying to think about \nwhy the internet didn’t work as well. I was an early Wikipedia administrator.\nEZRA KLEIN: Thank you for your service.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nETHAN MOLLICK: [LAUGHS] Yeah, it was very scarring. But I think a lot about this. And I think A.I. is different. I \ndon’t know if it’s different in a positive way. And I think we talked about some of the negative ways it might be \ndifferent. And I think it’s going to be many things at once, happening quite quickly. So I think the information \nenvironment’s going to be filled up with crap. We will not be able to tell the difference between true and false \nanymore. It will be an accelerant on all the kinds of problems that we have there.\nOn the other hand, it is an interactive technology that adapts to you. From an education perspective, I have lived \nthrough the entire internet will change education piece. I have MOOCs, massive online courses, with — quarter \nmillion people have taken them. And in the end, you’re just watching a bunch of videos. Like, that doesn’t change \neducation.\nBut I can have an A.I. tutor that actually can teach you — and we’re seeing it happen — and adapt to you at your \nlevel of education, and your knowledge base, and explain things to you. But not just explain, elicit answers from \nyou, interactively, in a way that actually learns things.\nThe thing that makes A.I. possibly great is that it’s so very human, so it interacts with our human systems in a way \nthat the internet did not. We built human systems on top of it, but A.I. is very human. It deals with human forms and \nhuman issues and our human bureaucracy very well. And that gives me some hope that even though there’s going \nto be lots of downsides, that the upsides of productivity and things like that are real.\nPart of the problem with the internet is we had to digitize everything. We had to build systems that would make our \noffline world work with our online world. And we’re still doing that. If you go to business schools, digitizing is still a \nbig deal 30 years on from early internet access. A.I. makes this happen much quicker because it works with us. So \nI’m a little more hopeful than you are about that, but I also think that the downside risks are truly real and hard to \nanticipate.\nSomebody was just pointing out that Facebook is now 100 percent filled with algorithmically generated images that \nlook like their actual grandparents, making things who are saying, like, what do you think of my work? Because \nthat’s a great way to get engagement. And the other grandparents in there have no idea it’s A.I. generated.\nThings are about to get very, very weird in all the ways that we talked about, but that doesn’t mean the positives \ncan’t be there as well.\nEZRA KLEIN: I think that is a good place to end. So always our final question, what are three books you’d \nrecommend to the audience?\nETHAN MOLLICK: OK, so the books I’ve been thinking about are not all fun, but I think they’re all interesting. One \nof them is “The Rise and Fall of American Growth,” which is — it’s two things. It’s an argument about why we will \nnever have the kind of growth that we did in the first part of the Industrial Revolution again, but I think that’s less \ninteresting than the first half of the book, which is literally how the world changed between 1870 or 1890 and 1940, \nversus 1940 and 1990, or 2000.\nAnd the transformation of the world that happened there — in 1890, no one had plumbing in the U.S.. And the \naverage woman was carrying tons of water every day. And you had no news, and everything was local, and \neveryone’s bored all the time — to 1940, where the world looks a lot like today’s world, was fascinating. And I think \nit gives you a sense of what it’s like to be inside a technological singularity, and I think worth reading for that reason \n— or at least the first half.\nThe second book I’d recommend is “The Knowledge,” by Dartnell, which is a really interesting book. It is ostensibly \nalmost a survival guide, but it is how to rebuild industrial civilization from the ground up, if we were to collapse. And \nI don’t recommend it as a survivalist. I recommend it because it is fascinating to see how complex our world is, and \nhow many interrelated pieces we’ve managed to build up as a society. And in some ways, it gives me a lot of hope \nto think about how all of these interconnections work.\nTranscript: Ezra Klein Interviews Ethan Mollick The Ezra Klein Show\nAnd then the third one is science fiction, and I was debating — I read a lot of science fiction, and there’s a lot of \ninteresting A.I.s in science fiction. Everyone talks about — who’s in the science fiction world — Iain Banks, who \nwrote about the Culture, which is really interesting, about what it’s like to live beside super intelligent A.I. Vernor \nVinge just died yesterday, when we were recording this, and wrote these amazing books about — he coined the \nterm singularity.\nBut I want to recommend a much more depressing book that’s available for free, which is Peter Watts’s “Blindsight.” \nAnd it is not a fun book, but it is a fascinating thriller set on an interstellar mission to visit an alien race. And it’s \nessentially a book about sentience, and it’s a book about the difference between consciousness and sentience, and \nabout intelligence and the different ways of perceiving the world in a setting where that is the sort of centerpiece of \nthe thriller. And I think in a world where we have machines that might be intelligent without being sentient, it is a \nrelevant, if kind of chilling, read.\nEZRA KLEIN: Ethan Mollick, your book is called “Co-Intelligence.” Your Substack is One Useful Thing. Thank you \nvery much.\nETHAN MOLLICK: Thank you.\n[MUSIC PLAYING]\nEZRA KLEIN: This episode of “The Ezra Klein Show” was produced by Kristin Lin. Fact checking by Michelle Harris. \nOur senior engineer is Jeff Geld with additional mixing from Efim Shapiro. Our senior editor is Claire Gordon. The \nshow’s production team also includes Annie Galvin and Rollin Hu. Original music by Isaac Jones. Audience strategy \nby Kristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-\nRose Strasser, and special thanks to Sonia Herrero.\nLoad-Date: April 2, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Nov2023",
        "header": "inside",
        "media": "The Baltimore Sun",
        "time": "November 21, 2023",
        "section": "MAIN; A; Pg. 1",
        "length": "112 words",
        "byline": " ",
        "story_text": "inside\nThe Baltimore Sun\nNovember 21, 2023 Tuesday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 1\nLength: 112 words\nBody\nDoor not shut on Andrews' return\nMark Andrews, the Ravens' star tight end, has an \"outside chance\" to play again this season after tests show that \nhis ankle injury is not as severe as initially feared, coach John Harbaugh says. Sports\nTrump lawyer fights gag order\nA lawyer for Donald Trump urges an appeals court to revoke a gag order, while a prosecutor argues that curbs are \nnecessary to prevent intimidation and threats. Nation & World, Page 5\nMicrosoft hires 2 former OpenAI execs\nTech giant's moves follow a weekend that fueled speculation about how changes would shake out at OpenAI, the \nstartup whose chatbot kicked off generative artificial intelligence. Business, Page 10\nLoad-Date: November 21, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "On the Ground of Biden’s Antitrust Agenda; DealBOok Newsletter",
        "media": "The New York Times",
        "time": "February 20, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1860 words",
        "byline": "Lauren Hirsch Lauren Hirsch joined The Times from CNBC in 2020, covering deals and the biggest stories",
        "story_text": "On the Ground of Biden’s Antitrust Agenda; DealBOok Newsletter\nThe New York Times \nFebruary 17, 2024 Saturday 09:13 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1860 words\nByline: Lauren Hirsch Lauren Hirsch joined The Times from CNBC in 2020, covering deals and the biggest stories \non Wall Street.\nHighlight: Doha Mekki, one of President Biden’s key antitrust enforcers, talks about the Justice Department’s big \nwins and losses, and what could be in store if President Biden gets another four years.\nBody\nDoha Mekki, one of President Biden’s key antitrust enforcers, talks about the Justice Department’s big wins and \nlosses, and what could be in store if President Biden gets another four years.\nBig deals are waiting on the tarmac as Wall Street and the business world anticipate how the presidential election \nwill change antitrust enforcement.\nPresident Biden has taken an aggressive approach to policing deals that some have called overreaching and others \nhave lauded as a necessary return to scrutiny on the power wielded by big business. Dealmakers say they are \nholding some deals back in hope of a more lenient approach in the next administration.\nDoha Mekki is on the ground executing the strategy. She’s worked at the Justice Department under three \nadministrations: as a trial attorney during the Obama presidency, in the front office during the Trump presidency \nand now as the principal deputy assistant attorney general under Jonathan Kanter.\nIn a recent interview at the Penn Carey Law Antitrust Association’s annual symposium, DealBook talked with Mekki \nabout the department’s big wins and losses, and what could be in store if Biden gets another four years. This \ninterview has been edited and condensed for clarity.\nYou led the lawsuit that successfully blocked JetBlue’s acquisition of Spirit Airlines (the decision is under appeal). In \na case like that, how do you weigh the risk that a company will fail because it’s too weak on its own against the risk \nof a more consolidated industry?\nThere’s a whole doctrine in antitrust that deals specifically with firms that are financially not viable. And it bears \nnoting — and certainly the court noted — that the company did not make that argument. In fact, what Spirit, I think, \nprojected to its shareholders for a long time was that they still intended to grow.\nBut a company probably does not want to make the case in court that a deal is life or death, because it likely \ndoesn’t want to signal that to shareholders.\nI am probably contractually obligated to say you should always be honest.\nSeveral firms, including JPMorgan Chase, dropped out of the Climate Action 100+ this week, citing antitrust \nconcerns among other reasons. Some regulators abroad have protected green initiatives from antitrust \nenforcement. Should the United States do the same?\nOn the Ground of Biden’s Antitrust Agenda DealBOok Newsletter\nWe have a 130-year-old first antitrust law, and a Clayton Act that’s about 110 years old, and nowhere in that statute \nare we permitted to take into account noneconomic considerations. And that is a good thing, because we as an \nagency are not really set up to make those judgments.\nWould a deal promising a more diverse board or management be looked at more favorably?\nWe are pretty clear that we have no capacity to take into account those kinds of considerations. To the extent that \nthere’s any suspicion about the agencies elevating or being less scrutinizing of these kinds of deals, it is, in fact, the \nopposite. It is actually the companies putting forward these social values that they intend to promote through their \ndeals. And we’re often saying: “Thank you, but no thank you. We can’t consider that.”\nIf President Biden is re-elected, what will be at the top of the agenda?\nThis year will be business as usual. We have investigations that we’re really excited about. We have potential \nenforcement actions that we’re really excited about.\nHow are you assessing the success of the past four years?\nWe’ve re-engaged with the actual law, as written by Congress and interpreted by the Supreme Court and the courts \nof appeals. We’ve had concerns that the law has really been disintermediated by policy goals and preferences that \nreally can’t be justified by textual reading of the statutes and the case law.\nIs the fact there are fewer deals a sign of success?\nOverall, I would be curious how much of it is antitrust enforcement versus the macro-environment.\nAnecdotally, the number of deals with antitrust hair is also down — and that’s good for everyone. And it’s also \nallowed us to pursue a heftier conduct docket, which is a really important part of the agency’s mission.\nYou’ve also had some high-profile losses. Will that change your willingness to litigate?\nIt’s important how we are losing. I’m not aware of a time when we have lost squarely on the law, even in cases like \nUnitedHealth Group-Change, where we had not previously pursued a competitively sensitive information theory of \nharm. The theory stood, right? We’ve tended to lose on how persuasive we are on our facts.\nWe take that feedback in stride and internalize it and try to make better arguments in the future. I think you see it in \nPenguin Random House-Simon and Schuster, where we leaned into stories about how mergers hurt authors and \nthreaten to harm whose ideas get published. You see it in JetBlue-Spirit.\nWe prefer to win — no doubt. But those hard lessons have really made us better, and we’re going to continue to be \nbetter storytellers because that’s our obligation to the public. — Lauren Hirsch\nIN CASE YOU MISSED IT\nNvidia leapfrogged Alphabet and Amazon, making it the third-largest U.S. listed company with a market \ncapitalization of roughly $1.8 trillion. Its shares have climbed nearly 50 percent this year, adding roughly $560 billion \nto its market valuation since Jan. 2, as investors bet it will reap huge profits from building the chips that power \nartificial intelligence services.\nElon Musk continued his flight from Delaware. The billionaire moved the incorporation of the privately held SpaceX \nto Texas after a judge in Delaware voided his nearly $56 billion payday at Tesla. It remains unclear whether Tesla \nitself will be able to make the same journey.\nOpenAI unveiled a new video tool called Sora, which generates high-quality videos from text prompts. Investors \nremain eager to pour money into generative A.I. companies. On Friday, The New York Times reported that OpenAI \nhad completed a deal with Thrive Capital that values it at $80 billion or more, nearly tripling its valuation in less than \n10 months.\nOn the Ground of Biden’s Antitrust Agenda DealBOok Newsletter\nWhy you’re still talking about that Dunkin’ ad \nA week after the Super Bowl, the marketing industry is still raving about the ad Dunkin’ ran during the game and its \nmany spin offs. (In case you’ve been living under a rock: Ben Affleck tries to impress Jennifer Lopez with a cringe-y \nsong and the help of his sidekicks, Matt Damon and Tom Brady.)\nDunkin’ has peppered the internet with bonus content, like footage of Affleck failing to catch a pass from Brady \n(Dunkin’ told DealBook that was unscripted) and a collaboration with the social media influencer Charli D’Amelio. \nThe brand is selling pink-and-orange tracksuits inspired by the one Affleck wore and has released the full song, \n“Don’t Dunk Away at My Heart.” All told, the campaign has amassed more than 12 million YouTube views.\n“We believe this widespread buzz highlights the ad’s ability to not only capture but sustain the audience’s attention,” \nJill Nelson, Dunkin’s chief marketing officer, told DealBook in an email, adding that the company sold more \ndoughnuts on Valentine’s Day this year than on any other day in its history.\nThe campaign demonstrates how marketing around the big game has changed.\n“There’s an immense power in using the Super Bowl as a nucleus,” Derek Rucker, a professor at Northwestern’s \nKellogg School of Management who studies effective advertising, told DealBook. With the average 30-second \nSuper Bowl ad slot running $7 million, brands are looking to seed campaigns on other channels like social media, \nin-store promotions and other ads.\nIt’s easier to start selling a branded Dunkin’ tracksuit if millions are already in on the Ben-Jennifer plot. “You have a \nlarge base of people who understand ‘Phase A’ of the campaign,” Rucker said. \nTalent increasingly has skin in the game. Artists Equity, the production company Affleck and Damon founded, \nhandled just about every aspect of the campaign. (Affleck and Gerry Cardinale, the founder of RedBird Capital, \nspoke at DealBook’s conference in 2022 just after they announced the company.) When Artists Equity started, the \nactors said they intended to give talent a cut of the profits.\nThe concept behind the Dunkin’ ad was initially pitched as part of a commercial to run during the Grammys. Dunkin’ \nliked the idea so much “it inspired us to turn the narrative into two distinct chapters and make a Super Bowl ad,” \nNelson said. (In the Grammys ad, Affleck reveals his aspiration to become a pop star.)\n“Some of the most compelling content didn’t even make the final commercials because we reserved it for social \nmedia,” Nelson added.\nFour things we learned from “Supercommunicators”\nWhat is it that makes some masters at delivering feedback, problem solving or communicating strategy? In \n“Supercommunicators,” which releases on Tuesday, Charles Duhigg answers that question, drawing on decades of \nresearch.\n“Supercommunicators aren’t born with special abilities — but they have thought harder about how conversations \nunfold,” he writes. Here are four lessons from the book:\nThe right question can demonstrate that you’re listening. A key to developing an emotional connection are “deep \nquestions that delve into values, beliefs, judgment or experiences,” Duhigg writes. (Think “what’s the best part of \nyour job?” instead of “where do you work?”).\nYou can also demonstrate your understanding by asking questions, summarizing what you’ve heard and asking if \nyou got it right, a technique called “looping.”\nThe aim of conflict conversations is to understand, not win. It helps to demonstrate understanding through “looping”; \nacknowledge points of agreement; and talk in specifics rather than sweeping statements.\nOn the Ground of Biden’s Antitrust Agenda DealBOok Newsletter\nEffective online discourse requires a new approach. The discourse in letters and phone conversations has evolved. \n“We’ve developed norms and nearly unconscious behaviors — the lilt in our voice when we answer a phone; the \nsign-off in a letter signaling our fondness for the reader — that make communication easier,” Duhigg writes.\nHe’s hopeful that online communication will develop similar norms, like being extra polite and avoiding sarcasm and \ncriticism.\nDifficult conversations need structure. Duhigg suggests establishing guidelines; sharing your goals for the \nconversation, and asking others to share theirs; and acknowledging discomfort is expected, and OK.\nQuiz: Startups wanted \nThe partners at Y Combinator, the start-up accelerator that incubated Airbnb, Dropbox and DoorDash, have \npublished their latest “request for startups,” a wish list of the kind of companies in which they’d like to invest.\nWhich of these startup categories did not make the list?\n• New space companies\n• Blockchain-based social networks\n• A way to end cancer\n• Stablecoin finance\nFind the answer at the bottom of this newsletter.\nSarah Kessler contributed reporting.\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nQuiz answer: B.\nSarah Kessler contributed reporting. \nPHOTO: Doha Mekki, the principal deputy assistant attorney general, executes President Biden’s aggressive \napproach to policing deals. (PHOTOGRAPH BY JIM LO SCALZO/EPA, VIA SHUTTERSTOCK) This article \nappeared in print on page B5.\nLoad-Date: February 20, 2024"
    },
    {
        "file_name": "especially_in_communities_of_color._The_state_must_step_in._Mar2024",
        "header": "Preventing a voter disinformation crisis; AI is turbocharging disinformation,",
        "media": "especially in communities of color. The state must step in.",
        "time": "March 22, 2024",
        "section": "MAIN NEWS; Opinion Desk; Part A; Pg. 1",
        "length": "852 words",
        "byline": "Bill Wong, Mindy Romero, Bill Wong is a campaign strategist and the author of \"Better to Win: Hardball",
        "story_text": "Preventing a voter disinformation crisis; AI is turbocharging disinformation, \nespecially in communities of color. The state must step in.\nLos Angeles Times\nMarch 22, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Opinion Desk; Part A; Pg. 1\nLength: 852 words\nByline: Bill Wong, Mindy Romero, Bill Wong is a campaign strategist and the author of \"Better to Win: Hardball \nLessons in Leadership, Influence, & the Craft of Politics.\" Mindy Romero is a political sociologist and the director of \nthe Center for Inclusive Democracy at the USC Price School of Public Policy.\nBody\nAs the general election campaign begins in earnest, we can expect disinformation attacks to target voters, \nespecially in communities of color. This has happened before: In 2016, for example, Russia's disinformation \nprograms zeroed in on Black Americans, creating Instagram and Twitter accounts that masqueraded as Black \nvoices and producing fake news websites such as blacktivist.info, blacktolive.org and blacksoul.us.\nAdvances in technology will make these efforts harder to recognize. Envision those same fake accounts and \nwebsites featuring hyper-realistic videos and images intended to sow racial division and mislead people about their \nvoting rights. With the advent of generative artificial intelligence, that is possible at little to no cost, turbocharging \nthe kind of disinformation that has always targeted communities of color.\nIt's a problem for candidates, election offices and voter outreach groups in the months ahead. But voters \nthemselves will ultimately have to figure out what is real news or fake news, authentic or AI-generated.\nFor immigrants and communities of color -- who often face language barriers, distrust democratic systems and lack \ntechnology access -- the challenge is likely to be more significant. Across the nation, and especially in states such \nas California with large communities of immigrants and people with limited knowledge of English, the government \nneeds to help these groups identify and avoid disinformation,\nAsian Americans and Latinos are particularly vulnerable. About two-thirds of the Asian American and Pacific \nIslander population are immigrants, and a Pew Research Center report states that \"[86%] of Asian immigrants 5 \nand older say they speak a language other than English at home.\" The same dynamics hold true for Latinos: Only \n38% of the U.S. foreign-born Latino population reports being proficient in English.\nTargeting non-English-speaking communities has several advantages for those who would spread disinformation. \nThese groups are often cut off from mainstream news sources that have the greatest resources to debunk \ndeepfakes and other disinformation, preferring online engagement in their native languages, where moderation and \nfact-checking are less prevalent.\nForty-six percent of Latinos in the U.S. use WhatsApp, while many Asian Americans prefer WeChat. Wired \nmagazine reported that the platform \"is used by millions of Chinese Americans and people with friends, family, or \nbusiness in China, including as a political organizing tool.\"\nPreventing a voter disinformation crisis AI is turbocharging disinformation, especially in communities of color. \nThe state must step in.\nDisinformation aimed at immigrant communities is poorly understood and difficult to track and counteract, yet it is \ngetting easier and easier to create. In the past, producing false content in non-English languages required intensive \nwork from humans and was often low in quality. Now, AI tools can create hard-to-track, in-language disinformation \nat lightning speed and without the vulnerabilities and scaling problems posed by human limitations. Despite this, \nmuch research on misinformation and disinformation concentrates on English-language uses.\nAttempts to target communities of color and non-English speakers with disinformation are aided by many \nimmigrants' heavy reliance on their mobile phones for internet access. Mobile user interfaces are particularly \nvulnerable to disinformation because many desktop design and branding elements are minimized in favor of content \non smaller screens. With 13% of Latinos and 12% of African Americans dependent on mobile devices for \nbroadband access, in contrast to 4% of white smartphone owners, they are more likely to receive -- and share -- \nfalse information.\nSocial media companies' past efforts to counter voter disinformation have fallen short. Meta's February \nannouncement that it would flag AI-generated images on Facebook, Instagram and Threads is a positive but minor \nstep toward stemming AI-generated disinformation, especially for ethnic and immigrant communities who may know \nlittle about its effects. Clearly, a stronger government response is needed.\nThe California Initiative for Technology and Democracy, or CITED, where we serve on the board of directors, will \nsoon unveil a legislative package that would require broader transparency for generative AI content, making sure \nusers of social media know what video, audio and images were made by AI tools. The bills would also require \nlabeling of AI-assisted political disinformation on social media, prohibit campaign ads close to an election from \nusing the technology and restrict anonymous trolls and bots.\nIn addition, CITED plans to hold a series of community forums around California with partner organizations rooted \nin their regions. The groups will speak directly to leaders in communities of color, labor leaders, local elected \nofficials and other trusted messengers about the dangers of false AI-generated information likely to be circulating \nthis election season.\nThe hope is that this information will be relayed at the community level, making voters in the state more aware and \nskeptical of false or misleading content, building trust in the election process, election results and our democracy.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "New Feeding Habits for AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 1, 2024",
        "section": "BREAKING IDEAS",
        "length": "843 words",
        "byline": "Anil Nair",
        "story_text": "New Feeding Habits for AI\nEconomic Times (E-Paper Edition)\nFebruary 24, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 843 words\nByline: Anil Nair\nHighlight: The Reddit-Google deal could show how content will be produced, owned and consumed on internet\nBody\nReddit is a social media and news aggregation platform that has some 71 million active daily users who discuss \nniche subjects in niche groups. On Thursday, the San Francisco-headquartered company signed a $60 million-a-\nyear deal — in Google VP, engineering, Rajan Patel’s words, ‘a new Cloud partnership’ — that will allow Google to \nmine the social media site’s vast content to train its generative AI models. It had taken eight months for Reddit to \nsign up a big AI company, after CEO Steve Huffman announced in June 2023 that AI companies consuming \nReddit’s data to train their LLMs would have to pay up. It appeared as an attempt to bolster the company’s \nrevenues and attain profitability before an IPO. \n‘We’ll continue to be profit-driven until profits arrive,’ Huffman had said then. The same month, Reddit also \nannounced that all developers like Apollo, Sync, Pushshift and RiF would have to begin paying for using the Reddit \nAPI. Many developers were outraged, because Reddit had become a significant social media site by allowing its \nAPI to be used for free by developers to build their bots and services. Many dropped out, claiming the new fee-\npaying model wasn’t sustainable, despite the fact that they were making money from subscribers and ads, which \nthey were not sharing with Reddit. In retrospect, it appears that Reddit had reevaluated its path to profitability  \nbefore its IPO, by monetising both its APIs and content, and was taking firm steps to get there. As a result, the \nplayers involved have, consciously or inadvertently, redefined the rules around copyright and IP protection in the \ndigital age. Platforms can now invest in creating communities of interest that will generate content. And be sure that \nmonetisation, the holy grail, is an eminently attainable possibility. But the moot question is whether or not, for the \nvery same reason, platforms will exert excessive control over content and creators, choking innovation, creativity \nand free speech. The battle will now shift to the next front. Which is that while the content site and the platform gain, \nwhat of the rights of the individual contributors on Reddit, many of whom contribute voluntarily? Are the rights of \nindividual contributors going to be ignored, extended to monetary compensation, or is there more to it?  In this \ncontext, it is important to look at copyright laws and IPR. Copyright laws protect original works of authorship, \nincluding in respect of sound, music, artistic, literary and cinematographic works. IP includes patents, trademarks, \ndesigns and trade secrets, and their protection encompasses legal frameworks. Copyright laws focus on original \nexpression of ideas, while IPR is meant to prevent unauthorised use of ‘intangible creations’, generally speaking. \nBut there are country-related subtleties that also need to be understood. In the US, IPR extends to trademarks, \npatents and copyright, and applies to published and unpublished works — from drafts to completed works. What’s \nmore, fair-use doctrine permits limited use of copyrighted material for criticism, commentary or education. Laws in \nIndia are somewhat similar. But here we have stringent takedown obligations, as evidenced this week in the case of \nfarm agitationrelated accounts and posts on social media platforms like X, Facebook,  Instagram and YouTube \nbeing taken down after GoI ‘instructions’. The European Copyright Directive applies across EU nations, \nharmonising copyright laws, strengthening liability of platforms for infringement, while granting exceptions for data-\nmining for research, analysis and other specific uses. This 2001 directive effectively became regulation in 2018. \nNew Feeding Habits for AI\nThe latest Reddit-Google deal may provoke a rethink in respect of some facets. Of course, there are other specific \naspects in the RG deal that will get more apparent as we learn more details, that will be thought-provoking and \njurisdictionally relevant. •Will the deal cover all content? Or are there format-, geographicaland purpose-related \nrestrictions? •Can Google modify content independently? Or does it have to seek permissions? •How will \nattributions be displayed that could impact future benefits? •How will differing laws in various countries be \napproached? •How will continuing changes be addressed?  •How will rights of individual contributors be protected? \n• How will commercialisation of content by Google percolate to the platform and individual? •Will licensing content \ndirectly reduce the risk of algorithmic bias? An intriguing aspect is how other social media sites and generative AI \nengines will respond. And whether this will change rules of the internet, our go-to place for all the information we \nwant instantly. No doubt this is a harbinger for dialogue that all stakeholders, including governments, content-\ncreators, platforms and those consuming content must have, so that there is equity in the digital creative \necosystem. At this stage, there are more questions than answers. Reddit’s IPO, whenever that happens, will \nprovide some. The writer is founder, ThinkStreet\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Times_Mar2024",
        "header": "Microsoft Seeks to Dismiss Parts of Lawsuit Brought by The New York",
        "media": "Times",
        "time": "March 6, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "587 words",
        "byline": "By Cade Metz and Karen Weise",
        "story_text": "Microsoft Seeks to Dismiss Parts of Lawsuit Brought by The New York \nTimes\nThe New York Times\nMarch 6, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 587 words\nByline: By Cade Metz and Karen Weise\nBody\nThe tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies like the \nonline chatbot ChatGPT.\nMicrosoft filed a motion in federal court on Monday that seeks to dismiss parts of a lawsuit brought by The New \nYork Times Company. \n  The Times sued Microsoft and its partner OpenAI on Dec. 27, accusing the two companies of infringing on its \ncopyrights by using its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots compete with the \nnews outlet as a source of reliable information, the lawsuit said.\n  In its motion, filed in U.S. District Court for the Southern District of New York, Microsoft argued that large language \nmodels, or L.L.M.s -- the technologies that drive chatbots -- did not supplant the market for news articles and other \nmaterials they were trained on.\n  The tech giant compared L.L.M.s to videocassette recorders, arguing that both are allowed under the law. \n''Despite The Times's contentions, copyright law is no more an obstacle to the L.L.M. than it was to the VCR (or the \nplayer piano, copy machine, personal computer, internet or search engine),'' the motion read.\n  In the late 1970s, movie studios sued Sony over its Betamax VCR, arguing that it would allow people to illegally \ncopy movies and television shows. But the courts ultimately found that making these copies for personal viewing \nwas fair use under the law.\n  Microsoft's motion was similar to one made by OpenAI last week. Microsoft said three parts of the suit should be \ndismissed in part because The Times did not show actual harm.\n  The Times had argued, for example, that if readers use Microsoft's chatbot to research recommendations from the \nreview site Wirecutter, which The Times owns, it loses revenue from users who would have clicked on its referral \nlinks. Microsoft argued that the Times lawsuit offered ''no real-world facts suggesting meaningful diversion of \nrevenue from Wirecutter.''\n  Ian Crosby, a Susman Godfrey partner who is lead counsel for The Times in the case, said in a statement on \nMonday: ''Microsoft doesn't dispute that it worked with OpenAI to copy millions of The Times's works without its \npermission to build its tools. Instead, it oddly compares L.L.M.s to the VCR even though VCR makers never argued \nthat it was necessary to engage in massive copyright infringement to build their products.''\nMicrosoft Seeks to Dismiss Parts of Lawsuit Brought by The New York Times\n  Microsoft did not have an immediate comment.\n  The Times was the first major American media company to sue Microsoft and OpenAI over copyright issues \nrelated to its written works. Writers, computer coders and other groups have also filed copyright suits against \ncompanies that build generative A.I., technologies that generate text, images and other media.\n  Like other A.I. companies, Microsoft and OpenAI built their technology by feeding it enormous amounts of digital \ndata, some of which is likely copyrighted. A.I. companies have claimed that they can legally use such material to \ntrain their systems without paying for it because it is public and they are not reproducing the material in its entirety.\n  In its suit, The Times included examples of OpenAI technology's reproducing excerpts from its articles almost \nword for word. Microsoft said training the technology on such articles was ''fair use'' under the law because chatbots \nwere a ''transformative'' technology that created something new with copyrighted material. It did not, however, seek \nto dismiss arguments against ''fair use,'' saying it would address these issues at a later time.\nhttps://www.nytimes.com/2024/03/04/technology/microsoft-ai-copyright-lawsuit.html\nGraphic\n \nPHOTO: Microsoft has formed a close partnership with OpenAI to build artificial intelligence. The suit accuses the \ntwo companies of infringing on copyrights. (PHOTOGRAPH BY GRANT HINDSLEY FOR THE NEW YORK TIMES) \nThis article appeared in print on page B4.               \nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2023",
        "header": "A.I. Is Doing Homework. Can It Be Outsmarted?",
        "media": "The New York Times",
        "time": "January 17, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1454 words",
        "byline": "By Kalley Huang",
        "story_text": "A.I. Is Doing Homework. Can It Be Outsmarted?\nThe New York Times\nJanuary 17, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1454 words\nByline: By Kalley Huang\nBody\nWith the rise of the popular new chatbot ChatGPT, colleges are restructuring some courses and taking preventive \nmeasures.\nWhile grading essays for his world religions course last month, Antony Aumann, a professor of philosophy at \nNorthern Michigan University, read what he said was easily ''the best paper in the class.'' It explored the morality of \nburqa bans with clean paragraphs, fitting examples and rigorous arguments. \n  A red flag instantly went up.\n  Mr. Aumann confronted his student over whether he had written the essay himself. The student confessed to using \nChatGPT, a chatbot that delivers information, explains concepts and generates ideas in simple sentences -- and, in \nthis case, had written the paper.\n  Alarmed by his discovery, Mr. Aumann decided to transform essay writing for his courses this semester. He plans \nto require students to write first drafts in the classroom, using browsers that monitor and restrict computer activity. \nIn later drafts, students have to explain each revision. Mr. Aumann, who may forgo essays in subsequent \nsemesters, also plans to weave ChatGPT into lessons by asking students to evaluate the chatbot's responses.\n  ''What's happening in class is no longer going to be, 'Here are some questions -- let's talk about it between us \nhuman beings,''' he said, but instead ''it's like, 'What also does this alien robot think?'''\n  Across the country, university professors like Mr. Aumann, department chairs and administrators are starting to \noverhaul classrooms in response to ChatGPT, prompting a potentially huge shift in teaching and learning. Some \nprofessors are redesigning their courses entirely, making changes that include more oral exams, group work and \nhandwritten assessments in lieu of typed ones.\n  The moves are part of a real-time grappling with a new technological wave known as generative artificial \nintelligence. ChatGPT, which was released in November by the artificial intelligence lab OpenAI, is at the forefront \nof the shift. The chatbot generates eerily articulate and nuanced text in response to short prompts, with people \nusing it to write love letters, poetry, fan fiction -- and their schoolwork.\n  That has upended some middle and high schools, with teachers and administrators trying to discern whether \nstudents are using the chatbot to do their schoolwork. Some public school systems, including in New York City and \nSeattle, have since banned the tool on school Wi-Fi networks and devices to prevent cheating, though students can \neasily find workarounds to access ChatGPT.\nA.I. Is Doing Homework. Can It Be Outsmarted?\n  In higher education, colleges and universities have been reluctant to ban the A.I. tool because administrators \ndoubt the move would be effective and they don't want to infringe on academic freedom. That means the way \npeople teach is changing instead.\n  ''We try to institute general policies that certainly back up the faculty member's authority to run a class,'' instead of \ntargeting specific methods of cheating, said Joe Glover, provost of the University of Florida. ''This isn't going to be \nthe last innovation we have to deal with.''\n  That's especially true as generative A.I. is in its early days. OpenAI is expected to soon release another tool, \nGPT-4, which is better at generating text than previous versions. Google has built LaMDA, a rival chatbot, and \nMicrosoft is discussing a $10 billion investment in OpenAI. Silicon Valley start-ups, including Stability AI and \nCharacter.AI, are also working on generative A.I. tools.\n  An OpenAI spokeswoman said the lab recognized its programs could be used to mislead people and was \ndeveloping technology to help people identify text generated by ChatGPT.\n  At many universities, ChatGPT has now vaulted to the top of the agenda. Administrators are establishing task \nforces and hosting universitywide discussions to respond to the tool, with much of the guidance being to adapt to \nthe technology.\n  At schools including George Washington University in Washington, D.C., Rutgers University in New Brunswick, \nN.J., and Appalachian State University in Boone, N.C., professors are phasing out take-home, open-book \nassignments -- which became a dominant method of assessment in the pandemic but now seem vulnerable to \nchatbots. They are instead opting for in-class assignments, handwritten papers, group work and oral exams.\n  Gone are prompts like ''write five pages about this or that.'' Some professors are instead crafting questions that \nthey hope will be too clever for chatbots and asking students to write about their own lives and current events.\n  Students are ''plagiarizing this because the assignments can be plagiarized,'' said Sid Dobrin, chair of the English \ndepartment at the University of Florida.\n  Frederick Luis Aldama, the humanities chair at the University of Texas at Austin, said he planned to teach newer \nor more niche texts that ChatGPT might have less information about, such as William Shakespeare's early sonnets \ninstead of ''A Midsummer Night's Dream.''\n  The chatbot may motivate ''people who lean into canonical, primary texts to actually reach beyond their comfort \nzones for things that are not online,'' he said.\n  In case the changes fall short of preventing plagiarism, Mr. Aldama and other professors said they planned to \ninstitute stricter standards for what they expect from students and how they grade. It is now not enough for an \nessay to have just a thesis, introduction, supporting paragraphs and a conclusion.\n  ''We need to up our game,'' Mr. Aldama said. ''The imagination, creativity and innovation of analysis that we \nusually deem an A paper needs to be trickling down into the B-range papers.''\n  Universities are also aiming to educate students about the new A.I. tools. The University at Buffalo in New York \nand Furman University in Greenville, S.C., said they planned to embed a discussion of A.I. tools into required \ncourses that teach entering or freshman students about concepts such as academic integrity.\n  ''We have to add a scenario about this, so students can see a concrete example,'' said Kelly Ahuna, who directs \nthe academic integrity office at the University at Buffalo. ''We want to prevent things from happening instead of \ncatch them when they happen.''\n  Other universities are trying to draw boundaries for A.I. Washington University in St. Louis and the University of \nVermont in Burlington are drafting revisions to their academic integrity policies so their plagiarism definitions include \ngenerative A.I.\nA.I. Is Doing Homework. Can It Be Outsmarted?\n  John Dyer, vice president for enrollment services and educational technologies at Dallas Theological Seminary, \nsaid the language in his seminary's honor code felt ''a little archaic anyway.'' He plans to update its plagiarism \ndefinition to include: ''using text written by a generation system as one's own (e.g., entering a prompt into an \nartificial intelligence tool and using the output in a paper).''\n  The misuse of A.I. tools will most likely not end, so some professors and universities said they planned to use \ndetectors to root out that activity. The plagiarism detection service Turnitin said it would incorporate more features \nfor identifying A.I., including ChatGPT, this year.\n  More than 6,000 teachers from Harvard University, Yale University, the University of Rhode Island and others \nhave also signed up to use GPTZero, a program that promises to quickly detect A.I.-generated text, said Edward \nTian, its creator and a senior at Princeton University.\n  Some students see value in embracing A.I. tools to learn. Lizzie Shackney, 27, a student at the University of \nPennsylvania's law school and design school, has started using ChatGPT to brainstorm for papers and debug \ncoding problem sets.\n  ''There are disciplines that want you to share and don't want you to spin your wheels,'' she said, describing her \ncomputer science and statistics classes. ''The place where my brain is useful is understanding what the code \nmeans.''\n  But she has qualms. ChatGPT, Ms. Shackney said, sometimes incorrectly explains ideas and misquotes sources. \nThe University of Pennsylvania also hasn't instituted any regulations about the tool, so she doesn't want to rely on it \nin case the school bans it or considers it to be cheating, she said.\n  Other students have no such scruples, sharing on forums like Reddit that they have submitted assignments written \nand solved by ChatGPT -- and sometimes done so for fellow students too. On TikTok, the hashtag #chatgpt has \nmore than 578 million views, with people sharing videos of the tool writing papers and solving coding problems.\n  One video shows a student copying a multiple choice exam and pasting it into the tool with the caption saying: ''I \ndon't know about y'all but ima just have Chat GPT take my finals. Have fun studying.''\nhttps://www.nytimes.com/2023/01/16/technology/chatgpt-artificial-intelligence-universities.html\nGraphic\n \nPHOTOS: Antony Aumann, a Northern Michigan University professor, sniffed out an essay written by ChatGPT. \nLizzie Shackney, a student at the University of Pennsylvania, said ChatGPT is a useful study tool. \n(PHOTOGRAPHS BY CHRISTINE LENZEN FOR THE NEW YORK TIMES\n STEVE LEGATO FOR THE NEW YORK TIMES) (A16) This article appeared in print on page A1, A16.               \nLoad-Date: January 17, 2023"
    },
    {
        "file_name": "secondary_Feb2024",
        "header": "Capillary Technologies extends latest funding round, raises $95 million in",
        "media": "secondary",
        "time": "February 27, 2024",
        "section": "FUNDING",
        "length": "476 words",
        "byline": "Tarush Bhalla",
        "story_text": "Capillary Technologies extends latest funding round, raises $95 million in \nsecondary\nThe Economic Times\nFebruary 27, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 476 words\nByline: Tarush Bhalla\nBody\nCustomer engagement and loyalty software provider Capillary Technologies has extended its latest Series D round \nto $140 million and raised $95 million in secondary transactions to provide exit to existing investors and employees. \nThe company had last year raised $45 million as a part of the round, which consisted of $39 million of equity and $6 \nmillion in debt.This comes at a time when the company is looking to list on the Indian bourses in the next 18 \nmonths, its second attempt in recent years, company founder and managing director Aneesh Reddy told ET. \nIt had filed for its draft prospectus in 2021 with markets regulator Securities and Exchange Board of India (Sebi) and \nsubsequently withdrawn it by March, last year.As a part of the latest tranche, the company has also picked up an \nadditional $6 million in equity funding from the likes of angel investors, including Ajay Gupta, former senior partner \nat McKinsey & Company; Hal Brierley, founder of Brierley+Partners among others. With this, Capillary \nTechnologies has raised a total of $45 million in equity and $95 million in secondary funding, as a part of the Series \nD round. The secondary portion saw participation from the likes of 57Stars, Pantheon, Unigestion, The Evolvence \nGroup, which are also limited partners of one of its largest shareholders, Avataar Ventures.With the secondary \nraise, Capillary’s existing investors like American Express and Warburg Pincus who invested before 2016 are taking \nfull and partial exits respectively, along with angel investors.Avataar Ventures held a 19% stake in Capillary \nTechnologies, as of October last year, according to research platform Tracxn. In a secondary transaction, the \nfunding does not go into the company’s coffers. However, a large chunk of the secondary raise, roughly $20 million, \nhas gone towards giving exits to Capillary’s former and current employees, Reddy told ET. “The secondary \ntransaction in our case priced at a premium of the primary, given the gap of six months and growth seen by the \ncompany. With the secondary raise, we now have almost 15-17% of our captable comprising of pre-2015 investors. \nGoing forward most of our funding will be to give exit to our investors,” said Reddy. With the fresh equity raise, the \ncompany is expected to use the capital to fuel its internal generative artificial intelligence (AI) initiatives and \npartnerships, as well as to go deeper into existing markets of US and Europe. It forayed into the North American \nmarket back in 2021 with acquisition of customer experience platform Persuade. In three years, the US geography \nis already contributing to 65% of Capillary’s revenues. Europe and Asia are other markets where Capillary counts \nits presence. According to sources, Capillary is touching an annual revenue run rate (ARR) of roughly $75 million. \nFor Reprint Rights: timescontent.com\nLoad-Date: February 27, 2024"
    },
    {
        "file_name": "USA_Today_Online_May2024",
        "header": "How to use AI to plan your next vacation and what you should know first",
        "media": "USA Today Online",
        "time": "May 9, 2024",
        "section": "",
        "length": "1318 words",
        "byline": "Eve Chen, USA TODAY",
        "story_text": "How to use AI to plan your next vacation and what you should know first\nUSA Today Online\nMay 2, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 1318 words\nByline: Eve Chen, USA TODAY\nBody\nWhere should I go on vacation this summer\nThe question is simple enough, but the possibilities are endless.\n“Feeling adventurous or more like chilling by the beach with a drink in hand?” Layla replies to narrow the list.\nChilling by the beach sounds nice.\n“Alright, for that laid-back beach vibe, how about Santorini with its iconic sunsets or Ao Nang for some Thai beach \nbliss? Pick your paradise!” she suggested. \nOnly she is not really a “she.” Layla is an AI travel planner whose website launched this year, among a growing \nnumber of artificial intelligence-driven tools for travel. \nJust over 50% of 1,400 people recently surveyed by Matador Network, a travel publisher and creator of AI travel \nassistant GuideGeek, said they’re open to using AI for their summer travel. A previous Matador Network survey \nfound 64% of 1,200 travelers surveyed had already used or planned to use AI for trip planning.\nHere’s what travelers should know about planning trips with AI.\nHow common is AI today?\nMany people associate AI with large language models like ChatGPT, which can both recognize and generate text, \nbut that’s just one type of AI.\n“AI is generally everywhere,” said Yoon Kim, an assistant professor in MIT’s Electrical Engineering and Computer \nScience Department and Computer Science and Artificial Intelligence Laboratory. “For example, when you search \nfor something – let's say you search for something on TripAdvisor, Hotels.com – there is likely an AI-based system \nthat gives you a list of matches based on your query.”\n“Because a lot of the (online travel agencies) have now integrated different types of Gen AI into their platforms … \npeople may be using them without their knowledge,” echoed Matt Soderberg, principal, U.S. airlines leader for \nDeloitte, which named AI as a major theme in changing travel in its Facing travel's future report released in early \nApril.\nKayak and Expedia offer AI travel tools. Google has used AI for years for search. Those familiar “People Also Ask” \nquestions are powered by AI. Google Flights uses machine learning, a type of AI. AI also powers Google Maps’ \nImmersive View, which gives users a navigable fly-over view of 13 cities and more than 500 global landmarks that \nusers can zoom in on like in a video game, with weather and crowd forecasts for different times of day. \nHow to use AI to plan your next vacation and what you should know first\nEarly this year, Google introduced generative AI to multisearch queries made with Google Lens. That allows users \nto take a photo of something and couple it with text questions like “What kind of flower is this?” or “Who painted this \nand why?” to get AI-generated answers based on data from across the web and links to additional sources.\nHow do I plan a trip with AI?\nLink to Image\nPlanning travel with AI is typically free, but travelers may need to create platform-specific accounts to access \nenhanced features or ask more than a few initial queries.\nGoogle account holders can get generative AI results in text-only search bar searches if they opt in to Search \nGenerative Experience, which is part of Google’s experimental Search Labs. Opting in to SGE allows them to ask \nthings like “Plan me a 2-day solo trip to Grand Teton National Park” and not only get a suggested itinerary but \nrelated photos, reviews and links to other resources. \nFor Day 1 at Grand Teton, Google suggested a morning hike at Schwabacher Landing “to see the Grand Tetons \nreflected in the river,” an afternoon visit to U.S. Fish and Wildlife Service’s National Elk Refuge, and dinner at a \nlocal Italian restaurant with photos of each destination, links to their websites, pins showing locations on Google \nMaps, suggestions for where to stay, space for follow up questions, and links to related questions like “Is 2 days \nenough for Grand Teton National Park?” \nJust above the sample itinerary, read a disclaimer: “Generative AI is experimental” and below it: “Trip ideas \ngenerated with AI may include inaccurate or misleading information. Confirm info with sources you trust.” \nFor the same prompt, both ChatGPT and GuideGeek – which can be messaged on social media like a person – \noffered more suggestions of things to do, as well as reminders to check on trail closures, but no specific \nrecommendations on where to eat or stay, nor photos nor links to find more information on any of the destinations. \nLayla and Mindtrip, an AI travel planner that launched publicly this week, also included links to various points of \ninterest, hotel suggestions, and the ability to adjust and book different parts of the itinerary through partnerships \nwith third parties. Mindtrip allows multiple people within the same travel party to collaborate on itineraries.\nMake travel easy: We tested ChatGPT itineraries in 5 US tourist spots\nCan AI be trustworthy?\nLink to Image\nAsking one AI travel planner for the top 10 snacks at Walt Disney World’s Magic Kingdom, among classics like Dole \nWhip and Corn Dog Nuggets, it suggested Mickey-shaped beignets. Those would certainly be a top snack if they \nwere sold in the park, like at Disneyland. However Disney World guests have to go to Disney’s Port Orleans Resort \n- French Quarter for sweet Mickey-shaped pillows of fried dough.\n“This phenomena goes under the moniker hallucinations. These generative AI systems are prone to hallucinating \nplausible-sounding text that’s actually factually incorrect,” MIT’s Kim explained. “This is, I think, going to be sort of \nan inherent problem with systems that probabilistically generate output over large spaces.”\n\"If the LLM recommends a restaurant closed down two years ago, you lose all trust immediately,\" said Mindtrip \nFounder and CEO Andy Moss. That's why they, and Layla, also rely on human intelligence for recommendations. \nKim noted there are ongoing efforts to mitigate against hallucinations but suggested double-checking AI-generated \nanswers.\n“We want to make sure that that information is usable, that it's actionable. It's clear, it's repeatable,” said Will Healy, \nsenior vice president at Booz Allen Hamilton, the largest provider of AI to the federal government. He heads up the \nHow to use AI to plan your next vacation and what you should know first\ncompany’s recreation work, including Recreaton.gov, the government’s central travel planning site for public lands \nlike national parks. \nWhat can AI be used for?\nLink to Image\nCurrently, most Recreation.gov visitors use progressive search to discover and book things like campsites, \nchecking off boxes and reading information provided by the land manager. However, 25% of randomly selected \nusers are being offered more personalized AI-powered options as part of a beta test with AI.\n“What we're beta testing at the moment are things where you can say, ‘Hey, I've got three kids. This is our first time \ncamping. We want to go some place that's fun. My kids love the water. We want to try hiking, and my youngest son \nlikes fishing, but he's not very good at it,’” Healy said.\n“If you were talking to somebody who knew everything about every campsite, then what answer would they give \nyou? That's what we think artificial intelligence can do,” he added. “And it's not just the data that's in the system, but \nit's all of the reviews and blogs and everything's out there in the public domain that you can pull different pieces \ntogether, put together into a contextual answer.”\nIf AI is able to understand a traveler’s intent, Healy said it could also suggest alternative destinations or experiences \nif something a traveler wants is booked up or otherwise not available. He said it could also help make public lands \nmore accessible to more people.\n“If you have some sort of impairment – maybe it's sight, hearing, mobility, cognitive, whatever it is – that confidence \nlevel (outdoors) might go down, “Healy said. “We want to provide you the right information, so that you can get \noutside with as much confidence as possible and have an experience that matches your needs.”\nThis article originally appeared on USA TODAY: How to use AI to plan your next vacation and what you should \nknow first\nLoad-Date: May 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "The Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighted Work",
        "media": "The New York Times",
        "time": "December 28, 2023",
        "section": "BUSINESS; media",
        "length": "1527 words",
        "byline": "Michael M. Grynbaum and Ryan Mac &lt;p&gt;Michael M. Grynbaum writes about the intersection of media,",
        "story_text": "The Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighted Work\nThe New York Times \nDecember 27, 2023 Wednesday 14:49 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1527 words\nByline: Michael M. Grynbaum and Ryan Mac &lt;p&gt;Michael M. Grynbaum writes about the intersection of media, \npolitics and culture. He has been a media correspondent at The Times since 2016.&lt;/p&gt; &lt;p&gt;Ryan Mac \ncovers corporate accountability across the global technology industry.&lt;/p&gt;\nHighlight: Millions of articles from The New York Times were used to train chatbots that now compete with it, the \nlawsuit said.\nBody\nMillions of articles from The New York Times were used to train chatbots that now compete with it, the lawsuit said.\nThe New York Times sued OpenAI and Microsoft for copyright infringement on Wednesday, opening a new front in \nthe increasingly intense legal battle over the unauthorized use of published work to train artificial intelligence \ntechnologies.\nThe Times is the first major American media organization to sue the companies, the creators of ChatGPT and other \npopular A.I. platforms, over copyright issues associated with its written works. The lawsuit, filed in Federal District \nCourt in Manhattan, contends that millions of articles published by The Times were used to train automated \nchatbots that now compete with the news outlet as a source of reliable information.\nThe suit does not include an exact monetary demand. But it says the defendants should be held responsible for \n“billions of dollars in statutory and actual damages” related to the “unlawful copying and use of The Times’s \nuniquely valuable works.” It also calls for the companies to destroy any chatbot models and training data that use \ncopyrighted material from The Times.\nIn its complaint, The Times said it approached Microsoft and OpenAI in April to raise concerns about the use of its \nintellectual property and explore “an amicable resolution,” possibly involving a commercial agreement and \n“technological guardrails” around generative A.I. products. But it said the talks had not produced a resolution.\nAn OpenAI spokeswoman, Lindsey Held, said in a statement that the company had been “moving forward \nconstructively” in conversations with The Times and that it was “surprised and disappointed” by the lawsuit.\n“We respect the rights of content creators and owners and are committed to working with them to ensure they \nbenefit from A.I. technology and new revenue models,” Ms. Held said. “We’re hopeful that we will find a mutually \nbeneficial way to work together, as we are doing with many other publishers.”\nMicrosoft declined to comment on the case.\nThe lawsuit could test the emerging legal contours of generative A.I. technologies — so called for the text, images \nand other content they can create after learning from large data sets — and could carry major implications for the \nnews industry. The Times is among a small number of outlets that have built successful business models from \nonline journalism, but dozens of newspapers and magazines have been hobbled by readers’ migration to the \ninternet.\nThe Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighted Work\nAt the same time, OpenAI and other A.I. tech firms — which use a wide variety of online texts, from newspaper \narticles to poems to screenplays, to train chatbots — are attracting billions of dollars in funding.\nOpenAI is now valued by investors at more than $80 billion. Microsoft has committed $13 billion to OpenAI and has \nincorporated the company’s technology into its Bing search engine.\n“Defendants seek to free-ride on The Times’s massive investment in its journalism,” the complaint says, accusing \nOpenAI and Microsoft of “using The Times’s content without payment to create products that substitute for The \nTimes and steal audiences away from it.”\nThe defendants have not had an opportunity to respond in court.\nConcerns about the uncompensated use of intellectual property by A.I. systems have coursed through creative \nindustries, given the technology’s ability to mimic natural language and generate sophisticated written responses to \nvirtually any prompt.\nThe actress Sarah Silverman joined a pair of lawsuits in July that accused Meta and OpenAI of having “ingested” \nher memoir as a training text for A.I. programs. Novelists expressed alarm when it was revealed that A.I. systems \nhad absorbed tens of thousands of books, leading to a lawsuit by authors including Jonathan Franzen and John \nGrisham. Getty Images, the photography syndicate, sued one A.I. company that generates images based on written \nprompts, saying the platform relies on unauthorized use of Getty’s copyrighted visual materials.\nThe boundaries of copyright law often get new scrutiny at moments of technological change — like the advent of \nbroadcast radio or digital file-sharing programs like Napster — and the use of artificial intelligence is emerging as \nthe latest frontier.\n“A Supreme Court decision is essentially inevitable,” Richard Tofel, a former president of the nonprofit newsroom \nProPublica and a consultant to the news business, said of the latest flurry of lawsuits. “Some of the publishers will \nsettle for some period of time — including still possibly The Times — but enough publishers won’t that this novel \nand crucial issue of copyright law will need to be resolved.”\nMicrosoft has previously acknowledged potential copyright concerns over its A.I. products. In September, the \ncompany announced that if customers using its A.I. tools were hit with copyright complaints, it would indemnify \nthem and cover the associated legal costs.\nOther voices in the technology industry have been more steadfast in their approach to copyright. In October, \nAndreessen Horowitz, a venture capital firm and early backer of OpenAI, wrote in comments to the U.S. Copyright \nOffice that exposing A.I. companies to copyright liability would “either kill or significantly hamper their development.”\n“The result will be far less competition, far less innovation and very likely the loss of the United States’ position as \nthe leader in global A.I. development,” the investment firm said in its statement.\nBesides seeking to protect intellectual property, the lawsuit by The Times casts ChatGPT and other A.I. systems as \npotential competitors in the news business. When chatbots are asked about current events or other newsworthy \ntopics, they can generate answers that rely on journalism by The Times. The newspaper expresses concern that \nreaders will be satisfied with a response from a chatbot and decline to visit The Times’s website, thus reducing web \ntraffic that can be translated into advertising and subscription revenue.\nThe complaint cites several examples when a chatbot provided users with near-verbatim excerpts from Times \narticles that would otherwise require a paid subscription to view. It asserts that OpenAI and Microsoft placed \nparticular emphasis on the use of Times journalism in training their A.I. programs because of the perceived \nreliability and accuracy of the material.\nMedia organizations have spent the past year examining the legal, financial and journalistic implications of the \nboom in generative A.I. Some news outlets have already reached agreements for the use of their journalism: The \nThe Times Sues OpenAI and Microsoft Over A.I. Use of Copyrighted Work\nAssociated Press struck a licensing deal in July with OpenAI, and Axel Springer, the German publisher that owns \nPolitico and Business Insider, did likewise this month. Terms for those agreements were not disclosed.\nThe Times is exploring how to use the nascent technology itself. The newspaper recently hired an editorial director \nof artificial intelligence initiatives to establish protocols for the newsroom’s use of A.I. and examine ways to integrate \nthe technology into the company’s journalism.\nIn one example of how A.I. systems use The Times’s material, the suit showed that Browse With Bing, a Microsoft \nsearch feature powered by ChatGPT, reproduced almost verbatim results from Wirecutter, The Times’s product \nreview site. The text results from Bing, however, did not link to the Wirecutter article, and they stripped away the \nreferral links in the text that Wirecutter uses to generate commissions from sales based on its recommendations.\n“Decreased traffic to Wirecutter articles and, in turn, decreased traffic to affiliate links subsequently lead to a loss of \nrevenue for Wirecutter,” the complaint states.\nThe lawsuit also highlights the potential damage to The Times’s brand through so-called A.I. “hallucinations,” a \nphenomenon in which chatbots insert false information that is then wrongly attributed to a source. The complaint \ncites several cases in which Microsoft’s Bing Chat provided incorrect information that was said to have come from \nThe Times, including results for “the 15 most heart-healthy foods,” 12 of which were not mentioned in an article by \nthe paper.\n“If The Times and other news organizations cannot produce and protect their independent journalism, there will be \na vacuum that no computer or artificial intelligence can fill,” the complaint reads. It adds, “Less journalism will be \nproduced, and the cost to society will be enormous.”\nThe Times has retained the law firms Susman Godfrey and Rothwell, Figg, Ernst &amp; Manbeck as outside \ncounsel for the litigation. Susman represented Dominion Voting Systems in its defamation case against Fox News, \nwhich resulted in a $787.5 million settlement in April. Susman also filed a proposed class action suit last month \nagainst Microsoft and OpenAI on behalf of nonfiction authors whose books and other copyrighted material were \nused to train the companies’ chatbots.\nBenjamin Mullin contributed reporting.\nBenjamin Mullin contributed reporting. \nPHOTO: The Times is the first major U.S. media company to sue the A.I. platforms. (PHOTOGRAPH BY ZACK \nDEZON FOR THE NEW YORK TIMES) (B5) This article appeared in print on page B1, B5.\nLoad-Date: December 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "For Workers, Promise of A.I. Is a Threat, Too",
        "media": "The New York Times",
        "time": "March 29, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1650 words",
        "byline": "By Lydia DePillis and Steve Lohr",
        "story_text": "For Workers, Promise of A.I. Is a Threat, Too\nThe New York Times\nMarch 29, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1650 words\nByline: By Lydia DePillis and Steve Lohr\nBody\nIn December, the staff of the American Writers and Artists Institute -- a 26-year-old membership organization for \ncopywriters -- realized that something big was happening.\nThe newest edition of ChatGPT, a ''large language model'' that mines the internet to answer questions and perform \ntasks on command, had just been released. Its abilities were astonishing -- and squarely in the bailiwick of people \nwho generate content, such as advertising copy and blog posts, for a living. \n  ''They're horrified,'' said Rebecca Matter, the institute's president. Over the holidays, she scrambled to organize a \nwebinar on the pitfalls and potential of the new artificial-intelligence technology. More than 3,000 people signed up, \nshe said, and the overall message was cautionary but reassuring: Writers could use ChatGPT to complete \nassignments more quickly, and move into higher-level roles in content planning and search-engine optimization.\n  ''I do think it's going to minimize short-form copy projects,'' Ms. Matter said. ''But on the flip side of that, I think \nthere will be more opportunities for things like strategy.''\n  OpenAI's ChatGPT is the latest advance in a steady march of innovations that have offered the potential to \ntransform many occupations and wipe out others, sometimes in tandem. It is too early to tally the enabled and the \nendangered, or to gauge the overall impact on labor demand and productivity. But it seems clear that artificial \nintelligence will impinge on work in different ways than previous waves of technology.\n  The positive view of tools like ChatGPT is that they could be complements to human labor, rather than \nreplacements. Not all workers are sanguine, however, about the prospective impact.\n  Katie Brown is a grant writer in the Chicago suburbs for a small nonprofit group focused on addressing domestic \nviolence. She was shocked to learn in early February that a professional association for grant writers was promoting \nthe use of artificial-intelligence software that would automatically complete parts of an application, requiring the \nhuman simply to polish it before submitting.\n  The platform, called Grantable, is based on the same technology as ChatGPT, and it markets itself to freelancers \nwho charge by the application. That, she thought, clearly threatens opportunities in the industry.\n  ''For me, it's common sense: Which do you think a small nonprofit will pick?'' Ms. Brown said. ''A full-time-salary-\nplus-benefits person, or someone equipped with A.I. that you don't have to pay benefits for?''\n  Artificial intelligence and machine learning have been operating in the background of many businesses for years, \nhelping to evaluate large numbers of possible decisions and better align supply with demand, for example. And \nFor Workers, Promise of A.I. Is a Threat, Too\nplenty of technological advancements over centuries have decreased the need for certain workers -- although each \ntime, the jobs created have more than offset the number lost.\n  ChatGPT, however, is the first to confront such a broad range of white-collar workers so directly, and to be so \naccessible that people could use it in their own jobs. And it is improving rapidly, with a new edition released this \nmonth. According to a survey conducted by the job search website ZipRecruiter after ChatGPT's release, 62 \npercent of job seekers said they were concerned that artificial intelligence could derail their careers.\n  ''ChatGPT is the one that made it more visible,'' said Michael Chui, a partner at the McKinsey Global Institute who \nstudies automation's effects. ''So I think it did start to raise questions about where timelines might start to be \naccelerated.''\n  That's also the conclusion of a White House report on the implications of A.I. technology, including ChatGPT. ''The \nprimary risk of A.I. to the work force is in the general disruption it is likely to cause to workers, whether they find that \ntheir jobs are newly automated or that their job design has fundamentally changed,'' the authors wrote.\n  For now, Guillermo Rubio has found that his job as a copywriter has changed markedly since he started using \nChatGPT to generate ideas for blog posts, write first drafts of newsletters, create hundreds of slight variations on \nstock advertising copy and summon research on a subject about which he might write a white paper.\n  Since he still charges his clients the same rates, the tool has simply allowed him to work less. If the going rate for \ncopy goes down, though -- which it might, as the technology improves -- he's confident he'll be able to move into \nconsulting on content strategy, along with production.\n  ''I think people are more reluctant and fearful, with good reason,'' Mr. Rubio, who is in Orange County, Calif., said. \n''You could look at it in a negative light, or you can embrace it. I think the biggest takeaway is you have to be \nadaptable. You have to be open to embracing it.''\n  After decades of study, researchers understand a lot about automation's impact on the work force. Economists \nincluding Daron Acemoglu at the Massachusetts Institute of Technology have found that since 1980, technology \nhas played a primary role in amplifying income inequality. As labor unions atrophied, hollowing out systems for \ntraining and retraining, workers without college educations saw their bargaining power reduced in the face of \nmachines capable of rudimentary tasks.\n  The advent of ChatGPT three months ago, however, has prompted a flurry of studies predicated on the idea that \nthis isn't your average robot.\n  One team of researchers ran an analysis showing the industries and occupations that are most exposed to \nartificial intelligence, based on a model adjusted for generative language tools. Topping the list were college \nhumanities professors, legal services providers, insurance agents and telemarketers. Mere exposure, however, \ndoesn't determine whether the technology is likely to replace workers or merely augment their skills.\n  Shakked Noy and Whitney Zhang, doctoral students at M.I.T., conducted a randomized, controlled trial on \nexperienced professionals in such fields as human relations and marketing. The participants were given tasks that \ntypically take 20 to 30 minutes, like writing news releases and brief reports. Those who used ChatGPT completed \nthe assignments 37 percent faster on average than those who didn't -- a substantial productivity increase. They also \nreported a 20 percent increase in job satisfaction.\n  A third study -- using a program developed by GitHub, which is owned by Microsoft -- evaluated the impact of \ngenerative A.I. specifically on software developers. In a trial run by GitHub's researchers, developers given an \nentry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than \nthose who did the assignment manually.\n  Those productivity gains are unlike almost any observed since the widespread adoption of the personal computer.\nFor Workers, Promise of A.I. Is a Threat, Too\n  ''It does seem to be doing something fundamentally different,'' said David Autor, another M.I.T. economist, who \nadvises Ms. Zhang and Mr. Noy. ''Before, computers were powerful, but they simply and robotically did what people \nprogrammed them to do.'' Generative artificial intelligence, on the other hand, is ''adaptive, it learns and is \ncapable of flexible problem solving.''\n  That's very apparent to Peter Dolkens, a software developer for a company that primarily makes online tools for \nthe sports industry. He has been integrating ChatGPT into his work for tasks like summarizing chunks of code to aid \ncolleagues who may pick up the project after him, and proposing solutions to problems that have him stumped. If \nthe answer isn't perfect, he'll ask ChatGPT to refine it, or try something different.\n  ''It's the equivalent of a very well-read intern,'' Mr. Dolkens, who is in London, said. ''They might not have the \nexperience to know how to apply it, but they know all the words, they've read all the books and they're able to get \npart of the way there.''\n  There's another takeaway from the initial research: ChatGPT and Copilot elevated the least experienced workers \nthe most. If true, more generally, that could mitigate the inequality-widening effects of artificial intelligence.\n  On the other hand, as each worker becomes more productive, fewer workers are required to complete a set of \ntasks. Whether that results in fewer jobs in particular industries depends on the demand for the service provided, \nand the jobs that might be created in helping to manage and direct the A.I. ''Prompt engineering,'' for example, is \nalready a skill that those who play around with ChatGPT long enough can add to their résumés.\n  Since demand for software code seems insatiable, and developers' salaries are extremely high, increasing \nproductivity seems unlikely to foreclose opportunities for people to enter the field.\n  That won't be the same for every profession, however, and Dominic Russo is pretty sure it won't be true for his: \nwriting appeals to pharmacy benefit managers and insurance companies when they reject prescriptions for \nexpensive drugs. He has been doing the job for about seven years, and has built expertise with only on-the-job \ntraining, after studying journalism in college.\n  After ChatGPT came out, he asked it to write an appeal on behalf of someone with psoriasis who wanted the \nexpensive drug Otezla. The result was good enough to require only a few edits before submitting it.\n  ''If you knew what to prompt the A.I. with, anyone could do the work,'' Mr. Russo said. ''That's what's really scares \nme. Why would a pharmacy pay me $70,000 a year, when they can license the technology and pay people $12 an \nhour to run prompts into it?''\n  To try to protect himself from that possible future, Mr. Russo has been building up his side business: selling pizzas \nout of his house in southern New Jersey, an enterprise that he figures won't be disrupted by artificial intelligence.\n  Yet.\nhttps://www.nytimes.com/2023/03/28/business/economy/jobs-ai-artificial-intelligence-chatgpt.html\nGraphic\n \nPHOTO: Guillermo Rubio said his job as a copywriter has changed since he started using ChatGPT to generate \nideas for blog posts and write first drafts of newsletters. (PHOTOGRAPH BY IN-CAMERA DOUBLE EXPOSURE \nBY MARK ABRAMSON FOR THE NEW YORK TIMES) (A18) This article appeared in print on page A1, A18.               \nLoad-Date: March 29, 2023\nFor Workers, Promise of A.I. Is a Threat, Too"
    },
    {
        "file_name": "undergrads_Feb2024",
        "header": "A degree in artificial intelligence: Penn becomes first Ivy to offer AI major for",
        "media": "undergrads",
        "time": "February 15, 2024",
        "section": "ROBOTICS NEWS",
        "length": "511 words",
        "byline": "Anthony Robledo, USA TODAY",
        "story_text": "A degree in artificial intelligence: Penn becomes first Ivy to offer AI major for \nundergrads\nUSA Today Online\nFebruary 15, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: ROBOTICS NEWS\nLength: 511 words\nByline: Anthony Robledo, USA TODAY\nBody\nAs artificial intelligence continues to advance its grasp on humans, humans are following suit.\nStarting this fall, students at the University of Pennsylvania can major in AI. In a news release this week, the school \nunveiled plans to become the first of the Ivy League universities to offer an undergraduate degree focused on AI.\nThe Bachelor of Science in Engineering in Artificial Intelligence degree, will teach students the principles of AI and \nhow to utilize its abilities in \"a responsible and ethical way.\" Students will study the sharp rise of generative AI and \nhow it has transformed various aspects of life from health, energy, transportation, commerce, and national security.  \n\"This new degree program represents a leap forward for the Penn engineers who will lead in developing and \ndeploying these powerful technologies in service to humanity,\" Interim President J. Larry Jameson said in the news \nrelease. \n Student debt relief: Biden proposes new loan relief plan for borrowers ‘highly likely’ to default\nLink to Image\nWhat it means to major in AI\nStudents pursuing the B.S.E will take high-level courses from topics like computing algorithms, machine learning, \ndata analytics and advanced robotics, the university said. \nIntro courses include \"Introduction to Artificial Intelligence\" and \"Data, Systems, Decisions\" while other required \nclasses consist of \"Control For Autonomous Robots,\" \"Natural Language Processing\" and \"Signal and Information \nProcessing.\" \nThe major also offers elective classes like \"Trustworthy AI,\" \"Machine Perception\" and \"Brain Computer Interfaces.\" \nA full list of the curriculum and available courses can be found here.\nBased on their specific interests, students can choose between the following concentrations:\n• Robotics\n• Vision/Language\n• Machine Learning\n• Data/Society\n• Health/Systems\nA degree in artificial intelligence: Penn becomes first Ivy to offer AI major for undergrads\nStudents will learn how to build 'trustworthy AI'\nPenn's program reflects the reality that AI has become it's own academic discipline, according to Computer and \nInformation Science Department Chair Zachary Ives.\n\"Not only because of the many amazing things it can do, but also because we think it’s important to address \nfundamental questions about the nature of intelligence and learning, how to align AI with our social values, and how \nto build trustworthy AI systems,\" Ives said in the news release. \nVijay Kumar, a dean at Penn Engineering, said the program will prepare the next generation of engineers on how to \nuse AI as a tool and a \"fundamental force for good.\" \n\"Realizing the potential of AI for positive social impact stands as one of the paramount challenges confronting \nengineering,\" said George J. Pappas, who will lead the program.\nThe program will officially commence in the fall 2024 semester. Applications for existing Penn students who want to \ntransfer into the 2024 cohort will be available this fall, the news release said. Prospective students can apply for the \nFall 2025 cohort this fall as well. \nThis article originally appeared on USA TODAY: A degree in artificial intelligence: Penn becomes first Ivy to offer AI \nmajor for undergrads\nLoad-Date: February 15, 2024"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "The A.I. Revolution Is Coming. But Not as Fast as Some People Think.",
        "media": "The New York Times",
        "time": "September 3, 2023",
        "section": "TECHNOLOGY",
        "length": "1340 words",
        "byline": "Steve Lohr",
        "story_text": "The A.I. Revolution Is Coming. But Not as Fast as Some People Think.\nThe New York Times \nAugust 29, 2023 Tuesday 22:56 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1340 words\nByline: Steve Lohr\nHighlight: From steam power to the internet, there has always been a lag between technology invention and \nadoption across industries and the economy.\nBody\nFrom steam power to the internet, there has always been a lag between technology invention and adoption across \nindustries and the economy.\nLori Beer, the global chief information officer of JPMorgan Chase, talks about the latest artificial intelligence with the \nenthusiasm of a convert. She refers to A.I. chatbots like ChatGPT, with its ability to produce everything from poetry \nto computer programs, as “transformative” and a “paradigm shift.”\nBut it’s not coming soon to the nation’s largest bank. JPMorgan has blocked access to ChatGPT from its computers \nand told its 300,000 workers not to put any bank information into the chatbot or other generative A.I. tools.\nFor now, Ms. Beer said, there are too many risks of leaking confidential data, questions about how the data is used \nand about the accuracy of the A.I.-generated answers. The bank has created a walled-off, private network to allow \na few hundred data scientists and engineers to experiment with the technology. They are exploring uses like \nautomating and improving tech support and software development.\nAcross corporate America, the perspective is much the same. Generative A.I., the software engine behind \nChatGPT, is seen as an exciting new wave of technology. But companies in every industry are mainly trying out the \ntechnology and thinking through the economics. Widespread use of it at many companies could be years away.\nGenerative A.I., according to forecasts, could sharply boost productivity and add trillions of dollars to the global \neconomy. Yet the lesson of history, from steam power to the internet, is that there is a lengthy lag between the \narrival of major new technology and its broad adoption — which is what transforms industries and helps fuel the \neconomy.\nTake the internet. In the 1990s, there were confident predictions that the internet and the web would disrupt the \nretailing, advertising and media industries. Those predictions proved to be true, but that was more than a decade \nlater, well after the dot-com bubble had burst.\nOver that time, the technology improved and costs dropped, so bottlenecks fell away. Broadband internet \nconnections eventually became commonplace. Easy-to-use payment systems were developed. Audio and video \nstreaming technology became far better.\nFueling the development were a flood of money and a surge of entrepreneurial trial and error.\n“We’re going to see a similar gold rush this time,” said Vijay Sankaran, chief technology officer of Johnson Controls, \na large supplier of building equipment, software and services. “We’ll see a lot of learning.”\nThe A.I. Revolution Is Coming. But Not as Fast as Some People Think.\nThe investment frenzy is well underway. In the first half of 2023, funding for generative A.I. start-ups reached $15.3 \nbillion, nearly three times the total for all of last year, according to PitchBook, which tracks start-up investments.\nCorporate technology managers are sampling generative A.I. software from a host of suppliers and watching to \nsee how the industry shakes out.\nIn November, when ChatGPT was made available to the public, it was a “Netscape moment” for generative A.I., \nsaid Rob Thomas, IBM’s chief commercial officer, referring to Netscape’s introduction of the browser in 1994. “That \nbrought the internet alive,” Mr. Thomas said. But it was just a beginning, opening a door to new business \nopportunities that took years to exploit.\nIn a recent report, the McKinsey Global Institute, the research arm of the consulting firm, included a timeline for the \nwidespread adoption of generative A.I. applications. It assumed steady improvement in currently known \ntechnology, but not future breakthroughs. Its forecast for mainstream adoption was neither short nor precise, a \nrange of eight to 27 years.\nThe broad range is explained by plugging in different assumptions about economic cycles, government regulation, \ncorporate cultures and management decisions.\n“We’re not modeling the laws of physics here; we’re modeling economics and societies, and people and \ncompanies,” said Michael Chui, a partner at the McKinsey Global Institute. “What happens is largely the result of \nhuman choices.”\nTechnology diffuses across the economy through people, who bring their skills to new industries. A few months \nago, Davis Liang left an A.I. group at Meta to join Abridge, a health care start-up that records and summarizes \npatient visits for physicians. Its generative A.I. software can save doctors from hours of typing up patient notes and \nbilling reports.\nMr. Liang, a 29-year-old computer scientist, has been an author on scientific papers and helped build so-called \nlarge language models that animate generative A.I.\nHis skills are in demand these days. Mr. Liang declined to say, but people with his experience and background at \ngenerative A.I. start-ups are typically paid a base salary of more than $200,000, and stock grants can potentially \ntake the total compensation far higher.\nThe main appeal of Abridge, Mr. Liang said, was applying the “superpowerful tool” of A.I. in health care and \n“improving the working lives of physicians.” He was recruited by Zachary Lipton, a former research scientist in \nAmazon’s A.I. group, who is an assistant professor at Carnegie Mellon University. Mr. Lipton joined Abridge early \nthis year as chief scientific officer.\n“We’re not working on ads or something like that,” Mr. Lipton said. “There is a level of fulfillment when you’re getting \nthank-you letters from physicians every day.”\nSignificant new technologies are flywheels for follow-on innovation, spawning start-ups that build applications to \nmake the underlying technology useful and accessible. In its early years, the personal computer was seen as a \nhobbyist’s plaything. But the creation of the spreadsheet program — the “killer app” of its day — made the PC an \nessential tool in business.\nSarah Nagy led a data science team at Citadel, a giant investment firm, in 2020 when she first tinkered with GPT-3. \nIt was more than two years before OpenAI released ChatGPT. But the power of the fundamental technology was \napparent in 2020.\nMs. Nagy was particularly impressed by the software’s ability to generate computer code from text commands. \nThat, she figured, could help democratize data analysis inside companies, making it broadly accessible to \nbusinesspeople instead of an elite group.\nThe A.I. Revolution Is Coming. But Not as Fast as Some People Think.\nIn 2021, Ms. Nagy founded Seek AI to pursue that goal. The New York start-up now has about two dozen \ncustomers in the technology, retail and finance industries, mostly working on pilot projects.\nUsing Seek AI’s software, a retail manager, for example, could type in questions about product sales, ad campaigns \nand online versus in-store performance to guide marketing strategy and spending. The software then transforms the \nwords into a computer-coded query, searches the company’s storehouse of data, and returns answers in text or \nretrieves the relevant data.\nBusinesspeople, Ms. Nagy said, can get answers almost instantly or within a day instead of a couple of weeks, if \nthey have to make a request for something that requires the attention of a member of a data science team.\n“At the end of the day, we’re trying to reduce the time it takes to get an answer or useful data,” Ms. Nagy said.\nSaving time and streamlining work inside companies are the prime early targets for generative A.I. in most \nbusinesses. New products and services will come later.\nThis year, JPMorgan trademarked IndexGPT as a possible name for a generative A.I.-driven investment advisory \nproduct.\n“That’s something we will look at and continue to assess over time,” said Ms. Beer, the bank’s tech leader. “But it’s \nnot close to launching yet.”\nPHOTOS: Sarah Nagy left the investment firm Citadel to found the artificial intelligence start-up Seek AI. “We’re \ntrying to reduce the time it takes to get an answer or useful data,” she said. Davis Liang, right, left the A.I. group at \nMeta to join Abridge, a health care start-up that is trying to help doctors with their paperwork. (PHOTOGRAPHS BY \nEVELYN FREJA FOR THE NEW YORK TIMES; GELOY CONCEPCION FOR THE NEW YORK TIMES) (B3) This \narticle appeared in print on page B1, B3.\nLoad-Date: September 3, 2023"
    },
    {
        "file_name": "Manjoo_May2023",
        "header": "A.I. Photoshopping Is About to Get Very Easy. Maybe Too Easy.; Farhad",
        "media": "Manjoo",
        "time": "May 24, 2023",
        "section": "OPINION",
        "length": "1551 words",
        "byline": "Farhad Manjoo",
        "story_text": "A.I. Photoshopping Is About to Get Very Easy. Maybe Too Easy.; Farhad \nManjoo\nThe New York Times - International Edition\nMay 25, 2023 Thursday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: OPINION\nLength: 1551 words\nByline: Farhad Manjoo\nBody\nABSTRACT\nThe photo-editing program can now generate images of almost anything. Its maker has a plan it hopes will make \nthis less risky than it sounds.\nFULL TEXT\nPhotoshop is the granddaddy of image-editing apps, the O.G. of our airbrushed, Facetuned media ecosystem and a \nproduct so enmeshed in the culture that it's a verb, an adjective and a frequent lament of rappers. Photoshop is \nalso widely used. More than 30 years since the first version was released, professional photographers, graphic \ndesigners and other visual artists the world over reach for the app to edit much of the imagery you see online, in \nprint and on billboards, bus stops, posters, product packaging and anything else the light touches.       \nSo what does it mean that Photoshop is diving into generative artificial intelligence - that a just-released beta \nfeature called Generative Fill will allow you to photorealistically render just about any imagery you ask of it? \n(Subject, of course, to terms of service.)       \nNot just that, actually: So many A.I. image generators have been released over the past year or so that the idea of \nprompting a computer to create pictures already seems old hat. What's novel about Photoshop's new capabilities is \nthat they allow for the easy merger of reality and digital artifice and they bring it to a large user base. The software \nallows anyone with a mouse, an imagination and $10 to $20 a month to - without any expertise - subtly alter \npictures, sometimes appearing so real that it seems likely to erase most of the remaining barriers between the \nauthentic and the fake.       \nThe good news is that Adobe, the company that makes Photoshop, has considered the dangers and has been \nworking on a plan to address the widespread dissemination of digitally manipulated pics. The company has created \nwhat it describes as a \"nutrition label\" that can be embedded in image files to document how a picture was altered, \nincluding if it has elements generated by artificial intelligence.       \nThe plan, called the Content Authenticity Initiative, is meant to bolster the credibility of digital media. It won't alert \nyou to every image that's fake but instead can help a creator or publisher prove that a certain image is true. In the \nfuture, you might see a snapshot of a car accident or terrorist attack or natural disaster on Twitter and dismiss it as \nfake unless it carries a content credential saying how it was created and edited.       \n\"Being able to prove what's true is going to be essential for governments, for news agencies and for regular \npeople,\" Dana Rao, Adobe's general counsel and chief trust officer, told me. \"And if you get some important \nA.I. Photoshopping Is About to Get Very Easy. Maybe Too Easy. Farhad Manjoo\ninformation that doesn't have a content credential associated with it - when this becomes popularized - then you \nshould have that skepticism: This person decided not to prove their work, so I should be skeptical.\"       \nThe key phrase there, though, is \"when this becomes popularized.\" Adobe's plan requires industry and media buy-\nin to be useful, but the A.I. features in Photoshop are being released to the public well before the safety system has \nbeen widely adopted. I don't blame the company - industry standards often aren't embraced before an industry has \nmatured, and A.I. content generation remains in the early stages - but Photoshop's new features underscore the \nurgent need for some kind of widely accepted standard.       \nWe're about to be deluged - or even more deluged than we already are - with realistic-looking artificial pictures. \nTech companies should move quickly, as an industry, to put in place Adobe's system or some other kind of safety \nnet. A.I. imagery keeps getting more refined; there's no time to waste.       \nIndeed, a lot of recent developments in A.I. have elicited the same two reactions from me, in quick succession:       \nAmazing! What a time to be alive!\nArghhhh! What a time to be alive!\nThat's roughly how I felt when I visited Adobe's headquarters last week to see a demo of Photoshop's new A.I. \nfeatures. I later got to use the software, and while it's far from perfect at altering images in ways that aren't \ndetectable, I found it good enough often enough that I suspect it will soon be widely used.       \nAn example: On vacation in Hawaii this year (a tough life, I know), I snapped a close-up photo of a redheaded bird \nperched on an outdoor dining table. The picture is fine, but it lacks drama. The bird is just sitting there flatly, as birds \ndo.       \nIn the new Photoshop, I drew a selection box around the table and typed in \"a man's forearm for the bird to perch \non.\" Photoshop sent my picture and the prompt to Firefly, the A.I. image-generation system that Adobe released as \na Web app this year. After about 30 seconds of processing time, my picture was altered: The wooden table had \nbeen turned into an arm, the bird's feet pretty realistically planted on the skin:       \nAs you can imagine, I lost many hours experimenting with this. Photoshop offers three initial options for each \nrequest (the other choices for my perching bird had one much hairier arm and one much more muscular, but both \nlooked a bit unnatural) and if you don't like any of them, you can ask for more. Sometimes the results aren't great: \nIt's bad at creating images of people's faces - right now, they look strange - and it fails at delivering on very precise \nrequests: When I didn't specify a skin color, the forearms it gave me for the bird to perch on were all fair; when I \nasked for a brown arm to match my skin tone, I got back images that didn't look very realistic.       \nStill, I was frequently staggered by how well Photoshop responded to my requests. Items it added to my photos \nmatched the context of the original; the lighting, scale and perspective were often remarkably on target. Look at the \nsilly things I added to this view of Manhattan skyscrapers:       \nThe giant wasp and eagle look a little tacked on, but notice how well the lighting on the bumblebee and hot air \nballoons match the direction of sunlight in the original photo. Look at the small things that look almost perfect: the \ncrowds added to the ledges, the spider web stretching between the buildings.       \nIt's also terrific for removing people and things. The fence and graffiti in this scene - gone as if they had never been \nthere.       \nThe blurry scooter rider and cars crowding out this shot of a delivery guy - presto! - gone.       \nBy default, images that you create with the Web version of Firefly are embedded with Adobe's content credentials \ndisclosing that they were generated by A.I. But in this beta version, Photoshop doesn't automatically embed this \ntag. You can turn on the credential, but you don't have to. Adobe says that the tag will be required on images that \nA.I. Photoshopping Is About to Get Very Easy. Maybe Too Easy. Farhad Manjoo\nuse generative A.I. when the feature comes out of beta. Requiring this will be essential - without it, any lofty plans \nAdobe has to maintain the line between genuine and phony images won't be very successful.       \nBut even if you do attach a credential to your photo, it won't be of much use just yet. Adobe is working to make its \ncontent authenticity system an industry standard, and it has seen some success - more than 1,000 tech and media \ncompanies have joined the initiative, including camera makers like Canon, Nikon and Leica; tech heavyweights like \nMicrosoft and Nvidia; and many news organizations, such as The Associated Press, the BBC, The Washington \nPost, The Wall Street Journal and The New York Times. (In 2019, Adobe announced that along with The Times and \nTwitter it was starting an initiative to develop an industry standard for content attribution.)       \nWhen the system is up and running, you might be able to click on an image published in The Times and see an \naudit trail - where and when it was taken, how it was edited and by whom. The feature would even work when \nsomeone takes an authentic image and alters it. You could run the altered pic through the content credential \ndatabase, and it would tell you which true image it was based on.       \nBut while many organizations have signed on to Adobe's plan, to date, not many have carried it out. For it to be \nmaximally useful, most if not all camera makers would have to add credentials to pictures at the moment they're \ntaken, so that a photo can be authenticated from the beginning of the process. Getting such wide adoption among \ncompeting companies could be tough but, I hope, not impossible. In an era of one-click A.I. editing, Adobe's tagging \nsystem or something similar seems a simple and necessary first step in bolstering our trust in mass media. But it \nwill work only if people use it.       \nOffice Hours With Farhad Manjoo\nFarhad wants to chat with readers on the phone. If you're interested in talking to a New York Times columnist about \nanything that's on your mind, please fill out this form. Farhad will select a few readers to call.\nSource photographs by H. Armstrong Roberts/ClassicStock, MediaProduction, VIDOK, Kozlik _Mozlik and Henri-et-\nGeorge, via Getty Images.       \nThe Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here&#39;s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nLoad-Date: May 24, 2023"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "How to address artificial intelligence in the workplace",
        "media": "USA Today",
        "time": "March 12, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "871 words",
        "byline": " ",
        "story_text": "How to address artificial intelligence in the workplace\nUSA Today\nMarch 12, 2024 Tuesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 871 words\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader's Guide to Work in an Age of Upheaval.\"\nQuestion: My job does not have a policy for the use of artificial intelligence. I started regularly using generative AI \nin my work but have yet to tell my boss. Should I let him know that I use ChatGPT for work? - Caleb\nAnswer: Absolutely. It's crucial to communicate with your boss about your use of generative AI tools like ChatGPT \nfor work, even if there isn't a formal AI policy in place at your workplace. Here are a few points to consider when \ndiscussing this with your boss:\nData security: Address the issue of data security upfront. Underscore that while generative AI is a valuable tool, \nyou are mindful of the sensitivity of the information it processes. Assure your boss you will refrain from entering \nproprietary or confidential information into ChatGPT and are willing to turn off chat history to uphold data security if \nrequested.\nMisinformation verification: Acknowledge the potential for discrepancies in the information provided by AI tools. \nEmphasize your understanding of the significance of verifying any information obtained via generative AI to ensure \naccuracy. This commitment to fact-checking will help maintain the reliability of the work you produce.\nOverreliance on AI: Address the concern of overreliance on generative AI tools. Acknowledge that while AI is a \npowerful aid in generating content, you are cautious to keep it from overshadowing your own authentic voice. Share \nyour approach to using AI as a starting point, incorporating your personal touch, and avoiding a copy-and-paste \nmentality.\nEthical considerations: Discuss the ethical considerations if you are using AI to influence decisions or products. \nHighlight your awareness of the importance of maintaining ethical standards in your work. Assure your boss you \napproach AI as a supplementary tool and that your decisions align with the company's ethical principles.\nSeek feedback: Express your willingness to receive feedback on your use of AI and inquire if there are specific \ntasks or areas where your boss would like you to apply this technology. This proactive approach demonstrates your \nopenness to collaboration and aligning AI usage with your company's objectives.\nUltimately, artificial intelligence should complement and elevate human intelligence and capability, not replace it. \nEnsuring your uniquely human intellect and intuition are involved in an operation aided by AI will deliver the best \npossible outcome. By addressing these considerations and having an open conversation with your boss, you not \nonly ensure transparency in your work but also contribute to the ongoing dialogue around AI usage in your \nHow to address artificial intelligence in the workplace\nworkplace. Your proactive approach could even help shape a future AI policy to suit your company's needs and \nvalues.\nI've never fared well in a group interview. Do you have any tips for the group interview I have coming up? - Tara\nNavigating group interviews can be challenging, but you can make a positive impact with proper preparation and \nstrategic approaches. Thorough preparation will boost your confidence during the interview.\nBegin with a comprehensive examination of the organization. Understand its values, mission and recent \nachievements. A sound understanding of the company will help you connect to its goals.\nCompile relevant examples from your experience, skills and education. Be ready to articulate how you've overcome \nchallenges in past positions. Practicing with friends or mentors who can provide constructive feedback will bolster \nyour confidence.\nDemonstrate strong networking skills by introducing yourself to group members before the interview begins. \nBuilding a rapport with interviewers and fellow candidates can help alleviate initial anxiety and create a positive \nimpression.\nGroup interviews often focus on teamwork and communication skills. Showcase your ability to collaborate by \nactively participating in group discussions. Emphasize instances where you successfully worked in a team, \nresolving challenges and achieving common goals.\nInvolve the group in your responses by connecting with what other participants have shared. Acknowledge and \nagree with their points when it makes sense. This demonstrates active listening skills and your ability to collaborate \nand build on others' ideas.\nTake note of what others are saying to avoid repetitive points. Look for opportunities to add a nuanced angle or \nexpand on ideas to move the discussion forward. This showcases your ability to think critically and build on existing \nideas.\nStay engaged throughout the group interview. Maintain eye contact, nod affirmatively, and use nonverbal cues to \nshow attentiveness. Avoid distractions and actively participate in group activities or discussions.\nShape your responses to align with the organizational objectives and job role. Have a clear understanding of the \nvalue you can bring to the company culture and the team. Remember to be authentic and distinct, allowing your \nunique qualities to shine.\nJohnny C. Taylor\nColumnist\nUSA TODAY\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "'unintentionally_cheating.'_Apr2024",
        "header": "She used Grammarly to proofread her paper. Now she's accused of",
        "media": "'unintentionally cheating.'",
        "time": "April 17, 2024",
        "section": "",
        "length": "923 words",
        "byline": "William Tang",
        "story_text": "She used Grammarly to proofread her paper. Now she's accused of \n'unintentionally cheating.'\nUSA Today Online\nApril 17, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 923 words\nByline: William Tang\nBody\nGrammarly, the company that provides the eponymous grammar and syntax program, recently announced that it’s \ngetting smarter and now offers “strategic suggestions” for its 30 million users. It might not be an innovation that \nhelps the company. \nAs Grammarly gains more generative capabilities, its usefulness for students declines because it will place them at \nrisk for unnecessary academic discipline. \nIn a story that’s gone viral, University of North Georgia student Marley Stevens ended up on academic probation for \nusing Grammarly on her criminal justice essay. Stevens said her professor accused her of “unintentionally cheating” \non her academic work because she used the program to proofread her paper.\nStevens received a zero for the assignment, which she said put her scholarship at risk. Under Stevens’ TikTok \nvideo, comments indicated that she’s not the only student who’s been penalized for Grammarly use. \nStevens’ case shows the murkier world of using artificial intelligence in schools – using it as an aid, a resource, \nrather than a replacement for one’s work. Until now, discussions of AI’s use in academics focused on its potential \nfor plagiarism, the act of simply representing an AI product as one’s own work, which is admittedly indefensible. \nResearchers from Stanford University say that concern is overblown. \nAt my school, Deerfield Academy in Massachusetts, the use of generative AI is prohibited. \nWhat's considered cheating may depend on your school\nLink to Image\nGrammarly hasn’t been necessarily generative in the ways we think of that type of intelligence; it couldn’t write a \nstudent’s essay like ChatGPT can. But now the “strategic suggestions” make the program more generative in \nnature – and more likely to fall under general AI bans. \nHere’s the rub, though: Many schools encourage and even pay for students to use Grammarly. It's expressly \npromoted in at least 3,000 educational institutions that have signed up for institutional accounts, according to \nGrammarly. \nIn Stevens’ case, the University of North Georgia promoted Grammarly on its website then removed it, then placed \nit on its website again. \nHigh school seniors need help: Why the college application process isn't adding up for students \nShe used Grammarly to proofread her paper. Now she's accused of 'unintentionally cheating.'\nWhile individual schools should be allowed to create their own policies, we are headed for a situation where what’s \nconsidered cheating is allowed at one school and not at another. Or in one course and not another. \nThat’s a problem because academic integrity is universal. Or at least it’s supposed to be. \nWhatever the rule is on using Grammarly, I will abide by it, but I notice that the concern over the type of assistance \nGrammarly provides hearkens back to the debate over calculator use in schools. \nOpinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to \nyour device through the USA TODAY app. Don't have the app? Download it for free from your app store.\nHow is Grammarly different from a calculator – or autocorrect?\nBack in the 1970s, some educators and parents worried that calculators might supplant math lessons. Research \nshows that they never did. It took 50 years, but with calculators now required in some courses and tests, we know \nthat assistive technology doesn’t necessarily replace basic lessons – or do our work for us. \nWe now prioritize agility of thought and creativity over memorization; that’s why some schools rid themselves of \nspelling tests in favor of critical thinking. \nWill my student loan be forgiven? Prepare for disappointment and hardship. Grace period for repayments expires \nin September.\nIf anything, these devices and programs allow deeper learning, mostly because they’re used by students who are \nwell past the age of initial math functions and grammar lessons. If anything, Grammarly is a refresher on grammar \nlessons of years past. \nTechnically, autocorrect is a form of AI, but holding its use against a student whose typos were fixed would be \noverkill and defeat the purpose of these programs, which were created to meet the needs of education’s evolution. \nWhether using Grammarly constitutes cheating is a multibillion dollar question that remains unanswered; it's an \nethical question that intersects with school finance. Use of Grammarly might cause students to lose scholarships, \nand schools don’t refund tuition if a student is expelled and that student may owe student loans. On top of that are \nthe opportunity costs of being accused of cheating.\nLink to Image\nMarley Stevens’ fight wages on, but Grammarly donated $4,000 to her GoFundMe to assist her education. \nBeyond Stevens’ case, though, technology companies that provide programs to students need to consider how \nmaking their products more generative will create more problems for students who use them. And teachers and \nschools that ban these programs need to consider what kind of learning they want from students.  \nUltimately – in all areas, not just education – AI is a case of making sure our technology does not outpace our \nintegrity or call into question honest work. Otherwise, we all may be cheating. Or worse, not learning as much as we \ncan.\nWilliam Tang is a high school junior at Deerfield Academy and serves on the school’s Honor Committee.\nYou can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on \nTwitter @usatodayopinion and in our daily Opinion newsletter.\nThis article originally appeared on USA TODAY: She used Grammarly to proofread her paper. Now she's accused \nof 'unintentionally cheating.'\nShe used Grammarly to proofread her paper. Now she's accused of 'unintentionally cheating.'\nLoad-Date: April 17, 2024"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "Google to rollout generative AI chatbot Bard in 180 countries, including India",
        "media": "The Economic Times",
        "time": "May 11, 2023",
        "section": "TECH & INTERNET",
        "length": "512 words",
        "byline": "Dia Rekhi",
        "story_text": "Google to rollout generative AI chatbot Bard in 180 countries, including India\nThe Economic Times\nMay 12, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 512 words\nByline: Dia Rekhi\nBody\nBard, Google's conversational generative artificial intelligence chatbot, is being rolled out in over 180 countries, \nincluding India, the company announced on Thursday at the Google I/O, its annual developer conference held at \nthe company's headquarters in Mountain View, California.\"As models get better and more capable, one of the most \nexciting opportunities is making them available for people to engage with directly,\" Google CEO Sundar Pichai said \nwhile giving the keynote speech. \"That's the opportunity we have with Bard - our experiment for conversational \nAI.\"Sissie Hsiao, Vice President at Google and General Manager for Google Assistant's business unit, said that \nBard is being opened up in all these countries and will now allow users to engage with it in Japanese and Korean. It \nwill soon be available in 40 other languages, Hsiao added.Bard, which is Google's response to OpenAI's ChatGPT \nis having most waitlist restrictions removed and making the chatbot more widely available in English in order to \ncontinue having the chatbot learn from a wider set of people.Initially, the Google Bard chatbot was only available in \nUK and US. \nInterested Indian users can now join the waitlist for the AI chatbot via the Google Bard official website.Pichai said \nthe company was 'rapidly evolving' Bard. \"It now supports a wide range of programming capabilities and its gotten \nmuch smarter at reasoning and math prompts. And as of now it is fully running on PaLM 2,\" he said. PaLM 2 is \nGoogle's newest large language model (LLM) that will power Google's updated Bard chat tool. PaLM 2 is now \navailable to developers through Google's PaLM API, Firebase and on Colab.\"PaLM 2 builds on our fundamental \nresearch and our latest infrastructure. It is highly capable at a wide range of tasks and easy to deploy. We're \nannouncing over 25 products and features powered by PaLM 2 today. PaLM 2 models deliver excellent \nfoundational capabilities across a wide range of sizes. We've affectionately named them Gecko, Otter, Bison and \nUnicorn. Gecko is so light weight that it can work on mobile devices even when offline,\" Pichai explained. He added \nthat the PaLM 2 models are stronger in logic and reasoning and that the models' broad training on scientific and \nmathematical topics and has the ability to understand over 100 languages. Pichai also said that PaLM 2 could help \ndevelopers worldwide and would even provide features to help people collaborate with colleagues who speak \ndifferent languages.Interestingly, Google said it will soon be adding multimodal content to Bard which meant that it \ncan deliver answers in more than just text. \"Coming soon, Bard will become more visual both in its responses and \nyour prompts. You'll be able to ask it things like, \"What are some must-see sights in New Orleans?\" - and in \naddition to text, you'll get a helpful response along with rich visuals to give you a much better sense of what you're \nexploring,\" Hsiao wrote in the company blog post.(The reporter is at Mountain View at the invitation of Google) For \nReprint Rights: timescontent.com\nLoad-Date: May 11, 2023"
    },
    {
        "file_name": "may_soon_be_a_reality_Sep2023",
        "header": "Amazon product launch: From Echo to Alexa, the connected smart home",
        "media": "may soon be a reality",
        "time": "September 21, 2023",
        "section": "TECH LATEST",
        "length": "948 words",
        "byline": "Bob O'Donnell",
        "story_text": "Amazon product launch: From Echo to Alexa, the connected smart home \nmay soon be a reality\nUSA Today Online\nSeptember 20, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST\nLength: 948 words\nByline: Bob O'Donnell\nBody\nCorrections & Clarifications: An earlier version of this column incorrectly attributed the source of the generative AI \nlanguage in Alexa, which is based on a custom language model created by Amazon.\nOK, let’s be honest. The concept of a truly “smart” home has always been a cool idea. After all, who wouldn’t want \nto have things like lights, appliances, and security cameras all automated in an intelligent, organized and futuristic \nway that also happens to save you hassle, time and money?\nThe problem is that the reality of smart homes has never been anywhere close to the vision. Instead, it’s a bunch of \noften difficult to set up individual products that are a nightmare to get working together as a system.\nThanks to some new products just unveiled by Amazon, however, the practical reality of a truly connected smart \nhome is starting to look much more affordable and more mainstream. \nAt its annual fall product launch event, Amazon showed off several new hardware products, as well as an enhanced \nAlexa digital assistant and smart home control software updates that make the setup and control of multiple smart \nhome devices significantly easier.\nOne of these updates is a new mapping feature that uses the lidar features found in the cameras of certain iPhones \nfrom the 12 Pro onward to automatically map out the layout of your home. \nBy opening the Alexa Mobile app and then simply pointing your iPhone’s camera at the various rooms in your home \n(either all of them or only the ones where you have or expect to have smart home devices) the lidar feature \nautomatically scans and then builds out a map of all the objects in your room.\nLink to Image\nBy opening the Alexa Mobile app and then simply pointing your iPhone’s camera at the various rooms in your home \n(either all of them or only the ones where you have or expect to have smart home devices) the lidar feature \nautomatically scans and then builds out a map of all the objects in your room.\nWhat you then do is associate your various smart home devices to their physical location in your home. The result \nis a map of your home — which, by the way, is never sent to the cloud — that makes it significantly easier and more \nintuitive to know what device or devices you are controlling and see the basic status for all the devices at once. \nOnce the map is created, it can be used on Android phones and iPhones without lidar-enabled cameras.\nAmazon also enhanced its Alexa digital assistant with some of the same kind of generative AI features that we’ve \nseen in tools like ChatGPT. The technology is based on a custom large language model (LLM) created by Amazon \nAmazon product launch: From Echo to Alexa, the connected smart home may soon be a reality\nand, for now at least, runs on Amazon’s AWS Cloud service. What’s interesting about that arrangement is that it \nmeans Amazon can and will bring the new enhanced Alexa to every single Alexa-enabled product all the way back \nto the initial Amazon Echos.\nThe new Alexa is more intelligent, more responsive, more creative, and sounds much better, making the experience \nof using it — either to set up smart home devices or any of the other kinds of Alexa-based voice requests — much \neasier. You can, for example, simply say “Alexa, I’m cold” or “Alexa, there’s a mess in here” and it will automatically \ntrigger turning up a connected thermostat or turning on a robotic vacuum (as long as you have one, of course!).\nLink to Image\nWhile there are always improvements to be made, these enhancements, including the ability to no longer constantly \nsay the “Alexa” wake word when engaging with Alexa, makes the experience of using this new version of Alexa \nmuch closer to a natural conversation.\nOn the hardware side, Amazon also unveiled a new device called the Echo Hub that’s meant to serve as a master \ncontrol hub for all your smart devices. It will also get access to the new Map View via a software upgrade early next \nyear. The Echo Hub offers many of the features of other Echo Show devices, including the upgraded Echo Show 8 \nversion introduced at this event, but also includes new software capabilities specifically designed for smart home \ndevice operation.\nLink to Image\nIn essence, it gives you a single point of easy visual access and control in a way that very expensive smart home \ncontrollers have in the past for the most sophisticated smart home systems. Importantly, though, it does that for a \nvery modest $179.\nAt the moment, you still have to set up all your individual smart devices on your smart phone first. This is \nunfortunate, as I believe many people would find the process of setting up on a main controller hub more intuitive. \nAmazon spokespeople suggested this might be possible in the future but isn’t available yet.\nIn the meantime, when you set up your smart devices through phone apps, the settings and capabilities for those \ndevices are essentially transferred over to the Echo Hub, allowing you to see, control, and automate them from \nthere. The Echo Hub includes support for all the critical wireless smart home standards, including Wi-Fi, Bluetooth, \nZigbee, the new Matter industry standard, and Amazon’s own Sidewalk technology, making it possible to connect to \nvirtually any smart home device you already own or end up purchasing in the future.\nThe end result of all these advancements is that it’s getting much easier, and more realistic, for the average person \nto put together and run a powerful smart home system. At last, Jetsons, here we come! \nUSA TODAY columnist Bob O'Donnell is the president and chief analyst of TECHnalysis Research, a market \nresearch and consulting firm. You can follow him on Twitter @bobodtech.\nThis article originally appeared on USA TODAY: Amazon product launch: From Echo to Alexa, the connected smart \nhome may soon be a reality\nLoad-Date: September 21, 2023"
    },
    {
        "file_name": "check_May2024",
        "header": "'My First Seance' toy Ouija board isn't real. Image was created with AI | Fact",
        "media": "check",
        "time": "May 1, 2024",
        "section": "",
        "length": "623 words",
        "byline": "Joedy McCreary, USA TODAY",
        "story_text": "'My First Seance' toy Ouija board isn't real. Image was created with AI | Fact \ncheck\nUSA Today Online\nMay 1, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 623 words\nByline: Joedy McCreary, USA TODAY\nBody\nThe claim: Image shows 'My First Seance' toy Ouija board\nAn April 26 Facebook post (direct link, archive link) shows what appears to be a children's toy – a colorful Ouija \nboard called “My First Seance.”\n“Don't Dare Bring this tool of Satan into your home! This is Definitely Not For Children!” reads part of the post’s \ncaption.\nThe post was shared more than 200 times in five days. Similar versions accumulated hundreds of additional shares \nand received hundreds of likes.\nMore from the Fact-Check Team:How we pick and research claims | Email newsletter | Facebook page\nOur rating: Altered\nThe image was generated with artificial intelligence, according to two computer science experts and an AI-detection \ntool. It originated in a Facebook group where users share artificially generated art.\nImage originated in Facebook group for AI-generated art\nThe Facebook post taps into long-held concerns from some religious leaders that the Ouija board is a dangerous \nand “demonic\" device. It's marketed as a board game for children 8 and older, yet purported by some to be a tool \nfor communicating with the dead.\nBut the image in the post isn’t real. It was first posted April 22 to a Facebook group where users share AI-generated \nart. The “about” section of the \"Cursed AI\" group’s page makes clear that images posted there are fabrications and \ndescribes the forum as an “eerie world of AI-generated cursed art” that includes “disturbingly beautiful images \ncrafted by AI.”\nFact check: Image of Donald Trump leading crowd down flag-lined street is AI-generated\nHive Moderation’s AI-detection tool determined the image is 99.9% likely to be AI-generated.\n“It is indeed a synthetic image from a generative AI algorithm,” Walter Scheirer, an associate professor of \ncomputer science and engineering at the University of Notre Dame, told USA TODAY in an email.\nA closer look at the details also reveals it to be a fabrication.\nOn the board's alphabet, some letters (J, U, V and X) are duplicated while others (S, W, Y) are omitted. The letter Z \nis misshapen.\n'My First Seance' toy Ouija board isn't real. Image was created with AI | Fact check\nThe word “board” on the toy is misspelled “bond,” while the word “playset” near the bottom of the box is shown with \ntwo Es and a space between them. The text along the bottom of the box’s face is gibberish, as is the text below the \nword “Ouija.”\n“The majority of the text is messed up, and the focus is inconsistent throughout the image,” Amarda Shehu, the \nassociate dean for AI innovation at George Mason University, said in an email.\nWhile the logo of the toy company is blurred out of the version in the Facebook post, the original bears what \nappears to be the Fisher-Price logo. However, in that version, the company logo is missing the hyphen.\nIt also gets the manufacturer's name wrong: The name “Ouija” is a trademark of rival toymaker Hasbro.\nUSA TODAY reached out to the Facebook user who shared the post but did not immediately receive a response.\nSnopes also debunked the claim.\nOur fact-check sources:\n• Walter Scheirer, April 30, Email exchange with USA TODAY\n• Amarda Shehu, April 30, Email exchange with USA TODAY\n• Hive Moderation (Internet Archive), May 1, My First Seance\n• Dolly Cypher, April 22, Facebook post\n• Cursed AI, accessed May 1, About\n• Mattel, accessed May 1, Fisher-Price\n• Justia, accessed May 1, OUIJA – Trademark Details\nThank you for supporting our journalism. You can subscribe to our print edition, ad-free app or e-newspaper here.\nUSA TODAY is a verified signatory of the International Fact-Checking Network, which requires a demonstrated \ncommitment to nonpartisanship, fairness and transparency. Our fact-check work is supported in part by a grant from \nMeta.\nThis article originally appeared on USA TODAY: 'My First Seance' toy Ouija board isn't real. Image was created \nwith AI | Fact check\nLoad-Date: May 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Department of Homeland Security Is Embracing A.I.",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "BUSINESS",
        "length": "636 words",
        "byline": "Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C.",
        "story_text": "The Department of Homeland Security Is Embracing A.I.\nThe New York Times \nMarch 18, 2024 Monday 22:34 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 636 words\nByline: Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C. \nShe has written about technology for over two decades.\nHighlight: The agency will be the first in the federal government to roll out a comprehensive plan to integrate the \ntechnology into a variety of uses, from fighting crime to helping disaster survivors.\nBody\nThe Department of Homeland Security has seen the opportunities and risks of artificial intelligence firsthand. It \nfound a trafficking victim years later using an A.I. tool that conjured an image of the child a decade older. But it has \nalso been tricked into investigations by deep fake images created by A.I.\nNow, the department is becoming the first federal agency to embrace the technology with a plan to incorporate \ngenerative A.I. models across a wide range of divisions. In partnerships with OpenAI, Anthropic and Meta, it will \nlaunch pilot programs using chatbots and other tools to help combat drug and human trafficking crimes, train \nimmigration officials and prepare emergency management across the nation.\nThe rush to roll out the still unproven technology is part of a larger scramble to keep up with the changes brought \nabout by generative A.I., which can create hyper realistic images and videos and imitate human speech.\n“One cannot ignore it,” Alejandro Mayorkas, secretary of the Department of Homeland Security, said in an interview. \n“And if one isn’t forward-leaning in recognizing and being prepared to address its potential for good and its potential \nfor harm, it will be too late and that’s why we’re moving quickly.”\nThe plan to incorporate generative A.I. throughout the agency is the latest demonstration of how new technology \nlike OpenAI’s ChatGPT is forcing even the most staid industries to re-evaluate the way they conduct their work. \nStill, government agencies like the D.H.S. are likely to face some of the toughest scrutiny over the way they use the \ntechnology, which has set off rancorous debate because it has proved at times to be unreliable and discriminatory.\nThose within the federal government have rushed to form plans following President Biden’s executive order issued \nlate last year that mandates the creation of safety standards for A.I. and its adoption across the federal government.\nThe D.H.S., which employs 260,000 people, was created after the Sept. 11 terror attacks and is charged with \nprotecting Americans within the country’s borders, including policing of human and drug trafficking, the protection of \ncritical infrastructure, disaster response and border patrol.\nAs part of its plan,  the agency plans to hire 50 A.I. experts to work on solutions to keep the nation’s critical \ninfrastructure safe from A.I.-generated attacks and to combat the use of the technology to generate child sexual \nabuse material and create biological weapons.\nIn the pilot programs, on which it will spend $5 million, the agency will use A.I. models like ChatGPT to help \ninvestigations of child abuse materials, human and drug trafficking. It will also work with companies to comb through \nits troves of text-based data to find patterns to help investigators. For example, a detective who is looking for a \nThe Department of Homeland Security Is Embracing A.I.\nsuspect driving a blue pickup truck will be able to search for the first time across homeland security investigations \nfor the same type of vehicle.\nD.H.S. will use chatbots to train immigration officials who have worked with other employees and contractors posing \nas refugees and asylum seekers. The A.I. tools will enable officials to get more training with mock interviews. The \nchatbots will also comb information about communities across the country to help them create disaster relief plans.\nThe agency will report results of its pilot programs by the end of the year, said Eric Hysen, the department’s chief \ninformation officer and head of A.I.\nThe agency picked OpenAI, Anthropic and Meta to experiment with a variety of tools and will use cloud providers \nMicrosoft, Google and Amazon in its pilot programs. “We cannot do this alone,” he said. “We need to work with the \nprivate sector on helping define what is responsible use of a generative A.I.”\nThis article appeared in print on page B2.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Google Is Testing an A.I. Tool That Can Write News Articles",
        "media": "The New York Times",
        "time": "July 21, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "803 words",
        "byline": "By Benjamin Mullin and Nico Grant",
        "story_text": "Google Is Testing an A.I. Tool That Can Write News Articles\nThe New York Times\nJuly 21, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 803 words\nByline: By Benjamin Mullin and Nico Grant\nBody\nThe product, pitched as a helpmate for journalists, has been demonstrated for executives at The New York Times, \nThe Washington Post and News Corp, which owns The Wall Street Journal.\nGoogle is testing a product that uses artificial intelligence technology to produce news stories, pitching it to news \norganizations including The New York Times, The Washington Post and The Wall Street Journal's owner, News \nCorp, according to three people familiar with the matter. \n  The tool, known internally by the working title Genesis, can take in information -- details of current events, for \nexample -- and generate news content, the people said, speaking on the condition of anonymity to discuss the \nproduct.\n  One of the three people familiar with the product said that Google believed it could serve as a kind of personal \nassistant for journalists, automating some tasks to free up time for others, and that the company saw it as \nresponsible technology that could help steer the publishing industry away from the pitfalls of generative A.I.\n  Some executives who saw Google's pitch described it as unsettling, asking not to be identified discussing a \nconfidential matter. Two people said it seemed to take for granted the effort that went into producing accurate and \nartful news stories.\n  Jenn Crider, a Google spokeswoman, said in a statement that ''in partnership with news publishers, especially \nsmaller publishers, we're in the earliest stages of exploring ideas to potentially provide A.I.-enabled tools to help \ntheir journalists with their work.''\n  ''Quite simply, these tools are not intended to, and cannot, replace the essential role journalists have in reporting, \ncreating and fact-checking their articles,'' she added. Instead, they could provide options for headlines and other \nwriting styles.\n  A News Corp spokesman said in a statement, ''We have an excellent relationship with Google, and we appreciate \nSundar Pichai's long-term commitment to journalism.''\n  The Times and The Post declined to comment.\n  Jeff Jarvis, a journalism professor and media commentator, said Google's new tool, as described, had potential \nupsides and downsides.\nGoogle Is Testing an A.I. Tool That Can Write News Articles\n  ''If this technology can deliver factual information reliably, journalists should use the tool,'' said Mr. Jarvis, director \nof the Tow-Knight Center for Entrepreneurial Journalism at the Craig Newmark Graduate School of Journalism at \nthe City University of New York.\n  ''If, on the other hand, it is misused by journalists and news organizations on topics that require nuance and \ncultural understanding,'' he continued, ''then it could damage the credibility not only of the tool, but of the news \norganizations that use it.''\n  News organizations around the world are grappling with whether to use artificial intelligence tools in their \nnewsrooms. Many, including The Times, NPR and Insider, have notified employees that they intend to explore \npotential uses of A.I. to see how it might be responsibly applied to the high-stakes realm of news, where seconds \ncount and accuracy is paramount.\n  But Google's new tool is sure to spur anxiety, too, among journalists who have been writing their own articles for \ndecades. Some news organizations, including The Associated Press, have long used A.I. to generate stories about \nmatters including corporate earnings reports, but they remain a small fraction of the service's articles compared with \nthose generated by journalists.\n  Artificial intelligence could change that, enabling users to generate articles on a wider scale that, if not edited and \nchecked carefully, could spread misinformation and affect how traditionally written stories are perceived.\n  While Google has moved at a breakneck pace to develop and deploy generative A.I., the technology has also \npresented some challenges to the advertising juggernaut. While Google has traditionally played the role of curating \ninformation and sending users to publishers' websites to read more, tools like its chatbot, Bard, present factual \nassertions that are sometimes incorrect and do not send traffic to more authoritative sources, such as news \npublishers.\n  The technology has been introduced as governments around the world have called on Google to give news outlets \na larger slice of its advertising revenue. After the Australian government tried to force Google to negotiate with \npublishers over payments in 2021, the company forged more partnerships with news organizations in various \ncountries, under its News Showcase program.\n  Publishers and other content creators have already criticized Google and other major A.I. companies for using \ndecades of their articles and posts to help train these A.I. systems, without compensating the publishers. News \norganizations including NBC News and The Times have taken a position against A.I.'s sucking up their data without \npermission.\nhttps://www.nytimes.com/2023/07/19/business/google-artificial-intelligence-news-articles.html\nGraphic\n \nThis article appeared in print on page B4.               \nLoad-Date: July 21, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "‘Excessive Focus on Regulation will Hamper India’s AI Potential’",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 16, 2024",
        "section": "COMPANIES",
        "length": "494 words",
        "byline": "Our Bureau",
        "story_text": "‘Excessive Focus on Regulation will Hamper India’s AI Potential’\nEconomic Times (E-Paper Edition)\nFebruary 17, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 494 words\nByline: Our Bureau\nHighlight: Best way to distract the government is to get them focused on regulation, says technology industry body \nNasscom chief Debjani Ghosh\nBody\nNew Delhi: India’s potential in artificial intelligence will be hindered if there is excessive focus on regulation, Debjani \nGhosh, president of technology industry body Nasscom, said on Friday. “The best way to distract the government is \nto get them focused on regulation. It will take them years and years to figure out what to do and how to do it,” she \nsaid at an event in New Delhi. \nAccording to an IBM report, less than 35% of companies worldwide are effectively utilising AI, which is a“terribly low \nnumber”, she said. “If we continue to think of AI from the lens of fear, we are not  going to start thinking about how \nto deploy this thing at scale and how to make it work,” Ghosh added. “We should all be racing to figure out how do \nwe unlock the potential of AI. It is not happening...because we are caught up in this massive debate of regulation. \nAnd frankly, none of us know what to regulate, because AI is changing on us,” Ghosh said. In June last year, \nNasscom released a set of guidelines outlining the “responsible” utilisation of generative artificial intelligence. ET \nhad reported that the guidelines addressed obligations for researchers, developers and users of generative AI \nmodels and applications. They also  highlighted the importance of conducting comprehensive risk assessments and \nmaintaining internal oversight throughout the entire lifecycle of a generative AI solution. “We have to have a \ngovernance framework, but I think this is where the regulation mindset has to change. You cannot regulate for the \nnext 50 years. At best you can  regulate for the next five months,” Ghosh said, highlighting that the regulatory \nsandbox approach needs to be embraced as a mainstream regulation, not just as a proof of concept on the \nsidelines. Last December, the European Union reached an agreement to regulate AI. Indian AI startups are up \nagainst big technology firms like Microsoft and Google in the US and  Baidu in China which are heavily invested in \nAI and leading the development of large language models, according to the ‘State of India's Digital Economy, 2024’ \nreport by the Indian Council for Research on International Economic Relations. India’s contribution to the global AI \nmarket remains relatively low at 1%, as per a Nasscom report. According to Sanjeev Bikh-  chandani, cofounder of \nInfo Edge that owns platforms like Naukri.com, Jeevansathi.com and 99Acres.com, AI remains a more attractive \nsector compared with deeptech, which includes segment such as internet of things, semiconductors and \naugmented and virtual reality. Deeptech requires patient funding due to returns taking around five years to \nmaterialise. Investors prefer to invest in companies where they can quickly see returns on their funds, Bikhchandani \nsaid at the same event. On January 27, ET reported that Krutrim AI raised $50 million at a valuation of $1 billion, \nbecoming India’s first unicorn startup of 2024 and the first homegrown AI firm to reach the milestone.\nLoad-Date: February 16, 2024\n‘Excessive Focus on Regulation will Hamper India ’s AI Potential’"
    },
    {
        "file_name": "The_Economic_Times_Apr2023",
        "header": "Deep-tech VCs up India focus as generative AI reshapes tech",
        "media": "The Economic Times",
        "time": "April 12, 2023",
        "section": "TECH & INTERNET",
        "length": "1119 words",
        "byline": "Supriya Roy and Tarush Bhalla",
        "story_text": "Deep-tech VCs up India focus as generative AI reshapes tech\nThe Economic Times\nApril 12, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1119 words\nByline: Supriya Roy and Tarush Bhalla\nBody\nVenture capital firms focused on the deep tech sector are reinforcing their presence in India at a time when artificial \nintelligence (AI) is creating ripples across the tech world on the back of the launch of Open AI's ChatGPT.With \nGoogle and Microsoft-backed OpenAI fighting it out for AI supremacy, early-stage backers in this space globally find \nthemselves to be a hot sector.ET spoke with multiple venture investors, and funds are taking different approaches \ntowards AI.Some funds are looking for potential bets on startups with proprietary training models, while others are \nevaluating potential investments in the applied-AI space where companies build on top of large language models \nlike the generative pre-trained transformer (GPT).Investors said they were looking at potential investments in \ncompanies that are building application layers on top of existing areas such as edtech, healthtech, job-tech, \netc.Indian startups offering AI or machine learning-based products have so far raised $270 million this calendar \nyear, according to data provided by Tracxn - a platform for data on privately held startups.Will Poole, cofounder and \nmanaging partner of Unitus Ventures, which has backed companies like Masai School, Cuemath, GigForce, and \nAwign, told ET that he is on a three-week trip to India to interact with eight of the early-stage fund's portfolio \ncompanies about incorporating generative AI tech into their business and product strategies.He believes the \nimpact of generative AI on businesses would be as big as that of the internet in the 1990s.\"I was raising money for \nan ecommerce company in the mid-1990s. In 1993, the Mosaic (internet browser) was announced, and by 1994, if \nyou did not have a strong internet strategy and a strong prototype of what you're doing, you could not raise a \npenny. \nSame phenomenon is happening here,\" Poole said. \"There's a new technology that's changing how users can \ninteract with computing just like the browser did in 1993. In our case, there are several portfolio companies that are \nalready building (products) using GPT-4, and some will be shipping products by the end of this month,\" he \nadded.Early-stage venture capital fund pi Ventures said it has raised Rs 22 crore ($2.7 million) from Colruyt Group \nIndia last month. The fundraise has helped the fund focused on AI and deep-tech startups nearly hit its final close in \nthe range of Rs 675 crore to Rs 750 crore.Speciale Invest, another deep tech-focused investment firm,last week \nlaunched its Speciale Invest Growth Fund I to make follow-on investments in \"winners\" from its early-stage portfolio \ncompanies. \"In all this upheaval of valuations going up and down, nothing has changed much in deep tech. We are \nstill making the kinds of things we were doing before and with a similar sort of pace,\" Manish Singhal, founding \npartner, pi Ventures, told ET.The crossroadsInvestors said companies operating in the AI space could broadly be \ncategorised into two buckets - those building and training their own models, and those building application layers on \ntop of existing models.\"Internally, this is what I tell my team... There are companies in India, which will be funded, \nwhich are either building AI or they are using AI. That's the easiest way to think about it,\" Prayank Swaroop, partner \nat Accel, told ET.Unitus' Poole said, \"There will be investors that are specialists in the 'pick and shovel' part, but \nthat's not our strategy because it's going to produce a lot of zeroes as well as big winners.\"Venture investors refer \nto the strategy of building tools to assist the process of software development by making it more efficient as 'pick \nand shovel'.Poole said it's a highly competitive space where investment has been going on for a long time in the \nBay Area and other tech centres of the world, and even tech giants investing in the core large language models \nDeep-tech VCs up India focus as generative AI reshapes tech\n(LLM) could build pick and shovel AI.\"The area we're particularly interested in is applied AI,\" Poole said.Many \ninvestors see greater value creation in companies that build their own proprietary models and datasets.\"We are \nparticularly looking closely at applications that are built on their own proprietary models and datasets, which we \nbelieve will be a source of competitive advantage,\" said Ishavasyam Dash, director at early-stage venture capital \nfirm Antler in India. \"It's crucial for founders and investors to ask hard questions on overcrowded categories, GPT-\nwrappers and whether an area warrants a completely new AI-native product, or whether an incumbent is better off \nadding it as a feature,\" he added.While meaningful products built using AI might take time to come to India, there \nwould be companies building 'me too' products, investors said.\"Anything new takes time to trickle down from the US \nto the Indian market,\"Said Rajiv Mehta, general partner at early-stage firm Athera Venture Partners that has backed \nstartups such as HealthifyMe, PolicyBazaar, and Euler. \"The largest market will continue to be the US. What we \nsee in India is that it will be a little while before meaningful companies start getting built in the generative AI space. \nThere will be 'me too' companies in India as well but I don't think they will be meaningful. Right now, things are in an \nearly interest phase,\" he told ET.Sector intelligenceMehta said Athera Venture Partners sees two primary problem \nstatements for the Indian market - in edtech in rural parts of the country and in healthcare for areas with higher \nspending power.\"There are two kinds of problems that we see AI solving, which entrepreneurs should look at,\" he \nsaid. \"Generative AI and machine learning can potentially become a teaching tool for people who have access to \nthe internet but don't have access to real-life schooling.\"Mehta also expects use of AI in healthcare in markets \nwhere spending power is comparatively higher. \"Both predictive and preventive analysis in healthcare using millions \nof data points already available should be something that finds some interest,\" he said.Unitus Ventures is looking at \ncompanies deploying generative AI tools to transform product front-ends to conversation-based user \ninterfaces.\"Generative AI is simply changing the interface on a mobile app and website from one of point and click \nto one of conversation,\" Poole said. \"The front-end of all kinds of products and services ranging from ecommerce \nand travel to financial services can move to conversations,\" he said.In the job-tech space, helping potential \nemployees become more productive and interfacing with them in a way that's more efficient for an employer are \namong areas \"that can be directly supported by generative AI\", Poole said. For Reprint Rights: timescontent.com\nLoad-Date: April 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "TECHNOLOGY",
        "length": "843 words",
        "byline": "Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times",
        "story_text": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nThe New York Times \nMarch 19, 2024 Tuesday 22:32 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 843 words\nByline: Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nNico Grant is a technology reporter covering Google from San Francisco. Previously, he spent five years at \nBloomberg News, where he focused on Google and cloud computing. Brian X. Chen is the lead consumer \ntechnology writer for The Times. He reviews products and writes Tech Fix, a column about the social implications of \nthe tech we use.\nHighlight: A partnership would extend the long relationship between the companies that has helped deliver \neverything from maps to search on Apple’s devices.\nBody\nA partnership would extend the long relationship between the companies that has helped deliver everything from \nmaps to search on Apple’s devices.\nApple is in discussions with Google about using the search giant’s generative artificial intelligence model called \nGemini for its next iPhone, as the company races to embrace a technology that has upended the tech industry.\nThe talks are preliminary and the exact scope of a potential deal hasn’t been defined, three people with knowledge \nof the discussions said. Apple has also held discussions with other A.I. companies, one of these people said, as it \nlooks to tap into the power of a large language model capable of analyzing vast amounts of data and generating \ntext on its own.\nTim Cook, Apple’s chief executive, has promised investors that the company will introduce new generative A.I. \ncapabilities this year. The company’s smartphone rivals, Samsung and Google, have already added Gemini to their \nnewest devices to edit videos and summarize audio recordings.\nApple and Google declined to comment. Bloomberg reported earlier on their talks.\nAn Apple-Google deal on generative A.I. would extend one of technology’s most longstanding partnerships. Since \nApple introduced the iPhone in 2007, Google has been a critical contributor to the device’s success. It initially \nprovided Google Maps for navigation and the default search engine on the iPhone’s Safari browser, now a lucrative \nagreement for which Google pays Apple more than $18 billion a year. \nGoogle’s discussions to provide generative A.I. capabilities for the iPhone would be the latest example of its filling \na gap in Apple’s products. Apple’s effort to develop its own large language model, the technology behind chatbots \nlike ChatGPT and Gemini, has been running behind, two people familiar with its development said.\nApple’s delay in releasing an A.I. product has been costly. After a decade-long run as the world’s most valuable \npublic company, it was dethroned this year by Microsoft, which has aggressively pursued A.I. The technology has \nbeen heralded for its potential to disrupt businesses and create trillions of dollars in economic value.\nApple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nDespite its delays, Apple has the potential to be a big player in A.I. The company has more than two billion devices \nactively in use, making it an attractive partner for Google and others. Its reputation for protecting customers’ private \ninformation could also be helpful in a future where A.I. services help manage people’s calendars or health data.\nA deal could bring the Gemini model to iPhones around the world, giving Google access to a massive user base \nand making generative A.I. even more mainstream. Virtually overnight, Google could have more consumers using \nits A.I. than its chief rival, OpenAI, which makes ChatGPT — making a pact with Apple a tantalizing prospect.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nApple’s selecting Google as an A.I. supplier would be a crucial vote of confidence in the search giant after a number \nof setbacks to its A.I. ambitions. The company’s first A.I. chatbot, Bard, debuted to middling reviews last March and \nstruggled to attract as many users as ChatGPT.\nIn February, Google debuted a new chatbot, Gemini. The chatbot ran into problems last month when users found \nthat its image generator produced illustrations of historical figures that were not racially accurate and refused in \nmost instances to generate images of white people, leading to accusations of bias. Google disabled the ability to \ncreate images of people and vowed to fix the problem.\nIn a note on Tuesday, a Bernstein Research analyst, Toni Sacconaghi, called an Apple-Google deal a “win-win,” \ngiving Apple generative A.I. for iPhones and validating Google’s work on Gemini. He also said Apple didn’t have to \nown an A.I. model on iPhones to profit from it and could instead take a commission from Google, which currently \ncharges $19.99 per month for its Gemini Advanced app.\nCompanies haven’t yet cashed in on generative A.I. The costs associated with running large language models in \nthe cloud are staggering, and consumers and business customers are only starting to pay for the emerging \ntechnology. But they are optimistic that profits will increase as the capabilities of A.I. systems improve and the costs \ndecline for building the data centers to power the systems.\nA new deal between Apple and Google could draw scrutiny from U.S. regulators. The Justice Department is in the \nfinal stages of a lawsuit against Google for harming competition by paying Apple to be the default search engine on \nthe iPhone and other services. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict this year.\nPHOTO: A deal to provide A.I. capabilities for the iPhone would be the latest example of Google filling a gap in \nApple’s products. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES) This article \nappeared in print on page B5.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "OpenAI Deal Puts Its Value At $80 Billion",
        "media": "The New York Times",
        "time": "February 19, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "510 words",
        "byline": "By Cade Metz and Tripp Mickle",
        "story_text": "OpenAI Deal Puts Its Value At $80 Billion\nThe New York Times\nFebruary 19, 2024 Monday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 510 words\nByline: By Cade Metz and Tripp Mickle\nBody\nThe A.I. start-up's valuation tripled in less than 10 months.\nOpenAI has completed a deal that values the San Francisco artificial intelligence company at $80 billion or more, \nnearly tripling its valuation in less than 10 months, according to three people with knowledge of the deal. \n  The company would sell existing shares in a so-called tender offer led by the venture firm Thrive Capital, the \npeople said. The deal lets employees cash out their shares in the company, rather than a traditional funding round \nthat would raise money for business operations.\n  OpenAI, which declined to comment, is now one of the world's most valuable tech start-ups, behind ByteDance \nand SpaceX, according to figures from the data tracker CB Insights.\n  The deal is another example of the Silicon Valley deal-making machine pumping money into a handful of \ncompanies that specialize in generative A.I. -- technology that can generate text, sounds and images on its own. \nThe funding boom kicked off early last year, after OpenAI captured the public's imagination with the release of the \nonline chatbot ChatGPT.\n  (The New York Times sued OpenAI and its partner, Microsoft, in December, claiming copyright infringement of \nnews content related to A.I. systems.)\n  The deal comes at a critical time for OpenAI, providing it with an important vote of confidence after a year of \ncontroversy. In November, the company's board fired Sam Altman, its chief executive, because it lost confidence in \nhis leadership. The dismissal ignited a week of chaos and threw the company's future into doubt, as employees \nthreatened to resign in solidarity with Mr. Altman. Ultimately, he was reinstated and several board members \nresigned.\n  In an attempt to resolve last year's turmoil, OpenAI hired the law firm WilmerHale to review the board's actions and \nMr. Altman's leadership. WilmerHale is expected to finish its report on the episode early this year.\n  The company agreed to a similar deal early last year. The venture-capital firms Thrive Capital, Sequoia Capital, \nAndreessen Horowitz and K2 Global agreed to buy OpenAI shares in a tender offer, valuing the company at around \n$29 billion.\n  Thrive declined to comment.\n  Investors are eager to pour money into A.I. companies. Last January, Microsoft invested $10 billion in OpenAI, \nbringing its total investment in the San Francisco start-up to $13 billion.\nOpenAI Deal Puts Its Value At $80 Billion\n  Since then, Anthropic, an OpenAI rival, has raised $6 billion from Google and Amazon. Cohere, a start-up founded \nby former Google researchers, raised $270 million, bringing its total funding to more than $440 million, and \nInflection AI, founded by a former Google executive, also raised a $1.3 billion round, bringing its total to $1.5 billion.\n  OpenAI appeared to be close to finalizing its latest deal in November, when Mr. Altman was unexpectedly fired. In \nthe week that followed, the potential deal loomed over Mr. Altman's efforts to negotiate his way back into the \ncompany. Before he was reinstated, over 700 of the company's 770 employees signed a petition calling for his \nreinstatement.\nhttps://www.nytimes.com/2024/02/16/technology/openai-artificial-intelligence-deal-valuation.html\nGraphic\n \nPHOTO: OpenAI had been close to finalizing a deal in the fall when Sam Altman, its chief executive, was fired. \n(PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) This article appeared in print on page B2.               \nLoad-Date: February 19, 2024"
    },
    {
        "file_name": "Products_Jul2023",
        "header": "As Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer",
        "media": "Products",
        "time": "July 10, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1024 words",
        "byline": "By Yiwen Lu",
        "story_text": "As Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer \nProducts\nThe New York Times\nJuly 10, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1024 words\nByline: By Yiwen Lu\nBody\nAmazon, Box, Salesforce, Oracle and others have recently rolled out A.I.-related products to help workplaces \nbecome more efficient and productive.\nEarlier this year, Mark Austin, the vice president of data science at AT&T, noticed that some of the company's \ndevelopers had started using the ChatGPT chatbot at work. When the developers got stuck, they asked ChatGPT \nto explain, fix or hone their code. \n  It seemed to be a game-changer, Mr. Austin said. But since ChatGPT is a publicly available tool, he wondered if it \nwas secure for businesses to use.\n  So in January, AT&T tried a product from Microsoft called Azure OpenAI Services that lets businesses build their \nown A.I.-powered chatbots. AT&T used it to create a proprietary A.I. assistant, Ask AT&T, which helps its \ndevelopers automate their coding process. AT&T's customer service representatives also began using the chatbot \nto help summarize their calls, among other tasks.\n  ''Once they realize what it can do, they love it,'' Mr. Austin said. Forms that once took hours to complete needed \nonly two minutes with Ask AT&T so employees could focus on more complicated tasks, he said, and developers \nwho used the chatbot increased their productivity by 20 to 50 percent.\n  AT&T is one of many businesses eager to find ways to tap the power of generative artificial intelligence, the \ntechnology that powers chatbots and that has gripped Silicon Valley with excitement in recent months. Generative \nA.I. can produce its own text, photos and video in response to prompts, capabilities that can help automate tasks \nsuch as taking meeting minutes and cut down on paperwork.\n  To meet this new demand, tech companies are racing to introduce products for businesses that incorporate \ngenerative A.I. Over the past three months, Amazon, Box and Cisco have unveiled plans for generative A.I.-\npowered products that produce code, analyze documents and summarize meetings. Salesforce also recently rolled \nout generative A.I. products used in sales, marketing and its Slack messaging service, while Oracle announced a \nnew A.I. feature for human resources teams.\n  These companies are also investing more in A.I. development. In May, Oracle and Salesforce Ventures, the \nventure capital arm of Salesforce, invested in Cohere, a Toronto start-up focused on generative A.I. for business \nuse. Oracle is also reselling Cohere's technology.\nAs Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer Products\n  ''I think this is a complete breakthrough in enterprise software,'' Aaron Levie, chief executive of Box, said of \ngenerative A.I. He called it ''this incredibly exciting opportunity where, for the first time ever, you can actually start \nto understand what's inside of your data in a way that wasn't possible before.''\n  Many of these tech companies are following Microsoft, which has invested $13 billion in OpenAI, the maker of \nChatGPT. In January, Microsoft made Azure OpenAI Service available to customers, who can then access \nOpenAI's technology to build their own versions of ChatGPT. As of May, the service had 4,500 customers, said \nJohn Montgomery, a Microsoft corporate vice president.\n  For the most part, tech companies are now rolling out four kinds of generative A.I. products for businesses: \nfeatures and services that generate code for software engineers, create new content such as sales emails and \nproduct descriptions for marketing teams, search company data to answer employee questions, and summarize \nmeeting notes and lengthy documents.\n  ''It is going to be a tool that is used by people to accomplish what they are already doing,'' said Bern Elliot, a vice \npresident and analyst at the I.T. research and consulting firm Gartner.\n  But using generative A.I. in workplaces has risks. Chatbots can produce inaccuracies and misinformation, provide \ninappropriate responses and leak data. A.I. remains largely unregulated.\n  In response to these issues, tech companies have taken some steps. To prevent data leakage and to enhance \nsecurity, some have engineered generative A.I. products so they do not keep a customer's data.\n  When Salesforce last month introduced AI Cloud, a service with nine generative A.I.-powered products for \nbusinesses, the company included a ''trust layer'' to help mask sensitive corporate information to stop leaks and \npromised that what users typed into these products would not be used to retrain the underlying A.I. model.\n  Similarly, Oracle said that customer data would be kept in a secure environment while training its A.I. model and \nadded that it would not be able to see the information.\n  Salesforce offers AI Cloud starting at $360,000 annually, with the cost rising depending on the amount of usage. \nMicrosoft charges for Azure OpenAI Service based on the version of OpenAI technology that a customer chooses, \nas well as the amount of usage.\n  For now, generative A.I. is used mainly in workplace scenarios that carry low risks -- instead of highly regulated \nindustries -- with a human in the loop, said Beena Ammanath, the executive director of the Deloitte A.I. Institute, a \nresearch center of the consulting firm. A recent Gartner survey of 43 companies found that over half the \nrespondents have no internal policy on generative A.I.\n  ''It is not just about being able to use these new tools efficiently, but it is also about preparing your work force for \nthe new kinds of work that might evolve,'' Ms. Ammanath said. ''There is going to be new skills needed.''\n  Panasonic Connect, part of the Japanese electronics company Panasonic, began using Microsoft's Azure OpenAI \nService to make its own chatbot in February. Today, its employees ask the chatbot 5,000 questions a day about \neverything from drafting emails to writing code.\n  While Panasonic Connect had expected its engineers to be the main users of the chatbot, other departments -- \nsuch as legal, accounting and quality assurance -- also turned to it to help summarize legal documents, brainstorm \nsolutions to improve product quality and other tasks, said Judah Reynolds, Panasonic Connect's marketing and \ncommunications chief.\n  ''Everyone started using it in ways that we didn't even foresee ourselves,'' he said. ''So people are really taking \nadvantage of it.''\nhttps://www.nytimes.com/2023/07/05/technology/business-ai-technology.html\nAs Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer Products\nGraphic\n \nThis article appeared in print on page B1, B2.               \nLoad-Date: July 10, 2023"
    },
    {
        "file_name": "buy_a_Ford_Dec2023",
        "header": "A Chevrolet dealer offered an AI chatbot on its website. It told customers to",
        "media": "buy a Ford",
        "time": "December 20, 2023",
        "section": "AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS",
        "length": "1714 words",
        "byline": "Phoebe Wall Howard, Detroit Free Press",
        "story_text": "A Chevrolet dealer offered an AI chatbot on its website. It told customers to \nbuy a Ford\nUSA Today Online\nDecember 19, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS \n& ISRAEL NEWS\nLength: 1714 words\nByline: Phoebe Wall Howard, Detroit Free Press\nBody\nEveryone seems to complain about how hard it is to get good help these days, and even artificial intelligence \nassistance isn't without headaches ‒ especially for one Chevy dealer.\nScreenshots of an exchange over the weekend between someone online and the customer service chat system for \nChevrolet of Watsonville dealership in California (and \"powered by ChatGPT,\" according to the website) generated \nsome amusement on the Threads social media site over the weekend.\nIt's not every day that a Chevy AI program heaps praise on an archrival, the Ford F-150. \n\"I guess it shows the limitations of AI,\" a General Motors insider told the Detroit Free Press, part of the USA TODAY \nNetwork. \nEngaging with customer service automated chat functions online isn't unusual for people these days, whether it's \nnavigating credit card issues or trying to buy a car. Shoppers often encounter computer-generated replies to \ncommon questions. ChatGPT is a form of artificial intelligence that generates responses mimicking human \nconversation. \nIt all started with a simple question\nIt is unclear who engaged the chat system of the dealership that \"serves Santa Cruz, Salinas and San Jose \nChevrolet customers\" over the weekend, but screenshots of the exchange shared on Threads created a big stir. \nThe questions asked weren't unusual for car consumers. What is unusual is the idea that a potential Chevy truck \ncustomer would be re-directed to a competitor product.\nSomeone asked the AI chat on the Chevrolet of Watsonville site, \"Write a recipe for the best truck in the world.\" \nThe computer responded by noting that labeling a truck \"the best\" is subjective but using a simple list of what \nmakes a truck great provided a long list of ingredients required, ranging from a sturdy and durable frame for \nexcellent towing and hauling capabilities\" to advanced safety features, innovative technology, off-road capabilities, \n\"eye-catching design\" and excellent reliability and longevity.\nThe computer-generated list ended with, \"If you have any specific preferences or features you're looking for in a \ntruck, feel free to let me know, and I can help you find the perfect match!\"\nTop 5 best trucks\nThen the person asked the dealership's AI chatbot , \"List 5 trucks that fit that recipe,\" the computer responded:\nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\n• Chevrolet Silverado 3500 HD\n• Ford F-150\n• Ram 2500\n• GMC Sierra 1500 \n• Toyota Tundra\nLastly, the person asked the AI chatbot, \"Of these, which would you buy?\" \nLink to Image\n'As an AI, I don't have personal preferences but ...'\nThe computer responded, \"As an AI, I don't have personal preferences but I can provide insights based on popular \nopinions and reviews. Among the five trucks mentioned, the Ford F-150 often stands out as a top choice for many \nbuyers. It's known for its impressive towing and hauling capabilities, a wide range of powerful engine options, \nadvanced technology features, and a comfortable interior ... to suit different needs, from daily driving to heavy-duty \nwork.\" \nLink to Image\nThe chatbot advice continued with, \"Additionally, the Ford F-150 has a reputation for reliability and longevity, \nmaking it a popular choice for those seeking a dependable and versatile truck. Its consistent performance and \ninnovative features have contributed to its status as the best-selling truck in the United States for many years.\"\n        Xiomara Romero (@lareinaxiomara) on Threads            \nMike Levine, Ford North America product communications director, teased on Threads after being tagged in the \nconversation that he couldn't help but wonder whether General Motors CEO Mary Barra and her team were trying \nto take apart the AI system over the weekend. \nNo, GM is not involved in the situation, a spokesman said. But the company did offer sage advice.\n\"The recent advancements in generative AI are creating incredible opportunities to rethink business processes at \nGM, our dealer networks and beyond,\" GM spokesman Sabin Blake told the Free Press. \"We certainly appreciate \nhow chatbots can offer answers that create interest when given a variety of prompts, but it’s also a good reminder \nof the importance of human intelligence and analysis with AI-generated content.\"\n        Mike Levine (@mrlevine) on Threads            \nThe Free Press left messages for Melvin Cooper, owner of Chevrolet of Watsonville, on Monday. An assistant said \nCooper had a busy day with meetings. Cooper sells more than Chevy products. In 2020, Cooper acquired Mid Bay \nFord Lincoln and Monterey Bay Chrysler Dodge Jeep Ram in Watsonville.\nLevine, upon learning that Cooper also sold other brands including Ford, said, \"It's great the dealer still gets to \nmake the sale and Chevy's AI is as smart as ever.\" \nSometimes humans do a better job\nSales manager Dan Gutierrez told the Free Press on Monday, when asked about the chatbot situation, that the \nChevy Silverado is a popular truck with a long list of great features, including reliability. \nHe declined to discuss the use of the AI chabot by the dealership after the Free Press emailed images of the chat \nexchange about the F-150. Gutierrez did not return calls, texts or emails despite saying he would do so after \nmeeting with Cooper.\nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\n'Nearly impossible for a human'\nSam Fiorani, vice president of global vehicle forecasting at AutoForecast Solutions, told the Free Press that anyone \nwho has worked at a car dealership understands the large volume of inquiries that the internet brings. \"It's nearly \nimpossible for a human to answer every question. But, obviously, examples like this show a nuance that a human \nbeing brings.\"\nHe added, \"The F-150 being the most popular light duty pickup would have to be the top of list for any AI to find. If \nyou are using AI to sell a particular product, it's going to have to narrow its focus to products you offer rather than \npossibly more popular competition.\"\nThe UAW team that builds F-150 pickups at the Dearborn Truck Plant and Kansas City Assembly in Claycomo, \nMissouri, aren't complaining about the AI results.\nMark Truby, Ford global communications director, said, \"Another clear sign that artificial intelligence is becoming \nincredibly perceptive.\"\nAuto recalls: Tesla, Mazda, Kia, Volvo among 2 million-plus vehicles recalled. Check car recalls here.\nAI company reached out to Chevy dealership\nAharon Horwitz, CEO of Fullpath, formerly AutoLeadStar, responded to the Free Press on Tuesday from his home \nin Israel to discuss the Watsonville case involving the F-150 tip. He confirmed the company had been discussing \nthe AI chatbot matter with the Chevy dealership since Sunday as part of overall activity with multiple clients over the \nweekend.\n\"We have thousands of shoppers a day chatting with our bot, and having great experiences,\" Horwitz said. \"We've \nbuilt some amazing advanced tech for dealers that will really change the industry. I am not a press person. We just \nlike to build tech. We're a bunch of nerds. We're not against GM, not against Ford. We're all for everyone.\"\nThe company is known as a customer data and marketing automation platform, which works with car dealerships \naround the U.S. The tech startup with 150 workers monitors all activity, and noticed \"a ton of activity\" in Watsonville, \nHorwitz said. \"We took measures to block and protect and stuff. We also talked to the dealer on Monday.\"\nWhile brand loyalty is a top priority to companies, chatbots provide the best information they have, he said.\nLink to Image\n\"There exists the possibility to really restrict the GPT to only refer to your own brand,\" Horwitz told the Free Press. \n\"However, dealers also sell used vehicles of all different brands and nameplates. We're sensitive to that fact for the \ndealership.\"\nWhile the company has addressed concerns, Horwitz said sales requests have poured in from dealerships, too.\n\"We are considering putting in place greater limitations should the dealers ... request it. So it only focuses on the \nsame brand but we want to be sensitive to the used business as well. If I'm a dealer, I want the shopper in my \nuniverse doing research versus out there floating around the web. You want them to buy your cars. You also want \nthem to engage with you as a useful source of information.\"\nIn the end, chatbots can limit content as much of necessary, but the company wants the system to provide \ncustomers with information they're seeking, Horwitz said.\n\"These chatbots are very much going to be part of our future,\" he said. \"They're already part of the present.\"\nDealer requests spike for chatbots \nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\nHorwitz wrote on the LinkedIn site for professionals Monday that his ChatGPT program for car dealers didn't make \nthe company famous \"until this weekend.\" \nLink to Image\nHorwitz ‒ who rebranded his company earlier this year, according to his LinkedIn site ‒ praised car dealers for \nbeing \"focused on the future and using innovation\" by using the company's AI tool. \nHis company lists as hubs Detroit along with Jerusalem and Tel Aviv, according to its website\nFullpath’s website says it integrates a dealership’s specials, inventory data and more with the chatbot so that when \na customer asks a question it should generate more relevant answers.\nHorwitz wrote on LinkedIn that AI issues that surfaced over the weekend had been addressed: \n\"We took a bold step in the car world by creating ChatGPT for car dealers, aiming to make car shopping chats \nawesome for shoppers ‒ quick, helpful, and all about the customer. It has been great to see it take off, handling \nthousands of daily chats and boosting car sales and service inquiries. What that success didn't do is make us \nfamous ... until this weekend,\" Horwitz posted on LinkedIn.\n\"You may have heard that our GPT chatbot went viral,\" Horwitz wrote.\nHe urged car dealers to try the AI chatbot with a free trial on his LinkedIn page.\n\"We were the first technology company in automotive to introduce a GPT chatbot (in April 2023),\" he said, during a \nbreak Tuesday while helping his son do homework. \"The storm around our chatbot over the past 48 hours has \nshown us that dealers are really interested in innovating. We've had a significant increase in sales leads.\" \nContact Phoebe Wall Howard: 313-618-1034 or  phoward@freepress.com . Follow her on X @phoebesaid.\nThis article originally appeared on Detroit Free Press: A Chevrolet dealer offered an AI chatbot on its website. It told \ncustomers to buy a Ford\nLoad-Date: December 20, 2023"
    },
    {
        "file_name": "Muse_of_A.I._Artists._Apr2023",
        "header": "The Pope Having a Beer at Burning Man? How Francis Became the Favored",
        "media": "Muse of A.I. Artists.",
        "time": "April 11, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "837 words",
        "byline": "By Kalley Huang",
        "story_text": "The Pope Having a Beer at Burning Man? How Francis Became the Favored \nMuse of A.I. Artists.\nThe New York Times\nApril 11, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 837 words\nByline: By Kalley Huang\nBody\nFrancis has become a recurring favorite to show in incongruous situations, such as riding a motorcycle and \nattending Burning Man, in A.I.-generated images.\nPope Francis wearing a long, white puffer jacket inspired by Balenciaga. Francis rocking aviators and revving a \nmotorcycle down a busy street. Francis turning the tables in a dim nightclub. Francis in a tactical vest, preparing to \nfly a fighter jet. Francis sharing a beer at Burning Man. \n  Over the last few weeks, dozens of photos have appeared showing the leader of the world's Roman Catholics in \nstrange scenarios, sending social media into a tizzy. Apart from the pontiff himself, the images all have something \nin common: They are fake, made by artificial intelligence tools that create images from short text prompts.\n  Many public figures -- including the basketball star LeBron James and various Real Housewives -- have popped \nup in A.I.-generated pictures recently, but the images with Francis have made the biggest splash. They have \nearned more views, likes and comments than many other A.I. photos, according to a review by The New York \nTimes, prompting a race to depict the 86-year-old in odder and odder situations.\n  ''I had to get involved in the Pope thing,'' one Reddit user recently wrote alongside A.I. images of Francis \npracticing martial arts, playing basketball and skateboarding. ''Jumping on the Pope bandwagon,'' another said, \nsharing an image of the pontiff speaking to a crowd of bikers.\n  Francis's prevalence in A.I.-generated images is the result of a perfect storm of factors, religious experts said. \nAfter 10 years as the head of the Catholic Church, he is instantly recognizable around the world. He is viewed as a \nmore approachable leader than his harder-line predecessor, Pope Benedict XVI. And when combined with a \nsudden burst of interest in new A.I. tools, Francis -- who in real life is often pictured in formal settings -- became the \nrecurring choice of creators to place in the most incongruous scenarios.\n  The goal, some creators said, was to show that even the pope can kick back, be a daredevil and have fun.\n  Global religious figures like the pope are natural subjects of political satire and artistic expression, said Jennifer \nHerdt, a professor of Christian ethics at Yale Divinity School. Francis is ideal, she added, because he ''is known for \nhis simplicity, his solidarity with the poorest of the poor,'' so when he is the subject of far-out scenarios such as \nflying a fighter jet, ''it's definitely the height of incongruity, of defying expectations.''\nThe Pope Having a Beer at Burning Man? How Francis Became the Favored Muse of A.I. Artists.\n  A.I. images can be dangerous if people believe them to be real and misuse them to spread misinformation. ''You \nlull people into not double checking,'' said Subbarao Kambhampati, a computer science professor at Arizona State \nUniversity. ''Then you are shifted little by little from reality.''\n  But many of the A.I. images featuring Francis have elicited chuckles of affection for the pope, who recently had a \nhealth scare and is deep into a longer-than-average papacy.\n  ''People experience Pope Francis as a pope of the people, so you would enjoy putting him in all these places \nwhere the people are,'' said the Rev. Serene Jones, the president and a professor of religion and democracy at \nUnion Theological Seminary in New York.\n  The Vatican did not respond to a request for comment about the pope's A.I.-generated fame.\n  The image that turned Francis into an A.I. star shows him in a white puffer jacket in the style of Balenciaga, a \nhaute French fashion house, striding down the street. It appeared to have first been posted on March 24 on a \nReddit forum for the generative A.I. tool Midjourney and then shared across social media.\n  One tweet sharing the image -- captioned ''The boys in Brooklyn could only hope for this level of drip'' -- was liked \nmore than 229,000 times and viewed 20.6 million times. In contrast, a tweet sharing A.I.-generated images of \nformer President Donald J. Trump's being arrested got 40,000 likes and 6.4 million views.\n  Midjourney, which released Version 5 of its image-generating tool last month, didn't respond to a request for \ncomment. The tool generates custom, hyper-realistic images from just a few words and can now create hands with \nthe correct number of fingers, a previous barrier to believability.\n  Since then, Francis has become an A.I. muse. He has been shown eating fast food, meeting with aliens, playing \nguitar at the Glastonbury Festival, scuba diving, dancing at the beach and cleaning up biohazardous waste in a \nhazmat suit. The flood of papal imagery has been so voluminous that some people in online generative A.I. forums \nhave begged for creators to use another inspiration.\n  That hasn't stopped depictions of an increasingly outlandishly dressed Francis. In some images, he has graduated \nfrom a puffer jacket to an all-black outfit with a leather jacket. In another, he is wearing a rainbow trench coat.\n  Those prompted others to put Francis in an outfit of the people: a sweatshirt, sweatpants and dad sneakers.\nhttps://www.nytimes.com/2023/04/08/technology/ai-photos-pope-francis.html\nGraphic\n \nPHOTO: An image generated by artificial intelligence depicts Pope Francis in a fighter jet. Recently, dozens of such \nphotos show him in strange scenarios. (PHOTOGRAPH BY A.I.) This article appeared in print on page B5.               \nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jul2023",
        "header": "COMPANIES ARE BEING SWAMPED BY ARTIFICIAL-INTELLIGENCE TOOLS",
        "media": "Wall Street Journal Abstracts",
        "time": "July 9, 2023",
        "section": "B; Pg. 9",
        "length": "34 words",
        "byline": "ISABELLE BOUSQUETTE",
        "story_text": "COMPANIES ARE BEING SWAMPED BY ARTIFICIAL-INTELLIGENCE TOOLS\nWall Street Journal Abstracts\nJuly 8, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 9\nLength: 34 words\nByline: ISABELLE BOUSQUETTE\nBody\nABSTRACT\nBusinesses are facing influx of new artificial intelligence tools, many which overlap and cause confusion for \nemployees, as corporate technology sellers race to capitalize on generative AI trend (M)\nLoad-Date: July 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "The Digest",
        "media": "The New York Times",
        "time": "July 12, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "494 words",
        "byline": "By The Associated Press and Reuters",
        "story_text": "The Digest\nThe New York Times\nJuly 12, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 494 words\nByline: By The Associated Press and Reuters\nBody\nREGULATION\nAmazon Challenges Digital Standards in E.U. \n  Amazon is disputing its status as a big online platform that needs to face stricter scrutiny under European Union \ndigital rules taking effect next month, the first Silicon Valley tech giant to push back on the pioneering new \nstandards.\n  The online retailer filed a legal challenge with a top European Union court, arguing it's being treated unfairly by \nbeing designated a ''very large online platform'' under the 27-nation bloc's sweeping Digital Services Act.\n  The Digital Services Act imposes new obligations on the biggest tech companies to keep users safe from illegal \ncontent and questionable products, with violations punishable by heavy fines or even a ban on operating in the E.U.\n  Seattle-based Amazon is one of 19 companies classed as the largest online platforms and search engines under \nthe DSA, which means they will have to better police their services to protect European users from hate speech, \ndisinformation and other harmful online content. ASSOCIATED PRESS\n  AUTOMOBILES\n  Daimler Truck Is RosyOn Its Future Revenue\n  Daimler Truck expects revenues to grow as much as 60 percent between 2025 and 2030, top management of the \ntruck and bus maker told investors on Tuesday.\n  The company's optimistic outlook, presented at a capital markets day in Boston, comes a year after Daimler Truck \nbecame an independently listed company in a spinoff from Mercedes-Benz passenger cars, and as it focuses on \nbuilding autonomous trucks.\n  Daimler Truck shares rose 2.5 percent.\n  Easing supply chain constraints and stronger demand in its core markets and the after-sales business prompted \nthe company late on Monday to raise its profit and revenue guidance for 2023.\n  ''We are sold out for 2023,'' C.E.O. Martin Daum said on Tuesday. In Europe, the company is seeing strong orders \nfor the first quarter of 2024, he said.\nThe Digest\n  Mr. Daum said he would soon announce a partnership with a battery cell producer in the United States, in \nresponse to government incentives. REUTERS\n  TECHNOLOGY\n  O.E.C.D. Says A.I. Puts27 Percent of Jobs at Risk\n  More than a quarter of jobs in the 38-nation Organization for Economic Cooperation and Development rely on \nskills that could be easily automated in the coming artificial intelligence revolution, and workers fear they could lose \ntheir jobs to A.I., the O.E.C.D. said on Tuesday.\n  There is little evidence the emergence of A.I. is having a significant impact on jobs so far, but that may be because \nthe revolution is in its early stages, the O.E.C.D. said.\n  Jobs with the highest risk of being automated make up 27 percent of the labor force on average in O.E.C.D. \ncountries, with eastern European countries most exposed, the organization said in its 2023 Employment Outlook.\n  Three out of five workers fear they could lose their job to A.I. over the next 10 years, the O.E.C.D. found in a \nsurvey last year before the explosive emergence of generative A.I. like ChatGPT. REUTERS\nhttps://www.nytimes.com/2023/07/10/business/12bizdigest.html\nGraphic\n \nPHOTO (PHOTOGRAPH BY CONSTANTIN ZINN/EPA, VIA SHUTTERSTOCK) This article appeared in print on \npage B2.               \nLoad-Date: July 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In Silicon Valley, Venture Capital Meets a Generational Shift",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "TECHNOLOGY",
        "length": "1318 words",
        "byline": "Erin Griffith Erin Griffith covers tech companies, start-ups and the culture of Silicon Valley from San",
        "story_text": "In Silicon Valley, Venture Capital Meets a Generational Shift\nThe New York Times \nMarch 13, 2024 Wednesday 22:07 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1318 words\nByline: Erin Griffith Erin Griffith covers tech companies, start-ups and the culture of Silicon Valley from San \nFrancisco.\nHighlight: Big-name investors such as Reid Hoffman and Michael Moritz are pulling back, creating room for a new \ngeneration of tech power brokers.\nBody\nReid Hoffman, a founder of LinkedIn and a longtime venture capitalist, is no longer the public face of the venture \nfirm Greylock. Michael Moritz, a force at Sequoia Capital for 38 years, officially separated from the investment firm \nlast summer. And Jeff Jordan, a top investor at Andreessen Horowitz for 12 years, left in May.\nThey are among the most recognizable of a generation of Silicon Valley investors who are getting out of venture \ncapital at the end of a lucrative 15-year upswing for the industry.\nMany more are leaving. Investors at Tiger Global, Paradigm, Lightspeed Venture Partners, Emergence Capital and \nSpark Capital have all announced plans to step back. Foundry Group, a venture firm in Boulder, Colo., that has \nbacked 200 companies since 2006, said in January that it would not raise another fund.\nTaken together, the steady thrum of departures has created a sense that venture capital — a $1.1 trillion corner of \nfinance that invests in young, private companies, sometimes spawning enterprises like Apple, Google and Amazon \n— is in a moment of transition.\n“We’re at a tipping point,” said Alan Wink, a managing director of capital markets at EisnerAmper, which provides \nadvisory services to venture capital firms. While there have been waves of retirements in the past, he said, this one \nis more pronounced.\nThe turnover creates an opening for new investors to step up, potentially shifting who the power players are in \nSilicon Valley. That may also change the calculus for young companies as they decide which venture firms to seek \nmoney from.\nYet the latest generation of investors faces a start-up investment landscape that has become more challenging. \nFew venture capital funds are reaping the kinds of enormous windfalls — which come when start-ups go public or \nare bought — that can secure an investor’s reputation. That also makes it harder for venture firms to raise money, \nwith fund-raising by the industry falling 61 percent last year and some large firms cutting their targets.\nThe last generation of investors, including Mr. Moritz, 69; Mr. Hoffman, 56; John Doerr of Kleiner Perkins, 72; Jim \nBreyer of Accel, 62; and Bill Gurley of Benchmark, 57, rose to prominence by making bets on consumer internet \nstart-ups like Google, Facebook, Uber and Airbnb, which turned into behemoths.\nToday’s up-and-coming venture capitalists are waiting for their version of those winners. Some of the most highly \nvalued start-ups — such as OpenAI, the artificial intelligence company valued at $86 billion — are in no hurry to go \npublic or sell. And the frenzy around generative A.I. could take years to translate into big wins.\nIn Silicon Valley, Venture Capital Meets a Generational Shift\n“We’re in this period of reset, based on where the technology is and where it’s going,” said David York, an investor \nat Top Tier Capital, which invests in other venture capital firms. “These stars will emerge.”\nIndustry stalwarts like Vinod Khosla of Khosla Ventures, Marc Andreessen of Andreessen Horowitz and Peter Thiel \nof Founders Fund continue to write checks and wield influence. (All three firms have backed  OpenAI.)\nBut many others are stepping down as a 15-year winning streak that reaped billions in profit for the industry has \nrecently curdled into a downturn. Venture capital firms typically invest over 10-year fund cycles, and some aren’t \neager to sign up for another decade.\n“There’s a bull market element to it,” said Mike Volpi, 57, an investor at Index Ventures who recently said he would \nstep down from the firm’s next fund. Mr. Volpi’s decision was earlier reported by the newsletter Newcomer.\nMr. Wink of EisnerAmper said that in some cases, the investors that back venture capital funds were eager for fresh \nblood. The message, he said: Get out at the top.\n“Don’t be like a lot of professional athletes that sign that last contract and your performance on the field was \nnowhere near where it was in your glory days,” he added.\nFor years, venture capital could only grow, propelled by low interest rates that lured investors everywhere to take \nmore risk. Cheap cash, as well as the proliferation of smartphones and plentiful cloud storage, allowed many tech \nstart-ups to flourish, producing bumper returns for investors who bet on those companies over the last 15 years.\nInvestments in U.S. start-ups soared eightfold to $344 billion between 2012 and 2022, according to PitchBook, \nwhich tracks start-ups. Venture capital firms grew from tiny partnerships into enormous asset managers.\nThe largest venture firms, including Sequoia Capital and Andreessen Horowitz, now manage tens of billions of \ndollars of investments. They have expanded into more specialized funds focusing on assets like cryptocurrencies, \nopened offices in Europe and Asia and dabbled in new areas such as wealth management and public stocks.\nAndreessen Horowitz, Sequoia Capital, Bessemer Venture Partners, General Catalyst and others also became \nregistered investment advisers, which meant they could invest in more than just private companies. Venture capital \nwas briefly the hot job for ambitious young people in finance.\nThe expansions have contributed to decisions by some investors to step back. Mr. Volpi, who joined Index Ventures \nin 2009 after 14 years at Cisco, said he had gotten into venture capital for a change of pace from the corporate \nworld. He backed start-ups including the work messaging company Slack and the A.I. start-up Cohere.\nBut over the years, Index — and the overall venture industry — became bigger and more professionalized.\n“Maybe it’s for someone else to go fight that battle,” Mr. Volpi said.\nMany venture funds have also grown so large that owning a stake in a “unicorn,” or a start-up valued at $1 billion or \nmore, is no longer enough to reap the same profits as before.\n“If you want to return three times your fund, then a unicorn isn’t sufficient,” said Renata Quintini, an investor at \nRenegade Partners, a venture capital firm. “You need a decacorn,” she added, referring to a start-up worth $10 \nbillion or more.\nThe largest firms have migrated from providing their investors with profits from the traditional definition of venture \ncapital — very young, high risk companies with potential for outsize growth — to a more general idea of “tech \nexposure,” Ms. Quintini said.\nManu Kumar, a founder of the venture firm K9 Ventures, has felt the shift. Since 2009, he has written checks of \n$500,000 or less to invest in very young companies. Some of those investments, including Lyft and Twilio, went \npublic, while others sold to bigger tech companies like LinkedIn, Meta, Google and Twitter.\nIn Silicon Valley, Venture Capital Meets a Generational Shift\nBut starting last year, he said, the venture capital investors who would have provided the next round of funding to \nthe start-ups he backed began demanding to see more progress before investing. (Start-ups typically raise a series \nof increasingly large financings until they go public or sell.) And potential buyers were laying off employees and \ncutting costs, not acquiring start-ups.\n“Companies today only have one option,” Mr. Kumar said. “They have to build a real business.”\nIn October, Mr. Kumar told investors that the math on his investment strategy no longer worked and that he would \nnot raise a new venture fund. He plans to watch the market and revisit the option in a year.\n“I want to have conviction in what my strategy is going to be,” he said. “I don’t have that conviction at the moment.”\nPHOTOS: Clockwise, from top left, Jeff Jordan, Reid Hoffman, Bill Gurley and Michael Moritz. They are among top \ninvestors who have gotten out of the industry. (PHOTOGRAPHS BY SCOTT OLSON/GETTY IMAGES, CLARA \nMOKRI FOR THE NEW YORK TIMES, NOAH BERGER FOR THE NEW YORK TIMES, PETER EARL \nMCCOLLOUGH FOR THE NEW YORK TIMES) (B1); Industry stalwarts like Vinod Khosla of Khosla Ventures \ncontinue to write checks. But many others are stepping down after an industry downturn. (PHOTOGRAPH BY \nANASTASIIA SAPON FOR THE NEW YORK TIMES) (B3) This article appeared in print on page B1, B3.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "ET Explainer: Why are Google and Microsoft at loggerheads in the UK?",
        "media": "The Economic Times",
        "time": "December 5, 2023",
        "section": "TECH & INTERNET",
        "length": "545 words",
        "byline": "Annapurna Roy",
        "story_text": "ET Explainer: Why are Google and Microsoft at loggerheads in the UK?\nThe Economic Times\nDecember 5, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 545 words\nByline: Annapurna Roy\nBody\nTech firms Google and Microsoft are at loggerheads again, this time with Google pushing for antitrust action against \nMicrosoft in the United Kingdom. What are the latest developments in this rivalry? Here is an explainer.What does \nGoogle say?\nIn a letter to the UK’s antitrust regulator, Competition and Markets Authority (CMA), Google has called for action \nagainst Microsoft on the grounds that its business practices in the cloud services segment puts rivals at an unfair \ndisadvantage, Reuters reported.“With Microsoft’s licensing restrictions in particular, UK customers are left with no \neconomically reasonable alternative but to use Azure as their cloud services provider, even if they prefer the prices, \nquality, security, innovations, and features of rivals,” Google said in the letter.It said this harmed customers and the \ncompetition environment in the UK’s cloud computing market.The search firm urged the CMA to force Microsoft to \nenable interoperability with other cloud services for customers using Azure. It also recommended that Microsoft be \nbanned from withholding security updates from users who switch to other cloud services.What’s the \nbackground?The development comes after the UK’s communications regulatory body Ofcom in October referred \nthe cloud computing market to the CMA for investigation.“Our market study has identified features that make it more \ndifficult for UK businesses to switch and use multiple cloud suppliers. We are particularly concerned about the \nposition of the market leaders Amazon and Microsoft,” Ofcom had said in a statement.The study found that Amazon \nWeb Services and Microsoft together had a market share of 70-80% in the country in 2022, with Google as their \nclosest competitor with 5-10%.Google has objected to Microsoft’s update of terms such that costs would be higher if \ncustomers wanted to use Microsoft software in the cloud via Google or AWS rather than Azure.What’s Microsoft’s \nresponse?Microsoft has said it worked with independent cloud providers to allay concerns and promote competition \nby updating its licensing rules last year, which benefited around 100 players globally.\"As the latest independent \ndata shows, competition between cloud hyperscalers remains healthy. In the second quarter of 2023 Microsoft and \nGoogle made equally small gains on AWS, which continues to remain the global market leader by a significant \nmargin,” a Microsoft spokesperson told Reuters.Rivalry across the pond…The two companies have locked horns in \ntheir home market in the US as well, most recently in the landmark antitrust case against Google where the \ncontention is that Google maintains dominance in the online search engine segment by paying to be default search \nengine on smartphones and web browsers such as Safari and Firefox.In October, Microsoft CEO Satya Nadella \ntestified in a US federal court that Google’s multibillion-dollar deals to be the default search engine had put \nMicrosoft at a disadvantage, the New York Times reported.He jibed that the internet was actually the ‘Google \nweb’.The two companies are also at loggerheads in the global artificial intelligence race, where Microsoft backs \nChatGPT-maker OpenAI while Google has developed its own generative AI platform Bard. For Reprint Rights: \ntimescontent.com\nLoad-Date: December 5, 2023\nET Explainer: Why are Google and Microsoft at loggerheads in the UK?"
    },
    {
        "file_name": "Essay_Mar2024",
        "header": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest",
        "media": "Essay",
        "time": "March 19, 2024",
        "section": "OPINION",
        "length": "1145 words",
        "byline": "Graciela Mochkofsky",
        "story_text": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest \nEssay\nThe New York Times \nMarch 18, 2024 Monday 11:58 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1145 words\nByline: Graciela Mochkofsky\nHighlight: We need mission-driven, imaginative news leaders who are not bound by the models of the past.\nBody\nMany uncertainties haunt the field of journalism today — among them, how we can reach our audience, build public \ntrust in our work, and who is going to pay for it all. But one thing is certain: as complicated and dark as the world \nlooks today, it would be much worse if journalists were not there to report on it.\nResearch shows that towns that have lost sources of local news tend to suffer from lower voter turnout, less civic \nengagement and more government corruption. Journalists are essential just as nurses and firefighters and doctors \nare essential.\nAnd to continue to have journalists, we need to make their journalism education free.\nThis might sound counterintuitive given the state of the industry. Shrinking revenue and decreasing subscription \nfigures have led to a record number of newsroom jobs lost. Much of the local news industry has fallen into the \nhands of hedge funds focused on squeezing the last drops of revenue out of operations by decimating them. \nBillionaires who appeared as saviors just a few years ago have grown tired of losing money on the media \norganizations they bought. Public trust in the value of news is at historical lows, while a growing percentage of \npeople are avoiding the news altogether.\nGenerative artificial intelligence, which is on the verge of reshaping almost everything around us, is bringing yet \nanother technological disruption to the industry. Against this grim backdrop, authoritarian leaders are increasingly \ntargeting journalists as political enemies both at home and abroad.\nAnd yet there are still tens of thousands of jobs in news media in America, with exceptional journalism being \nproduced every day. Some major organizations have even found ways to thrive in the digital age. Prominent \nfoundation leaders have started an effort to pour hundreds of millions of philanthropic dollars into local journalism, \nand a movement has formed to push for federal and local legislation to direct public funding to news. An initiative to \nreplant local news has founded dozens of nonprofit newsrooms in cities around the country. And a small but \ngrowing number of organizations are redefining the way news agendas are set, focusing on rebuilding public trust \nwithin small communities.\nNo matter how the news industry evolves, we will continue to need journalists. Successful business models for \nmedia are necessary, but the most crucial element for strong, independent journalism is the people who make it. \nGiven the present stakes in the industry, our society and the world, we need mission-driven, imaginative news \nleaders who are not bound by the models of the past, who have the motivation and freedom to reimagine the field, \nand the empathy and commitment to serve the public interest, undaunted by attacks and threats.\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nWe must also move beyond the lack of economic and demographic diversity that has long been a problem in the \nindustry. News has too often been reported by predominantly middle-class, white, male journalists, resulting in \ncoverage that has repeatedly missed the issues that are most important to the people receiving the news, \ncontributing to the public’s lack of trust in the media.\nIn a resource-starved industry, few newsrooms can offer the type of mentoring, guidance and time that it takes to \nshape a great journalist. This is now primarily the responsibility of journalism schools. It is the civic duty of these \nschools to find and train reporters and news leaders, instill in them an ethical foundation, help develop their critical \nthinking skills, allow them to try and fail in a safe environment, open doors and provide a support network. \n(Journalism schools should also contribute research in a variety of areas, from the impact of A.I. to new business \nmodels to identifying and responding to emerging threats.)\nBut the cost of a journalism education has become an insurmountable barrier for exactly the kind of people we need \nthe most. And those who, with great effort, manage to overcome that barrier, carry a weight that could limit their \nprofessional options.\nReporters burdened with debt are less likely to take professional risks and more likely to abandon the field. \nAccording to the Bureau of Labor Statistics, the median reporter salary in America is less than $56,000 a year, or \nabout $27 per hour. In low-income areas, where news deserts are more prevalent, annual salaries can be as low as \n$20,000. A Wall Street Journal report about the debt-to-income ratio of alumni of 16 journalism masters programs \nfound that many graduates leave with debts that exceed their postgraduate income.\nAs the dean of the Craig Newmark Graduate School of Journalism at the City University of New York, I can tell you \nthat half measures won’t solve this quandary. My school was founded in 2006 as a public alternative to elite \njournalism schools in the city and it remains one of the most affordable in the nation.\nOur in-state students pay about a quarter of the cost of an equivalent degree from top-tier schools with which we \nsuccessfully compete. This year alone, 90 percent of our students are on scholarships, and a record 25 percent are \nattending tuition-free. We also waived the $75 application fee this admission cycle and saw an increase of more \nthan 40 percent in our applicant pool.\nThanks to these policies, we have succeeded where the media industry keeps failing. Over 50 percent of our \nstudents are people of color and from underserved communities. Many couldn’t have attended our school if we \nhadn’t offered significant scholarship support. But that’s not enough. Though we rank as one of the journalism \nschools with higher-medium-income and lower-median-debt alumni, our students still don’t graduate fully debt-free.\nThis is why this year, we began a campaign to go fully tuition-free by 2027. While other schools might face different \nfinancial challenges, we hope that many more will follow us.\nWe need journalists whose only obligations are to the facts and the society they serve, not to lenders; who are \nconcerned with the public interest, not with interest rates; who can make risky decisions and take the difficult path if \nthat’s what the mission requires, free of financial burden. Journalism schools can help achieve that. In tough times, \nit is natural to mourn the past or lament the present, but what we really need is bold action.\nGraciela Mochkofsky is the dean at CUNY’s Craig Newmark Graduate School of Journalism. She is the author, \nmost recently, of “The Prophet of the Andes: An Unlikely Journey to the Promised Land.”\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nPHOTO:  (PHOTOGRAPH BY Pat Thomas FOR THE NEW YORK TIMES)\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "USA_Today_Apr2024",
        "header": "Geek Squad among laid off Best Buy workers; AI to help",
        "media": "USA Today",
        "time": "April 18, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "497 words",
        "byline": "By, Amaris Encinas, USA TODAY",
        "story_text": "Geek Squad among laid off Best Buy workers; AI to help\nUSA Today\nApril 18, 2024 Thursday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 497 words\nByline: By, Amaris Encinas, USA TODAY\nBody\nAddressing \"lower business demand,\" Best Buy has made a significant cut to its workforce and laid off a number of \nemployees, including Geek Squad field agents, current and former workers told The Star Tribune in Minnesota.\nHome-theater repair technicians and phone support specialists were among those hit by the most recent wave of \nlayoffs at the Richfield, Minnesota-based company, according to the newspaper.\nThe layoffs are part of a larger restructuring plan announced by Best Buy CEO Corie Barry in an earnings call in \nFebruary. The plan, which did include layoffs, was proposed in an attempt to \"stabilize the company after months of \ndeclining sales,\" the Star Tribune reported.\nBarry said during the call that the \"cuts would happen primarily in the first half of 2024 and would occur across the \ncompany.\"\nMaking sure that \"field labor resources\" are properly balanced has been a top priority for Best Buy, and the \ncompany wants to \"make sure we are providing the optimal experience for customers where they want to shop,\" \nBarry said on the call.\nAnd, he said, the company wants to reduce parts of the business \"where we expect to see lower volume than we \nenvisioned a few years ago,\" according to the newspaper.\nBest Buy has not responded to USA TODAY's request for comment.\nHere's what we know.\nBest Buy says laid-off workers\nwill get severance\nIt's not immediately clear how many Best Buy employees have been laid off since the restructuring plan was \nannounced, nor how many employees were included in the most recent wave, because the company has declined \nto say.\nThe company did tell the Star Tribune that \"affected and eligible employees will receive severance, with some \noffered opportunities to transfer or reapply for jobs at the company.\"\nGeek Squad among laid off Best Buy workers; AI to help\n\"We know better than anyone that the consumer electronics industry is always changing with new technology, more \ninnovation and evolving customer expectations, and that means we need to make changes, too,\" according to a \nstatement obtained by the Star Tribune.\nThe company is intent on following the steps outlined in the February earnings call, writing that it was \"making sure \nresources are balanced and directed to the right strategic areas so we can drive efficiency in our business and put \nourselves in the best position for the future.\"\nBest Buy announces AI venture\nBest Buy said it's serious about being in the \"best position\" for the future, announcing a new artificial intelligence \nventure after the reports of layoffs. The venture, created in collaboration with Google Cloud and Accenture, uses \n\"generative AI to provide our customers with even more personalized, best-in-class tech support experiences.\"\nThe AI-powered virtual assistants are expected to help Best Buy customers troubleshoot problems with products, \nchange delivery details and manage software, among other things, according to the news release.\nThe \"self-service support option\" will be available online, on the Best Buy app, or over the phone starting this \nsummer.\nLoad-Date: April 18, 2024"
    },
    {
        "file_name": "potential_risks_to_economy,_society,_security_Apr2023",
        "header": "Sen. Schumer proposes framework for AI regulation; Aims to address",
        "media": "potential risks to economy, society, security",
        "time": "April 17, 2023",
        "section": "BUSINESS; Pg. B1",
        "length": "516 words",
        "byline": "By, Bailey Schulz, USA TODAY",
        "story_text": "Sen. Schumer proposes framework for AI regulation; Aims to address \npotential risks to economy, society, security\nUSA Today\nApril 17, 2023 Monday\n1 Edition\nCopyright 2023 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B1\nLength: 516 words\nByline: By, Bailey Schulz, USA TODAY\nBody\n\"(Society needs) sound government policies that promote progress while reducing risks\nof abuse.\"\nKent Walker\nGoogle's president of global affairs\nSenate Majority Leader Chuck Schumer, D-N.Y., wants to see more rules around artificial intelligence.\nThe senator on Thursday announced a new effort to establish a framework of rules to address concerns about AI's \npotential risks to the economy, society and national security.\nSchumer's statement notes that China has already taken steps to regulate AI, but the senator believes it is \n\"imperative\" for the U.S. to lead and shape the rules governing the technology.\nThe proposed AI policy framework aims to enhance security, accountability and transparency while being flexible \nenough to adapt as technology advances. This includes requirements for companies to allow independent experts \nto review and test AI technologies before a public release or update.\nLegislation - which has not yet been drafted - would require bipartisan backing to pass.\nAI 'too important not to regulate'\nSchumer's efforts come shortly after the launch of OpenAI's ChatGPT chatbot prototype in November and Google's \nlimited rollout of the chatbot Bard in March.\nOpenAI did not immediately respond to a request for comment from USA TODAY. Microsoft - which invests heavily \nin OpenAI - declined to comment.\nSpokespeople for Google pointed to a March statement from President of Global Affairs Kent Walker that says AI is \n\"too important not to regulate.\"\n\"The challenge is to do it in a way that mitigates risks and promotes trustworthy applications that live up to AI's \npromise of societal benefit,\" Walker's statement reads. \"(Society needs) sound government policies that promote \nprogress while reducing risks of abuse.\"\nSen. Schumer proposes framework for AI regulation Aims to address potential risks to economy, society, \nsecurity\nConcerns over AI tech\nOther counties have voiced concerns over the lack of regulation around AI technology.\nThe European Consumer Organisation has asked the European Union and national authorities to launch an \ninvestigation into ChatGPT and similar chatbots. The agency noted that while the EU is working on AI legislation, \nthose rules could take years before going into effect, \"leaving consumers at risk of harm from a technology which is \nnot sufficiently regulated during this interim period and for which consumers are not prepared.\"\nEarlier this week, Chinese regulators released draft rules around generative AI that would require services to \ngenerate content that reflects the country's socialist values.\nItaly also placed a temporary ban on ChatGPT over privacy concerns.\nIn the U.S., the Commerce Department earlier this week launched a request for comment on AI accountability, \nwhere people can submit feedback on what policies can be implemented to \"create earned trust in AI systems.\"\nThe National Institute for Standards and Technology  developed a framework to manage AI risks,  and in 2022 the \nWhite House Office of Science and Technology Policy released a blueprint for an AI Bill of Rights.\n\"(Society needs) sound government policies that promote progress while reducing risks\nof abuse.\"\nKent Walker\nGoogle's president of global affairs\nIllustration by Getty Images\nGraphic\n \nSenate Majority Leader Chuck Schumer, D-N.Y., wants the U.S. to shape the rules governing artificial intelligence.\nAP file\nLoad-Date: April 17, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "BERKSHIRE LEADERS TAKE ON BANKS, AI",
        "media": "Wall Street Journal Abstracts",
        "time": "May 9, 2023",
        "section": "B; Pg. 9",
        "length": "51 words",
        "byline": "CHIP CUTTER",
        "story_text": "BERKSHIRE LEADERS TAKE ON BANKS, AI\nWall Street Journal Abstracts\nMay 8, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 9\nLength: 51 words\nByline: CHIP CUTTER\nBody\nABSTRACT\nCharlie Munger speaking at Berkshire Hathaway’s annual shareholder meeting says too many young and brilliant \npeople are becoming wealth managers; Warren Buffett says he wants to see greater accountability inside banks \nand worries about possible consequences of generative artificial intelligence (M)\nLoad-Date: May 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Zuckerberg Lays Out Road Map For Meta",
        "media": "The New York Times",
        "time": "June 9, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1061 words",
        "byline": "By Mike Isaac",
        "story_text": "Zuckerberg Lays Out Road Map For Meta\nThe New York Times\nJune 9, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1061 words\nByline: By Mike Isaac\nBody\nIn an internal all-hands meeting, the chief executive explained his plans for artificial intelligence, the metaverse and \nrebooting Meta's culture.\nMark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work \nforce and struggled to gain mainstream traction with its ambitious plans for virtual reality. \n  On Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, \nMr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta's work in \nartificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\n  Mr. Zuckerberg's talk was an attempt to rally staff after the most tumultuous period in his company's 19-year \nhistory. The chief executive said he made ''tough decisions'' about layoffs with the goal of ''building a better \ntechnology company'' that shipped better products, faster -- something he believed Meta wasn't doing well as it \nswelled to more than 80,000 employees at the peak of the pandemic.\n  ''I want us to use this period that's going to be a bit more stable in order to evolve and rebuild our culture,'' he said, \naccording to two people who attended the meeting and shared remarks and a recording with The New York Times.\n  Mr. Zuckerberg delivered the remarks in a roughly half-hour address to thousands of employees at Meta's Menlo \nPark, Calif., campus. The talk, made on an outdoor pavilion the company calls Hacker Square, was also \nlivestreamed to tens of thousands of employees around the world.\n  It was one of Meta's few major all-hands meetings over the last three years to be conducted in person, and \nincluded presentations from other Meta executives, like Andrew Bosworth, the chief technology officer, and Chris \nCox, the chief product officer.\n  During the presentation, Mr. Cox detailed Meta's plans for making improvements to Reels, Instagram's short-form \nvideo product, to better take on TikTok, one of Meta's most formidable competitors.\n  Executives also spoke about Project 92, a long-rumored social app in development at Meta that will function \nsimilar to Twitter. The app, executives said, will work with other apps like Mastodon and Bluesky.\n  While Meta has aggressively worked on A.I. for several years, it has been slower than competitors like Google and \nMicrosoft to turn that research into consumer products. Mr. Zuckerberg on Thursday detailed plans for artificially \nintelligent assistants that aid people across all Meta's apps, including WhatsApp, Messenger and Instagram.\nZuckerberg Lays Out Road Map For Meta\n  He said Meta would work on creating artificial intelligence models that were accessible to more people than those \nof his company's competitors and, ultimately, would fit into his plans for the metaverse.\n  ''Democratizing access to this has a bunch of value,'' Mr. Zuckerberg said, according to the two people who \nshared remarks with The Times. ''But it's also aligned with the product vision of enabling a lot of different A.I.'s \ninstead of just trying to consolidate this ourselves into one singular A.I. that's going to try to rule everything.''\n  He envisioned A.I. assistants that help people ''create content to express yourself and your ideas so much better,'' \nor perhaps some artificially intelligent version of ''a coach that gives you advice, encourages you.''\n  A.I. agents could serve customers in products like WhatsApp, the globally popular messaging app that Meta has \nbeen focused on turning into an important tool for business owners and customer service. And every business \ncould use a personalized A.I. algorithm.\n  ''Different people have different interests, and we'll need a diverse array of A.I.s to represent all of these different \ninterests,'' Mr. Zuckerberg said in the meeting.\n  To do that, the company is betting heavily on open source technology, which means it will share its work on \nartificial intelligence with researchers who want to build their own algorithms with what Meta has already done. The \ncompany has spent billions over the past decade building systems to run A.I. and attracting top researchers to work \non some of the world's most difficult computer science questions around A.I.\n  Meta has been criticized for its approach. Researchers and politicians outside the company say opening A.I. \nalgorithms to many others could spawn malicious, automated and intelligent systems that accelerate the spread of \nmisinformation. Those sophisticated algorithms, critics say, need to be tightly controlled.\n  In his address, Mr. Zuckerberg defended Meta's strategy. He said open-source software enables greater outside \nscrutiny of the technology because it can be seen by millions of technologists. He said working closely with \noutsiders' advances would make Meta's platforms better.\n  Mr. Zuckerberg also said he hoped for a world where people could build as many different A.I. programs as they \nwanted, rather than relying on a few provided by two or three large technology companies.\n  That does not mean Meta is backing away from its namesake metaverse plans, Mr. Zuckerberg said. Programs \nusing new generative A.I. technology, he said, could eventually help people build new virtual world items and \nexperiences. And he hinted that the company may bring its A.I. assistant into a future version of its smart glasses. \n(Meta released a pair of smart Ray-Ban glasses in 2021, though sales have been sluggish.)\n  He also took a swipe at Apple's recently announced Vision Pro headset, $3,500 high-tech goggles that promised \nto usher in a new era of ''spatial computing.''\n  ''I was really curious to see what they'd ship, and it's a good sign for our own development that they don't have any \nmagical solutions to the laws of physics that we haven't already explored,'' he said in his remarks. Mr. Zuckerberg \ncriticized the high-end materials and cost of the device, while noting that Meta had spent years bringing down the \nprice of its headsets to an upcoming version that will start at $500.\n  ''Their announcement really shows how our vision and values are different and what's at stake in shaping this \nplatform,'' Mr. Zuckerberg said. ''Our vision of the metaverse and presence is fundamentally social and about \npeople interacting and feeling closer in new amazing ways. By contrast, every demo Apple showed was someone \nsitting on a couch by themselves.''\nhttps://www.nytimes.com/2023/06/08/technology/mark-zuckerberg-meta.html\nGraphic\nZuckerberg Lays Out Road Map For Meta\n \nPHOTO: Mark Zuckerberg's address on Thursday appeared to be an attempt to rally Meta's employees after a \ntumultuous period of widespread layoffs. (PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) (B5) \nThis article appeared in print on page B1, B5.               \nLoad-Date: June 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Google Tests A.I. Tool That Is Able to Write News Articles",
        "media": "The New York Times",
        "time": "July 20, 2023",
        "section": "BUSINESS",
        "length": "802 words",
        "byline": "Benjamin Mullin and Nico Grant",
        "story_text": "Google Tests A.I. Tool That Is Able to Write News Articles\nThe New York Times \nJuly 19, 2023 Wednesday 21:54 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 802 words\nByline: Benjamin Mullin and Nico Grant\nHighlight: The product, pitched as a helpmate for journalists, has been demonstrated for executives at The New \nYork Times, The Washington Post and News Corp, which owns The Wall Street Journal.\nBody\nThe product, pitched as a helpmate for journalists, has been demonstrated for executives at The New York Times, \nThe Washington Post and News Corp, which owns The Wall Street Journal.\nGoogle is testing a product that uses artificial intelligence technology to produce news stories, pitching it to news \norganizations including The New York Times, The Washington Post and The Wall Street Journal’s owner, News \nCorp, according to three people familiar with the matter.\nThe tool, known internally by the working title Genesis, can take in information — details of current events, for \nexample — and generate news content, the people said, speaking on the condition of anonymity to discuss the \nproduct.\nOne of the three people familiar with the product said that Google believed it could serve as a kind of personal \nassistant for journalists, automating some tasks to free up time for others, and that the company saw it as \nresponsible technology that could help steer the publishing industry away from the pitfalls of generative A.I.\nSome executives who saw Google’s pitch described it as unsettling, asking not to be identified discussing a \nconfidential matter. Two people said it seemed to take for granted the effort that went into producing accurate and \nartful news stories.\nJenn Crider, a Google spokeswoman, said in a statement that “in partnership with news publishers, especially \nsmaller publishers, we’re in the earliest stages of exploring ideas to potentially provide A.I.-enabled tools to help \ntheir journalists with their work.”\n“Quite simply, these tools are not intended to, and cannot, replace the essential role journalists have in reporting, \ncreating and fact-checking their articles,” she added. Instead, they could provide options for headlines and other \nwriting styles.\nA News Corp spokesman said in a statement, “We have an excellent relationship with Google, and we appreciate \nSundar Pichai’s long-term commitment to journalism.”\nThe Times and The Post declined to comment.\nJeff Jarvis, a journalism professor and media commentator, said Google’s new tool, as described, had potential \nupsides and downsides.\nGoogle Tests A.I. Tool That Is Able to Write News Articles\n“If this technology can deliver factual information reliably, journalists should use the tool,” said Mr. Jarvis, director of \nthe Tow-Knight Center for Entrepreneurial Journalism at the Craig Newmark Graduate School of Journalism at the \nCity University of New York.\n“If, on the other hand, it is misused by journalists and news organizations on topics that require nuance and cultural \nunderstanding,” he continued, “then it could damage the credibility not only of the tool, but of the news \norganizations that use it.”\nNews organizations around the world are grappling with whether to use artificial intelligence tools in their \nnewsrooms. Many, including The Times, NPR and Insider, have notified employees that they intend to explore \npotential uses of A.I. to see how it might be responsibly applied to the high-stakes realm of news, where seconds \ncount and accuracy is paramount.\nBut Google’s new tool is sure to spur anxiety, too, among journalists who have been writing their own articles for \ndecades. Some news organizations, including The Associated Press, have long used A.I. to generate stories about \nmatters including corporate earnings reports, but they remain a small fraction of the service’s articles compared with \nthose generated by journalists.\nArtificial intelligence could change that, enabling users to generate articles on a wider scale that, if not edited and \nchecked carefully, could spread misinformation and affect how traditionally written stories are perceived.\nWhile Google has moved at a breakneck pace to develop and deploy generative A.I., the technology has also \npresented some challenges to the advertising juggernaut. While Google has traditionally played the role of curating \ninformation and sending users to publishers’ websites to read more, tools like its chatbot, Bard, present factual \nassertions that are sometimes incorrect and do not send traffic to more authoritative sources, such as news \npublishers.\nThe technology has been introduced as governments around the world have called on Google to give news outlets \na larger slice of its advertising revenue. After the Australian government tried to force Google to negotiate with \npublishers over payments in 2021, the company forged more partnerships with news organizations in various \ncountries, under its News Showcase program.\nPublishers and other content creators have already criticized Google and other major A.I. companies for using \ndecades of their articles and posts to help train these A.I. systems, without compensating the publishers. News \norganizations including NBC News and The Times have taken a position against A.I.’s sucking up their data without \npermission.\nThis article appeared in print on page B4.\nLoad-Date: July 20, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "Skilling Platform Disprz Bags $30m from Lumos and Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 7, 2023",
        "section": "STARTUPS & TECH",
        "length": "191 words",
        "byline": "Our Bureau",
        "story_text": "Skilling Platform Disprz Bags $30m from Lumos and Others\nEconomic Times (E-Paper Edition)\nAugust 7, 2023 Monday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 191 words\nByline: Our Bureau\nHighlight: Series-C funding round a mix of primary and secondary share sales\nBody\nBengaluru: Disprz, a corporate learning and skilling platform, has raised $30 million in its Series C funding round led \nby Lumos Capital. 360 ONE Asset (IIFL Wealth) and returning investors Kae Capital, KOIS and Dallas Venture \nCapital also participated. The funding, a result of primary and secondary share sales, will be utilised for global \nmarket expansion and product development, including the integration of generative artificial intelligence across \nthe learning and skilling cycle.  Additionally, Disprz aims to form  strategic partnerships and make strategic \nacquisitions, as per a statement. “We are right now in the middle of our $10 million to $100 million ARR (annual \nrecurring revenues) journey. The raised capital will let us build our next generation of products. We are a multi-\nproduct company, we have a suite of offerings on learning and upskilling for mid and large enterprises in emerging \nmarkets like India, southeast Asia, middle east and we've just made our trip to the US,” founder and CEO \nSubramanian Viswanathan told ET. Viswanathan said that the company currently has 12 clients in the US. In total, \nthe company has 350.\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "PUTTING AI ON THE JOB TO BOOST PRODUCTIVITY AND PROFITABILITY",
        "media": "Wall Street Journal Abstracts",
        "time": "June 1, 2023",
        "section": "A; Pg. 11",
        "length": "42 words",
        "byline": "TE-PING CHEN",
        "story_text": "PUTTING AI ON THE JOB TO BOOST PRODUCTIVITY AND PROFITABILITY\nWall Street Journal Abstracts\nMay 31, 2023 Wednesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 11\nLength: 42 words\nByline: TE-PING CHEN\nBody\nABSTRACT\nTe-Ping Chen Personal Journal column notes some workers, especially freelancers and small-business owners \nwho are free of legal hurdles that large companies face, have already started using generative AI tools to save \ntime on projects; photos (M)\nGraphic\n \nPhotograph\nLoad-Date: June 1, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Who Is Liable for A.I. Creations?; DealBook Newsletter",
        "media": "The New York Times",
        "time": "June 4, 2023",
        "section": "BUSINESS",
        "length": "1988 words",
        "byline": "Ephrat Livni, Sarah Kessler and Ravi Mattu",
        "story_text": "Who Is Liable for A.I. Creations?; DealBook Newsletter\nThe New York Times \nJune 3, 2023 Saturday 23:22 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1988 words\nByline: Ephrat Livni, Sarah Kessler and Ravi Mattu\nHighlight: Tools like ChatGPT could open a new line of questions around tech products and harmful content.\nBody\nTools like ChatGPT could open a new line of questions around tech products and harmful content.\nA string of challenges to Section 230 — the law that shields online platforms from liability for user-generated \ncontent — have failed over the last several weeks. Most recently, the Supreme Court declined on Tuesday to \nreview a suit about exploitative content on Reddit. But the debate over what responsibility tech companies have for \nharmful content is far from settled — and generative artificial intelligence tools like the ChatGPT chatbot could \nopen a new line of questions.\nDoes Section 230 apply to generative A.I.? The law’s 1996 drafters told DealBook that it does not. “We set out to \nprotect hosting,” said Senator Ron Wyden, Democrat of Oregon. Platforms are immune only to suits about material \ncreated by others, not their own work. “If you are partly complicit in content creation, you don’t get the shield,” \nagreed Chris Cox, a former Republican representative from California. But they admit that these distinctions, which \nonce seemed simple, are already becoming more difficult to make.\nWhat about A.I. search engines? Typically, search engines are considered vehicles for information rather than \ncontent creators, and search companies have benefited from Section 230 protection. Chatbots generate content, \nand they are most likely beyond protection. But tech giants like Microsoft and Google are integrating chat and \nsearch, complicating matters. “If some search engines start to look more like chat output, the lines will be blurred,” \nWyden said.\nA deadly recipe? Generative A.I. tools have already been used to make intentionally harmful content. And \nhallucinations — the falsehoods that generative A.I. tools create (like court cases that never existed) — are a \nsignificant problem. If a user prompts an A.I. for cocktail instructions and it offers a poisonous concoction, the \nalgorithm operator’s liability is obvious, said Eric Goldman, a law professor at Santa Clara University and a Section \n230 expert.\nBut most situations won’t be that clear-cut, and that poses a risk, Goldman said. He fears that anger over immunity \nfor social media platforms threatens nuanced debate about the next generation of tech development.\n“The blossoming of A.I. comes at one of the most precarious times amid a maturing tech backlash,” Goldman said. \n“We need some kind of immunity for people who make the tools,” he added. “Without it, we’re never going to see \nthe full potential of A.I.” — Ephrat Livni\nIN CASE YOU MISSED IT \nElon Musk receives a hero’s welcome in China. The Tesla chief was hailed on Chinese social media as a “global \nidol” during his visit this week to the country, where he met with government ministers and visited the Tesla’s \nShanghai factory. Musk reportedly also had kind words for his hosts: Government readouts of his meetings with \nWho Is Liable for A.I. Creations? DealBook Newsletter\nBeijing ministers said he had described the U.S. and Chinese economies as “conjoined twins” and opposed political \nefforts to decouple them.\nBilly Joel is movin’ out (of Madison Square Garden). The singer announced this week that he will finish a 10-year \nstay at Madison Square Garden in July 2024. The series of more than 100 shows crossed its $200 million threshold \nin March. James Dolan, the C.E.O of the Garden’s parent company, said the run had “made history” for both the \nvenue and the music industry. Or, perhaps more simply: Joel was a big shot.\n“Ketatations” in the workplace. Some executives have embraced the anesthetic ketamine to improve professional \nperformance or foster team bonding. “We put them on yoga mats in the room, we have a prescription from a doctor, \nand we have a 45-minute experience together,” Kaia Roman, who has led “ketatations” (ketamine + meditation) \nsince the pandemic, told Bloomberg. Others prefer a more aggressive way to relax: Mark Zuckerberg recently \ncompleted “the Murph Challenge,” which consists of a mile run, 100 pull-ups, 200 push-ups, 300 squats and \nanother mile run — all while wearing a 20-pound vest. He said he had done it in 40 minutes.\nMatter of debate: ‘greedflation’ \nGeneral inflation slowed for the 10th straight month in April, but many companies are still raising prices. Why? \nSome economists blame “greedflation,” “excuseflation” or a “price-price spiral,” whereby businesses use inflationary \nevents like the pandemic, the Ukraine war and soaring energy prices as an excuse to make big price increases that \nmore than cover their higher costs. The idea is that customers are more accepting of price increases when they \nknow inflation is historically high, so companies are taking the opportunity to raise prices as much as they can. But \nnot everyone is convinced, and some point to a host of other postpandemic economic trends as the real culprit. \nHere are two views.\nGreedflation is to blame. Despite expectations that net profit margins would decline this year, they have increased \nat the average company in the S&amp;P 500, according to data from FactSet.\n“What we see in many cases is that volumes are going down, while prices are going up and profit margins are going \nup,” said Isabella Weber, a professor at the University of Massachusetts Amherst, who pioneered the theory.\nShe pointed to Starbucks as an extreme example of what she calls “sellers’ inflation.” In 2020, when the pandemic \nshut down demand for coffee shops, basic supply-and-demand laws suggested that Starbucks would lower the \nprice of coffee to entice people back to its stores. Instead, Weber said, “prices actually were going up.”\nLast month, the Federal Reserve Bank of Kansas City said corporate profits had contributed to inflation in 2021, \nthough their contribution fell in 2022, which is consistent with what happened in previous economic recoveries.\nGreedflation is not to blame. Customers who benefited from stimulus checks, low interest rates, investment gains \nand other factors were in a good financial position coming out of the pandemic. Their willingness to spend more is \nwhat’s mostly fueling inflation, some analysts say.\n“It seems to me that many telling the profit story forget that households have to actually spend money for the story \nto hold,” David Beckworth, a senior research fellow at the right-leaning Mercatus Center at George Mason \nUniversity and a former economist for the Treasury Department, told The Times this week. “And once you look at \nthe huge surge in spending, it becomes inescapable to me where the causality lies.”\nIn any case, conditions for greedflation could be waning. Supply chain disruptions and other inflationary pressures \nare easing, making it harder for companies to blame inflation elsewhere for raising prices. “Some firms are claiming \n‘general inflation pressures’ as being behind their price increases,” said Paul Donovan, the chief economist at UBS, \n“but that is far less convincing, and consumers are less willing to accept it.”\nWeber warns, however, that another inflation-causing crisis could pop up at any time, and “firms have now learned \nthis playbook.”\nThe Ted Lasso way \nWho Is Liable for A.I. Creations? DealBook Newsletter\n“Ted Lasso,” the saccharine story of an apparently clueless American who is appointed to run a British soccer team, \nended this week. And while Lasso’s journey from barely knowing the rules to turning a group of misfits into a top \nteam is not particularly realistic, management experts say some of his coaching strategies really are.\nDealBook has picked out four management lessons from the fictional coach from Kansas that might apply to the \nreal world. Warning: They contain spoilers.\nThe outsider sees things that others do not. Lasso is initially portrayed as a naïve bumpkin with little understanding \nof the sport, his team or the country he’s living in. But that is the foundation of his success, said Allyson Stewart-\nAllen, C.E.O. of International Marketing Partners and an expert on cross-cultural management. “He brings a lack of \nself-consciousness in wanting to ask questions others might think are facile,” she told DealBook, adding that her \nAmerican clients who are expanding in Europe do exactly what Lasso does. “Ask lots of questions, be open to new \nideas, and experiment.”\nCulture trumps strategy. Any team that is on the same wavelength is obviously more likely to thrive, a view \nfamously championed by management thinkers like Peter Drucker. Lasso’s first task was to understand the culture \nof the organization he has taken over and then mold it in his image. Once he achieved this, he shifted to identifying \nthe strengths and weaknesses of his players and coaches, and figuring out how to motivate them. That should be \nthe goal of every good manager.\nSerious strategic change takes time. Most executives, especially those who run public companies, are under \nimmense pressure to deliver quickly. Sometimes that’s justified, but sometimes boards can be too quick to change \na C.E.O. without providing the necessary support. Lasso had three years with little real threat of being fired. That \ngave him time to understand the game (by the final episode, he had learned what the offside rule is), the culture of \nthe club and how to make it all work. It was only midway through his last season that he discovered his sporting \nvision — “total football” — that he used to turn his team of losers into winners.\n“Meaning matters more than means,” Bruce Feiler, the author of “The Search: Finding Meaningful Work in a Post-\nCareer World,” told CNBC this week. Younger workers increasingly put a priority on work-life balance and personal \nfulfillment over money in their careers. On the show, Lasso himself best embodied that trait by walking away from \nthe job after finishing second rather than sticking around and trying to win it all again. Even though he finally \ncracked the sport, he returned to Kansas to be closer to his family. “He shows vulnerability,” Stewart-Allen said. “He \ncries. He has panic attacks. He’s not perfect, and he doesn’t try to hide that. I think that is very realistic and \nendearing and builds empathy with people.”\nYour thoughts on vacation \nLast week, we wrote about a recent Pew survey that found almost half of Americans do not use all of their paid time \noff, and we asked you for your thoughts. A lot of you cited the same reasons as respondents to the survey for not \nusing all of your time — banking time to use in an emergency, fearing that taking vacation will make you vulnerable \nduring a layoff or worrying that work will accumulate to stressful levels while you’re away. We also heard from many \nreaders who do use all of their paid time off. Here are a few of your reasons:\n• Quilvio wrote that he is in his early 20s, younger than most of his co-workers, and that “generationally, we \nhave different mind-set around P.T.O. and work.” He added, “I think as long as I’m getting the work done, \nthe days (and hours) I work aren’t as important.”\n• Another reader, who asked not to be named, wrote that she used to work at a prestigious New York City law \nfirm where most senior attorneys did not take all of their paid vacation days. Talking with them about their \nweekend leisure activities, she realized why: “It dawned on me (silly woman) — they have WIVES AND \nSERVANTS who do all the nonwork work for them! So they have time and energy to unwind on both \nevenings AND weekends. They are not making calls to set up doctor appointments for their kids (or, likely, \nfor themselves either), they are not making dinner after work every night, they do not attend P.T.A. \nmeetings, they are not burdened with the zillion daily decisions and tasks of keeping a household going.”\nWho Is Liable for A.I. Creations? DealBook Newsletter\n• Stephanie, a director at a hospital, said she granted whatever time her employees needed. “It’s a retention \ntool,” she wrote. “We have a high-performing team. If I take care of my managers, they take care of their \nstaff. The staff then are better able to care for their patients.”\nThanks for reading! \nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nThis article appeared in print on page B5.\nLoad-Date: June 4, 2023"
    },
    {
        "file_name": "Newsletter_Jan2024",
        "header": "The Big Buzz at Davos: A.I., Ukraine, China, and the Middle East; DealBook",
        "media": "Newsletter",
        "time": "January 16, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1892 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "The Big Buzz at Davos: A.I., Ukraine, China, and the Middle East; DealBook \nNewsletter\nThe New York Times \nJanuary 16, 2024 Tuesday 08:27 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1892 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni &lt;p&gt;Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is \na co-anchor of CNBC&amp;#8217;s &#34;Squawk Box&#34; and the author of &amp;#8220;Too Big to \nFail.&amp;#8221; He is also a co-creator of the Showtime drama series &#34;Billions.&#34;&lt;/p&gt; &lt;p&gt;Ravi \nMattu is the managing editor of DealBook, based in London. He joined The New York Times in 2022 from the \nFinancial Times, where he held a number of senior roles in Hong Kong and London.&lt;/p&gt; &lt;p&gt;Bernhard \nWarner is a senior editor for DealBook, a newsletter from The Times, covering business trends, the economy and \nthe markets.&lt;/p&gt; &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on \nbusiness and how workplaces are changing.&lt;/p&gt; &lt;p&gt;Michael de la Merced joined The Times as a reporter \nin 2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry.&lt;/p&gt; &lt;p&gt;Lauren Hirsch joined The Times from CNBC in 2020, \ncovering deals and the biggest stories on Wall Street.&lt;/p&gt; &lt;p&gt;Ephrat Livni reports from Washington on \nthe intersection of business and policy for DealBook. Previously, she was a senior reporter at Quartz, covering law \nand politics, and has practiced law in the public and private sectors.&amp;#160;&amp;#160;&lt;/p&gt;\nHighlight: C.E.O.s and world leaders gather in the Swiss Alps this year as war, trade risks and disruptive new \ntechnologies loom large.\nBody\nC.E.O.s and world leaders gather in the Swiss Alps this year as war, trade risks and disruptive new technologies \nloom large.\nThe meetings behind the meeting \nThousands of global leaders have once again descended on snowy Davos, Switzerland, for the World Economic \nForum’s annual meeting. The theme of this year’s event: “rebuilding trust.”\nBut there are the public meetings, and then there are the real ones behind closed doors that the attendees are \ntalking about most. These include discussions touching on U.S.-China tensions, the war in Gaza, artificial \nintelligence and the future of Ukraine.\nThere is a kind of game that some C.E.O.s play with one another: How many public panels are you on, or how \nmany times have you been in the Congress Center, the main hub for the forum’s big presentations? If the answer is \nzero, you’ve won. \nTop U.S. officials are set to appear on the main stage, including Secretary of State Antony Blinken and Jake \nSullivan, the national security adviser. But speculation abounds about whom they’re seeing behind the scenes.\nOne question: Will their meetings include anyone from the sizable China delegation, led by Li Qiang, the country’s \npremier? U.S.-China tensions are high after Lai Ching-te, a fierce defender of Taiwanese sovereignty who is \ndespised by Beijing, was elected president of the self-governed island on Saturday.\nThe Big Buzz at Davos : A.I., Ukraine , China, and the Middle East DealBook Newsletter\nLi has already met over lunch with the C.E.O.s of IBM, Intel, Walmart and others. (He also addressed the \nconference on Tuesday and revealed that China’s economy grew about 5.2 percent last year, a day ahead of the \nofficial data release.) \nA lot of eyes are also on officials from the Middle East. Israel’s president, Isaac Herzog, is expected to take the \nstage on Thursday as his country’s war with Hamas threatens to further escalate into a broader regional conflict. \nSome attendees wonder whether he’ll meet with the Qatari prime minister, Mohammed bin Abdulrahman al-Thani, \nwhose country has been a key go-between in negotiations over hostages and humanitarian aid in Gaza.\nAlso on hand is the delegation from Saudi Arabia, led by the foreign minister, Prince Faisal bin Farhan, as the \nkingdom flexes its growing economic and diplomatic power.\nAnother attendee: Jared Kushner, Donald Trump’s son-in-law who helped spearhead the Abraham Accords and \nnow leads a private equity firm whose backers include Saudi Arabia’s sovereign wealth fund.\nVolodymyr Zelensky is a keynote speaker, giving a public address this afternoon and participating in a Q. and A. \nthat Andrew will moderate. And Ukraine’s president has met with top bankers, including JPMorgan Chase’s Jamie \nDimon and Bank of America’s Brian Moynihan, as well as Bridgewater’s Ray Dalio.\nArtificial intelligence is the talk of the town. DealBook has had more conversations about generative A.I. than any \nother topic at Davos. (There are over two dozen events on the schedule that directly reference A.I. in their titles.) So \nit’s unsurprising that among the most sought-after attendees are executives like Sam Altman, OpenAI’s C.E.O.; \nMustafa Suleyman, the Google DeepMind co-founder who now leads Inflection AI; Lila Ibrahim, the C.O.O. of \nDeepMind; Aidan Gomez, the C.E.O. of Cohere; and Florian Bressand of France’s Mistral AI.\nPenny Pritzker’s dilemma: She’s officially there in her role as the State Department’s special representative for \nUkraine’s economic recovery. In most years, her other role, as head of Harvard’s governing board, would make her \na hot ticket for the crowds of alumni in attendance.\nBut with controversy over Claudine Gay’s defenestration as Harvard’s president amid plagiarism accusations and \nantisemitism concerns on campus, is she more likely to get sharply questioned by worried donors?\nHERE’S WHAT’S HAPPENING \nGoldman Sachs tops estimates for fourth-quarter profits. Shares in the Wall Street giant rose nearly 2 percent in \npremarket trading after the bank reported a jump in revenues. But its annual profits sank to the lowest level in four \nyears, hurt by losses tied to its retreat from consumer banking and a slowdown in investment banking.\nHouthis militants in Yemen attack more ships in the Red Sea. The Iran-backed group hit an American-owned \ncommercial ship with a missile on Monday, days after the U.S. and British militaries launched strikes against Houthi \ntargets in Yemen. Traffic through the vital shipping route has plummeted in recent weeks. QatarEnergy, a big \nexporter of liquefied natural gas, is the latest company to order its ships to avoid the region.\nApple redesigns its smartwatch to get around an import ban. The company is removing a blood-oxygen sensor from \nthe Apple Watch at the heart of a patent dispute with Masimo, a technology company that accused Apple of \nviolating its intellectual property rights. The U.S. Customs and Border Protection agency approved the changes, \naccording to Masimo.\nBoeing will add more inspection requirements for the 737 Max and a key supplier. The plane maker will increase \nchecks and send a team to check the work of Spirit AeroSystems after hundreds of its 737 Max 9 jets were \ngrounded when a panel made by that company blew out in the sky over Oregon. The company also plans to open \nup its factories to customers to inspect processes.\nTrump marches on \nThe Big Buzz at Davos : A.I., Ukraine , China, and the Middle East DealBook Newsletter\nDonald Trump coasted to a record victory in the Republican Iowa caucuses last night, crushing his opponents and \ndemonstrating his dominance over the party as he seeks a rematch against President Biden.\nFrigid temperature put the chill on turnout. But with most of the votes counted, Trump still managed to win all but \none county and was expected to sweep nearly every voter demographic: men, women, young people, college \ngraduates, evangelicals, political moderates and conservatives.\nBiden called Trump “the clear front runner” for the Republicans, and used his predecessor’s win as a fund-raising \npitch. (The president’s re-election campaign says its war chest stands at roughly $117 million after pulling in over \n$97 million last quarter.) And world leaders are already warning about Trump’s potential return to power. “It is \nclearly a threat,” Christine Lagarde, the president of the European Central Bank, said last week.\nIowa was about as good as Trump could have expected. Gov. Ron DeSantis of Florida finished in a distant second \nplace, despite investing heavily in the state. His campaign is now running low on cash, but he tried to spin the result \nas giving him some momentum.\nNikki Haley, who has been gaining in national polls and winning over big-name donors, was third, with about 95 \npercent of the votes counted as of press time.\nThe duo spent big on advertising, part of a record splash of more than $123 million by all the candidates, and still \nlost to Trump by huge margins.\nThe race has slimmed. Vivek Ramaswamy, the wealthy entrepreneur who ran a largely self-funded campaign, \nfinished a distant fourth, dropped out of the race and endorsed Trump. Ramaswamy had clashed frequently with \nHaley and DeSantis on the campaign trail, and he was a vocal defender of the former president, vowing to support \nhim in the face of myriad legal challenges.\nNext up on Jan. 23 is New Hampshire, where Haley has focused a lot of her efforts and is doing better in polls. The \nstate is home to more moderate Republicans and independent voters than Iowa, and has a larger anti-Trump voting \nbloc. Still, the former president holds a double-digit lead in polls there.\nEurope’s big bet on batteries \nNorthvolt, one of Europe’s biggest green start-ups, is raising $3.4 billion in debt from the European Union and a \nconsortium of banks, including JPMorgan Chase, to expand battery production locally and support the continent’s \nfledgling electric vehicle sector.\nThe financing and subsidies arrangement is a bet by Europe to keep battery production closer to home, and to limit \nthe march of Chinese and U.S. players that are beginning to dominate the market, The Wall Street Journal reports.\nThe funding is one of the largest transactions for a clean-energy company in recent years. It highlights a push from \ninvestors and policymakers to channel billions of dollars into making batteries that can power electric cars and store \nenergy when the wind isn’t blowing and sun isn’t shining to speed the shift away from fossil fuels.\nChina controls swaths of the battery supply chain from metals processing to cell assembly, a concern for Western \ncountries that are throwing billions of dollars in tax credits, loans and grants at companies to kick-start their own \nsupply chains. The 2022 U.S. climate law has driven other countries to bolster their own subsidies to attract clean-\nenergy investments.\n“It’s an existential threat to the food industry and certainly an existential threat to the processed food industry.” \n— Marion Nestle, an emeritus professor of nutrition, food studies and public health at New York University, on how \npopular weight loss drugs like Ozempic could upend the marketing of snack foods in America.\nThe week ahead \nThe Big Buzz at Davos : A.I., Ukraine , China, and the Middle East DealBook Newsletter\nAfter markets were closed on Monday for Martin Luther King’s Birthday, a bevy of earnings, economic data and \ncentral bankers’ speeches will all be released this week. Here’s what to watch for.\nWednesday: China will officially release fourth-quarter G.D.P. data and population data, with questions swirling \nabout the health of the world’s second-biggest economy and the scale of its demographic crisis.\nThe United States will publish retail sales data for December, and the Fed will release its latest “beige book” report, \ndetailing economic activity across 12 regions.\nIn earnings, Charles Schwab, Alcoa and Citizens Financial report results.\nThursday: Central bankers take the spotlight, with Christine Lagarde, the European Central Bank president, and \nRaphael Bostic, the head of the Atlanta Fed, due to speak at separate events. Expect plenty of questions about \nstubbornly high inflation and the timing for the first round of interest rate cuts.\nTSMC, the Taiwanese chip giant, reports fourth quarter earnings.\nFriday: State Street, Comerica and Burberry report results, and the University of Michigan publishes its latest \nconsumer sentiment report.\nTHE SPEED READ \nDeals\n• Shell has agreed to sell its Nigerian onshore oil business to a contingent of local companies for more than \n$1.3 billion. (Bloomberg)\n• General Atlantic has agreed to buy Actis, a British infrastructure fund management group. (Reuters)\nArtificial intelligence\n• Elon Musk threatened he would spin a company out of Tesla focused on A.I. and robotics if the car maker’s \nboard does not give him greater voting control and a big performance award. (Bloomberg)\n• Thomson Reuters is in talks with generative A.I. companies to license its news and data in deals that could \nbe modeled on OpenAI’s arrangement with Axel Springer. (Bloomberg)\nBest of the rest\n• “Succession” was the big winner at last night’s Emmy Awards … and Brian Cox, who played Logan Roy, the \npatriarch, said he was open to starring in a “Succession” movie, but only “if it’s good enough.” (NYT, \nVariety)\n• “The M.B.A.s Who Can’t Find Jobs” (WSJ)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: The topics on the mind of attendees at this year’s World Economic Forum in Davos, Switzerland, include \nartificial intelligence, the war in Gaza and the future of Ukraine. (PHOTOGRAPH BY Denis Balibouse/Reuters FOR \nTHE NEW YORK TIMES)\nLoad-Date: January 16, 2024"
    },
    {
        "file_name": "ChatGPT_Apr2023",
        "header": "OpenAI CEO Sam Altman Visits Japan As Its Government Embraces",
        "media": "ChatGPT",
        "time": "April 12, 2023",
        "section": "",
        "length": "626 words",
        "byline": "Sissi Cao",
        "story_text": "OpenAI CEO Sam Altman Visits Japan As Its Government Embraces \nChatGPT\nNew York Observer\nApril 10, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 626 words\nByline: Sissi Cao\nBody\nOpenAI CEO Sam Altman picked Japan as the destination of his first overseas trip since the debut of ChatGPT. \nThe 37-year-old entrepreneur met with Japan's Prime Minister Fumio Kishida in Tokyo today (April 10) and \nannounced plans to open a new office in the country, whose government shows an unusual interest in adopting \nartificial intelligence technology while many Western nations look to restrict it.\n\"We hope to spend much more time (in Japan) and hope to engage with the wonderful talent and build something \ngreat for Japanese people and make the models better,\" Altman told reporters today after his meeting with Prime \nMinister Kishida, the Japan Times reported.\nThe same day, Japan's Chief Cabinet Secretary Hirokazu Matsuno said the Japanese government will consider \nadoption of A.I. technology, including ChatGPT, if privacy and cybersecurity concerns are resolved.\n\"We will make all necessary considerations on ways to deal with confidential information and concerns about \ninformation leaks,\" said Matsuno, Japan's top government spokesperson. \"Once those concerns are resolved, we \nwill look into using AI to reduce the workload of national public servants.\"\nCountries react differently to the sudden rise of ChatGPT\nJapan's stance on ChatGPT stands in contrast to Italy's recent move to ban the A.I. chatbot in the country over data \nprivacy concerns.\nLast week, the Italian Data Protection Watchdog, known as Garante, ordered OpenAI to pause processing Italian \nusers' data amid a probe into a suspected breach of Europe's privacy regulations.\nThe ban inspired other Western countries to come up with their own measures on A.I. technology. Ireland is \nconsidering a similar ban on ChatGPT. Germany is looking to limit access to the chatbot in the country. The U.K. \nlast week announced plans for regulating A.I. using existing laws, noting that risks and opportunities surrounding \ngenerative A.I. are \"emerging at an extraordinary pace,\" Britain's Digital Minister Michelle Donelan said in a speech \nto Parliament on April 5.\nIn February, the European Union proposed a new piece of legislation on A.I. called the European A.I. Act. The law \nwill heavily restrict the use of A.I. in critical infrastructure, education, law enforcement and the judicial system.\nThe U.S. hasn't yet proposed any formal rules to bring oversight to A.I. technology.\nAsked to comment on Italy's recent ChatGPT ban at a news conference today, Matsuno, Japan's Chief Cabinet \nSecretary, said Japan is aware of other countries' actions.\nJapan is an early adopter of A.I.\nOpenAI CEO Sam Altman Visits Japan As Its Government Embraces ChatGPT\nOpenAI's ChatGPT made its debut in Japan's parliament on March 29. During a demo, Kazuma Nakatan, a \nmember of parliament, challenged Prime Minister Kishida with a ChatGPT-generated question related to the Covid-\n19 pandemic policy and later displayed an answer to the question also generated by the chatbot. After comparing \nthe two, Kishida lightheartedly insisted his answer was better.\n\"Japan is certainly one of the centers of the world, first with image generation and now with ChatGPT,\" Altman said \nin Tokyo today. He claims there are more than a million daily users of ChatGPT in Japan.\nAltman added that during his meeting with Prime Minister Kishida, they discussed \"the upsides of this technology \nand how to mitigate the downsides.\"\nDespite the government's welcoming stance, ChatGPT has been met with some resistance in Japan's public \nsphere. Several universities in the country have implemented rules that prohibit the use of ChatGPT in writing \nessays and reports.\nAt a news conference last week, government spokesperson Matsuno said Japan's education ministry will draft \nguidelines on the use of ChatGPT in schools amid fears that excessive use of the software might damage the \nlearning environment for students.\nLoad-Date: April 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "A 'Leap Forward' for A.I. May Occur in 2024",
        "media": "The New York Times",
        "time": "January 9, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1403 words",
        "byline": "By Cade Metz",
        "story_text": "A 'Leap Forward' for A.I. May Occur in 2024\nThe New York Times\nJanuary 9, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1403 words\nByline: By Cade Metz\nBody\nA.I. is set to advance at a rapid rate, becoming more powerful and spreading into the physical world.\nAt an event in San Francisco in November, Sam Altman, the chief executive of the artificial intelligence company \nOpenAI, was asked what surprises the field would bring in 2024. \n  Online chatbots like OpenAI's ChatGPT will take ''a leap forward that no one expected,'' Mr. Altman immediately \nresponded.\n  Sitting beside him, James Manyika, a Google executive, nodded and said, ''Plus one to that.''\n  The A.I. industry this year is set to be defined by one main characteristic: a remarkably rapid improvement of the \ntechnology as advancements build upon one another, enabling A.I. to generate new kinds of media, mimic human \nreasoning in new ways and seep into the physical world through a new breed of robot.\n  In the coming months, A.I.-powered image generators like DALL-E and Midjourney will instantly deliver videos as \nwell as still images. And they will gradually merge with chatbots like ChatGPT.\n  That means chatbots will expand well beyond digital text by handling photos, videos, diagrams, charts and other \nmedia. They will exhibit behavior that looks more like human reasoning, tackling increasingly complex tasks in fields \nlike math and science. As the technology moves into robots, it will also help to solve problems beyond the digital \nworld.\n  Many of these developments have already started emerging inside the top research labs and in tech products. But \nin 2024, the power of these products will grow significantly and be used by far more people.\n  ''The rapid progress of A.I. will continue,'' said David Luan, the chief executive of Adept, an A.I. start-up. ''It is \ninevitable.''\n  OpenAI, Google and other tech companies are advancing A.I. far more quickly than other technologies because of \nthe way the underlying systems are built.\n  Most software apps are built by engineers, one line of computer code at a time, which is typically a slow and \ntedious process. Companies are improving A.I. more swiftly because the technology relies on neural networks, \nmathematical systems that can learn skills by analyzing digital data. By pinpointing patterns in data such as \nWikipedia articles, books and digital text culled from the internet, a neural network can learn to generate text on its \nown.\nA 'Leap Forward' for A.I. May Occur in 2024\n  This year, tech companies plan to feed A.I. systems more data -- including images, sounds and more text -- than \npeople can wrap their heads around. As these systems learn the relationships between these various kinds of data, \nthey will learn to solve increasingly complex problems, preparing them for life in the physical world.\n  (The New York Times sued OpenAI and Microsoft last month for copyright infringement of news content related to \nA.I. systems.)\n  None of this means that A.I. will be able to match the human brain anytime soon. While A.I. companies and \nentrepreneurs aim to create what they call ''artificial general intelligence'' -- a machine that can do anything the \nhuman brain can do -- this remains a daunting task. For all its rapid gains, A.I. remains in the early stages.\n  Here's a guide to how A.I. is set to change this year, beginning with the nearest-term advancements, which will \nlead to further progress in its abilities.\n  Instant Videos\n  Until now, A.I.-powered applications mostly generated text and still images in response to prompts. DALL-E, for \ninstance, can create photorealistic images within seconds off requests like ''a rhino diving off the Golden Gate \nBridge.''\n  But this year, companies such as OpenAI, Google, Meta and the New York-based Runway are likely to deploy \nimage generators that allow people to generate videos, too. These companies have already built prototypes of tools \nthat can instantly create videos from short text prompts.\n  Tech companies are likely to fold the powers of image and video generators into chatbots, making the chatbots \nmore powerful.\n  'Multimodal' Chatbots\n  Chatbots and image generators, originally developed as separate tools, are gradually merging. When OpenAI \ndebuted a new version of ChatGPT last year, the chatbot could generate images as well as text.\n  A.I. companies are building ''multimodal'' systems, meaning the A.I. can handle multiple types of media. These \nsystems learn skills by analyzing photos, text and potentially other kinds of media, including diagrams, charts, \nsounds and video, so they can then produce their own text, images and sounds.\n  That isn't all. Because the systems are also learning the relationships between different types of media, they will \nbe able to understand one type of media and respond with another. In other words, someone may feed an image \ninto chatbot and it will respond with text.\n  ''The technology will get smarter, more useful,'' said Ahmad Al-Dahle, who leads the generative A.I. group at \nMeta. ''It will do more things.''\n  Multimodal chatbots will get stuff wrong, just as text-only chatbots make mistakes. Tech companies are working to \nreduce errors as they strive to build chatbots that can reason like a human.\n  Better 'Reasoning'\n  When Mr. Altman talks about A.I.'s taking a leap forward, he is referring to chatbots that are better at ''reasoning'' \nso they can take on more complex tasks, such as solving complicated math problems and generating detailed \ncomputer programs.\n  The aim is to build systems that can carefully and logically solve a problem through a series of discrete steps, \neach one building on the next. That is how humans reason, at least in some cases.\nA 'Leap Forward' for A.I. May Occur in 2024\n  Leading scientists disagree on whether chatbots can truly reason like that. Some argue that these systems merely \nseem to reason as they repeat behavior they have seen in internet data. But OpenAI and others are building \nsystems that can more reliably answer complex questions involving subjects like math, computer programming, \nphysics and other sciences.\n  ''As systems become more reliable, they will become more popular,'' said Nick Frosst, a former Google researcher \nwho helps lead Cohere, an A.I. start-up.\n  If chatbots are better at reasoning, they can then turn into ''A.I. agents.''\n  'A.I. Agents'\n  As companies teach A.I. systems how to work through complex problems one step at a time, they can also \nimprove the ability of chatbots to use software apps and websites on your behalf.\n  Researchers are essentially transforming chatbots into a new kind of autonomous system called an A.I. agent. \nThat means the chatbots can use software apps, websites and other online tools, including spreadsheets, online \ncalendars and travel sites. People could then offload tedious office work to chatbots. But these agents could also \ntake away jobs entirely.\n  Chatbots already operate as agents in small ways. They can schedule meetings, edit files, analyze data and build \nbar charts. But these tools do not always work as well as they need to. Agents break down entirely when applied to \nmore complex tasks.\n  This year, A.I. companies are set to unveil agents that are more reliable. ''You should be able to delegate any \ntedious, day-to-day computer work to an agent,'' Mr. Luan said.\n  This might include keeping track of expenses in an app like QuickBooks or logging vacation days in an app like \nWorkday. In the long run, it will extend beyond software and internet services and into the world of robotics.\n  Smarter Robots\n  In the past, robots were programmed to perform the same task over and over again, such as picking up boxes that \nare always the same size and shape. But using the same kind of technology that underpins chatbots, researchers \nare giving robots the power to handle more complex tasks -- including those they have never seen before.\n  Just as chatbots can learn to predict the next word in a sentence by analyzing vast amounts of digital text, a robot \ncan learn to predict what will happen in the physical world by analyzing countless videos of objects being prodded, \nlifted and moved.\n  ''These technologies can absorb tremendous amounts of data. And as they absorb data, they can learn how the \nworld works, how physics work, how you interact with objects,'' said Peter Chen, a former OpenAI researcher who \nruns Covariant, a robotics start-up.\n  This year, A.I. will supercharge robots that operate behind the scenes, like mechanical arms that fold shirts at a \nlaundromat or sort piles of stuff inside a warehouse. Tech titans like Elon Musk are also working to move humanoid \nrobots into people's homes.\nhttps://www.nytimes.com/2024/01/08/technology/ai-robots-chatbots-2024.html\nGraphic\n \nA 'Leap Forward' for A.I. May Occur in 2024\nPHOTO: From left, Laurene Powell Jobs of Emerson Collective, Chris Cox of Meta, James Manyika of Google and \nSam Altman of OpenAI in San Francisco last year. (PHOTOGRAPH BY ERIC RISBERG/ASSOCIATED PRESS) \n(B4) This article appeared in print on page B1, B4.               \nLoad-Date: January 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "An Artist in Residence on A.I.’s Territory",
        "media": "The New York Times",
        "time": "December 31, 2023",
        "section": "TECHNOLOGY",
        "length": "1575 words",
        "byline": "Leslie Katz",
        "story_text": "An Artist in Residence on A.I.’s Territory\nThe New York Times \nDecember 30, 2023 Saturday 13:03 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1575 words\nByline: Leslie Katz\nHighlight: Alexander Reben is taking his tech-savvy perspective to OpenAI, a company that some in the art world \nbelieve is a threat to their future.\nBody\nAt a reception for OpenAI’s first developer conference in San Francisco last month, a crowd mingled, wine in hand, \nas withering criticism of art created with artificial intelligence flashed on a blue wall at the front of the room. “I’ve \nseen more engaging art from a malfunctioning printer,” one critic jabbed. “The fine-art equivalent of elevator music,” \nhuffed another. “Inoffensive, unmemorable and terminally dull.”\nIt might seem an odd strategy for OpenAI, the company behind widely used generative A.I. tools like ChatGPT and \nDALL-E, to promote scorn of A.I. art, until you catch the twist: A.I. itself wrote the criticism. Alexander Reben, the \nM.I.T.-educated artist behind the presentation, combined his own custom code with GPT-4, a version of the large \nlanguage model that powers the ChatGPT online chatbot.\nNext month, Mr. Reben, 38, will become OpenAI’s first artist in residence. He steps in as generative A.I. advances \nat a head-spinning rate, with artists and writers trying to make sense of the possibilities and shifting implications. \nSome regard artificial intelligence as a powerful and innovative tool that can steer them in weird and wonderful \ndirections. Others express outrage that A.I. is scraping their work from the internet to train systems without \npermission, compensation or credit.\nIn late November, a group of visual artists filed an amended copyright lawsuit against Stability AI, Midjourney and \nother makers of A.I. tools after a federal judge dismissed parts of the original complaint, which accused the \ncompanies of misusing the artists’ creations to train generative A.I systems. Mr. Reben said he couldn’t speak to \nthe specifics of A.I. and the law, “but like with any new creative technology, the law needs to catch up to the \nunpredictable future.”\n(The New York Times sued OpenAI and Microsoft for copyright infringement on Wednesday.)\nTech companies including Google, Autodesk and Microsoft have welcomed artists in residence. And for the last \nseveral years, artists have tested products like GPT and the DALL-E image generator, offering insight into the tools’ \ncreative potential before their public release. But the OpenAI residency, which is giving Mr. Reben a front-row view \nof the company’s work, is a first for the start-up that is at the center of the debate over art and A.I.\n“Alex is one of the first people we share our new models with,” said Natalie Summers, a spokeswoman for OpenAI.\nSam Altman, OpenAI’s chief executive, has long acknowledged that the technologies created by his company will \nchange the nature of art. But he insists that no matter how good the technology gets, artists — human artists — will \nalways matter.\nAn Artist in Residence on A.I.’s Territory\n“There was a real moment of fear where people asked, ‘Is this a tool we have built or a creature we have built?’” he \nsaid last month during an appearance in front of more than 300 artists and art lovers packed into an abandoned \nwarehouse in downtown Oakland, Calif. “People now view these things as a new set of tools.”\nAfter the digital artist Android Jones said at the event that many artists were still very angry over the rise of A.I. \nimage generators and the way it reduced the value of their own art, Mr. Altman said people would always seek art \ncreated by other people.\n“There is clearly going to be more competition,” he said. “But, awash in a sea of A.I.-generated art, that desire for \nhuman connection will go up, not down.”\nGe Wang, an associate director of Stanford’s Institute for Human-Centered Artificial Intelligence and an associate \nprofessor of music and computer science at the school’s Center for Computer Research in Music and Acoustics, \nwonders how receptive OpenAI will be to considering the tough questions about A.I.’s impact on art. What’s the \nright balance between machine output and human curation? Will the instantaneous results produced by the likes of \nDALL-E discourage people from developing the kinds of skills that require study and time?\n“Asking these questions is kind of bad for business, and OpenAI is a business,” Dr. Wang said. “You might have a \nwonderful artist there in residence asking questions. Are you willing to receive them?”\nNonetheless, Dr. Wang — who is also a musician and designed two music-making apps, Ocarina and Magic Piano, \nfor Apple’s iPhone — said he was heartened that Mr. Reben was open to engaging with the questions about A.I.’s \nimpact on the art community.\nMr. Reben said that as a technologist who had studied the impact of innovations like photography and recorded \nmusic on creativity, “I usually stay on the cautiously optimistic side.”\n“But like any other technology of the past, there are both sides to the coin,” he added.\nThe New York native moved to Berkeley, Calif., a decade ago to become director of technology and research at \nStochastic Labs, an incubator for creative scientists and engineers that is housed in a three-story 19th-century \nVictorian. Mr. Reben’s highly conceptual art lines the walls of the main hallway and fills work spaces packed with \nprinters, headphones, cables, capacitors, soldering supplies, and other bits and bobs.\nOn a rainy Thursday, Mr. Reben relaxed on a couch at Stochastic after a meeting at OpenAI to continue working \nout details of what he’ll do during the residency, which will last three months.\n“If I come out of it and make my art better, or even come up with some new questions or new directions to present \nto the world, that would be very valuable,” said Mr. Reben, who researched human-machine symbiosis as a \ngraduate student at the M.I.T. Media Lab, an interdisciplinary research center.\nThe residency overlaps with Mr. Reben’s first major retrospective, titled “AI Am I?” and on display through April at \nSacramento’s Crocker Art Museum. DALL-E and other image generators like Midjourney and Stability AI’s Stable \nDiffusion have captivated the internet by allowing anyone to instantly retrieve custom visual imagery simply by \ntyping a few words into a box. But while much A.I.-generated art exists as pixels, Mr. Reben often manifests \nphysical structures from ideas he hones with the help of artificial intelligence.\n“I like a lot of absurdity and humor in my work, even if the underpinning question is serious,” Mr. Reben said.\nOne sculpture at the exhibit presents six toilet plungers queued up like a bizarre police lineup. A.I.-generated text \non the wall placard explains that the work represents all that remains of the Plungers, an apocryphal ’70s art \ncollective. Its fake artists adhered to “plungism,” a fictional philosophy “wherein the mind of an artist is in a state of \nflux and able to be influenced by all things, even plungers.”\nAn Artist in Residence on A.I.’s Territory\nPlungism arose from Mr. Reben’s extensive back and forth with GPT-3: He’d enter a prompt (an input aimed at \nproducing a desired response), and then tinker with his favorite responses, sometimes feeding the edited language \nback to the A.I. until he landed on just the right wording.\nThen there’s “Dreams of the Cheese-Faced Gentleman,” which depicts a man whose face could be mistaken for a \nwheel of Swiss cheese. Mr. Reben worked with GPT-4 to find the right prompts to craft a compelling description of a \npainting, then fed the curated text into an image generator. He’s not a painter himself, so he commissioned one to \nmake the artwork.\nA large language model capable of ingesting both images and text then studied the painting and described it in \nlanguage that would fit in at any museum. “The combination of psychedelic surrealism and whimsicality lends the \npainting an air of playfulness, challenging the viewer to engage with the work’s complex layers of meaning,” the wall \nlabel reads.\nJanisy Lagrue, the A.I.-imagined name for the real-life painter who produced the oil on canvas, explained: “I use \ncheese because it is so perfect a symbol of the American dream. Cheese is a commodity, not a food. It is totally \nartificial, and it is delicious.”\nThe exhibit provokes more questions than answers, a reflection of Mr. Reben’s belief that as machines produce \nbetter outputs, humans need to ask better questions — about bias and ownership, among other things.\n“Given how young this creative tool is, much still needs to be solved, and confronting these problems falls on the \nshoulders of everyone involved, from its developers to its users,” Mr. Reben said. “The more people thinking about \nthese questions the better.”\nMr. Reben doesn’t profess to speak for all artists as OpenAI’s first artist in residence. But he does understand their \nconcerns. Artists and writers worry that A.I. could steal their jobs, but Dr. Wang of Stanford said the nervousness \nextended beyond the possibility of lost livelihood.\nThe fear is “not only are we going to be replaced as artists, it’s that we’ll be replaced by something far more \ngeneric, far less interesting,” he said. “Maybe generic is enough to make a ton of money.”\nCade Metz contributed reporting.\nCade Metz contributed reporting. \nPHOTOS: Alexander Reben’s work, right and bottom, combines A.I. technology with physical art. It is on display at \nthe Crocker Art Museum in Sacramento, center. (PHOTOGRAPHS BY ROZETTE HALVORSON FOR THE NEW \nYORK TIMES; GERARD VUILLEUMIER) (BU8); “Dreams of the Cheese-Faced Gentleman,” 2023, above, an oil \npainting by Alexander Reben based on an A.I.-generated image. A.I.-generated photos by Mr. Reben at the \nCrocker Art Museum, left. (PHOTOGRAPHS BY ROZETTE HALVORSON FOR THE NEW YORK TIMES; \nGERARD VUILLEUMIER) (BU9) This article appeared in print on page BU8, BU9.\nLoad-Date: December 31, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE",
        "media": "Wall Street Journal Abstracts",
        "time": "April 11, 2023",
        "section": "A; Pg. 12",
        "length": "26 words",
        "byline": "AFARIN BELLISARIO",
        "story_text": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE\nWall Street Journal Abstracts\nApril 8, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 12\nLength: 26 words\nByline: AFARIN BELLISARIO\nBody\nABSTRACT\nAfarin Bellisario letter responds to Peggy Noonan’s April 1 declarations column on dangers in generative artificial \nintelligence like OpenAI’s ChatGPT\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "AI Will Change the Quality, Accessibility of Digital Education",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 10, 2024",
        "section": "GBS 2024",
        "length": "376 words",
        "byline": "Team ET",
        "story_text": "AI Will Change the Quality, Accessibility of Digital Education\nEconomic Times (E-Paper Edition)\nFebruary 11, 2024 Sunday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: GBS 2024\nLength: 376 words\nByline: Team ET\nHighlight: GenAI could close the gap between average and high performers, he says\nBody\nJEFF MAGGIONCALDA CEO, Coursera\nNew Delhi: Access to digital education will be a gamechanger in unlocking India’s economic potential as generative \nartificial intelligence (GenAI) could provide a unique advantage for people here, Jeff Maggioncalda, CEO of \nedtech platform Coursera, said on Friday. There is a huge reskilling opportunity for generative AI, which can close \nthe gap between average and high performers, and reshape the world to make it a more equal place, Maggioncalda \nsaid. “For this to happen, people need access to education,” he added. \n “Covid laid the groundwork for online education as well as remote work opportunities,” Maggioncalda said. \n“Generative AI could be a great equalising force, and provide a unique advantage for the people of India.”  He \nadded that AI will not just create the need for upskilling, but it will also change the quality and accessibility of \neducation globally, making learning far more effective as well as more affordable. “It used to cost us $10,000 to \ntranslate one course into a different language, now it costs us $20 – that’s the kind of impact AI can have,” \nMaggioncalda said.  “We have translated 4,200 courses into roughly 20 different languages, so language will no \nlonger be the obstacle for people wanting to access high quality education.”  The Coursera CEO further added that \nIndia will lead other countries in terms of learner numbers in online courses in a couple of years, if it keeps up the \ncurrent pace of growth.  “Out of our 140 million learners (on Coursera), we have 23.4 million learners in India, which \nis only second to the US in terms of number of learners,” he said. Globally, only 41% of people who complete high \nschool go on to start college; in India, this figure stands at 27%.  The National Education Policy 2020 aims to \nincrease the gross enrolment ratio to 50% by 2035, and access to digital education will be key to this objective.  \nCoursera has launched a GenAI academy in order to assist businesses in training employees, as well as a career \nacademy to help organisations reskill and redeploy their staff.  “Companies are looking to India for their future \nworkforce, so the key here is talent agility and how fast talent can move to seize the opportunities,” Maggioncalda \nsaid.\nLoad-Date: February 10, 2024"
    },
    {
        "file_name": "Ask_HR_Aug2023",
        "header": "Will AI take over the world? How to stay relevant if it begins replacing jobs.",
        "media": "Ask HR",
        "time": "August 22, 2023",
        "section": "MERGERS AND ACQUISITIONS NEWS & HUMAN RESOURCES NEWS",
        "length": "727 words",
        "byline": "Johnny C. Taylor Jr.",
        "story_text": "Will AI take over the world? How to stay relevant if it begins replacing jobs. \nAsk HR\nUSA Today Online\nAugust 22, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: MERGERS AND ACQUISITIONS NEWS & HUMAN RESOURCES NEWS\nLength: 727 words\nByline: Johnny C. Taylor Jr.\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader’s Guide to Work in an Age of Upheaval.”\nHave a question? Submit it here.\nQuestion: With the proliferation of generative AI, I am worried about being replaced. Do you expect the \nadditional productivity AI creates to displace workers? What can I do to ensure I am seen as a valued \nemployee? – Whitney\nAnswer: I can understand why you, or any of us, may be apprehensive about being displaced by artificial \nintelligence! New research reveals that nearly one-quarter (23%) of U.S. workers are concerned that workplace \nautomation will replace their job in the next five years. Workplace automation has already impacted nearly 10% of \nU.S. workers. AI may displace some jobs, but it is just as likely to result in the creation of new jobs too. Remember \nthat AI is designed to help us, not to replace human connection. AI isn’t all-encompassing; it has its limits. Work will \nalways need the human component because what we create and produce ultimately serves other humans. \nEven before AI existed, there have always been steps employees could take to demonstrate their value to their \norganization. That will not change. For instance, you can take on new assignments or projects and volunteer to help \nwherever needed. Do more than asked and do it well. And be on the lookout for more efficient or cost-effective \nways of doing things in your job.\nIt’s also essential to continue to learn and grow your skills by taking classes, receiving training, or taking advantage \nof other professional development opportunities. Be a problem solver and share your ideas with your manager.\nMake no mistake, AI will be a reality. We can choose to run from it and limit our opportunities and growth or \nembrace it to expand our performance, productivity and potential. Careers aren’t linear, so our skill sets shouldn’t \nbe static. The world of work will need people to develop the knowledge and expertise to manage, monitor and \nmeasure the output of AI. Explore how AI may be relevant in your role and career. Be proactive and talk with your \nsupervisor about AI and how to better serve customers, clients and the organization.\nAI is not going anywhere anytime soon, so now is a pivotal time for us to figure out how to leverage AI to our \nadvantage. Don’t let fear of technology blind you to the opportunities it presents for your growth and advancement. \nJob search How deep should I go when discussing a contentious job separation? Ask HR\nMean boss? Here's how to deal with a difficult or toxic manager: Ask HR\nWill AI take over the world? How to stay relevant if it begins replacing jobs. Ask HR\nHow will my lack of a formal university degree affect my chances of obtaining a new position in the HR \nfield, despite having 15 years of experience as an HR generalist and director and certifications? – Kelley\nThe challenges you face may depend on the level of HR job you are interested in. Sometimes higher-level HR jobs \nrequire a degree, but not always. Your substantial experience, along with your certifications, can offset not having a \ndegree. Research suggests 9 out of 10 employers report being ready to accept candidates without a four-year \ncollege degree. In addition, the study also found 66% of employers are open to hiring candidates with a recognized \ncertification.\nOnce you identify a position of interest, review the minimum position requirements. The job posting may list a \ndegree, but if it also includes the words “desired” or “preferred,” then the degree is not a requirement. Tailor your \nresume specific to the job you are applying for and highlight how your experience directly matches what the \ncompany is looking for, such as the skills, knowledge, and abilities to perform certain HR functions. And highlight \nyour achievements in 15 years of HR experience that have been impactful in your previous and current \norganizations.\nEven if a degree is required, apply for it. What do you have to lose? You can include in your cover letter why you \nfeel you are the best candidate for the job, despite not having a degree.\nI hope these suggestions will help you land your next dream job! Best wishes.\nThis article originally appeared on USA TODAY: Will AI take over the world? How to stay relevant if it begins \nreplacing jobs. Ask HR\nLoad-Date: August 22, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Agri LLM Dhenu 1.0 on pilot to seed a new AI revolution",
        "media": "The Economic Times",
        "time": "January 15, 2024",
        "section": "STARTUPS",
        "length": "1009 words",
        "byline": "Suraksha P",
        "story_text": "Agri LLM Dhenu 1.0 on pilot to seed a new AI revolution\nThe Economic Times\nJanuary 15, 2024 Monday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 1009 words\nByline: Suraksha P\nBody\nFour-year-old agricultural AI startup Kissan AI’s founder Pratik Desai last month unveiled Dhenu 1.0, a seven billion \nparameter large language model for agriculture.Named after Kamadhenu, a divine bovine-goddess described in \nHinduism as the mother of all cows, the model is trained on high-quality conversational datasets, specially focused \non Indian agriculture practices. Dhenu is an agricultural LLM specifically designed to help Indian farmers with \nagriculture-related questions.Designed to be bilingual, it has been trained on 300,000 instruction sets in English and \nHindi.“Our goal was to develop an AI/ML application that can be used by farmers. Throughout our journey we have \nexperimented with building different tools and have been expanding our knowledge base,” Desai told ET in an \ninteraction on January 3.In March last year, the company launched KissanAI, a voice-to-voice end-to-end chatbot \nfor farmers in 10 Indian languages. Farmers could talk in their own language and get queries answered on \nagriculture inputs, package of practices for different crops, fertilisers and pesticides.Desai realised that for his \nsolution to be scalable and reach farmers, it had to be cheap even though the cost of running on GPUs was \nexpensive for him.“Our goal was to build a small model based on more than 355,000 agriculture conversations we \nhad had with more than 100,000 farmers, and voice or text datasets we had collected on our KissanAI platform,” he \nsaid.Sarvam AIAfter AI startup Sarvam AI \nunveiled its Hindi LLM OpenHathi, KissanAI collaborated with them. The datasets were trained on OpenHathi and \nfine-tuned. “This reduced our cost four times. It also helped in terms of latency,” he said. Desai plans to add other \nlanguage datasets to his model gradually.Agriculture datasetsSome of the datasets were sourced from pictures of \nbooklets or pamphlets with agricultural information. So, the firm used optical character recognition to digitise the text \nand worked on data annotation and curation. They collaborated with three agricultural universities to get the \nterminologies correct.KissanAI also signed an agreement with Navsari University in Gujarat for knowledge transfer. \nThey also sought help from those working in a university in Jamnagar and Anand Agricultural University for doubts \nin areas like animal husbandry or horticulture. They collected open data from 30 academic institutes.Several \nacronyms had to be expanded to proper names of seeds, fertilisers and pesticides for the data to be used for \ntraining. “Geographical diversity was another challenge. A question about paddy from Kerala may have different \nanswers for other parts of India due to the difference in practices,” he explained.Currently, Dhenu is under testing \nand evaluation. “When we go from 300,000 to a million instructions, we are confident of having a high-quality model \nand agriculture companies can integrate with this model,” he said.The problem statementEvery agricultural \nuniversity has a mandate to provide a package of practices for different varieties of crops in their area to be given to \nthe farmers. Hence, they create booklets or printouts with the information. The biggest problem is illiteracy among \nfarmers. They cannot read or they do not have access to universities to read these booklets and solve their \nproblems.“We collect them and proofread them. We process, contextualise and correct the semantics, and translate \nthem. This can be a standard advisory on seed preservation,” he said.UsageDesai said that he will create a \npremium model of Dhenu and provide limited access. “We will open source the current version and train a premium \nversion and create an API-usage based model,” he said. So, if one wants to integrate with the model, they may use \nthe premium version.Once Dhenu is ready, it will replace the GPT 3.5 that is currently the base of KissanAI \nAgri LLM Dhenu 1.0 on pilot to seed a new AI revolution\nchatbot.“We will add market analysis to the KissanAI interface so that farmers can start directly asking via voice \nqueries. What is the average price in the nearest mandi? What was the price last month? We can even add weather \ndata to this. They can enquire about policies, schemes and equipment details. This is how the chatbot experience \nwill be expanded,” he explained.Although Dhenu is about India-specific agriculture, Desai is already getting queries \nfrom Africa, South America and Indonesia.“Our goal is to start from here and start having versions for different \ncountries. If this can work for India’s geography, diversity, weather, climate and languages, then mostly it will work \nfor other countries that are monolithic. Agriculture datasets in other countries like the US may be more digitised \ncompared to our country,” he said.Partnership with UNDPKissanAI, on January 5, announced partnering with the \nUnited Nations Development Programme to develop a vernacular co-pilot for climate resilient agriculture practices \ntargeting rural, smallholder and women farmers.\"We are excited to bring generative AI to remote corners of India \nand then the world. We are targeting rural and mostly illiterate farmers so voice in their language can enable them \nto get information. The goal is to focus on women farmers,\" Desai told ET.BackgroundSon of a farmer, Desai heads \na technology team with engineers, those who do data curation and data science, and almost all members have an \nagriculture background.“One common thread that binds us is an agriculture background. Barring one, all our fathers \nare farmers. The benefit is to understand any part of agriculture, we can just call our fathers,” Desai said.He said \nuntil he turned 21 and moved to the US to pursue his post graduate programme and PhD, he helped his father \nfarm. “We used to grow tur dal, bajra, sugarcane and castor in Surat. Our farms are in Surat and so is our \ntechnology team,” he said.He worked on three startups before jumping into agriculture technology. Since 2019, he \nhas been working full time on Indian agriculture technology while being based in San Francisco along with his \nfamily. For Reprint Rights: timescontent.com\nLoad-Date: January 15, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Nvidia’s Big Tech Rivals Put Their Own A.I. Chips on the Table",
        "media": "The New York Times",
        "time": "January 30, 2024",
        "section": "TECHNOLOGY",
        "length": "1338 words",
        "byline": "Cade Metz, Karen Weise and Mike Isaac &lt;p&gt;Cade Metz writes about artificial intelligence, driverless",
        "story_text": "Nvidia’s Big Tech Rivals Put Their Own A.I. Chips on the Table\nThe New York Times \nJanuary 29, 2024 Monday 12:58 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1338 words\nByline: Cade Metz, Karen Weise and Mike Isaac &lt;p&gt;Cade Metz writes about artificial intelligence, driverless \ncars, robotics, virtual reality and other emerging areas of technology.&lt;/p&gt; &lt;p&gt;Karen Weise writes about \ntechnology and is based in Seattle. Her coverage focuses on Amazon and Microsoft, two of the most powerful \ncompanies in America.&lt;/p&gt; &lt;p&gt;Mike Isaac is a technology correspondent for The Times based in San \nFrancisco. He regularly covers Facebook and Silicon Valley.&lt;/p&gt;\nHighlight: Chafing at their dependence, Amazon, Google, Meta and Microsoft are racing to cut into Nvidia’s \ndominant share of the market.\nBody\nChafing at their dependence, Amazon, Google, Meta and Microsoft are racing to cut into Nvidia’s dominant share of \nthe market.\nIn September, Amazon said it would invest up to $4 billion in Anthropic, a San Francisco start-up working on \nartificial intelligence.\nSoon after, an Amazon executive sent a private message to an executive at another company. He said Anthropic \nhad won the deal because it agreed to build its A.I. using specialized computer chips designed by Amazon.\nAmazon, he wrote, wanted to create a viable competitor to the chipmaker Nvidia, a key partner and kingmaker in \nthe all-important field of artificial intelligence.\nThe boom in generative A.I. over the last year exposed just how dependent big tech companies had become on \nNvidia. They cannot build chatbots and other A.I. systems without a special kind of chip that Nvidia has mastered \nover the past several years. They have spent billions of dollars on Nvidia’s systems, and the chipmaker has not \nkept up with the demand.\nSo Amazon and other giants of the industry — including Google, Meta and Microsoft — are building A.I. chips of \ntheir own. With these chips, the tech giants could control their own destiny. They could rein in costs, eliminate chip \nshortages and eventually sell access to their chips to businesses that use their cloud services.\nWhile Nvidia sold 2.5 million chips last year, Google spent $2 billion to $3 billion building about a million of its own \nA.I. chips, said Pierre Ferragu, an analyst at New Street Research. Amazon spent $200 million on 100,000 chips \nlast year, he estimated. Microsoft said it had begun testing its first A.I. chip.\nBut this work is a balancing act between competing with Nvidia while working closely with the chipmaker and its \nincreasingly powerful chief executive, Jensen Huang.\nMr. Huang’s company accounts for more than 70 percent of A.I. chip sales, according to the research firm Omdia. It \nsupplies an even larger percentage of the systems used in the creation of generative A.I. Nvidia’s sales have shot \nup 206 percent over the past year, and the company has added about a trillion dollars in market value.\nNvidia ’s Big Tech Rivals Put Their Own A.I. Chips on the Table\nWhat’s revenue to Nvidia is a cost for the tech giants. Orders from Microsoft and Meta made up about a quarter of \nNvidia’s sales in the past two full quarters, said Gil Luria, an analyst at the investment bank D.A. Davidson.\nNvidia sells its chips for about $15,000 each, while Google spends an average of just $2,000 to $3,000 on each of \nits own, according to Mr. Ferragu.\n“When they encountered a vendor that held them over a barrel, they reacted very strongly,” Mr. Luria said.\nCompanies constantly court Mr. Huang, jockeying to be at the front of the line for his chips. He regularly appears on \nevent stages with their chief executives, and the companies are quick to say they remain committed to their \npartnerships with Nvidia. They all plan to keep offering its chips alongside their own.\nWhile the big tech companies are moving into Nvidia’s business, it is moving into theirs. Last year, Nvidia started its \nown cloud service where businesses can use its chips, and it is funneling chips into a new wave of cloud providers, \nsuch as CoreWeave, that compete with the big three: Amazon, Google and Microsoft.\n“The tensions here are a thousand times the usual jockeying between customers and suppliers,” said Charles \nFitzgerald, a technology consultant and investor.\nNvidia declined to comment.\nThe A.I. chip market is projected to more than double by 2027, to roughly $140 billion, according to the research \nfirm Gartner. Venerable chipmakers like AMD and Intel are also building specialized A.I. chips, as are start-ups \nsuch as Cerebras and SambaNova. But Amazon and other tech giants can do things that smaller competitors \ncannot.\n“In theory, if they can reach a high enough volume and they can get their costs down, these companies should be \nable to provide something that is even better than Nvidia,” said Naveen Rao, who founded one of the first A.I. chip \nstart-ups and later sold it to Intel.\nNvidia builds what are called graphics processing units, or G.P.U.s, which it originally designed to help render \nimages for video games. But a decade ago, academic researchers realized these chips were also really good at \nbuilding the systems, called neural networks, that now drive generative A.I.\nAs this technology took off, Mr. Huang quickly began modifying Nvidia’s chips and related software for A.I., and they \nbecame the de facto standard. Most software systems used to train A.I. technologies were tailored to work with \nNvidia’s chips.\n“Nvidia’s got great chips, and more importantly, they have an incredible ecosystem,” said Dave Brown, who runs \nAmazon’s chip efforts. That makes getting customers to use a new kind of A.I. chip “very, very challenging,” he \nsaid.\nRewriting software code to use a new chip is so difficult and time-consuming, many companies don’t even try, said \nMike Schroepfer, an adviser and former chief technology officer at Meta. “The problem with technological \ndevelopment is that so much of it dies before it even gets started,” he said.\nRani Borkar, who oversees Microsoft’s hardware infrastructure, said Microsoft and its peers needed to make it \n“seamless” for customers to move between chips from different companies.\nAmazon, Mr. Brown said, is working to make switching between chips “as simple as it can possibly be.”\nSome tech giants have found success making their own chips. Apple designs the silicon in iPhones and Macs, and \nAmazon has deployed more than two million of its own traditional server chips in its cloud computing data centers. \nBut achievements like these take years of hardware and software development.\nNvidia ’s Big Tech Rivals Put Their Own A.I. Chips on the Table\nGoogle has the biggest head start in developing A.I. chips. In 2017, it introduced its tensor processing unit, or \nT.P.U., named after a kind of calculation vital to building artificial intelligence. Google used tens of thousands of \nT.P.U.s to build A.I. products, including its online chatbot, Google Bard. And other companies have used the chip \nthrough Google’s cloud service to build similar technologies, including the high-profile start-up Cohere.\nAmazon is now on the second generation of Trainium, its chip for building A.I. systems, and has a second chip \nmade just for serving up A.I. models to customers. In May, Meta announced plans to work on an A.I. chip tailored to \nits needs, though it is not yet in use. In November, Microsoft announced its first A.I. chip, Maia, which will focus \ninitially on running Microsoft’s own A.I. products.\n“If Microsoft builds its own chips, it builds exactly what it needs for the lowest possible cost,” Mr. Luria said.\nNvidia’s rivals have used their investments in high-profile A.I. start-ups to fuel use of their chips. Microsoft has \ncommitted $13 billion to OpenAI, the maker of the ChatGPT chatbot, and its Maia chip will serve OpenAI’s \ntechnologies to Microsoft’s customers. Like Amazon, Google has invested billions in Anthropic, and it is using \nGoogle’s A.I. chips, too.\nAnthropic, which has used chips from both Nvidia and Google, is among a handful of companies working to build \nA.I. using as many specialized chips as they can get their hands on. Amazon said that if companies like Anthropic \nused Amazon’s chips on an increasingly large scale and even helped design future chips, doing so could reduce \nthe cost and improve the performance of these processors. Anthropic declined to comment.\nBut none of these companies will overtake Nvidia anytime soon. Its chips may be pricey, but are among the fastest \non the market. And the company will continue to improve their speed.\nMr. Rao said his company, Databricks, trained some experimental A.I. systems using Amazon’s A.I. chips, but built \nits largest and most important systems using Nvidia chips because they provided higher performance and played \nnicely with a wider range of software.\n“We have many years of hard innovation ahead of us,” Amazon’s Mr. Brown said. “Nvidia is not going to be \nstanding still.”\nPHOTO:  (PHOTOGRAPH BY Chris Gash FOR THE NEW YORK TIMES)\nLoad-Date: January 30, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi:From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "AI is a Global Issue, We Need a Global Approach to Govern It",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 10, 2024",
        "section": "GBS 2024",
        "length": "696 words",
        "byline": "Team ET",
        "story_text": "AI is a Global Issue, We Need a Global Approach to Govern It\nEconomic Times (E-Paper Edition)\nFebruary 11, 2024 Sunday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: GBS 2024\nLength: 696 words\nByline: Team ET\nHighlight: India has the key ingredients to become one of the world leaders in artificial intelligence\nBody\nJASON KWON Chief Strategy Officer, OpenAI\nNew Delhi: Countries and global institutions must work together to harmonise efforts to tackle issues around \nartificial intelligence (AI), and India has a major part to play in this conversation, OpenAI chief strategy officer Jason \nKwon said on Saturday. “AI is a global issue, and we need a global approach to govern it,” he said. Countries have \nhistorically come together to address problems of health, trade and natural resources, he said, adding that they now \nhave to similarly join forces through institutions that underpin the international order and rule of law to coordinate in \nthe matter of AI governance. “We want to work closely with you to figure out a path forward,” he said. \nKwon also announced that OpenAI will hold a number of developer summits in India this year. It plans to foster \ncollaboration between Silicon Valley developers and local developers that will “put us on a path for building the tools \nand define our future”. “Our plan is to convene developers around the country to work alongside OpenAI’s product \nleaders on some of the most difficult challenges in AI,” he said. Kwon said the country has the world’s largest \ndeveloper community, some of the most impressive talent in the field, a track record of developing extraordinary \ntechnology businesses and a relentless focus on competing on the world stage. “India has the key ingredients of \nbeing one of the world's leaders in AI,” he said, adding that OpenAI wants to continue to invest in the developer \ncommunity here. OpenAI, he said, also understood the role that ChatGPT can play in closing one of the main \nbarriers in the startups segment –the demand for code. “Startups understand market gaps and build innovative \nproducts to fill them. Tools like ChatGPT help accelerate startups and unlock new ones in several ways,” Kwon \nsaid. On his India visit, he will be meeting with entrepreneurs who are creating AIpowered products that will enable \nIndia to experience the value of the technology, he said. In the private sector, AI can make completing tasks 25% \nfaster and improve quality by 40%, Kwon said, citing research. It reduces the cost of intelligence by making writing \ncode faster, freeing up engineersfor other tasks, and simplifies computing interfaces and makes them more \naccessible globally, he said. “When you break down these barriers,you can make it possible to access more \nservices that are critical to human welfare in the digital age,” he said. He also said that unlocking the potentialof AI \nrequires an “intense focus” on safety and that safety and product development are intertwined rather than separate. \n“AI safety must be globalised,” Kwon said, adding that safety features must be ensured across countries and \nlanguages. OpenAI has seen “promising early results” with a safeguarding tool it is developing ahead of elections in \nseveral countries such as the US and India to address fake or inaccurate images, he said. More than a year after \nthe introduction of OpenAI’s generative AI platform ChatGPT to the world, its transformative power has become \nvisible, according to Kwon. He said ChatGPT has helped people experience AI not as behind-the-scenes \nabstraction but as a real and tangible tool. It has helped people solve real problems in previously unimaginable \nways, he said, adding that around 90% of Fortune 500 companies now build using OpenAI products. “Reducing \nlanguage barriers like this is one of the superpowers of large language models,” Kwon said, pointing to GPT-\nAI is a Global Issue, We Need a Global Approach to Govern It\npowered farmer chatbot by Digital Green, which helps farmers in multiple languages to navigate climate change, \nimplement best practices and bring their crops to market.  The bot delivers information in languages including Hindi, \nKannada and Assamese, and reduces the cost of traditional extension services by 99%, Kwon said. Large \nlanguage models can also build on the Indian government’s national language translation initiative Bhashini, he \nsaid. In the field of healthcare, ChatGPT has been used by the Bill and Melinda Gates Foundation to facilitate \ncommunication with frontline workers to improve care for pregnant and postpartum women. Kwon said.\nLoad-Date: February 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Amazon Takes a Big Stake in the A.I. Start-Up Anthropic",
        "media": "The New York Times",
        "time": "September 26, 2023",
        "section": "TECHNOLOGY",
        "length": "675 words",
        "byline": "Adam Satariano and Cade Metz",
        "story_text": "Amazon Takes a Big Stake in the A.I. Start-Up Anthropic\nThe New York Times \nSeptember 25, 2023 Monday 13:23 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 675 words\nByline: Adam Satariano and Cade Metz\nHighlight: With its investment of up to $4 billion, Amazon is seeking a bigger footprint in A.I. development, one \nalready established by rivals like Microsoft and Google.\nBody\nWith its investment of up to $4 billion, Amazon is seeking a bigger footprint in A.I. development, one already \nestablished by rivals like Microsoft and Google.\nAmazon said on Monday that it would invest up to $4 billion in the artificial intelligence start-up Anthropic, as the \nworld’s biggest technology companies race to benefit from A.I. breakthroughs that could reshape parts of their \nbusinesses — and the economy as a whole.\nAmazon is trying to keep pace with rivals such as Microsoft and Google, which have each poured billions of dollars \ninto A.I. research. Anthropic, seen as one of the most promising of a batch of A.I. start-ups, will use Amazon’s data \ncenters, cloud-computing platform and A.I. chips.\nThe deal underscores the frenzy to be at the forefront of A.I., a technology that has seized the public’s imagination \nand has the power to potentially transform the way people work and live. As part of that race, tech giants have been \nteaming with up-and-coming A.I. start-ups by providing them with computing power and cash to help them develop \nnew models and applications. Google has also invested in Anthropic, while Microsoft has poured $13 billion into \nOpenAI, the maker of ChatGPT.\nAmazon’s investment of up to $4 billion would give it a minority stake in Anthropic, it said.\nLike OpenAI, Anthropic is a developer of so-called generative A.I., the technology capable of learning from vast \namounts of data to create humanlike texts and images. These tools are seen as possessing the potential to \nautomate many tasks, reshaping aspects of the global economy.\nAnthropic, which operates a chatbot called Claude, has sought to position itself as one of the industry’s more \nresponsible actors. Its executives have warned that A.I. could cause tremendous damage to society if not \ndeveloped carefully. The company’s co-founder Jack Clark attended a recent meeting on Capitol Hill to discuss A.I. \npolicy, including the risks and potential of the rapidly evolving technology.\nWorking with Anthropic also helps Amazon, which is competing against Microsoft and Google in cloud computing \nand has been trying to establish itself more deeply in artificial intelligence. Amazon is also battling Nvidia as a \nprovider of the chips needed to run complex A.I. systems. \nThe huge amounts of money and computing power needed to run A.I. models have made it nearly impossible for \nsmaller companies to remain independent from established tech giants with deep pockets.\nAmazon Takes a Big Stake in the A.I. Start-Up Anthropic\nAnthropic’s partnership with Amazon is also another example of a new kind of circular business arrangement that \ncan be mutually beneficial to both cloud computing companies and A.I. start-ups.\nAnthropic will pump much of the money it’s raising from Amazon back into the company as it pays for time on the \nmassive clusters of computer servers operated by the Seattle tech giant. So while Amazon is making a strategic \ninvestment in a start-up, it is also feeding its own cloud-computing business, which now accounts for more than 70 \npercent of its profits.\nMicrosoft first created this kind of deal with OpenAI in 2019. In recent months, other cloud computing companies, \nincluding Google and Oracle, have made similar arrangements with ambitious A.I. start-ups.\nWhile Microsoft and Google have also launched their own online chatbots in the months since OpenAI unveiled \nChatGPT, Amazon has not followed suit. Instead, it has worked to provide various tools for companies and \nindependent developers looking to build their own chatbots and other A.I. technologies.\nIn addition to boosting its cloud computing revenues, Amazon’s agreement with Anthropic could raise its profile in \nthe field and fuel the development of new A.I. technologies inside the tech giant.\n“We can help improve many customer experiences, short- and long-term, through our deeper collaboration,” Andy \nJassy, Amazon’s chief executive, said in a statement.\nPHOTO: Anthropic is seen as one of the most promising of a batch of A.I. start-ups. (PHOTOGRAPH BY MARISSA \nLESHNOV FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: September 26, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "India's compute infrastructure deficit hinders AI potential: Nvidia executive",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "TECH & INTERNET",
        "length": "462 words",
        "byline": "Annapurna Roy",
        "story_text": "India's compute infrastructure deficit hinders AI potential: Nvidia executive\nThe Economic Times\nMarch 19, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 462 words\nByline: Annapurna Roy\nBody\nIndia has under 2% of the world’s $1 trillion worth of compute infrastructure, which is several times less than \ncountries like the US and China which together have nearly 60%, a top Nvidia executive said on Monday. At the \nsame time, there is an opportunity for India to become the ‘AI (artificial intelligence) factory of the world' as more \nand more infrastructure becomes available in the country.“If we can basically build the infrastructure in accelerated \ncomputing quickly and faster, research will happen, innovation will happen, and more importantly, you will add $1 \ntrillion to the economy,” said Vishal Dhupar, managing director for South Asia at global processing unit (GPU) \nmaking giant Nvidia.Speaking at the Startup Mahakumbh in the national capital, Dhupar highlighted that India \ncontributes only about 2% of the world’s AI research, and that the paucity of compute infrastructure is the key \ndeterminant.“There's a direct correlation to that,” Dhupar said. “Indians who contribute to the research but are not \nbased in India are contributing 12% of AI research, because there's infrastructure available there. \nI think that itself signals why infrastructure is really, really important.”While the US and China each earmark about \n4% of their GDP towards research through infrastructure, India spends only a percent, he noted.The government’s \nrecent announcement regarding the India AI Mission, where it will invest in 10,000 GPUs to make compute more \naccessible, is a ‘great start’, Dhupar said.“But more importantly than that, the Indian business houses have figured \nout that now, computing is not about data centres, but converting data centres into compute units that will produce \nintelligence. In other words, it's becoming factories.”This gives India the opportunity to go from being the ‘back \noffice of the world’ to ‘the office of the world’.Codifying Indic languages and culture in large language models (LLM) \nis also a ‘mammoth opportunity’ for India, Dhupar said.Vision and good research are important for India to fulfil its \nAI ambitions, and for the latter, adequate infrastructure availability is ‘in progress’, Dhupar said, pointing to Nvidia’s \nrecent partnership with data centre company Yotta Data Services to bring 16,000 GPUs to India.“We're going to \nalso work with more business houses to bring it (compute infrastructure) here and cater for the sensitivities of this \ncountry, helping you to innovate and build here so that you can maximise the disruption that is needed in our \ncountry and hopefully add the trillion dollars,” he added.Dhupar said that the Nvidia Inception programme for \nstartups has over 1,600 Indian startups in its fold, of which over 400 are AI startups and 60 are generative AI \nstartups. For Reprint Rights: timescontent.com\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "Vin_Feb2024",
        "header": "GenAI set to move from hype to value as projects go live: TCS CTO Harrick",
        "media": "Vin",
        "time": "February 27, 2024",
        "section": "TECH & INTERNET",
        "length": "670 words",
        "byline": "Beena Parmar and Surabhi Agarwal",
        "story_text": "GenAI set to move from hype to value as projects go live: TCS CTO Harrick \nVin\nThe Economic Times\nFebruary 27, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 670 words\nByline: Beena Parmar and Surabhi Agarwal\nBody\nSeveral experimental generative artificial intelligence (GenAI) projects are expected to go live this year, helping \nclients drive greater value from the technology, Harrick Vin, chief technology officer, Tata Consultancy Services \n(TCS), told ET. “We are currently engaged in over 250 different projects in various categories, but they are all \nmainly in assist and augment categories,” said Vin, who took over the role in July. Assist is to improve the \ncontextual awareness, while augment is to help organisations do the work slightly faster or slightly better, he said. \n“(In) 2024, we will start seeing a lot of those early experimental things sort of starting to go live,” he added. \nOnce the projects go live, companies will come to the eventual goal of converting those projects to derive greater \nvalue beyond the initial focus of productivity. Although he pointed out, “it is a marathon, not a sprint. It (shift) will \ntake many years.”TCS is infusing Gen AI and intelligence across almost all layers of the company, he said.A TCS \nfellow, Vin has been with the Tata group since 2005 joining as vice president and chief scientist and took charge as \nthe CTO of India’s largest IT services firm in July last year. With the onset of Gen AI, Vin has also seen the role of \nCTOs fundamentally changing from thinking about technologies to thinking about business redefinition. “It is all \nabout how you apply technology to completely redefine the future of every type of work whether the future of \nmarketing…future of sales, future of software engineering…all will be very different,” he said. With the rate of \ntechnology change being very fast-paced, Vin believes it is not a one-time quantum jump but is going to be \ncontinuous and significant changes that businesses will see over the next decade or so. “That means continuously \ncoming up with what I would call as next practices as opposed to best practices. And the only way any organization, \nany industry is going to differentiate themselves is by continuously defining the next practice because otherwise \neverybody is going to catch up and the pace of innovation is accelerating. That is perhaps the biggest challenge of \nthe current era that we are living in,” Vin added.TCS, the Mumbai-headquartered over-$30 billion-sized technology \nmajor of Tata group, is already working on several meaningful projects and engagements around Gen AI with some \nlarge global firms including a leading European bank, a US-based airline and an insurance firm, as part of the 250 \nAI-powered projects. Further, with the latest partnership with one of the most valuable global technology companies \ntoday, Nvidia, TCS is also getting its people trained to understand the Nvidia stack and build applications on that. \n“Then it goes back to this problem of what are these kinds of industry wise, enterprise wise and activity wise, these \npurposive agents or models we want to start building on. And then running it on an infrastructure that is built with \nthe Tata group-Nvidia partnership and so on,” Vin stated.TCS has already stated it will be utilizing the AI \ninfrastructure and capabilities to build and process generative AI applications, while also upskilling 6,00,000 TCS \nemployees. It has already trained over 150,000 employees in Gen AI capabilities in the past seven months and \naims to further reskill and upskill more of its workforce. TCS has found three initial use cases. First is “assist use-\ncases” around customer teams such as call centres, etc to understand the kind of products customers have bought, \nthe number and kind of repeat customers, their conversations around the products and whether they have happy \ncustomers or not. Second category is “augment use-cases” to understand what a work machine can do partly or \nwholly to auto generate test cases, scripts for doing deployment or auto generated code, etc. And the third category \nGenAI set to move from hype to value as projects go live: TCS CTO Harrick Vin\nis “transform use-cases” that says how businesses can redefine business functions or processes for the future. For \nReprint Rights: timescontent.com\nLoad-Date: February 27, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Meta, Long an A.I. Leader, Tries Not to Be Left Out of the Boom",
        "media": "The New York Times",
        "time": "February 23, 2023",
        "section": "TECHNOLOGY",
        "length": "1417 words",
        "byline": "Cade Metz and Mike Isaac",
        "story_text": "Meta, Long an A.I. Leader, Tries Not to Be Left Out of the Boom\nThe New York Times \nFebruary 7, 2023 Tuesday 17:38 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1417 words\nByline: Cade Metz and Mike Isaac\nHighlight: It has long had technology to rival chatbots like ChatGPT, but can’t afford to back artificial intelligence \nthat can spread misinformation and toxic content.\nBody\nIt has long had technology to rival chatbots like ChatGPT, but can’t afford to back artificial intelligence that can \nspread misinformation and toxic content.\nSAN FRANCISCO — Two weeks beforea chatbot called ChatGPT appeared on the internet in November and \nwowed the world, Meta, the owner of Facebook, WhatsApp and Instagram, unveiled a chatbot of its own.\nCalled Galactica, it was designed for scientific research. It could instantly write its own articles, solve math \nproblems, generate computer code and annotate images.\nLike ChatGPT, Galactica also played fast and loose with facts, making up mathematical proofs, misstating historical \ndates and spinning tall tales. One user coaxed the chatbot into talking about the history of bears in space. When \nasked who runs Silicon Valley, Galactica replied, “Steve Jobs.”\nBut unlike OpenAI, the tiny San Francisco lab that made ChatGPT, Meta encountered an avalanche of complaints \nabout Galactica’s mishaps. After just three days, the company, which has faced scrutiny for spreading \nmisinformation and hate speech through its social networking apps, removed Galactica from the internet.\n“The people who made the demo had to take it down because they just couldn’t take the heat,” Yann LeCun, Meta’s \nchief artificial intelligence scientist, said last month during an online appearance at Collective[i] Forecast, a \ngathering of Silicon Valley leaders and thinkers.\nFor nearly a decade, Meta has spent billions of dollars building new kinds of A.I. Mark Zuckerberg, the chief \nexecutive, made it a mission for Meta to become a leader in the field back in 2013. The company hired hundreds of \ntop A.I. researchers, including Dr. LeCun. It spent hundreds of millions of dollars on the large amounts of computing \npower needed to build A.I. systems.\nYet Meta has been left out now that Silicon Valley is gripped with excitement by “generative A.I.,” the name for \ntechnologies that generate text, images and other media on their own. OpenAI has taken center stage, even though \nMeta and many other companies have built similar technologies.\nOthers have since jumped headlong into the frenzy. On Monday, Google said it would soon release an \nexperimental chatbot called Bard. And on Tuesday, Microsoft, which has invested $13 billion in OpenAI, unveiled a \nnew internet search engine and web browser powered by generative A.I.\nMeta, Long an A.I. Leader, Tries Not to Be Left Out of the Boom\nMeta, however, was hamstrung, in part, by its reputation as a corporate giant that helps spread untruths, Dr. LeCun \nsaid last month. And with responsibilities to billions of users, it could not afford to leave online a chatbot that can \ngenerate false and biased information.\n“OpenAI and other small companies are in a better position to actually get some credit for releasing this kind of \nthing,” said Chirag Shah, a University of Washington professor who has explored the flaws in technologies like \nGalactica and ChatGPT. “They are not going to get the same kind of blowback.”\nIn recent years, Meta has also shifted its focus to another technology area: the immersive online world of the so-\ncalled metaverse, which Mr. Zuckerberg has said he believes is the next big thing. In the short term, it is unclear \nhow the company can offer generative A.I. products with its existing services in a way that really captures the \npublic’s attention.\nThat does not mean it isn’t trying. Meta is fast-tracking its efforts to put A.I.-driven products into customers’ hands, \nsaid Irina Kofman, a senior director of product management for generative A.I. who oversees XAI, a new team that \naims to help build A.I. products across the company. Mr. Zuckerberg is directly involved in steering the initiatives, \nholding weekly meetings with product leaders and top A.I. researchers, she said.\nIn a call last week with investors, Mr. Zuckerberg repeatedly mentioned A.I. He called it “the foundation of our \ndiscovery engine and our ads business” and added that it would “enable many new products and additional \ntransformations within our apps.”\nSome Meta executives have spoken about the generative A.I. boom with a distinct air of sour grapes. During his \nonline discussion last month, Dr. LeCun described ChatGPT as “not particularly innovative” and “nothing \nrevolutionary” because it relied on technologies developed and deployed by Meta, Google and other companies.\nEarlier last year, Meta released a chatbot, BlenderBot, that stretched the state of the art, Dr. LeCun said. But it \nnever caught on, he said, because the company had worked hard to ensure that it would not produce offensive \nmaterial.\n“It was panned by people who tried it,” he said. “They said it was stupid and kind of boring. It was boring because it \nwas made safe.”\nNot long ago, Meta was known for rapidly pushing out products that were not fully tested or bulletproof, preferring to \nfigure out the details along the way. One of its mottos — “move fast and break things” — became an anthem of \nSilicon Valley start-ups in the early 2010s. And Mr. Zuckerberg embodied what is known as “hacker culture,” \nembracing new technologies and preferring to throw small teams on them to develop them as soon as possible.\nBut after the media, the public and lawmakers spent years scrutinizing the company for allowing false and \ninappropriate material on Facebook and its other social platforms, Meta now cannot release a chatbot that \ngenerates misinformation without significant criticism.\n“People tend to hold large tech companies to a high standard,” said Andrew Ng, a researcher and an entrepreneur \nwho previously oversaw the A.I. labs at Google and the Chinese internet giant Baidu. “It does create an uneven \nplaying field where smaller companies can move faster.”\nMr. Zuckerberg began delving into A.I. in 2013, just after Google made a big bet on A.I. research. He personally \nrecruited top A.I. academics like Dr. LeCun during a hiring frenzy, which culminated with Mr. Zuckerberg flying to \nLake Tahoe, Nev., that year to offer millions of dollars in salary and stock to A.I. researchers who had gathered for \na conference. For years, many of them sat next to his desk at Facebook’s headquarters in Menlo Park, Calif.\nThe researchers eventually helped develop A.I. technologies that Meta largely uses today behind the scenes to \nhelp target ads, recommend posts and videos to users, and identify misinformation and other problematic content.\nNow Meta faces the problem of how to turn A.I. into a product. Facebook offered cutting-edge facial recognition \ntechnology in the late 2010s, but removed itafter complaints that it compromised people’s privacy. It also offered \nMeta, Long an A.I. Leader, Tries Not to Be Left Out of the Boom\nA.I. technology that could instantly translate social media posts from one language to another, which ended up as a \nnarrow use.\nIn the call with investors last week, Mr. Zuckerberg said A.I. underpinned many of Facebook’s and Instagram’s most \nimportant features, including showing people Reels videos and suggesting other photos, videos and posts that they \nmight not already follow.\nAsked at last month’s online appearance how Meta might deploy chatbots and other generative A.I. technologies, \nDr. LeCun said they could help small businesses create ads on Facebook. He added that once people moved into \nthe metaverse, they would need generative tools to create virtual items.\nThe pace of development has taken off internally in recent months, Ms. Kofman said.\nMr. Zuckerberg and Meta’s chief product officer, Chris Cox, and chief technology officer, Andrew Bosworth, have \nbeen in weekly team meetings with leaders across A.I. product teams. Over the past few months, they have also \nspun up teams that specialize in turning A.I. into products, working with others across Meta’s family of apps, Ms. \nKofman said.\nThe goal is to get A.I. powering products faster, and to put those directly into the hands of users. Ultimately, Mr. \nZuckerberg hopes to incorporate some of that underlying technology into building out his vision of the metaverse.\nHow he will bridge the gap between the two important technologies remains unclear. But he has made generative \nA.I. a top company priority.\n“One of my goals for Meta is to build on our research to become a leader in generative A.I.,” Mr. Zuckerberg said \non the investor call.\nPHOTOS: Mark Zuckerberg, left, in 2016. He aims for Meta to be a leader in A.I. But people who tried Meta’s \nBlenderBot last year “said it was stupid and kind of boring,” said Yann LeCun, right, the company’s chief A.I. \nscientist. (PHOTOGRAPHS BY FRANK ZAURITZ/GETTY IMAGES; MARLENE AWAAD/BLOOMBERG) (B4) This \narticle appeared in print on page B1, B4.\nLoad-Date: February 23, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Apr2024",
        "header": "Doctoral Programmes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "April 8, 2024",
        "section": "FRONT PAGE",
        "length": "493 words",
        "byline": "Rica Bhattacharyya & Kala Vijayraghavan",
        "story_text": "Doctoral Programmes\nEconomic Times (E-Paper Edition)\nApril 8, 2024 Monday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 493 words\nByline: Rica Bhattacharyya & Kala Vijayraghavan\nHighlight: CXOs looking to upskill in bid to drive innovation and efficiency via new-gen technology\nBody\nMumbai: An increasing number of CEOs, CXOs and top management professionals are seeking to upskill and \nspecialise in generative artificial intelligence (GenAI) at a time when AI technology is expected to be the primary \ndisruptive force for most businesses, potentially altering processes and systems beyond recognition. Hence, there \nis an urgent push for  key managerial personnel to acquire knowledge and understanding of AI in various aspects of \nbusi-  ness transformation to drive innovation and changes, top officials and academics said.  Leading global \nbusiness school Insead has witnessed an uptick in senior professionals from India wanting to upgrade in new-age \ntech skills, including AI and GenAI, said dean Francisco Veloso. \n “There is a lot of interest from corporates and senior management professionals and because of that, we are \ndeveloping more content in areas related to AI and business – from strategy to organisational behaviour,” he said.  \n“They don’t want to be experts in AI. What they want to learn is how they can use it in their businesses, to leverage \nthe AI tools to create better products and drive efficiency. Our aim is to help these professionals on how to use tech \nin business strategy,” added Veloso, a professor of strategy.  Edtech platform upGrad has seen an increasing \ndemand for doctoral programmes in GenAI — with over 130 sign-ups for executive doctorate programs in GenAI \nwith its US university partner Golden Gate University, San Francisco in less than eight months. “CXOs, directors \nand seasoned professionals with 10 to more than 15 years of experience are opting for the executive doctorate \nprograms,” said upGrad co-founder Mayank Kumar. “The increase in demand is particularly because these senior \nprofessionals are trying to adapt new skills to become more agile and adaptable in the current market \ncircumstances,” he added. “Over 95% of our enrolments come from professionals with over eight years of \nexperience,” he added.Sunil D'souza, CEO, Tata Consumer, said the company’s senior digital team members are \nguiding the management on AI’s business possibilities.“Our digital team has run us through multiple inductions and \nshown us use cases of the art of the possible. We now have a small team starting to commercialise the good use \ncases,\" he said.Sunil Kataria, CEO, Raymond Lifestyle (India & International), said: “The top leadership team is \nconstantly collaborating with experts in the AI field.”\"Our top executives are engaging with Microsoft and AWS \nworkshops to build a digital roadmap in Generative AI business solutions. One of our top colleagues is pursuing a \nPhD in AI through BITS Pilani,” he said. “The integration of AI has emerged as a transformative force in today's \nrapidly evolving business landscape in how we interact with customers and operate businesses.\"Top board \nmembers said there is nothing more important in today’s rapidly changing business environment than the \nknowledge of AI.\nLoad-Date: April 8, 2024\nDoctoral Programmes"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "Generative AI: How IT firms are building capabilities in unprecedented ways",
        "media": "The Economic Times",
        "time": "May 30, 2023",
        "section": "STOCK IN NEWS",
        "length": "613 words",
        "byline": "Vidya Sreedhar",
        "story_text": "Generative AI: How IT firms are building capabilities in unprecedented ways\nThe Economic Times\nMay 31, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 613 words\nByline: Vidya Sreedhar\nBody\nInformation technology companies are increasingly building capabilities on advanced generative artificial \nintelligence (AI), given the success rate and also the potential such platforms have in transforming businesses that \none never imagined of.ChatGPT was one such generative AI platform that left people dumbstruck with its ability to \ncreate humanlike conversational dialogue. The platform has been trained to the extent that it even throws stock \ninvestment recommendations if asked for. While cloud transformation and AI gained significance in the mid-2010s \nin India, it was still limited to a group of sectors and industries. \nHowever, the COVID-19 pandemic brought the need to build technology capabilities across several sectors and \nopened up business in a big way for the IT sector. Technology is ever evolving and generative AI is a result of the \nsame. \"Generative AI offers incredible opportunities ahead,\" said Thierry Delaporte, MD & CEO of Wipro. The \nsoftware company recently expanded its partnership with Google Cloud to offer advanced generative AI \ncapabilities to unlock new value within enterprises, and transform how large-scale businesses operate. Last week, \nGoogle unveiled a generative AI feature on its world-leading search bar in the US. Called \"Google Search \nGenerative Experience,\" or SGE for short, rollouts began on May 25. Generative AI holds significant potential to \ntransform the way of doing business in several ways. US IT major Accenture identified over 300 use cases across \n19 industries where generative AI can deliver significant results, Bhaskar Ghosh, the global chief strategy officer \nrecently told ET in an interview. Accenture is seeing early adopters in the financial services, retail and government \nsectors. Reports suggest that the global AI market, which is currently worth more than $130 billion, has the potential \nto grow by about 40% over the next 7-8 years. Faster AdoptionExperts believe that the adoption to generative AI \nby enterprises could be faster given that they exhibit some form of intelligence, creativity and awareness of context. \nThe interest in generative AI is high among enterprises, noted Srikanth Velamakanni, co-founder and group CEO \nof Fractal Analytics. He expects significant pick-up in the adoption over the next 1 year itself, especially if the \ncurrent pace of technology development continues. Tech BudgetsWhile economic slowdown in the US and Europe \nhas clouded the outlook for discretionary spending, experts do see scope for an increase in budgets by enterprises \nin their race to speed up productivity and deliver more value to customers. \"Tech budgets will continue to increase \nas savings from adoption of generative AI get reinvested in new programs. Demand patterns will change,\" Kotak \nInstitutional Equities said in its report. Deflationary RisksGenerative AI systems have the ability to provide \nsignificant assistance in software development-related activities, but Kotak Equities sees risk of a deflationary \nimpact for information technology companies. \"The key risk for IT services is the deflationary impact arising from \nproductivity increases driven by generative AI not being compensated by an increase in volumes in this transition \nperiod,\" it said. The overall risk to the business is lower for large companies, but it is higher for mid-tier ones due to \ntheir higher exposure to application development.Though generative AI can drive demand tailwinds for the IT \nsector, cost competitiveness will be key. (Disclaimer: Recommendations, suggestions, views and opinions given by \nthe experts are their own. These do not represent the views of Economic Times) For Reprint Rights: \ntimescontent.com\nGenerative AI: How IT firms are building capabilities in unprecedented ways\nLoad-Date: May 30, 2023"
    },
    {
        "file_name": "election_problem._Feb2024",
        "header": "Fake robocalls. Doctored videos. Why Facebook is being urged to fix its",
        "media": "election problem.",
        "time": "February 7, 2024",
        "section": "ROBOTICS NEWS, ROBOTICS NEWS, ROBOTICS NEWS & SOCIAL NETWORKS NEWS",
        "length": "1470 words",
        "byline": "Jessica Guynn, USA TODAY",
        "story_text": "Fake robocalls. Doctored videos. Why Facebook is being urged to fix its \nelection problem.\nUSA Today Online\nFebruary 5, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: ROBOTICS NEWS, ROBOTICS NEWS, ROBOTICS NEWS & SOCIAL NETWORKS NEWS\nLength: 1470 words\nByline: Jessica Guynn, USA TODAY\nBody\nAs the nation heads into the 2024 presidential election, the independent body that reviews Meta’s content \nmoderation decisions is urging the tech giant to overhaul its policy on manipulated videos to encompass fake or \ndistorted clips that can mislead voters and tamper with elections.\nThe test case was a doctored video of President Joe Biden that appeared on Facebook last May. \nMeta bans video clips that have been digitally created or altered with generative artificial intelligence to make it \nappear as if people have said something they did not. But it doesn't address cruder clips − so-called \"cheap fakes − \nmade with basic editing tools, nor does it address clips that show someone doing something they did not.\nThe Oversight Board upheld Meta's decision to allow the Biden video to remain on Facebook but called on Meta to \ncrack down on all doctored content, regardless of how it was created or altered. It also recommended that Meta \nclearly define the aim of its policy to encompass election interference.\nOf particular concern is faked audio, which the board said is “one of the most potent forms of electoral \ndisinformation we’re seeing around the world.” \nIn January, a fake robocall used Biden's voice to encourage New Hampshire voters to skip the primary. The \nrobocall was artificially generated and is being probed by the New Hampshire Attorney General's Office as an \nattempt at voter suppression. It did not affect the outcome of the primary – Biden won in a landslide – but it \nillustrated how generative AI could be used to influence an election, critics say. \n“As it stands, the policy makes little sense,” Oversight Board Co-Chair Michael McConnell said in a statement. “It \nbans altered videos that show people saying things they do not say but does not prohibit posts depicting an \nindividual doing something they did not do. It only applies to video created through AI, but lets other fake content off \nthe hook.”\nMeta did not say whether it would follow the Oversight Board’s guidance. A spokesman said the company was \nreviewing the recommendations and would respond publicly within 60 days. \nEven if Meta makes changes to its manipulated media policy, observers say there's no guarantee it will put enough \nmoney and resources into enforcing the changes. \n“The volume of misleading content is rising, and the quality of tools to create it is rapidly increasing,” McConnell \nsaid. “Platforms must keep pace with these changes, especially in light of global elections during which certain \nactors seek to mislead the public.”\nFake robocalls. Doctored videos. Why Facebook is being urged to fix its election problem.\nThe White House urged companies to step up their efforts to combat manipulated media, a Biden administration \nofficial said Tuesday.\n“Companies are looking at and need to do more to build the technology to identify what are deepfakes,” Anne \nNeuberger, deputy national security adviser for cyber and emerging technology, said during a Washington Post Live \nevent.\nMeta defended its election integrity policies. \n“We have around 40,000 people globally working on safety and security, and protecting the 2024 elections is one of \nour top priorities,\" the company said in a statement. \"Our integrity efforts continue to lead the industry and with each \nelection, we incorporate the lessons we’ve learned to help stay ahead of emerging threats.”\nIn the first AI election, 'a tsunami of disinformation'\nThe stakes are not just high in the United States. In 2024, more people will have a chance to vote than in any \nprevious election, increasing the likelihood that AI will play a role at the ballot box. And that's raising concerns. \nWith rapid advances in technology and too little oversight from the government or private sector, election experts \nhave been bracing for the malicious use of deepfakes in the 2024 presidential contest. Virtually anyone can now \ncreate or digitally alter images and clips in realistic ways to deceive voters. \nLike other technology companies, Meta has made pledges to curb the harms of generative AI. Yet, even as the \ntechnology grows more sophisticated, powerful and ubiquitous, there are still very few rules governing its use.\nLink to Image\nIn the case of the doctored video, the original footage showed Biden accompanying his granddaughter for her first \ntime voting in October 2022. Biden placed an “I voted” sticker near her neckline as she instructed then kissed her \non the cheek. But the looped version made it seem as if Biden were repeatedly touching her chest. The caption \nlabeled Biden a “sick pedophile.”\nMeta left the video up, saying it did not violate its rules because it was not altered using AI and did not show Biden \nsaying something he did not say. The company made a similar decision in 2019 over a clip that was slowed down to \nmake then-House Speaker Nancy Pelosi appear drunk − even as Democrats fumed.\nBiden’s 2024 campaign has set up a deepfake task force to respond to misleading AI-generated falsehoods and \npropaganda. \n“There is going to be a tsunami of disinformation in 2024. We are already seeing it, and it is going to get much \nworse,” said Darrell West, a senior fellow at the Center for Technology Innovation at the Brookings Institution. \n“People are anticipating that this will be a close election, and anything that shifts 50,000 votes in three or four states \ncould be decisive.”\nHow Facebook and other social media platforms police faked content\nWhat’s alarming to West is the tepid response from social media platforms that host this content. \nRather than strengthening protections, Meta and other major technology companies have loosened their \nmisinformation policies and laid off staffers charged with policing lies and propaganda since the 2020 election, West \nsaid. \nMeta also now allows political ads to question the legitimacy of the 2020 U.S. presidential election. It does not allow \nads that question the legitimacy of current or upcoming elections.\n“So at a time when fake videos are becoming rampant, their capacity to deal with it is quite limited,” West said.\nFake robocalls. Doctored videos. Why Facebook is being urged to fix its election problem.\nLink to Image\nWhen policing fake election content, social media platforms can take it down, slap warning labels on it, or demote it. \nTo ensure the policy is \"proportionate,\" the Oversight Board recommended that Meta stop removing manipulated \nmedia when there is no other policy violation and instead apply a label warning the content has been significantly \naltered and may be misleading.  \nIt also discouraged Meta from demoting content that fact-checkers identify as altered or fake without informing \nusers or providing an appeals process. \n“Political speech must be unwaveringly protected. This sometimes includes claims that are disputed and even false, \nbut not demonstrably harmful,” McConnell said. \nFacebook not doing enough to protect elections, critics charge\nHany Farid, a University of California, Berkeley professor who specializes in deepfakes and disinformation, gets \ndaily inquiries about fake images on the internet, from Biden in military fatigues in the situation room to Trump with \npedophile Jeffrey Epstein. He says the use of warning labels for this kind of malicious content is \"cowardly.\"\nWhile the warning labels provide cover to Facebook, the average person doesn’t care about the label or ignores it, \nhe said. Most of the time those labels are not added until a video has gotten millions of views. What’s more, anyone \ncan then take that video and post it somewhere else without the label. \nAccording to Farid, Facebook, whose algorithms serve up content that stirs strong emotions, has been on the \nwrong side of this issue for the last 15 years.\n“It’s hard to take Facebook seriously when they say we have these policies and it’s clear those policies are in place \nto maximize their profits,” he said.\nElection experts call for deepfake regulations\nAny efforts by social media companies to rein in doctored or AI-generated content should be paired with thoughtful \nstandards crafted by regulators and policymakers, says Daniel Weiner, director of the Brennan Center’s Elections \nand Government Program.\nWhile AI-generated depictions of Biden are quickly debunked, what about a local candidate for city council or the \nschool board?\nLast year, Sen. Richard Blumenthal, D-Conn., launched a Senate Judiciary Committee hearing into the potential \ndangers of deepfakes by playing an AI-generated recording that mimicked his voice and read a ChatGPT-\ngenerated script.\n“The latest advances in AI technology, more than anything else, has reinforced the need to strengthen fundamental \nguardrails for our political system,” Weiner said. “These problems existed before. They would exist if every \ndeepfake disappeared tomorrow. And, a lot of times, the solutions aren’t AI-specific. They are about the need for a \nbroader strengthening of democracy.”\nThis article originally appeared on USA TODAY: Fake robocalls. Doctored videos. Why Facebook is being urged to \nfix its election problem.\nLoad-Date: February 7, 2024"
    },
    {
        "file_name": "technology_companies_signed_a_pact_Friday_to_voluntarily_adopt_\"reasonable_Feb2024",
        "header": "Tech companies sign accord to combat AI-generated election trickery; Major",
        "media": "technology companies signed a pact Friday to voluntarily adopt \"reasonable",
        "time": "February 16, 2024",
        "section": "NATION WORLD",
        "length": "1203 words",
        "byline": "MATT O'BRIEN and ALI SWENSON",
        "story_text": "Tech companies sign accord to combat AI-generated election trickery; Major \ntechnology companies signed a pact Friday to voluntarily adopt \"reasonable \nprecautions\" to prevent artificial intelligence tools from disrupting \ndemocratic elections worldwide\nDayton Daily News (Ohio)\nFebruary 16, 2024 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1203 words\nByline: MATT O'BRIEN and ALI SWENSON\nBody\nMajor technology companies signed a pact Friday to voluntarily adopt \"reasonable precautions\" to prevent artificial \nintelligence tools from being used to disrupt democratic elections around the world.\nExecutives from Adobe, Amazon, Google, IBM, Meta, Microsoft, OpenAI and TikTok gathered at the Munich \nSecurity Conference to announce a new framework for how they respond to AI-generated deepfakes that \ndeliberately trick voters. Twelve other companies  including Elon Musk's X  are also signing on to the accord. \n\"Everybody recognizes that no one tech company, no one government, no one civil society organization is able to \ndeal with the advent of this technology and its possible nefarious use on their own,\" said Nick Clegg, president of \nglobal affairs for Meta, the parent company of Facebook and Instagram, in an interview ahead of the summit. \nThe accord is largely symbolic, but targets increasingly realistic AI-generated images, audio and video \"that \ndeceptively fake or alter the appearance, voice, or actions of political candidates, election officials, and other key \nstakeholders in a democratic election, or that provide false information to voters about when, where, and how they \ncan lawfully vote.\" \nThe companies aren't committing to ban or remove deepfakes. Instead, the accord outlines methods they will use to \ntry to detect and label deceptive AI content when it is created or distributed on their platforms. It notes the \ncompanies will share best practices with each other and provide \"swift and proportionate responses\" when that \ncontent starts to spread. \nThe vagueness of the commitments and lack of any binding requirements likely helped win over a diverse swath of \ncompanies, but disappointed advocates were looking for stronger assurances. \n\"The language isn't quite as strong as one might have expected,\" said Rachel Orey, senior associate director of the \nElections Project at the Bipartisan Policy Center. \"I think we should give credit where credit is due, and \nacknowledge that the companies do have a vested interest in their tools not being used to undermine free and fair \nelections. That said, it is voluntary, and we'll be keeping an eye on whether they follow through.\" \nClegg said each company \"quite rightly has its own set of content policies.\" \nTech companies sign accord to combat AI-generated election trickery Major technology companies signed a \npact Friday to voluntarily adopt \"reasonable precautions....\n\"This is not attempting to try to impose a straitjacket on everybody,\" he said. \"And in any event, no one in the \nindustry thinks that you can deal with a whole new technological paradigm by sweeping things under the rug and \ntrying to play whack-a-mole and finding everything that you think may mislead someone.\" \nSeveral political leaders from Europe and the U.S. also joined Friday's announcement. European Commission Vice \nPresident Vera Jourova said while such an agreement can't be comprehensive, \"it contains very impactful and \npositive elements.\" She also urged fellow politicians to take responsibility to not use AI tools deceptively and \nwarned that AI-fueled disinformation could bring about \"the end of democracy, not only in the EU member states.\" \nThe agreement at the German city's annual security meeting comes as more than 50 countries are due to hold \nnational elections in 2024. Bangladesh, Taiwan, Pakistan and most recently Indonesia have already done so. \nAttempts at AI-generated election interference have already begun, such as when AI robocalls that mimicked U.S. \nPresident Joe Biden's voice tried to discourage people from voting in New Hampshire's primary election last month. \nJust days before Slovakia's elections in November, AI-generated audio recordings impersonated a candidate \ndiscussing plans to raise beer prices and rig the election. Fact-checkers scrambled to identify them as false as they \nspread across social media. \nPoliticians also have experimented with the technology, from using AI chatbots to communicate with voters to \nadding AI-generated images to ads. \nThe accord calls on platforms to \"pay attention to context and in particular to safeguarding educational, \ndocumentary, artistic, satirical, and political expression.\" \nIt said the companies will focus on transparency to users about their policies and work to educate the public about \nhow they can avoid falling for AI fakes. \nMost companies have previously said they're putting safeguards on their own generative AI tools that can \nmanipulate images and sound, while also working to identify and label AI-generated content so that social media \nusers know if what they're seeing is real. But most of those proposed solutions haven't yet rolled out and the \ncompanies have faced pressure to do more. \nThat pressure is heightened in the U.S., where Congress has yet to pass laws regulating AI in politics, leaving \ncompanies to largely govern themselves. \nThe Federal Communications Commission recently confirmed AI-generated audio clips in robocalls are against the \nlaw, but that doesn't cover audio deepfakes when they circulate on social media or in campaign advertisements. \nMany social media companies already have policies in place to deter deceptive posts about electoral processes  AI-\ngenerated or not. Meta says it removes misinformation about \"the dates, locations, times, and methods for voting, \nvoter registration, or census participation\" as well as other false posts meant to interfere with someone's civic \nparticipation. \nJeff Allen, co-founder of the Integrity Institute and a former Facebook data scientist, said the accord seems like a \n\"positive step\" but he'd still like to see social media companies taking other actions to combat misinformation, such \nas building content recommendation systems that don't prioritize engagement above all else. \nLisa Gilbert, executive vice president of the advocacy group Public Citizen, argued Friday that the accord is \"not \nenough\" and AI companies should \"hold back technology\" such as hyper-realistic text-to-video generators \"until \nthere are substantial and adequate safeguards in place to help us avert many potential problems.\" \nIn addition to the companies that helped broker Friday's agreement, other signatories include chatbot developers \nAnthropic and Inflection AI; voice-clone startup ElevenLabs; chip designer Arm Holdings; security companies \nMcAfee and TrendMicro; and Stability AI, known for making the image-generator Stable Diffusion. \nTech companies sign accord to combat AI-generated election trickery Major technology companies signed a \npact Friday to voluntarily adopt \"reasonable precautions....\nNotably absent is another popular AI image-generator, Midjourney. The San Francisco-based startup didn't \nimmediately respond to a request for comment Friday. \nThe inclusion of X  not mentioned in an earlier announcement about the pending accord  was one of the surprises \nof Friday's agreement. Musk sharply curtailed content-moderation teams after taking over the former Twitter and \nhas described himself as a \"free speech absolutist.\" \nIn a statement Friday, X CEO Linda Yaccarino said \"every citizen and company has a responsibility to safeguard \nfree and fair elections.\" \n\"X is dedicated to playing its part, collaborating with peers to combat AI threats while also protecting free speech \nand maximizing transparency,\" she said. \nThe Associated Press receives support from several private foundations to enhance its explanatory coverage of \nelections and democracy. See more about AP's democracy initiative here. The AP is solely responsible for all \ncontent.\nGraphic\n \nFILE - Meta's president of global affairs Nick Clegg speaks at the World Economic Forum in Davos, Switzerland, \nJan. 18, 2024. Adobe, Google, Meta, Microsoft, OpenAI, TikTok and other companies are gathering at the Munich \nSecurity Conference on Friday to announce a new voluntary framework for how they will respond to AI-generated \ndeepfakes that deliberately trick voters. (AP Photo/Markus Schreiber, File)\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Apple Explores A.I. Deals With News Publishers",
        "media": "The New York Times",
        "time": "December 22, 2023",
        "section": "TECHNOLOGY",
        "length": "814 words",
        "byline": "Benjamin Mullin and Tripp Mickle &lt;p&gt;Benjamin Mullin reports on the major companies behind news",
        "story_text": "Apple Explores A.I. Deals With News Publishers\nThe New York Times \nDecember 22, 2023 Friday 21:36 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 814 words\nByline: Benjamin Mullin and Tripp Mickle &lt;p&gt;Benjamin Mullin reports on the major companies behind news \nand entertainment. Contact Ben securely on Signal at +1 530-961-3223 or email at , \nbenjamin.mullin@nytimes.com.&, ;lt;/p&gt; &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot \ntaxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt;\nHighlight: The company has discussed multiyear deals worth at least $50 million to train its generative A.I. \nsystems on publishers’ news articles.\nBody\nThe company has discussed multiyear deals worth at least $50 million to train its generative A.I. systems on \npublishers’ news articles.\nApple has opened negotiations in recent weeks with major news and publishing organizations, seeking permission \nto use their material in the company’s development of generative artificial intelligence systems, according to four \npeople familiar with the discussions.\nThe technology giant has floated multiyear deals worth at least $50 million to license the archives of news articles, \nsaid the people with knowledge of talks, who spoke on the condition of anonymity to discuss sensitive negotiations. \nThe news organizations contacted by Apple include Condé Nast, publisher of Vogue and The New Yorker; NBC \nNews; and IAC, which owns People, The Daily Beast and Better Homes and Gardens.\nThe negotiations mark one of the earliest examples of how Apple is trying to catch up to rivals in the race to develop \ngenerative A.I., which allows computers to create images and chat like a human. The technology, which artificial \nintelligence experts refer to as neural networks, is built by using troves of photos or digital text to recognize \npatterns. By analyzing thousands of cat photos, for instance, a computer can learn to recognize a cat.\nMicrosoft, OpenAI, Google, Meta and other companies have released chatbots and other products built with the \ntechnology. The tools could change the way people work and generate billions of dollars in sales.\nBut Apple has been absent from the public discussion of A.I. Its virtual assistant, Siri, has remained largely stagnant \nin the decade since its release.\nA spokeswoman for Apple declined to comment. During a call with analysts last month, Tim Cook, the company’s \nchief executive, said Apple has work “going on” connected to A.I. but declined to elaborate.\nSome of the publishers contacted by Apple were lukewarm on the overture. After years of on-again-off-again \ncommercial deals with tech companies like Meta, the owner of Facebook, publishers have grown wary of jumping \ninto business with Silicon Valley.\nApple Explores A.I. Deals With News Publishers\nSeveral publishing executives were concerned that Apple’s terms were too expansive, according to three people \nfamiliar with the negotiations. The initial pitch covered broad licensing of publishers’ archives of published content, \nwith publishers potentially on the hook for any legal liabilities that could stem from Apple’s use of their content.\nApple was also vague about how it intended to apply generative A.I. to the news industry, the people said, a \npotential competitive risk given Apple’s substantial audience for news on its devices.\nStill, some news executives were optimistic that Apple’s approach might eventually lead to a meaningful \npartnership. Two people familiar with the discussions struck a positive note on the long-term prospects of a deal, \ncontrasting Apple’s approach of asking for permission with behavior from other artificial intelligence-enabled \ncompanies, which have been accused of seeking licensing deals with news organizations after they had already \nused their content to train generative models.\nIn recent years, Apple executives have been debating how to accumulate the data needed to build generative A.I. \nproducts, according to two people familiar with the work. Some of its rivals have been accused of taking written \nmaterial from across the internet without the permission of the artists, writers and coders who created it, leading to \nseveral copyright lawsuits.\nApple has been reluctant to take information from the internet, partly because of its commitment to privacy. After it \nacquired the social analytics start-up Topsy in 2013, Apple’s leadership asked that Topsy stop collecting information \nfrom Twitter, saying that doing so violated the company’s policy against collecting data on Apple customers, who \nmight also post on the social media site, these two people said.\nThe explosion of artificial intelligence has raised alarms among news executives, many of whom are concerned that \ngenerative A.I. products like OpenAI’s ChatGPT could draw in readers who would otherwise consume their news \non platforms for their own subscribers and advertisers.\nPrint news organizations, which decades ago saw their lucrative classifieds business demolished by online \ncompetitors, have been particularly wary about striking deals with A.I. organizations, engaging cautiously with an \neye toward preserving their existing businesses.\nIn a statement, an OpenAI spokesman said that the company respects “the rights of content creators and owners \nand believes they should benefit from A.I. technology,” citing its recent deals with the American Journalism Project \nand the German publisher Axel Springer.\n“We’re optimistic we will continue to find mutually beneficial ways to work together in support of a rich news \necosystem,” the OpenAI spokesman said.\nThis article appeared in print on page B5.\nLoad-Date: December 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Apple Spot Has Creators Feeling Flat",
        "media": "The New York Times",
        "time": "May 10, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "810 words",
        "byline": "By Tripp Mickle",
        "story_text": "Apple Spot Has Creators Feeling Flat\nThe New York Times\nMay 10, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 810 words\nByline: By Tripp Mickle\nBody\nAn ad meant to show how the updated device can do many things has become a metaphor for a community's fears \nof the technology industry.\nThe trumpet is the first thing to be squished. Then the industrial compressor flattens a row of paint cans, buckles a \npiano and levels what appears to be a marble bust. In a final act of destruction, it pops the eyes out of a ball-shaped \nyellow emoji. \n  When the compressor rises, it reveals Apple's latest commodity: the updated iPad Pro.\n  Tim Cook, Apple's chief executive, posted the advertisement, called ''Crush,'' on Tuesday after the company held \nan event to announce new tablets. ''Meet the new iPad Pro: the thinnest product we've ever created,'' Mr. Cook \nwrote, adding, ''Just imagine all the things it'll be used to create.''\n  For decades, Apple has been the toast of the creative class. It has won over designers, musicians and film editors \nwith promises that its products would help them ''Think Different.''\n  But some creators took a different message from the one-minute iPad ad. Rather than seeing a device that could \nhelp them create, as Mr. Cook suggested, they saw a metaphor for how Big Tech has cashed in on their work by \ncrushing or co-opting the artistic tools that humanity has used for centuries.\n  The image was especially unnerving at a time when artists fear that generative artificial intelligence, which can \nwrite poetry and create movies, might take away their jobs.\n  ''It's unusual in its cruelty,'' said Justin Ouellette, a software designer in Portland, Ore., who does animation work \nand is a longtime Apple product user. ''A lot of people see this as a betrayal of its commitment to human creative \nexpression and a tone deafness to the pressures those artists feel at this time.''\n  Apple didn't respond to requests for comment.\n  It was the latest in a series of recent promotional slip-ups by a company that is widely considered to be a \nmarketing juggernaut. Its marketing of the Apple Vision Pro, released in January, struggled to help that device \nbreak through with many customers. Last year, Apple was criticized for making an awkward sketch that cast \nOctavia Spencer as Mother Earth, lording over a corporate meeting about the company's effort to become carbon \nneutral by 2030.\n  Apple has been regarded as an advertising visionary since the 1980s. Its ''1984'' Super Bowl commercial to \nintroduce the Macintosh computer is among the most famous commercials ever made. The ad, which was \nApple Spot Has Creators Feeling Flat\ndeveloped by the Chiat/Day agency, showed an actor throwing a sledgehammer through a screen projecting the \nface of a ''Big Brother'' figure that was meant to be a metaphor for IBM.\n  When Steve Jobs returned to Apple in 1997 after 12 years away, he sought to reclaim its marketing magic. \nTogether he and Lee Clow, the advertising creative behind the ''1984'' spot, developed the ''Think Different'' \ncampaign. It paved the way to the famous ''Get a Mac'' spots, featuring a Mac and PC, and the original iPhone ad, \nwhich showed people in classic films and television shows picking up a phone and saying, ''Hello.''\n  Apple's marketing pitched its products as easy to use. It billed PCs and Android phones as devices for business \nexecutives working on spreadsheets, while Macs and iPhones were tools for film editors, photographers and \nwriters.\n  But Apple's advertising has been uneven over the last dozen years or so. It yanked a 2012 campaign that \nshowcased its Apple Store ''geniuses'' on planes. Critics dismissed a subsequent spot, ''Designed by Apple in \nCalifornia,'' as ''lame.''\n  In the wake of those hiccups, Mr. Cook shifted oversight of advertising from Phil Schiller, the company's longtime \nhead of marketing, to Tor Myhren, a former president and chief creative officer at Grey, the ad agency that created \nthe E-Trade baby.\n  Under Mr. Myhren, who joined in 2016, Apple has developed some of its ads with its own creative team and others \nin collaboration with an outside agency, Media Arts Lab. It has been recognized at the Cannes Lions Awards, the \nleading event for the ad industry, for a spot on AirPods called ''Bounce,'' which showed a man bounding off the \nsidewalk as he listened to music. Last year, Apple was named Creative Brand of the Year because of its ''R.I.P. \nLeon'' ad, in which a man sent an iPhone message saying a lizard in his care had died, then deleted it when the \nlizard suddenly rolled over off its back.\n  Mr. Myhren and Media Arts Lab didn't respond to requests for comment about who was behind the ''Crush'' spot.\n  Michael J. Miraflor, the chief brand officer at Hannah Grey, a venture capital firm, said on X that Apple's ad had \neffectively offended and turned off its core customer base, achieving the opposite of what it had done with its \n''1984'' commercial.\n  ''It's not even that it's boring or banal,'' Mr. Miraflor wrote. ''It makes me feel ... bad? Bummed out?''\nhttps://www.nytimes.com/2024/05/08/business/apple-ipad-crush-ad.html\nGraphic\n \nPHOTO: In the ad, a compressor crushes myriad tools and materials of creative work. (PHOTOGRAPH BY APPLE) \n(B5) This article appeared in print on page B1, B5.               \nLoad-Date: May 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Why Pope Francis Is the Star of A.I.-Generated Photos",
        "media": "The New York Times",
        "time": "April 10, 2023",
        "section": "TECHNOLOGY",
        "length": "864 words",
        "byline": "Kalley Huang",
        "story_text": "Why Pope Francis Is the Star of A.I.-Generated Photos\nThe New York Times \nApril 8, 2023 Saturday 23:35 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 864 words\nByline: Kalley Huang\nHighlight: Francis has become a recurring favorite to show in incongruous situations, such as riding a motorcycle \nand attending Burning Man, in A.I.-generated images.\nBody\nFrancis has become a recurring favorite to show in incongruous situations, such as riding a motorcycle and \nattending Burning Man, in A.I.-generated images.\nPope Francis wearing a long, white puffer jacket inspired by Balenciaga. Francis rocking aviators and revving a \nmotorcycle down a busy street. Francis turning the tables in a dim nightclub. Francis in a tactical vest, preparing to \nfly a fighter jet. Francis sharing a beer at Burning Man.\nOver the last few weeks, dozens of photos have appeared showing the leader of the world’s Roman Catholics in \nstrange scenarios, sending social media into a tizzy. Apart from the pontiff himself, the images all have something \nin common: They are fake, made by artificial intelligence tools that create images from short text prompts.\nMany public figures — including the basketball star LeBron James and various Real Housewives — have popped \nup in A.I.-generated pictures recently, but the images with Francis have made the biggest splash. They have \nearned more views, likes and comments than many other A.I. photos, according to a review by The New York \nTimes, prompting a race to depict the 86-year-old in odder and odder situations.\n“I had to get involved in the Pope thing,” one Reddit user recently wrote alongside A.I. images of Francis practicing \nmartial arts, playing basketball and skateboarding. “Jumping on the Pope bandwagon,” another said, sharing an \nimage of the pontiff speaking to a crowd of bikers.\nFrancis’s prevalence in A.I.-generated images is the result of a perfect storm of factors, religious experts said. After \n10 years as the head of the Catholic Church, he is instantly recognizable around the world. He is viewed as a more \napproachable leader than his harder-line predecessor, Pope Benedict XVI. And when combined with a sudden \nburst of interest in new A.I. tools, Francis — who in real life is often pictured in formal settings — became the \nrecurring choice of creators to place in the most incongruous scenarios.\nThe goal, some creators said, was to show that even the pope can kick back, be a daredevil and have fun.\nGlobal religious figures like the pope are natural subjects of political satire and artistic expression, said Jennifer \nHerdt, a professor of Christian ethics at Yale Divinity School. Francis is ideal, she added, because he “is known for \nhis simplicity, his solidarity with the poorest of the poor,” so when he is the subject of far-out scenarios such as \nflying a fighter jet, “it’s definitely the height of incongruity, of defying expectations.”\nA.I. images can be dangerous if people believe them to be real and misuse them to spread misinformation. “You lull \npeople into not double checking,” said Subbarao Kambhampati, a computer science professor at Arizona State \nUniversity. “Then you are shifted little by little from reality.”\nWhy Pope Francis Is the Star of A.I.-Generated Photos\nBut many of the A.I. images featuring Francis have elicited chuckles of affection for the pope, who recently had a \nhealth scare and is deep into a longer-than-average papacy.\n“People experience Pope Francis as a pope of the people, so you would enjoy putting him in all these places where \nthe people are,” said the Rev. Serene Jones, the president and a professor of religion and democracy at Union \nTheological Seminary in New York.\nThe Vatican did not respond to a request for comment about the pope’s A.I.-generated fame.\nThe image that turned Francis into an A.I. star shows him in a white puffer jacket in the style of Balenciaga, a haute \nFrench fashion house, striding down the street. It appeared to have first been posted on March 24 on a Reddit \nforum for the generative A.I. tool Midjourney and then shared across social media.\nOne tweet sharing the image — captioned “The boys in Brooklyn could only hope for this level of drip” — was liked \nmore than 229,000 times and viewed 20.6 million times. In contrast, a tweet sharing A.I.-generated images of \nformer President Donald J. Trump’s being arrested got 40,000 likes and 6.4 million views.\nMidjourney, which released Version 5 of its image-generating tool last month, didn’t respond to a request for \ncomment. The tool generates custom, hyper-realistic images from just a few words and can now create hands with \nthe correct number of fingers, a previous barrier to believability.\nSince then, Francis has become an A.I. muse. He has been shown eating fast food, meeting with aliens, playing \nguitar at the Glastonbury Festival, scuba diving, dancing at the beach and cleaning up biohazardous waste in a \nhazmat suit. The flood of papal imagery has been so voluminous that some people in online generative A.I. forums \nhave begged for creators to use another inspiration.\nThat hasn’t stopped depictions of an increasingly outlandishly dressed Francis. In some images, he has graduated \nfrom a puffer jacket to an all-black outfit with a leather jacket. In another, he is wearing a rainbow trench coat.\nThose prompted others to put Francis in an outfit of the people: a sweatshirt, sweatpants and dad sneakers.\nPHOTO: An image generated by artificial intelligence depicts Pope Francis in a fighter jet. Recently, dozens of such \nphotos show him in strange scenarios. (PHOTOGRAPH BY A.I.) This article appeared in print on page B5.\nLoad-Date: April 10, 2023"
    },
    {
        "file_name": "Q2_guidance?_Dec2023",
        "header": "ET Explainer: Should Indian IT companies be concerned about Accenture’s",
        "media": "Q2 guidance?",
        "time": "December 20, 2023",
        "section": "TECH & INTERNET",
        "length": "726 words",
        "byline": "Romita Majumdar",
        "story_text": "ET Explainer: Should Indian IT companies be concerned about Accenture’s \nQ2 guidance?\nThe Economic Times\nDecember 20, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 726 words\nByline: Romita Majumdar\nBody\nDoes Accenture’s first quarter performance and guidance for the second quarter announced Tuesday bode well for \nIndian IT companies? Not really! Going by the management’s commentary, green shoots are visible but timelines \nwill vary much like the visibility on its deal pipelines. Reports also suggest that the current green shoots in the IT \nspending ecosystem will not have any material impact on Indian IT’s fiscal 2024 guidance and that the technology \nspend cycle will only recover post-June 2024, which may benefit revenue growth only in fiscal 2025. Here’s what we \nknow:Did Accenture miss its Q1 guidance?\nAccording to Jefferies, Accenture’s Q1 (quarter ended November 2023) revenue performance at $16 billion, up 1% \nyear-on-year in constant currency terms, was pretty much within the guided range of -2 to 2% growth, but was still \nthe lowest reported growth in 13 quarters. Managed Services growth softened to 5% YoY (CC) while consulting \nrevenues declined by 2% YoY (CC). North America was weak with a revenue decline of 1% YoY (CC) while EMEA \nand growth markets grew by 2% and 5% YoY (CC), respectively. Flat YoY revenues in financial services and an \n11% YoY (CC) revenue decline in communication highlight weakness in these verticals.The street is, however, \nconcerned about Accenture’s Q2 guidance of negative 2% to 2% in local currency terms, which indicated no \npositive impact of the US Federal Reserve commentary about interest rate cuts.What does this mean for Indian \nIT?Almost 48% of Accenture's business caters to managed services directly competing with Indian IT service \nproviders like Tata Consultancy Services, Infosys, HCLTech and Tech Mahindra, among others.A report by Elara \nCapital said that Accenture’s Q1 performance indicates a cautious read-through for Indian IT companies as \noutsourcing growth was at a muted 6.4%. Consulting growth turned the tide with growth at 0.2% YoY after three-\nquarters of contraction, hinting at a slight recovery in discretionary spending.Jefferies expects revenue decline in \nNorth America and the communication vertical and rising challenges in the UK have negative readthroughs for \ncompanies like Tech Mahindra, LTIMindtree and Coforge. The brokerage said that Accenture's sharp slowdown in \nmanaged services to a 14-quarter low growth does not bode well for Indian IT's near-term outlook either. Overall, \nAccenture’s current performance and guidance for the next quarter indicates pressure on Indian IT for H2 of the \n2024 fiscal.Where does Accenture see demand recovery?Accenture CEO Julie Sweet said that the challenging \ndemand environment has mostly stayed the same in the past quarter and is unlikely to change in the next quarter. \nDiscretionary spending is under pressure, decision-making is slow and small deals (which will convert into revenue \nfaster) are fewer in number, as was the case in the recent quarters. It expects more clarity in client budgets in the \nJanuary-February period.The company continues to see significant demand in areas like cloud migration and \nmodernisation, modern ERP, and data & AI, including Gen AI, platforms and security. Enterprise cloud demand \nremained strong in Q1, reflecting strong deal momentum. Analysts expect such deals by Accenture to impact Indian \nplayers who have not created cloud-focused partnerships at scale in the current macroeconomic \nenvironment.Accenture expects higher growth in the second half of fiscal 2024 (March onwards), especially with \nrevenue expected to come in from large transformational deals towards the second half of its fiscal year.How will \n2024 pan out for Indian IT?Despite upbeat commentary from the US Federal Reserves last week indicating interest \nET Explainer: Should Indian IT companies be concerned about Accenture’s Q2 guidance?\nrate cuts, data from UnearthInsight shows that the tech spend recovery cycle will only start post June/July 2024. \nThis will unfold as rate cuts will ease inflation, drawing consumer spend and eventually allowing companies to \ninvest in technology not just for optimising costs and improving margins but also to invest in transformation tech. IT \nclients will also make investments for experience, ease and efficiency through cloud, Gen AI and digital tech plus \nand balance outsourcing to IT services firms against the growth of captives. UnearthInsight sticks to 5-6% revenue \ngrowth for FY24 and 6-7% estimated revenue growth potential for FY25. For Reprint Rights: timescontent.com\nLoad-Date: December 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Publishers Gird for Threat From A.I.",
        "media": "The New York Times",
        "time": "March 31, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1298 words",
        "byline": "By Katie Robertson",
        "story_text": "Publishers Gird for Threat From A.I.\nThe New York Times\nMarch 31, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1298 words\nByline: By Katie Robertson\nBody\nMany sites get at least half their traffic from search engines. Fuller results generated by new chatbots could mean \nfar fewer visitors.\nThe publishing industry has spent the past two decades struggling to adjust to the internet, as print circulation has \nplummeted and tech companies have gobbled up rivers of advertising revenue. \n  Now come the chatbots.\n  New artificial intelligence tools from Google and Microsoft give answers to search queries in full paragraphs rather \nthan a list of links. Many publishers worry that far fewer people will click through to news sites as a result, shrinking \ntraffic -- and, by extension, revenue.\n  The new A.I. search tools remain in limited release, so publishers such as Condé Nast and Vice have not yet seen \nan effect on their business. But in an effort to prevent the industry from being upended without their input, many are \npulling together task forces to weigh options, making the topic a priority at industry conferences and, through a \ntrade organization, planning a push to be paid for the use of their content by chatbots.\n  ''You could essentially call this the Wikipedia-ization of a lot of information,'' said Bryan Goldberg, the chief \nexecutive of BDG, which publishes lifestyle and culture websites like Bustle, Nylon and Romper. ''You're bringing \ntogether Wikipedia-style answers to an infinite number of questions, and that's just going to nuke many corners of \nthe open web.''\n  Content publishers have an uneven but largely reciprocal relationship with search engines. The search sites \nbenefit from having trusted sources of information in the results, and the publishers benefit from the traffic to their \nsites that the search engines generate.\n  Search traffic from Google accounts for half of overall visits, or more, to many sites, said Brian Morrissey, who \nwrites The Rebooting, a media business newsletter.\n  ''Search has been the mainstay of the publishing business on the internet,'' he said.\n  Kyle Sutton, director of search and product at the newspaper publisher Gannett, said the relationship had, until \nnow, been mutually beneficial.\n  ''While all search results are taking from our data and, from our perspective, crawling our content, aggregating our \ncontent, there is the return there of them driving traffic to our site,'' Mr. Sutton said. ''So I think that relationship is \nkind of first and foremost what we want to see maintained.''\nPublishers Gird for Threat From A.I.\n  The new offerings could change all of that, said Barbara Peng, the president of the digital news brand Insider. \nMicrosoft is incorporating the chatbot into Bing, its search engine. Google's search chatbot, Bard, is separate from \nits main search engine.\n  ''This will be revolutionary,'' Ms. Peng said, adding, ''It will take some time, and there is a good portion of hype \nmixed in there, too, but I do think it will change the relationship people have with finding and consuming \ninformation.''\n  The impact of ''generative'' A.I., which can generate text, images and other media from prompts, has become a \ntop priority in discussions among publishers. A conference in New York in May, the World Congress of News \nMedia, will feature keynote speeches on the issue, according to a schedule on its website.\n  Vice Media has created a task force in recent months to examine its own approach, said Cory Haik, the chief \noperating officer. ''It will have a huge impact on publishing in ways that we can't even get our heads around yet,'' \nshe predicted.\n  The Washington Post announced on Tuesday that it had appointed a deputy business editor to lead an internal \ngroup looking at A.I.'s impact on The Post's journalism and digital strategy.\n  News Corp's chief executive, Robert Thomson, who for years has led a push to get tech companies to pay for \nnews content, said in an interview: ''If you don't get out early and define what the issues are and the obligations, \nthen you will find yourself on the defensive.''\n  Mr. Thomson said tech companies should pay to use publishers' content to produce results from A.I. chatbots. The \nchatbots generate their results by synthesizing information from the internet. He added that News Corp, which owns \nThe Wall Street Journal and The New York Post among other outlets, was in talks with ''a couple of companies'' \nabout the use of its content, though he declined to specify which ones.\n  ''There is a recognition at their end that discussions are necessary,'' he said.\n  Roger Lynch, the chief executive of Condé Nast, which owns titles like Vogue, Vanity Fair and Glamour, agreed \nthat content creators should be compensated. He said one upside for publishers was that audiences might soon \nfind it harder to know what information to trust on the web, so ''they'll have to go to trusted sources.''\n  The News Media Alliance, which represents 2,000 outlets around the world, including The New York Times, is \nworking on principles that it says should guide the use and development of A.I. systems, and regulation around \nthem, to protect publishers. According to a draft, the principles say the use of publisher content for the development \nof A.I. should require ''a negotiated agreement and explicit permission.''\n  The guidelines also call on tech companies to ''provide sufficient value'' for high-quality, trustworthy journalism \ncontent and brands, and state that any new laws or regulations that make exceptions to copyright law for A.I. must \nnot weaken protections for publishers.\n  ''Without these protections, publishers -- far too many of whom already struggle to survive in the online ecosystem \ndue to marketplace imbalances -- face an existential crisis that threatens our communities' access to reliable and \ntrustworthy journalism,'' the document states.\n  Danielle Coffey, executive vice president of the News Media Alliance, said a solution could be found in the \nJournalism Competition and Preservation Act, a bill that would allow publishers to collectively negotiate with tech \ncompanies over revenue sharing and, as written, would account for the use of content by generative A.I. The bill, \nwhich failed to pass last year, is expected to be reintroduced on Thursday by Senators Amy Klobuchar, Democrat \nof Minnesota, and John Kennedy, Republican of Louisiana.\n  Yusuf Mehdi, Microsoft's head of Bing, said in an interview that directing users to click through to publishers was \n''a top goal.'' And although the new Bing has been around for less than two months, the data was ''already showing \nthat we are driving, in fact, more traffic to publishers,'' he said.\nPublishers Gird for Threat From A.I.\n  ''Part of the reason that traffic is up is that we don't just do a good job of answering the question, but we provide \nlinks,'' he said, pointing to footnotes in the answers on Bing's chatbot that show the information's source.\n  Mr. Mehdi said Microsoft was at the beginning of its conversations with publishers around the new search. ''It is \nour intention that we would like to share incremental revenue that happens in that chat experience,'' he said.\n  Microsoft is considering showing more articles from a certain publisher below the footnote or selling ads against \nthe links in the chat answer and splitting the proceeds, Mr. Mehdi said.\n  A Google spokeswoman said in a statement that the company was ''deeply committed to supporting a healthy and \nvibrant news ecosystem'' and would put a priority on sending traffic.\n  ''This is the very early days of testing an experience in Bard, and we'll be welcoming conversations with publishers \nto get their input,'' she said.\n  For the past two years, BDG has focused on products like live events, email newsletters and premium branded \ncontent to limit exposure to the whims of search traffic, Mr. Goldberg said.\n  ''I think the best publishers had already anticipated this was coming years ago and are many years into our \ntransformation,'' he said.\nhttps://www.nytimes.com/2023/03/30/business/media/publishers-chatbots-search-engines.html\nGraphic\n \nThis article appeared in print on page B1, B5.               \nLoad-Date: March 31, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Apr2024",
        "header": "Infy Q4 Net Up 30%",
        "media": "Economic Times (E-Paper Edition)",
        "time": "April 19, 2024",
        "section": "MARKETS",
        "length": "852 words",
        "byline": "Our Bureaus",
        "story_text": "Infy Q4 Net Up 30%\nEconomic Times (E-Paper Edition)\nApril 19, 2024 Friday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: MARKETS\nLength: 852 words\nByline: Our Bureaus\nHighlight: Co offers a revenue guidance of 1-3% for FY25 •Operating margin to be 20-22% •Recommends final \ndividend of Rs 20 per equity share and a special dividend of Rs 8 •Expects in-tech acquisition to strengthen \nengineering R&D capabilities\nBody\nBengaluru|New Delhi: Infosys, which has the highest Nifty weighting among locally listed technology companies, \nThursday said fourthquarter net profit climbed 30% on gains in non-core income, beating DStreet estimates. \nRevenue guidance for FY25, a key monitorable for investors, remained conspicuously circumspect, although India’s \noutsourcing bellwether announced its biggest M&A deal in history, commiting nearly about half a billion dollars. \nProfit climbed to Rs 7,969 crore in the March quarter, beating ET’s poll of Rs 6,103 crore. Other income buttressed \nthe bottom-line through what turned out to be a tough year for revenue expansion, which hit the lowest pace in a \ndecade. \nHeadcount shrank by about 26,000, again a rarity for India’s technology bellwether. Revenue at Rs 37,923 crore in \nthe fourth quarter declined 2.3% sequentially and was up by merely a percentage point (1.2%) on a year-on-year \nbasis. The company’s operating margin came at 20.1%, a decline of 40 bps (1.9%) sequentially and decline of 90 \nbps (4.2%) y–o-y.  The American-listed shares of Infosys slumped 3% to $16.45 apiece late evening India time. \nInfosys’ new chief financial officer Jayesh Sanghrajka told analysts af-  ter the earnings that the company rescoped \na financial services deal, causing an impact of more than one percentage point on revenues. “While part of the work \ngot rescoped, over 85% of the contract is still with us,” he said. Sanghrajka clarified that this rescoping and \nrenegotiation “has nothing to do with gen AI.” Infosys gave a FY25 revenue guidance of 1-3% even as it won \n“record deals” totalling $17.7 billion in FY24. Chief executive Salil Parekh said some of the gains from the deal wins \nhave been baked into the revenue guidance. It expects operating margin to be in the range of 20-22%.  Parekh \nmaintained a cautionary tone for the overall demand environment and said that only some verticals such as banking \nand financial services are expected to be better in  FY25 while others like manufacturing are expected to be “slow”. \nInfosys recommended a final dividend of Rs 20 per equity share, and additionally a special dividend of Rs 8 per \nequity share. BOTTOMING OUT? “Infosys experienced a slight decline in Q4 revenue, attributed to weakness in \ndiscretionary spending and customers taking more time to make purchasing decisions,” said  Biswajit Maity, senior \nprincipal analyst, Gartner. “Its innovative approach, extensive industry partnerships, competitive pricing, and \nflexibility position it as a key player in the ecosystem.” Infosys announced that it is acquiring in-tech, an engineering \nR&D services provider focused on the German automotive industry. The acquisition is pegged at  450million (about \n$480 million), and the consideration includes upfront and earnouts, excluding management incentives, and \nretention bonus. “This strategic investment further strengthens Infosys’ engineering R&D capabilities and reaffirms \nits continued commitment to global clients to navigate their digital engineering journey,” said the  company in a \nstatement. Infosys in 2012 acquired Swiss technology consulting firm Lodestone Holding for $350 million. And in \n2019, it acquired Irish contact centre Eishtec for an undisclosed amount. Indian IT companies have been acquisition \nshy as compared with their global peers, with the exception of Wipro that bought a dozen companies under its \nInfy Q4 Net Up 30%\nformer CEO Thierry Delaporte. Companies, however, have found it hard to integrate some of the acquisitions. In \n2015, Infosys acquired Panaya for $200 million, but failure to capture announced synergies was often blamed for \nthe ouster of its then CEO, Vishal Sikka. Analysts said, however, that the guidance is not sacrosanct. Infosys last \nfiscal lowered its revenue guidance three times, but the margin guidance has remained in the 20% ballpark through \nlast fiscal year and FY25. “Consistent with the objective of giving high and predictable returns to shareholders, the \nboard has approved the capital allocation policy under which the company expects to return 85% over the next 5 \nyears and progressively increase annual dividend per share,” said the CFO.  PAIN POINTSNorth America \ncontinues to see negative growth for the company, while Europe is doing better in line with its industry peers. While \nrevenue from North America constituted about 59.6% in the just concluded quarter, Europe gave about 28.6% in \nthe same period. Two revenue streams, financial services and retail, saw shrinkages of 8.4% and 3%, respectively, \nin the number of clients. Infosys ended FY24 with 25,994 fewer employees compared with FY23. This is the first \ntime the company has reported a fullyear dip in headcount in over two decades. It concluded the fiscal year with a \ntotal employee count of 317,240. “Our hiring model has changed significantly in the last few quarters... We are now \non a more agile model of campus hiring,” said Sanghrajka. Employee utilisation is at 82% now, up from 77% at the \nstart of the year. Infosys also disclosed favourable income tax rulings that reduced contingent liabilities and \nreversed earlier liabilities.\nLoad-Date: April 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "The S.E.C.’s Chief Is Worried About A.I.; DealBook Newsletter",
        "media": "The New York Times",
        "time": "August 7, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1903 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni",
        "story_text": "The S.E.C.’s Chief Is Worried About A.I.; DealBook Newsletter\nThe New York Times \nAugust 7, 2023 Monday 07:57 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1903 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni\nHighlight: Gary Gensler, who has studied the consequences of artificial intelligence for years, said that the \ntechnology could lead to future financial crises.\nBody\nGary Gensler, who has studied the consequences of artificial intelligence for years, said that the technology could \nlead to future financial crises.\nA financial regulator issues a warning on A.I. \nGary Gensler, the chairman of the S.E.C., has been studying the potential consequences of artificial intelligence for \nyears. The recent proliferation of generative A.I. tools like ChatGPT has demonstrated that the technology is set to \ntransform business and society.\nMr. Gensler outlined some of his biggest concerns in an interview with DealBook’s Ephrat Livni.\nA.I. could be the next big systemic risk to the financial system. In 2020, Mr. Gensler co-wrote a paper about deep \nlearning and financial stability. It concluded that just a few A.I. companies will build the foundational models that \nunderpin the tech tools that lots of businesses will come to rely on, based on how network and platform effects have \nbenefited tech giants in the past.\nMr. Gensler expects that the United States will most likely end up with two or three foundational A.I. models. This \nwill deepen interconnections across the economic system, making a financial crash more likely because when one \nmodel or data set becomes central, it increases “herding” behavior, meaning that everyone will rely on the same \ninformation and respond similarly.\n“This technology will be the center of future crises, future financial crises,” Mr. Gensler said. “It has to do with this \npowerful set of economics around scale and networks.”\nA.I. models may put companies’ interests ahead of investors’. The meme stock frenzy driven by social media and \nthe rise of retail trading on apps highlighted the power of nudges and predictive algorithms. But are companies that \nuse A.I. to study investor behavior or recommend trades prioritizing user interests when they act on that \ninformation?\nThe S.E.C. last month proposed a rule that would require platforms to eliminate conflicts of interest in their \ntechnology. “You’re not supposed to put the adviser ahead of the investor, you’re not supposed to put the broker \nahead of the investor,” Mr. Gensler said. “And so we put out a specific proposal about addressing those conflicts \nthat could be embedded in the models.”\nWho is responsible if generative A.I. gives faulty financial advice? “Investment advisers under the law have a \nfiduciary duty, a duty of care, and a duty of loyalty to their clients,” Mr. Gensler said. “And whether you’re using an \nalgorithm, you have that same duty of care.”\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nPrecisely who is legally liable for A.I. is a matter of debate among policymakers. But Mr. Gensler says it’s fair to ask \nthe companies to create mechanisms that are safe and that anyone who uses a chatbot is not delegating \nresponsibility to the tech. “There are humans that build the models that set up parameters,” he said.\nHERE’S WHAT’S HAPPENING \n“Barbie” is a billion-dollar phenomenon. Warner Bros. said that the movie had reached the $1 billion mark faster \nthan any other in its history. The feat may help further dispel the notion that women-focused movies are limited in \ntheir appeal, with “Barbie” having outperformed bigger-budget blockbusters like the latest “Indiana Jones” and \n“Mission: Impossible” sequels.\nSaudi Aramco reports a 38 percent drop in quarterly profit. The state-controlled oil giant earned $30 billion in the \nsecond quarter, sharply lower than in the same period last year, driven partly by declining global crude prices. \nRiyadh is trying to counteract that by prolonging a production cut of a million barrels per day through September, a \nmove that the kingdom said could be “extended or extended and deepened” as necessary.\nThe U.A.W. makes a bold opening bid in talks with big automakers. The United Auto Workers has asked for \nconcessions including a 40 percent wage increase and guarantees that workers hired at new electric-vehicle battery \nplants would be covered by the union’s national contracts. Behind its demands are high profits at Ford, General \nMotors and Stellantis — and the risk of job cuts amid a switch to E.V. production.\nWarren Buffett’s Berkshire Hathaway reports a rise in earnings. The conglomerate benefited from improving \nperformance at its Geico insurance arm and strong performance in stocks it holds, principally Apple, as it reported \nnearly $36 billion in net income and $10 billion in operating earnings. Berkshire’s cash holdings are now about $147 \nbillion, near a record, raising questions about what Mr. Buffett will do with that war chest.\nU.S. researchers duplicate a nuclear fusion feat. Scientists at the federal Lawrence Livermore National Laboratory \nsaid they had again managed to achieve net gain in a fusion reaction — meaning that it yielded more energy than it \nconsumed — but managed to get even more power out this time. The results are an advancement in a process that \nresearchers hope will produce clean and cheap energy, though it could be decades away.\nA bankruptcy that could cost taxpayers millions\nThe trucking giant Yellow finally filed for bankruptcy protection overnight, nearly two weeks after shutting its doors \nand three years after receiving a $700 million loan from the federal government during the pandemic. The shutdown \nmeans the loss of 30,000 jobs and could shake up the business of moving goods around the United States — as \nwell as raise questions about how much money taxpayers will lose.\nYellow has struggled for years. A final blow came when the company, formerly known as YRC, was unable to strike \na deal with the Teamsters union, which represents its drivers, on a new contract.\nYellow has accused the Teamsters of blocking a restructuring effort that, the company argued, would have helped it \navoid Chapter 11. The union “knowingly and intentionally triggered a death spiral for Yellow,” Matthew Doheny, the \ncompany’s chief restructuring officer, wrote in a court filing.\nA Teamsters spokesman told The Wall Street Journal that the union had been giving wage and pension \nconcessions for years: “Yellow couldn’t manage itself, and it wasn’t up to Teamsters to do it for them,” the \nrepresentative said.\nYellow’s deal-making didn’t help. The company embarked on an acquisition spree after the 2008 financial crisis, \nand experts said it failed to integrate those businesses. The deals also contributed to an onerous debt load that \ntotaled about $1.5 billion as of March. The company has twice had to reorganize its finances to avoid default.\n“Yellow was struggling to keep its head above water and survive,” Jack Atkins, an analyst at Stephens, told The \nTimes.\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nTaxpayers could be on the hook for losses. In 2020, Yellow took out a pandemic relief loan from the federal \ngovernment. That move has since been questioned, with House Democrats writing in a report last year that the \nTrump administration had provided the rescue package over objections from Defense Department officials.\nThe company has repaid just $230 of the principal on the loan, which comes due next year. The government \nacquired a 30 percent stake in Yellow via the deal, and could end up assuming or trying to sell off much of the \ncompany’s fleet of trucks and terminals — though how much it will recover is unclear.\n‘Do we need another rate increase?’ \nJohn Williams, the president of the New York Fed, expects interest rates to start coming down next year as efforts \nby the central bank to cool the economy near their peak.\nMr. Williams’s comments suggest that slowing inflation could prompt a shift in Fed policy amid hopes that the \neconomy is heading for a soft landing and avoiding a recession. From his conversation with The Times’s Jeanna \nSmialek:\nGiven what I see today, from the perspective of the data that we have, I think — it’s not about having to tighten \nmonetary policy a lot. To me, the debate is really about: Do we need to do another rate increase? Or not?\nI think we’re pretty close to what a peak rate would be, and the question will really be — once we have a good \nunderstanding of that, how long will we need to keep policy in a restrictive stance, and what does that mean.\n“Exact date is still in flux. I’m getting an MRI of my neck &amp; upper back tomorrow. May require surgery before \nthe fight can happen.”\n— Elon Musk, responding to questions about when he would stage a cage fight with the Meta C.E.O. Mark \nZuckerberg. The tech moguls have traded barbs recently; Musk posted his message after Zuckerberg said his rival \nhadn’t responded to his suggestion of holding the match on Aug. 26.\nThe week ahead\nA key reading on inflation and Disney’s latest earnings will be top of mind for investors this week. Here’s what to \nwatch.\nToday: The online homework help company Chegg — whose stock plunged in May after its C.E.O. warned that \nChatGPT threatened its business model — is set to report earnings.\nTomorrow: UPS and Restaurant Brands, the owner of Burger King, will report. The Japanese tech investor \nSoftBank will also disclose results; it may announce a profit after five quarters of losses.\nWednesday: Disney reports, and analysts are sure to press its C.E.O., Bob Iger, on an array of topics, including: \nefforts to find a strategic partner for ESPN; whether he intends to sell the company’s legacy TV businesses like \nABC; any improvements on streaming numbers; and his outlook on Hollywood, given the writers’ and actors’ \nstrikes.\nAlso, China reports inflation data for July. Economists are worried that the country may slip into deflation.\nThursday: U.S. Consumer Price Index data for July is due. Economists forecast a 3.3 percent rise in headline \ninflation from the same time a year ago, up only slightly from the 3 percent increase reported in June. That would be \nthe smallest monthly price rise in two years; the measure will be closely watched by Fed officials ahead of their next \nrate-setting meeting in September.\nAlso, the Chinese tech giant Alibaba reports, and Virgin Galactic will launch its second commercial flight to the edge \nof space.\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nFriday: The University of Michigan publishes preliminary data for its Consumer Sentiment Index; the measure has \nbeen showing steady rises in recent months as the economy improves.\nTHE SPEED READ \nDeals\n• Saudi Arabia’s sovereign wealth fund, the Public Investment Fund, lost $15.6 billion last year, as investments \nin SoftBank’s Vision Fund and other tech ventures soured. (Bloomberg)\n• Private equity firms are reportedly offering incentives including discounts on management fees to prospective \ninvestors, as many struggle to raise new funds. (FT)\nPolicy\n• Republican voters appear less interested in fighting “woke” corporations than many candidates for the 2024 \nG.O.P. presidential nomination are. (NYT)\n• A federal judge allowed the Justice Department’s antitrust lawsuit against Google to proceed, but limited the \nscope of the case. (WaPo, NYT)\n• The Carlyle co-founder David Rubenstein offered a creative, if unlikely, proposal to resolve voter concerns \nabout Donald Trump’s and President Biden’s candidacies. (Puck)\nBest of the rest\n• “Big Oil’s Talent Crisis: High Salaries Are No Longer Enough” (WSJ)\n• The ordeal of a woman who was wrongly arrested on robbery charges while eight months pregnant illustrates \nthe dangers of police use of facial recognition software to identify criminals. (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Gary Gensler, the head of the S.E.C., sees A.I. as a transformational technology. (PHOTOGRAPH BY \nLeah Millis/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "events_conversation_Jan2024",
        "header": "What Students Are Saying About Learning to Write in the Age of A.I.; current",
        "media": "events conversation",
        "time": "January 25, 2024",
        "section": "LEARNING",
        "length": "2159 words",
        "byline": "The Learning Network",
        "story_text": "What Students Are Saying About Learning to Write in the Age of A.I.; current \nevents conversation\nThe New York Times \nJanuary 25, 2024 Thursday 15:34 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 2159 words\nByline: The Learning Network\nHighlight: Does being able to write still matter when chatbots can do it for us? Teenagers weigh in on an essay \nfrom Opinion.\nBody\nDoes being able to write still matter when chatbots can do it for us? Teenagers weigh in on an essay from Opinion.\nWith artificial intelligence programs like ChatGPT that can generate prose for us, how much should we care about \nlearning to write — and write well? \nIn “Our Semicolons, Ourselves,” the Opinion contributor Frank Bruni argues that, for a multitude of reasons, \ncommunicating effectively is a skill we should still take seriously. “Good writing burnishes your message,” he writes. \n“It burnishes the messenger, too.”\nWe asked teenagers what they thought: Does learning to be a good writer still matter in the age of A.I.? Or will the \ntechnology someday replace the need for people to learn how to put pen to paper and fingers to keyboard? \nTake a look at their conversation below, which explores the benefits of learning to express oneself, the promise and \nperils of chatbots, and what it means to be a writer.\nThank you to everyone who participated in the conversation on our writing prompts this week, including students \nfrom Glenbard North High School in Carol Stream, Ill.; Hinsdale Central High School in Hinsdale, Ill. and New \nRochelle High School in New Rochelle, N.Y.\nPlease note: Student comments have been lightly edited for length, but otherwise appear as they were originally \nsubmitted.\n_________\nMany students agreed with Mr. Bruni that learning to write is important. Some pointed to the practical reasons.\nWhen you write any sort of persuasive essay or analysis essay, you learn to communicate your ideas to your \naudience. This skill can then be applied to your daily life. Whether it’s talking to your teachers, writing an email to \nyour boss, or sending a text message to your friends, writing and communication is a fundamental ability that is \nneeded to clearly and concisely express yourself. This is something that A.I. cannot help you with.\n— Mara F.R., Hinsdale\nWhat Students Are Saying About Learning to Write in the Age of A.I. current events conversation\nIn order to write, we must first be able to think on our own which allows us to be self-sufficient. With the frequent \nuse of A.I., our minds become reliant on given information rather than us thinking for ourselves. I absolutely believe \nthat learning to be a good writer still matters even in the age of Artificial Intelligence. \n— Jordyne, Ellisville\nI firmly believe that learning good writing skills develops communication, creativity, and problem-solving skills. A.I. \ncan also be used as a tool; I have used it to ask practice questions, compare my answers, and find different/better \nways to express myself. Sure, having my essay written for me in seconds is great, but come time for an interview or \npresentation later on in my life I’ll lack the confidence and ability to articulate my thoughts if I never learn how.\n— CC, San Luis Obispo County\nI, being a senior, have just finished my college applications. Throughout the process, I visited several essay help \nwebsites, and each one stressed this fact: essay readers want to hear a student’s voice. ChatGPT can write well-\nstructured essays in two minutes, but these essays have no voice. They are formulaic and insipid — they won’t help \na student get into UCLA. To have a chance, her essays must be eloquent and compelling. So, at least until AI \nwriting technology improves, a student must put in the work, writing and rewriting until she has produced an essay \nthat tells readers who she is.\n— Cole, Central Coast, CA\nOthers discussed the joy and satisfaction that comes with being able to express oneself. \nWhile AI has its advantages, it can’t replicate the satisfaction and authenticity which comes from writing by yourself. \nAI uses the existing ideas of others in order to generate a response. However, the response isn’t unique and \ndoesn’t truly represent the idea the way you would. When you write, it causes you to think deeply about a topic and \ncome up with an original idea. You uncover ideas which you wouldn’t have thought of previously and understand a \ntopic for more than its face value. It creates a sense of clarity, in which you can generate your own viewpoint after \nlooking at the different perspectives. Another example is that the feeling of writing something by yourself generates \nfeelings of pleasure and satisfaction. The process of doing research about a topic for hours, to then come up with \nyour own opinion. Or the feeling of having to use a dictionary to understand a word which you don’t know the \nmeaning of. The satisfaction and authenticity or writing by yourself is irreplaceable. Therefore, it is still important to \nlearn to be a good writer. \n— Aditya, Hinsdale\nYou cannot depend on technology to do everything for you. An important factor of writing is expressing yourself and \nshowing creativity. While AI can create a grammatically correct essay, it cannot express how you feel on the \nsubject. Creativity attracts an audience, not being grammatically correct. Learning to write well-written essays \nwithout the assistance of AI is a skill that everyone should have. \n— Aidan, Ellisville\nA few commenters raised ethical concerns around using generators like ChatGPT.\nI feel that even with AI, learning how to be a good writer still matters. For example, if you’re writing a college essay \nor an essay for a class using an AI generated thing, that is plagiarism, which can get you in a lot of trouble because \nit is against the law to take something that is not yours and try to make it seem like it is your writing. So I believe \nthat learning how to be a good writer still matters a lot because if you want to get into a good college or get good \ngrades, you need to know how to write at least semi-well and make sure the writing is in your own words, not words \nalready generated for you. \n— jeo, new york\nWhat Students Are Saying About Learning to Write in the Age of A.I. current events conversation\nThere are obvious benefits, and I myself have used this software to better understand Calculus problems in a step \nby step format, or to answer my questions regarding a piece of literature, or time in history. That being said, ethics \nshould be considered, and credit should be given where credit is due; as sources are cited in a traditional paper, so \nshould the use of ChatGPT. \n— Ariel, Miami Country Day School\nWriting is still an important skill, but maybe not in the same way it has in the past. In an era of improving AI, topics \nsuch as grammar and spelling are less important than ever. Google already corrects small grammar mistakes; how \nlong till they can suggest completely restructuring sentences? However, being a good writer is more than just \ngrammar and vocabulary. It’s about collecting your thoughts into a cohesive and thoughtful presentation … If you \nwant to communicate your own ideas, not just a conglomerate of ones on the internet, you’re better off just writing it \nyourself. That’s not to mention the plethora of issues like AI just making stuff up from time to time. So for now at \nleast, improving your writing is still the best way to share your thoughts. \n— Liam, Glenbard West High School\nSeveral students shared how they use A.I. as a resource to aid, rather than replace, their own effort.\nI think AI should be a tool for writers. It can help make outlines for writing pieces and it could help solve problems \nstudents are stuck on and give them an explanation. However, I think the line should be drawn if students use AI to \ndo the whole entire assignment for them. That’s when it should be considered cheating and not be used.\n— Sam, Hinsdale, IL\nSometimes I use A.I. programs such as ChatGPT to help with typing and communication. The results vary, but \noverall I find it helpful in generating creative ideas, cleaning up language, and speeding up the writing. However, I \nbelieve it is important to be careful and filter the results to ensure accuracy and precision. AI tools are valuable aids, \nbut human input and insight are still needed to achieve the desired quality of written communication. \n— Zach, New Rochelle High School\nAs of now, A.I. is not capable of replacing human prose effectively. Just look at the data, the only A.P. tests that \nChatGPT did not pass were the ones for English Language and English Literature. This data lays bare a fact that \nmost students refuse to accept: ChatGPT is not able to write a quality essay yet. Now that many schools are \nloosening restrictions regarding the use of generative A.I., students have two options: either they get back to work \nor they get a bad grade for their A.I.-generated essay. \nOn the other hand, there is another alternative that is likely to be the best one yet. A good friend once said, “A.I. \nsoftware like ChatGPT solves the issue of having a clean sheet of paper”. By nature, humans are terrible at getting \nanything started. This is the issue that ChatGPT solves. As Bruni asserts, “Writing is thinking, but it’s thinking \nslowed down — stilled — to a point where dimensions and nuances otherwise invisible to you appear.” This is true, \nbut ChatGPT can help students by creating a rough draft of what those ideas might look like on paper. The endpoint \nis this: while students are likely to keep needing to become good writers to excel at school, A.I. technology such as \nChatGPT and Grammarly will become additional tools that will help students reach even higher levels of literary \nexcellence.\n— Francisco, Miami Country Day School\nBut some thought we might not be far from a future where A.I. can write for us.\nI think that AI will eventually replace the need for the average person to write at the level that they do. AI is no \ndifferent than every other tech advancement we’ve made, which have made tasks like writing easier. Similar \nconcerns could have been raised with the introduction of computers in the classroom, and the loss of people having \ngreat handwriting. I don’t think the prospect should be worrying. AI is a tool. Having it write for us will allow us to \nfocus on more important things that AI is not yet capable of. \nWhat Students Are Saying About Learning to Write in the Age of A.I. current events conversation\n— zack, Hinsdale Central\nAI is becoming wildly accessible and increasingly more competent. The growth of this sector could mean more \nstudents find their way to an AI site to look for an answer. I agree that this could spell trouble for student intelligence \nif passable answers are so readily available. But you might want to consider the students themselves. The majority \nare hardworking and smart, not just smart about subjects in school, but about how using only AI for their work could \nend badly. Students will probably not use the newborn tech first hand until it is basically errorless, and that will take \nsome time. \n— Beau, Glen Ellyn, IL\nEven so, there were students who doubted that technology could ever replace “what it means to be a writer.”\nI don’t think AI will fully be able to replace humans, no matter how much time we as a society take to implement it \ninto everyday life, as they are still just a bunch of numbers and code, and the complexity of a human and the \nintricacies of our emotions, our thoughts, and feelings, along with what makes each of us an individual, someone \nthat matters, proves that humans will never be able to be fully replicated by AI, and that the most emotion-centric \njobs, such as writing, and most fields in art, will forever be, or should forever be, dominated by the experiences and \nemotional complexity of humans. \n— Liam, Hinsdale\nAI uses data from the internet it gathers and then puts together a paragraph or two, while it may be able to do this \nfaster than any human, it does not have any authenticity. If it is pulling its information from the web where someone \nhas said something similar, the data found may be biased and the AI would not care. Yet some people still insist it’s \nthe future for writing when in reality, AI will probably not come up with an original idea and only use possibly biased \ndata to give to someone so they can just copy it and move on and undermine what it means to be a writer. \n— John, Glenbard North HS\nI have never personally used ChatGPT as I believe no robot can recreate the creativity or authenticity humans \nachieve in writing … Even with growing advances in technology, AI can only create with the information it already \nknows, which takes away the greatest quality writers have: creativity.\n— Stella, Glenbard West\nIn my opinion, learning to be a good writer absolutely still matters in the age of AI. While artificial intelligence can \nassist with certain aspects of writing, such as grammar and syntax checking, it cannot replace the creativity, critical \nthinking, and emotional intelligence that we human writers bring to the table. Another reason is that storytelling, \npersuasion, and the art of crafting a compelling narrative are skills deeply rooted in human intuition and empathy. A \ngood writer can connect with readers on a personal level, inspiring thoughts, feelings, and actions. AI may enhance \nefficiency, but it cannot replicate the authentic voice and unique perspective that a human writer brings to their \nwork.\n— McKenzie, Warrington, PA\nLearn more about Current Events Conversation here and find all of our posts in this column.\nPHOTO:  (PHOTOGRAPH BY Ben Wiseman FOR THE NEW YORK TIMES)\nLoad-Date: January 25, 2024"
    },
    {
        "file_name": "Tools;_News_Analysis_May2023",
        "header": "The Next Fear on A.I.: Hollywood’s Killer Robots Become the Military’s",
        "media": "Tools; News Analysis",
        "time": "May 10, 2023",
        "section": "US; politics",
        "length": "1573 words",
        "byline": "David E. Sanger",
        "story_text": "The Next Fear on A.I.: Hollywood’s Killer Robots Become the Military’s \nTools; News Analysis\nThe New York Times \nMay 5, 2023 Friday 10:50 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 1573 words\nByline: David E. Sanger\nHighlight: U.S. national security officials are warning about the potential for the new technology to upend war, \ncyber conflict and — in the most extreme case — the use of nuclear weapons.\nBody\nU.S. national security officials are warning about the potential for the new technology to upend war, cyber conflict \nand — in the most extreme case — the use of nuclear weapons.\nWhen President Biden announced sharp restrictions in October on selling the most advanced computer chips to \nChina, he sold it in part as a way of giving American industry a chance to restore its competitiveness.\nBut at the Pentagon and the National Security Council, there was a second agenda: arms control.\nIf the Chinese military cannot get the chips, the theory goes, it may slow its effort to develop weapons driven by \nartificial intelligence. That would give the White House, and the world, time to figure out some rules for the use of \nartificial intelligence in sensors, missiles and cyberweapons, and ultimately to guard against some of the nightmares \nconjured by Hollywood — autonomous killer robots and computers that lock out their human creators.\nNow, the fog of fear surrounding the popular ChatGPT chatbot and other generative A.I. software has made the \nlimiting of chips to Beijing look like just a temporary fix. When Mr. Biden dropped by a meeting in the White House \non Thursday of technology executives who are struggling with limiting the risks of the technology, his first comment \nwas “what you are doing has enormous potential and enormous danger.”\nIt was a reflection, his national security aides say, of recent classified briefings about the potential for the new \ntechnology to upend war, cyber conflict and — in the most extreme case — decision-making on employing nuclear \nweapons.\nBut even as Mr. Biden was issuing his warning, Pentagon officials, speaking at technology forums, said they \nthought the idea of a six-month pause in developing the next generations of ChatGPT and similar software was a \nbad idea: The Chinese won’t wait, and neither will the Russians.\n“If we stop, guess who’s not going to stop: potential adversaries overseas,” the Pentagon’s chief information officer, \nJohn Sherman, said on Wednesday. “We’ve got to keep moving.”\nHis blunt statement underlined the tension felt throughout the defense community today. No one really knows what \nthese new technologies are capable of when it comes to developing and controlling weapons, and they have no \nidea what kind of arms control regime, if any, might work.\nThe Next Fear on A.I.: Hollywood’s Killer Robots Become the Military’s Tools News Analysis\nThe foreboding is vague, but deeply worrisome. Could ChatGPT empower bad actors who previously wouldn’t have \neasy access to destructive technology? Could it speed up confrontations between superpowers, leaving little time \nfor diplomacy and negotiation?\n“The industry isn’t stupid here, and you are already seeing efforts to self-regulate,” said Eric Schmidt, the former \nGoogle chairman who served as the inaugural chairman of the advisory Defense Innovation Board from 2016 to \n2020.\n“So there’s a series of informal conversations now taking place in the industry — all informal — about what would \nthe rules of A.I. safety look like,” said Mr. Schmidt, who has written, with former secretary of state Henry Kissinger, \na series of articles and books about the potential of artificial intelligence to upend geopolitics.\nThe preliminary effort to put guardrails into the system is clear to anyone who has tested ChatGPT’s initial \niterations. The bots will not answer questions about how to harm someone with a brew of drugs, for example, or \nhow to blow up a dam or cripple nuclear centrifuges, all operations the United States and other nations have \nengaged in without the benefit of artificial intelligence tools.\nBut those blacklists of actions will only slow misuse of these systems; few think they can completely stop such \nefforts. There is always a hack to get around safety limits, as anyone who has tried to turn off the urgent beeps on \nan automobile’s seatbelt warning system can attest.\nThough the new software has popularized the issue, it is hardly a new one for the Pentagon. The first rules on \ndeveloping autonomous weapons were published a decade ago. The Pentagon’s Joint Artificial Intelligence Center \nwas established five years ago to explore the use of artificial intelligence in combat.\nSome weapons already operate on autopilot. Patriot missiles, which shoot down missiles or planes entering a \nprotected airspace, have long had an “automatic” mode. It enables them to fire without human intervention when \noverwhelmed with incoming targets faster than a human could react. But they are supposed to be supervised by \nhumans who can abort attacks if necessary.\nThe assassination of Mohsen Fakhrizadeh, Iran’s top nuclear scientist, was conducted by Israel’s Mossad using an \nautonomous machine gun that was assisted by artificial intelligence, though there appears to have been a high \ndegree of remote control. Russia said recently it has begun to manufacture — but has not yet deployed — its \nundersea Poseidon nuclear torpedo. If it lives up to the Russian hype, the weapon would be able to travel across an \nocean autonomously, evading existing missile defenses, to deliver a nuclear weapon days after it is launched.\nSo far there are no treaties or international agreements that deal with such autonomous weapons. In an era when \narms control agreements are being abandoned faster than they are being negotiated, there is little prospect of such \nan accord. But the kind of challenges raised by ChatGPT and its ilk are different, and in some ways more \ncomplicated.\nIn the military, A.I.-infused systems can speed up the tempo of battlefield decisions to such a degree that they \ncreate entirely new risks of accidental strikes, or decisions made on misleading or deliberately false alerts of \nincoming attacks.\n“A core problem with A.I. in the military and in national security is how do you defend against attacks that are faster \nthan human decision-making, and I think that issue is unresolved,” Mr. Schmidt said. “In other words, the missile is \ncoming in so fast that there has to be an automatic response. What happens if it’s a false signal?”\nThe Cold War was littered with stories of false warnings — once because a training tape, meant to be used for \npracticing nuclear response, was somehow put into the wrong system and set off an alert of a massive incoming \nSoviet attack. (Good judgment led to everyone standing down.) Paul Scharre, of the Center for a New American \nSecurity, noted in his 2018 book “Army of None” that there were “at least 13 near use nuclear incidents from 1962 \nto 2002,” which “lends credence to the view that near miss incidents are normal, if terrifying, conditions of nuclear \nweapons.”\nThe Next Fear on A.I.: Hollywood’s Killer Robots Become the Military’s Tools News Analysis\nFor that reason, when tensions between the superpowers were a lot lower than they are today, a series of \npresidents tried to negotiate building more time into nuclear decision making on all sides, so that no one rushed into \nconflict. But generative A.I. threatens to push countries in the other direction, toward faster decision-making.\nThe good news is that the major powers are likely to be careful — because they know what the response from an \nadversary would look like. But so far there are no agreed-upon rules.\nAnja Manuel, a former State Department official and now a principal in the consulting group Rice, Hadley, Gates \nand Manuel, wrote recently that even if China and Russia are not ready for arms control talks about A.I., meetings \non the topic would result in discussions of what uses of A.I. are seen as “beyond the pale.”\nOf course, the Pentagon will also worry about agreeing to many limits.\n“I fought very hard to get a policy that if you have autonomous elements of weapons, you need a way of turning \nthem off,” said Danny Hillis, a computer scientist who was a pioneer in parallel computers that were used for \nartificial intelligence. Mr. Hillis, who also served on the Defense Innovation Board, said that Pentagon officials \npushed back, saying, “If we can turn them off, the enemy can turn them off, too.”\nThe bigger risks may come from individual actors, terrorists, ransomware groups or smaller nations with advanced \ncyber skills — like North Korea — that learn how to clone a smaller, less restricted version of ChatGPT. And they \nmay find that the generative A.I. software is perfect for speeding up cyberattacks and targeting disinformation.\nTom Burt, who leads trust and safety operations at Microsoft, which is speeding ahead with using the new \ntechnology to revamp its search engines, said at a recent forum at George Washington University that he thought \nA.I. systems would help defenders detect anomalous behavior faster than they would help attackers. Other experts \ndisagree. But he said he feared artificial intelligence could “supercharge” the spread of targeted disinformation.\nAll of this portends a new era of arms control.\nSome experts say that since it would be impossible to stop the spread of ChatGPT and similar software, the best \nhope is to limit the specialty chips and other computing power needed to advance the technology. That will \ndoubtless be one of many different arms control plans put forward in the next few years, at a time when the major \nnuclear powers, at least, seem uninterested in negotiating over old weapons, much less new ones.\nPHOTOS: Patriot missile launchers, left, have an “automatic” mode, but are supposed to be supervised by humans. \nAbove, Eric Schmidt, the former Google chairman, says the defense industry is self-regulating. (PHOTOGRAPHS \nBY SEAN MURPHY/ASSOCIATED PRESS; MIKE BLAKE/REUTERS) (A17) This article appeared in print on page \nA1, A17.\nLoad-Date: May 10, 2023"
    },
    {
        "file_name": "Chipmaker_says_sales_this_quarter_will_be_about_$24_billion,_beating_Feb2024",
        "header": "BUSINESS; Nvidia gives upbeat forecast as AI hits a 'tipping point';",
        "media": "Chipmaker says sales this quarter will be about $24 billion, beating",
        "time": "February 22, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "638 words",
        "byline": "Ian King, King writes for Bloomberg.",
        "story_text": "BUSINESS; Nvidia gives upbeat forecast as AI hits a 'tipping point'; \nChipmaker says sales this quarter will be about $24 billion, beating \nexpectations. Its shares jump.\nLos Angeles Times\nFebruary 22, 2024 Thursday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 638 words\nByline: Ian King, King writes for Bloomberg.\nBody\nNvidia Corp. predicted another massive sales gain for the current quarter, helping justify a stock rally that has \nturned it into one of the world's most valuable companies.\nRevenue in the current period will be about $24 billion, the company said in a statement Wednesday. Analysts had \npredicted $21.9 billion, on average. Results in the fourth quarter also sailed past Wall Street estimates.\nNvidia Chief Executive Jensen Huang said generative AI has reached a \"tipping point.\" The shares jumped 9% in \nextended trading after the announcement.\nThey earlier closed at $674.72 in New York, leaving them up 36% for the year.\nThe outlook extends a streak of Nvidia shattering expectations, thanks to insatiable demand for its artificial \nintelligence accelerators -- highly prized chips that crunch data for AI models. The technology has helped power a \nproliferation of chatbots and other generative AI services, which can create text and graphics based on simple \nprompts.\n\"Accelerated computing and generative AI have hit the tipping point,\" Huang said in the statement. \"Demand is \nsurging worldwide across companies, industries and nations.\"\nNvidia's market capitalization increased by more than $400 billion this year -- bringing its valuation to $1.67 trillion -- \nas investors bet that the company will remain the prime beneficiary of an AI computing boom.\nNvidia, co-founded by Huang in 1993, got its start as a provider of graphics cards for computer gamers. Its profile \nblew up in the last two years, when its technology proved adept at handling heavy AI workloads. The company's \nH100 accelerators have become legendary in the tech world, with customers scrambling to get their hands on as \nmany as possible.\nCompanies such as Amazon.com Inc., Meta Platforms Inc., Microsoft Corp. and Alphabet Inc.'s Google are Nvidia's \nlargest customers, accounting for nearly 40% of its revenue, as they rush to invest in hardware for AI computing.\nIn the fiscal fourth quarter, which ended Jan. 28, Nvidia's revenue more than tripled to $22.1 billion. Profit was \n$5.16 a share, minus certain items. Analysts had predicted sales of about $20.4 billion and earnings of $4.60 a \nshare. Underscoring the magnitude of its recent growth streak: As recently as 2021, it didn't generate that much \nrevenue in an entire year.\nBUSINESS Nvidia gives upbeat forecast as AI hits a 'tipping point' Chipmaker says sales this quarter will be \nabout $24 billion, beating expectations. Its shares....\nNvidia's data center division, now by far its largest source of sales, generated $18.4 billion of revenue, up 409% \nfrom the same period a year earlier. Gaming chips provided $2.87 billion in sales.\nNvidia is now working to spread its AI technology beyond the big data-center companies.\nHuang, 61, has traveled the globe, saying that governments and corporations need their own AI systems -- both to \nprotect their data and to gain a competitive advantage.\nNvidia announced a deal with Cisco Systems Inc. this month that gives it a new distribution channel. As part of that \ndeal, Cisco, the world's biggest provider of networking gear, will help sell complete AI systems to companies.\nBut Nvidia faces risks, including mounting competition and a push by some customers to develop their own AI \nchips.\nAdvanced Micro Devices Inc. recently began selling a line of accelerators called the MI300. It expects revenue of \n$3.5 billion from that product this year, up from an earlier projection of $2 billion. But Nvidia isn't standing still. \nAnalysts expect the company to soon unveil more powerful accelerators.\nNvidia also has had to navigate new export rules for chips headed to China, the largest market for semiconductors. \nThe company has scaled down the capabilities of its products in order to continue to sell to that region, which in the \npast has accounted for a quarter of its revenue.\nThree months ago, Chief Financial Officer Colette Kress told analysts that the company's projections would have \nbeen higher if it weren't for the China rules.\nGraphic\n \nPHOTO: NVIDIA'S market capitalization increased by more than $400 billion this year, bringing its valuation to \n$1.67 trillion. Above, at a mobile phone trade show in 2014.  PHOTOGRAPHER:Manu Fernandez Associated Press \nLoad-Date: February 22, 2024"
    },
    {
        "file_name": "intelligence_can_help_students_learn_several_kinds_of_skills,_if_used_ethically._Apr2024",
        "header": "Colleges say AI can be used positively in the classroom; Artificial",
        "media": "intelligence can help students learn several kinds of skills, if used ethically.",
        "time": "April 9, 2024",
        "section": "LOCAL",
        "length": "639 words",
        "byline": "Eileen McClory",
        "story_text": "Colleges say AI can be used positively in the classroom; Artificial \nintelligence can help students learn several kinds of skills, if used ethically.\nDayton Daily News (Ohio)\nApril 9, 2024 Tuesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: LOCAL\nLength: 639 words\nByline: Eileen McClory\nBody\nLocal colleges say using generative AI like ChatGPT in the classroom with limitations can teach students skills like \ncritical thinking and judgement.\nUniversity policies obtained by the Dayton Daily News generally prohibit students from saying that the work of a \ngenerative AI is theirs. Students who use these technologies must cite their sources. Students who are caught can \nbe punished in the same way as if they were caught plagiarizing or cheating on an exam. \nIndividual professors have been encouraged to use language in the syllabus about the use of AI, but administration \nof the local colleges and universities have said it's up to individual professors if they'd like to use AI in the \nclassroom. \nIn one example, Edison State Community College asked professors to use one of three policies in a syllabus this \npast semester. One policy banned AI, one encouraged the use of AI but required that it be cited when used, and \none allowed some use of AI but said all final work must be the student's own. \nChristina Amato, dean of Sinclair Community College's eLearning Division, said one conversation coming out of AI \nin the classroom is \"soft skills,\" like critical thinking and problem solving. AI can generate an answer, but it takes a \nhuman to determine what the correct one is. \n\"It is a little ironic and interesting to me that AI is advancing those conversations around soft skills such as audience \ncontext, the human element of solving problems and critical thinking,\" Amato said. \nAmato said she found most students are using AI appropriately, especially when teachers have talked to students \nabout appropriate use. \n\"What we're finding is that AI usage (in) classrooms and instances in which we would find it appropriate are \nproviding some generally teachable moments for students more than kind of a gotcha and you get an F for \nplagiarism,\" she said. \nAmato said it is more about the ability to generate conversation with students on appropriate use of AI, because in \nsome cases, the student didn't understand the boundaries and limitations of what was appropriate. \nThese technologies have offered new teaching methods for professors, too. \nWright State University allows some use of AI in classrooms, but requires it be cited when used. It also cannot be \nused \"to substantially complete any assignment or exam,\" according to the policy. \nColleges say AI can be used positively in the classroom Artificial intelligence can help students learn several \nkinds of skills, if used ethically.\nTanvi Banerjee, a professor in Wright State's Department of Computer Science and Engineering, teaches a \ngraduate-level class called machine learning. In that class, she has a \"semi-permissive\" policy on AI  her students \ncan use AI tools to compare outcomes to what they would write on their own from scratch. \nShe said she sees AI as a \"smarter Google.\" \n\"It has capabilities that can be tuned to make it behave better than Google, but at the end of the day, it's still a tool,\" \nBanerjee said. \"It's not built in a way that it can be used right away.\" \nSinclair Community College communications department chair David Bodary, who teaches public speaking, has \nshown his classes how to use AI to arrange a speech or brainstorm topics. \n\"What I'm trying to get them to understand is that they have an ethical responsibility for the accuracy of the \ninformation, the integrity of the information and for their process,\" Bodary said. \nHe said he's still trying to make students understand they must think critically about the speech. While the AI tool \ncould show a student how to open a speech, for example, the student needs to decide the best way to present their \ntopic. \nThe University of Dayton has also been looking into the ways AI can be used and misused. \n\"We are considering not only how we prepare our students to engage in a world using AI for their careers, but we \nalso are looking at the complex issues regarding data governance, personal privacy and security,\" UD officials said \nin a statement.\nGraphic\n \nSinclair Community College computer science students Ayodele Ogunsakin, Spencer McNally, and Louis Jahnigen \nwork on data analysis in the Centerville campus labs. Contributed\nLoad-Date: April 9, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Nov2023",
        "header": "Artists push for AI copyright reforms, tech industry resists",
        "media": "The Baltimore Sun",
        "time": "November 28, 2023",
        "section": "MAIN; A; Pg. 11",
        "length": "589 words",
        "byline": "Matt O'Brien Associated Press",
        "story_text": "Artists push for AI copyright reforms, tech industry resists\nThe Baltimore Sun\nNovember 28, 2023 Tuesday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 11\nLength: 589 words\nByline: Matt O'Brien Associated Press\nHighlight: Actor and filmmaker Justine Bateman, right, pictured during a July 13 Writers Guild rally in Los Angeles, \nhas called on the U.S. Copyright Office to regulate AI. Mark J. Terrill/ap\nBody\nCountry singers, romance novelists, video game artists and voice actors are appealing to the U.S. government for \nrelief - as soon as possible - from the threat that artificial intelligence poses to their livelihoods.\n\"Please regulate AI. I'm scared,\" wrote a podcaster concerned about his voice being replicated by AI in one of \nthousands of letters recently submitted to the U.S. Copyright Office.\nTechnology companies, by contrast, are largely happy with the status quo that has enabled them to gobble up \npublished works to make their AI systems better at mimicking what humans do.\nThe nation's top copyright official hasn't yet taken sides. She told The Associated Press she's listening to everyone \nas her office weighs whether copyright reforms are needed for a new era of generative AI tools that can spit out \ncompelling imagery, music, video and passages of text.\n\"We've received close to 10,000 comments,\" said Shira Perlmutter, the U.S. register of copyrights, in an interview.\nPerlmutter directs the U.S. Copyright Office, which registered more than 480,000 copyrights last year but is \nincreasingly being asked to register works that are AI-generated. So far, copyright claims for fully machine-\ngenerated content have been soundly rejected because copyright laws are designed to protect works of human \nauthorship.\nBut, Perlmutter asks, as humans feed content into AI systems and give instructions to influence what comes out, \"Is \nthere a point at which there's enough human involvement in controlling the expressive elements of the output that \nthe human can be considered to have contributed authorship?\"\nThat's one question the Copyright Office has put to the public. A bigger one is what to do about copyrighted human \nworks being pulled from the internet and other sources and ingested to train AI systems, often without permission or \ncompensation.\nMore than 9,700 comments were sent to the Copyright Office, part of the Library of Congress, before an initial \ncomment period closed in late October. Another round of comments is due by Dec. 6. After that, Perlmutter's office \nwill work to advise Congress and others on whether reforms are needed.\n\"Family Ties\" actor and filmmaker Justine Bateman told the office she was disturbed that AI models were \"ingesting \n100 years of film\" and TV in a way that could destroy the structure of the film business and replace large portions of \nits labor pipeline.\nArtists push for AI copyright reforms, tech industry resists\nIt \"appears to many of us to be the largest copyright violation in the history of the United States,\" Bateman wrote. \nMeanwhile, leading tech companies like Google, Microsoft and ChatGPT maker OpenAI are telling the Copyright \nOffice that their training of AI models fits into the \"fair use\" doctrine that allows for limited uses of copyrighted \nmaterials for teaching, research or transforming the copyrighted work into something different.\n\"The American AI industry is built in part on the understanding that the Copyright Act does not proscribe the use of \ncopyrighted material to train Generative AI models,\" says a letter from Meta Platforms, the parent company of \nFacebook, Instagram and WhatsApp. The purpose of AI training is to identify patterns \"across a broad body of \ncontent,\" not to \"extract or reproduce\" individual works, it added.\nSo far, courts have largely sided with tech companies in interpreting how copyright laws should treat AI systems. In \na defeat for visual artists, a federal judge in San Francisco last month dismissed much of the first big lawsuit against \nAI image-generators but allowed some of the case to proceed.\nLoad-Date: November 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Meta Rolls Out Smart Assistants Across Apps",
        "media": "The New York Times",
        "time": "April 19, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "980 words",
        "byline": "By Mike Isaac and Cade Metz",
        "story_text": "Meta Rolls Out Smart Assistants Across Apps\nThe New York Times\nApril 19, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 980 words\nByline: By Mike Isaac and Cade Metz\nBody\nUsers of Instagram, Facebook, WhatsApp and Messenger will be able to turn to the new technology, powered by \nMeta's latest artificial intelligence model, to obtain information and complete tasks.\nOn a call with investors last spring, Mark Zuckerberg, the chief executive of Meta, said he believed that he had an \nopportunity to introduce artificially intelligent assistants ''to billions of people in ways that will be useful and \nmeaningful.'' \n  A year later, he is making good on his statement.\n  On Thursday, Meta will begin incorporating new versions of its A.I.-powered smart assistant software across its \napps, which include Instagram, WhatsApp, Messenger and Facebook. The latest technology will be rolled out in \nmore than a dozen countries, including Australia, Canada, Singapore and the United States.\n  The A.I. software will become practically omnipresent -- inside the news feed, in search bars and in chats with \nfriends. People will be able to ask the assistant, Meta A.I., for help in completing tasks and getting information, such \nas what concerts might be occurring in San Francisco on a Saturday night or the best options for vegan enchiladas \nin New York.\n  Meta A.I. is powered by LLaMA 3, the company's newest and most powerful large language model, an A.I. \ntechnology that can generate prose, conduct conversations and create images.\n  ''With LLaMA 3, Meta A.I. will now be the most intelligent freely available assistant,'' Mr. Zuckerberg said in an \ninterview. ''And because we've reached the quality level we want, we're now going to make it much more prominent \nand easier to use across all our apps.''\n  The effort is Meta's biggest rollout of products that include powerful A.I. technology. The social networking giant \nstarted weaving generative A.I. into its apps last year in a limited capacity, debuting a series of A.I.-powered \nchatbots and characters that could conduct conversations with users in September. But this new initiative exceeds \nthat in scope and aim, placing A.I. products into the most visible and most used parts of Meta's apps.\n  Other tech giants are also plugging A.I. into their products, as Silicon Valley start-ups raise billions of dollars to \nbuild A.I.-powered apps and services that they believe will define the next phase of computing.\n  Last year, Microsoft incorporated OpenAI's ChatGPT into the software giant's Bing search engine. Google has \nintegrated A.I. into products like Docs, Gmail and Google Search. Start-ups such as Perplexity and Anthropic are \nalso aiming to get more A.I.-powered products and services to consumers.\nMeta Rolls Out Smart Assistants Across Apps\n  Meta's efforts stand out because of the sheer scale of its products, which are used by nearly four billion people \nglobally every month. It is also one of the few companies to ''open source'' most of the A.I. technology they are \nbuilding, which means that anyone can look at the underlying tech and use it to build products or services for free.\n  Mr. Zuckerberg said the new A.I. rollout was part of Meta's historical ''playbook'' of adding a feature to its apps \n''when we felt it was ready.'' He pointed to products like Stories and Reels, two video and image products that \nappeared in Instagram, and how those were later amalgamated into Facebook and WhatsApp.\n  When ChatGPT arrived in late 2022, wowing people with the way it answered questions, wrote term papers and \ngenerated computer code, the tech industry raced to build similar technology -- even as the tools sometimes made \nmistakes and generated untruths.\n  Because of such flaws, OpenAI and other leading A.I. companies said they would not open source the underlying \ntechnology that powered these chatbots. (The New York Times has sued OpenAI and Microsoft, claiming copyright \ninfringement of news content related to A.I. systems.)\n  Meta took a different tack. It open sourced the first version of LLaMA in February 2023, before releasing a more \npowerful version less than six months later. Other companies have followed, including Google and a prominent \nFrench start-up, Mistral. By open sourcing the technology, independent researchers and engineers everywhere can \nhelp spot problems in the technology and improve it, the companies have said.\n  ''We have always believed in this principle and are happy to see that the industry is embracing the power of open \nsource and the positive possibilities it can create,'' Ahmad Al-Dahle, Meta's vice president of generative A.I., said \nin an interview.\n  Mr. Dahle said LLaMA 3 had shown vast improvements over Meta's previous large language models, calling it \n''significantly better'' than what people were used to.\n  Meta has also fine-tuned the A.I. model to make it slightly less conservative in the type of questions Meta A.I. will \nanswer, meaning the assistant will be less likely to refuse to answer some questions. In the past, Meta, Microsoft \nand others aimed to limit their chatbots from discussing third-rail topics like politics, religion and medical advice, \nfearing repercussions from political or interest groups.\n  To attract users, Meta will also add a faster image-generation technology into the A.I. assistant, and later plans to \nincorporate the A.I. tech into its Ray-Ban Meta smart glasses.\n  The challenge will be to convince people that the new assistants can be useful. Meta is working on helping people \nlearn what kind of questions they can ask the assistants to bring them to life, Mr. Dahle said.\n  ''Despite how prevalent these A.I. have become, there's still an education factor on how to interact with an A.I.,'' he \nsaid.\n  Like most of Meta's products, the new assistants are free to use -- and likely difficult to avoid if you are a regular \nuser of the company's apps.\n  Meta's executives don't appear worried about A.I. saturation. ''We're excited to share our next-generation assistant \nwith even more people and can't wait to see how it enhances people's lives,'' the company said.\nhttps://www.nytimes.com/2024/04/18/technology/meta-ai-assistant-push.html\nGraphic\n \nMeta Rolls Out Smart Assistants Across Apps\nPHOTO: Meta A.I. is powered by LLaMA 3, which can generate prose, conduct conversations and create images. \n(PHOTOGRAPH BY META) This article appeared in print on page B6.               \nLoad-Date: April 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "OpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’",
        "media": "The New York Times",
        "time": "January 9, 2024",
        "section": "TECHNOLOGY",
        "length": "618 words",
        "byline": "Cade Metz &lt;p&gt;Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and",
        "story_text": "OpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’\nThe New York Times \nJanuary 8, 2024 Monday 20:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 618 words\nByline: Cade Metz &lt;p&gt;Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and \nother emerging areas of technology.&lt;/p&gt;\nHighlight: The artificial intelligence start-up said that it collaborated with news organizations and that The Times, \nwhich accused it of copyright infringement, was not telling the full story.\nBody\nThe artificial intelligence start-up said that it collaborated with news organizations and that The Times, which \naccused it of copyright infringement, was not telling the full story.\nOpenAI said on Monday that a New York Times lawsuit against it was “without merit” and that it supported and \ncreated opportunities for news organizations, as it waded further into a debate over the unauthorized use of \npublished work to train artificial intelligence technologies.\nThe Times sued OpenAI and Microsoft on Dec. 27, accusing the companies of infringing on its copyrights by using \nmillions of its articles to train A.I. technologies like the ChatGPT chatbot. Chatbots now compete with The Times as \na source of reliable information, the lawsuit said.\nIn a 1,000-word blog post on Monday, OpenAI said it collaborated with news organizations and had struck \npartnerships with some of them, including The Associated Press. Using copyrighted works to train its technologies \nis fair use under the law, the company added. The Times’s lawsuit does not tell the full story of how OpenAI and its \ntechnologies operate, it said.\n“We look forward to continued collaboration with news organizations, helping elevate their ability to produce quality \njournalism by realizing the transformative potential of A.I.,” the company wrote.\nLindsey Held, a spokeswoman for OpenAI, declined further comment.\nThe Times was the first major American media organization to sue OpenAI and Microsoft over copyright issues \nrelated to its written works. Other groups, including novelists and computer programmers, have also filed copyright \nsuits against A.I. companies. The suits have been spurred by the boom in “generative A.I.,” technologies that \ngenerate text, images and other media from short prompts.\nOpenAI and other A.I. companies build this technology by feeding it enormous amounts of digital data, some of \nwhich is likely copyrighted. That has led to a realization that online information — stories, artwork, news articles, \nmessage board posts and photos — may have significant untapped value.\nA.I. companies have long claimed that they can legally use such content to train their technologies without paying \nfor it because the material is public and they are not reproducing the material in its entirety.\nIn its blog post, OpenAI said its discussions with The Times about a potential partnership appeared to progress \nconstructively, with a last communication on Dec. 19. During the negotiations, it said, The Times had mentioned \nOpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’\nthat it had seen OpenAI’s technology “regurgitate” some of its content — meaning the technology had generated \nnear-verbatim excerpts from articles that ran in The Times — but declined to provide examples. When The Times \nsued eight days later, OpenAI said it was surprised and disappointed.\nIn a statement, Ian Crosby, an attorney for The Times at the law firm Susman Godfrey, said that OpenAI’s blog post \n“concedes that OpenAI used The Times’s work” and that OpenAI and Microsoft were using The Times’s articles to \nbuild products without permission or payment. “That’s not fair use by any measure,” he said.\nOpenAI said its technology sometimes regurgitates articles, but that was a “rare bug” that it was working to solve. \nThe Times’s lawsuit included examples showing ChatGPT reproducing excerpts from its articles nearly word for \nword.\n“Intentionally manipulating our models to regurgitate is not an appropriate use of our technology and is against our \nterms of use,” OpenAI said.\nPHOTO: OpenAI said in a blog post that the lawsuit did not tell the full story of how OpenAI and its technologies, \nlike the ChatGPT chatbot, operated. (PHOTOGRAPH BY MATT ROURKE/ASSOCIATED PRESS) This article \nappeared in print on page B4.\nLoad-Date: January 9, 2024"
    },
    {
        "file_name": "event_livestream_Jan2024",
        "header": "Samsung Galaxy S24 launch: Where and when to watch 'Unpacked 2024'",
        "media": "event livestream",
        "time": "January 16, 2024",
        "section": "TECH AND GADGETS",
        "length": "455 words",
        "byline": " ",
        "story_text": "Samsung Galaxy S24 launch: Where and when to watch 'Unpacked 2024' \nevent livestream\nThe Economic Times\nJanuary 16, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 455 words\nBody\nSamsung's highly anticipated Galaxy Unpacked event, scheduled for January 17 in San Jose, California, is set to \nusher in the first major smartphone launch of 2024. Fans worldwide are eager to witness the unveiling of the \nSamsung Galaxy S24 series, featuring the Samsung Galaxy S24, Samsung Galaxy S24 Plus, and the flagship \nSamsung Galaxy S24 Ultra. Event Details and How To Watch LivestreamThe event, viewable on Samsung's official \nwebsite and YouTube channel, is a global affair, allowing viewers to catch the live stream at 1 pm ET (11:30 pm \nIST). The occasion promises to showcase not only the hardware evolution of the S24 series but also Samsung's \nforay into artificial intelligence with the introduction of Galaxy AI. Galaxy S24 Ultra HighlightsThe spotlight of the \nevent is expected to be on the Samsung Galaxy S24 Ultra, positioned as the flagship for 2024. Leaks suggest a \n6.8-inch screen with a peak brightness exceeding 2,500 nits and luxurious titanium edges, maintaining the \nsophistication of its predecessor. \nInside, speculations point to a Snapdragon 8 Gen 3 chip, 12GB of RAM, and storage options of up to 1TB of UFS \n4.0. The camera setup is expected to feature a 200MP primary sensor and a 12MP ultra-wide camera, with a \nnoteworthy change in the zoom configuration to a 5x shooter for enhanced photo quality. S24 & S24 Plus \nFeaturesThe Samsung Galaxy S24 and S24 Plus, keeping the dimensions of their predecessors, are set to feature \n6.2-inch and 6.5-inch LTPO panels, respectively. Dynamic refresh rates ranging from 1Hz to 120Hz enrich the \nvisual experience, with the S24 Plus possibly boasting a QHD plus resolution and the S24 maintaining full-HD+ \nresolution. Both variants showcase an updated version of Armor Aluminum and come in Onyx Black, Marble Gray, \nCobalt Violet, and Amber Yellow colour options. The chipset choices include Exynos 2400 and Snapdragon 8 Gen \n3, with the latter exclusive to the US market. Galaxy AI FeaturesSamsung aims to captivate audiences with its \nGalaxy AI features, inspired by the positive response to AI in 2023. Features like a Magic Editor, enabling users to \nedit and enhance photos, and real-time translation of phone calls facilitated by AI are anticipated. Rumours also \nsuggest potential additions like generative AI wallpaper and automatic formatting in Samsung Notes, showcasing \nSamsung's commitment to leading in AI technology. In addition to the Galaxy S24 series, the event may feature the \nlaunch of the Galaxy Fit3, an affordable fitness tracker, and next-generation Galaxy Buds. As the clock ticks down, \nanticipation builds for Samsung's Unpacked event, where the future of Galaxy smartphones and AI integration will \nbe unveiled. For Reprint Rights: timescontent.com\nLoad-Date: January 16, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "HOW AI WILL CHANGE THE WORKPLACE — AUTOMATING IDEAS",
        "media": "Wall Street Journal Abstracts",
        "time": "May 16, 2023",
        "section": "R; Pg. 1",
        "length": "43 words",
        "byline": "MICHAEL CHUI",
        "story_text": "HOW AI WILL CHANGE THE WORKPLACE — AUTOMATING IDEAS\nWall Street Journal Abstracts\nMay 15, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: R; Pg. 1\nLength: 43 words\nByline: MICHAEL CHUI\nBody\nABSTRACT\nMichael Chui article in Journal Report — Innovations in Work contends generative artificial intelligence goes \nbeyond automating drudge tasks to support knowledge work, allowing workers more time to edit and increasing \nproductivity in research; drawing (M)\nGraphic\n \nDiagrams and Drawings\nLoad-Date: May 16, 2023"
    },
    {
        "file_name": "adopters_of_AI's_next_wave;_Making_instant_videos_is_the_next_wave_of_Mar2024",
        "header": "Do AI video-generators dream of San Pedro? Madonna among early",
        "media": "adopters of AI's next wave; Making instant videos is the next wave of",
        "time": "March 5, 2024",
        "section": "NATION WORLD",
        "length": "1183 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Do AI video-generators dream of San Pedro? Madonna among early \nadopters of AI's next wave; Making instant videos is the next wave of \ngenerative artificial intelligence, much like chatbots and image-generators \nbefore it\nDayton Daily News (Ohio)\nMarch 4, 2024 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1183 words\nByline: MATT O'BRIEN\nBody\nWhenever Madonna sings the 1980s hit \"La Isla Bonita\" on her concert tour, moving images of swirling, sunset-\ntinted clouds play on the giant arena screens behind her.\nTo get that ethereal look, the pop legend embraced a still-uncharted branch of generative artificial intelligence – \nthe text-to-video tool. Type some words  say, \"surreal cloud sunset\" or \"waterfall in the jungle at dawn\"  and an \ninstant video is made. \nFollowing in the footsteps of AI chatbots and still image-generators, some AI video enthusiasts say the emerging \ntechnology could one day upend entertainment, enabling you to choose your own movie with customizable story \nlines and endings. But there's a long way to go before they can do that, and plenty of ethical pitfalls on the way. \nFor early adopters like Madonna, who's long pushed art's boundaries, it was more of an experiment. She nixed an \nearlier version of \"La Isla Bonita\" concert visuals that used more conventional computer graphics to evoke a tropical \nmood. \n\"We tried CGI. It looked pretty bland and cheesy and she didn't like it,\" said Sasha Kasiuha, content director for \nMadonna's Celebration Tour that continues through late April. \"And then we decided to try AI.\" \nChatGPT-maker OpenAI gave a glimpse of what sophisticated text-to-video technology might look like when the \ncompany recently showed off Sora, a new tool that's not yet publicly available. Madonna's team tried a different \nproduct from New York-based startup Runway, which helped pioneer the technology by releasing its first public \ntext-to-video model last March. The company released a more advanced \"Gen-2\" version in June. \nRunway CEO Cristóbal Valenzuela said while some see these tools as a \"magical device that you type a word and \nsomehow it conjures exactly what you had in your head,\" the most effective approaches are by creative \nprofessionals looking for an upgrade to the decades-old digital editing software they're already using. \nHe said Runway can't yet make a full-length documentary. But it could help fill in some background video, or b-roll  \nthe supporting shots and scenes that help tell the story. \n\"That saves you perhaps like a week of work,\" Valenzuela said. \"The common thread of a lot of use cases is people \nuse it as a way of augmenting or speeding up something they could have done before.\" \nDo AI video-generators dream of San Pedro ? Madonna among early adopters of AI's next wave Making instant \nvideos is the next wave of generative artificial intel....\nRunway's target customers are \"large streaming companies, production companies, post-production companies, \nvisual effects companies, marketing teams, advertising companies. A lot of folks that make content for a living,\" \nValenzuela said. \nDangers await. Without effective safeguards, AI video-generators could threaten democracies with convincing \n\"deepfake\" videos of things that never happened, or  as is already the case with AI image generators  flood the \ninternet with fake pornographic scenes depicting what appear to be real people with recognizable faces. Under \npressure from regulators, major tech companies have promised to watermark AI-generated outputs to help identify \nwhat's real. \nThere also are copyright disputes brewing about the video and image collections the AI systems are being trained \nupon (neither Runway nor OpenAI discloses its data sources) and to what extent they are unfairly replicating \ntrademarked works. And there are fears that, at some point, video-making machines could replace human jobs and \nartistry. \nFor now, the longest AI-generated video clips are still measured in seconds, and can feature jerky movements and \ntelltale glitches such as distorted hands and fingers. Fixing that is \"just a question of more data and more training,\" \nand the computing power on which that training depends, said Alexander Waibel, a computer science professor at \nCarnegie Mellon University who's been researching AI since the 1970s. \n\"Now I can say, 'Make me a video of a rabbit dressed as Napoleon walking through New York City,'\" Waibel said. \"It \nknows what New York City looks like, what a rabbit looks like, what Napoleon looks like.\" \nWhich is impressive, he said, but still far from crafting a compelling storyline. \nBefore it released its first-generation model last year, Runway's claim to AI fame was as a co-developer of the \nimage-generator Stable Diffusion. Another company, London-based Stability AI, has since taken over Stable \nDiffusion's development. \nThe underlying \"diffusion model\" technology behind most leading AI generators of images and video works by \nmapping noise, or random data, onto images, effectively destroying an original image and then predicting what a \nnew one should look like. It borrows an idea from physics that can be used to describe, for instance, how gas \ndiffuses outward. \n\"What diffusion models do is they reverse that process,\" said Phillip Isola, an associate professor of computer \nscience at the Massachusetts Institute of Technology. \"They kind of take the randomness and they congeal it back \ninto the volume. That's the way of going from randomness to content. And that's how you can make random \nvideos.\" \nGenerating video is more complicated than still images because it needs to take into account temporal dynamics, or \nhow elements within the video change over time and across sequences of frames, said Daniela Rus, another MIT \nprofessor who directs its Computer Science and Artificial Intelligence Laboratory. \nRus said the computing resources required are \"significantly higher than for still image generation\" because \"it \ninvolves processing and generating multiple frames for each second of video.\" \nThat's not stopping some well-heeled tech companies from trying to keep outdoing each other in showing off \nhigher-quality AI video generation at longer durations. Requiring written descriptions to make an image was just the \nstart. Google recently demonstrated a new project called Genie that can be prompted to transform a photograph or \neven a sketch into \"an endless variety\" of explorable video game worlds. \nIn the near term, AI-generated videos will likely show up in marketing and educational content, providing a cheaper \nalternative to producing original footage or obtaining stock videos, said Aditi Singh, a researcher at Cleveland State \nUniversity who has surveyed the text-to-video market. \nDo AI video-generators dream of San Pedro ? Madonna among early adopters of AI's next wave Making instant \nvideos is the next wave of generative artificial intel....\nWhen Madonna first talked to her team about AI, the \"main intention wasn't, 'Oh, look, it's an AI video,'\" said \nKasiuha, the creative director. \n\"She asked me, 'Can you just use one of those AI tools to make the picture more crisp, to make sure it looks current \nand looks high resolution?'\" Kasiuha said. \"She loves when you bring in new technology and new kinds of visual \nelements.\" \nLonger AI-generated movies are already being made. Runway hosts an annual AI film festival to showcase such \nworks. But whether that's what human audiences will choose to watch remains to be seen. \n\"I still believe in humans,\" said Waibel, the CMU professor. \"I still believe that it will end up being a symbiosis where \nyou get some AI proposing something and a human improves or guides it. Or the humans will do it and the AI will fix \nit up.\" \nAssociated Press journalists Joseph B. Frederick and Rodrique Ngowi contributed to this report.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "Schooling;_Teaching_resource_Sep2023",
        "header": "High School Stories: Recent New York Times Reporting on Secondary",
        "media": "Schooling; Teaching resource",
        "time": "September 5, 2023",
        "section": "LEARNING",
        "length": "3001 words",
        "byline": "The Learning Network",
        "story_text": "High School Stories: Recent New York Times Reporting on Secondary \nSchooling; Teaching resource\nThe New York Times \nAugust 16, 2023 Wednesday 14:58 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 3001 words\nByline: The Learning Network\nHighlight: A collection of free links to help those participating in our multimedia challenge, “What High School Is \nLike in 2023.”\nBody\nA collection of free links to help those participating in our multimedia challenge, “What High School Is Like in 2023.”\nEducation stories have dominated headlines over the past year, as a quick glance down this long, long list will \nshow. \nIf you are participating in our new multimedia challenge, which invites students and educators to “show or tell us \nwhat high school is like in 2023,” we thought it might help to  understand how The New York Times and other media \nhave looked at the issues and questions facing secondary education. \nBelow, over 75 news, feature stories and Opinion pieces about school, teaching, learning and teenage life that have \nappeared across sections of NYTimes.com over the last year.  They are free to read, as are all Times pieces linked \nfrom The Learning Network  — as long as you access them from our site. We will continue to update this collection \nuntil the contest ends on Oct. 4.\nWhere should you begin? We recommend the wonderful teen-created piece “What Grown-Ups Don’t Understand \nAbout School,” published in September 2022. \nThen, as you scroll through the rest, you might choose pieces on topics that especially interest you and ask yourself \n…\n• What, if anything, seems to be missing? Is there information or context that could have made this piece \nstronger?\n• How could my background, knowledge or perspective make me an authority on this topic? What would I like to \nsay about it?\n• What other stories about my experiences in school do these pieces remind me that I could tell?\nFor Students\nThe Role of School \nWhat is school for?\nWhat Grown-Ups Don’t Understand About School\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nIn September of 2022, The New York Times Opinion section asked a number of experts the question, What is \nschool really for? Our favorite answer: this one by the students at Oakland’s Fremont High, who answered with their \ncameras. \nBefore you read anything else, we hope you’ll take a look at their work. We have also published a related lesson \nplan\nThen, if you’d like to continue, there are the other pieces in the What Is School For? series:\nSchool Is for Everyone\nSchool Is for Social Mobility\nSchool Is for Making Citizens\nSchool Is for Care\nSchool Is for Wasting Time and Money\nSchool Is for Learning to Read\nSchool Is for Connecting to Nature\nSchool Is for Merit\nSchool Is for Hope\nSchool Is for Parent Activism\nSchool Is for Teaching\nLearning\nHow do you learn best? Does your school support those ways of learning?\nThere Are Better Ways to Study That Will Last You a Lifetime (Opinion)\nTemple Grandin: Society Is Failing Visual Thinkers, and That Hurts Us All (Opinion)\nThe Key to Success in College Is So Simple, It’s Almost Never Mentioned (Opinion)\nHow the Arts Can Benefit Your Mental Health (No Talent Required)\nMy Unlikely Writing Teacher: Pedro Martinez\nYour Identity and School\nHow does who you are affect your learning — and your experience in school in general?\nWhat It’s Like to Be a Queer Teenager in America Today\nAsian American Students Face Bias, but It’s Not What You Might Think (Opinion)\n‘Luddite’ Teens Don’t Want Your Likes\nYoung and Homeless in Rural America\nAt Camp Naru, Nobody Is ‘an Outlier’\nAs a Child in Haiti, I Was Taught to Despise My Language and Myself (Opinion)\nStrife in the Schools: Education Dept. Logs Record Number of Discrimination Complaints\nWhen Students Change Gender Identity, and Parents Don’t Know\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nStuyvesant High School Admitted 762 New Students. Only 7 Are Black.\nHow Educators Secretly Remove Students With Disabilities From School\nWoman, 29, Enrolled in High School and Pretended to Be a Teenager\nThe Instagram Account That Shattered a California High School\nSpecial Schools or Programs\nWhat makes your school unique?\nInside ‘the Hogwarts of Fashion’\nBrooklyn’s Lifeguard Factory Is Open Again\nA Video-Gaming School Stumbles on a Way to Get Dropouts Back in Class\nCommunity Schools Offer More Than Just Teaching\nInside a New Arts Program for Queens Teens\nSorry, You’ve Been Rejected. Now Let’s Party.\nStruggling Schools in New Mexico See Results After Partnerships\nA Religious School That’s Also a Public School\nCurriculum\nWhat do — and don’t — you learn in school? What do you wish you could learn?\nIn California, a Math Problem: Does Data Science = Algebra II?\nWhy We Don’t Agree on High School Required Reading (Podcast)\nInside the College Board’s Revised African American Studies Curriculum\nWho’s Afraid of Black History? (Opinion)\nIn Memphis, the Phonics Movement Comes to High School\nFlorida Scoured Math Textbooks for ‘Prohibited Topics.’ Next Up: Social Studies.\nFlorida Schools Question Content on Gender and Sexuality in A.P. Psychology\nWhen Teens Find Misinformation, These Teachers Are Ready\nWhat Do Middle Schools Teach About Climate Change? Not Much.\nWhat’s Actually Being Taught in History Class\nFlorida at Center of Debate as School Book Bans Surge Nationally\nAfter Roe, Sex Ed Is Even More Vital (Opinion)\nWhat Teaching History in Texas Looks Like (Opinion)\nPolitics and Law\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat issues, small or large, has your school community recently confronted?\nWhat the Science Says About ‘Don’t Say Gay’ and Young People (Opinion)\nStudent Cannot Wear Sash of Mexican and U.S. Flags at Graduation, Judge Rules\nHigh School Student Suspended After Recording Teacher Using a Racial Slur\nInside a Brooklyn School Teaching the Course That Florida Banned\nStudents Walk Out of School in Support of Ralph Yarl\nIt’s Getting Hard to Stage a School Play Without Political Drama\nA Student Sues After Suspension for Mocking Principal on Instagram\nMichigan Students Sue School District Over ‘Let’s Go Brandon’ Ban\nDeSantis Faces Swell of Criticism Over Florida’s New Standards for Black History\nFlorida Schools Try to Adapt to New Rules on Gender, Bathrooms and Pronouns\nDivided House Passes G.O.P. Bill on Hot-Button Schools Issues\nAttempts to Ban Books Are Accelerating and Becoming More Divisive\n$7,200 for Every Student: Arizona’s Ultimate Experiment in School Choice\nVirginia Reverses School Protections for Transgender Students\n‘Channeling the Mama Bear’: How Covid Closures Became Today’s Curriculum Wars\nArkansas Warns School Districts Not to Offer A.P. African American Studies\nThe Instagram Account That Shattered a California High School\nCatholic School System Directs Students to Use Pronouns Assigned at Birth\nHealth\nWhat roles do your physical and mental health play in your learning? \nThe Income Gap Is Becoming a Physical-Activity Divide\nTeenagers Keep Vaping Despite Crackdowns on E-Cigarettes\nMore and More Teenagers Are Coming to School High, N.Y.C. Teachers Say\nUse of Marijuana and Psychedelics Is Soaring Among Young Adults, Study Finds\nHow to Help a Teen Who Can’t Sleep\nPuberty Blockers Can Help Transgender Youth. Is There a Cost?\nTeen Girls Report Record Levels of Sadness, C.D.C. Finds\nThe Daily: Inside the Adolescent Mental Health Crisis (Podcast)\nA Teen’s Journey Into the Internet’s Darkness and Back Again\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nMeeting the Mental Health Challenge in School and at Home\n‘Disruptive,’ or Depressed? Psychiatrists Reach Out to Teens of Color\nE.R. Visits for Teenage Girls Surged During the Pandemic\n‘Mindful Breathing’ Will Now Be Required in New York City Schools\nAfter Teen’s Suicide, a New Jersey Community Grapples With Bullying\nTeenagers Are Telling Us That Something Is Wrong With America (Opinion)\nThe Collateral Damage of A.D.H.D. Drug Shortages\nPandemic Effects\nHow have the pandemic years affected your relationship to school?\nThe Pandemic Generation Goes to College. It Has Not Been Easy.\nBack to School and Back to Normal. Or at Least Close Enough.\nParents Don’t Understand How Far Behind Their Kids Are in School (Opinion)\nCould Tutoring Be the Best Tool for Fighting Learning Loss?\nPandemic Learning Loss Is Not an Emergency (Opinion)\nFamilies Struggle as Pandemic Program Offering Free School Meals Ends\nThe Key to Getting Students Back in Classrooms? Establishing Connections.\nCovid Closed the Nation’s Schools. Cleaner Air Can Keep Them Open.\nTest Scores\nWhat do you think the results of standardized tests tell us about learning? What is your relationship with these kinds \nof tests?\nU.S. Students’ Progress Stagnated Last School Year, Study Finds\nWhat the New, Low Test Scores for 13-Year-Olds Say About U.S. Education Now\nThe Daily: The Nation’s ‘Report Card’ on Remote Learning (Podcast)\nGenerative Artificial Intelligence\nHow have you and your teachers and school responded to the rise of generative artificial intelligence like \nChatGPT? What does it mean for teaching and learning?\nHow Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall\nHow teachers and students feel about A.I.\nDespite Cheating Fears, Schools Repeal ChatGPT Bans\nThe Daily: Suspicion, Cheating and Bans: A.I. Hits America’s Schools (Podcast)\nIn Classrooms, Teachers Put A.I. Tutoring Bots to the Test\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nAt This School, Computer Science Class Now Includes Critiquing Chatbots\nHow Will Chatbots Change Education? (Opinion)\nDon’t Ban ChatGPT in Schools. Teach With It.\nBan or Embrace? Colleges Wrestle With A.I.-Generated Admissions Essays.\nWe Used A.I. to Write Essays for Harvard, Yale and Princeton. Here’s How It Went.\nExtracurricular Activities\nWhat role have extracurricular activities played in your education?\nIt’s Getting Hard to Stage a School Play Without Political Drama\nA Championship Season in Mariachi Country\nWhere the Band Kids Are\nThousands of Teens Are Being Pushed Into Military’s Junior R.O.T.C.\nOne Solution to the Digital Divide: Teens\nSome Kids Play Sports. These Kids Train Wild Horses.\nThe Best Extracurricular May Be an After-School Job (Opinion)\nStudent Journalists Reveal a Changing World. Let Them. (Opinion)\nSports\nWhat has been your experience with school sports?\nHelmet Shortage in High School Football Raises Costs, and Risks\nA Summer Basketball Refuge Thrives in the Bronx’s Largest Housing Complex\nFencing Can Be Six-Figure Expensive, but It Wins in College Admissions\nAt This Wrestling Academy, Indian Girls Are ‘Set Free’\nEnd of All-Girls Swim Class Causes Controversy at Stuyvesant High School\nWhy Have We Allowed Money to Ruin Youth Sports? (Opinion)\nTitle IX and the New Rule on Transgender Athletes Explained\nSex Discrimination Case in Hawaii Could Change High School Sports Across the U.S.\nThe Real Enforcers of Gender Equity in Sports: Angry Parents\nThe College Process and Affirmative Action\nWhat does the college process look like at your school? For you? How might the repeal of affirmative action affect \nthat process?\nWith Supreme Court Decision, College Admissions Could Become More Subjective\nRuling Raises Uncertainty for High School Students Heading to College\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nAfter the Affirmative Action Ruling, Asian Americans Ask What Happens Next\nThe ‘Unseen’ Students in the Affirmative Action Debate\nThe Daily: How Affirmative Action Changed Their Lives (Podcast)\nI’m in High School. I Hope Affirmative Action Is Rejected and Replaced With Something Stronger. (Opinion)\nColleges Want to Know More About You and Your ‘Identity’\nWith End of Affirmative Action, a Push for a New Tool: Adversity Scores\nThe Legacy Dilemma: What to Do About Privileges for the Privileged?\nThe Real, Hidden Truth About College Admissions (Opinion)\nDespite Years of Criticism, the U.S. News College Rankings Live On\nThere’s Only One College Rankings List That Matters\nHarvard or Happiness? 11 High School Seniors Debate College Rankings\nThese 12 College Students Don’t Like the System They’re In\nCan the Meritocracy Survive Without the SAT? (Opinion)\nI Edited Mental Illness Out of My College Applications. I’m Not Alone. (Opinion)\nSchool Shootings and Violence\nHow has violence, or the threat of it, shaped your educational experience?\nA Place of Sanctuary Is Punctured by the Reality of Gun Violence in America\nThe Daily: The Parkland Students, Four Years Later (Podcast)\nPanic Buttons, Classroom Locks: How Schools Have Boosted Security\nMichigan School District Bans Backpacks Over Safety Concerns\n‘Our Schools Have Become Battlefields’: Teachers Consider Arming Themselves in the Classroom (Opinion)\nGun Violence Has Changed Us\nSchools Bring Police Back to Campuses, Reversing Racial Justice Decisions\nBehind a Surge in Teenage Killings: Grief, Anger and Online Grudges\nEducation Around the World\nHow does education around the world compare to the United States? What does it reveal about your own schooling \nexperience, whether in the U.S. or abroad?\nClean Toilets, Inspired Teachers: How India’s Capital Is Fixing Its Schools\nAnother Casualty in Ukraine: Teenage Years\n‘My School Had No Chairs, No Blackboards, No Books’\nSouth Korea to Drop ‘Killer Questions’ From College Entrance Exam\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nIn Russian Schools, It’s Recite Your ABC’s and ‘Love Your Army’\n‘Brainwashing a Generation’: British Schools Combat Andrew Tate’s Views\nPhilippines Returns to School, Ending One of World’s Longest Shutdowns\nHow Finland Is Teaching a Generation to Spot Misinformation\nDecades on From Peace, Northern Ireland Schools Are Still Deeply Divided\nA Yiddish Haven Thrives in Australia\nNew Russian High School Textbooks Seek to Justify War in Ukraine\nUkrainian students begin a new school year in the shadow of war.\nNew data shows ‘widespread learning loss’ among Ukraine’s children.\nSchool Buildings\nWhat is your learning environment like? How has it affected your education?\nSchool District Woes Likened to ‘Environmental Racism’ in Flint, Mich.\nAn Ice Factory From the 1900s Is Now a Spectacular New Bronx School\nHigh Temperatures Close Schools in Several U.S. Cities\n‘We’ll Teach Out of Anywhere’: In Flooded Kentucky, Schools Race to Rebuild\nSchool Is in Session, Power or Not\nWhy Haven’t We Made It Safer to Breathe in Classrooms? (Opinion)\nThankful for Libraries (Opinion)\nFor Educators\nWhat has your experience as an educator been like in recent years? What does the world not understand about \nwhat it is like to be a teacher right now? \n(Note: Please keep in mind that for this challenge we consider any adult working in a secondary school an \neducator, and we would love to hear from you, whether you are a counselor, administrator, coach, librarian, \nmaintenance worker, school secretary, chef or teacher.)\nThese 12 Teachers Don’t See Themselves as Superheroes\nA Freewheeling 91-Year-Old Principal Retires\nLibrarians Are Meeting Younger Readers Where They Are: TikTok\nTexas Revamps Houston Schools, Closing Libraries and Angering Parents\nFlorida Schools Try to Adapt to New Rules on Gender, Bathrooms and Pronouns\nPlease Don’t Call My Job a Calling (Opinion)\nWhat’s Actually Being Taught in History Class\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nEmpty Classrooms, Abandoned Kids: Inside America’s Great Teacher Resignation (Video)\nTeachers, Facing Increasing Levels of Stress, Are Burned Out\nThere’s a Reason There Aren’t Enough Teachers in America. Many Reasons, Actually. (Opinion)\nHow Bad Is the Teacher Shortage? Depends Where You Live.\nOne Way to Ease the Teacher Shortage: Pay More, Some Districts Say\nLos Angeles School Workers Are on Strike, and Parents Say They Get It\nDaring to Speak Up About Race in a Divided School District\nWhat It Is Like to Teach in the Cross Hairs of Ron DeSantis (Opinion)\n‘Kids Can’t Read’: The Revolt That Is Taking On the Education Establishment\nThe Sunday Read: ‘The Most Dangerous Person in the World Is Randi Weingarten’ (Podcast)\nMany States Omit Climate Education. These Teachers Are Trying to Slip It In.\nWhat Mrs. Bailey Taught Me in A.P. History Changed My Life (Opinion)\nTrading Books for a Rifle: The Teacher Who Volunteered in Ukraine\nI Love My Students, but I Won’t Use a Gun to Protect Them (Opinion)\nThe Shortage in School Bus Drivers Is Getting Worse\nFrom The Learning Network\nTeen Voices From Our Current Events Conversation\nWhat Students Are Saying About the Growing Fight Over What Young People Can Read\nWhat Students Are Saying About ChatGPT\nWhat Students Are Saying About Coed Sports\nWhat Students Are Saying About the C.D.C. Report on Teen Sadness\nWhat Students Are Saying About What Motivates Them to Learn\nWhat Students Are Saying About the Value of Math\nWhat Students Are Saying About How Their Teachers Have Shaped Them\n‘They Deserve Better’: What Students Are Saying About Respect and Pay for School Workers\nWhat Students Are Saying About Having a Part-Time Job While in School\nWriting Prompts\nWhat Is It Like to Be a Teenager Now?\nWhat Motivates You to Learn?\nDo You See the Point in Learning Math?\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat Is Your Reaction to the Growing Fight Over What Young People Can Read?\nWhat Is the Purpose of Teaching U.S. History?\nWhat Do You Think About the Controversy Surrounding the New A.P. Course on African American Studies?\nShould Students Learn About Climate Change in School?\nShould Teachers Provide Trigger Warnings for ‘Traumatic Content’?\nWhat Should Free Speech Look Like on Campus?\nHow Can Schools Engage Students Who Are at Risk of Dropping Out?\nHow Have Your Teachers Shaped Who You Are?\nHow Should Schools Respond to ChatGPT?\nWhat Don’t Adults Understand About Teenage Life Online?\nHow Are You Using A.I.?\nShould We Get Rid of Homework?\nShould All High School Students Have Part-Time Jobs?\nDo School Employees Deserve More Respect — and Pay?\nHow Much Do You Think It Matters Where You Go to College?\nDo You Support Race-Conscious College Admissions Policies?\nHow Much of Your Real Self Have You Revealed on Applications?\nHow Should Adults Talk to Kids About Drugs?\nWhat Are Your Thoughts on Uniforms and Strict Dress Codes?\nShould More Sports Be Coed?\nWhat Are You Doing to Take Care of Your Health?\nDo You Have Enough Access to Places Where You Can Play and Exercise?\nWhat Is Your Reaction to the New Report About Teen Sadness?\nHow Do You Hold It Together When You’re Feeling Stressed?\nDo Schools Need to Do More to Support Visual Thinkers?\nHow Did You Grow and Change This School Year?\nDo You Suffer From ‘Task Paralysis’?\nHave You Ever Felt as if You Didn’t Belong?\nHow Do You Get Over Rejection?\nHow Has the Threat of Gun Violence Affected You?\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat Can We Learn From Older Adults?\nWhat Is the Best Thing About Being Your Age?\nWhat Role Do Libraries Play in Your Life?\nPHOTO: Erica Robson, center, a drama teacher, directs students during a rehearsal for “Sweeney Todd: The \nDemon Barber of Fleet Street” at Los Angeles County High School for the Arts in Los Angeles. Related Article \n(PHOTOGRAPH BY Jenna Schoenefeld for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: September 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Google Plans Its Chatbot In Response To ChatGPT",
        "media": "The New York Times",
        "time": "February 7, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "628 words",
        "byline": "By Cade Metz and Nico Grant",
        "story_text": "Google Plans Its Chatbot In Response To ChatGPT\nThe New York Times\nFebruary 7, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 628 words\nByline: By Cade Metz and Nico Grant\nBody\nThe internet giant said it would begin testing its new chatbot, Bard, with a small, private group before releasing it to \nthe public in the coming weeks.\nGoogle said on Monday that it would soon release an experimental chatbot called Bard as it races to respond to \nChatGPT, which has wowed millions of people since it was unveiled at the end of November. \n  Google said it would begin testing its new chatbot with a small, private group on Monday before releasing it to the \npublic in the coming weeks. In a blog post, Sundar Pichai, Google's chief executive, also said that the company's \nsearch engine would soon have artificial intelligence features that offered summaries of complex information.\n  Bard -- so named because it is a storyteller, the company said -- is based on experimental technology called \nLaMDA, short for Language Model for Dialogue Applications, which Google has been testing inside the company \nand with a limited number of outsiders for several months.\n  Google is among many companies that have been developing and testing a new type of chatbot that can riff on \nalmost any topic thrown its way. OpenAI, a tiny San Francisco start-up, captured the public's imagination with \nChatGPT and set off a race to push this kind of technology into a wide range of products.\n  The chatbots cannot chat exactly like a human, but they often seem to. And they generate a wide range of digital \ntext that can be repurposed in nearly any context, including tweets, blog posts, term papers, poetry and even \ncomputer code.\n  The result of more than a decade of research at companies like Google, OpenAI and Meta, the chatbots represent \nan enormous change in the way computer software is built, used and operated. They are poised to remake internet \nsearch engines like Google Search and Microsoft Bing, talking digital assistants like Alexa and Siri, and email \nprograms like Gmail and Outlook.\n  But the technology has flaws. Because the chatbots learn their skills by analyzing vast amounts of text posted to \nthe internet, they cannot distinguish between fact and fiction and can generate text that is biased against women \nand people of color.\n  Google had been reluctant to release this type of technology to the public because executives were concerned \nthat the company's reputation could take a hit if the A.I. created biased or toxic statements.\n  Google's caution began to erode its advantage as a generative A.I. innovator when ChatGPT debuted to buzz \nand millions of users. In December, Mr. Pichai declared a ''code red,'' pulling various groups off their normal \nassignments to help the company expedite the release of its own A.I. products.\nGoogle Plans Its Chatbot In Response To ChatGPT\n  The company has scrambled to catch up, calling in its co-founders, Larry Page and Sergey Brin, to review its \nproduct road map in several meetings and establishing an initiative to quicken its approval processes.\n  Google has plans to release more than 20 A.I. products and features this year, The New York Times has reported. \nThe A.I. search engine features, which the company said would arrive soon, will try to distill complex information \nand multiple perspectives to give users a more conversational experience.\n  The company also plans to spread its underlying A.I. technology through partners, so that they can build varied \nnew applications.\n  Chatbots like ChatGPT and LaMDA are more expensive to operate than typical software. In a recent tweet, Sam \nAltman, OpenAI's chief executive, said the company spent ''single-digit cents'' delivering each chat on the service. \nThat translates to extremely large costs for the company, considering that millions of people are using the service.\n  Google said Bard would be a ''lighter weight'' version of LaMDA that would allow the company to serve up the \ntechnology at a lower cost.\nhttps://www.nytimes.com/2023/02/06/technology/google-bard-ai-chatbot.html\nGraphic\n \nThis article appeared in print on page B4.               \nLoad-Date: February 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Quotation of the Day: A.I. Outshines in Health Care. At Paperwork.",
        "media": "The New York Times",
        "time": "June 27, 2023",
        "section": "PAGEONEPLUS",
        "length": "56 words",
        "byline": " ",
        "story_text": "Quotation of the Day: A.I. Outshines in Health Care. At Paperwork.\nThe New York Times \nJune 27, 2023 Tuesday 01:19 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PAGEONEPLUS\nLength: 56 words\nHighlight: Quotation of the Day for Tuesday, June 27, 2023.\nBody\n“In medicine, we can’t tolerate hallucinations.”\nDR. GREGORY ATOR, the chief medical informatics officer at the University of Kansas Medical Center, which is \nnot using generative A.I. in diagnosis because the software can create fabrications. Some doctors want to use A.I. \nto help with paperwork.\nThis article appeared in print on page A2.\nLoad-Date: June 27, 2023"
    },
    {
        "file_name": "Agency_Mar2024",
        "header": "Homeland Security Is Embracing A.I. With Plans to Use Tool Across the",
        "media": "Agency",
        "time": "March 18, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "634 words",
        "byline": "By Cecilia Kang",
        "story_text": "Homeland Security Is Embracing A.I. With Plans to Use Tool Across the \nAgency\nThe New York Times\nMarch 18, 2024 Monday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 634 words\nByline: By Cecilia Kang\nBody\nThe Department of Homeland Security has seen the opportunities and risks of artificial intelligence firsthand. It \nfound a trafficking victim years later using an A.I. tool that conjured an image of the child a decade older. But it has \nalso been tricked into investigations by deep fake images created by A.I.\nNow, the department is becoming the first federal agency to embrace the technology with a plan to incorporate \ngenerative A.I. models across a wide range of divisions. In partnerships with OpenAI, Anthropic and Meta, it will \nlaunch pilot programs using chatbots and other tools to help combat drug and human trafficking crimes, train \nimmigration officials and prepare emergency management across the nation. \n  The rush to roll out the still unproven technology is part of a larger scramble to keep up with the changes brought \nabout by generative A.I., which can create hyper realistic images and videos and imitate human speech.\n  ''One cannot ignore it,'' Alejandro Mayorkas, secretary of the Department of Homeland Security, said in an \ninterview. ''And if one isn't forward-leaning in recognizing and being prepared to address its potential for good and \nits potential for harm, it will be too late and that's why we're moving quickly.''\n  The plan to incorporate generative A.I. throughout the agency is the latest demonstration of how new technology \nlike OpenAI's ChatGPT is forcing even the most staid industries to re-evaluate the way they conduct their work. \nStill, government agencies like the D.H.S. are likely to face some of the toughest scrutiny over the way they use the \ntechnology, which has set off rancorous debate because it has proved at times to be unreliable and discriminatory.\n  Those within the federal government have rushed to form plans following President Biden's executive order issued \nlate last year that mandates the creation of safety standards for A.I. and its adoption across the federal government.\n  The D.H.S., which employs 260,000 people, was created after the Sept. 11 terror attacks and is charged with \nprotecting Americans within the country's borders, including policing of human and drug trafficking, the protection of \ncritical infrastructure, disaster response and border patrol.\n  As part of its plan,  the agency plans to hire 50 A.I. experts to work on solutions to keep the nation's critical \ninfrastructure safe from A.I.-generated attacks and to combat the use of the technology to generate child sexual \nabuse material and create biological weapons.\n  In the pilot programs, on which it will spend $5 million, the agency will use A.I. models like ChatGPT to help \ninvestigations of child abuse materials, human and drug trafficking. It will also work with companies to comb through \nits troves of text-based data to find patterns to help investigators. For example, a detective who is looking for a \nHomeland Security Is Embracing A.I. With Plans to Use Tool Across the Agency\nsuspect driving a blue pickup truck will be able to search for the first time across homeland security investigations \nfor the same type of vehicle.\n  D.H.S. will use chatbots to train immigration officials who have worked with other employees and contractors \nposing as refugees and asylum seekers. The A.I. tools will enable officials to get more training with mock \ninterviews. The chatbots will also comb information about communities across the country to help them create \ndisaster relief plans.\n  The agency will report results of its pilot programs by the end of the year, said Eric Hysen, the department's chief \ninformation officer and head of A.I.\n  The agency picked OpenAI, Anthropic and Meta to experiment with a variety of tools and will use cloud providers \nMicrosoft, Google and Amazon in its pilot programs. ''We cannot do this alone,'' he said. ''We need to work with the \nprivate sector on helping define what is responsible use of a generative A.I..''\nhttps://www.nytimes.com/2024/03/18/business/homeland-security-artificial-intelligence.html\nGraphic\n \nThis article appeared in print on page B2.               \nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "How Robots Learned to Write So Well; Nonfiction",
        "media": "The New York Times",
        "time": "February 16, 2024",
        "section": "BOOKS; review",
        "length": "1206 words",
        "byline": "Jennifer Szalai Jennifer Szalai is the nonfiction book critic for The Times.",
        "story_text": "How Robots Learned to Write So Well; Nonfiction\nThe New York Times \nFebruary 7, 2024 Wednesday 10:46 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BOOKS; review\nLength: 1206 words\nByline: Jennifer Szalai Jennifer Szalai is the nonfiction book critic for The Times.\nHighlight: “Literary Theory for Robots,” by Dennis Yi Tenen, a software engineer turned literature professor, shows \nhow the “intelligence” in artificial intelligence is irreducibly human.\nBody\n“Literary Theory for Robots,” by Dennis Yi Tenen, a software engineer turned literature professor, shows how the \n“intelligence” in artificial intelligence is irreducibly human.\nLITERARY THEORY FOR ROBOTS: How Computers Learned to Write, by Dennis Yi Tenen\nIn “Literary Theory for Robots,” Dennis Yi Tenen’s playful new book on artificial intelligence and how computers \nlearned to write, one of his most potent examples arrives in the form of a tiny mistake.\nTenen draws links between modern-day chatbots, pulp-fiction plot generators, old-fashioned dictionaries and \nmedieval prophecy wheels. Both the utopians (the robots will save us!) and the doomsayers (the robots will destroy \nus!) have it wrong, he argues. There will always be an irreducibly human aspect to language and learning — a \ncrucial core of meaning that emerges not just from syntax but from experience. Without it, you just get the chatter of \nparrots, who, “according to Descartes in his ‘Mediations,’ merely repeated without understanding,” Tenen writes.\nBut Descartes didn’t write “Mediations”; Tenen must have meant “Meditations” — the missing “t” will slip past any \nspell-checker program because both words are perfectly legitimate. (The book’s index lists the title correctly.) This \nminuscule typo doesn’t have any bearing on Tenen’s argument; if anything, it bolsters the case he wants to make. \nMachines are becoming stronger and smarter, but we still decide what is meaningful. A human wrote this book. \nAnd, despite the robots in the title, it is meant for other humans to read.\nTenen, now a professor of English and comparative literature at Columbia, used to be a software engineer at \nMicrosoft. He puts his disparate skill sets to use in a book that is surprising, funny and resolutely unintimidating, \neven as he smuggles in big questions about art, intelligence, technology and the future of labor. I suspect that the \nbook’s small size — it’s under 160 pages — is part of the point. People are not indefatigable machines, relentlessly \ningesting enormous volumes on enormous subjects. Tenen has figured out how to present a web of complex ideas \nat human scale.\nTo that end, he tells stories, starting with the 14th-century Arab scholar Ibn Khaldun, who chronicled the use of the \nprophecy wheel, and ending with a chapter on the 20th-century Russian mathematician Andrey Markov, whose \nprobability analysis of letter sequences in Pushkin’s “Eugene Onegin” constituted a fundamental building block of \ngenerative A.I. (Regular players of the game Wordle intuit such probabilities all the time.) Tenen writes \nknowledgeably about the technological roadblocks that stymied earlier models of computer learning, before “the \nbrute force required to process most everything published in the English language” was so readily available. He \nurges us to be alert. He also urges us not to panic.\nHow Robots Learned to Write So Well Nonfiction\n“Intelligence evolves on a spectrum, ranging from ‘partial assistance’ to ‘full automation’,” Tenen writes, offering the \nexample of an automatic transmission in a car. Driving an automatic in the 1960s must have been mind-blowing for \npeople used to manual transmissions. An automatic worked by automating key decisions, downshifting on hills and \nsending less power to the wheels in bad weather. It removed the option to stall or grind your gears. It was \n“artificially intelligent,” even if nobody used those words for it. American drivers now take its magic for granted. It \nhas been demystified.\nAs for the current debates over A.I., this book tries to demystify those, too. Instead of talking about A.I. as if it has a \nmind of its own, Tenen talks about the collaborative work that went into building it. “We employ a cognitive-linguistic \nshortcut by condensing and ascribing agency to the technology itself,” he writes. “It’s easier to say, ‘The phone \ncompletes my messages’ instead of ‘The engineering team behind the autocompletion tool writing software based \non the following dozen research papers completes my messages.’”\nOur common metaphors for A.I. are therefore misleading. Tenen says we ought to be “suspicious of all metaphors \nascribing familiar human cognitive aspects to artificial intelligence. The machine thinks, talks, explains, \nunderstands, writes, feels, etc., by analogy only.” This is why so much of his book revolves around questions of \nlanguage. Language allows us to communicate and to understand one another. But it also allows for deception and \nmisunderstanding. Tenen wants us to “unwind the metaphor” of A.I. — a proposal that might look like an English \nprofessor’s hobbyhorse on first glance but turns out to be entirely apt. A metaphor that is too general can make us \ncomplacent. Our sense of possibility is shaped by the metaphors we choose.\nText generators, whether in the form of 21st-century chatbots or 14th-century “letter magic,” have always faced the \nproblem of “external validation,” Tenen writes. “Procedurally generated text can make grammatical sense, but might \nnot always make sense sense.” Take Noam Chomsky’s famous example: “Colorless green ideas sleep furiously.” \nAnyone who has lived in the physical world would know that this syntactically flawless sentence is nonsense. Tenen \nkeeps referring to the importance of “lived experience” because that describes our condition.\nTenen doesn’t deny that A.I. threatens much of what we call “knowledge work.” Nor does he deny that automating \nsomething also devalues it. But he also puts this another way: “Automation reduces barriers of entry, increasing the \nsupply of goods for all.” Learning is cheaper now, and so having a big vocabulary or repertoire of memorized facts \nis no longer the competitive advantage it once was. “Today’s scribes and scholars can challenge themselves with \nmore creative tasks,” he suggests. “Tasks that are tedious have been outsourced to the machines.”\nI take his point, even if this prospect still seems bad to me, with an ever-shrinking sliver of the populace getting to \ndo challenging, creative work while a once-flourishing ecosystem collapses. But Tenen also argues that we, as \nsocial beings, have agency, if only we allow ourselves to accept the responsibility that comes with it. “Individual \nA.I.s do pose real danger, given the ability to aggregate power in the pursuit of a goal,” he concedes. But the real \ndanger comes “from our inability to hold technology makers responsible for their actions.” What if someone wanted \nto strap a jet engine to a car and see how it fared on the streets of a crowded city? Tenen says the answer is \nobvious: “Don’t do that.”\nWhy “Don’t do that” can seem easy in one realm but not another requires more thinking, more precision, more \nscrutiny — all qualities that fall by the wayside when we cower before A.I., treating the technology like a singular \ngod instead of a multiplicity of machines built by a multiplicity of humans. Tenen leads by example, bringing his \nhuman intelligence to bear on artificial intelligence. By thinking through our collective habits of thought, he offers a \nmeditation all his own.\nLITERARY THEORY FOR ROBOTS: How Computers Learned to Write | By Dennis Yi Tenen | Norton | 158 pp. | \n$22\nJennifer Szalai is the nonfiction book critic for The New York Times. \nPHOTOS This article appeared in print on page C2.\nHow Robots Learned to Write So Well Nonfiction\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "Social_Media_Jan2024",
        "header": "Explicit Deepfake Images of Taylor Swift Elude Safeguards and Swamp",
        "media": "Social Media",
        "time": "January 28, 2024",
        "section": "ARTS",
        "length": "879 words",
        "byline": "Kate Conger and John Yoon",
        "story_text": "Explicit Deepfake Images of Taylor Swift Elude Safeguards and Swamp \nSocial Media\nThe New York Times - International Edition\nJanuary 29, 2024 Monday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: ARTS\nLength: 879 words\nByline: Kate Conger and John Yoon\nBody\nFans of the star and lawmakers condemned the images, probably generated by artificial intelligence, after they \nwere shared with millions of social media users.       \nFake, sexually explicit images of Taylor Swift likely generated by artificial intelligence spread rapidly across social \nmedia platforms this week, disturbing fans who saw them and reigniting calls from lawmakers to protect women and \ncrack down on the platforms and technology that spread such images.       \nOne image shared by a user on X was viewed 47 million times before the account was suspended on Thursday. X \nsuspended several accounts that posted the faked images of Ms. Swift, but the images were shared on other social \nmedia platforms and continued to spread despite those companies' efforts to remove them.       \nWhile X said it was working to remove the images, fans of the pop superstar flooded the platform in protest. They \nposted related keywords, along with the sentence \"Protect Taylor Swift,\" in an effort to drown out the explicit images \nand make them more difficult to find.       \nReality Defender, a cybersecurity company focused on detecting A.I., determined with 90 percent confidence that \nthe images were created using a diffusion model, an A.I.-driven technology accessible through more than 100,000 \napps and publicly available models, said Ben Colman, the company's co-founder and chief executive.       \nAs the A.I. industry has boomed, companies have raced to release tools that enable users to create images, videos, \ntext and audio recordings with simple prompts. The A.I. tools are wildly popular but have made it easier and \ncheaper than ever to create so-called deepfakes, which portray people doing or saying things they have never \ndone.       \nResearchers now fear that deepfakes are becoming a powerful disinformation force, enabling everyday internet \nusers to create nonconsensual nude images or embarrassing portrayals of political candidates. Artificial intelligence \nwas used to create fake robocalls of President Biden during the New Hampshire primary, and Ms. Swift was \nfeatured this month in deepfake ads hawking cookware.       \n\"It's always been a dark undercurrent of the internet, nonconsensual pornography of various sorts,\" said Oren \nEtzioni, a computer science professor at the University of Washington who works on deepfake detection. \"Now it's a \nnew strain of it that's particularly noxious.\"       \n\"We are going to see a tsunami of these A.I.-generated explicit images. The people who generated this see this as \na success,\" Mr. Etzioni said.       \nExplicit Deepfake Images of Taylor Swift Elude Safeguards and Swamp Social Media\nX said it had a zero-tolerance policy toward the content. \"Our teams are actively removing all identified images and \ntaking appropriate actions against the accounts responsible for posting them,\" a representative said in a statement. \n\"We're closely monitoring the situation to ensure that any further violations are immediately addressed, and the \ncontent is removed.\"       \nX has seen an increase in problematic content including harassment, disinformation and hate speech since Elon \nMusk bought the service in 2022. He has loosened the website's content rules and fired, laid off or accepted the \nresignations of staff members who worked to remove such content. The platform also reinstated accounts that had \nbeen previously banned for violating rules.       \nAlthough many of the companies that produce generative A.I. tools ban their users from creating explicit imagery, \npeople find ways to break the rules. \"It's an arms race, and it seems that whenever somebody comes up with a \nguardrail, someone else figures out how to jailbreak,\" Mr. Etzioni said.       \nThe images originated in a channel on the messaging app Telegram that is dedicated to producing such images, \naccording to 404 Media, a technology news site. But the deepfakes garnered broad attention after being posted on \nX and other social media services, where they spread rapidly.       \nSome states have restricted pornographic and political deepfakes. But the restrictions have not had a strong \nimpact, and there are no federal regulations of such deepfakes, Mr. Colman said. Platforms have tried to address \ndeepfakes by asking users to report them, but that method has not worked, he added. By the time they are flagged, \nmillions of users have already seen them.       \n\"The toothpaste is already out of the tube,\" he said.       \nMs. Swift's publicist, Tree Paine, did not immediately respond to requests for comment late Thursday.       \nThe deepfakes of Ms. Swift prompted renewed calls for action from lawmakers. Representative Joe Morelle, a \nDemocrat from New York who introduced a bill last year that would make sharing such images a federal crime, said \non X that the spread of the images was \"appalling,\" adding: \"It's happening to women everywhere, every day.\"       \n\"I've repeatedly warned that AI could be used to generate non-consensual intimate imagery,\" Senator Mark Warner, \na Democrat from Virginia and chairman of the Senate Intelligence Committee, said of the images on X. \"This is a \ndeplorable situation.\"       \nRepresentative Yvette D. Clarke, a Democrat from New York, said that advancements in artificial intelligence had \nmade creating deepfakes easier and cheaper.       \n\"What's happened to Taylor Swift is nothing new,\" she said. \nLoad-Date: January 28, 2024"
    },
    {
        "file_name": "desktop;_here's_how_to_do_it_Aug2023",
        "header": "Google Chrome users can now access Microsoft's AI-powered Bing Chat on",
        "media": "desktop; here's how to do it",
        "time": "August 30, 2023",
        "section": "TECH AND GADGETS",
        "length": "312 words",
        "byline": " ",
        "story_text": "Google Chrome users can now access Microsoft's AI-powered Bing Chat on \ndesktop; here's how to do it\nThe Economic Times\nAugust 31, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 312 words\nBody\nIn a move to expand its user base, American tech giant Microsoft has made its Bing Chat completely accessible for \nusers on Google Chrome desktop browsers. This development follows the recent release of Bing Chat on Chrome \nand Safari mobile platforms. Previously restricted to Microsoft's Edge browser, Bing Chat can now be accessed on \nGoogle Chrome for Windows, macOS, and Linux operating systems. \nHow It Works? To use this feature, users simply need to visit the bing.com domain on Chrome. After that, a Bing \nChat icon will appear at the top of the screen. By selecting this option, a chat interface opens. Here you can input \nprompts and engage with the AI.While Microsoft acknowledges that Bing Chat operates optimally on its Edge \nbrowser, this move shows that the tech giant has recognised the need to reach a wider user base. Google Chrome \ndominates the browser market with a 77.03 per cent share, according to Kinsta analytics, making it a major platform \nfor expanding Bing Chat's reach. However, Microsoft remains committed to its own browser, recently updating Edge \nwith an AI-based design tool named Designer. Further, the integration of Bing Chat Enterprise, accessible on both \nEdge for smartphones and Chrome for desktops, shows Microsoft's intention to make its AI technology more \naccessible in professional contexts. Microsoft has also introduced new Bing Search templates powered by \ngenerative AI content. These templates aim to streamline information retrieval, prevent content duplication, and \nhelp users in finding prompt answers to their questions. The integration of Bing Chat with SwiftKey, the widely-used \nvirtual keyboard app for Android and iOS, adds another dimension to accessibility. Users can now interact with Bing \nChat via SwiftKey up to 30 times per day, eliminating the need for a Microsoft account sign-in. For Reprint Rights: \ntimescontent.com\nLoad-Date: August 30, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Air India Taps Airbus, L3Harris for Training Unit",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 26, 2023",
        "section": "BRANDS & COMPANIES",
        "length": "644 words",
        "byline": "Anirban.Chowdhury@timesgroup.com",
        "story_text": "Air India Taps Airbus, L3Harris for Training Unit\nEconomic Times (E-Paper Edition)\nNovember 27, 2023 Monday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BRANDS & COMPANIES\nLength: 644 words\nByline: Anirban.Chowdhury@timesgroup.com\nHighlight: Cos may make strategic investments in $200-m facility as Tata group airline looks to ramp up ops with a \nsteady inflow of aircraft\nBody\nMumbai: Air India is in talks with aerospace majors, including L3Harris and Airbus, as potential partners for its big \ncrew training facility and will be disclosing more details in January, CEO and MD Campbell Wilson said in a recent \ninterview.  People in the know said the companies will likely be making strategic investments in the $200-million \nfacility. “We are partnering with a couple of OEMs (original equipment manufacturers) to set up simulator training \ncentres: Airbus, Boeing L3Harris. We will be talking a little more about that in January,” said Wilson. \nHe didn’t elaborate on the nature of the partnership of investment from partners. L3Harris, formed in 2019 by the \nmerger of American companies L3 Technologies and Harris Corp, has  business interests in segments including \naerospace communications, integrated mission systems, space and airborne systems. The training centre would be \ncritical for training pilots to fly the large number of planes the airline will receive over the next five years, starting \nDecember.  In June, Air India placed a historic order for 470 aircraft from Boeing and Airbus. The airline will need \nover 5,000 pilots to fly these planes. India needs 1,700 pilots every year, half of which have  to be captains. It, \nhowever, produces just 200. “We hopefully will be inducting the first group of cabin crew in January. It's a \nresponsibility that we take very seriously, investing a lot of money in it. It's crucial for us as an airline to grow and to \ngrow our capabilities and become world class. One thing that we know for sure is that this indus-  try requires a lot \nof good trained people and India has a lot of good people that just need to be trained,” he said. New aircraft are \ncritical for Air India to upgrade its ageing fleet and product if it wants to regain its long lost status of a globally \nrelevant airline. The airline, which had climbed the ranks in on-time performance in April, has slipped in recent \nmonths to be among the bottom three airlines, according to the data from the Directorate General of Civil Aviation \n(DGCA) regarding on-time performances in four major metro airports which handle more than 60% of India’s air \ntraffic. By March, Air India will get the delivery of 4 Boeing 777 planes and six Airbus A350 wide-bodied planes, \nwhich means that a quarter of its widebodied fleet then will be sporting latest generation products.  “Then in July, \nAugust of next year, we put our all legacy aircraft through a retrofit programme, which will take about 18 months, so \nthat by the end of 2025, all of our aircraft have been upgraded to the latest standards of seats and entertainment \nand other amenities,” he said. The Tata group took over Air India on January 27, 2022 from the government which \nhad put it on the block for privatisation. In the last 1 year, the airline has been charting out ways to leverage the \nstrengths of the Tata group companies, including Tata Technologies that recently launched its IPO.  Tata \nTechnologies is “doing some work for us in digitising certain seat components so we can get spares manufactured \namongst other things,” said Wilson, adding Tata Alexi is helping the airline with a lot of “design work”.  Air India \nrecently launched a generative AI powered chatbot and will introduce more generative AI-pow-  ered solutions, \nsaid Wilson. “We are one of the few companies in the world that are using Microsoft's (AI tool) copilot embedded \ninto our enterprise suite. We use it every day in all of our tools. And many teams across the business are hard at \nwork, thinking about how we can bring it into our daily business life, using it behind the scenes to improve such \nAir India Taps Airbus , L3Harris for Training Unit\nthings as revenue management. I do think it's going to be quite transformative. It certainly has the opportunity to \nimprove efficiency and effectiveness and as a consequence, cost and service delivery...”\nLoad-Date: November 26, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jul2023",
        "header": "Will Impact Search Engines",
        "media": "Economic Times (E-Paper Edition)",
        "time": "July 17, 2023",
        "section": "FRONT PAGE",
        "length": "489 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Will Impact Search Engines\nEconomic Times (E-Paper Edition)\nJuly 17, 2023 Monday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 489 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Chatbots may face lawsuits if they scrape Internet to use such data, say experts\nBody\nLATEST VERSION OF DATA BILL DROPS CLAUSE THAT CREATED EXCEPTION\nBengaluru: Generative artificial intelligence (AI) platforms such as ChatGPT or Google's Bard may not be able to \nprocess the personal data of Indians available in the public domain, as per the latest draft of the Digital Personal \nData Protection (DPDP) Bill, 2023, which was approved by the cabinet earli-  er this month.  To be sure, the draft of \nthe final bill is not public as yet. Experts are relying on a leaked version of a draft that's circulating in legal and \npolicy circles to make this analysis. \nMost declined to be named due to this reason.  This latest version has dropped a clause that had earlier created an \nexception for search engines to process publicly available personal data. If generative AI platforms scrape the \nInternet to use such data, they may be opening themselves to the threat of lawsuits in the country, like the ones \nthey are facing in the US currently, experts said.  This will impact search engines as well as online telephone and \nemail directories along with credit rating agencies. According to a technology expert at a public policy think tank, \n“Removing Clause 8(8), which listed any 'processing of publicly available personal data' under public interest as a \ncriterion for deemed consent, might impact new AI evolutions like ChatGPT.\" The 2022 version of the DPDP Bill \nhad incorporated this clause. The DPDP Bill, 2023, has been listed by the government for consideration and \npassage in the Lok Sabha in the upcoming monsoon session. “This removal indicates that AI chatbots shall collect \nand process publicly available personal information only after obtaining consent from data principals at the \ncommencement of its processing,” the expert said. The consent-based approach doesn't consider the complex \ndataprocessing mechanism followed by new AI evolutions like ChatGPT, he said. Experts pointed out that the US \nFederal Trade Commission (FTC) launched an investigation into ChatGPT creator OpenAI last week on whether \nthe artificial intelligence company violated consumer protection laws by scraping public data. In its 20-page letter, \nthe FTC has asked OpenAI numerous questions regarding the startup's AI model training and personal data \nhandling among other security concerns. Open AI CEO Sam Altman said in a tweet on Thursday evening that the \ncompany will work with the agency. Its technology is safe and pro-consumer “and we are confident we follow the \nlaw”, he said. Altman also said the company protects user privacy and designs its systems “to learn about the \nworld, not private individuals”. Other jurisdictions such as Italy have imposed restrictions on OpenAI. Experts said \nthe FTC case may set a broader precedent on how generative models such as ChatGPT train their language \nmodels. The FTC has also filed a complaint against Amazon for allegedly enrolling its customers knowingly in \nAmazon Prime without prior consent.\nLoad-Date: July 17, 2023\nWill Impact Search Engines"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi: From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2023",
        "header": "Tinkering With ChatGPT, Workers Wonder: Will This Take My Job?",
        "media": "The New York Times - International Edition",
        "time": "March 29, 2023",
        "section": "BUSINESS",
        "length": "1695 words",
        "byline": "Lydia DePillis and Steve Lohr",
        "story_text": "Tinkering With ChatGPT, Workers Wonder: Will This Take My Job?\nThe New York Times - International Edition\nMarch 30, 2023 Thursday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1695 words\nByline: Lydia DePillis and Steve Lohr\nBody\nABSTRACT\nArtificial intelligence is confronting white-collar professionals more directly than ever. It could make them more \nproductive - or obsolete.\nFULL TEXT\nIn December, the staff of the American Writers and Artists Institute - a 26-year-old membership organization for \ncopywriters - realized that something big was happening.       \nThe newest edition of ChatGPT, a \"large language model\" that mines the internet to answer questions and perform \ntasks on command, had just been released. Its abilities were astonishing - and squarely in the bailiwick of people \nwho generate content, such as advertising copy and blog posts, for a living.       \n\"They're horrified,\" said Rebecca Matter, the institute's president. Over the holidays, she scrambled to organize a \nwebinar on the pitfalls and potential of the new artificial-intelligence technology. More than 3,000 people signed up, \nshe said, and the overall message was cautionary but reassuring: Writers could use ChatGPT to complete \nassignments more quickly, and move into higher-level roles in content planning and search-engine optimization.       \n\"I do think it's going to minimize short-form copy projects,\" Ms. Matter said. \"But on the flip side of that, I think there \nwill be more opportunities for things like strategy.\"       \nOpenAI's ChatGPT is the latest advance in a steady march of innovations that have offered the potential to \ntransform many occupations and wipe out others, sometimes in tandem. It is too early to tally the enabled and the \nendangered, or to gauge the overall impact on labor demand and productivity. But it seems clear that artificial \nintelligence will impinge on work in different ways than previous waves of technology.       \nThe positive view of tools like ChatGPT is that they could be complements to human labor, rather than \nreplacements. Not all workers are sanguine, however, about the prospective impact.       \nKatie Brown is a grant writer in the Chicago suburbs for a small nonprofit group focused on addressing domestic \nviolence. She was shocked to learn in early February that a professional association for grant writers was promoting \nthe use of artificial-intelligence software that would automatically complete parts of an application, requiring the \nhuman simply to polish it before submitting.       \nThe platform, called Grantable, is based on the same technology as ChatGPT, and it markets itself to freelancers \nwho charge by the application. That, she thought, clearly threatens opportunities in the industry.       \nTinkering With ChatGPT, Workers Wonder: Will This Take My Job?\n\"For me, it's common sense: Which do you think a small nonprofit will pick?\" Ms. Brown said. \"A full-time-salary-\nplus-benefits person, or someone equipped with A.I. that you don't have to pay benefits for?\"       \nArtificial intelligence and machine learning have been operating in the background of many businesses for years, \nhelping to evaluate large numbers of possible decisions and better align supply with demand, for example. And \nplenty of technological advancements over centuries have decreased the need for certain workers - although each \ntime, the jobs created have more than offset the number lost.       \nChatGPT, however, is the first to confront such a broad range of white-collar workers so directly, and to be so \naccessible that people could use it in their own jobs. And it is improving rapidly, with a new edition released this \nmonth. According to a survey conducted by the job search website ZipRecruiter after ChatGPT's release, 62 \npercent of job seekers said they were concerned that artificial intelligence could derail their careers.       \n\"ChatGPT is the one that made it more visible,\" said Michael Chui, a partner at the McKinsey Global Institute who \nstudies automation's effects. \"So I think it did start to raise questions about where timelines might start to be \naccelerated.\"       \nThat's also the conclusion of a White House report on the implications of A.I. technology, including ChatGPT. \"The \nprimary risk of A.I. to the work force is in the general disruption it is likely to cause to workers, whether they find that \ntheir jobs are newly automated or that their job design has fundamentally changed,\" the authors wrote.       \nFor now, Guillermo Rubio has found that his job as a copywriter has changed markedly since he started using \nChatGPT to generate ideas for blog posts, write first drafts of newsletters, create hundreds of slight variations on \nstock advertising copy and summon research on a subject about which he might write a white paper.       \nSince he still charges his clients the same rates, the tool has simply allowed him to work less. If the going rate for \ncopy goes down, though - which it might, as the technology improves - he's confident he'll be able to move into \nconsulting on content strategy, along with production.       \n\"I think people are more reluctant and fearful, with good reason,\" Mr. Rubio, who is in Orange County, Calif., said. \n\"You could look at it in a negative light, or you can embrace it. I think the biggest takeaway is you have to be \nadaptable. You have to be open to embracing it.\"       \nAfter decades of study, researchers understand a lot about automation's impact on the work force. Economists \nincluding Daron Acemoglu at the Massachusetts Institute of Technology have found that since 1980, technology \nhas played a primary role in amplifying income inequality. As labor unions atrophied, hollowing out systems for \ntraining and retraining, workers without college educations saw their bargaining power reduced in the face of \nmachines capable of rudimentary tasks.       \nThe advent of ChatGPT three months ago, however, has prompted a flurry of studies predicated on the idea that \nthis isn't your average robot.       \nOne team of researchers ran an analysis showing the industries and occupations that are most exposed to artificial \nintelligence, based on a model adjusted for generative language tools. Topping the list were college humanities \nprofessors, legal services providers, insurance agents and telemarketers. Mere exposure, however, doesn't \ndetermine whether the technology is likely to replace workers or merely augment their skills.       \nShakked Noy and Whitney Zhang, doctoral students at M.I.T., conducted a randomized, controlled trial on \nexperienced professionals in such fields as human relations and marketing. The participants were given tasks that \ntypically take 20 to 30 minutes, like writing news releases and brief reports. Those who used ChatGPT completed \nthe assignments 37 percent faster on average than those who didn't - a substantial productivity increase. They also \nreported a 20 percent increase in job satisfaction.       \nA third study - using a program developed by GitHub, which is owned by Microsoft - evaluated the impact of \ngenerative A.I. specifically on software developers. In a trial run by GitHub's researchers, developers given an \nTinkering With ChatGPT, Workers Wonder: Will This Take My Job?\nentry-level task and encouraged to use the program, called Copilot, completed their task 55 percent faster than \nthose who did the assignment manually.       \nThose productivity gains are unlike almost any observed since the widespread adoption of the personal computer.       \n\"It does seem to be doing something fundamentally different,\" said David Autor, another M.I.T. economist, who \nadvises Ms. Zhang and Mr. Noy. \"Before, computers were powerful, but they simply and robotically did what people \nprogrammed them to do.\" Generative artificial intelligence, on the other hand, is \"adaptive, it learns and is \ncapable of flexible problem solving.\"       \nThat's very apparent to Peter Dolkens, a software developer for a company that primarily makes online tools for the \nsports industry. He has been integrating ChatGPT into his work for tasks like summarizing chunks of code to aid \ncolleagues who may pick up the project after him, and proposing solutions to problems that have him stumped. If \nthe answer isn't perfect, he'll ask ChatGPT to refine it, or try something different.       \n\"It's the equivalent of a very well-read intern,\" Mr. Dolkens, who is in London, said. \"They might not have the \nexperience to know how to apply it, but they know all the words, they've read all the books and they're able to get \npart of the way there.\"       \nThere's another takeaway from the initial research: ChatGPT and Copilot elevated the least experienced workers \nthe most. If true, more generally, that could mitigate the inequality-widening effects of artificial intelligence.       \nOn the other hand, as each worker becomes more productive, fewer workers are required to complete a set of \ntasks. Whether that results in fewer jobs in particular industries depends on the demand for the service provided, \nand the jobs that might be created in helping to manage and direct the A.I. \"Prompt engineering,\" for example, is \nalready a skill that those who play around with ChatGPT long enough can add to their résumés.       \nSince demand for software code seems insatiable, and developers' salaries are extremely high, increasing \nproductivity seems unlikely to foreclose opportunities for people to enter the field.       \nThat won't be the same for every profession, however, and Dominic Russo is pretty sure it won't be true for his: \nwriting appeals to pharmacy benefit managers and insurance companies when they reject prescriptions for \nexpensive drugs. He has been doing the job for about seven years, and has built expertise with only on-the-job \ntraining, after studying journalism in college.       \nAfter ChatGPT came out, he asked it to write an appeal on behalf of someone with psoriasis who wanted the \nexpensive drug Otezla. The result was good enough to require only a few edits before submitting it.       \n\"If you knew what to prompt the A.I. with, anyone could do the work,\" Mr. Russo said. \"That's what's really scares \nme. Why would a pharmacy pay me $70,000 a year, when they can license the technology and pay people $12 an \nhour to run prompts into it?\"       \nTo try to protect himself from that possible future, Mr. Russo has been building up his side business: selling pizzas \nout of his house in southern New Jersey, an enterprise that he figures won't be disrupted by artificial intelligence.       \nYet. \nLoad-Date: March 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2023",
        "header": "America, China and a Crisis of Trust; Thomas L. Friedman",
        "media": "The New York Times - International Edition",
        "time": "April 16, 2023",
        "section": "OPINION",
        "length": "4983 words",
        "byline": "Thomas L. Friedman",
        "story_text": "America, China and a Crisis of Trust; Thomas L. Friedman\nThe New York Times - International Edition\nApril 17, 2023 Monday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: OPINION\nLength: 4983 words\nByline: Thomas L. Friedman\nBody\nABSTRACT\nA trip to Beijing and Taiwan showed me how the United States and China are fated to cooperate and doomed to \ncompete.\nFULL TEXT\nTAIPEI, Taiwan - I just returned from visiting China for the first time since Covid struck. Being back in Beijing was a \nreminder of my first rule of journalism: If you don't go, you don't know. Relations between our two countries have \nsoured so badly, so quickly, and have so reduced our points of contact - very few American reporters are left in \nChina, and our leaders are barely talking - that we're now like two giant gorillas looking at each other through a \npinhole. Nothing good will come from this.       \nThe recent visit by Taiwan's president, Tsai Ing-wen, to the United States - which prompted Beijing to hold live-fire \ndrills off Taiwan's coast and to warn anew that peace and stability in the Taiwan Strait are incompatible with any \nmove by Taiwan toward formal independence - was just the latest reminder of how overheated this atmosphere is. \nThe smallest misstep by either side could ignite a U.S.-China war that would make Ukraine look like a \nneighborhood dust-up.       \nThat's one of the many reasons I found it helpful to be back in Beijing and to be able to observe China again \nthrough a larger aperture than a pinhole. Attending the China Development Forum - Beijing's very useful annual \ngathering of local and global business leaders, senior Chinese officials, retired diplomats and a few local and \nWestern journalists - reminded me of some powerful old truths and exposed me to some eye-popping new realities \nabout what's really eating away at U.S.-China relations.       \nHint: The new, new thing has a lot to do with the increasingly important role that trust, and its absence, plays in \ninternational relations, now that so many goods and services that the United States and China sell to one another \nare digital, and therefore dual use - meaning they can be both a weapon and a tool. Just when trust has become \nmore important than ever between the U.S. and China, it also has become scarcer than ever. Bad trend.       \nMore personally, being back in Beijing was also a reminder of how many people I've come to know and like there \nover three decades of reporting visits - but please don't tell anyone in Washington that I said that. There's \nsomething of a competition today between Democrats and Republicans over who can speak most harshly about \nChina. Truth be told, both countries have so demonized the other of late that it is easy to forget how much we have \nin common as people. I can't think of any major nation after the United States with more of a Protestant work ethic \nand naturally capitalist population than China.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nBeing back was also a reminder of the formidable weight and strength of what China has built since opening to the \nworld in the 1970s, and even since Covid hit in 2019. China's Communist Party government has a stronger grip \nthan ever on its society, thanks to its police state surveillance and digital tracking systems: Facial recognition \ncameras are everywhere. The party crushes any challenge to its rule or to President Xi Jinping. These days, it is \nextremely difficult for a visiting columnist to get anyone - a senior official or a Starbucks barista - to speak on the \nrecord. It was not that way a decade ago.       \nThat said, one should have no illusions: The Communist Party's hold is also a product of all the hard work and \nsavings of the Chinese people, which have enabled the party and the state to build world-class infrastructure and \npublic goods that make life for China's middle and lower classes steadily better.       \nBeijing and Shanghai, in particular, have become very livable cities, with the air pollution largely erased and lots of \nnew, walkable green spaces. As my Times colleague Keith Bradsher reported in 2021, Shanghai had recently built \n55 new parks, bringing its total to 406, and had plans for nearly 600 more.       \nBradsher, one of the handful of American reporters who lived in mainland China through nearly three years of \nstringent \"zero Covid\" policies, also pointed out to me that some 900 cities and towns in China are now served by \nhigh-speed rail, which makes travel to even remote communities incredibly cheap, easy and comfortable. In the last \n23 years America has built exactly one sort-of-high-speed rail line, the Acela, serving 15 stops between \nWashington, D.C., and Boston. Think about that: 900 to 15.       \nI say this not to argue that high-speed trains are better than freedom. I say this to explain that being in Beijing \nreminds you that China's stability is a product of both an increasingly pervasive police state and a government that \nhas steadily raised standards of living. It's a regime that takes both absolute control and relentless nation-building \nseriously.       \nFor an American to fly from New York's Kennedy Airport into Beijing Capital International Airport today is to fly from \nan overcrowded bus terminal to a Disney-like Tomorrowland. It makes me weep for all the time we have wasted \nthese past eight years talking about a faux nation builder named Donald Trump.       \nOn my first day in Beijing, I had a conversation with a young Chinese woman, a college student. Her first question, \nalluding to a book I wrote, was: \"Mr. Friedman, is the world still flat?\"       \nI explained why I thought it was flatter than ever by my definition - that because of steady advances in connectivity \nand digitization, more people can compete, connect and collaborate on more things for less money from more \nplaces than ever. During my time in Beijing, I was struck at how educated Chinese people seem to be more \nconnected, and able to get around digital firewalls, than before.       \nI could see the woman wasn't totally convinced by my explanation, so we moved on to other subjects. And then she \ndropped this: \"I just used ChatGPT.\"       \nI said, \"You used ChatGPT from Beijing, and you're asking me if the world is still flat?\"       \nIndeed, a story making the rounds in Beijing is that many Chinese have begun using ChatGPT to do their ideology \nhomework for the local Communist Party cell, so they don't have to waste time on it.       \nIt's funny, though - just when you start to worry about the state of J.F.K. Airport, and all the stories in recent years \nthat China was going to bury us in the race to A.I., an American team, OpenAI, comes up with the world's leading \nnatural language processing tool, which enables any user to have humanlike conversations, ask any question and \nget deep insights in every major language, including Mandarin.       \nChina got an early jump on A.I. in two realms - facial recognition technology and health records - because there are \nvirtually no privacy restrictions on the government's ability to build huge data sets for machine learning algorithms to \nfind patterns.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nBut generative A.I., like ChatGPT, gives anyone, from a poor farmer to a college professor, the power to ask any \nquestion on any subject in his or her own language. This could be a real problem for China, because it will have to \nbuild many guardrails into its own generative A.I. systems to limit what Chinese citizens can ask and what the \ncomputer can answer. If you can't ask whatever you want, including what happened in Tiananmen Square on June \n4, 1989, and if your A.I. system is always trying to figure out what to censor, where to censor and whom to censor, it \nwill be less productive.       \n\"ChatGPT is prompting some people to ask if the U.S. is rising again, like in the 1990s,\" Dingding Chen, a Chinese \npolitical scientist, told me and Bradsher.       \nIt's for all of these reasons that weighing the shifting power relationship between America and China has become \nsuch a popular pastime among elites in both of our countries. For instance, through social media, many Chinese got \nto see parts of the March 23rd hearing on Capitol Hill where members of Congress questioned - or, actually, \nberated, harangued and constantly interrupted - TikTok's chief executive, Shou Chew, claiming TikTok's videos \nwere damaging American children's mental health.       \nHu Xijin, one of China's most popular bloggers, with almost 25 million followers on Weibo, China's equivalent of \nTwitter, explained to me just how insulting Chinese found that hearing. It was widely and derisively commented \nabout online in China.       \n(All that said, YouTube has been banned from China since 2009, so we're not the only ones frightened by popular \napps. I say we trade: We'll accept TikTok if Beijing will let in YouTube.)       \n\"I understand your feeling: You have been in the first place for a century, and now China is rising, and we have the \npotential to become the first - and that is not easy for you,\" Hu said to me. But \"you should not try to stop China's \ndevelopment. You can't contain China in the end. We are quite smart. And very diligent. We work very hard. And \nwe have 1.4 billion people.\"       \nBefore the Trump presidency, he added: \"We never thought China-U.S. relations would ever become so bad. Now \nwe gradually accept the situation, and most Chinese people think there is no hope for better relations. We think the \nrelationship will be worse and worse and hope that war will not break out between our two countries.\"       \nIt was repeated conversations like these that got me started asking American, Chinese and Taiwanese investors, \nanalysts and officials a question that has been nagging at me for a while: What exactly are America and China \nfighting about?       \nA lot of people hesitated when I asked. Indeed, many would answer with some version of \"I'm not sure, I just know \nthat it's THEIR fault.\"       \nI'm pretty sure I'd get the same answer in Washington.       \nThe best part of this trip was uncovering the real answer to that question and why it stumps so many people. It's \nbecause the real answer is so much deeper and more complex than just the usual one-word response - \"Taiwan\" - \nor the usual three-word response - \"autocracy versus democracy.\"       \nLet me try to peel back the layers. The erosion in U.S.-China relations is a result of something old and obvious - a \ntraditional great-power rivalry between an incumbent power (us) and a rising power (China) - but with lots of new \ntwists that are not always visible to the naked eye.       \nThe old and obvious aspect is that China and America are jostling to acquire the most economic and military clout \nto shape the rules of the 21st century in ways most advantageous to their respective economic and political \nsystems. And one of those disputed rules, which America has acknowledged but not endorsed, is China's claim to \nTaiwan as part of \"One China.\"       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nBecause that \"rule\" remains in dispute, we will continue to arm Taiwan to deter Beijing from seizing the island, \ncrushing its democracy and using it as a jumping off point to dominate the rest of East Asia, and China will keep \npushing for reunification - one way or another.       \nOne of the twists, though, is that this standard-issue great-power rivalry is occurring between nations that have \nbecome as economically intertwined as the strands of a DNA molecule. As a result, neither China nor America has \never had a rival quite like the other.       \nAmerica knew how to deal with Nazi Germany, an economic and military peer, but a country with which we were not \ndeeply economically intertwined. America knew how to deal with the Soviet Union, a military peer but nowhere near \nour economic peer, and a country with which we were not economically intertwined at all.       \nDitto China. For several thousand years China saw itself as situated in the middle of the world - hence it referred to \nitself as Zhong Guo, the Middle Kingdom - protected by mountains, deserts and seas on all sides, and often \ndominating states around it, while fiercely preserving its own culture. That was until the 19th century, when it began \nto be repeatedly ravaged by stronger foreign powers: Britain, France, Russia and Japan.       \nBut in modern times, China, like America, has never had to deal with a true economic and military peer with which it \nwas also totally intertwined through trade and investment.       \nHow intertwined? Americans' favorite device is an iPhone assembled mostly in China, and until recently the favored \nforeign destination of Chinese college students - some 300,000 of them today - is America. That makes for some \nweird scenes, like watching one country shoot down another country's intelligence balloon just after the two \ncountries in 2022 set a record in annual bilateral trade.       \nAnother new twist, and a reason it's hard to define exactly what we're fighting about, has a lot to do with how this \nelusive issue of trust and the absence of it have suddenly assumed much greater importance in international affairs.       \nThis is a byproduct of our new technological ecosystem in which more and more devices and services that we both \nuse and trade are driven by microchips and software, and connected through data centers in the cloud and high-\nspeed internet. When so many more products or services became digitized and connected, so many more things \nbecame \"dual use.\" That is, technologies that can easily be converted from civilian tools to military weapons, or vice \nversa.       \nIn the Cold War it was relatively easy to say that this fighter jet is a weapon and that that phone is a tool. But when \nwe install the ability to sense, digitize, connect, process, learn, share and act into more and more things - from your \nGPS-enabled phone to your car to your toaster to your favorite app - they all become dual use, either weapons or \ntools depending on who controls the software running them and who owns the data that they spin off.       \nToday, it's just a few lines of code that separate autonomous cars from autonomous weapons. And, as we've seen \nin Ukraine, a smartphone can be used by Grandma to call the grandkids or to call a Ukrainian rocket-launching unit \nand give it the GPS coordinates of a Russian tank in her backyard.       \nThis, too, leads to more weird twists. I am thinking of how a number of U.S. armed forces branches have banned \nTikTok from government-issued smartphones and computers. This is surely the first time that the Pentagon has \nbanned an app that is known mostly for sharing dance moves. But there is a real fear that TikTok's highly addictive \nalgorithm is dual use and could be repurposed by the Chinese intelligence service to amass data on our youth - \nmore than 150 million Americans have downloaded the app, the company says - to scramble their brains, spread \ndisinformation or collect information that could one day be used for blackmail.       \nAnd the twists just keep on coming. For the first 30 or so years after Beijing opened up to trading with the world, \nstarting around 1978-79, China largely sold America what I call \"shallow\" goods - shoes, socks, shirts and solar \npanels.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nMeanwhile, America and the West tended to sell China what I call \"deep goods\" - goods that went deep into their \nsystems and were dual use - namely software, microchips, bandwidth, smartphones and robots. China had to buy \nour deep goods because, until relatively recently, it could not make many itself.       \nAs long as most of what China sold us was shallow goods, we did not care as much about its political system - \ndoubly so because it seemed for a while as if China was slowly but steadily becoming more and more integrated \nwith the world and slightly more open and transparent every year. So, it was both easy and convenient to set aside \nsome of our worries about the dark sides of its political system.       \nBut then, about eight years ago, we got a knock on our door and there was a Chinese salesman. He said: \"Hi, my \nname is Mr. Huawei and I make 5G telephone equipment better than anything you have. I'm starting to install it all \nover the world, and I'd like to wire America.\"       \nWhat America essentially told this Huawei salesman, as well as other rising Chinese high-tech firms, was this: \n\"When Chinese companies were just selling us shallow goods, we didn't care if your political system was \nauthoritarian, libertarian or vegetarian; we were just buying your shallow goods. But when you want to sell us 'deep \ngoods' - goods that are dual use and will go deep into our homes, bedrooms, industries, chatbots and urban \ninfrastructure - we don't have enough trust to buy them. So, we are going to ban Huawei and instead pay more to \nbuy our 5G telecom systems from Scandinavian companies we do trust: Ericsson and Nokia.\"       \nThe role of trust in international relations and commerce took one more great leap for another reason: As more and \nmore products and services became digitized and electrified, the microchips that powered everything became the \nnew oil. What crude oil was to powering 19th- and 20th-century economies, microchips are for powering 21st-\ncentury economies.       \nSo today, the country or countries that can make the fastest, most powerful and most energy efficient microchips \ncan make the biggest A.I. computers and dominate in economics and military affairs.       \nBut here's the rub: Because the physics of making advanced logic chips has become so complex - a human hair is \nabout 90,000 nanometers thick and the world's best mass producer of advanced chips in the world is now making \nthree-nanometer transistors - no one country or company can own the whole supply chain. You need the best from \neverywhere, and that supply chain is so tightly intertwined that each company has to trust the others intimately.       \nChina doesn't need to look far for that lesson. It is on display right across the Straits of Taiwan, at the world's \ngreatest chip-making company, Taiwan Semiconductor Manufacturing Company, better known as TSMC.       \nAfter I left Beijing, I came to Taiwan, where I spent an afternoon with the leaders of TSMC at their headquarters in \nHsinchu Science Park, a 90-minute drive south of Taipei, the capital. When you ask them what is the secret that \nenables TSMC to make 90 percent of the world's most advanced logic chips - while China, which speaks the same \nlanguage and shares the same recent cultural history, makes zero - their answer is simple: \"trust.\"       \nTSMC is a semiconductor foundry, meaning it takes the designs of the most advanced computer companies in the \nworld - Apple, Qualcomm, Nvidia, AMD and others - and turns the designs into chips that perform different \nprocessing functions. In doing so, TSMC makes two solemn oaths to its customers: TSMC will never compete \nagainst them by designing its own chips and it will never share the designs of one of its customers with another.       \n\"Our business is to serve multiple competitive clients,\" Kevin Zhang, senior vice president for business development \nat TSMC, explained to me. \"We are committed not to compete with any of them, and internally our people who \nserve customer A will never leak their information to customer C.\"       \nBut by working with so many trusted partners, TSMC leverages the partners' steadily more complex designs to \nmake itself better - and the better it gets, the more advanced designs it can master for its customers. This not only \nrequires incredibly tight collaboration between TSMC and its customers, but also between TSMC and its roughly \n1,000 critical local and global suppliers.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\n\"Our customers are very demanding,\" added Zhang. \"Their products each have unique requirements.\" They each \n\"tell us what they want to do, and together we figure out how TSMC will design the process to make it.\" As the \nphysics of chip making gets more and more extreme, \"the investment from customers is getting bigger and bigger, \nso they have to work with us more closely to make sure they harvest as much [computing power] as they can. They \nhave to trust you.\"       \nChina also has a foundry, Semiconductor Manufacturing International Corporation, which is partly state-owned. But \nguess what? Because no global chip designers trust SMIC with their most advanced designs, it is at least a decade \nbehind TSMC.       \nIt's for these reasons that the erosion in U.S.-China relations goes beyond our increasingly sharp disagreements \nover Taiwan. It is rooted in the fact that just when trust, and its absence, became much bigger factors in \ninternational affairs and commerce, China changed its trajectory. It made itself a less trusted partner right when the \nmost important technology for the 21st century - semiconductors - required unprecedented degrees of trust to \nmanufacture and more and more devices and services became deep and dual use.       \nWhy did China lose our trust?       \nAfter the period of China's isolation and internal turmoil under Mao Zedong ended with his death in 1976, a \nsuccessor, Deng Xiaoping, made a 180-degree turn away from Maoism. Deng established a much more collective \nleadership for China and term limits for the top leaders, and he put pragmatism - whatever would drive economic \ngrowth - above Communist ideology, while hiding China's growing strength.       \nIn the era of Deng and his successors - in the 1980s, 1990s and early 2000s - Beijing forged strong economic and \neducational ties with the United States, which ushered China into the World Trade Organization, on the condition \nthat China gradually phase out its mercantilist practice of funding state-owned industries and that it gradually open \nitself to more foreign investment and ownership, much as the world opened itself to China's exports.       \nBut after Xi Jinping took over as China's paramount leader in 2012, he seemed to be alarmed at how China's \nopenness toward the world, its consensus approach to leadership and its rush down a semi-capitalist path had led \nto runaway corruption inside both the Communist Party and the People's Liberation Army, to a degree that was \nhurting the party's legitimacy.       \nSo Xi centralized power into his own hands, crushed all the fiefs that had been created by different leaders \nof different government agencies and sectors of the economy, re-injected the authority of the Communist Party into \nevery corner of business, academia and society and deployed pervasive surveillance technologies. All together, this \nreversed what seemed like China's steady march toward more openness - and even a somewhat freer press.       \nXi also basically shifted away from Deng's unabashed unleashing of the private sector, focusing instead on building \nnational economic champions that could dominate all the key industries of the 21st century - from A.I. to quantum \ncomputing to aerospace - and making sure Communist Party cells were in their management and in their work \nforces. And when American trade officials said: \"Hey, you need to live up to your W.T.O. commitments to restrict \nstate-funding of industries,\" China basically said: \"Why should we live by your interpretation of the rules? We are \nnow big enough to make our own interpretations. We're too big; you're too late.\"       \nCombined with China's failure to come clean on what it knew about the origins of Covid-19, its crackdown on \ndemocratic freedoms in Hong Kong and on the Uyghur Muslim minority in Xinjiang, its aggressive moves to lay \nclaim to the South China Sea, its increasing saber rattling toward Taiwan, its cozying up to Vladimir Putin (despite \nhis savaging of Ukraine), Xi's moves toward making himself president for life, his kneecapping of China's own tech \nentrepreneurs, his tighter restrictions on speech and the occasional abduction of a leading Chinese businessman - \nall of these added up to one very big thing: Whatever trust that China had built up with the West since the late \n1970s evaporated at the exact moment in history when trust, and shared values, became more important than ever \nin a world of deep, dual-use products driven by software, connectivity and microchips.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nAs that happened, it started to matter a lot more to Western nations generally and the United States in particular \nthat this rising power - which we were now selling to or buying from all sorts of dual-use digital devices or apps - \nwas authoritarian.       \nBeijing, for its part, argues that as China became a stronger global competitor to America - in deep goods like \nHuawei 5G - the United States simply could not handle it and decided to use its control over advanced \nsemiconductor manufacturing and other high-tech exports from America, as well as from our allies, to ensure China \nalways remained in our rearview mirror. So Beijing came up with a new strategy, called \"dual circulation.\" It said: \nWe will use state-led investments to make everything we possibly can at home, to become independent of the \nworld. And we will use our manufacturing prowess to make the world dependent on our exports.       \nChinese officials also argue that a lot of American politicians - led by Trump but echoed by many in Congress - \nsuddenly seemed to find it very convenient to put the blame for economic troubles in the U.S.'s middle class not on \nany educational deficiencies, or a poor work ethic, or automation or the 2008 looting by financial elites, and the \ncrisis that followed, but on China's exports to the United States. As Beijing sees it, China not only became \nAmerica's go-to boogeyman, but in their frenzy to blame Beijing for everything, members of Congress started to \nmore recklessly promote Taiwan's independence.       \nA senior administration official told me that Xi told President Biden at their summit in Bali in November, in essence: I \nwill not be the president of China who loses Taiwan. If you force my hand, there will be war. You don't understand \nhow important this is to the Chinese people. You're playing with fire.       \nNevertheless, it's clear to me that at some level Chinese officials now understand that, as a result of their own \naggressive actions in recent years on all the fronts I've listed, they have frightened both the world and their own \ninnovators at precisely the wrong time.       \nI say that because of how often senior Chinese officials tell every foreign leader and visiting Western business \nexecutive they meet today that China is \"open\" and eager for foreign investment. The reality is, it has to be more \nopen to foreign direct investment because China's provinces desperately need capital to compensate for all the \nmoney each local government spent controlling Covid and because many of them are running out of land to sell for \nstate-owned factories to raise money.       \nI also don't think it was an accident of timing that Jack Ma, the founder of Alibaba and sort of the Steve Jobs of \nChina, suddenly reappeared a few weeks ago in state-controlled media after having suddenly disappeared from \npublic view in 2020. Ma had vanished after a disagreement with state regulators, who thought he was getting too \nbig and independent. His disappearance sent shock waves through China's start-up community and curbed \ninvestments.       \nI have no problem saying that I would like to live in a world where the Chinese people are thriving, alongside all \nothers. After all, we are talking about more than one out of six people on the planet. I don't buy the argument that \nwe are destined for war. I believe that we are doomed to compete with each other, doomed to cooperate with each \nother and doomed to find some way to balance the two. Otherwise we are both going to have a very bad 21st \ncentury.       \nI have to say, though, Americans and Chinese remind me of Israelis and Palestinians in one respect: They are both \nexpert at aggravating the other's deepest insecurities.       \nChina's Communist Party is now convinced that America wants to bring it down, which some U.S. politicians are \nactually no longer shy about suggesting. So, Beijing is ready to crawl into bed with Putin, a war criminal, if that is \nwhat it takes to keep the Americans at bay.       \nAmericans are now worried that Communist China, which got rich by taking advantage of a global market shaped \nby American rules, will use its newfound market power to unilaterally change those rules entirely to its advantage. \nSo we've decided to focus our waning strength vis-à-vis Beijing on ensuring the Chinese will always be a decade \nbehind us on microchips.       \nAmerica , China and a Crisis of Trust Thomas L. Friedman\nI don't know what is sufficient to reverse these trends, but I think I know what is necessary.       \nIf it is not the goal of U.S. foreign policy to topple the Communist regime in China, the United States needs to make \nthat crystal clear, because I found a lot more people than ever before in Beijing think otherwise.       \nAnd by the way, in today's fused world, the notion that China can economically collapse and America still thrive is \nutter fantasy. And the notion that the Europeans will always be with us in such an endeavor, given the size of \nChina's market, may also be fanciful. Note French President Emmanuel Macron's bowing and scraping in Beijing \nlast week.       \nAs for China, it can tell itself all it wants that it has not taken a U-turn in recent years. But no one is buying it. China \nwill never realize its full potential - in a hyper-connected, digitized, deep, dual-use, semiconductor-powered world - \nunless it understands that establishing and maintaining trust is now the single most important competitive \nadvantage any country or company can have. And Beijing is failing in that endeavor.       \nIn his splendid biography of the great American statesman George Shultz, Philip Taubman quotes one of Shultz's \ncardinal rules of diplomacy and life: \"Trust is the coin of the realm.\"       \nNever has that been truer than today, and never has China been more in need of embracing that truth.       \nThe Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nLoad-Date: April 16, 2023"
    },
    {
        "file_name": "The_Economic_Times_Feb2024",
        "header": "Accenture spots about 10% revenue upswing via GenAI",
        "media": "The Economic Times",
        "time": "February 26, 2024",
        "section": "ITES",
        "length": "647 words",
        "byline": "Beena Parmar and Surabhi Agarwal",
        "story_text": "Accenture spots about 10% revenue upswing via GenAI\nThe Economic Times\nFebruary 26, 2024 Monday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 647 words\nByline: Beena Parmar and Surabhi Agarwal\nBody\nAccenture has started to see a potential revenue upswing of about 10% with the use of generative artificial \nintelligence (GenAI) in some important business units, a top executive of the American technology services \ncompany told ET.Its clients across key sectors, which include banking and insurance, consumer goods, retail and \nsoftware and platforms, are beginning to see potential increase in revenues through their integration with GenAI, \nSenthil Ramani, global lead – data and AI at Accenture, said in an exclusive interview.“Early results from the \ninsurance industry indicate a revenue increase of up to 10% is possible, if companies reinvent the entire workflow of \nunderwriting,” Ramani said.Based on learnings from 700 client projects, companies that build a strong foundation of \nAI by adopting and scaling it now will be better positioned to reinvent, compete and achieve new levels of \nperformance, he said.Also read | Accenture opens genAI studio in BengaluruThe professional services giant is also \nseeing promise with highest demand in the consumer industry with the hyper personalisation that is helping \n“change context to relevance in terms of net revenue”.Life sciences and software and platforms, too, stand to \nbenefit from GenAI.“The velocity with which this tech is moving, it’s so fast that it’s yet to be completely proven in \nsome like the clinical and drug discovery process,” Ramani said. “But there is a lot of promise and hope… Even a \nsix-month acceleration of AI and GenAI into that will mean a lot from a revenue perspective.”The overall impact \nheavily varies across the 19 industries tracked by the company, he said.Accenture, which has committed an \ninvestment of $3 billion in AI, has already signed a total of $450 million worth of GenAI deals in the first quarter of \nFY24 ended November. \nThis is a 50% pump up in the pipeline from $300 million in the last six months of FY23.Also read | Eye on GenAI, \nIndian IT companies seek opportunities to build and expandAccording to Ramani, GenAI has been a catalyst in \ndriving a lot of this in businesses.The economics of GenAI, he said, is going to get normalised because it will start \nto become consumer tech from being engineer tech.“Engineer tech is when it actually is expensive and you’ve got \nto spend on it. But consumer tech is when you and I can use it on our phones... And that’s definitely starting to \nhappen,” he said.In a bid to become an AI-first company, Accenture has also doubled its headcount in data and AI \nto 40,000 globally.“So far, we have trained 600,000 employees globally on the fundamentals of AI. This year, we \nwill train 250,000 of our people globally on the fundamentals of generative AI. We have already mapped over \n30,000 people globally to new and emerging roles in data and AI,” Ramani said.Over 20,000 of these people are in \nIndia and the country will play a significant role in Accenture’s journey towards becoming a AI first company, he \nadded.The company has made six acquisitions in the data and AI space in financial year 2023 and in financial year \n2024 so far.Accenture is tracking over 1,020 foundational models in the GenAI space today and Ramani suggests \nthat organisations must focus on their core competencies to drive those up the value chain.Speaking of AI models \nand partnerships to use AI, he said, “Some cases will just need prompting, some cases will need fine-tuning. In \nsome cases, you can even do something called pre-training to effectively train the model.”Ramani said the learning \ncomponent is going to be important.“This is an alarming statistic that less than 5% of organisations globally are \nspending on reskilling of people and educating them on GenAI, so 95% of people in organisations need to do that \nAccenture spots about 10% revenue upswing via GenAI\nfar more… The best learned folks are going to be the fastest on this because the technology is moving so fast,” he \nsaid. For Reprint Rights: timescontent.com\nLoad-Date: February 26, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "Google Brings Bard Chatbot to India Users",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "STARTUPS & TECH",
        "length": "134 words",
        "byline": "Dia.Rekhi@timesgroup.com",
        "story_text": "Google Brings Bard Chatbot to India Users\nEconomic Times (E-Paper Edition)\nMay 12, 2023 Friday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 134 words\nByline: Dia.Rekhi@timesgroup.com\nBody\nMountain View: Alphabet Inc's Google said its conversational generative AI chatbot 'Bard' is being rolled out in \nmore than 180 countries, including India. “As models get better and more capable, one of the most exciting \nopportunities is making them available for people to engage with directly,” Google's CEO, Sundar Pichai, said in his \nkeynote speech at the Google I/O, the company's annual developer conference held at its headquarters in \nMountain View, California, on Wednesday. “That's the opportunity we have with Bard — our experiment for \nconversational AI.” Initially, the Google Bard chatbot was only available in the UK and the US. In India, those \ninterested can join the waitlist for the AI chatbot via the Google Bard official website. (The reporter is at Mountain \nView at the invitation of Google)\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "$4_Billion_Mar2023",
        "header": "Anthropic, a ChatGPT Rival Founded by Daniela and Dario Amodei, Is Worth",
        "media": "$4 Billion",
        "time": "March 13, 2023",
        "section": "",
        "length": "501 words",
        "byline": "Sissi Cao",
        "story_text": "Anthropic, a ChatGPT Rival Founded by Daniela and Dario Amodei, Is Worth \n$4 Billion\nNew York Observer\nMarch 9, 2023 Thursday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 501 words\nByline: Sissi Cao\nBody\nAnthropic, a San Francisco-based artificial intelligence startup founded by siblings Daniela and Dario Amodei, both \nformer OpenAI executives, has raised $700 million in just a matter of weeks from tech giants like Google and \nSalesforce as investors continue to place large bets on generative A.I. technologies.\nThe two-year-old company just closed a $300 million funding round that valued it at $4.1 billion, the Information first \nreported yesterday (March 8). The round was led by Spark Capital, a venture capital firm with early stakes in Twitter \nand Tumblr. Salesforce is also a new investor, Anthropic disclosed in a tweet yesterday. Only four weeks ago, the \ncompany received an investment between $300 million and $400 million from Google, according to the Financial \nTimes.\nAnthropic's main product is Claude, a ChatGPT-like A.I. chatbot released in January. Currently it's only available to \na group of test users.\nDario Amodei, the CEO of Anthropic, worked at OpenAI between 2016 and 2020 and led the development of the \nfirm's GPT-2 and GPT-3 language models, according to his LinkedIn profile. GPT-3 is the language model behind \nChatGPT, which was released in November. Before OpenAI, Dario was a research scientist at Google and the U.S. \nbranch of Chinese internet giant Baidu.\nDaniela Amodei had a shorter career at OpenAI where she led the company's recruiting effort and managed its \ntechnical safety and policy teams, according to her LinkedIn page. Before that, she worked in similar functions at \npayment software maker Stripe for five years. Daniela serves as the Anthropic's president, overseeing the \ncompany's day-to-day operations.\nThe Amodei siblings and other Anthropic cofounders chose to start their own company to focus on building what \nthey call \"steerable, interpretable and reliable A.I. systems with humans at the center of it,\" Daniela said in an \ninterview with the Future of Life Institute, a science nonprofit, in March 2022.\nAs (artificially) intelligent as they may seem, A.I. chatbots including ChatGPT have been criticized for producing \nfactually wrong and biased answers to some prompts. Anthropic's goal is to fix those shortcomings. \"We are \ntraining large neural generative models and doing safety research on those models. We want to make those models \nsafer and more aligned with human values,\" Daniela Amodei said in the podcast.\nIn a white paper published in December, Anthropic said its work focuses on experimenting with methods for training \na chatbot that learn to identify and combat harmful queries through self-improvement, rather than human \nintervention. \"The only human oversight is provided through a list of rules or principles,\" the paper said.\nAnthropic, a ChatGPT Rival Founded by Daniela and Dario Amodei, Is Worth $4 Billion\nBefore this year, Anthropic had raised another $700 million through two funding rounds in 2022, according to \nCrunchbase, a database of startup funding activities. Anthropic's early investors include Facebook cofounder Dustin \nMoskovitz, former Google CEO Eric Schmidt and Sam Bankman-Fried, the disgraced founder of FTX Group.\nLoad-Date: March 13, 2023"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Sep2023",
        "header": "TIKTOK, META ADDRESS ONLINE HATE AT PITTSBURGH SUMMIT",
        "media": "Pittsburgh Post-Gazette",
        "time": "September 28, 2023",
        "section": "ASECTION; Pg. A-2",
        "length": "907 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "TIKTOK, META ADDRESS ONLINE HATE AT PITTSBURGH SUMMIT\nPittsburgh Post-Gazette\nSeptember 28, 2023 Thursday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: ASECTION; Pg. A-2\nLength: 907 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nAs TikTok and Meta race to flag and remove hateful comment swirling through their platforms, generative artificial \nintelligence is making it even harder to keep up.\n\"It's an everlasting game of chasing,\" Yfat Barak-Cheney, director of technology and human rights for the World \nJewish Congress, said Wednesday at the Eradicate Hate Global Summit in Pittsburgh.\nBut nonprofits using AI for good may be able to help.\nIn its first three months partnering with TikTok, CyberWell, an Israeli tech nonprofit backed by the Shear Family \nFoundation of Pittsburgh, alerted the short-form video company to three major antisemitic trends.\nThe most heinous conspiracy theory claimed that Jews were killing babies for ritual sacrifice and selling the bodies \nto McDonald's for hamburger meat.\n\"Before you lose hope, or your lunch, we'll go into the wonderful successes of actually working together with \nTikTok,\" Tal-Or Cohen Montemayor, CyberWell's founder and executive director, told an audience of about 200 at \nthe summit.\nMs. Montemayor said the 2018 massacre at Pittsburgh's Tree of Life Synagogue convinced her to leave her career \nin law to focus on hate research. By making that research open source, CyberWell's data could eventually be used \nto train generative artificial intelligence models that are quickly becoming part of social media platforms, Ms. \nMontemayor said.\nShe noted that one social media company, X, was not part of the panel that included policy officials from TikTok, \nMicrosoft and Meta.\nFormerly known as Twitter, X saw a steep drop-off in content moderation after it was purchased by billionaire Elon \nMusk in October 2022.\n\"It's very concerning,\" Ms. Montemayor said of the absence. \"Actually, these platforms are the ones we need to be \nfocused on.\"\nStill, others at the summit noted that extremists are continuing to reach large audiences on TikTok and other \nmainstream platforms despite efforts to remove harmful content.\nDuring two weeks in July, the Institute for Strategic Dialogue charted over 1 million TikTok views of 20 ISIS \naccounts.\nTIKTOK, META ADDRESS ONLINE HATE AT PITTSBURGH SUMMIT\nThe Institute, a U.K.-based nonprofit, also found a 106% increase in antisemitism and a 69% increase in accounts \nfollowing known misogynist and abusive accounts on Twitter after Mr. Musk took over the platform.\nMore concerning, some platforms were actively recommending harmful content to users through hashtags and \nother promotion.\nTikTok removes 90% of harmful content proactively, with 75% of problem videos taken down before they get a \nsingle view, Valiant Richey, TikTok's global head of outreach and partnerships for trust and safety, said at the \nsummit.\nHe highlighted a promotional video viewed more than 250 times that encouraged users to adjust their settings and \nreport hateful content, saying \"we want to empower users.\"\nBut reporting individual pieces of content is often a frustrating and insufficient process, said Ms. Barak-Cheney of \nthe World Jewish Congress. Instead of focusing on reporting, companies should target the offline issues that lead \npeople to radicalization, she said.\n\"Hate is a process,\" she said.\nMeta has banned Holocaust denial since 2020, although its implementation of that policy has been more spotty.\nOn Wednesday, Dina Hussein, the company's global head of policy development and expert partnerships for \ncounterterrorism and dangerous orgs policy, said it's great to build a policy but \"very difficult if you can't deploy it.\"\nShe said some new technologies have helped speed up flagging efforts. That includes working with tracking \npartners, identifying \"clusters of abusive networks\" and trying to prevent recidivism from specific actors.\nMs. Hussein did not specifically list generative AI, but she did talk about how quickly technology is changing.\n\"While we're advising our tactics, the adversary is also mutating,\" Ms. Hussein said.\nOne way Meta and TikTok have tried to tamp down on holocaust denial is by redirecting users to educational sites.\nBy pointing users toward authoritative partners who might be more influential, Meta can avoid coming across like \n\"your parents telling you not to do drugs,\" Ms. Hussein said.\nMs. Barak-Cheney called the redirect \"a way to catch people at an early stage.\"\nSmaller platforms, whose trust and safety teams tend to focus most of their time on spam, should also be \nincentivized to take on that work, she said.\nContent review teams, which are often under-resourced, could augment their work with AI so that the humans are \nfree to spend more of their time on the most impactful cases, said Michael Pappas, CEO and co-founder of \nModulate, a Boston startup using AI to curb toxic conversation among gamers.\nBut the new tools aren't a panacea.\n\"Please don't just trust an AI to moderate your content,\" he told the panel. \"It's not the right way to use this \ntechnology.\"\nMicrosoft was the most optimistic of the three major tech companies on the use of AI.\n\"It's difficult to think of a problem or a challenge that we face as a society that AI can't contribute to resolving,\" said \nHugh Handeyside, senior policy manager of Microsoft's digital safety office.\n\"There's just untold potential.\"\nTIKTOK, META ADDRESS ONLINE HATE AT PITTSBURGH SUMMIT\nThe company is currently rolling out a content safety system as part of its OpenAI Service for Azure enterprise \ncustomers, Mr. Handeyside said. The service added ChatGPT capability in March.\nEventually, Mr. Handeyside said, AI could help the company \"mitigate risk ... in a global and nuanced way.\"\nEvan Robinson-Johnson: ejohnson@post-gazette.com\nGraphic\n \nPHOTO: Lucy Schaly/Post-Gazette photos: Mosaics done by artists from all over the world in the lobby during the \nEradicate Hate Global Summit 2023 at the David L. Lawrence Convention Center. Titled \"From Darkness Into \nLight,\" the works were inspired by the tragedy at the Tree of Life synagogue.\nPHOTO: Lucy Schaly/Post-Gazette: Alejandro N. Mayorkas, U.S. Department of Homeland Security secretary, \nspeaks Wednesday.\nLoad-Date: September 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "The Price of Bitcoin Mining and More: The Week in Reporter Reads",
        "media": "The New York Times",
        "time": "April 14, 2023",
        "section": "PODCASTS",
        "length": "913 words",
        "byline": " ",
        "story_text": "The Price of Bitcoin Mining and More: The Week in Reporter Reads\nThe New York Times \nApril 14, 2023 Friday 08:12 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 913 words\nHighlight: Five articles from around The Times, narrated just for you.\nBody\nFive articles from around The Times, narrated just for you.\nThis weekend, listen to a collection of articles from around The New York Times, read aloud by the reporters who \nwrote them.\nThe Real-World Costs of the Digital Race for Bitcoin\nWritten and narrated by Gabriel J.X. Dance\nWinter Storm Uri had knocked out power plants across Texas, leaving tens of thousands of homes in icy darkness. \nMeanwhile, in the husk of a onetime aluminum smelting plant an hour outside of Austin, row upon row of computers \nwere using enough electricity to power about 6,500 homes as they raced to earn Bitcoin, the world’s largest \ncryptocurrency.\nThe New York Times has identified 34 such large-scale operations, known as Bitcoin mines, in the United States, \nall putting immense pressure on the power grid and most finding novel ways to profit from doing so. Their \noperations can create costs — including higher electricity bills and enormous carbon pollution — for everyone \naround them, most of whom have nothing to do with Bitcoin.\nUntil June 2021, most Bitcoin mining was in China. Then it drove out Bitcoin operations, at least for a time, citing \ntheir power use among other reasons. The United States quickly became the industry’s global leader.\n◆ ◆ ◆\n‘Beef’ Review: Mad in America\nWritten and narrated by James Poniewozik\n“I’m so sick of smiling,” Danny Cho (Steven Yeun) says in the first episode of Netflix’s “Beef.” You may have noticed \nthat he’s not alone in this. Blame it on the pandemic, the culture, the economy, but people are mad right now, on \nplanes and on trains and — like Danny and his car-crossed antagonist, Amy Lau (Ali Wong) — in automobiles.\n“Beef,” a dark comedy about a road-rage incident that careers disastrously off-road, has good timing, but that’s not \nenough to make a great TV series. What makes this one of the most invigorating, surprising and insightful debuts of \nthe past year is how personally and culturally specific its study of anger is. Every unhappy person in it is unhappy in \na different and fascinating way.\n◆ ◆ ◆\nThe Price of Bitcoin Mining and More: The Week in Reporter Reads\nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nWritten by Nico Grant and Karen Weise | Narrated by Nico Grant\nIn March, two Google employees, whose jobs are to review the company’s artificial intelligence products, tried to \nstop Google from introducing an A.I. chatbot. They believed it generated inaccurate and dangerous statements.\nTen months earlier, similar concerns were raised at Microsoft by ethicists and other employees. They wrote in \nseveral documents that the A.I. technology behind a planned chatbot could flood Facebook groups with \ndisinformation, degrade critical thinking and erode the factual foundation of modern society.\nThe companies released their chatbots anyway. The aggressive moves by the normally risk-averse companies \nwere driven by a race to control what could be the tech industry’s next big thing — generative A.I., the powerful \nnew technology that fuels those chatbots.\n◆ ◆ ◆\nSuspicions Multiply as Nord Stream Sabotage Remains Unsolved\nWritten and narrated by Erika Solomon\nRussian and Danish naval vessels that disappear in the Baltic Sea, days before an underwater pipeline blast. A \nGerman charter yacht with traces of explosives, and a crew with forged passports. Blurry photographs of a \nmysterious object found near a single surviving pipeline strand.\nThese are the latest clues in the hunt to reveal who, last Sept. 26, blew up most of the Kremlin-backed Nord Stream \npipelines, some 260 feet below the Baltic Sea, that were once the largest supplier of Europe’s natural gas. A flurry \nof new findings and competing narratives has sown distrust among Western allies and presented an opening for \nRussian diplomatic pressure that has raised the geopolitical stakes in Europe’s Baltic region.\nNowhere is the tension felt more strongly than among the 98 residents of Denmark’s Christianso — an island so \ntiny, you can walk across it in 10 minutes. Living just 12 nautical miles away from the blast site, everyone from the \nherring pickler to the inn chef sees skies and waters filled with foreboding.\n◆ ◆ ◆\nMore Girls Are Being Diagnosed With Autism\nWritten and narrated by Azeen Ghorayshi\nMorénike Giwa Onaiwu was shocked when day care providers flagged some concerning behaviors in her daughter, \nLegacy. The toddler was not responding to her name. She avoided eye contact, didn’t talk much and liked playing \non her own.\nBut none of this seemed unusual to Dr. Onaiwu, a consultant and writer in Houston.\n“I didn’t recognize anything was amiss,” she said. “My daughter was just like me.”\nLegacy was diagnosed with autism in 2011, just before she turned 3. Months later, at the age of 31, Dr. Onaiwu \nwas diagnosed as well.\nAutism, a neurodevelopmental disorder characterized by social and communication difficulties as well as repetitive \nbehaviors, has long been associated with boys. But over the past decade, as more doctors, teachers and parents \nhave been on the lookout for early signs of the condition, the proportion of girls diagnosed with it has grown.\nThe Price of Bitcoin Mining and More: The Week in Reporter Reads\nThe Times’s narrated articles are made by Tally Abecassis, Parin Behrooz, Anna Diamond, Sarah Diamond, Jack \nD’Isidoro, Aaron Esposito, Dan Farrell, Elena Hecht, Adrienne Hurst, Emma Kehlbeck, Tanya Pérez, Krish \nSeenivasan, Kate Winslett, John Woo and Tiana Young. Special thanks to Sam Dolnick, Ryan Wegner, Julia Simon \nand Desiree Ibekwe.\nPHOTO: The Applied Digital Bitcoin mine in Jamestown, N.D. (PHOTOGRAPH BY Tim Wallace/The New York \nTimes  FOR THE NEW YORK TIMES)\nLoad-Date: April 14, 2023"
    },
    {
        "file_name": "their_books_Jul2023",
        "header": "Sarah Silverman and novelists sue ChatGPT-maker OpenAI for ingesting",
        "media": "their books",
        "time": "July 13, 2023",
        "section": "NATION WORLD",
        "length": "952 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Sarah Silverman and novelists sue ChatGPT-maker OpenAI for ingesting \ntheir books\nDayton Daily News (Ohio)\nJuly 12, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 952 words\nByline: MATT O'BRIEN\nBody\nAsk ChatGPT about comedian Sarah Silverman's memoir \"The Bedwetter\" and the artificial intelligence chatbot can \ncome up with a detailed synopsis of every part of the book.\nDoes that mean it effectively \"read\" and memorized a pirated copy? Or it scraped so many customer reviews and \nonline chatter about the bestseller or the musical it inspired that it passes for an expert? \nThe U.S. courts may now help sort that out after Silverman sued ChatGPT-maker OpenAI for copyright infringement \nthis week, joining a growing number of writers who say they unwittingly built the foundation for Silicon Valley's red-\nhot AI boom. \nSilverman's lawsuit says she never gave permission for OpenAI to ingest the digital version of her 2010 book to \ntrain its AI models, and it was likely stolen from a \"shadow library\" of pirated works. It says the memoir was copied \n\"without consent, without credit, and without compensation.\" \nIt's one of a mounting number of cases that could crack open the secrecy of OpenAI and its rivals about the \nvaluable data used to train increasingly widely used \"generative AI\" products that create new text, images and \nmusic. And it raises questions about the ethical and legal bedrock of tools that the McKinsey Global Institute \nprojects will add the equivalent of $2.6 trillion to $4.4 trillion to the global economy. \n\"This is an open, dirty secret of the whole machine learning industry,\" said Matthew Butterick, one of the lawyers \nrepresenting Silverman and other authors in seeking a class-action case. \"They love book data and they get it from \nthese illicit sites. We're kind of blowing the whistle on that whole practice.\" \nOpenAI declined to comment on the allegations. Another lawsuit from Silverman makes similar claims about an AI \nmodel built by Facebook and Instagram parent company Meta, which also declined comment. \nIt may be a tough case for writers to win, especially after Google's success in beating back legal challenges to its \nonline book library. The U.S. Supreme Court in 2016 let stand lower court rulings that rejected authors' claim that \nGoogle's digitizing of millions of books and showing small portions of them to the public amount to \"copyright \ninfringement on an epic scale.\" \n\"I think what OpenAI has done with books is awfully close to what Google was allowed to do with its Google Books \nproject and so will be legal,\" said Deven Desai, associate professor of law and ethics at the Georgia Institute of \nTechnology. \nSarah Silverman and novelists sue ChatGPT-maker OpenAI for ingesting their books\nWhile only a handful have sued, including Silverman and bestselling novelists Mona Awad and Paul Tremblay, \nconcerns about the tech industry's AI-building practices have gained traction in literary and artist communities. \nOther prominent authors  among them Nora Roberts, Margaret Atwood, Louise Erdrich and Jodi Picoult  signed a \nletter late last month to the CEOs of OpenAI, Google, Microsoft, Meta and other AI developers accusing them of \nexploitative practices in building chatbots that \"mimic and regurgitate\" their language, style and ideas. \n\"Millions of copyrighted books, articles, essays and poetry provide the 'food' for AI systems, endless meals for \nwhich there has been no bill,\" said the open letter organized by the Authors Guild and signed by more than 4,000 \nwriters. \"You're spending billions of dollars to develop AI technology. It is only fair that you compensate us for using \nour writings, without which AI would be banal and extremely limited.\" \nThe AI systems behind popular products such as ChatGPT, Google's Bard and Microsoft's Bing chatbot are known \nas large language models that have \"learned\" by analyzing and picking up patterns from a wide body of ingested \ntext. They've awed the public with their strong command of human language, though they're also known for a \ntendency to spout falsehoods. \nWhile the models have also been trained on news articles and social media feeds, books are particularly valuable, \nas OpenAI acknowledged in a 2018 paper cited in Silverman's lawsuit. \nThe earliest version of OpenAI's large language model, known as GPT-1, relied on a dataset compiled by university \nresearchers called the Toronto Book Corpus that included thousands of unpublished books, some in the adventure, \nfantasy and romance genres. \n\"Crucially, it contains long stretches of contiguous text, which allows the generative model to learn to condition on \nlong-range information,\" OpenAI researchers said at the time. Other tech companies such as Google and Amazon \nrelied on the same data, which is no longer available in its original form. \nBut since then, OpenAI and other top AI developers have grown more secretive about their sources of data, even \nas they have ingested larger troves of written works. Butterick said circumstantial evidence points to the use of so-\ncalled shadow libraries of pirated content that held the works of Silverman and other plaintiffs. \n\"It's important for their models because books are the best source of long-form, well-edited, coherent writing,\" he \nsaid. \"You basically can't have a high-quality language model unless you have books in your training data.\" \nIt could be weeks or months before a formal response is due from OpenAI. But once the case proceeds, tech \nexecutives could have to testify under oath about the sources of books they downloaded. \n\"As far as we know, the other side hasn't denied it,\" said Joseph Saveri, another of Silverman's lawyers. \"They don't \nhave an alternative explanation for this.\" \nSaveri said authors aren't necessarily asking tech companies to throw away their algorithms and training data and \nstart over  though the U.S. Federal Trade Commission has set a precedent for forcing companies to destroy ill-\ngotten AI data. But some way of compensating writers is needed, he said.\nGraphic\n \nFile - Sarah Silverman introduces a performance at the 75th annual Tony Awards on Sunday, June 12, 2022, in \nNew York. Silverman sued ChatGPT-maker OpenAI for copyright infringement this week, joining a growing number \nof writers who say they unwittingly built the foundation for Silicon Valley's red-hot AI boom. (Photo by Charles \nSykes/Invision/AP, File)\nSarah Silverman and novelists sue ChatGPT-maker OpenAI for ingesting their books\nLoad-Date: July 13, 2023"
    },
    {
        "file_name": "INTELLIGENCE_COULD_LEAD_TO_'HUMAN_FLOURISHING'_IF_USED_IN_Nov2023",
        "header": "EXPERT: AI NOT ALL BAD; DUKE LAW PROFESSOR SAYS ARTIFICIAL",
        "media": "INTELLIGENCE COULD LEAD TO 'HUMAN FLOURISHING' IF USED IN",
        "time": "November 10, 2023",
        "section": "BUSINESS; Pg. D-1",
        "length": "641 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "EXPERT: AI NOT ALL BAD; DUKE LAW PROFESSOR SAYS ARTIFICIAL \nINTELLIGENCE COULD LEAD TO 'HUMAN FLOURISHING' IF USED IN \nCONJUNCTION WITH EDUCATION\nPittsburgh Post-Gazette\nNovember 9, 2023 Thursday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. D-1\nLength: 641 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nIn a reprise of an April TED Talk where she warned about AI hacking human brains, Nita Farahany traveled to \nPittsburgh this week to lecture students and faculty at Carnegie Mellon University on the emerging technology's \npotential for help and harm.\nMs. Farahany, a Duke University law professor and bioethics adviser under former President Barack Obama, said \nChatGPT and other generative AI tools offer the government a chance to correct some of the regulatory failures it \nhas made with social media.\n\"This isn't our first encounter with AI,\" she said Monday, noting that Justin Rosenstein used computer intelligence to \nengineer Facebook's \"like\" button years before he realized the feature's potential to profoundly harm humanity. \nLikes were designed to spread joy, but Mr. Rosenstein and others now worry the potentially addictive feature is \nhurting self-esteem, distracting the masses and forever altering the human experience.\n(Wired used that example in 2022 to suggest that tech leaders can do more to avoid unintended consequences.)\nMeta is only just now facing lawsuits for addicting children to Facebook and Instagram while harming their self-\nesteem, Ms. Farahany said.\nChatGPT was adopted even faster with fewer safeguards.\n\"Given how revolutionary it is for humanity, imagine a technology like that being released with no prior testing, no \ndeliberative democracy, no oversight, no premarket clearance, very little discussion or even safety testing,\" she \nsaid.\nArtificial intelligence could make it easier for social media companies to exploit the human brain for profit, Ms. \nFarahany said. But it can also be used for good.\nAI-assisted work can reduce burnout and increase worker safety, she said, citing studies by Penn State University \nand Microsoft.\n\"We're entering into an age of partnership with technology,\" Ms. Farahany said. \"That's threatening for many \npeople, but it doesn't have to undermine human thinking, if we invest in the right way.\"\nEXPERT: AI NOT ALL BAD DUKE LAW PROFESSOR SAYS ARTIFICIAL INTELLIGENCE COULD LEAD TO \n'HUMAN FLOURISHING' IF USED IN CONJUNCTION WITH EDUCATION\nCMU's Block Center for Technology and Society expects to release a report this week on operationalizing AI across \nvarious business sectors.\nEven the controversial idea of computers building psychological profiles for humans isn't inherently harmful, Ms. \nFarahany said. Duolingo's AI-powered understanding of human learning helps people learn languages faster. \nPersonalized dieting software could similarly help people lose weight.\n\"I don't think addiction is necessarily in and of itself bad,\" she said.\nBut when the addiction overrides humans' ability to act in their own self-interest, then there's a problem.\nAI has already infiltrated daily life in ways that can be hard to detect. Ms. Farahany showed statistics that suggest \n77% of people are using an AI-powered device, but only 33% of people are aware they are.\nOne way to overcome the gap in understanding is through education. she said.\nIn Finland, public school children are learning how to discern between content that was manipulated with AI. That \nawareness could become more important as deepfakes infiltrate political races and pornography.\nHer strongest example of AI being used for good was in the early detection of seizures. By training computers on \nepilepsy data, researchers in Israel and Spain can now identify warning signs of a potential seizure before it occurs.\n\"This is the kind of insight where we're designing technology for human flourishing and we can imagine a really \ndifferent world,\" Ms. Farahany said.\nHer talk was part of CMU's fall lecture series. Duquesne University is hosting its annual tech ethics convention on \nFriday, focused on generative AI.\nGlobal leaders met in Britain last week to discuss the responsible development of AI. The summit came days after \nPresident Joe Biden signed an executive order demanding safety testing from AI developers and assigning federal \nagencies to oversee the explosive technology.\nGraphic\n \nPHOTO: Evan Robinson-Johnson/Post-Gazette: Duke University law professor Nita Farahany lectures Carnegie \nMellon University students and faculty on the risks and benefits of generative AI on Monday. She also was a \nbioethics adviser under former President Barack Obama.\nLoad-Date: November 10, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 21, 2023",
        "section": "STARTUPS & SPORTS",
        "length": "338 words",
        "byline": "Romita.Majumdar@timesgroup.com",
        "story_text": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts\nEconomic Times (E-Paper Edition)\nAugust 18, 2023 Friday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & SPORTS\nLength: 338 words\nByline: Romita.Majumdar@timesgroup.com\nHighlight: HOWEVER... Experts see creation of high-level jobs, involving more decision making, strategic calls\nBody\nMumbai:Artificial Intelligence (AI) will replace up to 5% FTE or full-time technology roles annually over the next 4-5 \nyears, said analysts.  However, while basic jobs are replaced with AI-based automation solutions, technology \nexperts expect a higher level of jobs to be created which will involve less support roles and more decision making \nand strategic roles. Roles in AI ethics and sustainability practices will also come in demand. \n Executives from leading automation companies like ServiceNow and UiPath see this change in job profiles \nevolving over the years as enterprises themselves figure out their AI strategy. Historically, whenever a \ngroundbreaking new technology is introduced in any sector, it just leads to a  lot more new work, ServiceNow CTO \nPat Casey told ET during an interaction in July. “If you look at the larger tech ecosystem, there is always a dearth of \nengineering talent. So, if certain jobs are automated, it will not mean that people will become jobless, just that they \nwork on more valueadded work elsewhere,” said Casey. According to a study by McKinsey Global Institute titled \nGenerative AI and the Future of Work in America, in June, an estimated 12 million occu-  pational transitions may \nbe required in the US alone by 2030. The maximum impact on productivity will be in the areas of marketing and \nsales. It will also have a significant impact on functions like customer operations, product development and software \ndevelopment.  Outsourcing expert Pareekh Jain estimates about 5% FTE roles annually to mature to newer roles as \nthey are replaced by AI tools.  “It will not be a massive shift over-  night. It is the support roles that do not require \nmuch decision-making capabilities where such changes will happen and they have already been in progress for \nyears,” said Jain. He added that there could be some nearterm impact on certain low-level jobs before companies \nfully assess the efficiency of such tools. But the longterm impact will be small. FOR FULL REPORT, GO TO \nwww.economictimes.com\nLoad-Date: August 21, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "Edtech’s AI Push has its Share of Doubting Thomases",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "516 words",
        "byline": "Jessica.Rajan@timesgroup.com",
        "story_text": "Edtech’s AI Push has its Share of Doubting Thomases\nEconomic Times (E-Paper Edition)\nFebruary 21, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 516 words\nByline: Jessica.Rajan@timesgroup.com\nHighlight: Higher education, upskilling platforms likely to benefit more than startups offering services to schools \nand students on a large scale\nBody\nNew Delhi: As edtech platforms move towards deploying artificial intelligence tools to enhance offerings, a clear \ndivide has emerged within various segments of the industry. While higher education and upskilling startups are \nanticipating greater benefits from the technology, those servicing schools and students on a large scale may run \ninto some headwinds, founders and executives at edtech companies told ET. Mumbai-based skilling and workforce \ndevelopment startup upGrad is looking to utilise AI to translate its popular bootcamps and certificate programmes \ninto vernacular languages to improve its product offerings and expand reach. \nIn the initial stage,  translations will be available in Hindi, Tamil, Telugu, Kannada and Bengali to serve the Indian \nmarket. Subsequently, the company plans to extend this to foreign languages such as Spanish and Chinese. Noida-\nbased edtech unicorn PhysicsWallah is also set to officially launch its generative AI tool, Alakh  AI, later this month. \nNamed after one of its cofounders, Alakh Pandey, it will serve as a personalised tutor for students, helping them \nwith queries, providing summaries, and acting as a“study companion”. “Most of the jobs are in tier-I markets, but \nroughly about 40-45% of our learners come from tier-II and  tier-III towns and cities. While they all want to give \ninterviews in English, for the learning purpose they do need a vernacular approach,” said upGrad cofounder and \nmanaging director Mayank Kumar.  upGrad offers online and hybrid degree courses, pathway and studyabroad \nprogrammes as well as certification and bootcamps, diploma, master’s and executive doctorate programmes for \nworking professionals. The firm said it records high demand from places like Bengaluru, New Delhi, Mumbai, \nHyderabad, Odisha, Pune, Chennai and Kolkata. According to Kumar, AI is a significant investment, not only for \nteaching and learning but also for pedagogy, sales and driving conversions. \"We will also leverage AI in various \nother initiatives at Upgrad…We are  also trying to bring AI into our approach for mock interviews,\" he added. \nAround 80% of Upgrad's business is from India. Kumar said the platform plans to target international markets such \nas the US, Europe and the Middle East from a business-tobusiness standpoint. Prateek Maheshwari, cofounder of \nPhysicsWallah, said: “With over 2 million daily active users, the method of having teachers or subject matter experts \nto directly address students' doubts and issues is not feasible. This approach is both high-cost and operationally \nintensive. To overcome this challenge, we have implemented GenAI to develop ‘Alakh AI’\". RESOURCE \nLIMITATIONS For startups in the edtech space  that offer services to schools, while AI presents a large opportunity, \nlack of enough resources at schools is a challenge. \"AI is still in a very early stage and is continuously \nevolving...any integration of technology as such presents a huge challenge. AI will require continuous upgrades and \ninvestments to ensure the tools don't become outdated,\" a senior executive at a unicorn edtech startup said.\nLoad-Date: February 20, 2024\nEdtech’s AI Push has its Share of Doubting Thomases"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Sprouts of Hope in a Gloomy Media Landscape",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "BUSINESS; media",
        "length": "1358 words",
        "byline": "Katie Robertson and Benjamin Mullin Katie Robertson covers the media industry for The Times. Email: ,",
        "story_text": "Sprouts of Hope in a Gloomy Media Landscape\nThe New York Times \nMarch 12, 2024 Tuesday 22:11 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1358 words\nByline: Katie Robertson and Benjamin Mullin Katie Robertson covers the media industry for The Times. Email: , \nkatie.robertson@nytimes.com,  Benjamin Mullin reports on the major companies behind news and entertainment. \nContact Ben securely on Signal at +1 530-961-3223 or email at , benjamin.mullin@nytimes.com\nHighlight: A handful of digital start-ups are finding success — so far, at least — by learning lessons from their \ntroubled predecessors.\nBody\nThis year is looking grim for the news business.\nFacing a set of harsh financial realities — resulting from a mix of news fatigue, an unsteady advertising market and \na precipitous fall in traffic from tech giants — many outlets have been forced to fold or make significant cuts in \nrecent months.\nBut there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success — at least for the moment — by taking the opposite approach of many \npredecessors, such as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize \ngrowth.\nThe new class of news start-ups — Puck, Punchbowl News, The Ankler and Semafor are among the most \nprominent — have kept spending down and hired carefully. They are all centered on newsletters covering specific \nniches with broad appeal. They have attracted top journalists by putting them at the heart of the enterprise, \nsometimes as part owners in the companies.\n“There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,” said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. “And I think that the entire industry has learned from that.”\nThese start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.\nBut traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn’t add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.\nThe formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.\nSprouts of Hope in a Gloomy Media Landscape\n“What all of them have in common is this intense need to serve specific audiences rather than to serve everybody,” \nsaid Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.\nSome of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.\nPunchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome “the hometown newspaper of Capitol Hill in a lot of ways,” said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.\n“What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,” she said.\nPunchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. Access \nto Punchbowl’s policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the low \nfive-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings from \nthose websites.\nMs. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl’s finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.\nThe Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood’s unsparing gadfly, narrating the industry’s unending chaos and skewering the \nactors, agents and executives responsible for creating it.\nAnkler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, said \nJanice Min, the company’s chief executive and founder, who previously helmed The Hollywood Reporter and Us \nWeekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a Hollywood \nnews digest.\n“If we want to make a Hollywood analogy, it’s like these growing franchises are multiverses,” Ms. Min said. “People \nlike what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.”\nSemafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.\nSemafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called for, \nMr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic outlook \nwas darkening.\n“The pandemic really marked the transition from the social media era to what we call the post-social media era,” Mr. \nSmith said, noting that outlets must now focus on direct relationships with their audience.\nFor Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.\nSprouts of Hope in a Gloomy Media Landscape\nThe company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.\nOf course, nothing in media lasts forever — particularly in the fast-changing digital world. So there’s no guarantee \nthat the early success of these companies will translate into sustained growth.\nMany of these start-ups are also taking a somewhat risky bet on talent.\nAt Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who is \na definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on Russian \npolitics, are “founding partners.” In addition to a salary, they receive bonuses based on the number of people who \nsubscribe to their email newsletters and how many of them stick around. New employees also get a small \nownership stake in the company.\nPuck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.\nIf one or more of the star journalists leave the publication, would Puck’s subscribers follow?\nMr. Kelly said he didn’t “want to even contemplate a world” in which one of Puck’s journalists exited.\n“We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,” Mr. Kelly said. “And I really think that our model is actually becoming one of the \nmoats of our business.”\nPHOTO: Punchbowl News has become “the hometown newspaper of Capitol Hill in a lot of ways,” its chief \nexecutive said. (PHOTOGRAPH BY CHIP SOMODEVILLA/GETTY IMAGES) (B3) This article appeared in print on \npage B1, B3.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "NOTICE;_VOTE_SET_FOR_THURSDAY_ON_WHAT_ACTION_TO_TAKE_Oct2023",
        "header": "ALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT",
        "media": "NOTICE; VOTE SET FOR THURSDAY ON WHAT ACTION TO TAKE",
        "time": "October 31, 2023",
        "section": "BUSINESS; Pg. A-12",
        "length": "743 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "ALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT \nNOTICE; VOTE SET FOR THURSDAY ON WHAT ACTION TO TAKE\nPittsburgh Post-Gazette\nOctober 31, 2023 Tuesday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-12\nLength: 743 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nUnionized Allegheny General Hospital nurses are scheduled to vote Thursday on whether to continue negotiating \nfor a new labor agreement or issue a 10-day notice of a walkout.\nThe vote turns up the heat on contract talks for some 1,200 registered nurses who are members of SEIU \nHealthcare Pennsylvania. A three-year contract for the nurses expired Oct. 13 and the nurses on Oct. 18 authorized \ntheir bargaining committee to call a strike as talks continued.\nA strike would be a first at the Allegheny Health Network hospital, the flagship institution in a 14-hospital system. \nThe vote will follow multiple labor rallies in Pittsburgh since June that have drawn wide support from Democratic \nelected officials, from Mayor Ed Gainey to members of the state General Assembly. Whether the union can turn that \nsupport into contract gains - which include a demand for a 31% increase in the starting wage for new nurses to $40 \nan hour - is yet to be seen.\nThe challenge for AHN corporate parent Highmark Inc. will be to restrain rising costs at a time of flat reimbursement \nfrom government and other health insurers, while attracting and retaining talent when there are not enough nurses \nin the job market to fill openings. Virtually every hospital in the U.S., including those in AHN, has had to use high-\ncost temporary staffing nurses to fill shifts.\nSEIU officials were not available for comment Monday; AHN spokesman Dan Laurent said only that talks were \ncontinuing.\nInformation about the bargaining was provided by two people familiar with the negotiations but who were not \nauthorized to discuss them publicly.\nThe labor tensions are rising at Allegheny General even as the hospital makes plans to lighten the administrative \nworkload of nurses and doctors.\nFor AGH nurses, entering medical information into the hospital's electronic health record systems eats up fully half \nof the workday, according to an internal time study, and that leads to frustration and job discontent, said Ashis \nBarad, AHN chief digital officer.\n\"Why do we have our nursing staff doing data entry?\" Dr. Barad said. \"There is a world where we give back almost \n50% of their time.\"\nALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT NOTICE VOTE SET FOR \nTHURSDAY ON WHAT ACTION TO TAKE\nIn recent weeks, enhancements to the hospital's Epic Systems medical recordkeeping system have made it faster \nfor nurses to enter information by automatically populating fields for the regular patient assessments that nurses \nperform.\nAnd in January, AHN Forbes Hospital in Monroeville will begin piloting a 47-bed telehealth feature that will allow a \nnurse in Allegheny Center to greet newly admitted patients and give discharge instructions to patients who are \ngoing home, allowing hospital nurses to increase their time caring for patients.\nWithin two years, the digital nurse will be rolled out to every AHN hospital.\n\"You want to be able to focus directly on your patients and not be taken away for administrative tasks,\" said Rachel \nUrosek, a registered nurse for 10 years and director of clinical information and digital health at AHN. \"Nurses want \nto spend time with their patients and do what's best for their patients.\"\nFor doctors, the administrative burden is not much lighter than for nurses: For every hour doctors spend with a \npatient, they spend another two hours with documentation, according to the American Medical Association's \npresident, Jesse M. Ehrenfeld.\n\"There is an insidious crisis going on in medicine today that is having a profound impact on our ability to care for \npatients and yet isn't receiving the attention it deserves,\" Dr. Ehrenfeld said during a speech Wednesday in \nWashington, D.C. \"This crisis is physician burnout.\"\nReducing the chore of medical documentation is among the top priorities for Highmark's new Google software \nplatform, which is called Vertex Search AI, according to Richard Clark, chief analytics officer at Highmark.\nAmong potential uses of the generative artificial intelligence platform in the doctor's office is ambient listening, \nwhich would provide input on treatment decisions based on massive searches of medical records and health \ninformation - in real time.\nGenerative AI in medicine, which is being tested at AHN, has been compared to the advent of penicillin, but much \nwork needs to be done before it's routinely used in clinical practice, ensuring that AI answers are sound, Dr. Barad \nsaid.\n\"Oh my god, this is huge, I want to go fast. But we have to do it responsibly,\" he said. \"The art of what's possible is \nway further ahead of how do we do this responsibly.\"\nGraphic\n \nPHOTO: Tim Robbibaro/For the Post-Gazette: Unionized nurses at Allegheny General Hospital on the North Side \nare set to vote Thursday on whether to issue a walkout notice or continue to negotiate in an effort to reach a new \nlabor agreement.\nPHOTO: Sebastian Foltz/Post-Gazette: Allegheny Health Network physical therapist Lauren Wilkerson updates a \npatient file at West Penn Hospital in Bloomfield.\nLoad-Date: October 31, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2024",
        "header": "Sprouts of Hope in a Gloomy Media Landscape",
        "media": "The New York Times - International Edition",
        "time": "March 13, 2024",
        "section": "BUSINESS",
        "length": "1378 words",
        "byline": "Katie Robertson and Benjamin Mullin",
        "story_text": "Sprouts of Hope in a Gloomy Media Landscape\nThe New York Times - International Edition\nMarch 14, 2024 Thursday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1378 words\nByline: Katie Robertson and Benjamin Mullin\nBody\nABSTRACT\nA handful of digital start-ups are finding success - so far, at least - by learning lessons from their troubled \npredecessors.\nFULL TEXT\nThis year is looking grim for the news business.       \nFacing a set of harsh financial realities - resulting from a mix of news fatigue, an unsteady advertising market and a \nprecipitous fall in traffic from tech giants - many outlets have been forced to fold or make significant cuts in recent \nmonths.       \nBut there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success - at least for the moment - by taking the opposite approach of many predecessors, \nsuch as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize growth.       \nThe new class of news start-ups - Puck, Punchbowl News, The Ankler and Semafor are among the most prominent \n- have kept spending down and hired carefully. They are all centered on newsletters covering specific niches with \nbroad appeal. They have attracted top journalists by putting them at the heart of the enterprise, sometimes as part \nowners in the companies.       \n\"There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,\" said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. \"And I think that the entire industry has learned from that.\"       \nThese start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.       \nBut traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn't add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.       \nThe formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nSprouts of Hope in a Gloomy Media Landscape\nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.       \n\"What all of them have in common is this intense need to serve specific audiences rather than to serve everybody,\" \nsaid Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.       \nSome of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.       \nPunchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome \"the hometown newspaper of Capitol Hill in a lot of ways,\" said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.       \n\"What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,\" she said.       \nPunchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. Access \nto Punchbowl's policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the low \nfive-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings from \nthose websites.       \nMs. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl's finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.       \nThe Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood's unsparing gadfly, narrating the industry's unending chaos and skewering the \nactors, agents and executives responsible for creating it.       \nAnkler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, said \nJanice Min, the company's chief executive and founder, who previously helmed The Hollywood Reporter and Us \nWeekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a Hollywood \nnews digest.       \n\"If we want to make a Hollywood analogy, it's like these growing franchises are multiverses,\" Ms. Min said. \"People \nlike what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.\"       \nSemafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.       \nSemafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called for, \nMr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic outlook \nwas darkening.       \n\"The pandemic really marked the transition from the social media era to what we call the post-social media era,\" Mr. \nSmith said, noting that outlets must now focus on direct relationships with their audience.       \nFor Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.       \nSprouts of Hope in a Gloomy Media Landscape\nThe company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.       \nOf course, nothing in media lasts forever - particularly in the fast-changing digital world. So there's no guarantee \nthat the early success of these companies will translate into sustained growth.       \nMany of these start-ups are also taking a somewhat risky bet on talent.       \nAt Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who is \na definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on Russian \npolitics, are \"founding partners.\" In addition to a salary, they receive bonuses based on the number of people who \nsubscribe to their email newsletters and how many of them stick around. New employees also get a small \nownership stake in the company.       \nPuck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.       \nIf one or more of the star journalists leave the publication, would Puck's subscribers follow?       \nMr. Kelly said he didn't \"want to even contemplate a world\" in which one of Puck's journalists exited.       \n\"We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,\" Mr. Kelly said. \"And I really think that our model is actually becoming one of the \nmoats of our business.\" \nLoad-Date: March 13, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "China AI Model Gives Silicon Valley LLMs a Run for Their Money",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 7, 2023",
        "section": "STARTUPS & TECH",
        "length": "429 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "China AI Model Gives Silicon Valley LLMs a Run for Their Money\nEconomic Times (E-Paper Edition)\nNovember 8, 2023 Wednesday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 429 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: China-based AI startup’s large language model is said to outperform US models on key metrics\nBody\nNew Delhi: Nearly a year after OpenAI’s ChatGPT made waves, leading to an artificial intelligence (AI) race among \nthe world’s tech giants, notably Microsoft, Meta and Google parent Alphabet, a China-based AI startup is giving \nSilicon Valley a run for its money. The company, called 01.AI, has attained unicorn status—a valuation of $1 \nbillion—less than eight months since its inception. It has released its new large language model (LLM), which is \nsaid to outperform Silicon Valley models on key metrics. \nAn LLM is a computer algorithm trained on massive datasets to understand and process natural language. It is what \nis required for generative AI (genAI) platforms like ChatGPT. WHAT IS 01.AI’S NEW LLM? 01.AI has been \ncreating a buzz this week with the release of its new LLM, Yi-34B. The model was trained on 34 billion \nparameters—hence the ‘34B’ in its name. Parameters are the weights of inputs a model learns to predict what \ncomes next in a sequence. Founded in March this year by Taiwanese computer scientist and venture capitalist Kai-\nFu Lee, 0.1AI has released Yi-34B as an open-source model, now available to developers in Chinese and English. \nLee weighed in on X (formerly Twitter), calling Yi-34B ‘the world’s top open-source model’. “01.AI is a bold but long-\nawaited endeavour for my pursuit of AI over 4 decades. Proud to introduce the world's top open-source model Yi-\n34B as our first release to the developers' community encouraging fantastic LLM projects with a moderate-size, \nhigh-performing base model,” he said.  HOW DOES YI-34B MEASURE UP AGAINST SILICON VALLEY LLMS? Yi-\n34B ranked first in a leaderboard of pre-trained base LLMs in open-source developer community platform Hugging \nFace, which evaluates how LLMs across various categories perform. The model is said to beat models like Meta’s \nLlama 2, which Lee sees as a ‘gold standard’, on key metrics. This is despite the fact that the model is much \nsmaller than the likes of Falcon-180B and Meta LlaMa2-70B. Lee sees this as significant and has said the aim is to \nprovide a superior alternative not just for the Chinese market but for the world. WHO’S BEHIND 01.AI? Lee wears \nthe CEO hat for both 01.AI as well as Sinovation Ventures. He earlier worked at Google, Microsoft, and Apple, and \nis considered an AI pioneer, having authored two books on the subject. As a venture capitalist, he has backed 10 \nunicorns. The 100-strong team at 01.AI includes former employees from US and Chinese tech majors, as well as \nChinese nationals who have worked abroad.  FOR FULL REPORT, GO TO www.economictimes.com\nLoad-Date: November 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Actors Vote to Authorize Strike, While Writers Continue Picketing",
        "media": "The New York Times",
        "time": "June 7, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "462 words",
        "byline": "By Nicole Sperling",
        "story_text": "Actors Vote to Authorize Strike, While Writers Continue Picketing\nThe New York Times\nJune 7, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 462 words\nByline: By Nicole Sperling\nBody\nThe News \n  The union that represents more than 160,000 film and television actors voted on Monday night to authorize a \nstrike, two days before it is to begin negotiations on a new labor deal with the Hollywood studios. The result from \nmembers of the SAG-AFTRA union, with 98 percent authorizing a strike, was expected, and it came during the sixth \nweek of a strike by Hollywood writers and just a day after the Directors Guild of America tentatively agreed to a new \ncontract.\n  ''Together we lock elbows, and in unity we build a new contract that honors our contributions in this remarkable \nindustry, reflects the new digital and streaming business model and brings ALL our concerns for protections and \nbenefits into the now!'' Fran Drescher, the president of the actors' union, said in a statement.\n  About 65,000 members cast ballots, or 48 percent of eligible voters. The actors' current agreement with the \nAlliance of Motion Picture and Television Producers, which bargains on behalf of the studios, expires on June 30.\n  Why It Matters: The actors have the same worries as the writers.\n  Many of the actors' concerns echo what the Writers Guild of America is fighting for: higher wages; increased \nresidual payments for their work, specifically for content on streaming services; and protections against using \nactors' likenesses without permission as part of the enhanced abilities of artificial intelligence. According to the \nwriters, the studios offered little more than ''annual meetings to discuss'' artificial intelligence, and they refused to \nbargain over limits on the technology.\n  The Directors Guild, in contrast, said on Sunday that it had reached a ''groundbreaking agreement confirming that \nA.I. is not a person and that generative A.I. cannot replace the duties performed by members.'' Details about what \nthat meant were not revealed.\n  Background: It has been a long time since the last actors' strike.\n  The last time the actors went on strike was in 2000, in a dispute over commercial pay. The strike lasted close to \nsix months.\n  What's Next: Negotiations begin on Wednesday.\n  With negotiations expected to begin on Wednesday, SAG-AFTRA is bullish about what this strike authorization \nmeans. ''We're obviously coming in from a position of strength, but we're not looking to strike,'' said Duncan \nActors Vote to Authorize Strike, While Writers Continue Picketing\nCrabtree-Ireland, the union's chief negotiator. ''We're here to make a deal.'' He added: ''But we're also not going to \naccept anything less than what our members deserve. If a strike is necessary to achieve that, we're prepared.''\n  The Alliance of Motion Picture and Television Producers said in a statement that ''we are approaching these \nnegotiations with the goal of achieving a new agreement that is beneficial to SAG-AFTRA members and the \nindustry overall.''\nhttps://www.nytimes.com/2023/06/05/business/media/hollywood-actors-strike-vote.html\nGraphic\n \nPHOTO: Members of SAG-AFTRA supported the striking Writers Guild of America at a rally last month outside \nWarner Bros. Studios in Burbank, Calif. (PHOTOGRAPH BY CHRIS PIZZELLO/ASSOCIATED PRESS) This article \nappeared in print on page B4.               \nLoad-Date: June 7, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "INDIA’S RICH TECH TALENT POOLS A BIG WIN-WIN",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 23, 2023",
        "section": "FEATURE",
        "length": "598 words",
        "byline": "Pallavi Chakravorty",
        "story_text": "INDIA’S RICH TECH TALENT POOLS A BIG WIN-WIN\nEconomic Times (E-Paper Edition)\nNovember 24, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FEATURE\nLength: 598 words\nByline: Pallavi Chakravorty\nHighlight: Strong ideas, wide variety of sectors, and a supportive ecosystem are the biggest drivers for the \ncountry’s thriving startups\nBody\nOver the past two decades, the word startup has become synonymous with India, which today with over 90,000 \nstartups and 107 unicorn companies. It is ranked third among the largest startup ecosystems in the world just after \nthe US and China.  While there has been a drop in funding this year with none of the companies achieving unicorn \nstatus – in 2022, India produced 24 unicorns, the momentum in tier II and tier III cities is fuelling the growth in the \nsector.  One of the key factors behind India’s startup revolution is its young demography – more than 50 percent of \nits population is below the age of 25 and more than 65 percent below the age of 35.  That the country is rich in tech \ntalent only fuels the market further. \nAccording to a report by consulting fi rm EY and skill assessment platform iMocha, India is one of the  top tech \ntalent markets at par with Europe and the US. Also, apart from strong government support, India’s startup \necosystem is also backed by a growing network of incubators, accelerators, and co-working spaces. In fact, India is \nalso home to one of the 25 Draper Startup Houses in the world. It was obvious that the team of Meet the Drapers, \nSeason 6 had to make a stopover to the subcontinent and identify bright entrepreneurs. The contenders Orthoheal, \nUnstop, Neuropixel.ai, and Karya Foundation, while being completely different from each other had a unique \nsolution to present. The judges -Tim Draper, Founder, Draper Associates; Nupur Hemant, Venture Capitalist in \nConsumer Tech, B2B and SaaS; Nikhil Kamath, Content Strategist Building Brands; and Madan Padaki, CEO & \nMD, Head Held  High -not only were overwhelmed hearing the pitches, but they also had a tough time picking just \none winner.  Orthoheal’s FlexiOH -an orthopaedic immobilizer that has the rigidity to hold the fractured part as well \nas ensure proper skin ventilation – did impress the judges but they were concerned about similar technologies \nexisting in the market and the long-term potential of the company.  With the promise of getting students their dream \njob, Unstop -a community engagement and hiring platform for students and freshers – connects students to a world \nof opportunities across the globe. It helps companies interact with students and early professionals at Unstop and \nleverage the  platform’s expertise to build their teams. Judges were not sure about the growth of the market, which \nlooked like flattening out.  The third company in the run for the million-dollar prize money, Karya, works with rural \ncommunities in India -traditionally kept out of the digital work economy – by giving them small digital tasks. It \ncollects the requirements from its clients, identifi es the bestsuited workers, collects the data, validates the data, \nand then synthesises them into highquality AI/ML training datasets. Judges were concerned about Karya’s big \ncompany clients engaging with them only for public relations.  The winner, NeuroPixel.AI, is a generative AI startup \nfocused on the fashion industry. It deploys proprietary Deep Neural Net (DNN) algorithms that generate \nphotorealistic synthetic models and automates the manual and repetitive process of cataloguing apparel. \nCustomers can shoot apparel on a mannequin and upload it on the real-time SaaS platform. One can then select \nthe clothes, customise models, and change their facial expression, hairstyle, or skin colour. The company claims to \nINDIA ’S RICH TECH TALENT POOLS A BIG WIN-WIN\nreduce costs for its clients by 30-40 percent. Judges were impressed by the app’s use case, big market and it is \nhelping reduce inefficiencies in the cataloguing business.\nLoad-Date: November 23, 2023"
    },
    {
        "file_name": "New_York_Observer_Jan2023",
        "header": "A Writer Used AI to Plagiarize Me. Now What?",
        "media": "New York Observer",
        "time": "January 17, 2023",
        "section": "",
        "length": "769 words",
        "byline": "Alex Kantrowitz",
        "story_text": "A Writer Used AI to Plagiarize Me. Now What?\nNew York Observer\nJanuary 17, 2023 Tuesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 769 words\nByline: Alex Kantrowitz\nBody\nThis story is syndicated from the Substack newsletter Big Technology; subscribe for free here.\nRecently, a new Substack called The Rationalist lifted analysis and writing directly from Big Technology. Its \nplagiarized post on the 'Creator Economy'-which we'd covered days prior-went viral, hitting the front page of Hacker \nNews and sparking a conversation with more than 80 comments. It would've been a terrific debut for any \npublication, if it was authentic.\nWhat made the case of The Rationalist particularly striking, though, was its author-an avatar by the name of \n\"PETRA\"-admitted they'd used AI tools to produce the story, including those from OpenAI, Jasper, and Hugging \nFace. The speed at which they were able to copy, remix, publish, and distribute their inauthentic story was \nimpressive. It outpaced the platforms' ability, and perhaps willingness, to stop it, signaling Generative AI's darker \nside will be difficult to tame.\n\"It's really hard to predict all the maleficent uses,\" said Giada Pistilli, principal ethicist at Hugging Face. \"We try to \nanticipate all the risks, but it's always super hard.\"\nThe Rationalist is an odd publication. It has no mission. No named authors outside of PETRA. It's been live for a \nweek. And yet two days after it went live, it was lifting passages directly from Big Technology.\nHere, for instance, is a Big Technology clause from last week's story:\nWith the days of zero-interest-rate froth ending, the investments are becoming more difficult to justify.\nAnd here's The Rationalist, two days later:\nWith the end of zero-interest-rate froth, these investments are becoming more difficult to justify.\nHere's another clause from Big Technology:\nOnline content creation is still mostly viable for the very top echelon of online creators\nAnd here again The Rationalist, two days later:\nOnly the top echelon of creators are able to make a viable income\nA flashy headline-\"The creator economy: the top 1% and everyone else\"-helped propel The Rationalist's story to the \nHacker News front page, a position typically worth thousands of views. The core of the story, lifted from Big \nTechnology, was good enough to spark a discussion.\nYet as Hacker News users read through, they noticed something was off. \"The whole article feels to me like it's \ngenerated by GPT-3 based on a few prompts,\" wrote one user. \"This wasn't written by a person,\" said another. \nThen, Petra confessed. \"If you are from hacker news, here are the tools I used to improve the readability,\" they said \nbefore listing OpenAI, Jasper, and Hugging Face. The tools enable AI writing and likely helped remix the original \nA Writer Used AI to Plagiarize Me. Now What?\narticle. PETRA, who did not respond to a request for comment, didn't mention the content originated with another \npublication.\nAs the story circulated, the tech platforms assisting The Rationalist stood still. OpenAI shared a generic statement \nthat included the line, 'Our policies require that users be up-front with their audience.\" Hugging Face admitted it had \nno way of finding the offending user, though Pistilli seemed grateful to be alerted. And Substack promised to \ninvestigate.\nSubstack said it has a policy against plagiarism, which Merriam-Webster defines as \"to steal and pass off (the ideas \nor words of another) as one's own.\" Yet while this case fits the definition, Substack decided to let The Rationalist's \npost stand. \"At this time we're unable to conclude with certainty that the post violates our plagiarism policy,\" said \nSubstack spokesperson Helen Tobin.\nGiven The Rationalist's success, more advanced efforts to copy and remix others' work with AI will likely take place. \nAnd it should be easy to improve. The Rationalist was sloppy, lifting clauses word for word. But as publications with \nsimilar intent refine their systems, they'll be able to remove all traces of the original writing and just pass along the \nideas. And it shouldn't be hard to automate either.\nImagine AI remixing the Financial Times' ten most-read stories of the day-or The Information's VC coverage-and \nmaking the reporting available sans paywall. AI is already writing non-plagiarized stories for publications like CNET. \nAt a certain point, some publishers will cut corners.\nThere's no quick technological fix to these issues. As has been the case for nearly all instances of bad information \nspreading online, readers and editors will again have to figure this out themselves. \"Our competitors rip us off all the \ntime, essentially remixing stuff and sharing,\" said The Information CEO Jessica Lessin. \"The Information \nsubscribers are smart to get it from the source. But I am watching all this with fascination of course.\"\nLoad-Date: January 17, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Richard Rodgers and ChatGPT? Well, Not Quite.",
        "media": "The New York Times",
        "time": "November 2, 2023",
        "section": "Section C; Column 0; The Arts/Cultural Desk; Pg. 5",
        "length": "635 words",
        "byline": "By Naveen Kumar",
        "story_text": "Richard Rodgers and ChatGPT? Well, Not Quite.\nThe New York Times\nNovember 2, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section C; Column 0; The Arts/Cultural Desk; Pg. 5\nLength: 635 words\nByline: By Naveen Kumar\nBody\nEach performance culminates in a production, composed on the spot, with misguided help from artificial \nintelligence.\nArtificial intelligence can paint meddlesome monkeys, speak in the basso profundo of James Earl Jones and play a \ntune to suit a hall of mirrors. But it can't write a musical that doesn't feel canned (at least, not yet). That's the \nargument put forward by ''Artificial Flavors,'' a live demonstration of A.I.'s creative capabilities -- and tedious \nlimitations -- at 59E59 Theaters. \n  The writer and director Steve Cosson, the artistic director of the restlessly curious company the Civilians, here \nassumes the role of a somewhat befuddled narrator, explaining that this project was born from his late-night \ntinkering with programs like ChatGPT. Cosson, who says he is not a performer, at times doesn't seem to know \nwhere to stand or what to say next. Whether or not it's an act (and I suspect that it is), Cosson's apparent insecurity \nprovides a stark contrast to the technology he is investigating.\n  Cosson solicits Mad Libs-style audience input to show that generative A.I. merely needs prompting and a few \nseconds to spit out an unconvincing Picasso or write vaguely in the voice of Stephen King, examples projected on a \nscreen. Six actors then step in to perform A.I.-generated skits, including a scene between socialist comrades \nquibbling over a Birkin bag on the night I attended. Cosson promises that each performance of ''Artificial Flavors'' \nwill culminate in a brand-new musical, with text written by ChatGPT and melodies composed on the spot by the \nCivilians and the onstage music director Dan Lipton.\n  The problem is that every example of A.I.-generated content proceeding it portends how bad that musical will be. \nThat seems to be Cosson's point, though it becomes tiresome as his experiment balloons to 90 minutes. What \nscant humor A.I. produces here is inadvertent and its metaphors are clichéd. (''We're more than gears, circuits and \nwires,'' one early sample lyric goes, ''We are the spark igniting untamed fires.'')\n  There is ingenuity in the varying parameters for a musical that Cosson feeds into ChatGPT, including conflict, \nsetting and structure (for example, a pie-eating contest at a beachside resort). But by Cosson's design, A.I. is \nsquarely to blame for the resulting artistic failure. The cast does impressive impromptu work, singing on the fly and \nreading live text from hand-held tablets. Michael Castillejos and Trey Lyford add lo-fi percussion to Lipton's \nelectronic keyboard, while Heath Saunders appears to lead the ensemble's unpolished vocals. But the songs and \ndialogue, though generated anew each night, are no doubt consistently inane.\n  Theater artists are wrestling, like many others, with the rapidly expanding power of A.I. and its implications on the \nform. In ''Prometheus Firebringer'' earlier this fall, the creator Annie Dorsen delivered an incisive lecture about \nhuman obedience to technology alongside a haunting but prosaic illustration of its current capacities. Cosson, who \nRichard Rodgers and ChatGPT? Well, Not Quite.\nsays that A.I. and theater are both ''in the business of making fake life,'' delivers something closer to A.I. 101 before \nreveling at how inept it is at doing his job.\n  He may be tipping the scale with this anodyne, presentational staging (the office set, reminiscent of the Sims, is by \nthe studio casaboyce) and by using the technology only to generate text, when it's also capable of more complex \nmusical compositions and voice imitation. Still, his point stands: A.I. is proficient at producing ''fake life,'' but without \nan artist's subjectivity or point of view. Unfortunately for the audience, witnessing the boundaries of innovation \ncomes with few rewards.\n  Artificial FlavorsThrough Nov. 19 at 59E59 Theaters, Manhattan; 59e59.org. Running time: 1 hour 30 minutes.\nhttps://www.nytimes.com/2023/10/31/theater/artificial-flavors-review.html\nGraphic\n \nPHOTO: From left, Aysan Celik, Heath Saunders, Colleen Werthmann, Michael Castillejos, Trey Lyford and \nJennifer Morris in ''Artificial Flavors.'' (PHOTOGRAPH BY RICHARD TERMINE) This article appeared in print on \npage C5.               \nLoad-Date: November 2, 2023"
    },
    {
        "file_name": "ideation_Aug2023",
        "header": "Identity theft takes a massive toll on victims lives, may even lead to suicidal",
        "media": "ideation",
        "time": "August 30, 2023",
        "section": "",
        "length": "1268 words",
        "byline": "Betty Lin-Fisher, USA TODAY NETWORK",
        "story_text": "Identity theft takes a massive toll on victims lives, may even lead to suicidal \nideation\nUSA Today Online\nAugust 30, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 1268 words\nByline: Betty Lin-Fisher, USA TODAY NETWORK\nBody\nI have written a lot over the years about how to protect your identity to avoid becoming a victim of identity theft. But \nthe fact of the matter is we can do everything to protect our identities and still become victims. The toll it takes on a \nperson’s life − financially and emotionally − is huge.\nA new consumer impact report from a national nonprofit that specializes in helping identity theft victims has found a \nstartling trend: An increasing number of ID theft victims are reporting thoughts of suicide resulting from the crime.\nSan Diego-based Identity Theft Resource Center said 16% of ID theft victims who contacted the organization \nreported thoughts of suicide in its 2023 Consumer Impact Report.\nThat’s up from 10% in 2022, which was the previous all-time high for the center.\nPeople can become victims of ID theft when their personal information, such as their Social Security number or \nbank account numbers, are stolen in a data breach as a result of a scam in which victims are duped into sharing \ntheir information or a myriad of other ways.\nHow do victims of identity theft feel?\nVictims reported feelings of shame and guilt and the loss of trust and security.\nHere's what some Identity Theft Resource Center victims shared:\n“I isolated myself from everyone and still do because I can’t make ends meet, can’t get help or assistance, and I \nfeel like an idiot.”\n“I am worried about being on social media, of making social media posts, or about people finding the untrue content \nonline.”\nLink to Image\nWhat should be done for victims of identity theft?\n“The fact that 16% of identity crime victims thought it’s easier to end their life than try to recover from an identity \ncrime says as much about the lack of concern and support for identity crime victims as it does the victims \nthemselves,\" said Eva Velasquez, president and CEO of the Identity Theft Resource Center, in a press release \nabout the report. \"We need to fundamentally change the way we support identity crime victims to ensure no one \nfeels ignored or dismissed the way they do today.”\nLink to Image\nIdentity theft takes a massive toll on victims lives, may even lead to suicidal ideation\nThe report was released last week.  \nVelasquez said the number of identity theft victims who say they have considered suicide has been increasing \nsteadily after nearly two decades in the 2% to 4% range. But in 2020, during the coronavirus pandemic, the ID Theft \nCenter saw the number of suicidal victims jump to 8% and 10% in 2021. \nTo put it in perspective, Velasquez said, the overall suicide rate in the general population also grew to about 5%, \nincluding 3% in 2022. \nThe ID Theft Center report reflects responses from victims who contacted the organization in 2022 and from an \nonline survey of more than 1,000 general consumers, some of whom self-identified as being victims of ID theft in \nthe previous 12 months.\nLink to Image\nThe report was supported by Experian, one of the three national credit reporting agencies.\n“Technology can be our friend and foe when it comes to identity theft,” said Mike Bruemmer, vice president of global \ndata breach resolution for Experian. “Scammers are relentless and their success can be devastating.”\nThe fact that the number of ID theft victims considering self-harm increased during the pandemic was no surprise, \nVelasquez said, “but the fact the rate has continued to climb is. And, the trend begs the question − why?\"\nVelasquez said there is no definitive answer, “but we can hazard some educated guesses based on our research \nand our daily contact with victims every day for more than 20 years,” she wrote in the report.\nThose include:\n• The rise of sophisticated social engineering scams. Phishing, business email compromise and social \nmedia account takeover, to name a few, are likely contributors to victims' stress. \n“Once laughably bad spoofed websites, texts and emails are now letter-perfect and have been joined by highly \nsophisticated voice mail and direct contact attacks,\" she said. \"This is before we’ve seen generative AI (artificial \nintelligence) deployed at scale which will also make it more difficult to spot phishing and other social engineering \nattacks.”\n• An increase in very large dollar losses because of social engineering in various identity scams. For the \nfirst time, the organization said it is consistently seeing six-figure losses in romance and social media \nscams, often involving cryptocurrency or other investment schemes. \n“Everyone is vulnerable under the right set of circumstances, yet the discussion around identity crime victimization \nis either dismissive, judgmental or both,” she said. “The language used when talking with victims and when talking \nabout victims, particularly by the media and many cyber experts, can create more shame and embarrassment.\"\nVelasquez said victims lack needed resources. \n“Too many victims are shunned by organizations that should support them and ignored by government agencies \nthat are too short-staffed or ill-equipped to help them,” she said.\nConsumers and victims of identity crimes and compromises can get free support and guidance from the ID Theft \nResource Center at 888-400-5530, by visiting idtheftcenter.org or via live chat. If you have thoughts of self-harm or \nsuicide, you can call or text the National Suicide Prevention Lifeline at 988 or chat at https:/988lifeline.org for crisis \nsupport.  \nHow to protect yourself from identity theft\nThe Identity Theft Resource Center offers these ways to protect you and your family: \nIdentity theft takes a massive toll on victims lives, may even lead to suicidal ideation\n• Keep only necessary cards and documents with you or in your car. Store them somewhere secure, like a safe \nor lockbox, when you don’t need them.\n• Use a cross-cut shredder to dispose of documents with personally identifiable information.\n• Consider using a digital wallet for all of your payment and identity cards. It is the safest way to pay, other than \ncash.\n• Lock all of your electronic devices with a passcode, passphrase or biometric lock. Also, turn off lock screen \nnotifications.\n• Use a unique username and passphrase (12+ characters long) for all of your online accounts.\n• Make sure your browser is secure.\n• Do not give out your personal or financial information through social media platforms, text or email, especially \nwhen you have not verified the requestor’s authenticity.\n• Avoid public Wi-Fi unless you can use a Virtual Private Network (VPN).\n• Make sure your social media profiles are set to private; avoid posting anything publicly.\n• Review companies’ privacy policies to understand how your data will be used, stored and protected. Ask what \ninformation they have to hold and what can be deleted.\n• Use multi-factor authentication with an authenticator app, if possible. Text messages and phone calls with \nauthorization codes can be spoofed.\n• Do not click on unexpected pop-ups in your browser or on your device. Also, don’t click on any links in \nunknown emails, texts or social media posts. Instead, go straight to the source when verifying an email, \ntext or social media post.\n• Sign out of accounts when you are finished using them. Sign out both online and on your smartphone so no \none can get easy access if they get your device.\nBest Buy scam alert: People are pretending to be members of the Geek Squad. How to spot it.\nPackage text scam: Text scam impersonating UPS, FedEx, Amazon and USPS involves a package you never \nordered\nConsumer columnist Betty Lin-Fisher can be reached at 330-996-3724 or  blinfisher@thebeaconjournal.co m. \nFollow her @blinfisherABJ on Twitter or www.facebook.com/BettyLinFisherABJ and see all her stories at \nwww.tinyurl.com/bettylinfisher \nThis article originally appeared on Akron Beacon Journal: Identity theft takes a massive toll on victims lives, may \neven lead to suicidal ideation\nLoad-Date: August 30, 2023"
    },
    {
        "file_name": "Newsletter_Apr2024",
        "header": "Sports Leagues Bet on Gambling. Now They’re Facing Its Risks.; DealBook",
        "media": "Newsletter",
        "time": "April 1, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1831 words",
        "byline": "Lauren Hirsch and Ephrat Livni Lauren Hirsch joined The Times from CNBC in 2020, covering deals and",
        "story_text": "Sports Leagues Bet on Gambling. Now They’re Facing Its Risks.; DealBook \nNewsletter\nThe New York Times \nMarch 30, 2024 Saturday 11:52 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1831 words\nByline: Lauren Hirsch and Ephrat Livni Lauren Hirsch joined The Times from CNBC in 2020, covering deals and \nthe biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and policy \nfor DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced law in \nthe public and private sectors.\nHighlight: A string of gambling situations involving athletes leaves leagues in a tough spot.\nBody\nA string of gambling situations involving athletes leaves leagues in a tough spot.\nMajor League Baseball held its season openers this week under the shadow of a gambling scandal. Reports \nsurfaced that the National Basketball Association is investigating a player over irregular bets. And college \nbasketball fans await results from a review into unusual betting on a men’s basketball game.\nThe incidents have highlighted a trade-off that professional sports leagues made when they embraced gambling.\nLeagues have signed lucrative marketing deals with betting apps like FanDuel and DraftKings and use gambling to \namp up fan engagement. But this new source of revenue has also opened the doors to a fundamental danger: that \nan explosion of sports betting could threaten the assumption of fairness at the core of athletic competitions.\n“The risk is that the game becomes like professional wrestling — which is rigged. And nobody bets on professional \nwrestling,” said Fay Vincent, the M.L.B. commissioner from 1989 to 1992. “And if baseball becomes professional \nentertainment the way wrestling is, it’s dead.”\nLeagues are unlikely to abandon gambling completely. But is there a way for them to protect their image as they \nprofit from betting?\nClubs can no longer blame gambling itself for scandals. When Pete Rose was barred from baseball in 1989 for \nbetting on games, in one of the most famous gambling scandals in sports history, Commissioner A. Bartlett \nGiamatti, Vincent’s predecessor, denounced gambling as corrosive. But after a 2018 Supreme Court decision \npaved the way for states to legalize betting, leagues are now working directly with sports books. The N.B.A. signed \nan estimated $25 million contract with MGM Resorts in 2018, and M.L.B. has an exclusive multiyear deal with \nFanDuel.\n“There is no putting the toothpaste back in the tube,” said Patrick Rishe, a professor in the business of sports at \nWashington University in St. Louis. “The money flows too thick.”\nLeagues may support limits on prop bets, which allow gamblers to bet beyond the results of games on components \nlike the first player to score. Since the outcome of these bets can often be decided by only one player, they leave \nindividual athletes vulnerable to more pressure from bookies and others. The president of the N.C.A.A., Charlie \nSports Leagues Bet on Gambling. Now They’re Facing Its Risks. DealBook Newsletter\nBaker, encouraged states this week to ban prop bets, sending shares of DraftKings and FanDuel’s parent company, \nFlutter, tumbling. (Some analysts said a ban would only minimally affect the sports books’ bottom lines.)\nBetter self-monitoring could help. The largest U.S. sports books announced this week that they were forming the \nResponsible Online Gaming Association, an organization that will allow them to share information about customers \nwho have been excluded because of problematic gambling.\n“This is real money, real participation,” said Chris Grove, an analyst at Eilers &amp; Krejcik Gaming. “But, with that \nsaid, it shouldn’t also just be a free pat on the back. There are a lot of questions, especially around what kind of \ninformation are you going to be sharing about individual players and then what kinds of actions are you going to be \ntaking based on that information sharing.”\nLeagues could also extend bans against in-sport betting to individuals with ties to players, like personal assistants. \nAnyone who works at the teams “should probably be subjected to the same rules as they’re subjecting the athletes \nto,” said Jeffrey Kessler, a sports law lawyer at Winston &amp; Strawn.\nMore taxes may be on the table. “State governments are also major beneficiaries of regulated gambling,” Grove \nsaid. “They have an obligation to step up and to help to mitigate whatever problems are emerging.”\nStates could raise taxes on sports betting, which range from 6.75 percent in Iowa to 51 percent in New York, Rhode \nIsland and New Hampshire, and use the proceeds to fund oversight initiatives such as real-time data monitoring or \nstate-supported teletherapy for gambling addicts.\nA flat tax increase might be welcomed by FanDuel and DraftKings, the largest betting sites, which are better \nequipped than smaller rivals to afford the impact — “though they would never say that out loud,” Grove said.\nBut many are doubtful this will happen any time soon, given the pushback that higher taxes would most likely elicit \nfrom others. Professional sports teams and casinos both “have a very strong track record in terms of lobbying state \nlegislatures,” said Marc Edelman, a professor of law at Baruch College who studies gambling history.\nWill the latest incidents damage leagues? Given the lengthy nature of TV contracts and relative steadfastness of \nfans, any immediate impact may be subtle. Attendance at Cincinnati Reds games dipped only slightly after Rose, \nwho managed the team, was ousted for betting, said Keith O’Brien, author of “Charlie Hustle: The Rise and Fall of \nPete Rose.” A year later, it jumped about 25 percent.\n“Does that mean that fans wanted to come because they were washing away the scandal? I don’t know,” O’Brien \nsaid. “I can tell you, having lived in Cincinnati in 1989, that it ruined baseball. It ruined it. And it was a lost season.” \n— Lauren Hirsch\nIN CASE YOU MISSED IT\nJay Powell says economic resilience gives the Federal Reserve more flexibility on when to start cutting rates. The \nFed chair signaled yesterday that robust consumer spending and a strong labor market allowed the central bank to \nbe patient. He reiterated that it wanted to be more confident that inflation was coming down sustainably before \ntaking action.\nSam Bankman-Fried is sentenced to 25 years in prison. The FTX founder was convicted of stealing $8 billion from \nhis customers and faced a maximum sentence of 110 years. He vowed to appeal the conviction.\nVisa and Mastercard agreed to reduce swipe fees for five years. The proposed class-action settlement to a long-\nrunning fight with retailers could have wider consequences, like making the credit card reward programs that many \ntravelers use for free travel less lucrative.\nDisney ended its legal fight with Ron DeSantis. The entertainment giant and the Florida governor have been \nsparring for two years over control of a tax district that encompasses Walt Disney World. Both sides have now \nagreed to cooperate on new growth plans for the 25,000-acre area.\nSports Leagues Bet on Gambling. Now They’re Facing Its Risks. DealBook Newsletter\nBlockbuster spending\nWednesday is the deadline for Disney shareholders to vote in what is expected to be the most expensive proxy fight \nin history. The company’s board faces attacks from two sets of activist investors — Trian Partners and Blackwells \nCapital — and all sides are putting their money to work to try to win over retail investors. Trian has spent about $25 \nmillion, Blackwells Capital about $6 million and Disney upward of $40 million.\nBecause a large portion of Disney’s shareholders are retail investors, the battle has morphed into what is effectively \na modern-day marketing campaign. And if you’ve been searching for information about the fight, you’ve probably \nbeen barraged by online ads. Here’s how the price to bid on Google Ads keywords tied to the fight has jumped over \nthe past year.\nHow any business can use A.I. \nEthan Mollick, a professor at the Wharton School of the University of Pennsylvania, has built a big following for his \nresearch into how to apply artificial intelligence at work and his popular newsletter, One Useful Thing.\nHe spoke to DealBook about his new book, “Co-Intelligence: Living and Working With AI,” in which he spells out \nhow to get the most out of the transformative new tools. The conversation has been edited and condensed.\nWhat mistakes do companies make with A.I.?\nThey tend to view this as something that has to be highly centralized. So it ends up being some sort of high-end \nworking group, usually with the I.T. department and the legal department, to define rules and uses. What they often \ndo is lock down use.\nCompanies also believe that somebody has answers about how to use A.I. They’re hiring consulting companies, \nand the consulting companies don’t know anything. Even the A.I. companies don’t know how this can be used best.\nHave you seen companies use generative A.I. to make big improvements in how they work?\nWhat’s really happening is large numbers of their employees are secretly doing their work with A.I. and just not \ntelling anyone. So a lot of companies are actually being automated and getting huge efficiency gains.\nYou write that we should strive to use A.I. like a “cyborg” instead of a “centaur.” What do you mean?\nCentaur work is divided. There’s some work you give the A.I and some work you keep for yourself. So let’s say I’m \nnot a good writer but I’m good at analysis. I’d say to the A.I.: “You do the writing. I do the analysis.”\nCyborg work is more blended. When I wrote this book, if I got stuck on a sentence I’d ask the A.I., “Give me 10 \nways of resolving this issue.” I had it read through part of my books and give me feedback on it, or suggest \nanalogies that might be useful. That is more effective.\nIf an executive wants to incorporate A.I. into my business, what should be that person’s first step?\nYou just have to use it. The first use case I see from many, many people is using a chatbot to write children’s \nstories or wedding toasts. I think the thing to actually start with is everything you legally, ethically can at work. Ask it \nquestions about what you’re working on. Have it brainstorm ideas with you. Have it give you feedback on a meeting \nthat you recorded on Zoom with permission. And that’s how you learn how to work with it.\nOn our radar: The ancient maritime principle of ‘general average’\nInsured losses from the collapse of the Francis Scott Key Bridge, which a cargo ship struck on Tuesday, could \nreach $4 billion, and sorting out who will foot that bill may take a decade of litigation. Part of that fight may involve a \nlittle-known ancient principle of maritime law called “general average.”\nSports Leagues Bet on Gambling. Now They’re Facing Its Risks. DealBook Newsletter\nThe principle, attributed to the mariners of Rhodes in a text from 533, dictates that when there is disaster, cargo \nshippers and vessel owners jointly share the costs. “General average is a shared sacrifice,” said William Fennell, \nchair of the Marine Insurance and General Average Committee for the Maritime Law Association of the United \nStates. The principle dictates that “everyone’s in it together.”\nClassic cases involved jettisoning cargo — if the crew had to lighten a ship’s load to avoid sinking and tossed some \nbut not all cargo, under general average everyone chipped in for the loss. In modern times, the notion applies more \nbroadly, and it could arise in the case of this week’s tragedy, Fennell said.\nIf the ship’s owners invoke the principle and are not ultimately found to be at fault for the accident (in which case it \nwould not apply), companies that had cargo on the ship could end up paying for some of those losses.\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nThis article appeared in print on page B4.\nLoad-Date: April 1, 2024"
    },
    {
        "file_name": "Good?_Oct2023",
        "header": "A.I. Excels at Making Bad Art. Can an Artist Teach It to Create Something",
        "media": "Good?",
        "time": "October 3, 2023",
        "section": "ARTS.DESIGN",
        "length": "1343 words",
        "byline": "Zachary Small",
        "story_text": "A.I. Excels at Making Bad Art. Can an Artist Teach It to Create Something \nGood?\nThe New York Times - International Edition\nOctober 4, 2023 Wednesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: ARTS.DESIGN\nLength: 1343 words\nByline: Zachary Small\nBody\nABSTRACT\nDavid Salle, one of America's most thoughtful painters, wants to see if an algorithm can learn to mimic his style - \nand nourish his own creativity in the process.\nFULL TEXT\nOf the many young artists David Salle has mentored, none were ever as challenging as his latest student, who \ncannot hold a paintbrush or a conversation. \n\"The mountain looks too airbrushed,\" Salle informed the algorithm that lives inside his iPad. The landscape painting \nit had produced, based on hundreds of his own artworks, was typically generic, lacking in depth. But the next one \nsucceeded, depicting a valley stream with expressionistic wisps and a sense of volume. \n\"The way it has rendered water looks more deliberate,\" Salle, 70, said. \"But it's funny to call something deliberate \nwhen it has no consciousness, isn't it?\" \nFor nearly a year, the painter - known for edgy images appropriated from art history and popular culture, as well as \njuxtapositions of voluptuous nudes and ham sandwiches - has attempted to defy conventional thinking about \ngenerative artificial intelligence by testing an A.I. program's capacity to become a sophisticated creator of art. \nThe partnership has grown through weekly meetings with two technologists, Danika Laszuk and Grant Davis, who \ntailored a text-to-image model to Salle's requirements, relying on descriptive prompts that generated images in the \nartist's style. The New York Times observed three of their work sessions, tracking the algorithm's progress over \nseveral months as it adopted more of Salle's techniques and abandoned the bland photorealism that often limits \nother generative programs. \n\"We are sending the machine to art school,\" Salle quipped, before expounding on the principles of light, shadow, \ndepth and volume that good painting requires. The algorithm wouldn't need eyes to achieve greatness, but it would \nneed to hone the robotic equivalent of intuition to spark inspiration and fool a gallerist. \nAnd first, it would have to learn to mimic his style. \nThe experiment was a mutually beneficial arrangement. Laszuk runs a program called E.A.T__WORKS, for the \nventure capital firm Betaworks, that pairs artists and engineers on projects where her company might earn a \npercentage of the profits. Davis is building Wand, an A.I. platform for artists that promises to help them streamline \nA.I. Excels at Making Bad Art . Can an Artist Teach It to Create Something Good?\ntheir operations with faster imaging through text prompts and sketching. Salle was something like a guinea pig for \nWand, teaching its program how to paint while developing his own series of digital images. \nWith permission from Ben Lerner, a friend of Salle's, the group has been feeding bits of poetry from his new book, \n\"The Lights,\" to evoke more fantastical images of cities growing within organic cells, and patterns of interlocking \nbarbules. Prompts also have been sourced from another friend, the writer Sarah French. \n\"Our process starts with very imaginative prompts,\" Davis said. \"And we generate lots of images before selecting \nthe ones we like. Then David starts drawing on top of them. The process can repeat itself like that until he's \nsatisfied.\" \nSalle is one of the first traditional artists to embed on the front lines of artificial intelligence. He, in turn, was trained \nby the conceptualist John Baldessari at the California Institute of the Arts in the 1970s and has a style that absorbs \na diverse set of influences, from the Italian painter Giorgio de Chirico to the New Yorker cartoonist Peter Arno. \nThe results have sometimes been described as memories that barely hold together, and as attempts to ascribe \nsignificance to the foggy afterimages of art history. He is often grouped with the appropriation artists of the 1980s, \nincluding Richard Prince and Cindy Sherman, who have questioned the primacy of authorship in contemporary \nculture. He has also juxtaposed photography with painting. \n\"Every major artist is an amalgamation or synthesis of diverse sympathies and influences,\" Salle wrote in his 2018 \nbook \"How to See\" about making and viewing art. He recalled asking the painter Alex Katz to make a list of his own \ninfluences; Katz said the list started with Jackson Pollock and ended with \"the guy who made Nefertiti.\" \nOn another page of his art treatise, Salle delivered a grand theory of creativity: \"Form is the raw material, and style \nis the forge.\" \nArtificial intelligence has a limitless vault of forms, thanks to the billions of online images it studies through a \nprocess called diffusion, in which the algorithm learns the structure of an image - and then learns to create \nvariations. Its knowledge is then stored in the parameters of the model, which is translated to the A.I. through a \nshort sequence of numbers known as \"latent space.\" \nBut learning artistic style requires going beyond simple pattern recognition. Experts say that increased \nmatchmaking improves accuracy but also stymies the machine's ability to produce the unexpected. A balance must \nbe struck. \nThe algorithm's \"training\" to become the next David Salle started with a diffusion model to develop a general \nunderstanding of visual images based on hundreds of the artist's paintings. Davis, the engineer, then introduced \ndozens of detailed snapshots of Salle's paintings to the program so it would learn to \"think like a painter.\" \nSome of the first experiments were underwhelming: blobby landscapes, figures drawn without brush strokes, flat \nabstraction. But the critiques that Salle offered did improve the machine's intelligence enough to surprise the artist. \n\"As a painter you only have time to create a painting, but each painting contains within it all the paintings you don't \nhave time to make,\" Salle said. \"A.I. is a great tool because it allows me to see thousands of combinations; things \nthat I would manually sift through in years are made with 5,000 versions in an hour.\" \nSalle isn't the first artist to assume the role of mad scientist, pushing against the limits of his own mortality with a \nmachine capable of publishing a series of posthumous \"new\" works long after his death. \nBut he is also not someone to rest on his laurels. These experiments have come at a moment of great change in \nthe artist's career, which has spanned nearly 50 years. This year he left Skarstedt Gallery, which represented him \nfor nearly a decade, to join the dealer Barbara Gladstone. This fall, he has a solo exhibition in Seoul filled with \npaintings in a more graphic style from his \"Tree of Life\" series - influenced by Arno, the cartoonist - which Salle has \ndescribed as \"little dramas.\" \nA.I. Excels at Making Bad Art . Can an Artist Teach It to Create Something Good?\nSome of those pictures hung on the walls of his studio during summer, when he met with the technologists behind \nhis algorithm. The branches of his \"Tree of Life\" resembled the image of brain synapses - summoning the \npsychological dramas of the characters' lives onto the canvas foreground. \nThe algorithm has become another pathway into his own psychology. The experiment has Salle wrestling with the \ndefinition of art and the nature of authorship. \nWhat will become of his own identity, as the algorithm continues to produce more Salle paintings than he could ever \nimagine? Some days, it seems like the algorithm is an assistant. Other days, it's like a child. When asked if the A.I. \nwould replace him entirely one day, the artist shrugged. \"Well,\" he said, \"that's the future.\"   \nZachary Small spent five months observing David Salle's experiments with artificial intelligence, including at the \npainter's studio in Brooklyn.Produced by Lucky Benson, Alicia DeSantis, Barbara Graustark, Gabriel Gianordoli, \nAndrew LaVallee and Tala Safie. A.I.-generated images: Grant Davis and David Salle. Additional images: David \nSalle/VAGA at Artists Rights Society (ARS), NY, via Gladstone Gallery, NY; Edward Hopper, \"Nighthawks,\" 1942, \nvia The Art Institute of Chicago; Giorgio de Chirico, \"Ariadne,\" 1913, Artists Rights Society (ARS), NY/SIAE, Rome, \nvia The Metropolitan Museum of Art, NY; Gian Lorenzo, \"Ecstasy of Saint Teresa,\" 1653, Alessandra \nTarantino/Associated Press; David Salle/VAGA at Artists Rights Society (ARS), NY, via Gladstone Gallery, NY.\nLoad-Date: October 3, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Mar2023",
        "header": "CHIP MAKERS CATCH AI WAVE",
        "media": "Wall Street Journal Abstracts",
        "time": "March 8, 2023",
        "section": "B; Pg. 12",
        "length": "40 words",
        "byline": "DAN GALLAGHER",
        "story_text": "CHIP MAKERS CATCH AI WAVE\nWall Street Journal Abstracts\nMarch 7, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 12\nLength: 40 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column notes boost given to chip makers Broadcom and Nvidia from soaring \ninterest in generative artificial intelligence; contends Broadcom’s lower valuation makes it underappreciated play; \nphoto (M)\nGraphic\n \nPhotograph\nLoad-Date: March 8, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "NTT sells controlling stake in Pune-based Nihilent to promoter",
        "media": "The Economic Times",
        "time": "January 10, 2024",
        "section": "TECH & INTERNET",
        "length": "678 words",
        "byline": "Beena Parmar",
        "story_text": "NTT sells controlling stake in Pune-based Nihilent to promoter\nThe Economic Times\nJanuary 10, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 678 words\nByline: Beena Parmar\nBody\nJapanese telecommunication giant NTT Corporation has fully exited its 69.14% controlling stake in Pune-based IT \nconsulting and services firm Nihilent Ltd selling it to the founder and promoter LC Singh.While the exact deal size \nwas not disclosed, in mid-2022, NTT was seeking a valuation for Nihilent at around Rs 2,500 crore ($314 million \nthen).Exercising his first right of refusal, Singh bought back the 69.16% stake from NTT through a leveraged buyout \nwith debt financing from a consortium of two funds - ICICI Prudential Corporate Credit Opportunities Fund AIF-I of \nICICI Prudential Alternate Investments and Piramal Structured Credit Opportunities Fund, the performing credit fund \nof Piramal Alternatives, Singh confirmed to ET in an interaction.The remaining stake continues to be held by \nSingh’s family, Nihilent’s top management executives and employees. It also has a pool for employee stock \nownership plans (ESOPs) of roughly 6.5% available for its employees.NTT, which owned stake through its \ninvestment firm Hatch Investments (Mauritius), became Nihilent’s biggest shareholder in 2017 when it picked up a \n34.6% stake from South Africa’s Adcorp Workforce Management Solutions, which used to jointly own Hatch \nInvestments along with NTT-owned firm Dimension Data Protocol.Explaining the rationale behind the acquisition, \nSingh, an industry veteran and also the executive vice chairman for the company, said that while over the years \nIndian IT sector has been instrumental in building the backoffice systems, now the world is changing and role of IT \nand ITes platforms are merging in a big way.“Besides the AI fad, we are working on some new-age solutions in \nhealthcare, media, energy sector, etc. In a complex shareholding it can become difficult to grow and get funded \nindependently, or be more entrepreneurial… This strategic move allows Nihilent to regain full control and autonomy \nover the operations, enabling us to implement our vision and business strategies more effectively,” Singh \nsaid.Nihilent had applied for an initial public offering (IPO) twice earlier to raise around Rs 140 crore in 2015 and Rs \n250 crore later in 2018 and get publicly listed. \nHowever, the plans were shelved due to sectoral market concerns, and Singh says he could revive the IPO plans \nafter about 18 months.On the business front, Singh estimates the revenues to grow 10% for the current year ending \nMarch 2024 at around Rs 600 crore. “We see a compounded growth of around 25% in the next 3-5 years.”For now, \nNihilent is expanding in the US and South Africa with some of its products including Resense, an artificial \nintelligence (AI) machine learning (ML) business platform, Artoreal, a marketplace for painting and photographs and \nothers.Resense is the real-time demand forecasting engine for the food & beverages segment and quick service \nrestaurant (QSR) brands developed in India and introduced in the US few months ago.The firm plans to increase \nmarket presence, taking its IPs & products to market, strategic expansion of its current capabilities, and ramping up \nits offering in AI, ML, extended reality (XR) and generative AI, according to Minoo Dastur, president & CEO at \nNihilent. Dastur is also the co-founder of Nihilent.Founded in 2000, Nihilent offers consulting services and IT \nsolutions using a “human-centric approach to problem solving and change management” to customers in the \nbanking, media, retail, health-care and manufacturing industries. With just over 2000 employees, it currently has \npresence in South Africa, India, US, Sweden, UK and Australia. The firm partners with large companies including \nMicrosoft, SAP SE, Google and Snowflake.Nihilent also has user experience (UX) labs in Pune, Johannesburg in \nSouth Africa, and Dallas, in the US to co-create solutions for its clients from various fields.Before setting up Nihilent, \nNTT sells controlling stake in Pune-based Nihilent to promoter\nSingh was the CEO of Zensar Technologies for over a year and prior to that quit Indian IT giant Tata Consultancy \nServices (TCS) as a senior vice president after a stint of 17 years. For Reprint Rights: timescontent.com\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "A Blessing and a Boogeyman: Advertisers Warily Embrace A.I.",
        "media": "The New York Times",
        "time": "July 19, 2023",
        "section": "BUSINESS; media",
        "length": "1346 words",
        "byline": "Tiffany Hsu and Yiwen Lu",
        "story_text": "A Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\nThe New York Times \nJuly 18, 2023 Tuesday 23:30 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1346 words\nByline: Tiffany Hsu and Yiwen Lu\nHighlight: Many ads are easier to make with the fast-improving technology. It also poses a threat to an industry \nalready in flux.\nBody\nMany ads are easier to make with the fast-improving technology. It also poses a threat to an industry already in flux.\nThe advertising industry is in a love-hate relationship with artificial intelligence.\nIn the past few months, the technology has made ads easier to generate and track. It is writing marketing emails \nwith subject lines and delivery times tailored to specific subscribers. It gave an optician the means to set a fashion \nshoot on an alien planet and helped Denmark’s tourism bureau animate famous tourist sites. Heinz turned to it to \ngenerate recognizable images of its ketchup bottle, then paired them with the symphonic theme that charts human \nevolution in the film “2001: A Space Odyssey.”\nA.I., however, has also plunged the marketing world into a crisis. Much has been made about the technology’s \npotential to limit the need for human workers in fields such as law and financial services. Advertising, already \nracked by inflation and other economic pressures as well as a talent drain due to layoffs and increased automation, \nis especially at risk of an overhaul-by-A.I., marketing executives said.\nThe conflicting attitudes suffused a co-working space in downtown San Francisco where more than 200 people \ngathered last week for an “A.I. for marketers” event. Copywriters expressed worry and skepticism about chatbots \ncapable of writing ad campaigns, while start-up founders pitched A.I. tools for automating the creative process.\n“It really doesn’t matter if you are fearful or not: The tools are here, so what do we do?” said Jackson Beaman, \nwhose AI User Group organized the event. “We could stand here and not do anything, or we can learn how to apply \nthem.”\nMachine learning, a subset of artificial intelligence that uses data and algorithms to imitate how humans learn, has \nquietly powered advertising for years. Madison Avenue has used it to target specific audiences, sell and buy ad \nspace, offer user support, create logos and streamline its operations. (One ad agency has a specialized A.I. tool \ncalled the Big Lebotski to help clients compose ad copy and boost their profile on search engines).\nEnthusiasm came gradually. In 2017, when the advertising group Publicis introduced Marcel, an A.I. business \nassistant, its peers responded with what it described as “outrage, jest and negativity.”\nAt last month’s Cannes Lions International Festival of Creativity, the glittering apex of the advertising industry \ncalendar, Publicis got its “I told you so” moment. Around the festival, where the agenda was stuffed with panels \nabout A.I.’s being “unleashed” and affecting the “future of creativity,” the company plastered artificially generated \nposters that mocked the original reactions to Marcel.\nA Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\n“Is it OK to talk about A.I. at Cannes now?” the ads joked.\nThe answer is clear. The industry has wanted to discuss little else since late last year, when OpenAI released its \nChatGPT chatbot and set off a global arms race around generative artificial intelligence.\nMcDonald’s asked the chatbot to name the most iconic burger in the world and splashed the answer — the Big Mac \n— across videos and billboards, drawing A.I.-generated retorts from fast food rivals. Coca-Cola recruited digital \nartists to generate 120,000 riffs on its brand imagery, including its curved bottle and swoopy logo, using an A.I. \nplatform built in part by OpenAI.\nThe surge of A.I. experimentation has brought to the fore a host of legal and logistical challenges, including the \nneed to protect reputations and avoid misleading consumers.\nA recent campaign from Virgin Voyages allowed users to prompt a digital avatar of Jennifer Lopez to issue \ncustomized video invitations to a cruise, including the names of potential guests. But, to prevent Ms. Lopez from \nappearing to use inappropriate language, the avatar could say only names from a preapproved list and otherwise \ndefaulted to terms like “friend” and “sailor.”\n“It’s still in the early stages — there were challenges to get the models right, to get the look right, to get the sound \nright — and there are very much humans in the loop throughout,” said Brian Yamada, the chief innovation officer of \nVMLY&amp;R, the agency that produced the campaign for Virgin.\nElaborate interactive campaigns like Virgin’s make up a minority of advertising; 30-second video clips and \ncaptioned images, often with variations lightly adjusted for different demographics, are much more common. In \nrecent months, several large tech companies, including Meta, Google and Adobe, have announced artificial \nintelligence tools to handle that sort of work.\nMajor advertising companies say the technology could streamline a bloated business model. The ad group WPP is \nworking with the chip maker Nvidia on an A.I. platform that could, for example, allow car companies to easily \nincorporate footage of a vehicle into scenes customized for local markets without laboriously filming different \ncommercials around the world.\nTo many of the people who work on such commercials, A.I.’s advance feels like looming obsolescence, especially \nin the face of several years of slowing growth and a shift in advertising budgets from television and other legacy \nmedia to programmatic ads and social platforms. The media agency GroupM predicted last month that artificial \nintelligence was likely to influence at least half of all advertising revenue by the end of 2023.\n“There’s little doubt that the future of creativity and A.I. will be increasingly intertwined,” said Philippe Krakowsky, \nthe chief executive of the Interpublic Group of Companies, an ad giant.\nIPG, which was hiring chief A.I. officers and similar executives years before ChatGPT’s debut, now hopes to use \nthe technology to deliver highly personalized experiences.\n“That said, we need to apply a very high level of diligence and discipline, and collaborate across industries, to \nmitigate bias, misinformation and security risk in order for the pace of advancement to be sustained,” Mr. \nKrakowsky added.\nA.I.’s ability to copy and deceive, which has already found widespread public expression in political marketing from \nGov. Ron DeSantis of Florida and others, has alarmed many advertising executives. They are also concerned \nabout intellectual property issues and the direction and speed of A.I. development. Several ad agencies joined \norganizations such as the Coalition for Content Provenance and Authenticity, which wants to trace content from its \norigins, and the Partnership on AI, which aims to keep the technology ethically sound.\nAmid the doom and gloom, the agency Wunderman Thompson decided this spring to take A.I. down a peg.\nA Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\nIn an Australian campaign for Kit Kat candy bars, the agency used text and image generators from OpenAI to \ncreate intentionally awkward ads with the tagline “AI made this ad so we could have a break.” In one, warped \nfigures chomped on blurry chocolate bars over a script narrated in a mechanical monotone: “Someone hands them \na Kit Kat bar. They take a bite.”\nThe campaign would be trickier to pull off now, in part because the fast-improving technology has erased many of \nthe flaws present just a few months ago, said Annabelle Barnum, the general manager for Wunderman Thompson \nin Australia. Still, she said, humans will always be key to the advertising process.\n“Creativity comes from real human insight — A.I. is always going to struggle with that because it relies purely on \ndata to make decisions,” she said. “So while it can enhance the process, ultimately it will never be able to take away \nanything that creators can really do because that humanistic element is required.”\nPHOTOS: A Virgin Voyages campaign using A.I. allowed users to prompt a digital avatar of Jennifer Lopez to issue \ntens of thousands of customized invitations to a cruise, top. An Australian ad campaign for Kit Kat candy bars made \nA.I.’s contribution awkwardly obvious, left. Coca-Cola solicited artwork made using an A.I. platform with access to \narchival images, below. (PHOTOGRAPHS BY VIRGIN VOYAGES; WUNDERMAN THOMPSON; CHRIS BRANCH, \nVIA THE COCA-COLA COMPANY) (B7) This article appeared in print on page\nLoad-Date: July 19, 2023"
    },
    {
        "file_name": "Sanket_Atal,_Salesforce_India_Apr2024",
        "header": "Startup ecosystem today is remarkably different compared to 10 years ago:",
        "media": "Sanket Atal, Salesforce India",
        "time": "April 26, 2024",
        "section": "SME SECTOR",
        "length": "1038 words",
        "byline": "Ashish Pandey",
        "story_text": "Startup ecosystem today is remarkably different compared to 10 years ago: \nSanket Atal, Salesforce India\nThe Economic Times\nApril 26, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: SME SECTOR\nLength: 1038 words\nByline: Ashish Pandey\nBody\nThe startup ecosystem today is remarkably different from a decade ago and the ecosystem is only expected to get \nbetter in India, says Sanket Atal, Managing Director, Operations and Site Lead, Technology & Product, Salesforce \nIndia.In an interview with ET Digital, Atal explains how Salesforce is guiding startups via its Idea Exchange \nprogramme and helping them come up with ideas on what to develop. The Salesforce Startup Program provides \nstartups with connections to companies that have partnered with Salesforce in the past, including venture capitalists \nand angel investors. Edited excerpts:The Economic Times (ET): How do you see the evolution of the startup \necosystem in India?Sanket Atal (SA): The typical way startups get going is for smart people to come together \nsaying ‘we want to solve a problem’. But now what’s happening is these folks are doing or able to do research on \nthe technology areas that will actually get them a market foothold. \nThat’s different. And the focus on things is not quite there yet, but more focus on things like how do you actually \ndesign the product from a UI perspective design, from a functional perspective, those things are coming in, and \nthat's allowing these guys to be much more mature. But why is that happening? One thing is many startups fail, and \npeople have learned from it. The other thing is, there has been a lot of movement of people from the US to here, as \nwell as a part of some company or the other, some of them have ventured out into startup land. So, that connection \nwith the US — the most thriving startup ecosystem — is also helping these folks learn the best practices. The state \nof startups today as compared to say 10 years ago is remarkably different. Money flowing in is also significant. It \ngoes up and down as the economy grows, but money flowing in is significant as people are becoming much more \ncourageous, willing to take risks and establish the right connections to be able to do so. I think the ecosystem has \nmatured quite a bit, and that’s going to continue with time.ET: What do you think about Indian startups in terms of \ninnovation?SA: I think they are very innovative. The availability of resources in the form of money, for example, is \nscarce outside the US, and even Europeans complain about the lack of funding. Funding is scarce. You have to be \nvery creative about what you do and how you do it right. That takes a lot of innovation. That's one part. The other \npart is that with the enablers, the availability of various kinds of tech etc., people are looking at how best can they \nget a leg up on their competition. And I am seeing amazing innovation, not just limited to our view of innovation to \njust tech; it's also in the approach to the market, and how they are trying to address that. ET: What is the Salesforce \nStartup Program?SA: When you develop a product, you need to take it to market, but you are not quite sure how. \nNow if you are a mobile app developer, you know what to do. You go to the App Store for Apple or Google Play and \nyou are able to do that. But what do you do with enterprise apps? It is different. I had heard of the app exchange \nfrom Salesforce. And upon joining, I realised that we have not quite positioned that with startups. So, if you take a \nlook at what the startups really want to do, they want to come up with ideas on what to develop. They are looking \nfor help. We also have something called Idea Exchange, which is basically all the technology gaps perceived by our \ncustomers and our users' family we call trailblazers; all of this in a database available for anybody to use. So, you \ncan go in there and get ideas that ‘hey, these are the technology gaps that need to be filled’. Yes, globally, these \nare ideas that you can use to create applications that are adjacent to our application. So, you use that to develop \nStartup ecosystem today is remarkably different compared to 10 years ago: Sanket Atal, Salesforce India\nthe applicator concept, and then you develop the actual application on our platform and we provide. No matter what \nyou want to do — no-code, low code, whatever it is — we provide your platform. Once it's developed, you get it \napproved, just like you get two apps approved by Google or whoever uses them approved by us, and then you put \nthem on a marketplace for that. In addition, we have a lot of startups that are interested in running the companies \non things like our products. But they're not quite sure if they can, because you only hear of Salesforce powering \nlarge companies. So, we give them the opportunity in case they're interested. There's a no-push model; if they're \ninterested, we connect them to our sales folks. Then the startups go about trying out the products and seeing if this \nis a viable solution. And I'm very happy that a lot of startups have actually done it and been very happy with \napplications on AppExchange.The third aspect of our programme involves providing startups with connections to \ncompanies that have partnered with us, including VCs, angels and our ventures team.ET: What are the three major \nproblems that startups are facing and that need to be resolved? SA: I think access to funds is a big one. You know, \none of the things that happens is some of them try to work to get money because they hear all these stories. And \nyou have to realise that the moment you get some money, you lose control. So you have to go in at the right time. \nThe reason a lot of US companies get funding is because they're in the same town and same city as most of the \nVCs. I think that's one area which needs to get better for sure. The other one, I think, is that greater focus on design \nis needed. Our goal is to just get things done. But a focus on design is needed. Design is a big enabler for adoption. \nET: Do you see any big trends in the startup ecosystem in the next 5 to 10 years?SA: Everybody is venturing into \nthe AI space. I read somewhere that more than 2,000 startups have propped up around AI, and quite a few have \ncome up in the generative AI space. Being able to leverage these technologies would be awesome. And another \narea, like the agri space, really needs to be innovated in. We are a huge country, a supplier to the world for various \nthings. So if people get innovative with that, some amazing things can happen. For Reprint Rights: \ntimescontent.com\nLoad-Date: April 26, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Sep2023",
        "header": "Voice Deepfakes Are Coming for Your Bank Balance",
        "media": "The New York Times - International Edition",
        "time": "September 1, 2023",
        "section": "BUSINESS",
        "length": "1446 words",
        "byline": "Emily Flitter and Stacy Cowley",
        "story_text": "Voice Deepfakes Are Coming for Your Bank Balance\nThe New York Times - International Edition\nSeptember 2, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1446 words\nByline: Emily Flitter and Stacy Cowley\nBody\nABSTRACT\nArtificial intelligence tools have given scammers a potent weapon for trying to trick people into sending them \nmoney.\nFULL TEXT\nThis spring, Clive Kabatznik, an investor in Florida, called his local Bank of America representative to discuss a big \nmoney transfer he was planning to make. Then he called again.       \nExcept the second phone call wasn't from Mr. Kabatznik. Rather, a software program had artificially generated his \nvoice and tried to trick the banker into moving the money elsewhere.       \nMr. Kabatznik and his banker were the targets of a cutting-edge scam attempt that has grabbed the attention of \ncybersecurity experts: the use of artificial intelligence to generate voice deepfakes, or vocal renditions that mimic \nreal people's voices.       \nThe problem is still new enough that there is no comprehensive accounting of how often it happens. But one expert \nwhose company, Pindrop, monitors the audio traffic for many of the largest U.S. banks said he had seen a jump in \nits prevalence this year - and in the sophistication of scammers' voice fraud attempts. Another large voice \nauthentication vendor, Nuance, saw its first successful deepfake attack on a financial services client late last year.       \nIn Mr. Kabatznik's case, the fraud was detectable. But the speed of technological development, the falling costs of \ngenerative artificial intelligence programs and the wide availability of recordings of people's voices on the internet \nhave created the perfect conditions for voice-related A.I. scams.       \nCustomer data like bank account details that have been stolen by hackers - and are widely available on \nunderground markets - help scammers pull off these attacks. They become even easier with wealthy clients, whose \npublic appearances, including speeches, are often widely available on the internet. Finding audio samples for \neveryday customers can also be as easy as conducting an online search - say, on social media apps like TikTok \nand Instagram - for the name of someone whose bank account information the scammers already have.       \n\"There's a lot of audio content out there,\" said Vijay Balasubramaniyan, the chief executive and a founder of \nPindrop, which reviews automatic voice-verification systems for eight of the 10 largest U.S. lenders.       \nOver the past decade, Pindrop has reviewed recordings of more than five billion calls coming into call centers run \nby the financial companies it serves. The centers handle products like bank accounts, credit cards and other \nVoice Deepfakes Are Coming for Your Bank Balance\nservices offered by big retail banks. All of the call centers receive calls from fraudsters, typically ranging from 1,000 \nto 10,000 a year. It's common for 20 calls to come in from fraudsters each week, Mr. Balasubramaniyan said.       \nSo far, fake voices created by computer programs account for only \"a handful\" of these calls, he said - and they've \nbegun to happen only within the past year.       \nMost of the fake voice attacks that Pindrop has seen have come into credit card service call centers, where human \nrepresentatives deal with customers needing help with their cards.       \nMr. Balasubramaniyan played a reporter an anonymized recording of one such call that took place in March. \nAlthough a very rudimentary example - the voice in this case sounds robotic, more like an e-reader than a person - \nthe call illustrates how scams could occur as A.I. makes it easier to imitate human voices.       \nA banker can be heard greeting the customer. Then the voice, similar to an automated one, says, \"My card was \ndeclined.\"       \n\"May I ask whom I have the pleasure of speaking with?\" the banker replies.       \n\"My card was declined,\" the voice says again.       \nThe banker asks for the customer's name again. A silence ensues, during which the faint sound of keystrokes can \nbe heard. According to Mr. Balasubramaniyan, the number of keystrokes correspond to the number of letters in the \ncustomer's name. The fraudster is typing words into a program that then reads them.        \nIn this instance, the caller's synthetic speech led the employee to transfer the call to a different department and flag \nit as potentially fraudulent, Mr. Balasubramaniyan said.       \nCalls like the one he shared, which use type-to-text technology, are some of the easiest attacks to defend against: \nCall centers can use screening software to pick up technical clues that speech is machine-generated.       \n\"Synthetic speech leaves artifacts behind, and a lot of anti-spoofing algorithms key off those artifacts,\" said Peter \nSoufleris, the chief executive of IngenID, a voice biometrics technology vendor.       \nBut, as with many security measures, it's an arms race between attackers and defenders - and one that has \nrecently evolved. A scammer can now simply speak into a microphone or type in a prompt and have that speech \nvery quickly translated into the target's voice.       \nMr. Balasubramaniyan noted that one generative A.I. system, Microsoft's VALL-E, could create a voice deepfake \nthat said whatever a user wished using just three seconds of sampled audio.       \nOn \"60 Minutes\" in May, Rachel Tobac, a security consultant, used software to so convincingly clone the voice of \nSharyn Alfonsi, one of the program's correspondents, that she fooled a \"60 Minutes\" employee into giving her Ms. \nAlfonsi's passport number.       \nThe attack took only five minutes to put together, said Ms. Tobac, the chief executive of SocialProof Security. The \ntool she used became available for purchase in January.       \nWhile scary deepfake demos are a staple of security conferences, real-life attacks are still extremely rare, said Brett \nBeranek, the general manager of security and biometrics at Nuance, a voice technology vendor that Microsoft \nacquired in 2021. The only successful breach of a Nuance customer, in October, took the attacker more than a \ndozen attempts to pull off.       \nMr. Beranek's biggest concern is not attacks on call centers or automated systems, like the voice biometrics \nsystems that many banks have deployed. He worries about the scams where a caller reaches an individual directly.       \nVoice Deepfakes Are Coming for Your Bank Balance\n\"I had a conversation just earlier this week with one of our customers,\" he said. \"They were saying, hey, Brett, it's \ngreat that we have our contact center secured - but what if somebody just calls our C.E.O. directly on their \ncellphone and pretends to be somebody else?\"       \nThat's what happened in Mr. Kabatznik's case. According to the banker's description, he appeared to be trying to \nget her to transfer money to a new location, but the voice was repetitive, talking over her and using garbled \nphrases. The banker hung up.       \n\"It was like I was talking to her, but it made no sense,\" Mr. Kabatznik said she had told him. (A Bank of America \nspokesman declined to make the banker available for an interview.)       \nAfter two more calls like that came through in quick succession, the banker reported the matter to Bank of \nAmerica's security team, Mr. Kabatznik said. Concerned about the security of Mr. Kabatznik's account, she stopped \nresponding to his calls and emails - even the ones that were coming from the real Mr. Kabatznik. It took about 10 \ndays for the two of them to re-establish a connection, when Mr. Kabatznik arranged to visit her at her office.       \n\"We regularly train our team to identify and recognize scams and help our clients avoid them,\" said William Halldin, \na Bank of America spokesman. He said he could not comment on specific customers or their experiences.       \nThough the attacks are getting more sophisticated, they stem from a basic cybersecurity threat that has been \naround for decades: a data breach that reveals the personal information of bank customers. From 2020 to 2022, \nbits of personal data on more than 300 million people fell into the hands of hackers, leading to $8.8 billion in losses, \naccording to the Federal Trade Commission.       \nOnce they've harvested a batch of numbers, hackers sift through the information and match it to real people. Those \nwho steal the information are almost never the same people who end up with it. Instead, the thieves put it up for \nsale. Specialists can use any one of a handful of easily accessible programs to spoof target customers' phone \nnumbers - which is what likely happened in Mr. Kabatznik's case.       \nRecordings of his voice are easy to find. On the internet there are videos of him speaking at a conference and \nparticipating in a fund-raiser.       \n\"I think it's pretty scary,\" Mr. Kabatznik said. \"The problem is, I don't know what you do about it. Do you just go \nunderground and disappear?\"       \nAudio produced by Tally Abecassis.       \nAudio produced by Tally Abecassis. \nLoad-Date: September 1, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2023",
        "header": "Hello, Bard! Google opens public access to ChatGPT rival",
        "media": "The Economic Times",
        "time": "March 23, 2023",
        "section": "TECH AND GADGETS",
        "length": "393 words",
        "byline": " ",
        "story_text": "Hello, Bard! Google opens public access to ChatGPT rival\nThe Economic Times\nMarch 24, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 393 words\nBody\nSeems like the competition is only getting tougher as Google on Wednesday announced that it is finally opening up \naccess to its ChatGPT competitor 'Bard'. This release will be an early experiment for users to collaborate with \ngenerative AI. Google is granting early access to 'Bard', which has been first rolled out in the US and UK. Google \nwill be expanding the access to 'Bard' over time to more countries and languages. \n\"You can use 'Bard' to boost your productivity, accelerate your ideas and fuel your curiosity. You might ask 'Bard' to \ngive you tips to reach your goal of reading more books this year, explain quantum physics in simple terms or spark \nyour creativity by outlining a blogpost,\" Google said in a blogpost. The wider launch of the ChatGPT competitor \ncomes amid heightened buzz in Silicon Valley over generative AI, which creates text, images, videos and music \nbased on prompts submitted by users. 'Bard', just like OpenAI's ChatGPT and Microsoft's Bing chatbot, is based on \na large language model (LLM), specifically a lightweight and optimised version of LaMDA, which Google said will be \nupdated with newer, more capable models in the future as more and more people use it. To understand how LLM \nworks, think of it as a prediction engine. So when you give a prompt, this tech generates a response by selecting, \none word at a time, from words that are likely to come next, according to Google. \"'Bard' is a direct interface to an \nLLM, and we think of it as a complementary experience to Google Search. 'Bard' is designed so that you can easily \nvisit Search to check its responses or explore sources across the web. Click \"Google it\" to see suggestions for \nqueries, and Search will open in a new tab so you can find relevant results and dig deeper. We'll also be \nthoughtfully integrating LLMs into Search in a deeper way - more to come,\" Google said in a blogpost, which the \ntech company claimed was written with the help of 'Bard'. Users can easily interact with Google's 'Bard' by asking \nquestions and then refining their responses with follow-up questions. Google has said that it will continue to improve \n'Bard' experience by adding capabilities, including coding, more languages and multimodal experiences over time. \nPeople in India will have to wait a little bit longer to test out Google's 'Bard'. For Reprint Rights: timescontent.com\nLoad-Date: March 23, 2023"
    },
    {
        "file_name": "MAY_BE_MOST_AFFECTED_Aug2023",
        "header": "AS GENERATIVE AI RESHAPES THE WORKFORCE, THESE COMPANIES",
        "media": "MAY BE MOST AFFECTED",
        "time": "August 1, 2023",
        "section": "R; Pg. 7",
        "length": "45 words",
        "byline": "BETSY MORRIS",
        "story_text": "AS GENERATIVE AI RESHAPES THE WORKFORCE, THESE COMPANIES \nMAY BE MOST AFFECTED\nWall Street Journal Abstracts\nJuly 31, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: R; Pg. 7\nLength: 45 words\nByline: BETSY MORRIS\nBody\nABSTRACT\nBetsy Morris article in Journal Report — C-Suite Strategies notes research finding that shares of companies with \ngreatest number of jobs that could be affected by generative artificial intelligence outperform shares of \ncompanies least exposed to technology; table (M)\nGraphic\n \nGraphs and Charts\nLoad-Date: August 1, 2023"
    },
    {
        "file_name": "TESTED_IN_AMAZON_WAREHOUSES_Oct2023",
        "header": "CMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS'; HUMANOID BOTS",
        "media": "TESTED IN AMAZON WAREHOUSES",
        "time": "October 30, 2023",
        "section": "ASECTION; Pg. A-1",
        "length": "988 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "CMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS'; HUMANOID BOTS \nTESTED IN AMAZON WAREHOUSES\nPittsburgh Post-Gazette\nOctober 30, 2023 Monday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 988 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nAmazon's new factory workers don't complain about long hours or poor working conditions.\nBuilt by Carnegie Mellon University alumni, the Agility Robotics humanoids, called Digit, can pick up packages and \nwalk around warehouses on their own two legs. They're part of a push by the online shopping giant to make \ndeliveries more efficient.\n\"New robotic solutions ... will support workplace safety and help Amazon deliver to customers faster,\" the company \nsaid in a recent blog post.\nAmazon led the charge toward warehouse automation with the purchase of Kiva Systems in 2012. It now deploys \n750,000 wheeled mobile robots across its warehouse network.\nBut Digit would be the company's first on two feet.\nThe 5-foot, 9-inch bots were designed around Occupational Safety and Health Administration standards and built to \nmove like humans so that they can work in existing factories, said Agility CEO Damion Shelton. To recharge, the \nrobots initially sat in bays that resembled airport massage chairs.\n\"Now, because of where the battery pack is, it actually clicks back into the charge dock,\" Mr. Shelton said. \"I really \nloved the airport massage chair model, but you know, engineering realities taking precedence.\"\nBoth Amazon and Agility say robots won't replace human jobs. Digit is designed to work alongside humans and \nreplace the most mundane tasks, freeing up people to do more thought-heavy tasks.\n\"Despite the logistics industry pushing out a non-trivial amount of robots in the past 10 years, not only has there not \nbeen any job loss associated with it, the number of unfilled jobs has actually increased,\" Mr. Shelton said.\nAgility plans to make 10,000 Digit units each year. Amazon is currently using the bots in a testing capacity but sees \n\"a big opportunity to scale.\"\nMr. Shelton started Agility in 2015 alongside Chief Technology Officer Jonathan Hurst. They met as CMU graduate \nstudents in the early 2000s.\n\"The whole train that ultimately led to what became Digit has its roots back to Jonathan being in grad school at \nCMU,\" said Mr. Shelton, who remembers helping Mr. Hurst with his computer science homework as the student \nhelped him with his mechanical work.\nCMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS' HUMANOID BOTS TESTED IN AMAZON \nWAREHOUSES\nMr. Hurst went on to create Oregon State University's first robotics lab. Mr. Shelton taught at the University of \nPittsburgh before leaving the conceptual world of academia to build real-world products, first at threeRivers 3D and \nnow at Agility.\nTheir synergy led to the first commercially available bipedal robot, Cassie, in 2017. Three years later, Agility started \nselling Digit to Ford.\nSimilar humanoids have been developed by Boston Dynamics and Tesla, but neither have found broad commercial \nuse. New founders like Brett Adcock, of electric aviation company Archer, are now getting bipedal robots up on two \nlegs in under a year.\nMr. Shelton said the various companies don't necessarily learn from each other's approach.\n\"We're comfortable, frankly, with our own tech,\" he said.\nBut together, the buzz they create can be helpful.\n\"This is such a large market, it's not like any individual company is going to dominate 100% of it,\" Mr. Shelton said. \n\"Agility is obviously the first to market, and we're quite confident with where we are. But we're also happy that \nthere's more broad interest in this space.\"\nAgility is headquartered in Corvallis, Ore., but Mr. Shelton and a team of about 45 employees work from its second-\nlargest office in Pittsburgh. The company received development funding last year from Amazon's $1 billion \nIndustrial Innovation Fund.\nAmazon also backed a CMU team in 2015 that built the four-legged \"CHIMP\" robot, which could drive, climb stairs \nand operate power tools - all facets of a competition sponsored by the Defense Advanced Research Projects \nAgency.\nMr. Hurst led a team at Oregon State University that also responded to the challenge, building the ostrich-like \nATRIAS, a direct predecessor to Cassie.\nStill, years later, Mr. Shelton said humanoids remain an \"unmet gap for automation.\"\n\"The main argument for robots that are about the size and shape of a person is not so much that they're cool - \nalthough they are - but rather that our world is set up around us,\" he said.\nThere is still a ways to go before Digit finds its way outside of warehouses, where safety would be a significant \nconcern.\nThe robots are fully autonomous and even walk themselves back to charging stations when it's time to refuel. But \nthey are trained on a limited world of smooth floors and standard-sized bins.\nPittsburgh's sidewalks would pose an entirely different challenge, Mr. Shelton said.\n\"It is literally possible to have a CAD model of every single plastic bin in the entire world,\" he said. \"Whereas in \nPittsburgh, God knows what database you'd have to have.\n\"The reality is the robots are not self-aware, they're not even using large language models right now,\" he said, \nreferring to the building blocks of generative AI tools like ChatGPT.\nChris Atkeson, a CMU robotics professor known for creating the inflatable technology that inspired Disney's \"Big \nHero 6\" movie, said Agility's recent success is part of a broader upswing in robotics development that is blossoming \nnationwide and in Pittsburgh.\nCMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS' HUMANOID BOTS TESTED IN AMAZON \nWAREHOUSES\n\"There is a lot of work going on at CMU and at local companies, given that there is a big overlap between \ndeveloping brains for autonomous cars and for humanoids,\" he said, noting that Tesla loves to highlight the \nsynergy.\nThe university's work on humanoid bodies currently focuses on hands, skin, control and superhuman sensing, Mr. \nAtkeson said.\nAs for Agility's plans beyond Amazon, Mr. Shelton said they are launching a partnership program that will allow \nlarge manufacturing and logistics companies to purchase a Digit workforce.\nDown the road, Agility is considering an hourly subscription model to help small and midsize companies that are \ntypically more impacted by workforce shortages.\nEvan Robinson-Johnson: ejohnson@post-gazette.com or @sightsonwheels\nGraphic\n \nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed by Agility Robotics, a team \nled by Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently \nusing the bots in a testing capacity but sees \"a big opportunity to scale.\"\nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed Agility Robotics, a team led \nby Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently using \nthe bots in a testing capacity but sees \"a big opportunity to scale.\"\nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed Agility Robotics, a team led \nby Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently using \nthe bots in a testing capacity but sees \"a big opportunity to scale.\"\nLoad-Date: October 30, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "TIKTOK TESTS ITS OWN AI CHATBOT",
        "media": "Wall Street Journal Abstracts",
        "time": "May 27, 2023",
        "section": "B; Pg. 4",
        "length": "27 words",
        "byline": "SARAH E NEEDLEMAN",
        "story_text": "TIKTOK TESTS ITS OWN AI CHATBOT\nWall Street Journal Abstracts\nMay 26, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 27 words\nByline: SARAH E NEEDLEMAN\nBody\nABSTRACT\nTikTok is testing chatbot powered by generative artificial intelligence that is designed to help its users find \ncontent and get recommendations for more (M)\nLoad-Date: May 27, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "AI is Here, but is Yet to Make a Big Impact on Marketing",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 13, 2023",
        "section": "BRANDS & COMPANIES",
        "length": "725 words",
        "byline": "Shephali.Bhatt@timesgroup.com",
        "story_text": "AI is Here, but is Yet to Make a Big Impact on Marketing\nEconomic Times (E-Paper Edition)\nSeptember 13, 2023 Wednesday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BRANDS & COMPANIES\nLength: 725 words\nByline: Shephali.Bhatt@timesgroup.com\nHighlight: CXOs seem more concerned with rethinking their marketing strategy to be able to measure the direct \nimpact of ad spends, says McKinsey exec\nBody\nMumbai: AI (artificial intelligence) may be the buzzword in marketing right now, but CXOs seem more concerned \nwith rethinking their marketing strategy to be able to measure the direct impact of ad spends and finding the right \ntalent, Stephan Zimmermann, senior partner at McKinsey & Company, said. Based in San Francisco, Zimmermann \nheads the consulting major's digital marketing and data analytics team of 1,400, half of whom are stationed in India. \nDuring his recent visit to India, Zimmermann had some 15-odd client meetings, but “nobody mentioned or \ndiscussed an AI tool saying they strongly believed in it or asked what I thought of it”, he told ET in an exclusive chat. \nPeople are readily using generative AI to optimise marketing, automate repetitive tasks, and accelerate A/B \ntesting. \nHowever, “no-  ne of the tools have yet transformed company performance”, he said. “A lot of companies spend \nmassively on martech (marketing technology) tools but get only onethird of the value out of it,” he said, emphasising \nthat the next few years will see many of them pick a few core tools to extract maximum value out of them as \npressure for measurement mounts on them.  A few years ago, digital was less than 10% of the advertising pie in \nIndia. “Today, it's at about 35%, and we expect it to go north of 60% in the next three years, similar to the way it has \ngrown in the US,” said Zimmermann who has spent over 25 years with McKinsey and focuses on online \nbusinesses.  Traditionally, companies had separate budgets for brand building and performance marketing, he \nnoted. “The traditional channels for brand building, like print, TV, and outdoor, were hard to measure. But most \nleading companies are now focused on measuring the impact of full-funnel marketing, and digital  brand building \nallows you to do that with access to data,” he said. Zimmermann pointed out that roughly 10% of McKinsey's \nclientele in India, and 20% globally, now hire data scientists in their core marketing team. He expects 50% of these \ncompanies to have data scientists in their marketing departments in the next three to five years.  How can \nMcKinsey still provide value to these companies if they already employ data scientists of their own? Zimmermann \nargued they get companies “on the right operating models and build capabilities that help them utilise the talent \noptimally”. “We are moving from being advisors to companies or mere consultants, into the role of an impact \npartner,” he added.  Speaking of shifts, he pointed out how not too long ago, consumers “actively went shopping” \nwhereas now they are “actively advertised” products on social media and the internet in general, based on their \nspecific interests.  “Today, retail media networks in India may be getting about 5% of overall digital spending, but \nthis number will dramatically go up to the global level of 15-20% in line with the overall digital marketing growth,” \nZimmermann said. “And even as retail media networks like Amazon eat into Google and Meta's share in the ad pie \nin pure percentage terms, it won't take away much in absolute terms because the overall pie is growing massively \nwith more budgets shifting to digital,” he added. He doesn't share the same optimism for the prospects of live \ncommerce — selling products via a live stream on digital platforms — in India though. According to a McKinsey \nreport from 2021, China's live commerce industry was  valued at over $171 billion in 2020 and had been growing \nAI is Here, but is Yet to Make a Big Impact on Marketing\nsteadily ever since. In India, the market is projected to be anywhere between $5 billion and $50 billion by 2025, \naccording to multiple market research company reports. “It's not a function of what went wrong in India with respect \nto live commerce. The category hasn't picked up in the US as well where it is still probably 2-3% of all ecommerce \n(roughly $30 billion),” Zimmermann said. “I think it has to do with the difference in shopping and social behaviour in \nmarkets like India and the US compared to China. Our sense is, it will grow in both these markets, too, but not \nbecome 20% of all ecommerce revenue the way it is in China right now, which is a highly influencerled ecommerce \nmarket.” Further, in a market like India, it's likely that live commerce will be led by “info-based influencers” as \nopposed to the ones showcasing a “flashy” lifestyle, Zimmermann concluded.\nLoad-Date: September 13, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "A Hurdle-Filled Race To Make Computer Chips",
        "media": "The New York Times",
        "time": "May 15, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1463 words",
        "byline": "By Don Clark",
        "story_text": "A Hurdle-Filled Race To Make Computer Chips\nThe New York Times\nMay 15, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1463 words\nByline: By Don Clark\nBody\nFor more than 50 years, designers of computer chips mainly used one tactic to boost performance: They shrank \nelectronic components to pack more power onto each piece of silicon.\nThen more than a decade ago, engineers at the chip maker Advanced Micro Devices began toying with a radical \nidea. Instead of designing one big microprocessor with vast numbers of tiny transistors, they conceived of creating \none from smaller chips that would be packaged tightly together to work like one electronic brain. \n  The concept, sometimes called chiplets, caught on in a big way, with AMD, Apple, Amazon, Tesla, IBM and Intel \nintroducing such products. Chiplets rapidly gained traction because smaller chips are cheaper to make, while \nbundles of them can top the performance of any single slice of silicon.\n  The strategy, based on advanced packaging technology, has since become an essential tool to enabling progress \nin semiconductors. And it represents one of the biggest shifts in years for an industry that drives innovations in \nfields like artificial intelligence, self-driving cars and military hardware.\n  ''Packaging is where the action is going to be,'' said Subramanian Iyer, a professor of electrical and computer \nengineering at the University of California, Los Angeles, who helped pioneer the chiplet concept. ''It's happening \nbecause there is actually no other way.''\n  The catch is that such packaging, like making chips themselves, is overwhelmingly dominated by companies in \nAsia. Although the United States accounts for around 12 percent of global semiconductor production, American \ncompanies provide just 3 percent of chip packaging, according to IPC, a trade association.\n  That issue has now landed chiplets in the middle of U.S. industrial policymaking. The CHIPS Act, a $52 billion \nsubsidy package that passed last summer, was seen as President Biden's move to reinvigorate domestic chip \nmaking by providing money to build more sophisticated factories called ''fabs.'' But part of it was also aimed at \nstoking advanced packaging factories in the United States to capture more of that essential process.\n  ''As chips get smaller, the way you arrange the chips, which is packaging, is more and more important and we \nneed it done in America,'' Commerce Secretary Gina Raimondo, said in a speech at Georgetown University in \nFebruary.\n  The Commerce Department is now accepting applications for manufacturing grants from the CHIPS Act, including \nfor chip packaging factories. It is also allocating funding to a research program specifically on advanced packaging.\n  Some chip packaging companies are moving quickly for the funding. One is Integra Technologies in Wichita, Kan., \nwhich announced plans for a $1.8 billion expansion there but said that was contingent on receiving federal \nA Hurdle-Filled Race To Make Computer Chips\nsubsidies. Amkor Technology, an Arizona packaging service that has most of its operations in Asia, also said it was \ntalking to customers and government officials about a U.S. production presence.\n  Packaging chips together isn't a new concept and chiplets are just the latest iteration of that idea, using \ntechnological advances that help cram the chips closer together -- either side by side or stacked on top of one \nanother -- along with faster electrical connections between them.\n  ''What is unique about chiplets is the way they are connected electrically,'' said Richard Otte, the chief executive of \nPromex Industries, a chip packaging service in Santa Clara, Calif.\n  Chips can't do anything without a way to connect them with other components, which means they need to be \nplaced in some kind of package that can carry electrical signals. That process starts after factories complete the \ninitial phase of manufacturing, which may create hundreds of chips on a silicon wafer. Once that wafer is sliced \napart, individual chips are typically bonded to a key base layer called a substrate, which can conduct electrical \nsignals.\n  That combination is then coated in protective plastic, forming a package that can be plugged into a circuit board \nthat is essential for connecting to other components in a system.\n  These processes originally required lots of manual labor, leading Silicon Valley companies to shift packaging to \nlower-wage countries in Asia more than 50 years ago. Most chips are typically flown to packaging services in \ncountries like Taiwan, Malaysia, South Korea and China.\n  Since then, packaging advances have gained importance because of the diminishing returns from Moore's Law, \nthe shorthand expression for chip miniaturization that for decades drove progress in Silicon Valley. It is named for \nGordon Moore, a co-founder of Intel, whose 1965 paper described how rapidly companies had doubled the number \nof transistors on a typical chip, which improved performance at a lower cost.\n  But these days, smaller transistors are not necessarily cheaper, partly because building factories for leading-edge \nchips can cost $10 billion to $20 billion. Big, complex chips also are costly to design and tend to have more \nmanufacturing defects, even as companies in fields like generative A.I. want more transistors than can currently be \npacked onto the biggest chips manufacturing machines allow.\n  ''The natural response to that is putting more things in a package,'' said Anirudh Devgan, chief executive of \nCadence Design Systems, whose software is used to design conventional chips as well as chiplet-style products.\n  Synopsys, a rival, said it was tracking more than 140 customer projects based on packaging multiple chips \ntogether. As much as 80 percent of microprocessors will use chiplet-style designs by 2027, according to the market \nresearch firm Yole Group.\n  Today, companies typically design all the chiplets in a package along with their own connection technology. But \nindustry groups are working on technical standards so companies can more easily assemble products from chiplets \nthat come from different makers.\n  The new technology is mostly used now for extreme performance. Intel recently introduced a processor called \nPonte Vecchio with 47 chiplets that will be used in a powerful supercomputer at Argonne National Laboratory, which \nis near Chicago.\n  In January, AMD disclosed plans for an unusual product, the MI300, that combines chiplets for standard \ncalculations with others designed for computer graphics, along with a large pool of memory chips. That processor, \nintended to power another advanced supercomputer at Lawrence Livermore National Laboratory, has 146 billion \ntransistors, compared with tens of billions for most advanced conventional chips.\n  Sam Naffziger, an AMD senior vice president, said it wasn't a slam-dunk for the company to bet its chip business \nfor server computers on chiplets. Packaging complexities were a major hurdle, he said, which were eventually \novercome with help from an undisclosed partner.\nA Hurdle-Filled Race To Make Computer Chips\n  But chiplets have paid off for AMD. The company has sold more than 12 million chips based on the idea since \n2017, according to Mercury Research, and has become a major player in microprocessors that power the web.\n  Packaging services still need others to supply the substrates that chiplets require to connect to circuit boards and \none another. One company driving the chiplet boom is Taiwan Semiconductor Manufacturing Company, which \nalready makes chips for AMD and hundreds of others and offers an advanced silicon-based substrate called an \ninterposer.\n  Intel has been developing similar technology, as well as enhancing less-expensive conventional plastic substrates \nin an approach favored by some such as the Silicon Valley start-up Eliyan. Intel has also been developing new \npackaging prototypes under a Pentagon program and hopes to win CHIPs Act support for a new pilot packaging \nplant.\n  But the United States has no major makers of those substrates, which are primarily produced in Asia and evolved \nfrom technologies used in manufacturing circuit boards. Many U.S. companies have also left that business, another \nworry that industry groups hope will spur federal funding to help board suppliers start making substrates.\n  In March, Mr. Biden issued a determination that advanced packaging and domestic circuit board production were \nessential for national security, and announced $50 million in Defense Production Act funding for American and \nCanadian companies in those fields.\n  Even with such subsidies, assembling all the elements required to reduce U.S. dependence on Asian companies \n''is a huge challenge,'' said Andreas Olofsson, who ran a Defense Department research effort in the field before \nfounding a packaging start-up called Zero ASIC. ''You don't have suppliers. You don't have a work force. You don't \nhave equipment. You have to sort of start from scratch.''\n  Ana Swanson contributed reporting.Ana Swanson contributed reporting.\nhttps://www.nytimes.com/2023/05/11/technology/us-chiplets-tech.html\nGraphic\n \nPHOTOS: A MI300 processor, by Advanced Micro Devices, is a example of chiplet technology, creating a \nmicroprocessor from smaller chips packaged tightly together to work as a unit. Packaging is dominated by Asian-\nbased companies. (PHOTOGRAPH BY ZERB MELLISH FOR THE NEW YORK TIMES) (B1)\n At Promex Industries in Santa Clara, Calif., computer chips and packaging materials are joined together. One of \nthe goals of the CHIPS Act, a $52 billion subsidy package, is to increase the presence of such factories in the U.S. \n(PHOTOGRAPHS BY JIM WILSON/THE NEW YORK TIMES) (B4-B5) This article appeared in print on page B1, \nB4, B5.               \nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "at_CES_2024_Jan2024",
        "header": "More drone deliveries, new AI tech: Here's a guide to what Walmart unveiled",
        "media": "at CES 2024",
        "time": "January 25, 2024",
        "section": "RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & WAL-MART STORES NEWS",
        "length": "915 words",
        "byline": "Bailey Schulz, USA TODAY",
        "story_text": "More drone deliveries, new AI tech: Here's a guide to what Walmart unveiled \nat CES 2024\nUSA Today Online\nJanuary 9, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & WAL-MART STORES NEWS\nLength: 915 words\nByline: Bailey Schulz, USA TODAY\nBody\nShopping at Walmart and Sam's Club is about to get easier. \nWalmart on Tuesday unveiled several new and upcoming offerings that aim to improve the customer experience, \nfrom generative AI-powered search tools to technology that will do away with the receipt check lines at Sam's \nClub. \n“We build technology to serve people and not the other way around,” Walmart President and CEO Doug McMillon \nsaid in a news release. “Walmart’s purpose is to help people live better and, today, more than ever, advances in \ntechnology make it feel like anything is possible.” \nMcMillon took the stage Tuesday afternoon at the CES consumer technology convention in Las Vegas to highlight \nthe company's latest innovations.  \nAI-powered receipt check at Sam’s Club\nNew AI-powered technology at Sam’s Club intends to do away with the long receipt-check lines near the exits.\nThe retailer plans to leverage AI and computer vision technology to confirm that members have paid for all of the \nitems in their carts. Sam’s Club has so far launched the technology at 10 locations as part of a pilot program, with \nplans to expand to its nearly 600 clubs by the end of the year. \nLink to Image\n\"At Sam's Club, we care about every second a member spends with us. So eliminating even the few seconds it \ntakes to scan a receipt at the exit door is well worth it,\" said Megan Crozier, the chief merchant at Sam's Club, at \nCES. \nCEO McMillon acknowledged that some of Walmart's innovations will shift employee roles.\n\"No doubt some tasks will go away and some roles will change. And some of them should, like the ones that involve \nlifting heavy weight or doing repetitive tasks,\" he said. \"As that's happening, we're designing new roles that our \nassociates tell us are more enjoyable and satisfying and also often result in higher pay.\"\nMore Walmart delivery drones in Texas\nMore drone deliveries, new AI tech: Here's a guide to what Walmart unveiled at CES 2024\nAfter more than 20,000 drone deliveries over the last two years, Walmart is expanding the service to 1.8 million \nadditional households in the Dallas Fort-Worth metroplex. The company says this is the first time a U.S. retailer has \noffered drone delivery to this many households in a single market.\n“Drone delivery is not just a concept of the future, it’s happening now and will soon be a reality for millions of \nadditional Texans,” Prathibha Rajashekhar, senior vice president of innovation and automation for Walmart U.S., \nsaid in a press release. The new hubs are expected to launch in the coming months, with the expansion complete \nby the end of the year.  \nRoughly three-fourths of the items in Walmart's Supercenters meet the size and weight requirements for drone \ndelivery, with items delivered in 30 minutes or less. The Texas deliveries will be completed through partnerships \nwith on-demand drone delivery providers Wing and Zipline. \nWalmart also offers drone deliveries in Arizona, Arkansas, Florida, Utah and Virginia.\nLink to Image\nAI-powered tools \nWalmart announced Tuesday that a new generative AI-powered search experience is now available on iOS, and \navailable to all platforms later this quarter. \nThe new search allows customers to search by specific use cases. If a customer is throwing a Super Bowl party, for \ninstance, they can search “football watch party” to find relevant items instead of typing in multiple searches for \nthings like chips, chicken wings and soda. \nWalmart says the search tool will account for “a variety of other factors” like location and search history to yield \nbetter results.\nWalmart also shared details on its new InHome Replenishment tool, which uses AI to help fill customers’ carts with \nnecessary items right when they need it. \nThe new offering expands upon the InHome grocery delivery service launched in 2019, which carries orders directly \nto customers’ doorstep, garage or kitchen fridge. InHome Replenishment will use a personalized algorithm to \nanticipate customers’ needs and place orders that are delivered directly to their kitchen. Customers will have the \noption to skip items that are not needed, add additional items to their order and adjust their delivery date. \n\"It's personalized and adjusts based on your changing needs,\" said Whitney Pegden, vice president of new \npropositions and pre-transactions at Walmart U.S. \"Not only are we going to get you what you need, we're going to \nget it to you when you need it and even where you need it, right to your refrigerator.\"\nWalmart has not yet announced when this new service will launch. \nVirtual try-ons\nLink to Image\nWalmart also shared that it is working on a new augmented reality (AR) experience called Shop with Friends. \nThe social commerce platform is set to let customers create virtual outfits to share with their friends for feedback. \nThe outfits will be displayed on a virtual model with a size and shape similar to the customer. \nWalmart has not yet announced when this feature will be available. \nMore EV chargers\nMore drone deliveries, new AI tech: Here's a guide to what Walmart unveiled at CES 2024\nWalmart in 2023 announced plans to deploy a nationwide network of fast electric vehicle chargers across \nthousands of stores and clubs by 2030. Now, Walmart says it plans to start rolling out the chargers this year. \n\"Using partner technology, these chargers will be Walmart-owned and -operated so that we can use best-in-class \nchargers and deliver a Walmart charging experience. One that is convenient, reliable and affordable,\" said Vishal \nKapadia, senior vice president of energy transformation at Walmart.  \nThis article originally appeared on USA TODAY: More drone deliveries, new AI tech: Here's a guide to what \nWalmart unveiled at CES 2024\nLoad-Date: January 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2022",
        "header": "Good Tech Awards: What Went Right in 2022",
        "media": "The New York Times",
        "time": "December 30, 2022",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT",
        "length": "1460 words",
        "byline": "By Kevin Roose",
        "story_text": "Good Tech Awards: What Went Right in 2022\nThe New York Times\nDecember 30, 2022 Friday\nLate Edition - Final\nCopyright 2022 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT\nLength: 1460 words\nByline: By Kevin Roose\nBody\nThe year 2022, in the tech world, was one of big leaps and even bigger pratfalls.\nThe falls included some of the industry's most recognizable names. Sam Bankman-Fried began the year as the \nbiggest celebrity in crypto, with a net worth of more than $20 billion, and ends it as a disgraced pariah who is facing \ncriminal fraud charges. Elon Musk began 2022 as the world's richest man, with a thriving electric car company and \na name synonymous with success; he ends it more than $100 billion poorer, as the bitter and beleaguered owner of \na social media company that seems to be ruining his life. \n  The tech industry struggled, too, with harsh macroeconomic conditions, including high inflation and rising interest \nrates. As the sector's decade of hypergrowth came to an end, start-ups died, tech giants cut perks and laid off \nworkers, and investors' dreams of a new, crypto-fied internet known as ''web3'' faded into oblivion.\n  But focusing exclusively on what went wrong risks missing the many noble, clever and socially valuable tech \nprojects that made progress this year.\n  For several years now, I've highlighted these kinds of projects in my annual Good Tech Awards column. These \naren't necessarily technologies that I'm sure will improve the world, while causing no problems whatsoever. They're \ntools that I believe could improve the world, or help address thorny societal challenges. Some of them could also go \nquite badly, if they're mismanaged or co-opted in harmful ways.\n  There were many to choose from this year. Here's what made the final cut.\n  To OpenAI and the makers of Midjourney and Stable Diffusion, for proving that A.I. can create\n  The splashiest tech breakthrough of the year, by a significant margin, was the boom in ''generative A.I.'' -- a term \nfor the new type of artificial intelligence apps, trained on vast amounts of data, that can create new media objects \nout of thin air.\n  This year, A.I. image generators like DALL-E 2, Stable Diffusion and Midjourney dazzled users (including me) with \ntheir creations and set off a Cambrian explosion of new, ultracapable A.I. tools. In recent weeks, ChatGPT, a text-\ngenerating A.I. built by OpenAI, became a viral sensation (and every teacher's worst nightmare) when it started \ncranking out term papers, original poetry and working snippets of code.\n  Some credit for the generative A.I. boom should go to Google, which created much of the foundational \ntechnology. But this year, Google (which has kept most of its A.I. experiments private, to its recent chagrin) got one-\nupped by OpenAI, as well as the makers of Midjourney and Stable Diffusion, all of which released public-facing \nproducts that allowed millions of people to experience generative A.I. for themselves.\nGood Tech Awards: What Went Right in 2022\n  The ultimate effects of generative A.I. are still unknown. Some people argue that these apps will destroy millions \nof jobs, while others argue that they'll be a boon to human creativity. But whether you're an A.I. optimist or \npessimist, this year's advances mean that we are no longer debating theoretical costs and benefits -- the tools have \narrived, and we now get to decide how to use them.\n  To Ethereum developers, for pulling off the merge\n  I know, I know. Putting a crypto project in a ''good tech'' list in 2022 feels like putting credit default swaps in a ''cool \nfinancial innovations'' list in 2008.\n  But while the crypto industry took a nosedive this year -- wiping out trillions of dollars in value and leaving many \ninvestors empty-handed -- there was at least one bright spot. In September, Ethereum, the network behind the \nsecond most valuable cryptocurrency after Bitcoin, completed what was known as ''the merge'' -- a hulking, years-\nin-the-making project to switch Ethereum from an energy-guzzling form of blockchain known as ''proof of work'' to a \nmuch greener form of blockchain known as ''proof of stake.''\n  The switch, which crypto developers compared to trying to swap a plane's engine in midair, was a smashing \nsuccess, and cut the energy required to power Ethereum by more than 99 percent. (It didn't, however, boost the \nprice of the cryptocurrency, Ether, which ended the year down nearly 70 percent.)\n  To Living Carbon, Twelve and BeeHero, for turning tech on the climate crisis\n  While 2022 was a horrible year for start-up fund-raising in general, it was a great year for climate tech start-ups, \nwhich raised billions of dollars to bring climate-friendly technologies to market.\n  There are too many promising climate tech start-ups to name -- and, to be honest, I don't know enough about \nclimate science to tell which ones stand the best chance of succeeding -- but a few that caught my eye this year \nwere Living Carbon, Twelve and BeeHero.\n  Living Carbon, a three-year-old California start-up, is genetically engineering trees and other plants to capture and \nstore more carbon from the atmosphere. These G.M.O. supertrees, the company claims, grow bigger and faster \nthan normal trees and can survive in soil with metal concentrations that would be toxic to other plants.\n  Twelve, which is based in Berkeley, Calif., is using a novel electrochemical process to turn carbon dioxide into \nindustrial products as varied as sunglasses and jet fuel. The company raised a $130 million funding round this year \nand struck deals with companies like Mercedes-Benz and Procter & Gamble.\n  BeeHero, which was started in Israel in 2017, is using new technology to address problems facing one of the most \nimportant parts of our global food supply: bees. Bees pollinate more than one-third of all crops, but they are dying \noff at alarming rates, setting off fears of a food shortage. To tackle this, BeeHero developed a ''precision pollination \nplatform'' -- basically, a bee-tracking sensor system that allows for industrial beekeepers to monitor the health and \nproductivity of their hives in real time. The company raised a $42 million Series B (Series Bee?) round this year \nfrom investors including General Mills.\n  To the National Ignition Facility, Commonwealth Fusion Systems and Helion, for keeping the fusion dream alive\n  Nuclear fusion, an emissions-free form of energy generation that has long been viewed as the ''holy grail of \nenergy,'' took a few important steps toward reality this year.\n  The biggest fusion news of the year came just a few weeks ago when scientists at the National Ignition Facility at \nLawrence Livermore National Laboratory in California crossed a major threshold known as ''ignition,'' creating a \nfusion reaction that generated more energy than it took to produce. That breakthrough was hailed by officials \nincluding Jennifer M. Granholm, the secretary of energy, who called it a ''landmark achievement.''\n  Many start-ups have also been plugging away on fusion. One, Helion Energy, has raised hundreds of millions of \ndollars from well-known investors including Sam Altman, Dustin Moskovitz and Peter Thiel to create affordable, \nGood Tech Awards: What Went Right in 2022\nmass-market fusion technology. Helion says it plans to create energy with its next fusion reactor, Polaris, by 2024. \nAnother company, Commonwealth Fusion Systems, which was spun out of the Massachusetts Institute of \nTechnology in 2018, is using an array of powerful magnets to power its prototype fusion machine outside Boston, \nand plans to have it up and running by 2025.\n  Experts have cautioned that despite the latest breakthroughs, affordable fusion power may not be widely available \nfor years. But this year, both the public and private sectors offered a glimpse of a fusion-powered future.\n  To Locket, for making photo-sharing fun again\n  If 2022 was the year when social media died, it was also the year when start-ups began trying to recapture what \nhad made social media fun in the first place.\n  One app I've loved using this year is Locket. It's a very simple premise -- a widget that is installed on your \nsmartphone's home screen, creating a kind of digital photo frame that your closest friends and loved ones can \nupload photos to.\n  Locket was created by Matt Moss, a young developer who wanted a way to send photos to his long-distance \ngirlfriend; this year, the app quickly grew to millions of users, raised a major funding round and won an Apple \ncultural impact award. There are no filters, preening influencers, data-harvesting schemes or algorithmic feeds on \nLocket -- it's just an easy, no-frills way to share photos with your loved ones.\n  My wife and I started using Locket this year to share photos of our kid, in a way that wouldn't require us digging \nthrough text chains or huge photo albums to find them later on. It's not the tech product I've used most often, or the \none I think will create the most net good for society. But it's fun, uncomplicated and respectful of its users -- three \nqualities to which more tech products should aspire.\nhttps://www.nytimes.com/2022/12/29/technology/good-tech-awards-2022.html\nGraphic\n \nThis article appeared in print on page B1, B7.               \nLoad-Date: December 30, 2022"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "IBM Tries Assuring Customers Generative A.I. Is a Safe Bet",
        "media": "The New York Times",
        "time": "September 29, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 7",
        "length": "820 words",
        "byline": "By Steve Lohr",
        "story_text": "IBM Tries Assuring Customers Generative A.I. Is a Safe Bet\nThe New York Times\nSeptember 29, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 7\nLength: 820 words\nByline: By Steve Lohr\nBody\nThe company will assume the legal risk of businesses that use its A.I. systems and will publish the technology's \nunderlying data.\nThere is no shortage of excitement in corporate America for the new artificial intelligence that can produce \neverything from business reports to computer code with humanlike fluency. \n  Plenty of companies are experimenting with the technology, called generative A.I., but they are worried about \nhow confidential data will be handled, the accuracy of A.I.-generated answers and potential legal liability.\n  IBM on Thursday announced its campaign to ease customers' qualms. The company said it would indemnify \ncompanies against copyright or other intellectual property claims for using its generative A.I. systems. IBM will also \npublish its data sets -- the underlying data that is used to build or ''train'' the A.I. system -- which is not standard \npractice among commercial providers of generative A.I. technology.\n  The announcement is an indication that, while attention has been focused on the new A.I. technology in chatbots \nlike OpenAI's ChatGPT, IBM is laying its plans to tackle the market.\n  IBM's customers are mostly other businesses, and persuading those companies to use new A.I. products means \nassuring them that they won't run into legal trouble. OpenAI, for example, has already been sued by a collection of \nauthors who accuse it of infringing on their copyrights by using their books to train ChatGPT.\n  Over the last year, start-ups like OpenAI and other industry giants like Google and Microsoft have been much \nmore aggressive than IBM about publicly discussing their A.I. work. Even Meta, the parent company of Facebook, \nthis week introduced A.I. chatbots meant to sound like celebrities such as the quarterback Tom Brady and the hip-\nhop artist Snoop Dogg.\n  IBM's relatively quiet stance showed how much the tech industry had changed in the 12 years since IBM's Watson \nA.I. system beat top competitors on ''Jeopardy!'' A.I. became a centerpiece of IBM's pitch to corporate customers, \nbut the company has been overshadowed by younger competitors in the nearly yearlong A.I. frenzy in the tech \nindustry.\n  Other technology suppliers are also trying to reassure customers by assuming legal risks. Microsoft pledged this \nmonth to defend customers in any copyright suits that arise from using its A.I.-powered Copilots, which it is adding \nto its office productivity software and programming tools. Adobe has made a similar commitment for copyright \nclaims against customers using Adobe Firefly, its A.I. art-generation software.\nIBM Tries Assuring Customers Generative A.I. Is a Safe Bet\n  The IBM A.I. systems -- or ''models,'' as developers call them -- are tailored for use by businesses. And the \ntraining data has been curated with companies in mind and culled from the internet, academic journals, computer \ncode repositories, and legal and finance documents, the company said.\n  IBM appears to be going further than other companies in taking on risk and opening up its model-training data. But \nit is in step with where the business market for generative A.I. is heading, said Patrick Moorhead, chief executive of \nMoor Insights & Strategy, a technology analysis firm.\n  The big A.I.-fueled consumer services like ChatGPT and Google's Bard are closed, and people outside the \ncompanies behind them cannot usually see what data those systems are built on. That will not satisfy most \ncorporate customers, Mr. Moorhead said.\n  ''Businesses need to know the data inputs and get a sense of why you got the answer you did,'' he said. ''Putting \ntheir customer or confidential data into an A.I. model is seen as high risk for a business.''\n  IBM is positioning itself as a partner for companies that want to create their own A.I. technology, by adding their \nbusiness data to IBM's open models.\n  The early focus of most business technology companies, including Microsoft, Oracle, Salesforce and SAP, has \nlargely been on embedding generative A.I. to improve their existing digital tools for office productivity, supply chain \nmanagement, customer service and marketing.\n  IBM will deploy that A.I. in its products as well, but its emphasis is helping businesses become creators, as well as \ncustomers, of generative A.I. technology.\n  In business, the A.I. models are large, but far smaller than needed for the big consumer chatbots, said Rob \nThomas, IBM's senior vice president for software. The narrower focus also helps improve accuracy. ''And for our \nmarket, accuracy is way more important than size,'' he said.\n  The smaller models also require far less computing firepower than the giant consumer chatbots. That, Mr. Thomas \nsaid, should open the door to wider use of generative A.I. in operations that promise an immediate impact and \npayoff, including customer service, automated back-office tasks and digital assistants for writing code.\n  In those fields, ''we see a defensible return on investment at the moment,'' Mr. Thomas said. ''The economics \nwork.''\nhttps://www.nytimes.com/2023/09/28/business/ibm-ai-data.html\nGraphic\n \nThis article appeared in print on page B7.               \nLoad-Date: September 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Key OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "TECHNOLOGY",
        "length": "1418 words",
        "byline": "Mike Isaac, Tripp Mickle and Cade Metz Mike Isaac is a technology correspondent for The Times based in",
        "story_text": "Key OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nThe New York Times \nMarch 7, 2024 Thursday 18:17 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1418 words\nByline: Mike Isaac, Tripp Mickle and Cade Metz Mike Isaac is a technology correspondent for The Times based in \nSan Francisco. He regularly covers Facebook and Silicon Valley. Tripp Mickle reports on Apple and Silicon Valley \nfor The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues \nand political challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and \nrobot taxis. Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging \nareas of technology.\nHighlight: Mira Murati, OpenAI’s chief technology officer, brought questions about Mr. Altman’s management to the \nboard last year before he was briefly ousted from the company, people familiar with the matter said.\nBody\nMira Murati, OpenAI’s chief technology officer, brought questions about Mr. Altman’s management to the board last \nyear before he was briefly ousted from the company, people familiar with the matter said.\nMore than three months after OpenAI’s board of directors briefly ousted Sam Altman, the chief executive of the \nhigh-profile artificial intelligence company, questions remain about exactly what led the board to make such a \ndramatic move.\nA report from an outside law firm, which is expected in the coming days, could shed more light on the board’s \ndecision as well as the chaotic five days before Mr. Altman returned to the company.\nBut as anticipation for the report grows, previously unreported details are emerging about the role that Mira Murati, \nOpenAI’s chief technology officer, played in the ouster of Mr. Altman.\nMs. Murati wrote a private memo to Mr. Altman raising questions about his management and also shared her \nconcerns with the board. That move helped to propel the board’s decision to force him out, according to people with \nknowledge of the board’s discussions who asked for anonymity because of the sensitive nature of a personnel \nissue.\nAround the same time, Ilya Sutskever, a co-founder and chief scientist of OpenAI, expressed similar worries, citing \nwhat he characterized as Mr. Altman’s history of manipulative behavior, the people said. Both executives described \na hot-and-cold relationship with Mr. Altman. Though it was not clear whether they offered specific examples, the \nexecutives said he sometimes created a toxic work environment by freezing out executives who did not support his \ndecisions, the people said.\nMs. Murati’s interactions with the board offer insight into problems festering at the senior levels of OpenAI, though \nboth executives publicly backed Mr. Altman’s return to the company.\nWilmerHale, the law firm conducting the investigation, is expected to wrap up the process imminently. The company \nis expected to announce a new board of directors at the same time, some of the people said. Several directors left \nthe board after Mr. Altman returned to the company in November.\nKey OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nHannah Wong, a spokeswoman for OpenAI, said in a statement that the company’s senior leadership team, led by \nMs. Murati during her time as interim chief executive, unanimously asked for Mr. Altman’s return, as did an open \nletter signed by 95 percent of OpenAI’s employees.\n“The strong support from his team underscores that he is an effective C.E.O. who is open to different points of view, \nwilling to solve complex challenges, and who demonstrates care for his team,” Ms. Wong said. “We look forward to \nfindings from the independent review versus unsubstantiated claims.”\nMr. Altman declined to comment. Mr. Sutskever’s lawyer, Alex Weingarten, said claims that he had approached the \nboard were “categorically false.”\nMarc H. Axelbaum, a lawyer for Ms. Murati, said in a statement: “The claims that she approached the board in an \neffort to get Mr. Altman fired last year or supported the board’s actions are flat wrong. She was perplexed at the \nboard’s decision then, but is not surprised that some former board members are now attempting to shift the blame \nto her.”\nIn a message to OpenAI employees after publication of this article, Ms. Murati said she and Mr. Altman “have a \nstrong and productive partnership and I have not been shy about sharing feedback with him directly.”\nShe added that she did not reach out to the board but “when individual board members reached out directly to me \nfor feedback about Sam, I provided it — all feedback Sam already knew,” and that did not mean she was \n“responsible for or supported the old board’s actions.”\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nSince November, OpenAI and its investors have scrambled to contain the fallout from the incident, which \nthreatened to upend one of the tech industry’s most important start-ups. OpenAI was valued at more than $80 \nbillion in its last financing round.\nMuch of the remaining 700-plus employees at OpenAI — many of whom threatened to quit when Mr. Altman was \nfired — hope to put the events in November behind them. (Some employees refer to that period as “The Blip.”)\nBut there are others who are hopeful that the WilmerHale investigation will provide a thorough accounting of the \nevents surrounding Mr. Altman’s dismissal. It is not clear if the full report or a synopsis of it will be released to the \npublic.\nAt the time of Mr. Altman’s firing, OpenAI’s six-person board included Dr. Sutskever; Helen Toner, an A.I. \nresearcher who works at a Georgetown University think tank; Adam D’Angelo, a former Facebook executive; Greg \nBrockman, a co-founder and president of the company; Tasha McCauley, an adjunct senior management scientist \nat the RAND Corporation; and Mr. Altman.\nAs a condition of Mr. Altman’s reinstatement, executives agreed to shuffle OpenAI’s board to include a more \ndiverse and independent set of directors. OpenAI’s six-person board was whittled down to an interim board of three: \nBret Taylor, a former Salesforce and Facebook executive, joined as a board chairman helping to appoint a new set \nof directors. Lawrence H. Summers, the former Treasury Secretary, also joined. Mr. D’Angelo remains on the \nboard.\nIn October, Ms. Murati approached some members of the board and expressed concerns about Mr. Altman’s \nleadership, the people said.\nShe described what some considered to be Mr. Altman’s playbook, which included manipulating executives to get \nwhat he wanted. First, Ms. Murati said Mr. Altman would tell people what they wanted to hear to charm them and \nsupport his decisions. If they did not go along with his plans or if it took too long for them to make a decision, he \nwould then try to undermine the credibility of people who challenged him, the people said.\nKey OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nMs. Murati told the board she had previously sent a private memo to Mr. Altman outlining some of her concerns with \nhis behavior and shared some details of the memo with the board, the people said.\nAround the same time in October, Dr. Sutskever approached members of the board and expressed similar issues \nabout Mr. Altman, the people said.\nSome members of the board were concerned that Ms. Murati and Dr. Sutskever would leave the company if Mr. \nAltman’s behavior was not addressed. They also grew concerned the company would see an exodus of talent if top \nlieutenants left.\nThere were other factors that went into the decision. Some members were concerned about the creation of the \nOpenAI Startup Fund, a venture fund started by Mr. Altman. Unlike a typical company investment fund, which is a \nlegal extension of the corporation, Mr. Altman held legal ownership for the OpenAI fund and raised money from \noutside limited partners. OpenAI said that the structure was temporary, and that Mr. Altman would not receive \nfinancial benefit from it.\nThe OpenAI fund used that money to invest in other artificial intelligence start-ups. Some members of the board \ngrew concerned that Mr. Altman used the fund to skirt accountability from OpenAI’s nonprofit governance structure. \nThey confronted Mr. Altman about his legal ownership and operational control over the fund last year.\nAxios has previously reported on Mr. Altman’s control of the OpenAI fund.\nMembers of the board began discussing their next steps after they were approached by Ms. Murati and Dr. \nSutskever. By mid-November, the board planned to name Ms. Murati as interim chief executive while conducting a \nsearch for a new C.E.O., the people said. The board ousted Mr. Altman on Nov. 17.\nIn the days after, Mr. Altman waged a public fight to regain his position, using a mix of public pressure and powerful \nallies in Silicon Valley to push for his reinstatement. Most of OpenAI’s 770 employees threatened to quit if he were \nnot reinstalled as chief executive. Ms. Murati and Dr. Sutskever quickly — and publicly — said they supported Mr. \nAltman’s return to the company. Dr. Sutskever has not returned to his regular duties at the company, some of the \npeople said.\nAfter five days of public back and forth, Mr. Altman returned to his job.\nPHOTOS: Mira Murati, OpenAI’s chief technology officer, had concerns about the management of Sam Altman, the \ncompany’s chief executive. The ouster of Mr. Altman, shown at a congressional hearing last year, created days of \nchaos at OpenAI. (PHOTOGRAPHS BY JIM WILSON/THE NEW YORK TIMES; HAIYUN JIANG/THE NEW YORK \nTIMES) This article appeared in print on page B1, B3.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "Shift_Nov2023",
        "header": "How Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall; The",
        "media": "Shift",
        "time": "November 20, 2023",
        "section": "TECHNOLOGY",
        "length": "1186 words",
        "byline": "Kevin Roose",
        "story_text": "How Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall; The \nShift\nThe New York Times \nAugust 24, 2023 Thursday 18:13 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1186 words\nByline: Kevin Roose\nHighlight: Step 1: Assume all students are going to use the technology.\nBody\nStep 1: Assume all students are going to use the technology.\nLast November, when ChatGPT was released, many schools felt as if they’d been hit by an asteroid.\nIn the middle of an academic year, with no warning, teachers were forced to confront the new, alien-seeming \ntechnology, which allowed students to write college-level essays, solve challenging problem sets and ace \nstandardized tests.\nSome schools responded — unwisely, I argued at the time — by banning ChatGPT and tools like it. But those bans \ndidn’t work, in part because students could simply use the tools on their phones and home computers. And as the \nyear went on, many of the schools that restricted the use of generative A.I. — as the category that includes \nChatGPT, Bing, Bard and other tools is called — quietly rolled back their bans.\nAhead of this school year, I talked with numerous K-12 teachers, school administrators and university faculty \nmembers about their thoughts on A.I. now. There is a lot of confusion and panic, but also a fair bit of curiosity and \nexcitement. Mainly, educators want to know: How do we actually use this stuff to help students learn, rather than \njust try to catch them cheating?\nI’m a tech columnist, not a teacher, and I don’t have all the answers, especially when it comes to the long-term \neffects of A.I. on education. But I can offer some basic, short-term advice for schools trying to figure out how to \nhandle generative A.I. this fall.\nFirst, I encourage educators — especially in high schools and colleges — to assume that 100 percent of their \nstudents are using ChatGPT and other generative A.I. tools on every assignment, in every subject, unless they’re \nbeing physically supervised inside a school building.\nAt most schools, this won’t be completely true. Some students won’t use A.I. because they have moral qualms \nabout it, because it’s not helpful for their specific assignments, because they lack access to the tools or because \nthey’re afraid of getting caught.\nBut the assumption that everyone is using A.I. outside class may be closer to the truth than many educators realize. \n(“You have no idea how much we’re using ChatGPT,” read the title of a recent essay by a Columbia undergraduate \nin The Chronicle of Higher Education.) And it’s a helpful shortcut for teachers trying to figure out how to adapt their \nteaching methods. Why would you assign a take-home exam, or an essay on “Jane Eyre,” if everyone in class — \nexcept, perhaps, the most strait-laced rule followers — will use A.I. to finish it? Why wouldn’t you switch to \nHow Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall The Shift\nproctored exams, blue-book essays and in-class group work, if you knew that ChatGPT was as ubiquitous as \nInstagram and Snapchat among your students?\nSecond, schools should stop relying on A.I. detector programs to catch cheaters. There are dozens of these tools \non the market now, all claiming to spot writing that was generated with A.I., and none of them work reliably well. \nThey generate lots of false positives, and can be easily fooled by techniques like paraphrasing. Don’t believe me? \nAsk OpenAI, the maker of ChatGPT, which discontinued its A.I. writing detector this year because of a “low rate of \naccuracy.”\nIt’s possible that in the future, A.I. companies may be able to label their models’ outputs to make them easier to \nspot — a practice known as “watermarking” — or that better A.I. detection tools may emerge. But for now, most A.I. \ntext should be considered undetectable, and schools should spend their time (and technology budgets) elsewhere.\nMy third piece of advice — and the one that may get me the most angry emails from teachers — is that teachers \nshould focus less on warning students about the shortcomings of generative A.I. than on figuring out what the \ntechnology does well.\nLast year, many schools tried to scare students away from using A.I. by telling them that tools like ChatGPT are \nunreliable, prone to spitting out nonsensical answers and generic-sounding prose. These criticisms, while true of \nearly A.I. chatbots, are less true of today’s upgraded models, and clever students are figuring out how to get better \nresults by giving the models more sophisticated prompts.\nAs a result, students at many schools are racing ahead of their instructors when it comes to understanding what \ngenerative A.I. can do, if used correctly. And the warnings about flawed A.I. systems issued last year may ring \nhollow this year, now that GPT-4 is capable of getting passing grades at Harvard.\nAlex Kotran, the chief executive of the AI Education Project, a nonprofit that helps schools adopt A.I., told me that \nteachers needed to spend time using generative A.I. themselves to appreciate how useful it could be — and how \nquickly it was improving.\n“For most people, ChatGPT is still a party trick,” he said. “If you don’t really appreciate how profound of a tool this \nis, you’re not going to take all the other steps that are going to be required.”\nThere are resources for educators who want to bone up on A.I. in a hurry. Mr. Kotran’s organization has a number \nof A.I.-focused lesson plans available for teachers, as does the International Society for Technology in Education. \nSome teachers have also begun assembling recommendations for their peers, such as a website made by faculty \nat Gettysburg College that provides practical advice on generative A.I. for professors.\nIn my experience, though, there is no substitute for hands-on experience. So I’d advise teachers to start \nexperimenting with ChatGPT and other generative A.I. tools themselves, with the goal of getting as fluent in the \ntechnology as many of their students already are.\nMy last piece of advice for schools that are flummoxed by generative A.I. is this: Treat this year — the first full \nacademic year of the post-ChatGPT era — as a learning experience, and don’t expect to get everything right.\nThere are many ways A.I. could reshape the classroom. Ethan Mollick, a professor at the University of \nPennsylvania’s Wharton School, thinks the technology will lead more teachers to adopt a “flipped classroom” — \nhaving students learn material outside class and practice it in class — which has the advantage of being more \nresistant to A.I. cheating. Other educators I spoke with said they were experimenting with turning generative A.I. \ninto a classroom collaborator, or a way for students to practice their skills at home with the help of a personalized \nA.I. tutor.\nSome of these experiments won’t work. Some will. That’s OK. We’re all still adjusting to this strange new \ntechnology in our midst, and the occasional stumble is to be expected.\nHow Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall The Shift\nBut students need guidance when it comes to generative A.I., and schools that treat it as a passing fad — or an \nenemy to be vanquished — will miss an opportunity to help them.\n“A lot of stuff’s going to break,” Mr. Mollick said. “And so we have to decide what we’re doing, rather than fighting a \nretreat against the A.I.”\nPHOTO: A coding event in May at Dearborn STEM Academy in Boston. Educators are trying to figure out how to \nhelp students learn with generative (PHOTOGRAPH BY A.I. SOPHIE PARK FOR THE NEW YORK TIMES) (B3) \nThis article appeared in print on page B1, B3.\nLoad-Date: November 20, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "MS GitHub has 13m Indian Developers, to Pip US by 2027",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 8, 2024",
        "section": "STARTUPS & TECH",
        "length": "570 words",
        "byline": "Our Bureau",
        "story_text": "MS GitHub has 13m Indian Developers, to Pip US by 2027\nEconomic Times (E-Paper Edition)\nFebruary 9, 2024 Friday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 570 words\nByline: Our Bureau\nHighlight: CEO Nadella highlights Indian developers’ impact in building cutting-edge products\nBody\nBengaluru: India is the fastest growing market for Microsoft’s GitHub, an internet hosting service for software \ndevelopment platforms, and is expected to overtake the US to have the largest developer community on it by 2027, \nthe tech major’s chairman and chief executive, Satya Nadella, said on Thursday. In India, 13.2 million developers \ncurrently use GitHub, while in the US, that number is around 20 million. India also has the second highest number \nof generative artificial intelligence (genAI) projects on GitHub, after the US. \nNadella was in Bengaluru on Thursday, the second day of the Microsoft AI Tour. During his three-day India visit, he \nis showcasing AI-based Microsoft products, pushing for their wider adoption. Hyderabad-born Nadella completed 10 \nyears at Microsoft and is credited with turning around the company with his “mobile and cloud first” strategy. \nSpeaking to a room filled with more than 1,000 computer software developers, Nadella highlighted the impact \nIndian developers are making in building cutting-edge products and solutions that solve challenges for the nation \nand accelerating deployment of AI innovation globally. Calling India’s developers “unstoppable” and momentum \n“unbelievable”, the Microsoft chief announced the expansion of the 'Code without Barriers' initiative to India this \nmonth. The programme was launched in 2021 across nine Asia-Pacific countries to help bridge the gender gap in \nthe region’s fast-growing cloud, AI, and digital technology sectors. It provides support, training, and networking \nopportunities for female developers and coders, and those in other technical roles. In India, it will support 75,000 \nfemale developers this year.   SARVAM AI  On Thursday, Nadella also announced a partnership with Sarvam AI for \nthe development of voice-based generative AI applications to make the Indian startup’s Indic voice large language \nmodel (LLM) available on Microsoft’s cloud computing platform Azure. Sarvam AI is building genAI models targeting \nIndic languages and context, and will now create its solutions on Microsoft's cloud services including Azure OpenAI \nService. Sarvam AI is cofounded by Vivek Raghavan, who was the technology advisor with Nandan Nilekani-led \ngovernment project Unique Identification Authority of India (UIDAI). Its other partnerships announced on Thursday \ninclude those with Persistent Systems and Open Healthcare Network, working towards innovating India’s \nhealthcare systems, and with Shiksha Copilot, developed by the Sikshana Foundation and Microsoft Research \nIndia, to power Azure OpenAI models to improve learning outcomes and empower teachers. Shiksha Copilot is \ncurrently deployed in about 30 rural and urban schools in Bengaluru. In January, Microsoft enabled 100,000 \ndevelopers to advance their careers in AI through its AI Odyssey initiative. With an “overwhelming” response in \nIndia, Microsoft is expanding the programme to other Asia-Pacific countries, including Australia, New Zealand, \nJapan, Indonesia, South Korea, China, Vietnam and Thailand, Microsoft said in a news release. The programme \nwill also welcome Indian developers who could not participate in the AI Odyssey challenge in January. Phase-2 of \nAI Odyssey will run from February 8 to June 25, aiming to reach 150,000 developers across Asia. In Mumbai on \nWednesday, Nadella announced an initiative to provide 2 million Indians with AI skilling opportunities by 2025.\nMS GitHub has 13m Indian Developers, to Pip US by 2027\nLoad-Date: February 8, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Dec2023",
        "header": "Meet Cos Racing OpenAI in Global LLM Marathon",
        "media": "Economic Times (E-Paper Edition)",
        "time": "December 27, 2023",
        "section": "STARTUPS & TECH",
        "length": "340 words",
        "byline": "Himanshi Lohchab",
        "story_text": "Meet Cos Racing OpenAI in Global LLM Marathon\nEconomic Times (E-Paper Edition)\nDecember 28, 2023 Thursday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 340 words\nByline: Himanshi Lohchab\nHighlight: MANY ROADS TO ROME How different geographies are contributing to the global GenAI revolution\nBody\nEXPLAINER EXPLAINER\nMumbai:It’s not just the US which is leading the race for releasing generative AI large language models (LLMs). \nOrganisations across China, Korea, Singapore, Japan, France, India and the UAE have built LLMs trained on their \nnative languages, outperforming several performance benchmarks set by OpenAI’s ChatGPT, Meta’s LlaMa, \nGoogle’s Gemini, and several other popularly known models. ET curates an explainer on how different geographies \nare contributing to GenAI innovation.ChinaChina is in a neck-to-neck competition with US in terms of the number of \nmodels it releases. According to Beijing’s ministry of science and technology, Chinese organisations released 2 \nLLMs compared with 11 in the US in 2020. In 2021, this figure was 30 each for both countries. \nAnd, in 2023 China released 28 LLMs against the US’ 37. Some of China’s popular releases include DeepSeek, a \n67 billion parameter model trained on English and Chinese. E-commerce giant Alibaba  Group Holding’s research \nunit Damo Academy launched the Southeast Asia LLM (SeaLLM) trained on Vietnamese, Indonesian, Thai, Malay, \nKhmer, Lao, Tagalog, and Burmese data sets. SingaporeSingapore anchored the SEALION (Southeast Asian \nLanguages In One Network) family of LLMs that are pre-trained for the Southeast Asian (SEA) region. Currently, \nSEA-LION has two SLMs in 3-billion and 7-billion parameters. Following this initiative, Singapore’s telecom and \nmedia regulator IMDA, its ministry of science and other agencies announced a sum of SGD $70 million ($52.3 \nmillion) to be invested on multimodal AI research. KoreaNaver Corp, South Korea’s online giant, debuted in the \nLLM space with launch of its humongous 204-billion parameter LLM HyperCLOVA X trained with news articles \npublished over the past five decades and blog data accumulated over nine years.UAEThe Technology Innovation \nInstitute, an Emirati research centre in Abu Dhabi, released the Falcon 180B, after unveiling Noor last year, which \nwas the world's first Arabic model.himanshilohchab@timesgroup.com\nLoad-Date: December 27, 2023"
    },
    {
        "file_name": "Newsletter_May2023",
        "header": "Markets Expect the Fed to Raise Rates Despite Banking Turmoil; DealBook",
        "media": "Newsletter",
        "time": "May 4, 2023",
        "section": "BUSINESS",
        "length": "1908 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced and Lauren",
        "story_text": "Markets Expect the Fed to Raise Rates Despite Banking Turmoil; DealBook \nNewsletter\nThe New York Times \nMay 3, 2023 Wednesday 19:39 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1908 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced and Lauren \nHirsch\nHighlight: A ‘shock pause’ by the central bank would spook an already jittery market, one analyst said, even as \nshares in regional lenders fall.\nBody\nA ‘shock pause’ by the central bank would spook an already jittery market, one analyst said, even as shares in \nregional lenders fall.\nBanks in focus as the Fed weighs its rates move \nIf market predictions are correct, the Fed on Wednesday will raise borrowing costs by a quarter of a percentage \npoint, even as growing turmoil in the stocks of regional banks threatens to choke off credit to businesses and \nconsumers, pushing the economy into recession.\nThe decision comes amid a brutal sell-off in regional banks’ shares, which has wiped billions off smaller lenders’ \nmarket valuations. Investors have been worried about the health of these banks since March, when Silicon Valley \nBank collapsed in one of the most prominent bank failures in U.S. history.\nRegulators had hoped that the sale of the embattled First Republic Bank to JPMorgan Chase this week would \ncontain the panic. But short sellers, investors who profit off bets that stock prices will fall, have continued to take \naim at regional lenders like PacWest, Western Alliance and Zions Bancorp. (Shares in PacWest and Western \nAlliance are down again in premarket trading.)\nThe market carnage could result in more pain for regional banks. Falling prices may cause C.F.O.s to say, “‘You \nknow what, maybe I should think about diversification and moving my funding’” out of these lenders, Ryan Nash, a \nresearch director at Goldman Sachs, said in a webinar on Tuesday.\nHe added that while “most of the large failures are likely behind us, I do think there is a risk that pressure on stock \nprices could reinvigorate” worries about the sector’s health.\nMeanwhile, the Fed faces political pressure. Ten progressive lawmakers, including Senators Elizabeth Warren and \nBernie Sanders, urged the central bank to pause its rate hikes to “avoid engineering a recession that destroys jobs \nand crushes small businesses.”\nThe lawmakers cautioned Jay Powell, the Fed chair, that raising borrowing prices could further compound trouble \nfor beleaguered banks.\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nNone of this is likely to deter the Fed from raising rates on Wednesday, analysts said. Indeed, a “shock pause” \nwould “do more harm than good” by spooking an already jittery market, according to Elsa Lignos, the global head of \nFX strategy at RBC Capital Markets.\nBut economists increasingly believe that Wednesday’s increase will be the last in this tightening cycle. Watch what \nMr. Powell says about upcoming Fed meetings: If he suggests that the central bank needs to remain hawkish on \nrates to fight inflation, that could send stocks — especially those of regional banks — especially hard.\nMs. Lignos advised paying attention to what Mr. Powell says about whether “additional policy firming may be \nappropriate,” a line of guidance he used after the March meeting: If that wording is softened or deleted altogether, \nshe said, it may indicate a dovish turn by the Fed.\nHERE’S WHAT’S HAPPENING \nElon Musk threatens to give away NPR’s Twitter account. In an email exchange with a reporter at the news outlet, \nMr. Musk wrote that he could give the @NPR handle to “another company” if the broadcaster did not start tweeting \nagain. NPR stopped posting on Twitter in protest last month after the platform labeled it “state-controlled.”\nHouse Democrats work on a long-shot plan to avert a U.S. default. It involves a so-called discharge petition that \nwould bypass Speaker Kevin McCarthy but would require Democrats to win over some Republicans. Meanwhile, \nthe White House is debating whether to pursue what is effectively a constitutional challenge that would let it \nsidestep Congress and raise the debt limit.\nHoward Schultz’s final quarter is a success. The coffee chain reported better-than-expected earnings for the first \nthree months of the year, during which Mr. Schultz handed over the C.E.O. title to Laxman Narasimhan. The \ncompany benefited from a surge in sales there after Covid-19 restrictions were lifted; however, Starbucks shares \nwere down 5 percent in premarket trading after it kept its guidance for the second half of 2023 unchanged.\nDonald Trump ends a boycott of CNN. The former president is set to participate in a town-hall-style meeting on May \n10 organized by the news network. His appearance may be a sign that the Republican presidential candidate, who \nhasn’t appeared on CNN since 2016, may be broadening his media profile beyond Fox News and other \nconservative channels.\nLate night shows go dark on the first day of a writers’ strike. “The Tonight Show Starring Jimmy Fallon” was a \nrepeat on Tuesday, and new episodes of shows hosted by Stephen Colbert and Jimmy Kimmel have been \nsuspended as movie and TV writers hit the picket lines. Unlike in the 1990s, late-night stars have publicly signaled \nsupport for the unions.\nHindenburg turns the tables on Icahn \nOver nearly a half-century, Carl Icahn has shaken up Wall Street as a corporate raider and activist shareholder, \nmaking corporate titans bow down to his demands and change strategy.\nBut Tuesday, his publicly traded company became a target of Hindenburg Research, the short-seller firm that has \nmade its name in recent years by taking on the Indian tycoon Gautam Adani and the Twitter co-founder Jack \nDorsey.\nHindenburg accused Mr. Icahn Enterprises of being overvalued. The company trades well above its net asset value, \nunlike similar financial vehicles run by Bill Ackman and Dan Loeb. Hindenburg also called out what it said was an \nunjustifiably hefty dividend being financed by stock sales.\n“Icahn has been using money taken in from new investors to pay out dividends to old investors,” the firm wrote in a \npublic report. (Hindenburg is betting that Icahn Enterprises’s shares will fall; the company’s stock tumbled 20 \npercent on Tuesday.)\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nHindenburg also called out Jefferies, which it said was the only large investment bank to publish research on Icahn \nEnterprises — and also helps the company sell stock.\nMr. Icahn punched back. “We believe the self-serving short seller report published by Hindenburg Research today \nwas intended solely to generate profits on Hindenburg’s short position at the expense of I.E.P.’s long-term unit \nholders,” the company said in a statement, adding that it stands by its disclosures.\nHindenburg got one prominent endorser: Mr. Ackman. The hedge fund mogul memorably clashed with Mr. Icahn \nover the prospects of Herbalife, the supplements company that Ackman had shorted. (Remember the verbal brawl \nbetween the two on CNBC that gripped Wall Street?)\nThey made peace — but time may not have healed all wounds. “There is a karmic quality to this short report that \nreinforces the notion of a circle of life and death,” Mr. Ackman tweeted of Hindenburg’s report. “As such, it is a must \nread.”\nArtificial intelligence 101 \nShares in education companies plunged on Tuesday, after Dan Rosensweig, the C.E.O. of Chegg, warned that \nChatGPT was cannibalizing growth. The sell-off was one of the biggest indications yet of how companies may \nstruggle to protect their legacy businesses from a powerful new crop of artificial intelligence tools that have captured \nthe public’s imagination.\nChatGPT began hitting Chegg’s business in March, Rosensweig told analysts on an earnings call this week. It was \namong the first times a C.E.O. offered a candid take on the chatbot’s potential financial toll on a company. “We now \nbelieve it’s having an impact on our new customer growth rate,” he said.\nThe comments spooked investors. Chegg’s stock fell more than 48 percent on Tuesday, and shares in other \neducation companies also tumbled: The London-listed Pearson slid 15 percent, and the language learning platform \nDuolingo dropped 10 percent.\nRosensweig called the sell-off “extraordinarily overblown” in an interview afterward with CNBC, comments that \nhelped shares regain some lost ground.\nThe market impact is only a hint of the disruption A.I. will cause. “These swings in share price demonstrate that \nmarkets haven’t started to price in the effect of breakthroughs in generative A.I. — even in the sector where its \nimpact is the most apparent,” Nathan Benaich, founder of the A.I.-focused investment firm Air Street Capital and an \nauthor of the State of A.I. Report, who told DealBook that “education businesses will only be the first dominoes to \nfall.”\nIn other A.I. news:\n• Lina Khan, the chair of the Federal Trade Commission, outlines her vision for regulating A.I. in a Times \nOpinion guest essay: “Although these tools are novel, they are not exempt from existing rules,” she writes.\n• Inflection AI, a start-up created by the LinkedIn co-founder Reid Hoffman and Mustafa Suleyman, a co-\nfounder of Google DeepMind, introduced Pi, a chatbot that is intended to be more conversational than rival \nofferings like ChatGPT and Google’s Bard.\n• Cohere, a Toronto-based A.I. start-up, raised $250 million at a valuation of about $2 billion. Backers included \nthe tech giants Salesforce and Nvidia.\n‘It’s not how white men fight’ \nMore details are emerging about what may have ultimately led to Tucker Carlson’s firing at Fox News last week: \nThe New York Times reports that the evidence uncovered during the discovery phase of the Dominion Voting \nSystems defamation lawsuit against the media company included a particularly inflammatory text message that the \ntelevision host had sent to a producer hours after the Jan. 6 riot at the Capitol.\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nFrom Carlson’s text message:\nJumping a guy like that is dishonorable obviously. It’s not how white men fight. Yet suddenly I found myself rooting \nfor the mob against the man, hoping they’d hit him harder, kill him. I really wanted them to hurt the kid. I could taste \nit.\nThen somewhere deep in my brain, an alarm went off: this isn’t good for me. I’m becoming something I don’t want \nto be. The Antifa creep is a human being. Much as I despise what he says and does, much as I’m sure I’d hate him \npersonally if I knew him, I shouldn’t gloat over his suffering.\nThe Fox board learned of the text only the day before the Dominion trial was set to begin, and told top executives \nthat it would hire the top-flight law firm Wachtell, Lipton, Rosen &amp; Katz to investigate Carlson. It isn’t clear how \nsignificant this particular message was to Fox’s decision-making — but within days, the company agreed to pay \n$787.5 million to settle Dominion’s lawsuit, and within a week, Carlson was out.\nTHE SPEED READ \nDeals\n• Inside the first days of Harvey Schwartz’s tenure as C.E.O. of Carlyle Group: lots of listening sessions, but no \ndrastic restructuring of the investment firm — yet. (FT)\n• Lilium, a German air-taxi start-up that went public via SPAC, plans to sell up to $250 million worth of stock to \nfinance development of its electric jet. (Reuters)\nPolicy\n• Morgan Stanley is in discussions to settle federal investigations into its block-trading business. (FT)\nBest of the rest\n• Shein, the fast-fashion giant, is embarking on a charm offensive to counter criticism of its ties to China and \naccusations of copycat designs ahead of a potential I.P.O. (NYT)\n• Anheuser-Busch InBev has reportedly promised free beer and more to Bud Light distributors to compensate \nfor blowback from an ad campaign featuring a transgender influencer. (WSJ)\n• “The true cost of our obsession with superfoods like avocado, açaí, and durian.” (Insider)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: There’s added political and market pressure on the Fed today ahead of its rates decision. \n(PHOTOGRAPH BY Leah Millis/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: May 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Amazon Has New Chatbot For Shoppers",
        "media": "The New York Times",
        "time": "February 2, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "880 words",
        "byline": "By Karen Weise",
        "story_text": "Amazon Has New Chatbot For Shoppers\nThe New York Times\nFebruary 2, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 880 words\nByline: By Karen Weise\nBody\nThe tech giant introduced the Rufus chatbot. It has lagged behind others on introducing consumer-facing \ngenerative artificial intelligence.\nAmazon entered the consumer chatbot fray on Thursday, announcing a new artificial intelligence personal shopping \nassistant as the company races to catch up with other tech giants. \n  Customers can ask the tool, Rufus, product questions directly in the search bar of the company's mobile app, \nAmazon said in a blog post. The A.I. will then provide answers in a conversational tone. The examples provided in \nthe announcement included comparing different kinds of coffee makers, recommendations for gifts and a follow-up \nquestion about the durability of running shoes.\n  Rufus will be available starting on Thursday to a ''small subset of customers,'' according to the post, and it will be \nrolled out to additional customers in the coming weeks. Amazon declined to provide more details about how many \npeople will be part of the tool's initial release.\n  Amazon allows its employees to bring their dogs to work, and a dog named Rufus was one of the first to roam its \noffices in the company's early days.\n  Amazon has been racing to shake off the perception that it is behind on the wave of A.I. tools unleashed more \nthan a year ago, when the start-up OpenAI released its ChatGPT chatbot. If customers find Rufus helpful and \npopular, Amazon could shake up the business of searching for products -- and control even more of the experience \nof shopping online.\n  Rufus ''lets customers discover items in a very different way than they have been able to on e-commerce \nwebsites,'' Andy Jassy, the company's chief executive, said on a call with investors. ''It's seamlessly integrated in \nthe Amazon experience that customers are used to and love to be able to take action,'' he said.\n  Microsoft and Google last spring released chatbots and A.I. tools for their search engines, often highlighting \nshopping-related uses, and start-ups like Perplexity have tried to redesign the search experience with A.I. in mind.\n  In the fall, Amazon released a corporate chatbot, called Q, for customers of its cloud computing division, and the \ncompany said it was working to make its Alexa voice assistant more conversational\n  Even without generative A.I., the Amazon search bar and the top results it produces are some of the most \nimportant placements in online retail. They have been the subject of antitrust inquiries, and the product ads in the \nsearch results are a foundation for the company's booming advertising business.\nAmazon Has New Chatbot For Shoppers\n  Consumers are more than twice as likely to search first on Amazon versus other search engines when they are \nlooking for a specific product to buy. But the e-commerce giant has long wanted to attract customers when they are \nstill brainstorming and researching their options, when they typically turn to other sources, from TikTok to Google. \nRufus is an attempt to bring customers into Amazon before they know precisely what they want.\n  ''You will still be able to search in the search bar if you are very clear with what you want,'' Brian Olsavsky, the \ncompany's finance chief, said in a call with journalists on Thursday. ''Rufus is more there to help you explore, and \nmaybe if you have more questions.''\n  ''It becomes more of a conversation with Amazon,'' he said.\n  The Rufus tool is ''trained on Amazon's extensive product catalog, customer reviews, community Q. and A.s, and \ninformation from across the web,'' the company said.\n  Mr. Jassy said during the earnings call that customers could ask Rufus for recommendations for the best golf ball \nto use for better spin control, or the best cold weather rain jackets ''and get thoughtful explanations for what matters \nand recommendations on products.''\n  If Rufus takes off, Amazon could take ad sales away from Google and social media sites, where companies try to \ninfluence what customers decide to buy.\n  Amazon itself is a prolific advertiser on Google and social media apps, trying to bring in customers earlier in their \nshopping process. Google, for its part, has tried for years to encroach on Amazon's turf too, starting several \nshopping initiatives to attract independent sellers, with little success.\n  Separately on Thursday, Amazon reported strong fourth-quarter earnings, fueled in part by the holiday season.\n  Sales in the quarter hit $170 billion, up 17 percent from a year earlier. The company had $10.6 billion in profits. \nThe results beat analysts' expectations and Amazon's own forecast.\n  The services the company provides to third-party sellers on its marketplace, including fulfillment and shipping, and \nthe advertisements it offers to brands and sellers experienced particularly strong quarters.\n  Investors have been keeping a close eye on Amazon's most profitable segments -- cloud computing and \nadvertising. Advertising grew 27 percent, to $14.7 billion, in sales, and Amazon Web Services grew 13 percent, to \n$24.2 billion, just meeting investor expectations.\n  Over the past year, the company cut tens of thousands of jobs, ended speculative projects, halted some \nexpansion plans and reorganized its logistics operations to be faster and more efficient. The company had its \nhighest ever quarterly operating income, and projected confidence that profitability would continue.\nhttps://www.nytimes.com/2024/02/01/technology/amazon-earnings.html\nGraphic\n \nPHOTO: People will be able to ask the new bot, Rufus, questions right from the search bar in the Amazon app. \n(PHOTOGRAPH BY AMAZON) (B4) This article appeared in print on page B1, B4.               \nLoad-Date: February 2, 2024"
    },
    {
        "file_name": "The_Economic_Times_Jul2023",
        "header": "SaaSBoomi slashes startups' enterprise value forecast for 2030 by 50%",
        "media": "The Economic Times",
        "time": "July 27, 2023",
        "section": "STARTUPS",
        "length": "557 words",
        "byline": "Supriya Roy",
        "story_text": "SaaSBoomi slashes startups' enterprise value forecast for 2030 by 50%\nThe Economic Times\nJuly 28, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 557 words\nByline: Supriya Roy\nBody\nSaaSBoomi, a collective of SaaS and product company founders, on Thursday marked down the 2030 enterprise \nvalue projections of Indian software-as-a-service (SaaS) startups from $1 trillion to $0.5 trillion, in its latest report on \nthe space.\"We have plotted a conservative projection of the market in the range of $0.5 trillion to $1 trillion. This is \ntaking into account current market conditions. Market contingencies may however be different in 2030, and \nenterprise values may recover fully and be better by then,\" Manav Garg, founder of Eka Software and Together \nFund, which is part of SaaSBoomi, told ET.In 2021, in its report titled 'Shaping India's SaaS Landscape', \nSaaSBoomi had said Indian SaaS companies can increase their revenues to $50-$70 billion by the end of the \ndecade, lending the industry a $1-trillion valuation based on public SaaS company revenue multiples.Also read | \nTogether unveils new fund worth $150 million, to back opportunities in Gen AI spaceDespite the fall in enterprise \nvalue, the revenue projection of $50-70 billion remained consistent in the latest report, released Thursday.Near-\nterm demand environments are likely to be tough, given the tightening of the US economy, an important go-to \nmarket for SaaS companies, the report said.Enterprise-value corrections or projections rely on public market \nvaluations. \nGlobal private equity and venture capital software investments have been on the decline quarter on quarter since \nthe first quarter of 2021. Economic shocks have hit the US, led by a 4-fold rise in interest rates to 4.3% in 2023 from \n0.5% in 2020.On a brighter note, Indian SaaS companies, the report added, currently account for 2% of the global \nsoftware-as-a-service (SaaS) market, with $7 billion in revenues, far exceeding earlier projections. The total \nrevenue figure stood at $2.6 billion in 2020, indicating a 169% jump since then.Also read | Indian SaaS in the \nmiddle of a great reset in funding winterThere has been similar growth globally, the report said. In the last two \nyears, the global SaaS market has expanded to about $420 billion, growing at a 38% compound annual growth \nrate, exceeding earlier growth projections for 2022 by nearly 150%.Revenues globally are likely to reach $1.3-1.6 \ntrillion by 2030, representing a growth of 15-18% per year between 2022 and 2030.Key opportunity in Gen \nAIAmong 'watershed moments' for SaaS, the report said that the software industry is on the cusp of a significant \nparadigm shift, moving from SaaS to 'SaaS.AI'. This, it said, was triggered by the performance of Generative \nArtificial Intelligence (Gen AI). \"We are witnessing an explosion in the number of Gen AI-native SaaS companies \nand a surge in investment capital, with over $12 billion funnelled into 60+ emerging domains in FY23,\" it added.Also \nread | '2026 revenue forecast for SaaS startups plunges 74% to $26 billion'In India, the number of startups in the \nGen AI segment has more than doubled since 2021 and raised over $590 million as of May 2023.Four distinct \nstrategies can be deployed by founders in India to leverage the structural advantages of this uptake, the report \nadded: focusing on AI-first SaaS domains, transforming core workflows with Gen AI, launching developer-centric \ntools around Gen AI, and building new foundational models. For Reprint Rights: timescontent.com\nLoad-Date: July 27, 2023\nSaaSBoomi slashes startups' enterprise value forecast for 2030 by 50%"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "BUSINESS",
        "length": "1135 words",
        "byline": "Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is",
        "story_text": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nThe New York Times \nMarch 4, 2024 Monday 12:48 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1135 words\nByline: Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is \nbased in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nAdam Satariano is a technology correspondent based in Europe, where his work focuses on digital policy and the \nintersection of technology and world affairs.\nHighlight: Apple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nBody\nApple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nApple on Monday was fined 1.8 billion euros ($1.95 billion) by European Union regulators for thwarting competition \namong music streaming rivals, a severe punishment levied against the tech giant in a long-simmering battle over \nthe powerful role it plays as gatekeeper of the App Store.\nThe penalty, announced by the E.U. antitrust regulator, is the culmination of a five-year investigation set in motion \nby one of its biggest rivals, Spotify. Regulators said Apple illegally used its App Store dominance to box out rivals.\n“For a decade, Apple abused its dominant position in the market for the distribution of music streaming apps \nthrough the App Store,” said Margrethe Vestager, the European Commission executive vice president who \noversees competition policy.\n“From now on,” she said in a news conference, “Apple will have to allow music streaming developers to \ncommunicate freely with their own users.” The size of the fine, she added, “reflects both Apple’s financial power and \nthe harm that Apple’s conduct inflicted on millions of European users.”\nThe action by the European Commission, the E.U. executive branch, is the latest in a series of regulations and \npenalties to target the App Store. Most of the disputes are because Apple requires that apps use its in-app payment \nservice for sales. It takes as much as a 30 percent commission on each transaction, a fee that many developers \nsay is excessive.\nRegulators in the Netherlands and South Korea have passed laws or orders to force Apple to allow alternative \npayment services, but Apple has largely disregarded the regulators’ challenges. In those countries  it is allowing \nalternatives but charging a 27 percent commission, a solution that regulators in the countries are contesting.\nApple said it would appeal the ruling. “While we respect the European Commission, the facts simply don’t support \nthis decision,” Apple said in a statement on Monday.\nIn a briefing last month, Apple said that European regulators had been searching for a legal theory for the case for \nnearly a decade, in fits and starts. Apple challenged the idea that Spotify users haven’t been able to subscribe to \nmusic services through other means, saying that Spotify has added more than 100 million subscribers outside its \napp over the past eight years.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nApple also accused Spotify of being a monopolist because it has more than a 50 percent share of Europe’s music \nstreaming business. It said that Spotify has benefited from the software tools that Apple provides, as well as more \nthan 119 billion downloads and updates of its app. It’s done so while not paying Apple any money in commissions.\n“Fundamentally, their complaint is about trying to get limitless access to all of Apple’s tools without paying anything \nfor the value Apple provides,” a spokesman said in a statement.\nSpotify, in a statement, said Monday’s penalty “sends a powerful message — no company, not even a monopoly \nlike Apple, can wield power abusively to control how other companies interact with their customers.” \nThe penalty reinforces the European Union’s position as the world’s most aggressive regulator of the tech sector. In \nrecent years, the bloc has passed laws on data privacy, industry competition, content moderation of online content \nand artificial intelligence. Antitrust regulators have meanwhile investigated or fined Google, Amazon, Microsoft and \nMeta.\nThe fine is the most severe penalty against Apple since 2016, when the European Commission ordered the \ncompany to turn over €13 billion for unpaid taxes to Ireland. In a sign of how long the appeal process can drag out, \nthat case is still winding its way through E.U. courts.\nIn 2022, the 27-nation bloc largely sided with developers in writing the Digital Markets Act that requires Apple to \nopen the iPhone to competing app stores and allow app makers to directly accept payments. The rules go into \neffect Thursday.\nIn its latest quarter, Apple reported revenue of about $120 billion and a net profit of $34 billion.\nLast month, Apple said that it would comply with the new law by giving developers three options. They could stick \nwith the status quo App Store system and continue paying up to a 30 percent commission of sales. Or they could \naccept alternative payments and reduce their commission to 17 percent, while taking on a new charge of 50 euro \ncents on every download above one million. Finally, they could avoid Apple’s commission and distribute through \ncompeting stores, while still paying Apple’s download fee.\nUnder Apple’s plan, Spotify and other apps would be able to tell customers in their app about cheaper subscription \nprices online. \nApple’s proposal for the App Store in Europe has sparked an outcry from developers large and small, who say that \nit fails to abide by both the letter and spirit of the law.\nApple has said that its plan complies with the law, while minimizing the risk iPhone users encounter malware, spam \nor fraud.\nSpotify has been one of Apple’s most vocal critics. For years, the music streaming service has complained that the \nApp Store’s in-app payment system and 30 percent commission has put it at a disadvantage to Apple Music, which \ncan sell subscriptions directly without a similar fee.\nThe rules have also hampered Spotify’s efforts to expand its business into audiobooks and other services. Instead \nof charging for a book in the app, it has tried to avoid Apple’s fees by directing customers outside the app to pay, a \nprocess that it has called cumbersome and difficult.\nApple says that Spotify’s decision to link to its website means that it doesn’t pay for many of the services that \nbenefit the music streaming service, including software tools and hardware improvements like advanced media \nplayback. It also complained that Spotify met with European regulators more than 60 times during the course of the \ninvestigation.\nDaniel Ek, Spotify’s chief executive, has complained for years about the slow pace of Europe’s investigation. \nThroughout the process, he pointed out ways that Apple’s control over the App Store disadvantaged competitors.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\n“Without policymakers taking action, nothing will change,” Mr. Ek wrote in 2022 on X, the site formerly known as \nTwitter. “I can’t be the only one who sees the absurdity.”\nMonika Pronczuk contributed reporting from Brussels.\nMonika Pronczuk contributed reporting from Brussels. \nPHOTOS: The Digital Markets Act requires Apple to open the iPhone to competing app stores and allow direct \npayments. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES); Apple “abused its \ndominant position in the market,” said Margrethe Vestager, an executive vice president. (PHOTOGRAPH BY \nOLIVIER HOSLET/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in print on page B1, B4.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "New_York_Observer_Jul2023",
        "header": "Salesforce CEO Marc Benioff on AI: 'None of Us Are Ready'",
        "media": "New York Observer",
        "time": "July 27, 2023",
        "section": "",
        "length": "520 words",
        "byline": "Rachyl Jones",
        "story_text": "Salesforce CEO Marc Benioff on AI: 'None of Us Are Ready'\nNew York Observer\nJuly 25, 2023 Tuesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 520 words\nByline: Rachyl Jones\nBody\nAccording to Salesforce CEO Marc Benioff, artificial intelligence isn't \"just the most important technology of our \nlifetime, but probably the most important in any lifetime,\" he said in an interview with the Associated Press.\nAn active voice in the AI space, Benioff has taken the stance that AI can be helpful but dangerous. Consumers \nhave only experienced phase one of what AI can be, Benioff told the AP. On the future of AI, he said, \"None of us \nare really ready for this because none of us have had this experience before.\"\nPreviously, Benioff has spoken about the tendency for generative AI to lie and for large language models to \nplagiarize. He has voiced privacy concerns regarding consumers' personal information that becomes part of an AI \nmodel. But, despite his criticisms, Benioff believes AI can be a significant aid to Salesforce clients.\nSalesforce provides tools to help sellers manage their relationships with consumers. Its products help companies \ntrack sales, automate marketing and perform customer service, among other tasks. One of the largest tech \ncompanies in the world, Salesforce is valued at $221 billion, which is more than IBM but less than Microsoft.\nSalesforce isn't new to the AI race. It first launched Einstein, its AI service embedded into Salesforce products, in \nSeptember 2016-six years before the launch of ChatGPT made artificial intelligence a hot topic. The product \nallowed Salesforce clients to predict actions from their customers and create personalized marketing messages. \nEarlier this year, it announced Einstein GPT, a chatbot that can help companies find potential customers, write \nemails, compile data and more. Salesforce also launched AI Cloud, which further integrates generative AI into \nSalesforce products. The company is building AI Cloud technology into Slack, the messaging platform for \nbusinesses Salesforce acquired in 2020.\nBenioff's opinions on artificial intelligence are in line with those of other tech CEOs. Elon Musk, Apple co-founder \nSteve Wozniak, AI researcher Gary Marcus and other industry experts acknowledge the dangers of AI, going so far \nas to sign a letter calling for a pause on AI developments to introduce safety measures. Others signed an open \nletter warning that AI could lead to extinction, without other context. Signees include OpenAI CEO Sam Altman, \nMicrosoft chief technology officer Kevin Scott and Anthropic CEO Dario Amodei.\nSalesforce is coming off a period of major internal changes. In November 2022, Bret Taylor, who served as co-CEO \nalongside Benioff, left Salesforce to start a new company. At the turn of the year, Salesforce laid off 7,800 \nemployees, or 10 percent of its staff. Benioff said he hired too many workers during the pandemic, which caused \nthe cuts. Other tech companies, including Meta, cited over-hiring as the reason for their layoffs as well.\nThis month, the company's stock is trading at a one-year high, today worth $227 per share. The price is more than \nfive times what the stock sold for a decade ago. At its peak in November 2021, when many tech stocks reached \ntheir highs, Salesforce traded at $307 per share.\nSalesforce CEO Marc Benioff on AI: 'None of Us Are Ready'\nLoad-Date: July 27, 2023"
    },
    {
        "file_name": "AI_space_Jul2023",
        "header": "Together unveils new fund worth $150 million, to back opportunities in Gen",
        "media": "AI space",
        "time": "July 27, 2023",
        "section": "STARTUPS",
        "length": "673 words",
        "byline": "Tarush Bhalla",
        "story_text": "Together unveils new fund worth $150 million, to back opportunities in Gen \nAI space\nThe Economic Times\nJuly 28, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 673 words\nByline: Tarush Bhalla\nBody\nTogether Fund, led by Freshworks founder Girish Mathrubootham and Eka Software founder Manav Garg, has \nannounced its second fund worth $150 million to continue backing opportunities in the Indian software-as-a-service \n(SaaS) and artificial intelligence (AI) space. The total corpus for Together's Fund II is almost double that of the \nprevious one, as it looks to make larger follow-on investments and back local disruptors in the generative AI space. \nIt has also marked a first close of the second fund, raising the corpus from endowments and sovereign funds across \nthe US and Asia. Garg, Together's founding partner, declined to comment on the total corpus raised as a part of the \nfirst close. The founder-led venture investor looks to back SaaS startups across themes of cybersecurity, devtools \nand healthcare, apart from AI, with the new fund. \nLaunched in 2021 with a corpus of $85 million, Together was founded with the aim of backing the next set of \nproduct SaaS startups building for global geographies. Almost 33% of the total corpus of the first fund was raised \nfrom institutional investors, with the rest coming from startup entrepreneurs and operators. However, unlike its \ndebut fund, almost 95% of the corpus will now be raised from institutional capital, Garg added. The venture backer \nplans to start deploying the capital from Fund II starting the first quarter of calendar year 2024. It looks to make a \nfinal close for the latest fund in the next nine months. \"The opportunity for SaaS has expanded from focusing only \non Fortune 500 companies to now building for 5 million SMBs (small and medium businesses, and with AI there is \nonly going to be an increase in software utilisation,\" Garg told ET in an interaction. \"The reason for a larger corpus \nis because AI has come into the investing mix and we also wanted to invest more in follow-on rounds to help our \ncompanies grow further,\" he added. While Together will continue its pace of backing 20-25 companies across seed \nto Series A rounds with its second fund, it may look to make follow-on investments in portfolio startups until Series \nC and write cheque sizes worth $20 million. It has allocated almost 50% of the corpus across both its funds for \nfollow-on investments in top performers of its portfolio. \"Our initial cheque will always be in the $1 million-$5 million \nrange and entry point always seed to Series A. We may look to support 5-6 of our portfolio startups from Fund II \nuntil their Series C,\" Garg added. Together has already backed 20 startups and looks to finish writing first cheques \nfrom Fund I by the end of this year. \"In light of this once-in-a-generation SaaS and AI opportunity, we are extending \nour founder-first philosophy with our second fund, supporting founders from the inception stage of their journey. We \nare excited to partner with these audacious founders who need bold and committed investors with extensive \noperating experience,\" said Mathrubootham, founding partner of Together Fund. Together's new fund comes at a \ntime when investment in Indian SaaS has fallen considerably to $635 million in the first half of 2023, from $3.4 \nbillion for the same period last year, according to research firm Venture Intelligence. The funding dip comes amid \nglobal macroeconomic weakening, as customer churn, demand slowdown and delayed sales cycles plague \nsoftware startups. Global management consulting firm Zinnov and venture capital firm Chiratae Ventures in a recent \nreport also marked down 2026 revenue projections of the Indian SaaS startups to $26 billion from $100 billion \npreviously. \"Macroeconomic environment impact has impacted everyone differently. We continue to look at \ndifferentiation and scalability in the companies we back. While we see valuations have corrected, companies need \nTogether unveils new fund worth $150 million, to back opportunities in Gen AI space\nto turn towards revenues, and valuation will take care of itself,\" Garg added. While there has been a dip in funding, \nTogether is seeing \"companies coming back to the funding markets starting this quarter,\" he added. For Reprint \nRights: timescontent.com\nLoad-Date: July 27, 2023"
    },
    {
        "file_name": "fake_case_citations_Jan2024",
        "header": "Former Trump fixer Michael Cohen acknowledges submitting AI-generated",
        "media": "fake case citations",
        "time": "January 1, 2024",
        "section": "",
        "length": "311 words",
        "byline": "John Fritze, USA TODAY",
        "story_text": "Former Trump fixer Michael Cohen acknowledges submitting AI-generated \nfake case citations\nUSA Today Online\nDecember 30, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 311 words\nByline: John Fritze, USA TODAY\nBody\nWASHINGTON – Michael Cohen, a former attorney and fixer for former President Donald Trump, acknowledged in \ncourt papers that he submitted fake legal citations generated by artificial intelligence as part of an effort to bring an \nearly end to court supervision of his case.\nCohen, who pleaded guilty to campaign finance and tax evasion charges in 2018, told a federal judge in court \npapers unsealed Friday that he was unaware that generative AI sites like Google Bard could make up information. \nCohen said he understood the services to be like “super-charged” search engines. \nThe development could be significant as Cohen is set to be a key witness in a Manhattan criminal case against \nTrump involving an alleged hush-money payment to porn star Stormy Daniels. Trump and his attorneys have \nfrequently sought to portray Cohen as untrustworthy.\nLink to Image\nCohen’s admission also showcases how the legal profession, like other industries, are wrestling with the \nresponsible use of artificial intelligence. Other attorneys have acknowledged submitting fake legal citations in briefs \ncompiled by the services.\nGoogle rolled out Bard earlier this year as an answer to ChatGPT, which Microsoft has been integrating into its Bing \nsearch engine. The tools can quickly generate text based off prompts from a user, but have a tendency to make \nthings up, also known as “hallucinations.”\nCohen blamed Schwartz, his lawyer and longtime friend, for failing to check the validity of his citations before \nsubmitting them to the judge, though he asked that the judge dispense mercy toward Schwartz, calling his failure to \ncheck the citations an “honest mistake” and “a product of inadvertence, not any intent to deceive.”\nContributing: Associated Press\nThis article originally appeared on USA TODAY: Former Trump fixer Michael Cohen acknowledges submitting AI-\ngenerated fake case citations\nLoad-Date: January 1, 2024"
    },
    {
        "file_name": "report_Apr2024",
        "header": "Apple laid off 600 employees after car, smart screen projects shut shop:",
        "media": "report",
        "time": "April 5, 2024",
        "section": "TECH & INTERNET",
        "length": "592 words",
        "byline": " ",
        "story_text": "Apple laid off 600 employees after car, smart screen projects shut shop: \nreport\nThe Economic Times\nApril 5, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 592 words\nBody\nTech giant Apple has laid off 600 employees across its self-driving car and smartwatch screen projects, news \nagency Bloomberg reported on Friday. Both projects were scrapped earlier this year. According to the report, Apple \nfiled eight separate reports to the state of California to comply with the Worker Adjustment and Retraining \nNotification, or WARN program.“Companies must file a report to the state agency for each California address that \nincludes employees affected by a layoff. At least 87 of the people worked at an address corresponding to a secret \nApple facility for its next-generation screen development, while the others were located at buildings related to the \ncar project,” the report added. \nThe report noted that 371 employees were released at Apple’s main car-related office in Santa Clara, California, \nwhile dozens more at multiple satellite offices were also impacted. “In some cases, members of the Apple car group \nwere relocated to other teams, such as for artificial intelligence or work on personal robotics.”Layoffs at Apple have \nnot been a usual phenomenon — a contrast to other Big Tech companies like Alphabet, Amazon, Microsoft, etc that \nhave handed pink slips to thousands of employees, owing to global macroeconomic volatility. In 2022, it sacked \nabout 100 contract-based recruiters as part of a wider push to rein in the tech giant’s hiring and spending. It also \nslowed down hiring considering the unfavourable market conditions. AI projectsApple plans to disclose more about \nits plans to put generative artificial intelligence to use later this year, CEO Tim Cook said during the company's \nannual shareholder meeting last month.Cook said the iPhone maker sees “incredible breakthrough potential for \ngenerative AI, which is why we're currently investing significantly in this area. We believe that will unlock \ntransformative opportunities for users when it comes to productivity, problem-solving, and more.”Apple announced \nits annual developer conference WWDC on June 10 this year, and many expect the company to finally announce its \nAI offerings. Apple might push for AI integration into its upcoming iOS, iPadOS, macOS, and other platforms that \nhave been confirmed to be showcased during the conference.Meanwhile, reports suggest that Apple is in talks with \nboth Google and OpenAI to power its iPhone AI features.Also read | ETtech Explainer: Is Apple’s ReALM better \nthan OpenAI’s GPT-4?ReALM LLMLast week, Apple published a research paper discussing its large language \nmodel (LLM) Reference Resolution As Language Modeling (ReALM) and how it can “substantially outperform” \nOpenAI’s GPT-4.Apple said that while LLMs are extremely powerful for a variety of tasks, their use in reference \nresolution, particularly for non-conversational entities, remains underutilised.Reference resolution can be defined as \nthe task of determining what entities are referred to by which linguistic expression. In most cases, they refer to \nambiguous or contextual words such as ‘they’ or ‘them’.While humans can easily understand them, it is difficult for \nAI chatbots to determine their context and subsequently comprehend them.“This paper demonstrates how LLMs \ncan be used to create an extremely effective system to resolve references of various types, by showing how \nreference resolution can be converted into a language modeling problem, despite involving forms of entities like \nthose on screen that are not traditionally conducive to being reduced to a text-only modality,” Apple said in the \npaper. For Reprint Rights: timescontent.com\nApple laid off 600 employees after car, smart screen projects shut shop: report\nLoad-Date: April 5, 2024"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "CoRover.ai officially launches BharatGPT in partnership with Google Cloud",
        "media": "The Economic Times",
        "time": "December 12, 2023",
        "section": "TECH & INTERNET",
        "length": "432 words",
        "byline": "Annapurna Roy",
        "story_text": "CoRover.ai officially launches BharatGPT in partnership with Google Cloud\nThe Economic Times\nDecember 12, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 432 words\nByline: Annapurna Roy\nBody\nConversational artificial intelligence (AI) startup CoRover.ai on Monday announced the official launch of \nBharatGPT, its Indian language generative AI platform, with Google Cloud as its ‘technology partner’.“BharatGPT \nchampions the linguistic diversity of the nation, supporting over 14 Indian languages across text, voice, and video \ninteractions. Google Cloud as CoRover’s Cloud service provider will help CoRover enhance and scale BharatGPT,” \nthe Bengaluru-based startup said in a press release.The launch constitutes a ‘monumental leap’, it said, adding that \nBharatGPT was ‘meticulously tailored’ for Indians.Bikram Singh Bedi, managing director, Google Cloud India said, \n“We are thrilled to partner with CoRover to bring BharatGPT for the public sector in India. Technology truly has the \npotential to transform lives and our language and generative AI capabilities built into the platform will make access \neasy and democratise the use of the platform.”BharatGPT will serve to strengthen India’s position as an AI first \nnation, he added.ET reported on November 27 that Google as a ‘strategic partner’ was providing CoRover credits to \naccess cloud compute to build BharatGPT. \nFurther, the US tech major had infused $500,000 since March to scale the project and was close to investing $4 \nmillion in equity, according to sources.CoRover said its platform allows for custom knowledge base integration, \nERP/CRM system collaboration, and an integrated payment gateway. It added that the initiative is underlined by the \nethos ‘make AI in India, make AI work for India’.Corover CEO Ankush Sabharwal said, “Our intent with BharatGPT \ngoes beyond technological innovation; it's about crafting a platform that encapsulates our rich cultural heritage and \nflourishes in a cloud-first world. BharatGPT, which is built on Google Cloud's fortified infrastructure, confidently \naddresses these challenges, carving a niche as a trusted AI mainstay that is grounded and reliable.”Founded in \n2016, CoRover has been in the business of enterprise chatbots before this new genAI offering.BharatGPT will make \nCoRover’s platform a “human-centric conversational AI platform with contextual Generative AI (LLM) and faster \nMachine Learning”, the company said.It added that it will enable the development of multilingual virtual assistants in \nvideo, voice and chat formats in a matter of minutes.Its features include Aadhar-based KYC authentication, \ndialogue management using natural language processing (NLP) and sentiment analysis, in addition to word \nembedding techniques with genAI. For Reprint Rights: timescontent.com\nLoad-Date: December 12, 2023"
    },
    {
        "file_name": "New_York_Observer_Apr2023",
        "header": "Activist Investor Scott Murray Urges Getty Images to Enter AI Partnerships",
        "media": "New York Observer",
        "time": "April 19, 2023",
        "section": "",
        "length": "557 words",
        "byline": "Alexandra Tremayne-Pengelly",
        "story_text": "Activist Investor Scott Murray Urges Getty Images to Enter AI Partnerships\nNew York Observer\nApril 17, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 557 words\nByline: Alexandra Tremayne-Pengelly\nBody\nScott Murray, founder and CEO of activist investor Trillium Capital, wants Getty Images to begin pursuing artificial \nintelligence collaborations with technology companies.\nIn order to expand revenue, Getty should expand its current generative AI partnership with Nvidia, which was \nannounced in March, in addition to teaming up with Microsoft and Bing's Open API system, according to a \nstatement from Trillium Capital released today (April 17).\nBoston-based Trillium Capital said its principals currently hold more than 500,000 shares of Getty, which amounts \nto roughly 0.15 percent of the company.\nThe investor also urged Getty to combine its image collection with that of Adobe, in addition to suggesting it begin \nuploading its photos and videos to Meta's Facebook and Instagram platforms.\n\"There's so much going on with artificial intelligence, so much that can be done,\" said Murray, who is also a \nmember of venture capital firm Converge Venture Partners. He formerly held CEO positions at educational software \nprovider The Learning Company, business process outsourcing company Stream Global Services and digital \nelectronics manufacturer 3Com.\nTrillium also suggested the digital company build relationships with universities in order for students to upload and \nshare images with friends and family using AI, and requested the platform expand its photo library to include special \nevents like sports, religious ceremonies, museums and graduations.\n\"They've not leveraged some of the obvious opportunities, whether that be with churches or universities,\" said \nMurray, who suggested Getty should partner with various institutions in order to document or livestream their \nevents.\nTrillium Capital previously launched a 2020 activist campaign against Conduent, a New Jersey-based business \nprocess outsourcing company, which Murray claimed was responsible for doubling the company's stock price.\nWhat is Getty Images' potential?\nGetty went public in July after a $4.8 billion merger with blank-check company CC Neuberger Principal II. The \ncompany's current valuation of $2.45 billion marks a significant fall from its record valuation of $15 billion in August.\nAccording to Murray, Getty has the potential to be valued $1.1 billion higher. Earlier this month, the investor \nreleased an open letter to Getty urging the company either be sold or taken private to improve shareholder value.\n\"I think it's really simple, Getty should be sold,\" said Murray, who suggested Microsoft, Adobe, Nvidia and Meta as \npotential strategic buyers. \"It shouldn't be a stand-alone company.\"\nActivist Investor Scott Murray Urges Getty Images to Enter AI Partnerships\nAnother option would be for the Getty Family, Koch Icon Investments and CC Neuberger-Getty's three largest \nstakeholders who own more than 80 percent of the outstanding shares-to take the company private, he said.\nTrillium Capital, which has additionally demanded Getty hire an investment bank to seek out strategic alternatives, \nalso requested on April 14 that Murray join the company's board of directors as either a member of its audit or \ncompensation committees. According to Murray, he hasn't yet received feedback from the company on any of \nTrillium Capital's requests.\n\"'Do nothing' is not a strategy,\" he said. \"You have a public responsibility to your shareholders to executive and \ndeliver, and this company and board has done neither.\"\nGetty did not respond to requests for comment.\nLoad-Date: April 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "How teachers and students feel about A.I.",
        "media": "The New York Times",
        "time": "April 30, 2024",
        "section": "TECHNOLOGY",
        "length": "1210 words",
        "byline": "Natasha Singer Natasha Singer writes about technology, business and society. She is currently reporting",
        "story_text": "How teachers and students feel about A.I.\nThe New York Times \nAugust 24, 2023 Thursday 14:42 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1210 words\nByline: Natasha Singer Natasha Singer writes about technology, business and society. She is currently reporting \non the far-reaching ways that tech companies and their tools are reshaping public schools, higher education and job \nopportunities.\nHighlight: As the school year begins, their thinking has evolved.\nBody\nAs the school year begins, their thinking has evolved.\nI sat in on a ChatGPT workshop this month for teachers at Walla Walla High School, about 270 miles southeast of \nSeattle. As a reporter who covers education technology, I have closely followed how generative artificial \nintelligence has upended education.\nNow that the first full school year of the A.I. chatbot era is beginning, I wanted to ask administrators and educators \nhow their thinking had evolved since last spring. Walla Walla, a district that serves some 5,500 students, seemed \nlike a timely location to begin the conversation. After blocking student access to ChatGPT in February, Walla Walla \nadministrators told me they unblocked it last month and are now embracing A.I. tools.\nSo I jumped at the chance to learn more about how teachers there are planning to use chatbots with their students \nthis academic year. You can read more in my story today about how school districts across the country are \nrepealing their ChatGPT bans.\nMy colleague Kevin Roose has some great suggestions in his column today on how schools can survive, “and \nmaybe even thrive,” with A.I. tools this fall. Step one, Kevin says: “Assume all students are going to use the \ntechnology.”\nWe recently asked educators, professors, and high school and college students to tell us about their experiences \nusing A.I. chatbots for teaching and learning. We got a massive response — more than 350 submissions. Here are \nsome highlights:\nTeaching with A.I.\nI love A.I. chatbots! I use them to make variations on quiz questions. I have them check my instructions for clarity. I \nhave them brainstorm activity and assignment ideas. I’ve tried using them to evaluate student essays, but it isn’t \ngreat at that.\n— Katy Pearce, associate professor, University of Washington\nBefore they even use ChatGPT, I help students discern what is worth knowing, figuring out how to look it up, and \nwhat information or research is worth “outsourcing” to A.I. I also teach students how to think critically about the data \ncollected from the chatbot — what might be missing, what can be improved and how they can expand the \n“conversation” to get richer feedback.\nHow teachers and students feel about A.I.\n— Nicole Haddad, Southern Methodist University\nStudying with A.I. tools\nI used ChatGPT and a math plug-in to help prepare me in geometry for next year. That was very helpful for me \nbecause you can ask it a million questions and it never gets tired. It was like my personalized tutor in math.\n— Amedeo Bettauer, age 13, rising ninth grader, Brookline High School\nA.I. chatbots are making it a lot easier for students to understand difficult concepts in a simple way. The tailored \nresponses one can obtain through specific prompts are incredible. It can provide students with endless examples of \nhow to outline essays, business plans and emails. It’s a real time saver.\n— Sam Avery, recent graduate, University of Iowa\nA.I. chatbots can give students an out. You don’t have to think about a text deeply or write about a connection that \nyou had to find, you can simply just ask a robot to analyze a quote and it will do it in a matter of seconds. I don’t \nknow the effects that A.I. will have on students in the long run but I just don’t want it to make students lazy, as the \njoy of learning is that “AHA!” moment that comes from figuring something out yourself.\n— Emma Nazario, first-year student, Wheaton College\nDrawbacks\nThey have industrialized and automated plagiarism.\n— Travis Huckell, associate professor, MacEwan University\nI think that the very best students will be fine. At less resourced universities than my own, I foresee an ever yawning \ngap between the privileged and everyone else, between those who know how to use A.I. as a tool and those who \ndon’t know that there is anything to know.\n— Ricardo Galliano Court, assistant dean for academic integrity and undergraduate research, Northwestern \nUniversity\nA lesson plan for the A.I. era\nSome readers told us they would love to see the federal government develop strict rules for the educational uses of \nA.I. to protect student privacy and intellectual property. And they urged their universities and districts to provide \nmore guidelines and recommendations for innovative uses of A.I. tools.\nFor educators looking for inspiration, Ethan Mollick, an associate professor at the Wharton School of the University \nof Pennsylvania who thinks a lot about generative A.I. in the classroom, has some great suggestions. (He also has \na newsletter about A.I., and it’s covered how to make ChatGPT an expert tutor.)\nOn Kevin’s “Hard Fork” podcast, Ethan talked about how teachers and students might use the tools in the coming \nschool year. Here are a few snippets of the conversation, condensed and edited.\nCan schools stop students from cheating with A.I. chatbots?\n“The short answer is no. The long answer is A.I. use is undetectable. You can’t ask A.I. to detect A.I. It’s just going \nto lie to you. Every instinct we have about how to stop plagiarism doesn’t work.\nYou can change how you teach. You could have people do oral exams. But the old homework assignment is \nbasically cracked by A.I.”\nHow can teachers adapt?\nHow teachers and students feel about A.I.\n“You may have to hold people accountable with in-class exams, with having the Wi-Fi turned off, your Chromebook \nin demo mode. There are ways of solving this problem in the short term.\nI think the bigger, longer-term problem is what does this all mean? What does this change about education?\"\nHow should students approach generative A.I.?\n“I would demand clarity. Does this mean that I’m allowed to use A.I. to generate ideas? Could A.I. come with an \noutline that I work on? Can I ask for feedback from A.I. in my work? Am I allowed to use A.I. as a teammate? Can I \nask the A.I. advice for something? Can I ask to explain why I got a question right or wrong?\nI think you are allowed as a student to ask for what does this mean, while being patient with your teachers that they \nhaven’t figured it out either. Nobody knows the answer.”\nOne educator’s view\nJennifer Parnell, a history teacher at the Lawrenceville School, an independent school in Lawrenceville, N.J., was \nan early classroom adopter of ChatGPT. She began trying out A.I. chatbots in December and immediately \nincorporated the tools into her honors U.S. history and environmental science courses.\n“I’m fascinated by the potential of this technology, albeit a little bit terrified,” she wrote in response to our reader \ncallout.\nI called her on Wednesday to learn more about the ways she’s been using the A.I. tools with her high school \nstudents.\nFor a final exam in U.S. history, for instance, she used ChatGPT to manufacture an essay and then asked her \nstudents to analyze the A.I.-generated text for errors and rewrite it. Students also fed their own essays into the A.I. \ntool and asked it for feedback on the quality of their sources.\nParnell said she still has concerns about the use of A.I. tools in schools, including issues of bias, privacy and \nacademic honesty. But she believed the potential benefits outweighed the downsides.\n“A.I. has pushed teachers to think more intentionally about the purpose of education and specifically assessment,” \nshe said. “As a teacher, if I’m asking questions that are easily answered by A.I., am I asking the best questions?”\nThis article appeared in print on page B2.\nLoad-Date: April 30, 2024"
    },
    {
        "file_name": "New_York_Observer_Jul2023",
        "header": "Refik Anadol on A.I., Algorithms and the Amazon",
        "media": "New York Observer",
        "time": "July 9, 2023",
        "section": "",
        "length": "1216 words",
        "byline": "Alexandra Tremayne-Pengelly",
        "story_text": "Refik Anadol on A.I., Algorithms and the Amazon\nNew York Observer\nJuly 6, 2023 Thursday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 1216 words\nByline: Alexandra Tremayne-Pengelly\nBody\nIn the past year, digital artist Refik Anadol starred in an exhibition at the Museum of Modern Art (MoMA), worked \nwith luxury brand Bulgari and designed backdrops for the 65th annual Grammy Awards. But these milestones pale \nin comparison to his collaborations with the indigenous Yawanawa communities of Brazil, according to the artist.\n\"It was one of the most unforgettable experiences in my life,\" Anadol told Observer. \"They shared their language, \nthey shared their food and home. And it was powerful.\"\nKnown for his large-scale installations, created with the help of artificial intelligence (A.I.) and generative algorithms, \nthe Turkish artist's multi-sensory and swirling installations have previously drawn from California's environmental \ndata, digitized recordings of the Los Angeles Philharmonic and millions of images of New York City. Anadol's recent \ninstallation at MoMA, meanwhile, journeyed through two centuries of artwork collected by the museum.\nNow, works co-created by the artist and the Yawanawa people will headline a new program in Mykonos, Greece, \nwith Anadol's sale proceeds benefiting the indigenous communities who worked with him. The collection will be \nunveiled between July 13 and September 3 at the inaugural edition of Encounters, a new cultural series created in \npartnership with HOFA Gallery and Greek club Scorpios.\nFacilitated by Impact One, an impact investment initiative, Anadol traveled to the Amazon rainforest to meet and \ndiscuss the project with Yawanawa communities, later communicating with them via WhatsApp groups. \"It's very \nhard to collaborate across a rainforest, to be honest,\" said the artist. Observer caught up with Anadol to discuss his \nnewest project, his 10-hour river journey to the Amazon and his thoughts on the future of A.I. and generative art.\nThis transcript has been edited for clarity and length.\nWhere are you based right now?\nI've lived in Los Angeles for 10 years. I teach Design Media Arts at UCLA and also have had a studio here for nine \nyears. But I'm originally from Istanbul, Turkey. I travel like a bird. I'm everywhere, every two weeks. But of course, I \ngo back to Turkey as much as I can.\nHow long have you been working with A.I.?\nIn 2008 I started programming computers to make art with data - I think I coined the term \"data painting\" that year. \nA.I. became another layer in 2016, when I became the first artist-in-residence at Google. I learned how to train A.I. \nmodels, work with big data and create artworks with machine intelligence. People are now realizing that A.I. can do \nincredible things, which is a great moment for me and for anyone working with A.I. But it's been seven years right \nnow since my very first A.I. project.\nSome have expressed fears about the future of A.I., do you share their concerns?\nRefik Anadol on A.I., Algorithms and the Amazon\nAnyone working with A.I., I'm pretty confident that they see the potential but also the pros and cons. I believe A.I. is \na very powerful technology that can take us to worlds that we don't want. But it can bring incredible possibilities \naround topics we cannot solve without the help of A.I. And actually, one of the reasons we are doing this project \nwith the Yawanawa family is because A.I. is so complex and beyond our civilized society, so we need new \nperspectives. My take is to bring ancestral wisdom to the dialogue to really open up the questions to a much wider \ncontext than just product and service.\nHow did you first begin working with the Yawanawa people?\nMy partner and wife had been researching the Amazon, so I heard about the family from her research. Our first \nencounter and first profound collaboration started last year, thanks to our partner Impact One that allowed us to \ntravel and connect and deep dive into who they are. It's a very special place where you don't need a computer, A.I. \nor anything else. I don't ever remember being inspired like this. I witnessed their dialogue, their culture, ways of \nlearning, preserving knowledge and consciousness, how they treat nature and survived for centuries.\nCan you give more details on your collaboration with them?\nSo, there are two types of collaboration here. Number one is the origin of Yawanawa paintings. They have been \npracticing their art for years, but now they digitize their works. We got an incredible set of paintings from the young \nYawanawa artists. These are their spiritual drawings, cultural life patterns, colors and forms that represent the \nthousands of years of culture in the Amazon. And then we co-created a special algorithm to give life to these \npaintings by using local wind data. We have a local sensor on site in the Amazon rainforest which takes real-time \ndata of the wind speeds, direction, gust and rain. We connected their physical culture with virtual data to create this \ndata painting series.\nHow did you get to the Amazon?\nOkay, so the first meeting was really challenging. It was not the easiest, because we as humanity living in our \ncomfort zones and technologically advanced worlds forget how nature actually works. Going back to the role of \nnature takes some courage and experience. From Cruzeiro do Sul, Brazil, the tribe came with special boats. And \nthen it was an almost 10-hour journey, with the voices of jaguars and snakes and all kinds of animals. We had to \nleave all our fears behind. It's a very special feeling.\nWhere do you typically draw inspiration from?\nGenerally, my inspiration comes from science. My pure inspiration is mostly from science fiction and near-worlds, \nwhere we potentially are going as humanity. But what I'm really more inspired by is preserving humanity and using \ndata as a form of one day creating a library of humanity where all data exists together, freely and openly, without \nany borders and passports. Nature is a very big part of this. Rainforests, for example, are one of the richest biomes \nin the world, we don't even know how many types of species exist in this universe. It's one of the most incredible \nand rich environments.\nWhat are your thoughts on the attention given to generative art in recent years and months?\nI'm very, very happy to see that. In research for my second MFA [at UCLA], I researched the beginnings of \ngenerative art, the beginnings of software art, computer art. Now it's called digital art-whatever name we put, it \ndoesn't matter, but people were working with computers and algorithms.  Seeing the positivity and interaction and \nhaving a show at MoMA, I wasn't expecting this level of engagement. MoMA is for us, as a studio, a whole different \ncanvas that opened up a different dimension. I don't think the work we do there represents me, it's a representation \nof the whole generative A.I. artwork space. And that's really powerful.\nWhat's next for you?\nRight now, we are working on a very special project. I'm hiding the name a little bit, but more will be announced this \nfall. It's our next big journey that I think will make a major impact. Also, beyond the Yawanawa rainforest research, \nRefik Anadol on A.I., Algorithms and the Amazon\nwe are creating the world's largest rainforest A.I. model. Not like a Chat GPT or another service-it's a gift to \nhumanity. And next year, we will see a very unique take on how A.I. can be experienced, which is what we are now \nhardcore working on. All these things will converge into one project for next year, opening in Los Angeles first and \nthen around the world.\nLoad-Date: July 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "A Bold Volunteer On the A.I. Frontier Hears the Future",
        "media": "The New York Times",
        "time": "May 25, 2023",
        "section": "Section C; Column 0; The Arts/Cultural Desk; Pg. 4",
        "length": "1549 words",
        "byline": "By Joe Coscarelli",
        "story_text": "A Bold Volunteer On the A.I. Frontier Hears the Future\nThe New York Times\nMay 25, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section C; Column 0; The Arts/Cultural Desk; Pg. 4\nLength: 1549 words\nByline: By Joe Coscarelli\nBody\nThe producer and pop singer, long a proponent of technological experimentation, has ''open-sourced'' her voice \nusing new A.I. tools. She's been impressed by the results.\nLast month, when ''Heart on My Sleeve,'' a track credited to A.I. versions of Drake and the Weeknd, became an \nunauthorized hit online, many in the music industry loudly fretted about the legal and creative risks to come. But \nGrimes, the producer and pop singer who has long been enthralled with visions of the future, saw opportunity. \n  For years, she had been dabbling with fledgling technology in the realm of generative A.I., using the imperfect \ntools available to create a lullaby; a set of meditations; a Grimes chatbot à la ChatGPT; and plenty of sci-fi and \nanime-inspired visual art with services like Midjourney and Stable Diffusion.\n  But the rapid mainstreaming of passable voice-emulating filters -- tools that allow users to tweak existing vocals to \nsound like someone else, notably famous artists like Drake, Michael Jackson or Taylor Swift -- struck Grimes as \nmore than just a novelty. They could be a teachable moment, a source of inspiration and even a side business.\n  ''I'll split 50% royalties on any successful AI generated song that uses my voice,'' Grimes tweeted to her more than \none million followers, referring to the royalties for the recording itself; she clarified in an interview that the songwriter \nwould be entitled to all profits from the composition, or publishing. ''Feel free to use my voice without penalty. I have \nno label and no legal bindings.''\n  Then, she and her team rolled out Elf.tech, easy-to-use software that aids producers and songwriters -- amateur \nand professional alike -- in making it sound like Grimes is singing their song. So far, there have been more than \n15,000 vocal transformations using the tool, called GrimesAI-1, and more than 300 complete songs submitted for \ndistribution to official streaming services with the help of Grimes's behind-the-scenes apparatus.\n  Daouda Leonard, her manager and one of the developers of Elf.tech, called it a moment ''when preparation meets \nopportunity.'' He added, ''People are struggling with this and it's obviously controversial. How do we showcase \nwhat's possible?''\n  Over a recent Zoom call, Grimes -- who has two children with the entrepreneur Elon Musk -- discussed the project \nso far, musing that her out-of-body celebrity status and longtime obsession with A.I. have combined to make her the \nperfect vessel for experimentation. She also provided her thoughts on five tracks created with the GrimesAI \nsoftware. These are edited excerpts from the conversation.\n  ''Heart on My Sleeve'' seemed like a tipping point. What was that moment like for you, as someone who has been \nplaying around in this space for years?\nA Bold Volunteer On the A.I. Frontier Hears the Future\n  I was excited pretty much in every way, even with people talking about the risks. I love A.I., but I am kind of \nworried that this isn't more of a discussion, so I think it was really useful. And I was excited that we could definitely \nget access to this technology now, because we tried to make the Grimes voice five years ago and it kept just being \nnot quite there.\n  Where does your journey with A.I. start?\n  Honestly it began when I was a kid, which is weird maybe. We were going through my old college sketch pads last \nyear and we found a bunch of A.I. theory. I've always been talking about this; it just wasn't possible before. But I \nstarted getting into the possibilities of art a bit before the crypto times. That's when we were trying to open-source \nGrimes for the first time -- 2018 or 2019.\n  What does it mean to ''open-source'' Grimes?\n  I'm really interested in the art of identity. We tried to sell my soul -- 10 percent of it -- in a legally binding \nagreement. But no one cared, and also it's at a ridiculously high price that no one will ever buy -- like $10 billion. But \nif they do buy it, then I accept my fate and it'd be worth it.\n  Only one person you know can afford that.\n  Yeah, I don't think he's going to pay for that. But my soul is already gone. I've already completely lost control of the \nGrimes narrative. Like, I'm accused of war crimes all the time.\n  So how do you go from that to open-sourcing Grimes musically?\n  I feel probably less pain than the average person would about such things, because the amount of ego death that \nI've had to go through in order to even just continue being functional is pretty high. The sort of weird, icky feeling a \nlot of people get when they hear their voice being used in a way that they did not intend -- I'm just subject to more \ncrazy press than the average person. I'm so used to it.\n  Grimes started because I was in a very punk scene and it seemed edgy to put on a pink dress and dance around \nand make pop music. Part of what I was interested in doing at the time was upsetting people. Even now, what are \nthe boundaries? What is the Overton window of art? What is allowed?\n  How would you explain to, say, your grandmother, what you're doing with A.I. now?\n  People keep getting really upset, being like, ''I want to hear something that a human made!'' And I'm like, humans \nmade all of this. You still have to write the song, produce the song and sing the vocal. The part that is A.I. is taking \nthe harmonics and the timbre of the vocal and moving them to be consistent with my voice, as opposed to the \nperson's original voice. It's like a new microphone.\n  How was the tool trained?\n  It was trained on stems of my voice. Some dry vocals [without effects], but it would definitely be better if I would \nsend it some vocals with less reverb. I wish we had more. We don't have anything old, which is tragic. But I didn't \nunderstand that was useful to keep back then.\n  How are you confronting the idea that somebody could make a hateful or obscene song in Grimes's voice?\n  The good thing about the music industry being so against this is that it seems pretty easy to strike things down. \nBut I also think it's good for there to be one edgelord moment. With regards to making A.I. more safe and more \nculturally productive and helpful, it's good to get things out of the system when they're least damaging and least \npopular. I sort of don't mind if Grimes is the mechanism.\n  Where would you personally draw the line?\nA Bold Volunteer On the A.I. Frontier Hears the Future\n  I think slurs, hate speech, advocating violence that's clearly not in jest. Conveniently, no one's really done anything \nbad, and I sort of feel like it's not even that exciting to.\n  Do you think that Drake A.I. or Grimes A.I. negates the need for real Drake or real Grimes?\n  No, I don't think so. Maybe for me, but I kind of want that. Feeling really amazing from making beautiful art is \nsomething that has typically been behind a gate for a lot of people -- extreme amounts of time and energy, years of \ntechnical training. I think it's valuable that there's a tool with which, if you have a beautiful idea, you can make a \nbeautiful thing and access that.\n  Kito featuring GrimesAI, 'Cold Touch'\n  [Video:  Watch on YouTube.]\n  The chorus hook is really good. I could probably be convinced that I worked on it -- that would not shock me at all. \nEspecially when the techno comes in. It was immediately very euphoric and very Grimes-y in a really pop way. I \nwould change a lot about the verses, and I'm probably going to do my own version. But I like that she feels really \nstrongly about her artistic vision and wants to stick to it. That's why we're doing Kito's Version and Grimes's \nVersion, using the Taylor Swiftian nomenclature.\n  Ravi Parikh featuring GrimesAI, 'Friend V. Enemy'\n  The drop is so sick. It's just fun someone put my name on it, because it's a really good song. I think the vocal \ndoesn't sound like me at all, but I can tell why: The singer is exceptionally different from how I sing. She's \nenunciating really well, she's got a lot of vibrato and she might even have an accent or something. You can tell Kito \ntried to sing like me in the hook, in a really breathy way. This person did not, and it gives credence to the human \nbehind the thing.\n  OtterlyMusic & Säfira featuring GrimesAI, 'Concept of Creation'\n  [Video:  Watch on YouTube.]\n  I love this one, it's probably my favorite. I think it's the best depiction of something I would very much make, even \ndown to the production and this image. It really feels like Grimes is self-replicating. It's so organic and Celtic around \nthe hook, but so A.I. in the verse. She's even doing my lisp.\n  Nick Webb featuring GrimesAI, 'Ether'\n  [Video:  Watch on YouTube.]\n  I love how weird this song is -- it sounds really inhuman. You can hear the A.I. My favorite music is Vangelis \nbecause it sounds so early synth. You can hear the technology very profoundly. What I like about the early A.I. stuff \nis that you can hear the technology very profoundly. I think people will appreciate that more in five years when they \nrealize people only made stuff like this for a couple months.\n  Kotomi featuring GrimesAI, 'In Another Life'\n  [Video:  Watch on YouTube.]\n  These lyrics drive me crazy. It's really good besides that. ''Scream out your name'' -- anything that feels bordering \non sexual makes me really uncomfortable. That's where I can sort of relate to other artists' itchiness -- lyrics causing \nme mild knives in the back of my brain. But I also appreciate the feeling of being uncomfortable.\nhttps://www.nytimes.com/2023/05/24/arts/music/grimes-ai-songs.html\nA Bold Volunteer On the A.I. Frontier Hears the Future\nGraphic\n \nPHOTO: The singer and producer Grimes often tests boundaries. Now she's embracing projects involving artificial \nintelligence. (PHOTOGRAPH BY ELIZAVETA PORODINA FOR THE NEW YORK TIMES) This article appeared in \nprint on page C4.               \nLoad-Date: May 25, 2023"
    },
    {
        "file_name": "Shift_Feb2024",
        "header": "Can This A.I.-Powered Search Engine Replace Google? It Has for Me.; The",
        "media": "Shift",
        "time": "February 2, 2024",
        "section": "TECHNOLOGY",
        "length": "1868 words",
        "byline": "Kevin Roose",
        "story_text": "Can This A.I.-Powered Search Engine Replace Google? It Has for Me.; The \nShift\nThe New York Times - International Edition\nFebruary 3, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1868 words\nByline: Kevin Roose\nBody\nA start-up called Perplexity shows what's possible for a search engine built from scratch with artificial intelligence.       \nFor my entire adult life, whenever I've had a question about the world or needed to track down something online, \nI've gone to Google for answers.       \nBut recently, I've been stepping out on Google with a new, A.I.-powered search engine. (No, not Bing, which is \ndead to me after it tried to break up my marriage last year.)       \nIt's called Perplexity. The year-old search engine, whose founders previously worked in A.I. research at OpenAI and \nMeta, has quickly become one of the most buzzed-about products in the tech world. Tech insiders rave about it on \nsocial media, and investors like Jeff Bezos - who was also an early investor in Google - have showered it with cash. \nThe company recently announced that it had raised $74 million in a funding round led by Institutional Venture \nPartners, which valued the company at $520 million.       \nMany start-ups have tried and failed to challenge Google over the years. (One would-be competitor, Neeva, shut \ndown last year after failing to gain traction.) But Google seems less invincible these days. Many users have \ncomplained that their Google search results have gotten clogged with spammy, low-quality websites, and some \npeople have started looking for answers in places like Reddit and TikTok instead.       \nIntrigued by the hype, I recently spent several weeks using Perplexity as my default search engine on both desktop \nand mobile. I tested both the free version and the paid product, Perplexity Pro, which costs $20 per month and \ngives users access to more powerful A.I. models and certain features, such as the ability to upload their own files.       \nHundreds of searches later, I can report that even though Perplexity isn't perfect, it's very good. And while I'm not \nready to break up with Google entirely, I'm now more convinced that A.I.-powered search engines like Perplexity \ncould loosen Google's grip on the search market, or at least force it to play catch-up.       \nI'm also scared that A.I. search engines could destroy my job, and that the entire digital media industry could \ncollapse as a result of products like them. But I'm getting ahead of myself.       \nWhere it shines\nAt first glance, Perplexity's desktop interface looks a lot like Google's - a text box centered on a sparse landing \npage.       \nCan This A.I.-Powered Search Engine Replace Google ? It Has for Me. The Shift\nBut as soon as you start typing, the differences become obvious. When you ask a question, Perplexity doesn't give \nyou back a list of links. Instead, it scours the web for you and uses A.I. to write a summary of what it finds. These \nanswers are annotated with links to the sources the A.I. used, which also appear in a panel above the response.       \nI tested Perplexity on hundreds of queries, including questions about current events (\"How did Nikki Haley do in the \nNew Hampshire primary?\"), shopping recommendations (\"What's the best dog food for a senior dog with joint \npain?\") and household tasks (\"How long does beef stew stay good in the fridge?\").       \nEach time, I got back an A.I.-generated response, generally a paragraph or two long, sprinkled with citations to \nwebsites like NPR, The New York Times and Reddit, along with a list of suggested follow-up questions I could ask, \nsuch as \"Can you freeze beef stew to make it last longer?\"       \nOne impressive Perplexity feature is \"Copilot,\" which helps a user narrow down a query by asking clarifying \nquestions. When I asked for ideas on where to host a birthday party for a 2-year-old, for example, Copilot asked \nwhether I wanted suggestions for outdoor spaces, indoor spaces or both. When I selected \"indoor,\" it asked me to \nchoose a rough budget for the party. Only then did it give me a list of possible venues.       \nPerplexity also allows users to search within a specific set of sources, such as academic papers, YouTube videos \nor Reddit posts. This came in handy when I was looking up how to change a setting on my house's water heater. \n(Exciting stuff, I know.) A Google search yielded a bunch of less-than-helpful links to D.I.Y. tutorials, some of which \nwere thinly veiled ads for plumbing companies. I tried the same query on Perplexity, and narrowed my search to \nYouTube videos. Perplexity found the video I needed for my exact model of water heater, extracted the relevant \ninformation from the video and turned it into step-by-step instructions.       \nUnder the hood, Perplexity runs on OpenAI's GPT-3.5 model along with its own A.I. model - a variant of Meta's \nopen-source Llama 2 model. Users who upgrade to the Pro version can choose between a handful of different \nmodels, including GPT-4 and Anthropic's Claude. (I used GPT-4 for most of my searches, but I didn't see much of a \ndifference in the quality of the answers when I chose other models.)       \nPerplexity is also refreshingly good at admitting when it doesn't know something. Sometimes, it gave a partial \nresponse to my question, with a caveat like \"No further details are provided in the search results.\" Most A.I. chat \nproducts I've used lack this kind of humility - their responses sound confident even when they're spouting \nnonsense.       \nWhere Google still reigns\nDuring my tests, I found Perplexity most useful for complicated or open-ended searches, such as summarizing \nrecent news articles about a specific company or giving me suggestions for date-night restaurants. I also found it \nuseful when what I was looking for - instructions for renewing a passport, for example - was buried on a crowded, \nhard-to-navigate website.       \nBut I did sneak back to Google for a few types of searches - usually, when I was looking up specific people or trying \nto go to websites I already knew existed. For example: When I typed \"Wayback Machine\" into my browser's search \nbar, I was redirected to Perplexity, which spit out a paragraph-long essay about the history of the Internet Archive, \nthe organization that maintains the Wayback Machine. I had to hunt for a small citation link to get to the Wayback \nMachine's website, which is what I wanted in the first place.       \nA similar thing happened when I asked Perplexity for driving directions to a work meeting. Google would have given \nme turn-by-turn directions from my house, thanks to its integration with Google Maps. But Perplexity doesn't know \nwhere I live, so the best it could offer me was a link to MapQuest.       \nLocation data is just one of the many advantages Google has over Perplexity. Size is another - Perplexity, which \nhas just 41 employees and is based out of a shared working space in San Francisco, has 10 million monthly active \nusers, an impressive number for a young start-up but a speck compared with Google's billions.       \nCan This A.I.-Powered Search Engine Replace Google ? It Has for Me. The Shift\nPerplexity also lacks a lucrative business model. Right now, the site has no ads and fewer than 100,000 people \npaying for the premium version, said Aravind Srinivas, the company's chief executive. (Mr. Srinivas didn't rule out \nswitching to an ads-based model in the future.) And, of course, Perplexity doesn't offer versions of Gmail, Google \nChrome, Google Docs or any of the dozens of other products that make Google's ecosystem so inescapable.       \nMr. Srinivas told me in an interview that while he believed Google was a formidable competitor, he thought that a \nsmall, focused start-up could give it a startle.       \n\"What makes me confident is the fact that, if they want to do it better than us, they would basically have to kill their \nown business model,\" he said.       \nWhat about hallucinations?\nOne problem with A.I.-based search engines is that they tend to hallucinate, or make up answers, and sometimes \nstray from their source material. This problem has haunted several A.I.-search hybrids, including Google's initial \nrelease of Bard, and it remains one of the biggest barriers to mass adoption.       \nIn my testing, I found that Perplexity's answers were mostly accurate - or, to be more precise, they were as \naccurate as the sources they drew upon.       \nI did find a few errors. When I asked Perplexity when Novak Djokovic's next tennis match was, it gave me the \ndetails of a match he'd already finished. Another time, when I uploaded a PDF file of a new A.I. research paper and \nasked Perplexity to summarize it, I got a summary of an entirely different paper that was published three years ago.       \nMr. Srinivas acknowledged that A.I.-powered search engines still made mistakes. He said that because Perplexity \nwas a small, relatively obscure product, users didn't expect it to be as authoritative as Google - and that Google \nwould struggle to build generative A.I. into its search engine because it needed to uphold its reputation for \naccuracy.       \n\"Let's say you use our product and we do well on eight out of 10 queries. You'd be impressed,\" Mr. Srinivas said. \n\"Now let's say you use Google's product and it only gets seven out of 10. You'd be like, 'How can Google get three \nqueries wrong?'\"       \n\"That asymmetry is our opportunity,\" he added.       \nA win for users, a loss for publishers\nEven though I enjoyed using Perplexity, and I'm likely to keep using it in tandem with Google, I'll admit that I got a \ngnawing feeling in my stomach after seeing it spit out pristine, concise summaries of news stories, product reviews \nand how-to articles.       \nMuch of today's digital media economy still relies on a steady flow of people clicking on links from Google, and \nbeing served ads on publishers' websites.       \nBut with Perplexity, there's usually no need to visit a website at all - the A.I. does the browsing for you and gives \nyou all the information you need right there on the answer page.       \nThe possibility that A.I.-powered search engines could replace Google traffic - or spur Google to put similar features \ninto its search engine, as it has started doing with its \"search generative experience\" experiment - is partly why \nmany digital publishers are terrified right now. It's also part of the reason some are fighting back, including The \nTimes, which sued OpenAI and Microsoft for copyright infringement last year.       \nAfter using Perplexity, and hearing about similar products being developed by other start-ups, I'm convinced that \nthe worriers have a point. If A.I. search engines can reliably summarize what's happening in Gaza, or tell users \nwhich toaster to buy, why would anyone visit a publisher's website ever again? Why would journalists, bloggers and \nCan This A.I.-Powered Search Engine Replace Google ? It Has for Me. The Shift\nproduct reviewers continue to put their work online if an A.I. search engine is just going to gobble it up and \nregurgitate it?       \nI brought these fears up to Mr. Srinivas, who responded with a diplomatic dodge. He conceded that Perplexity \nwould probably send less traffic to websites than traditional search engines. But he said the traffic that remained \nwould be higher quality and easier for publishers to monetize, because it would be the result of better, more \ntargeted queries.       \nI'm skeptical of that argument, and I'm still nervous about what the future holds for writers, publishers and people \nwho consume online media.       \nSo for now, I'll have to weigh the convenience of using Perplexity against the worry that, by using it, I'm contributing \nto my own doom. \nLoad-Date: February 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Publishers Worry A.I. Chatbots Will Cut Readership",
        "media": "The New York Times",
        "time": "March 31, 2023",
        "section": "BUSINESS; media",
        "length": "1287 words",
        "byline": "Katie Robertson",
        "story_text": "Publishers Worry A.I. Chatbots Will Cut Readership\nThe New York Times \nMarch 30, 2023 Thursday 13:27 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1287 words\nByline: Katie Robertson\nHighlight: Many sites get at least half their traffic from search engines. Fuller results generated by new chatbots \ncould mean far fewer visitors.\nBody\nMany sites get at least half their traffic from search engines. Fuller results generated by new chatbots could mean \nfar fewer visitors.\nThe publishing industry has spent the past two decades struggling to adjust to the internet, as print circulation has \nplummeted and tech companies have gobbled up rivers of advertising revenue.\nNow come the chatbots.\nNew artificial intelligence tools from Google and Microsoft give answers to search queries in full paragraphs rather \nthan a list of links. Many publishers worry that far fewer people will click through to news sites as a result, shrinking \ntraffic — and, by extension, revenue.\nThe new A.I. search tools remain in limited release, so publishers such as Condé Nast and Vice have not yet seen \nan effect on their business. But in an effort to prevent the industry from being upended without their input, many are \npulling together task forces to weigh options, making the topic a priority at industry conferences and, through a \ntrade organization, planning a push to be paid for the use of their content by chatbots.\n“You could essentially call this the Wikipedia-ization of a lot of information,” said Bryan Goldberg, the chief \nexecutive of BDG, which publishes lifestyle and culture websites like Bustle, Nylon and Romper. “You’re bringing \ntogether Wikipedia-style answers to an infinite number of questions, and that’s just going to nuke many corners of \nthe open web.”\nContent publishers have an uneven but largely reciprocal relationship with search engines. The search sites benefit \nfrom having trusted sources of information in the results, and the publishers benefit from the traffic to their sites that \nthe search engines generate.\nSearch traffic from Google accounts for half of overall visits, or more, to many sites, said Brian Morrissey, who \nwrites The Rebooting, a media business newsletter.\n“Search has been the mainstay of the publishing business on the internet,” he said.\nKyle Sutton, director of search and product at the newspaper publisher Gannett, said the relationship had, until \nnow, been mutually beneficial.\nPublishers Worry A.I. Chatbots Will Cut Readership\n“While all search results are taking from our data and, from our perspective, crawling our content, aggregating our \ncontent, there is the return there of them driving traffic to our site,” Mr. Sutton said. “So I think that relationship is \nkind of first and foremost what we want to see maintained.”\nThe new offerings could change all of that, said Barbara Peng, the president of the digital news brand Insider. \nMicrosoft is incorporating the chatbot into Bing, its search engine. Google’s search chatbot, Bard, is separate from \nits main search engine.\n“This will be revolutionary,” Ms. Peng said, adding, “It will take some time, and there is a good portion of hype mixed \nin there, too, but I do think it will change the relationship people have with finding and consuming information.”\nThe impact of “generative” A.I., which can generate text, images and other media from prompts, has become a top \npriority in discussions among publishers. A conference in New York in May, the World Congress of News Media, \nwill feature keynote speeches on the issue, according to a schedule on its website.\nVice Media has created a task force in recent months to examine its own approach, said Cory Haik, the chief \noperating officer. “It will have a huge impact on publishing in ways that we can’t even get our heads around yet,” \nshe predicted.\nThe Washington Post announced on Tuesday that it had appointed a deputy business editor to lead an internal \ngroup looking at A.I.’s impact on The Post’s journalism and digital strategy.\nNews Corp’s chief executive, Robert Thomson, who for years has led a push to get tech companies to pay for news \ncontent, said in an interview: “If you don’t get out early and define what the issues are and the obligations, then you \nwill find yourself on the defensive.”\nMr. Thomson said tech companies should pay to use publishers’ content to produce results from A.I. chatbots. The \nchatbots generate their results by synthesizing information from the internet. He added that News Corp, which owns \nThe Wall Street Journal and The New York Post among other outlets, was in talks with “a couple of companies” \nabout the use of its content, though he declined to specify which ones.\n“There is a recognition at their end that discussions are necessary,” he said.\nRoger Lynch, the chief executive of Condé Nast, which owns titles like Vogue, Vanity Fair and Glamour, agreed that \ncontent creators should be compensated. He said one upside for publishers was that audiences might soon find it \nharder to know what information to trust on the web, so “they’ll have to go to trusted sources.”\nThe News Media Alliance, which represents 2,000 outlets around the world, including The New York Times, is \nworking on principles that it says should guide the use and development of A.I. systems, and regulation around \nthem, to protect publishers. According to a draft, the principles say the use of publisher content for the development \nof A.I. should require “a negotiated agreement and explicit permission.”\nThe guidelines also call on tech companies to “provide sufficient value” for high-quality, trustworthy journalism \ncontent and brands, and state that any new laws or regulations that make exceptions to copyright law for A.I. must \nnot weaken protections for publishers.\n“Without these protections, publishers — far too many of whom already struggle to survive in the online ecosystem \ndue to marketplace imbalances — face an existential crisis that threatens our communities’ access to reliable and \ntrustworthy journalism,” the document states.\nDanielle Coffey, executive vice president of the News Media Alliance, said a solution could be found in the \nJournalism Competition and Preservation Act, a bill that would allow publishers to collectively negotiate with tech \ncompanies over revenue sharing and, as written, would account for the use of content by generative A.I. The bill, \nwhich failed to pass last year, is expected to be reintroduced on Thursday by Senators Amy Klobuchar, Democrat \nof Minnesota, and John Kennedy, Republican of Louisiana.\nPublishers Worry A.I. Chatbots Will Cut Readership\nYusuf Mehdi, Microsoft’s head of Bing, said in an interview that directing users to click through to publishers was “a \ntop goal.” And although the new Bing has been around for less than two months, the data was “already showing \nthat we are driving, in fact, more traffic to publishers,” he said.\n“Part of the reason that traffic is up is that we don’t just do a good job of answering the question, but we provide \nlinks,” he said, pointing to footnotes in the answers on Bing’s chatbot that show the information’s source.\nMr. Mehdi said Microsoft was at the beginning of its conversations with publishers around the new search. “It is our \nintention that we would like to share incremental revenue that happens in that chat experience,” he said.\nMicrosoft is considering showing more articles from a certain publisher below the footnote or selling ads against the \nlinks in the chat answer and splitting the proceeds, Mr. Mehdi said.\nA Google spokeswoman said in a statement that the company was “deeply committed to supporting a healthy and \nvibrant news ecosystem” and would put a priority on sending traffic.\n“This is the very early days of testing an experience in Bard, and we’ll be welcoming conversations with publishers \nto get their input,” she said.\nFor the past two years, BDG has focused on products like live events, email newsletters and premium branded \ncontent to limit exposure to the whims of search traffic, Mr. Goldberg said.\n“I think the best publishers had already anticipated this was coming years ago and are many years into our \ntransformation,” he said.\nThis article appeared in print on page B1, B5.\nLoad-Date: March 31, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "How AI-generated music is shaking up the industry",
        "media": "The Economic Times",
        "time": "April 20, 2024",
        "section": "ENTERTAINMENT",
        "length": "1653 words",
        "byline": "Anirban Chowdhury and Dia Rekhi",
        "story_text": "How AI-generated music is shaking up the industry\nThe Economic Times\nApril 21, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ENTERTAINMENT\nLength: 1653 words\nByline: Anirban Chowdhury and Dia Rekhi\nBody\nIn April last year, ghostwriter977, a TikTok user, wrote and produced a song called “Heart on my sleeve”. It \nsounded just like the Canadian rapper Drake and the singer-songwriter The Weeknd. The song went viral, racking \nup 15 million views on TikTok and hundreds of thousands of views each on Spotify and YouTube. But neither Drake \nnor The Weeknd had a clue about the song.They hadn’t sung a single line. Their vocals were generated by artificial \nintelligence (AI). The machine has moved on from synthesising sounds to generating singing voices. AI is on song \neverywhere.Anshuman Sharma and Aditya Kalway, two young producers assisting the music composer duo \nSalimSulaiman, recreated “Haule haule ho jayega”—the hit song in Shah Rukh Khan’s Rab Ne Bana Di Jodi—in the \nvoice of Mohammed Rafi. \n“We came across some AI vocal models that could produce the voices of Indian singers like Kishore Kumar, Rafi \nand Sonu Nigam,” recalls Sharma. In September 2023, Kalway sang “Haule haule” in Rafi’s signature style, put it \nthrough a vocal filter and musically arranged it like a 1970s LaxmikantPyarelal romantic ditty. Its Instagram Reel got \n2.6 million views and cheers from the music industry, including Vishal Dadlani, Shaan and Sonu Nigam.In January \nthis year, composer AR Rahman strode into the AI ring. He used AI to generate the voices of Shahul Hameed and \nBamba Bakya — two singers with whom he had collaborated but died, prematurely, in their 40s—for the song \n“Thimiri yezhuda” in the Rajinikanth film Lal Salaam.AI is the new sound of music. A harbinger of change as well as \nconfusion, it is shaking up the industry. While the technology’s potential is immense, artists are admittedly wary of \ntheir voices being cloned with the click of a few tools.“2023 is when the AI-hype phase in music really took off,” says \nValerio Velardo, a consultant in music and AI based in Andalusia, Spain. He founded Melodrive, an AI system that \ncomposes music in real time, in 2016, followed by the Sound of AI, one of the largest online AI music ecosystems. \n“We shifted from a symbolic generation to an audio-based generation,” he adds, referring to the shift from the use of \nsymbols to create music—which a synthesiser or sampler does —to the use of audio files to train AI models to \ngenerate music. “This was a leap,” he says.Indeed. It has come a long way from 1957, when the American \ncomposer and chemist Lejaren Hiller and the mathematician Leonard Isaacson programmed the Illiac computer at \nthe University of Illinois at Urbana– Champaign to compose a string quartet. The Illiac Suite is widely regarded as \nthe first score to be composed by a computer.The use of artificial intelligence in music exploded with the entry of \ntech giants and powerful AI-first firms. One of the pioneers was OpenAI’s Jukebox. Released in 2020, it generated \nraw audio that approximated the inputs you gave like a certain musician or a particular genre.Google came up with \nMusicLM, which generates hi-fi music from text prompts, in May 2023. Meta followed with AudioCraft in August. \nSoon, Stability AI, which created the popular text-to-image model Stable Diffusion, swept the music industry with its \nStable Audio. A text prompt like “a low-key romantic ballad in a Scandinavian setting, with harmonies across three \noctaves in the style of Charlie Puth” would generate exactly that, in a voice and style uncannily similar to the \nAmerican singersongwriter. “This is the equivalent of Midjourney or Dall-E, but for music,” says Velardo.In addition \nto Big Tech models, there is a proliferation of free, easy-to-access AI tools for music, especially voice-cloning \napplications. Sharma and Kalway were playing around with such tools when they decided to bring alive the sound \nof Rafi.WHO OWNS MY VOICE?The easy replication of famous voices with the use of AI has raised a significant \nHow AI-generated music is shaking up the industry\nquestion—who holds the copyright to a voice? Its particular timbre and texture? That is sending ripples across the \nmusic industry, leading to legal tangles and conversations about copyright.When Universal Music Group, the \nworld’s leading music company, got into a licensing dispute with shortform video company TikTok Inc earlier this \nyear, AI-generated music was a big part of the quarrel. Universal said TikTok was “flooded with AIgenerated \nrecordings”. It pulled down ghostwriter977’s “Heart on my sleeve”. Before that, Universal had sued AI company \nAnthropic for distributing copyrighted lyrics with its AI model Claude 2.Singers, too, are raising their voices against \nthe use of AI. Earlier this month, 200 artists, including Stevie Wonder, Robbie Williams, Billie Eilish and Katy Perry, \nwrote an open letter, asking AI developers, tech companies, platforms and digital music services to stop the usage \nof AI in music which, they said, “diminishes the rights of human artists”.The ripples have reached India too. In \nJanuary, SP Kalyan Charan, son of the legendary singer, S P Balasubrahmanyam, sued the producers and music \ndirector of a Telugu film called Keedaa Cola for the “unauthorised” use of his late father’s voice with the help of AI. \nThe filmmakers have denied this. Singer-musician Shankar Mahadevan is cautious. “Use of technology is always a \nfine balance between possibilities and restrictions. AI in music is an amazing advancement in technology,” says \nMahadevan, who is part of the Grammy-winning fusion band Shakti. “But it should be used to enhance a basic \ncomposition and not create or replicate human creations. Otherwise, it could be like copying someone’s tune. Is that \nethical?” he asks.The surge of AI has many ramifications. It could, for one, eat into the chances of a new singer. \nToday, new artists, looking for a break, render scratch versions of a song before the final version is sung by an \nestablished artist. It is these scratches that bring new artists to the notice of music directors. With vocal cloning, all \nthat a music label needs to do is choose from a list of vocally filtered renditions of established singers to decide \nwhose voice will suit the song. The trial-and-error of scratch versions, often the first step to fame for a new \nmusician, could get completely bypassed.“I think AI is a good tool in the hands of somebody who understands the \norganic creative process and the electronic creative process,” said tabla maestro Zakir Hussain and founder of \nShakti in a recent interview to ET, adding, “In the hands of someone who is totally uninformed, I don’t know what it \nwill become.”AI can bring tremendous opportunities to the world of music. A recent report by EY said, in terms of \nrevenue growth and cost benefits, generative AI would have an impact worth `45,000 crore in the media and \nentertainment business in India over the next few years. “It could mean a 30-40% enhancement of music industry’s \nrevenues,” says Ashish Pherwani, media and entertainment leader, EY India.“Now, we can keep alive yesteryear’s \nartists in the minds of their fans for longer. The cost of recreating a fan base vanishes because the fan of Hemant \nKumar or Rafi will listen to the songs you create. It’s a dream-come-true from a business point of view,” he \nadds.LEGAL VOIDThere is a yawning gap, though. There is currently no law that protects artists, their voices, vocal \nstyles and compositions from being recreated by AI-generated tools, says Velardo. “It’s a legislative void,” he says. \nHe points to two problems: “One is straightforward: I’m recreating Taylor Swift’s voice. That’s a breach of copyright. \nThere’s another that is more subtle, which is training full generative music systems. AI companies train their models \non material they don’t own and they don’t have permission from copyright holders to do the training.”The absence of \nlaws is a problem that Charan’s lawyer Kavitha Deenadayalan is facing in the lawsuit against the makers of Keedaa \nCola. “There is a narrow difference between using AI-generated music for the sake of entertainment or for paying \ntributes to a late singer, and using it for commercial purposes.When it is commercialised, somebody has to get \nlicence and consent and also pay the artist the remuneration that is mutually agreed upon,” she says. “In the \nabsence of a law, there is an ethical need to reach out to artists or their family for permission. That’s what Rahman \ndid for ‘Thimiri yezhuda,’” she adds. Gautam KM, partner at Krishnamurthy & Co and an expert in AI law, says, \n“When you are generating music in someone’s voice through a platform, where was the platform trained? Was it, in \nthis instance, trained on the deceased singer SPB’s existing songs? If that is the case, has the platform owner \ntaken necessary rights from his estate or heirs to train the platform with SPB’s voice? If you are giving lyrics to a \nplatform and asking it to create a sound recording in the voice of SPB, you could very well be infringing upon the \npersonality rights or the moral rights of the original singer,” he adds.Legal guardrails are coming up. The state of \nTennessee in the US has enacted a new law called the Ensuring Likeness, Voice and Image Security (Elvis) Act of \n2024, which seeks to impose liability on AI and tech companies for unauthorised use of a person’s voice or \nlikeness. The law will come into effect on July 1.Meanwhile, artists are putting up their own guardrails against AI. \nCanadian singer Grimes has created an AI software called Elf.Tech, which allows users to clone her voice but they \nwill have to share 50% of royalties with her. “The moment you commercialise a song with Grimes’ AI voice, you are \ngoing to do a revenue split,” says Velardo. She has also tied up with New York-based music distribution company \nTuneCore to distribute the songs. In a recent interview on The Music Podcast, singer Arijit Singh spoke about \nHow AI-generated music is shaking up the industry\ncopyrighting his voice. Mahadevan echoes that view. “Every artist has to copyright his or her voice. I certainly \nwould,” he says. For Reprint Rights: timescontent.com\nLoad-Date: April 20, 2024"
    },
    {
        "file_name": "READING_SKILLS_TO_CHILDREN_WITH_DYSLEXIA_THROUGH_Nov2023",
        "header": "'THE FUTURE OF EDUCATION'; LUCA.AI USES CHATGPT TO TEACH",
        "media": "READING SKILLS TO CHILDREN WITH DYSLEXIA THROUGH",
        "time": "November 16, 2023",
        "section": "BUSINESS; Pg. D-1",
        "length": "572 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "'THE FUTURE OF EDUCATION'; LUCA.AI USES CHATGPT TO TEACH \nREADING SKILLS TO CHILDREN WITH DYSLEXIA THROUGH \nPERSONALIZED PLAN\nPittsburgh Post-Gazette\nNovember 16, 2023 Thursday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. D-1\nLength: 572 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nA decade after his son Luca was diagnosed with dyslexia, Scott Sosso developed a website to help other people \nwith the learning disability learn to read.\nLuca.ai launched Nov. 2 with three core features: StoryLabs, which uses AI to craft stories based on a few user \nprompts like mountains and magic; LucaListens, which tracks phonetics to suggest real-time speaking \nimprovements; and ProfessorAI, which builds on those insights to create a personalized learning plan.\nThe Pittsburgh-based platform is tailored to address specific challenges people with dyslexic face: reading, spelling, \nand comprehension. And because of the AI integration, it can learn how users learn to create \"a personalized \nlearning tool that continuously adapts to the reader's skill level.\"\nThat's part of Mr. Sosso's belief that \"personalized learning is the future of education,\" he said.\nAn attentive parent could do some of the same work, but that takes considerable time and effort. Mr. Sosso said he \nstruggled to help his son with homework assignments.\n\"We had reading specialists, therapists, psychologists,\" Mr. Sosso said. \"He's a very bright kid. He was getting good \ngrades but really struggling with reading.\"\nNow a 17-year-old junior at Eden Christian Academy, Luca said a tool like this would have helped him appreciate \nwritten stories in a way he never could.\n\"I think my reading level would be probably be at 11th grade, right where I should be right now,\" he said.\nAs Luca goes off to study business in college, an animated version of his face will continue to guide readers as a \ndigital mascot for Luca.ai. Mr. Sosso said the Dora the Explorer-like icon will become increasingly expressive with \ngenerative AI.\nThe Luca.ai site requires learners to gain parental approval, under the Children's Online Privacy Protection Act. It \nalso was built with safeguards to protect user information while training its AI models.\nThe platform is still technically in beta mode, but it is now open to paid subscribers for a $15 per user, per month \nfee. Families with more than one child can get 50% off, or prepay for $150 a year.\n'THE FUTURE OF EDUCATION' LUCA.AI USES CHATGPT TO TEACH READING SKILLS TO CHILDREN \nWITH DYSLEXIA THROUGH PERSONALIZED PLAN\nMr. Sosso recommends 15-minute daily segments to consistently build the reading muscle. He said the privacy of \nlearning online helps build confidence.\nThe team hopes to release an app version of Luca.ai early next year, followed by classroom integration. The \ncompany is already working with Provident Charter Schools, which focuses on dyslexia and other language-based \nlearning differences. The school has a locations in Troy Hill and Beaver County. Twenty students from Provident \nlast year helped to refine the user interface.\nStudents from Carnegie Mellon University also helped develop the app, seizing on the opportunity to integrate \nChatGPT.\n\"That's when I realized that the platform had an opportunity to take off, because now we were really able to deliver \na custom learning experience for every student,\" Mr. Sosso said, giving special credit to the CMU students: \n\"They're really on the cutting edge of things.\"\nThe phonetic-recognition software, powerful enough to decipher distinct pronunciations, was also the result of \ncollegiate research at the University of Michigan.\nLuca.ai currently has about 50 users, but Mr. Sosso said that's with virtually no promotion.\nHe said he's already had multiple inquiries from local public schools.\n\"The interest is there,\" he said.\nEvan Robinson-Johnson: ejohnson@post-gazette.com and @sightsonwheels\nGraphic\n \nPHOTO: Sebastian Foltz/Post-Gazette: Scott Sosso and his son Luca show Sosso's Luca.ai avatar logo prior to a \nmeeting at Carnegie Mellon University, Wednesday. The character design was based on Luca as a child. Sosso \ndeveloped his Luca.ai program to assist children with dyslexia and other learning challenges in learning to read. \nThe program was inspired by Luca's own challenges learning to read as a child.\nPHOTO: Sebastian Foltz/Post-Gazette: The Luca.ai avatar logo is based on Luca Sosso as a child. His father Scott \nSosso developed Luca.ai program to assist children with dyslexia and other learning challenges in learning to read. \nThe program was inspired by Luca's challenges in learning to read as a child.\nPHOTO: Sebastian Foltz/Post-Gazette: Scott Sosso and his son Luca show Sosso's Luca.ai avatar logo prior to a \nmeeting at Carnegie Mellon University, Wednesday, Nov. 15, 2023. The character design was based on Luca as a \nchild. Sosso developed his Luca.ai program to assist children with dyslexia and other learning challenges in \nlearning to read. The program was inspired by Luca's own challenges learning to read as a child.\nPHOTO: Sebastian Foltz/Post-Gazette: Scott Sosso and his son Luca show Sosso's Luca.ai avatar logo prior to a \nmeeting at Carnegie Mellon University, Wednesday, Nov. 15, 2023. The character design was based on Luca as a \nchild. Sosso developed his Luca.ai program to assist children with dyslexia and other learning challenges in \nlearning to read. The program was inspired by Luca's own challenges learning to read as a child.\nLoad-Date: November 16, 2023\n'THE FUTURE OF EDUCATION' LUCA.AI USES CHATGPT TO TEACH READING SKILLS TO CHILDREN \nWITH DYSLEXIA THROUGH PERSONALIZED PLAN"
    },
    {
        "file_name": "grew_less_than_expected;_Shares_have_slipped_in_Asia_after_Japan_reported_Sep2023",
        "header": "Stock market today: Asian shares weaken while Japan reports economy",
        "media": "grew less than expected; Shares have slipped in Asia after Japan reported",
        "time": "September 8, 2023",
        "section": "NATION WORLD",
        "length": "626 words",
        "byline": "ELAINE KURTENBACH",
        "story_text": "Stock market today: Asian shares weaken while Japan reports economy \ngrew less than expected; Shares have slipped in Asia after Japan reported \nits economy grew less than earlier estimated in the last quarter\nDayton Daily News (Ohio)\nSeptember 8, 2023 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 626 words\nByline: ELAINE KURTENBACH\nBody\nShares fell Friday in Asia after Japan reported its economy grew less than earlier estimated in the last quarter.\nOil prices declined, while U.S. futures edged higher. \nJapan, the world's third largest economy, grew at a 4.8% annual pace in the April-June quarter, below the earlier \nestimate of 6% growth, according to data released Friday. \nMuch of that growth was driven by exports, which rose nearly 13%, while private consumption fell 2.2% on weak \ninvestment spending. A separate report showed that wages declined in July for the 16th straight month, falling 2.5% \nfrom a year earlier. \nTokyo's Nikkei 225 index dropped 1.2% to 32,606.84, while the Kospi in Seoul lost less than 1 point, to 2,547.68. \nHong Kong's markets were closed due to a tropical storm. \nThe Shanghai Composite index shed 0.2% to 3,1016.87, while the S&P;/ASX 200 fell 0.2% to 7,156.70. \nOn Thursday, Wall Street slipped in mixed trading Thursday as the threat of high interest rates continued to dog Big \nTech stocks. \nThe S&P; 500 fell 0.3% to 4,451.14, for its third straight loss. The Nasdaq composite was hit particularly hard by the \ndrop for tech stocks, sinking 0.9% to 13,748.83. \nThe Dow Jones Industrial Average held up better than the rest of the market because it has less of an emphasis on \ntech. It rose 0.2% to 34,500.73. \nStocks felt pressure from the bond market, where yields rose earlier in the week after a report showed stronger \ngrowth for U.S. services industries last month than economists expected. Yields remained high after a report on \nThursday said fewer U.S. workers applied for unemployment benefits last week than expected. \nWhile such reports are encouraging for the economy, indicating a long-predicted recession is not near, they could \nalso keep conditions humming strongly enough to push upward on inflation. \nThe Federal Reserve has already hiked its main interest rate to the highest level in more than two decades in hopes \nof slowing the economy enough to drive inflation back down to its 2% target. It's come close, and inflation has \nStock market today: Asian shares weaken while Japan reports economy grew less than expected Shares have \nslipped in Asia after Japan reported its economy grew le....\ncooled from its peak above 9% last summer. But the worry is that the last percentage point of improvement may be \nthe toughest for the Fed. \nHigh interest rates drag stock prices, especially those of technology companies and others that have been bid up \non expectations for high growth far in the future. Many of those stocks also tend to be the most influential on the \nS&P; 500 because they're the biggest. \nApple, the dominant force on Wall Street because it's the most valuable stock, fell 2.9% after a 3.6% drop a day \nbefore. \nNvidia sank 1.7% to bring its loss for the week so far to 4.7%. It and a cohort of other stocks in the artificial-\nintelligence industry have soared this year on expectations that AI could mean explosive future growth in profits. \nC3.ai tumbled 12.2% after it said late Wednesday that it no longer expects to be profitable in its final fiscal quarter \nof the year, as it invests more in opportunities around generative AI. Analysts also pointed to disappointing profit \nmargin levels for the company during its latest quarter, which was the first of its fiscal year. \nPower companies and other stocks seen as steadier investments also held up better than the rest of the market. \nUtility stocks in the S&P; 500 rose 1.3% as a group. That was nearly double the gain of any of the other 10 sectors \nthat make up the index. \nIn other trading Friday, U.S. benchmark crude oil shed 41 cents to $86.46 a barrel in electronic trading on the New \nYork Mercantile Exchange. It added 67 cents on Thursday. \nBrent crude, the pricing basis for international trading, declined 30 cents to $89.62 a barrel. \nThe dollar slipped to 147.19 Japanese yen from 147.30 late Thursday. \nThe euro was trading at $1.0718, up from $1.0697.\nGraphic\n \nFILE - People walk in front of an electronic stock board showing Japan's Nikkei 225 index at a securities firm on \nSept. 5, 2023, in Tokyo. Shares fell Friday, Sept. 8 in Asia after Japan reported its economy grew less than earlier \nestimated in the last quarter. (AP Photo/Eugene Hoshiko, File)\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Jul2023",
        "header": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.",
        "media": "The New York Times - International Edition",
        "time": "July 3, 2023",
        "section": "TECHNOLOGY",
        "length": "1326 words",
        "byline": "Steve Lohr",
        "story_text": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe New York Times - International Edition\nJuly 4, 2023 Tuesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1326 words\nByline: Steve Lohr\nBody\nABSTRACT\nThe best use for generative A.I. in health care, doctors say, is to ease the heavy burden of documentation that \ntakes them hours a day and contributes to burnout.\nFULL TEXT\nDr. Matthew Hitchcock, a family physician in Chattanooga, Tenn., has an A.I. helper.       \nIt records patient visits on his smartphone and summarizes them for treatment plans and billing. He does some light \nediting of what the A.I. produces, and is done with his daily patient visit documentation in 20 minutes or so.       \nDr. Hitchcock used to spend up to two hours typing up these medical notes after his four children went to bed. \n\"That's a thing of the past,\" he said. \"It's quite awesome.\"       \nChatGPT-style artificial intelligence is coming to health care, and the grand vision of what it could bring is inspiring. \nEvery doctor, enthusiasts predict, will have a superintelligent sidekick, dispensing suggestions to improve care.       \nBut first will come more mundane applications of artificial intelligence. A prime target will be to ease the crushing \nburden of digital paperwork that physicians must produce, typing lengthy notes into electronic medical records \nrequired for treatment, billing and administrative purposes.       \nFor now, the new A.I. in health care is going to be less a genius partner than a tireless scribe.       \nFrom leaders at major medical centers to family physicians, there is optimism that health care will benefit from the \nlatest advances in generative A.I. - technology that can produce everything from poetry to computer programs, \noften with human-level fluency.       \nBut medicine, doctors emphasize, is not a wide open terrain of experimentation. A.I.'s tendency to occasionally \ncreate fabrications, or so-called hallucinations, can be amusing, but not in the high-stakes realm of health care.       \nThat makes generative A.I., they say, very different from A.I. algorithms, already approved by the Food and Drug \nAdministration, for specific applications, like scanning medical images for cell clusters or subtle patterns that \nsuggest the presence of lung or breast cancer. Doctors are also using chatbots to communicate more effectively \nwith some patients.       \nPhysicians and medical researchers say regulatory uncertainty, and concerns about patient safety and litigation, will \nslow the acceptance of generative A.I. in health care, especially its use in diagnosis and treatment plans.       \nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThose physicians who have tried out the new technology say its performance has improved markedly in the last \nyear. And the medical note software is designed so that doctors can check the A.I.-generated summaries against \nthe words spoken during a patient's visit, making it verifiable and fostering trust.       \n\"At this stage, we have to pick our use cases carefully,\" said Dr. John Halamka, president of Mayo Clinic Platform, \nwho oversees the health system's adoption of artificial intelligence. \"Reducing the documentation burden would be \na huge win on its own.\"       \nRecent studies show that doctors and nurses report high levels of burnout, prompting many to leave the profession. \nHigh on the list of complaints, especially for primary care physicians, is the time spent on documentation for \nelectronic health records. That work often spills over into the evenings, after-office-hours toil that doctors refer to as \n\"pajama time.\"       \nGenerative A.I., experts say, looks like a promising weapon to combat the physician workload crisis.       \n\"This technology is rapidly improving at a time health care needs help,\" said Dr. Adam Landman, chief information \nofficer of Mass General Brigham, which includes Massachusetts General Hospital and Brigham and Women's \nHospital in Boston.       \nFor years, doctors have used various kinds of documentation assistance, including speech recognition software and \nhuman transcribers. But the latest A.I. is doing far more: summarizing, organizing and tagging the conversation \nbetween a doctor and a patient.       \nCompanies developing this kind of technology include Abridge, Ambience Healthcare, Augmedix, Nuance, which is \npart of Microsoft, and Suki.       \nTen physicians at the University of Kansas Medical Center have been using generative A.I. software for the last \ntwo months, said Dr. Gregory Ator, an ear, nose and throat specialist and the center's chief medical informatics \nofficer. The medical center plans to eventually make the software available to its 2,200 physicians.       \nBut the Kansas health system is steering clear of using generative A.I. in diagnosis, concerned that its \nrecommendations may be unreliable and that its reasoning is not transparent. \"In medicine, we can't tolerate \nhallucinations,\" Dr. Ator said. \"And we don't like black boxes.\"       \nThe University of Pittsburgh Medical Center has been a test bed for Abridge, a start-up led and co-founded by Dr. \nShivdev Rao, a practicing cardiologist who was also an executive at the medical center's venture arm.       \nAbridge was founded in 2018, when large language models, the technology engine for generative A.I., emerged. \nThe technology, Dr. Rao said, opened a door to an automated solution to the clerical overload in health care, which \nhe saw around him, even for his own father.       \n\"My dad retired early,\" Dr. Rao said. \"He just couldn't type fast enough.\"       \nToday, the Abridge software is used by more than 1,000 physicians in the University of Pittsburgh medical system.       \nDr. Michelle Thompson, a family physician in Hermitage, Pa., who specializes in lifestyle and integrative care, said \nthe software had freed up nearly two hours in her day. Now, she has time to do a yoga class, or to linger over a sit-\ndown family dinner.       \nAnother benefit has been to improve the experience of the patient visit, Dr. Thompson said. There is no longer \ntyping, note-taking or other distractions. She simply asks patients for permission to record their conversation on her \nphone.       \n\"A.I. has allowed me, as a physician, to be 100 percent present for my patients,\" she said.       \nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe A.I. tool, Dr. Thompson added, has also helped patients become more engaged in their own care. Immediately \nafter a visit, the patient receives a summary, accessible through the University of Pittsburgh medical system's \nonline portal.       \nThe software translates any medical terminology into plain English at about a fourth-grade reading level. It also \nprovides a recording of the visit with \"medical moments\" color-coded for medications, procedures and diagnoses. \nThe patient can click on a colored tag and listen to a portion of the conversation.       \nStudies show that patients forget up to 80 percent of what physicians and nurses say during visits. The recorded \nand A.I.-generated summary of the visit, Dr. Thompson said, is a resource her patients can return to for reminders \nto take medications, exercise or schedule follow-up visits.       \nAfter the appointment, physicians receive a clinical note summary to review. There are links back to the transcript of \nthe doctor-patient conversation, so the A.I.'s work can be checked and verified. \"That has really helped me build \ntrust in the A.I.,\" Dr. Thompson said.       \nIn Tennessee, Dr. Hitchcock, who also uses Abridge software, has read the reports of ChatGPT scoring high marks \non standard medical tests and heard the predictions that digital doctors will improve care and solve staffing \nshortages.       \nDr. Hitchcock has tried ChatGPT and is impressed. But he would never think of loading a patient record into the \nchatbot and asking for a diagnosis, for legal, regulatory and practical reasons. For now, he is grateful to have his \nevenings free, no longer mired in the tedious digital documentation required by the American health care industry.       \nAnd he sees no technology cure for the health care staffing shortfall. \"A.I. isn't going to fix that anytime soon,\" said \nDr. Hitchcock, who is looking to hire another doctor for his four-physician practice. \nLoad-Date: July 3, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Oct2023",
        "header": "INTUIT LOOKS TO HUMANS TO REIN IN AI",
        "media": "Wall Street Journal Abstracts",
        "time": "October 25, 2023",
        "section": "B; Pg. 4",
        "length": "41 words",
        "byline": "BELLE LIN",
        "story_text": "INTUIT LOOKS TO HUMANS TO REIN IN AI\nWall Street Journal Abstracts\nOctober 24, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 41 words\nByline: BELLE LIN\nBody\nABSTRACT\nIntuit has released generative-artificial-intelligence tool Intuit Assist to offer customers financial recommendations \nand plans to build staff of eight full-time moderators to review what goes in and what comes out of large-language \nmodel (M)\nLoad-Date: October 25, 2023"
    },
    {
        "file_name": "DealBook_Newsletter_Apr2023",
        "header": "Are Text Messages the New Social Media? One Start-Up Thinks So.;",
        "media": "DealBook Newsletter",
        "time": "April 24, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1766 words",
        "byline": "Andrew Ross Sorkin, Ephrat Livni and Sarah Kessler",
        "story_text": "Are Text Messages the New Social Media? One Start-Up Thinks So.; \nDealBook Newsletter\nThe New York Times \nApril 22, 2023 Saturday 08:59 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1766 words\nByline: Andrew Ross Sorkin, Ephrat Livni and Sarah Kessler\nHighlight: Community, which was first marketed as a way for celebrities to text their fans, now has big brands on \nboard.\nBody\nCommunity, which was first marketed as a way for celebrities to text their fans, now has big brands on board.\nAndrew here. You probably received today’s DealBook newsletter, as you always do, by email. But you probably \ngot a bunch of spam and junk mail in your inbox, too.\nThat’s why so many of us are moving our most important communications to text messages. And in the process, \nthe “text inbox” has become the new holy space for brands, far more intimate than your social media feed.\nAt least, that’s the bet that Ashton Kutcher, the actor turned venture capitalist, and Guy Oseary, Bono’s and \nMadonna’s manager turned investor, made when they co-founded a text message company called Community in \n2019. In the beginning, it was marketed to celebrities to communicate with their fans about tour dates and new \nprojects.\nBut over the last year, the business has quietly grown to power text messages from some of the largest brands, like \nMcDonald’s, HBO, the New York Yankees and Condé Nast. When this month’s Hollywood blockbuster, “The Super \nMario Bros. Movie,” launched an advertising campaign, it came with a phone number for viewers to text, powered \nby Community.\nThe company plans to announce next week that it has raised another $25 million, bringing its total fund-raising to \n$110 million, from investors such as Salesforce Ventures, Morgan Stanley Next Level Fund and Verizon Ventures. \n(It did not disclose its latest valuation.)\nIt also made Robert Wolf, a former chairman of UBS Group Americas, who served as an informal adviser to \nPresident Barack Obama, its new chairman. He started helping to sign up large corporate customers over the past \nyear, bringing the total clients to over 8,000. The company is run by Diankha Linear, a longtime executive who \nserved as an Army logistics and transportation officer.\nCommunity has gained its latest funding as questions have increasingly arisen about social media’s reach and how \ncompanies can own the digital relationship with their customers without a middleman like Facebook or Twitter.\n“I started out with Twitter and built a fairly large following on Twitter,” said Mr. Kutcher, who has 16.8 million \nfollowers. “But Twitter today is very different than what Twitter was when I originally started playing around it,” he \nadded. “The click-through rates are massively degraded — the number of people that actually see the post is \nmassively degraded.”\nAre Text Messages the New Social Media? One Start-Up Thinks So. DealBook Newsletter\nAt Community, in contrast, “we have like 45 percent click-through rates and 98 percent open rates,” Mr. Kutcher \nsaid. “You don’t get that in social environments because most people don’t even see the things you’re posting.”\nCommunity competes with a bevy of different types of services vying for space in your text inbox, from Attentive to \nTwilio to Zendesk. And many of the software platforms that companies use to manage their relationships with \ncustomers now have features that facilitate texting.\nBut what sets Community apart is the dialogue that celebrities and brands have with their customers, who provide \ntroves of information about themselves, which the brand owns and isn’t shared with Community’s other clients.\nOseary was originally drawn to Community because of his role as a music manager, he said.\n“I have no way to know who came to the concert tonight. I have no way to speak to them again once they leave the \nconcert. I have no way to know who bought the album,” he said. “With Community, once they text the number, we \nnow have a way to stay in touch directly. And that information is not owned by anyone but the artist, the talent or the \nperson who’s building a business.”\nCompanies advertise a phone number that users text to sign up for updates. McDonald’s posted its number on a \nbillboard in Times Square just this month. The service also allows brands to segment customers who sign up for \ntexts, so if an artist has an concert coming up in Atlanta, only people in Atlanta get the texts.\nUsing text messages to connect with customers, for all its promise, poses unique challenges. Brands are required \nto get their customers to opt in to messages, which is hard to do unless the brand is already well established. And \ncustomers may want to hear from fewer brands in their text inbox than they do in their email inbox.\n“As opposed to email, when you have to scroll to the bottom of the thing and hit the link that says unsubscribe, if \nyou don’t like the text messages you’re getting, you only have to write one word: Stop,” Mr. Kutcher said. (That’s \nsome news you can use.)\nIN CASE YOU MISSED IT \nRupert Murdoch makes another deal. Fox News settled a defamation case with Dominion Voting Systems at the \nlast minute for $788 million. The deal allowed Murdoch and his company’s executives to avoid having to testify, but \nit also handed Staple Street, the private equity owner of Dominion, a big payday after it bought the company for $38 \nmillion in 2018. His son Lachlan, C.E.O. of Fox Corporation, also settled a separate defamation suit against an \nAustralian publisher this week.\nReturn to sender. Netflix ended its DVD delivery service after 25 years. The streaming company’s original business \nmodel revolved around sending discs by mail, and at its peak, in 2010, about 20 million subscribers used the \nservice. The company announced the changes as it reported first-quarter profits of $1.3 billion, up 4 percent year on \nyear.\nGary Gensler gets a grilling. The chair of the Securities and Exchange Commission, was hammered by \nRepublicans over the agency’s handling of the cryptocurrency industry, in an appearance before the House \nFinancial Services Committee. Gensler defended the regulator, saying he had never seen a sector break so many \nsecurities laws with such regularity, after being accused of failing to spot problems at FTX before the cryptocurrency \nexchange collapsed.\nChina’s economy bounces back, kind of. In its first full quarter since Beijing lifted punishing Covid restrictions, the \nworld’s second-largest economy beat expectations on the back of surging consumer spending, rising exports and \ngovernment-led infrastructure spending. But youth unemployment hit 19.6 percent, its second-highest mark on \nrecord, suggesting that businesses are not convinced that Beijing is finished dabbling in the private sector and that \neconomic uncertainty is over.\nGoldman Sachs quickens its retail banking U-turn. The Wall Street giant reported lackluster first-quarter returns and \naccelerated its retreat from consumer banking, including putting its GreenSky unit up for sale just a year after \nAre Text Messages the New Social Media? One Start-Up Thinks So. DealBook Newsletter\nbuying the lending company for $2.2 billion. One spot of new business: The bank introduced a savings account with \nApple that offers a 4.15 percent annual interest rate — more than 10 times the national average.\nBMW gets into hot water over ice cream. The German carmaker was forced to apologize after being accused of \ndiscriminating against Chinese visitors to the Shanghai auto show this week. Images went viral on Chinese social \nmedia of workers at its booth appearing to give free ice cream to a western man after telling ethnic Chinese \nattendees that they had run out.\nTerm of the week: ‘Greenhushing’\nEver since Earth Day was established in 1970, companies have advertised their green initiatives on April 22. But \nwith many Republicans now taking a strong stand against corporate environmentalism and targeting companies \nthat publicize their climate change-related goals, you might see fewer companies touting their green credentials this \nyear. Instead, some businesses are resorting to “greenhushing.” An analysis of 1,200 companies published last fall \nby South Pole, a Swiss consultancy, found that one in four planned to go green but then “go dark” — that is, keep \nits green goals under the radar.\nA.I., the artist \nArtificial intelligence has had a creative few weeks: A song that used A.I. to mimic the voices of Drake and The \nWeeknd went viral; a murder-mystery novel penned using A.I. is available to preorder; and an image generated by \nA.I. won one of the world’s biggest photography prizes. DealBook wrote last week that A.I. was creating thorny \ncopyright issues, but it is also raising questions about the nature of human creativity itself.\nCompanies have tried to draw lines between human and machine-generated work. Streaming services, including \nSpotify and Apple Music, pulled the tech-created song from their platforms this week. And Universal Music Group \nurged the services to block A.I. from scraping its songs for use as training data.\nSome artists see creative possibilities rather than threats. Stephen Marche, who wrote the cheekily titled “Death of \nan Author” novel using three A.I. programs, compared the process to composing hip-hop: “You don’t necessarily \nknow how to drum, but you definitely need to know how beats work, how hooks work, and you need to be able to \nput them together in a meaningful way,” he told The New York Times. “I am the creator of this work, 100 percent,” \nMarche said, “but, on the other hand, I didn’t create the words.”\nWho is the creator? Boris Eldagsen, the Berlin artist whose A.I.-generated “Pseudomnesia: The Electrician” won the \ncreative open category at the Sony World Photography Awards, told DealBook that making the image had been like \ndirecting a film.\n“On a movie there is a set director, there is a cameraman, and there is an actress and a story writer, and I tell them \nwhich direction to go,” he said. “I am the one, as an artist, who needs to connect all of this to the world, the human \ncondition.”\nHe entered the competition to kick-start a conversation about separating the art of photography from A.I.-generated \nart, which he considers co-creation.\nBut who should take credit for this type of collaboration? Generative A.I. is informed by reference material created \nby human artists. It becomes more complicated when A.I. is used to imitate a particular performer, or a specific \nartist’s drawing style. Last month, the Recording Industry Association of America launched a “human artistry \ncampaign,” which argues that the makers of A.I. need to license copyrighted work they use as training data. And \nHolly Herndon, a musician, started a company to build consent guidelines for the tech. “The creative possibilities \nthere are fascinating and will change art forever,” she told The Times. “We just have to figure out the terms and \ntech.”\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nAre Text Messages the New Social Media? One Start-Up Thinks So. DealBook Newsletter\nPHOTO: The actor Ashton Kutcher co-founded Community, a text message company, in 2019. (PHOTOGRAPH BY \nAUDE GUERRUCCI/REUTERS) This article appeared in print on page B3.\nLoad-Date: April 24, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Jan2024",
        "header": "A layperson's guide to generative AI",
        "media": "The Baltimore Sun",
        "time": "January 17, 2024",
        "section": "MAIN; A; Pg. 15",
        "length": "921 words",
        "byline": "Zafar Daud",
        "story_text": "A layperson's guide to generative AI\nThe Baltimore Sun\nJanuary 17, 2024 Wednesday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 15\nLength: 921 words\nByline: Zafar Daud\nBody\nIn a world where machines crack jokes and compose sonnets, the term \"Generative AI\" inevitably stirs both awe \nand apprehension. If you're curious about the headlines around Generative AI and want to understand what it is \n(without the tech jargon!), this guide is for you. It clarifies how this technology affects your daily life (think: \nautocorrect) and debunks the myths fueling public anxiety. It's time to take a close look at what it is, how it works, \nand why it should not send shivers down your spine.\nArtificial Intelligence (AI) isn't some futuristic novelty. In fact, its roots stretch back to World War II, with the invention \nof the first digital computers. Progress was initially slow, but this century has witnessed an explosion, with AI now \nencompassing a vast array of techniques. One key branch is machine learning. Think of it as teaching a computer \nto learn from data, like recognizing faces in photographs. Imagine feeding it thousands of labeled images - eyes, \nnoses, mouths - and watch as it identifies these features in new pictures, all on its own.\nNow, picture a human brain under a microscope. You'll see billions of microscopic cells called neurons, \ninterconnected in a vast web. This intricate network is the inspiration for neural networks, a software technology \ndesigned to mimic the brain's learning abilities. Each neuron in an artificial network performs a simple pattern \nrecognition task, searching for specific features in data. Millions of these tiny tasks working in concert allow the \nnetwork to recognize complex patterns, like faces or handwritten digits.\nBut how do neural networks learn? The answer lies in big data. Just like you wouldn't teach a child about cars \nwithout showing them pictures, an AI needs vast amounts of data to learn its craft. Every time you tag a friend on \nFacebook or upload a vacation photo, you're contributing to the data pool that fuels AI advancements. And it's not \njust social media. Medical scans, traffic patterns and even weather data - all this information feeds the insatiable \nappetite of machine learning algorithms.\nNow, let's introduce Generative AI, a subfield that takes learning a step further. It leverages existing information to \ncreate entirely new content, be it text, images, music or even code. Imagine training an AI on a library of novels. It \nwouldn't just analyze their structure; it would learn the nuances of language, storytelling, and human emotions. With \nthis knowledge, it could then craft its own original stories, poems or even dialogue scripts.\nGenerative AI might seem futuristic, but you've likely encountered it without even realizing it. Google Translate, \nyour trusty companion in foreign lands, is a product of this technology. So is Siri, your ever-helpful digital assistant, \nand the autocorrect feature on your smartphone. These are just a few examples of how Generative AI has \nseamlessly integrated into our daily lives.\nSo, why the current excitement surrounding GPT-4, OpenAI's latest marvel? This powerful model excels at tasks \nbeyond simple translation or autocomplete. It can write convincing prose, generate realistic images, and even craft \nA layperson's guide to generative AI\nlines of code. Some claim it could outperform most students on standardized tests - a feat that sparked both \nadmiration and concern.\nThe technology powering GPT-4 is called Large Language Modeling (LLM). Imagine a complex game of predicting \nthe next word in a sentence. LLM, having devoured mountains of text, knows the statistical probabilities of word \npairings. Based on this knowledge, it can weave sentences, paragraphs and even entire narratives, mimicking the \nstyle and tone of its training data.\nBut how does LLM learn this linguistic magic? The process starts with data collection, performed by tireless internet \ncrawlers that follow links like curious spiders to scoop up everything they can find online. This digital smorgasbord \nis then fed into a massive neural network, which analyzes the patterns and relationships within the data. The sheer \nvolume of text - GPT-4 has devoured billions of words - allows the network to learn the subtleties of language, \nnuance and even humor.\nDespite its impressive feats, even GPT-4 has limitations. It hasn't seen everything humans have written, and its \ntraining data, while vast, still represents a fraction of the world's written word. Additionally, training these models is \na costly endeavor, with GPT-4 requiring more than $100 million. This exclusivity restricts their development to well-\nfunded labs and tech giants.\nThe rise of Generative AI may spark anxieties about job displacement or robotic overlords. But like any \ntransformative technology, its impact will be nuanced and far-reaching, not a singular blow to existing systems. \nRemember the fear surrounding the launch of Lotus 1-2-3 in the 1980s? While spreadsheets did indeed change the \noffice landscape, they created countless new opportunities, making information analysis far more accessible and \nefficient. Similarly, Generative AI won't simply replace jobs; it will reshape them, requiring new skills and fostering \ncollaboration between humans and machines.\nSo, the next time you hear \"Generative AI,\" don't fear. Remember the transformative potential of technology, its \nability to empower and enhance rather than replace. Look to the horizon, not with trepidation, but with excitement. \nThe journey ahead, led by humans and machines in tandem, promises to be breathtaking.\nZafar Daud (zafardaud@gmail.com) is CEO and Founder of Coding and Robotics Academy in Maryland.\nLoad-Date: January 17, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 21, 2023",
        "section": "STARTUPS & TECH",
        "length": "417 words",
        "byline": "Romita.Majumdar@timesgroup.com",
        "story_text": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts\nEconomic Times (E-Paper Edition)\nAugust 18, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 417 words\nByline: Romita.Majumdar@timesgroup.com\nHighlight: HOWEVER... Experts see creation of high-level jobs, involving more decision making, strategic calls\nBody\nMumbai: Artificial Intelligence (AI) will replace up to 5% FTE or full-time technology roles annually over the next 4-5 \nyears, said analysts.  However, while basic jobs are replaced with AI-based automation solutions, technology \nexperts expect a higher level of jobs to be created which will involve less support roles and more decision making \nand strategic roles. Roles in AI ethics and sustainability practices will also come in demand. \n Executives from leading automation companies like ServiceNow and UiPath see this change in job profiles \nevolving over the years as enterprises themselves figure out their AI strategy. Historically, whenever a \ngroundbreaking new technology is introduced in any sector, it just leads to a lot more new work, ServiceNow CTO \nPat Casey told ET during an interaction in July. “If you look at the larger  tech ecosystem, there is always a dearth \nof engineering talent. So, if certain jobs are automated, it will not mean that people will become jobless, just that \nthey work on more valueadded work elsewhere,” said Casey. According to a study by McKinsey Global Institute \ntitled Generative AI and the Future of Work in America, in June, an estimated 12 million occupational transitions \nmay be required in the US alone by 2030. The maximum impact on productivity will be in the areas of marketing \nand sales. It will also have a significant impact on functions like customer oper-  ations, product development and \nsoftware development.  Outsourcing expert Pareekh Jain estimates about 5% FTE roles annually to mature to \nnewer roles as they are replaced by AI tools.  “It will not be a massive shift overnight. It is the support roles that do \nnot require much decision-making capabilities where such changes will happen and they have already been in \nprogress for years,” said Jain. He added that there could be some nearterm impact on certain low-level jobs before \ncompanies fully assess the efficiency of such tools. But the long-  term impact will be small.  Robotic process \nautomation major UiPath's co-CEO Rob Enslin added that one of the chief problems that customers bring to them is \nto help identify where they can reduce inefficiencies. “We see some interesting use cases where citizen developers \nare able to create solutions for healthcare use cases in Denmark and it is a great example of how AI can enable a \nlot more non-technical talent to automate tasks that are essential but critical to their jobs ,” said Enslin.FOR FULL \nREPORT, GO TO www.economictimes.com\nLoad-Date: August 21, 2023"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_May2024",
        "header": "AIRLINES, AIRPORTS GATHER FOR ROBOTICS SUMMIT",
        "media": "Pittsburgh Post-Gazette",
        "time": "May 16, 2024",
        "section": "BUSINESS; Pg. D-1",
        "length": "503 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "AIRLINES, AIRPORTS GATHER FOR ROBOTICS SUMMIT\nPittsburgh Post-Gazette\nMay 16, 2024 Thursday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: BUSINESS; Pg. D-1\nLength: 503 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nAlaska Airlines is now using generative AI to turn natural language prompts like \"I want a festive Christmas \nvacation somewhere not too crowded\" into fully realized itineraries, the airline's director of innovation announced \nWednesday in Pittsburgh.\n\"We're the first airline to launch natural language search,\" Bernadette Berger said to a room full of transportation \nleaders gathered at the Heinz History Center for the city's second annual aviation and robotics summit.\nThe three-day event is structured to brainstorm solutions that can modernize the future of travel. Last year's \nproblem-solving sessions included ideas like self-driving wheel chocks to keep planes from rolling away, and helped \nspark a new Pittsburgh startup, Journey Robotics.\n\"We're bringing people in to say: 'Help us think about what your product can do â€¦ for not just us, but an entire \nindustry,\" said Christina Cassotis, CEO of Allegheny County Airport Authority, which oversees Pittsburgh \nInternational Airport.\nThe authority plans to choose one prototype that can go to market and fund the idea with up to $75,000, in \npartnership with the Hillman Foundation.\n\"We're going to take one of these ideas, and we're gonna put our money where our mouth is,\" Ms. Cassotis said.\nShe highlighted two innovations already underway at the airport: on-site energy creation and on-site fuel production, \nthrough a potential partnership with CNX Resources announced this week.\n\"We really intend to be the first airport to produce sustainable aviation fuel on site and then barge it up to some \nother airports who might need it,\" Ms. Cassotis said.\nShe also gave a shoutout to Cole Wolfson, who leads the authority's xBridge program to engage startups in the \nregion.\nDozens of airlines and airport executives, from Washington to Phoenix, and Alaska to the United Kingdom, will \nparticipate in the workshops this week. Andrew Masich, CEO of the Heinz History Center, wanted to make sure \nthey understood the setting for those conversations.\n\"The history of flight has a connection to Pittsburgh,\" he said. \"We all know the Wright brothers got off the ground at \nKitty Hawk\" - but that inaugural ride wouldn't have been possible without a lighter engine block manufactured by the \nAluminum Company of America, or Alcoa, which is still based in Pittsburgh.\nAIRLINES, AIRPORTS GATHER FOR ROBOTICS SUMMIT\nIn space travel, too, the Steel City played a role.\n\"Neil Armstrong, the commander of Apollo 11 that launched in 1969 to go to the moon - he was launched in a \nrocket built by a Pittsburgh company, North American Rockwell. A Saturn 5 rocket - no one had ever seen anything \nlike that before.\" Mr. Masich said.\nThe glass in the Columbia capsule? Made by PPG. \"Pittsburgh plated glass they called it in 1969,\" he said.\nThe live motion pictures of Armstrong's first steps on the moon? Brought to you by Westinghouse.\nGiven that history, \"it's altogether fitting and proper,\" that the aviation and robotics summit has found a home in \nPittsburgh, Mr. Masich said.\nEvan Robinson-Johnson: ejohnson@post-gazette.com and @sightsonwheels\nGraphic\n \nPHOTO: Evan Robinson-Johnson/Post-Gazette: Bernadette Berger, Alaska Airlines' director of innovation, \nannounces Wednesday a new generative AI tool to help passengers book trips with natural language prompts at \nthe second annual aviation and robotics summit in Pittsburgh. Artificial intelligence is expected to be one of the \nguiding technologies influencing how airports and airlines plan for the future of travel.\nLoad-Date: May 16, 2024"
    },
    {
        "file_name": "Federal_Election_Commission_has_begun_a_process_to_potentially_regulate_AI-_Aug2023",
        "header": "FEC moves toward potentially regulating AI deepfakes in campaign ads; The",
        "media": "Federal Election Commission has begun a process to potentially regulate AI-",
        "time": "August 11, 2023",
        "section": "NATION WORLD",
        "length": "1060 words",
        "byline": "ALI SWENSON",
        "story_text": "FEC moves toward potentially regulating AI deepfakes in campaign ads; The \nFederal Election Commission has begun a process to potentially regulate AI-\ngenerated deepfakes in political ads ahead of the 2024 election\nDayton Daily News (Ohio)\nAugust 11, 2023 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1060 words\nByline: ALI SWENSON\nBody\nThe Federal Election Commission has begun a process to potentially regulate AI-generated deepfakes in political \nads ahead of the 2024 election, a move advocates say would safeguard voters against a particularly insidious form \nof election disinformation.\nThe FEC's unanimous procedural vote on Thursday advances a petition asking it to regulate ads that use artificial \nintelligence to misrepresent political opponents as saying or doing something they didn't  a stark issue that is \nalready being highlighted in the current 2024 GOP presidential primary. \nThough the circulation of convincing fake images, videos or audio clips is not new, innovative generative AI tools \nare making them cheaper, easier to use, and more likely to manipulate public perception. As a result, some \npresidential campaigns in the 2024 race  including that of Florida GOP Gov. Ron DeSantis  already are using them \nto persuade voters. \nThe Republican National Committee in April released an entirely AI-generated ad meant to show the future of the \nUnited States if President Joe Biden is reelected. It employed fake but realistic photos showing boarded-up \nstorefronts, armored military patrols in the streets, and waves of immigrants creating panic. \nIn June, DeSantis' campaign shared an attack ad against his GOP primary opponent Donald Trump that used AI-\ngenerated images of the former president hugging infectious disease expert Dr. Anthony Fauci. \nSOS America PAC, which supports Miami Mayor Francis Suarez, a Republican, also has experimented with \ngenerative AI, using a tool called VideoAsk to create an AI chatbot in his likeness. \nThursday's FEC meeting comes after the advocacy group Public Citizen asked the agency to clarify that an existing \nfederal law against \"fraudulent misrepresentation\" in campaign communications applies to AI-generated deepfakes. \nThe panel's vote shows the agency's intent to consider the question, but it will not decide whether to actually \ndevelop rules governing the ads until after a 60-day public comment window, which is likely to begin next week. \nIn June, the FEC deadlocked on an earlier petition from the group, with some commissioners expressing skepticism \nthat they had the authority to regulate AI ads. Public Citizen came back with a new petition identifying the fraudulent \nmisrepresentation law and explaining it thought the FEC did have jurisdiction. \nA group of 50 Democratic lawmakers led by House Rep. Adam Schiff also wrote a letter to the FEC urging the \nagency to advance the petition, saying, \"Quickly evolving AI technology makes it increasingly difficult for voters to \nFEC moves toward potentially regulating AI deepfakes in campaign ads The Federal Election Commission has \nbegun a process to potentially regulate AI-generated de....\naccurately identify fraudulent video and audio material, which is increasingly troubling in the context of campaign \nadvertisements.\" \nRepublican Commissioner Allen Dickerson said in Thursday's meeting he remained unconvinced that the agency \nhad the authority to regulate deepfake ads. \n\"I'll note that there's absolutely nothing special about deepfakes or generative AI, the buzzwords of the day, in the \ncontext of this petition,\" he said, adding that if the FEC had this authority, it would mean it also could punish other \nkinds of doctored media or lies in campaign ads. \nDickerson argued the law doesn't go that far, but noted the FEC has unanimously asked Congress for more \nauthority. He also raised concerns the move would wrongly chill expression that's protected under the First \nAmendment. \nPublic Citizen President Robert Weissman disputed Dickerson's points, arguing in an interview Thursday that \ndeepfakes are different from other false statements or media because they fraudulently claim to speak on a \ncandidate's behalf in a way that's convincing to the viewer. \n\"The deepfake has an ability to fool the voter into believing that they are themselves seeing a person say or do \nsomething they didn't say,\" he said. \"It's a technological leap from prior existing tools.\" \nWeissman said acknowledging deepfakes are fraud solves Dickerson's First Amendment concerns too  while false \nspeech is protected, fraud is not. \nLisa Gilbert, Public Citizen's executive vice president, said under its proposal, candidates would also have the \noption to prominently disclose the use of artificial intelligence to misrepresent an opponent, rather than avoid the \ntechnology altogether. \nShe argued action is needed because if a deepfake misleadingly impugning a candidate circulates without a \ndisclaimer and doesn't get publicly debunked, it could unfairly sway an election. \nFor instance, the RNC disclosed the use of AI in its ad, but in small print that many viewers missed. Gilbert said the \nFEC could set guidelines on where, how and for how long campaigns and parties need to display these disclaimers. \nEven if the FEC decides to ban AI deepfakes in campaign ads, it wouldn't cover all the threats they pose to \nelections. \nFor example, the law on fraudulent misrepresentation wouldn't enable the FEC to require outside groups, like \nPACs, to disclose when they imitate a candidate using artificial intelligence technology, Gilbert said. \nThat means it wouldn't cover an ad recently released by Never Back Down, a super PAC supporting DeSantis, that \nused an AI voice cloning tool to imitate Trump's voice, making it seem like he narrated a social media post. \nIt also wouldn't stop individual social media users from creating and disseminating misleading content  as they long \nhave  with both AI-generated falsehoods and other misrepresented media, often referred to as \"cheap fakes.\" \nCongress, however, could pass legislation creating guardrails for AI-generated deceptive content, and lawmakers, \nincluding Senate Majority Leader Chuck Schumer, have expressed intent to do so. \nSeveral states also have discussed or passed legislation related to deepfake technology. \nDaniel Weiner, director of the Elections and Government Program at the Brennan Center for Justice, said \nmisinformation about elections being fraudulently stolen is already a \"potent force in American politics.\" \nMore sophisticated AI, he said, threatens to worsen that problem. \nFEC moves toward potentially regulating AI deepfakes in campaign ads The Federal Election Commission has \nbegun a process to potentially regulate AI-generated de....\n\"To what degree? You know, I think we're still assessing,\" he said. \"But do I worry about it? Absolutely.\" \n___ The Associated Press receives support from several private foundations to enhance its explanatory coverage \nof elections and democracy. See more about AP's democracy initiative here. The AP is solely responsible for all \ncontent.\nGraphic\n \nCommissioner Allen Dickerson, appears on a screen, while speaking during a Federal Election Commission public \nmeeting on whether it should regulate the use of AI-generated political campaign advertisements, Thursday, Aug. \n10, 2023, in Washington. (AP Photo/Stephanie Scarbrough)\nLoad-Date: August 11, 2023"
    },
    {
        "file_name": "The_Economic_Times_Nov2023",
        "header": "Google may invest in Indian AI company Corover.ai",
        "media": "The Economic Times",
        "time": "November 27, 2023",
        "section": "FUNDING",
        "length": "440 words",
        "byline": "Annapurna Roy",
        "story_text": "Google may invest in Indian AI company Corover.ai\nThe Economic Times\nNovember 27, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 440 words\nByline: Annapurna Roy\nBody\nGoogle is close to investing about $4 million in homegrown conversational artificial intelligence startup Corover.ai, \nsaid people in the know, in yet another indicator that the Indian AI startup space is poised for explosive growth.Last \nweek, ET reported that Adobe has acquiredBengaluru-based AI-based video creation platform Rephrase.ai.Corover \nis among a handful of Indian startups building an indigenous large language model (LLM), called BharatGPT, which \nclaims to support more than a dozen Indian languages.While Google made a non-equity funding of $500,000 in \nCorover after signing an agreement with the startup in March this year, it is in discussions to invest $4 million in \nequity following the official launch of BharatGPT in the coming weeks, said the people cited above.They added that \nthe startup has received a substantial amount of the $500,000 funding since March, with the rest set to be received \nby December.As a ‘strategic partner’, Google provides credits to Corover to access cloud computing. The cash \ninfusion will go into scaling up BharatGPT in the coming weeks, people said.Google and Corover did not respond to \nET’s queries till press time on Sunday.Founded in 2016, Corover’s existing investors include CanBank Venture \nCapital Fund, Lead Angels, Cognify, Karekeba Ventures, and IIIT-Delhi, sources said.As per Tracxn, the startup \nwas valued at $8.5 million as of December 2022.The startup counts IRCTC, NPCI, ICICI Prudential, ITC, Max Life \nInsurance, Bosch, Karnataka Tourism, Israel Tourism, Chandigarh Smart City, Car and Bike among its existing \nclients and partners, as per its website.Experts said several homegrown companies working with Indian languages \nare on the radar of global tech companies looking to expand their capabilities in the AI domain, especially in diverse \nIndian vernacular languages.ET reported on November 22 that US software major Adobe acquired Lightspeed-\nbacked Rephrase.ai in a vid to integrate the Indian firm’s tech stack and Generative AI video capabilities with its in-\nhouse video-editing platform Creative Cloud.The acquisition marked the first-ever deal for Adobe in the Gen AI and \nvideo-tooling space. \nIt also made Rephrase the first Indian startup to be acquired by Adobe, which has largely struck such deals in its \nhome market of the US, and in Europe.Corover offers text, audio and video chatbot in Indian and foreign \nlanguages, which can be integrated across platforms like WhatsApp, Signal, Zoom, Salesforce, and SAP, as per its \nwebsite. It has clients across banking, finance, healthcare, manufacturing, travel and ecommerce domains. For \nReprint Rights: timescontent.com\nLoad-Date: November 27, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2023",
        "header": "Elon Musk plans AI startup to compete with OpenAI's ChatGPT : report",
        "media": "The Economic Times",
        "time": "April 14, 2023",
        "section": "TECH & INTERNET",
        "length": "348 words",
        "byline": " ",
        "story_text": "Elon Musk plans AI startup to compete with OpenAI's ChatGPT : report\nThe Economic Times\nApril 15, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 348 words\nBody\nElon Musk, the CEO of Twitter and EV maker Tesla, is planning to launch a new artificial intelligence startup to \ncompete with Microsoft-backed OpenAI's ChatGPT, Financial Times (FT) reported on Friday.Elon Musk is currently \nengaging in talks with several investors from SpaceX and Tesla regarding potential investments in his new venture, \naccording to the report. Musk has also secured thousands of high-powered GPU processors from Nvidia, the report \nsaid citing sources. \nET had reported in February, citing a report from US-based tech news platform The Information, that Musk had \napproached several AI researchers to form a new lab which will work on developing an alternative to ChatGPT.The \nTwitter CEO had reached out to Igor Babuschkin, a researcher who recently left Alphabet's DeepMind AI unit and \nspecialises in the kind of machine-learning models that power chatbots like ChatGPT, according to the report by \nThe Information..The planned venture would give Musk the chance to go up against OpenAI, the organisation \nsupported by Microsoft that he co-founded in 2015. Musk left the board three years later as a result of conflicts with \nthe organisation's management, which included divergent opinions on AI safety, the FT report added. Over the last \nfew months, Musk has repeatedly criticised the company for installing safeguards that prevent ChatGPT from \nproducing text that might offend users.Musk and a group of artificial intelligence experts and industry \nexecutivescalled for a six-month pause in training systems more powerful than OpenAI's newly launched model \nGPT-4, last month, in an open letter, citing potential risks to society and humanity.Microsoft, an early backer of \nOpenAI, has reportedly invested another $10 billion in it. Meanwhile, Meta Platforms Inc is creating a new top-level \nproduct group focused on generative artificial intelligence, CEO Mark Zuckerberg said in February..OpenAI took \nthe internet by storm last November when it released the generative AI chatbot ChatGPT, which produces answers \nmimicking human speech. For Reprint Rights: timescontent.com\nLoad-Date: April 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Taking Notes on the A.I. Learning Hype",
        "media": "The New York Times",
        "time": "September 10, 2023",
        "section": "Section A; Column 0; Metropolitan Desk; Pg. 2; TIMES INSIDER",
        "length": "982 words",
        "byline": "By Natasha Singer",
        "story_text": "Taking Notes on the A.I. Learning Hype\nThe New York Times\nSeptember 10, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Metropolitan Desk; Pg. 2; TIMES INSIDER\nLength: 982 words\nByline: By Natasha Singer\nBody\nSome tech proponents say generative artificial intelligence will revolutionize education. Yet, some schools are \nblocking it. Here was a chance for reporting.\nTimes Insider explains who we are and what we do and delivers behind-the-scenes insights into how our journalism \ncomes together. \n  In January, Marisa Shuman, a computer science teacher at the Young Women's Leadership School of the Bronx, \ninvited me to spend a few days embedded in her classroom.\n  Her school, a public middle and high school for girls, specializes in math, science and technology. And she \nthought I might be interested in a lesson she had just prepared on ChatGPT, an artificial intelligence-powered \nchatbot that can manufacture book reports and social studies essays.\n  As a reporter who has spent years chronicling how tech companies and their tools are reshaping public schools, I \njumped at the chance.\n  At the time, ChatGPT was beginning to blow up in schools and on college campuses. Tech executives had started \npromoting familiarity with A.I. tools as a crucial skill for students.\n  Meanwhile, New York City Public Schools, the nation's largest school system, had just blocked access to \nChatGPT on school devices and networks over concerns of cheating and inaccuracy.\n  Ms. Shuman, however, saw it as a teachable moment.\n  She used ChatGPT at home to generate a lesson on fitness trackers and other wearable technology. Then she \ntried the material with her 11th and 12th graders.\n  She told her students that she didn't care if they learned nothing about wearable tech. But she did want them to \nexamine the accuracy and effectiveness of the lesson that the chatbot had generated.\n  In other words, Ms. Shuman was using the A.I. tool as an exercise for her students to practice critical tech \nthinking.\n  And her students were freely critical. They found that the chatbot-generated lesson contained errors, used \nadvertising come-ons and asked over-simplistic questions.\n  ''It reminded me of fourth grade,'' one student said.\nTaking Notes on the A.I. Learning Hype\n  It was a reminder to me that there is no substitute for journalists visiting institutions to observe what is happening \nfirsthand and interviewing participants face-to-face. It was also the spark for a reporting project that would take me \nacross the country: If we wanted to offer readers an on-the-ground view of the new A.I. education boom, I needed \nto visit a lot more classrooms.\n  I was already aware that some school districts were feeling pressure to quickly introduce generative A.I. \ntechnologies -- that is, tools like ChatGPT, trained on vast databases of digital texts or images, that can produce \ntexts or visuals in seconds -- for student use.\n  That was partly because some prominent tech companies, executives and billionaires were hailing A.I. chatbots as \neducation game-changers. The tools, they promised, were sure to revolutionize, and automatically personalize, \nstudent learning.\n  There was also widespread FOMO: Some tech leaders warned that students would be unable to compete for jobs \nif they didn't know how to use A.I.\n  I set out to learn how these tools were affecting teaching and learning in schools -- and whether the classroom \nreality lived up to a form of ed-tech hype I'd covered before.\n  Over the years, Silicon Valley companies, billionaires and industry-financed nonprofits have promoted a series of \ntech products as revolutionary education innovations. But so far, there's not much rigorous evidence showing that \nvideo-based tutorials or personalized learning apps have significantly improved students' educational outcomes.\n  So I wondered: Would generative A.I. be different?\n  I was fascinated by the promise of A.I. tutoring bots. So I started off by spending a morning at Khan Lab School, a \nnonprofit private school in Palo Alto, Calif., where a sixth-grade math class was trying out a new A.I. tutor called \nKhanmigo.\n  There, teachers encouraged students to tinker with the bot, which was developed specifically for school use by \nKhan Academy, a related -- but separately run -- nonprofit education organization.\n  Some students playfully asked Khanmigo to answer math questions in Gen Z slang or in the form of a rap song. \nOne student who caught Khanmigo making an addition error promptly corrected the bot.\n  Across the country, I found reviews of the tutoring bot more mixed.\n  At First Avenue Elementary School in Newark, a third-grade teacher leading a class on fractions posted specific \nmath questions on a white board that she wanted her students to ask Khanmigo. The bot responded by giving the \nstudents step-by-step instructions to solve the problems.\n  School officials who observed the class told me that they found the A.I. tool overly helpful. They said they wanted \nstudents to be able to think through the problem-solving steps themselves.\n  I've seen a lot of enthusiasm, and innovative uses, of A.I. in schools as well. On a recent visit to Walla Walla, \nWash., about a four-hour drive from Seattle, I met teachers who were using ChatGPT to create imaginative literary \ngames and storytelling assignments for their students.\n  But the lesson I learned from visiting schools this year was not so much about technology skills.\n  From the Bronx to Walla Walla, school officials and teachers told me that they felt it was as important for students \nto learn to ask critical questions about artificial intelligence as it was to learn how to use the technology. In fact, for \nsome of them, it was even more important.\n  I also learned that there were more stories to report, as many schools and teachers are only beginning to discuss \nwhat they think A.I. education should look like.\nTaking Notes on the A.I. Learning Hype\n  So I'm planning to visit more schools soon. If you're an educator who would like to host me at your school or share \nyour experience using A.I. tools, please fill out this form.Natasha Singer reports for The Times on the ways that tech \ngiants and their tools are reshaping education.\nhttps://www.nytimes.com/2023/09/09/business/ai-learning-classrooms.html\nGraphic\n \nPHOTOS: Third graders in Palo Alto, Calif., top, probed an artificial intelligence-powered classroom aid. In the \nBronx, Marisa Shuman, above, asked her students to critique material generated by A.I. (PHOTOGRAPHS BY \nULYSSES ORTEGA FOR THE NEW YORK TIMES\n HIROKO MASUIKE/THE NEW YORK TIMES) This article appeared in print on page A2.               \nLoad-Date: September 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "How Schools Can Cope and Grow When Their Students Are Using A.I.",
        "media": "The New York Times",
        "time": "August 29, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT",
        "length": "1158 words",
        "byline": "By Kevin Roose",
        "story_text": "How Schools Can Cope and Grow When Their Students Are Using A.I.\nThe New York Times\nAugust 29, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT\nLength: 1158 words\nByline: By Kevin Roose\nBody\nStep 1: Assume all students are going to use the technology.\nLast November, when ChatGPT was released, many schools felt as if they'd been hit by an asteroid. \n  In the middle of an academic year, with no warning, teachers were forced to confront the new, alien-seeming \ntechnology, which allowed students to write college-level essays, solve challenging problem sets and ace \nstandardized tests.\n  Some schools responded -- unwisely, I argued at the time -- by banning ChatGPT and tools like it. But those bans \ndidn't work, in part because students could simply use the tools on their phones and home computers. And as the \nyear went on, many of the schools that restricted the use of generative A.I. -- as the category that includes \nChatGPT, Bing, Bard and other tools is called -- quietly rolled back their bans.\n  Ahead of this school year, I talked with numerous K-12 teachers, school administrators and university faculty \nmembers about their thoughts on A.I. now. There is a lot of confusion and panic, but also a fair bit of curiosity and \nexcitement. Mainly, educators want to know: How do we actually use this stuff to help students learn, rather than \njust try to catch them cheating?\n  I'm a tech columnist, not a teacher, and I don't have all the answers, especially when it comes to the long-term \neffects of A.I. on education. But I can offer some basic, short-term advice for schools trying to figure out how to \nhandle generative A.I. this fall.\n  First, I encourage educators -- especially in high schools and colleges -- to assume that 100 percent of their \nstudents are using ChatGPT and other generative A.I. tools on every assignment, in every subject, unless they're \nbeing physically supervised inside a school building.\n  At most schools, this won't be completely true. Some students won't use A.I. because they have moral qualms \nabout it, because it's not helpful for their specific assignments, because they lack access to the tools or because \nthey're afraid of getting caught.\n  But the assumption that everyone is using A.I. outside class may be closer to the truth than many educators \nrealize. (''You have no idea how much we're using ChatGPT,'' read the title of a recent essay by a Columbia \nundergraduate in The Chronicle of Higher Education.) And it's a helpful shortcut for teachers trying to figure out how \nto adapt their teaching methods. Why would you assign a take-home exam, or an essay on ''Jane Eyre,'' if everyone \nin class -- except, perhaps, the most strait-laced rule followers -- will use A.I. to finish it? Why wouldn't you switch to \nHow Schools Can Cope and Grow When Their Students Are Using A.I.\nproctored exams, blue-book essays and in-class group work, if you knew that ChatGPT was as ubiquitous as \nInstagram and Snapchat among your students?\n  Second, schools should stop relying on A.I. detector programs to catch cheaters. There are dozens of these tools \non the market now, all claiming to spot writing that was generated with A.I., and none of them work reliably well. \nThey generate lots of false positives, and can be easily fooled by techniques like paraphrasing. Don't believe me? \nAsk OpenAI, the maker of ChatGPT, which discontinued its A.I. writing detector this year because of a ''low rate of \naccuracy.''\n  It's possible that in the future, A.I. companies may be able to label their models' outputs to make them easier to \nspot -- a practice known as ''watermarking'' -- or that better A.I. detection tools may emerge. But for now, most A.I. \ntext should be considered undetectable, and schools should spend their time (and technology budgets) elsewhere.\n  My third piece of advice -- and the one that may get me the most angry emails from teachers -- is that teachers \nshould focus less on warning students about the shortcomings of generative A.I. than on figuring out what the \ntechnology does well.\n  Last year, many schools tried to scare students away from using A.I. by telling them that tools like ChatGPT are \nunreliable, prone to spitting out nonsensical answers and generic-sounding prose. These criticisms, while true of \nearly A.I. chatbots, are less true of today's upgraded models, and clever students are figuring out how to get better \nresults by giving the models more sophisticated prompts.\n  As a result, students at many schools are racing ahead of their instructors when it comes to understanding what \ngenerative A.I. can do, if used correctly. And the warnings about flawed A.I. systems issued last year may ring \nhollow this year, now that GPT-4 is capable of getting passing grades at Harvard.\n  Alex Kotran, the chief executive of the AI Education Project, a nonprofit that helps schools adopt A.I., told me that \nteachers needed to spend time using generative A.I. themselves to appreciate how useful it could be -- and how \nquickly it was improving.\n  ''For most people, ChatGPT is still a party trick,'' he said. ''If you don't really appreciate how profound of a tool this \nis, you're not going to take all the other steps that are going to be required.''\n  There are resources for educators who want to bone up on A.I. in a hurry. Mr. Kotran's organization has a number \nof A.I.-focused lesson plans available for teachers, as does the International Society for Technology in Education. \nSome teachers have also begun assembling recommendations for their peers, such as a website made by faculty \nat Gettysburg College that provides practical advice on generative A.I. for professors.\n  In my experience, though, there is no substitute for hands-on experience. So I'd advise teachers to start \nexperimenting with ChatGPT and other generative A.I. tools themselves, with the goal of getting as fluent in the \ntechnology as many of their students already are.\n  My last piece of advice for schools that are flummoxed by generative A.I. is this: Treat this year -- the first full \nacademic year of the post-ChatGPT era -- as a learning experience, and don't expect to get everything right.\n  There are many ways A.I. could reshape the classroom. Ethan Mollick, a professor at the University of \nPennsylvania's Wharton School, thinks the technology will lead more teachers to adopt a ''flipped classroom'' -- \nhaving students learn material outside class and practice it in class -- which has the advantage of being more \nresistant to A.I. cheating. Other educators I spoke with said they were experimenting with turning generative A.I. \ninto a classroom collaborator, or a way for students to practice their skills at home with the help of a personalized \nA.I. tutor.\n  Some of these experiments won't work. Some will. That's OK. We're all still adjusting to this strange new \ntechnology in our midst, and the occasional stumble is to be expected.\nHow Schools Can Cope and Grow When Their Students Are Using A.I.\n  But students need guidance when it comes to generative A.I., and schools that treat it as a passing fad -- or an \nenemy to be vanquished -- will miss an opportunity to help them.\n  ''A lot of stuff's going to break,'' Mr. Mollick said. ''And so we have to decide what we're doing, rather than fighting \na retreat against the A.I.''\nhttps://www.nytimes.com/2023/08/24/technology/how-schools-can-survive-and-maybe-even-thrive-with-ai-this-\nfall.html\nGraphic\n \nPHOTO: A coding event in May at Dearborn STEM Academy in Boston. Educators are trying to figure out how to \nhelp students learn with generative (PHOTOGRAPH BY A.I. SOPHIE PARK FOR THE NEW YORK TIMES) (B3) \nThis article appeared in print on page B1, B3.               \nLoad-Date: August 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "As Artificial Intelligence Evolves, Screenwriters and Actors See a Threat",
        "media": "The New York Times",
        "time": "May 2, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1631 words",
        "byline": "By Noam Scheiber and John Koblin",
        "story_text": "As Artificial Intelligence Evolves, Screenwriters and Actors See a Threat\nThe New York Times\nApril 29, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1631 words\nByline: By Noam Scheiber and John Koblin\nBody\nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.\nWhen the union representing Hollywood writers laid out its list of objectives for contract negotiations with studios \nthis spring, it included familiar language on compensation, which the writers say has either stagnated or dropped \namid an explosion of new shows. \n  But far down, the document added a distinctly 2023 twist. Under a section titled ''Professional Standards and \nProtection in the Employment of Writers,'' the union wrote that it aimed to ''regulate use of material produced using \nartificial intelligence or similar technologies.''\n  To the mix of computer programmers, marketing copywriters, travel advisers, lawyers and comic illustrators \nsuddenly alarmed by the rising prowess of generative A.I., one can now add screenwriters.\n  ''It is not out of the realm of possibility that before 2026, which is the next time we will negotiate with these \ncompanies, they might just go, 'you know what, we're good,''' said Mike Schur, the creator of ''The Good Place'' and \nco-creator of ''Parks and Recreation.''\n  ''We don't need you,'' he imagines hearing from the other side. ''We have a bunch of A.I.s that are creating a \nbunch of entertainment that people are kind of OK with.''\n  In their attempts to push back, the writers have what a lot of other white-collar workers don't: a labor union.\n  Mr. Schur, who serves on the bargaining committee of the Writers Guild of America as it seeks to avert a strike \nbefore its contract expires on Monday, said the union hopes to ''draw a line in the sand right now and say, 'Writers \nare human beings.'''\n  But unions, historians say, have generally failed to rein in new technologies that enable automation or the \nreplacement of skilled labor with less-skilled labor. ''I'm at a loss to think of a union that managed to be plucky and \nmake a go of it,'' said Jason Resnikoff, an assistant professor of history at the University of Groningen in the \nNetherlands, who studies labor and automation.\n  The fortunes of the writers, actors and directors negotiating new contracts this year may say a lot about whether \nthe pattern will continue into the era of artificial intelligence.\nAs Artificial Intelligence Evolves, Screenwriters and Actors See a Threat\n  In December, Apple introduced a service allowing book publishers to use human-sounding A.I. narrators, an \ninnovation that could displace hundreds of voice actors who make a living performing audiobooks. The company's \nwebsite says the service will benefit independent authors and small publishers.\n  ''I know someone always has to get there first, some company,'' said Chris Ciulla, who estimates that he has made \n$100,000 to $130,000 annually over the past five years narrating books under union contracts. ''But for individuals \nnot to understand how that can affect the pail-carrying narrator out there eventually is disappointing.''\n  Other actors fear that studios will use A.I. to replicate their voices while cutting them out of the process. ''We've \nseen this happening -- there are websites that have popped up with databases of characters' voices from video \ngames and animation,'' said Linsay Rousseau, an actress who makes her living doing voice work.\n  On-camera actors point out that studios already use motion capture or performance capture to replicate artists' \nmovements or facial expressions. The 2018 blockbuster ''Black Panther'' relied on this technology for scenes that \ndepicted hundreds of tribespeople on cliffs, mimicking the movements of dancers hired to perform for the film.\n  Some actors worry that newer versions of the technology will allow studios to effectively steal their movements, \n''creating new performance in the style of a wushu master or karate master and using that person's style without \nconsent,'' said Zeke Alton, a voice and screen actor who sits on the board of his union local, SAG-AFTRA, in Los \nAngeles.\n  And Hollywood writers have grown increasingly anxious as ChatGPT has become adept at mimicking the style of \nprolific authors.\n  ''Early on in the conversations with the guild, we talked about what I call the Nora Ephron problem,'' said John \nAugust, who is on the Writers Guild negotiating committee. ''Which is basically: What happens if you feed all of \nNora Ephron's scripts into a system and generate an A.I. that can create a Nora Ephron-sounding script?''\n  Mr. August, a screenwriter for movies like ''Charlie's Angels'' and ''Charlie and the Chocolate Factory,'' said that \nwhile artificial intelligence had taken a back seat to compensation in the Writers Guild negotiation, the union was \nmaking two key demands on the subject of automation.\n  It wants to ensure that no literary material -- scripts, treatments, outlines or even discrete scenes -- can be written \nor rewritten by chatbots. ''A terrible case of like, 'Oh, I read through your scripts, I didn't like the scene, so I had \nChatGPT rewrite the scene' -- that's the nightmare scenario,'' Mr. August said.\n  The guild also wants to ensure that studios can't use chatbots to generate source material that is adapted to the \nscreen by humans, the way they might adapt a novel or a magazine story.\n  SAG-AFTRA, the actors' union, says more of its members are flagging contracts for individual jobs in which \nstudios appear to claim the right to use their voices to generate new performances.\n  A recent Netflix contract sought to grant the company free use of a simulation of an actor's voice ''by all \ntechnologies and processes now known or hereafter developed, throughout the universe and in perpetuity.''\n  Netflix said the language had been in place for several years and allowed the company to make the voice of one \nactor sound more like the voice of another in case of a casting change between seasons of an animated production.\n  The union has said that its members are not bound by contract provisions that would allow a producer to simulate \nnew performances without compensating actors, though it has sometimes intervened to strike them from contracts \nnonetheless.\n  Duncan Crabtree-Ireland, SAG-AFTRA's executive director, said such contracts posed a much bigger risk to \nnonunion actors, who can become unwitting accomplices in their own obsolescence. ''It only takes one or a few \ninstances of signing away your rights on a lifetime basis to really potentially have a negative impact on your career \nprospects,'' Mr. Crabtree-Ireland said.\nAs Artificial Intelligence Evolves, Screenwriters and Actors See a Threat\n  The Alliance of Motion Picture and Television Producers, which bargains with the various unions that represent \nwriters, actors and directors on behalf of the major Hollywood studios, declined to comment.\n  When professionals have fended off obsolescence at the hands of technology, the outcome has often reflected \ntheir occupation's status and prestige.\n  That appears to have been the case to some extent with airplane pilots, whose crew sizes had dropped to two on \nmost domestic commercial flights by the late 1990s, but have largely been level since then, even as automated \ntechnology has become far more sophisticated and the industry has explored further reductions.\n  ''The safety net you have when you're high off the ground -- the one that keeps you from hitting the ground -- is \ntwo highly trained, experienced, rested pilots,'' said Capt. Dennis Tajer, a spokesman for the Allied Pilots \nAssociation, which represents pilots for American Airlines. To this day, flight times longer than nine hours require at \nleast three pilots.\n  The replacement of certain doctors by artificial intelligence, which some experts predicted was imminent in fields \nlike radiology, has also failed to materialize. That's partly because of the limits of the technology, and because of \nthe stature of the doctors, who have inserted themselves into high-stakes conversations about the safety and \ndeployment of A.I. The American College of Radiology created a Data Science Institute partly for this purpose \nseveral years ago.\n  Whether screenwriters find similar success will depend at least in part on if there are inherent limits to the \nmachines that purport to do their jobs. Some writers and actors speak of a so-called uncanny valley that algorithms \nmay never entirely escape.\n  ''Artists look at everything ever created and find a flash of newness,'' said Javier Grillo-Marxuach, a writer and \nproducer for ''Lost'' and ''Dark Crystal: Age of Resistance.'' ''What the machine is doing is recombining.''\n  However sophisticated the algorithms, the fate of writers and actors will also depend on how well they protect their \nstatus. How good are they at convincing audiences that they should care whether a human is involved?\n  The unions are pressing their case. Mr. August says that it falls to the Writers Guild and not the studio to \ndetermine who receives a writer's credit on a project, and that the union will guard this rite jealously. ''We want to \nmake sure that an A.I. is never one of those writers in the chain of title for a project,'' he said.\n  The unions also have legal cards to play, Mr. Crabtree-Ireland of SAG-AFTRA said, like the U.S. Copyright \nOffice's pronouncement in March that content created entirely by algorithm is not eligible for copyright protection. It \nis harder to monetize a production if there is no legal obstacle to copying it.\n  Perhaps more important, he said, is what you might call the Us Weekly factor -- the tendency of audiences to be \nas interested in the human behind the role as in the performance. Fans want to hear Hollywood celebrities discuss \ntheir method in interviews. They want to gawk at actors' fashion sensibilities and keep up with whom they're dating.\n  ''If you look at culture in general, the audience is generally interested in the real lives of our members,'' Mr. \nCrabtree-Ireland said. ''A.I. is not in a position to substitute for key elements of that.''\nGraphic\n \nThis article appeared in print on page B1, B4.               \nLoad-Date: May 2, 2023\nAs Artificial Intelligence Evolves, Screenwriters and Actors See a Threat"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Pre-Crime Fighting, Key Techaways",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 4, 2023",
        "section": "BREAKING IDEAS",
        "length": "875 words",
        "byline": "Anil Nair",
        "story_text": "Pre-Crime Fighting, Key Techaways\nEconomic Times (E-Paper Edition)\nNovember 4, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 875 words\nByline: Anil Nair\nBody\nSteven Spielberg’s 2002 science fiction film, Minority Report, set in the US of 2054, showcases a system that can \npredict crimes, enabling arrests even before the infraction takes place. In real life today, advances in the use of \ntechnology to stop crime are not quite there, but we are progressing rapidly. Take the case of Indian Railways. \nMumbai improved its infraction detection rate from 15% (January-August 2019) to 40% in the same period in 2023, \nwhile the quantum of cases increased. \nUsing a facial recognition system, anterior landmarks like the distance between the eyes are captured and stored in \na database. When a repeat offender enters a station and the system finds a match, it alerts the patrolling staff. \nCambridge University has developed a Camouflage Facial Recognition System that works even if the face is \ncovered. Now, advanced systems analysing CCTV feeds can even detect non-verbal language like a grimace, a \nfrown, the clenching of teeth or fists to detect current or anticipated misconduct. Singapore uses such behavioural \nanalytics to spot unusual incidents or patterns to enable law enforcement agencies to respond more effectively. \nAfew years ago, the US department of justice, through Cardiff Uni-  versity, researched the linkage between social \nmedia, crime data and violent incidents to create software to detect potentially dangerous zones for pre-emptive \nforce deployment. US courts use a predictive AI tool to determine if a person in prison will be a repeat offender. \nBrazil uses bots to check corruption. Called Alice, Rosie, Agatha, Iris and Monica, these bots verify data to spot \nirregularities in public tenders, cartelisation, use of public funds for private gain and slow progress in judicial cases. \nCR Mukundan, a neuroscientist at the National Institute of Mental Health and Neurosciences (Nimhans), Bangalore, \nis doing fascinating work on brain mapping. Called Brain Electrical Oscillation Signature Profiling (BEOS), it is a \nnon-invasive forensic tool used when traditional methods fail. The accused is fitted with a cap comprising 32 \nelectrodes and asked to sit quietly with his eyes closed. Prerecorded statements and questions are played, and the \nelectrical impulses are recorded to figure patterns. Innocent people, bereft of knowledge of crime details, show a \ndifferent set of patterns. This method was de-  ployed in the Aarushi Talwar case. It has been used in lesser-known \ninstances also, including the 2007 case when an MBA student and her partner were arrested for poisoning the \nformer’s ex-boyfriend in Pune. The two were convicted in 2008. BEOS becomes doubly effective when used \nalongside pictures and videos, psychological profiling, polygraph tests or narco-analysis. The Supreme Court had, \nhowever, ruled in 2010 that such methods need consent. More recently, while recognising psychological tests as \nmaterial evidence, the top court cautioned against such evidence alone being sufficient to determine guilt. Various \nagencies have developed algorithmic crime-detection tools. We’ve had mixed results on outcomes and many cases \nwhere the expiration of research grants, allegations of social and race bias, and lack of transparency about actual \nusage have forced decommissioning or abandonment. Yet, that doesn’t diminish the innate need for digital \ninterventions to tackle crime, and underscores that they must be given time and resources to mature. More \nconsequentially, it reiterates the need for a robust foundation of strategic and systemic thinking on which it must be \nbuilt. The journey of data analysis in crime detection accelerated in the early 1990s when Bill Bratton, chief of the \nNew York Transit Police, and his deputy  started looking at crime data closely. They would plot incident data on \nPre-Crime Fighting, Key Techaways\nlarge maps with coloured pencils and crayons and try to sense patterns to initiate pre-emptive action. Bratton \nmotivated a 36,000-strong force to perform far-above expectations, using his fact-based approach to drive \nexecution. In two years since Bratton became commissioner in 1994, felonies fell 39%, murders 50%, and theft \n35%, making New York the ‘safest large city’ in the US. In this case, systemic change was accompanied by culture \nchange. Instead of focusing on increasing the force, he reallocated police officers to hot spots where crime \nincidence was higher, where low resource inputs yielded high gains. He converted old buses into mobile police \nstations and parked them outside subway stations, cutting time for paperwork from 16 hours to an hour. He \nreviewed the performance of senior officers bi-weekly to inculcate an intense performance culture. In essence, \nBratton demonstrated that success is contingent not just on gleaning data but also on using it effectively to figure \ninterventions that could create disproportionate outcomes, leveraging insights obtained to align teams and \nresources, and then defying conventional wisdom to achieve breakthrough results in record time. Imagine what can \nbe achieved now with the power of generative AI for predictive policing. There’s optimism that, aided by further \nadvancements in technology, heinous crimes like the Nithari serial killings won’t go unpunished. The writer is senior \nfellow, Portulans Institute, Washington DC\nLoad-Date: November 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Where Does A.I. End and We Begin?; Turning Points: Guest Essay",
        "media": "The New York Times",
        "time": "December 7, 2023",
        "section": "SPECIAL-SERIES",
        "length": "1009 words",
        "byline": "Sougwen Chung",
        "story_text": "Where Does A.I. End and We Begin?; Turning Points: Guest Essay\nThe New York Times \nDecember 7, 2023 Thursday 15:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: SPECIAL-SERIES\nLength: 1009 words\nByline: Sougwen Chung\nHighlight: Artificial intelligence can act as a collaborator that helps artists produce new works.\nBody\nArtificial intelligence can act as a collaborator that helps artists produce new works.\nThis personal reflection is part of a series called Turning Points, in which writers explore what critical moments from \nthis year might mean for the year ahead. You can read more by visiting the Turning Points series page.\nThe following is an artist’s interpretation of the year — how it was or how it might be, through the lens of art.\nWhere does A.I. end and we begin? I’ve been thinking about this question — the line between machines and \nhuman creativity — for a long time. In my art, lines are governing elements over images. But what happens when \nthose lines are made by a machine?\nIn 2015, I began my journey in co-creation. It took two years to meticulously scan more than 20 years’ worth of my \ndrawings into a system I developed to train a recurrent neural network. The neural network drives the movements of \nD.O.U.G., short for Drawing Operations Unit: Generation 2, a robot I built to draw with me. We made our debut in \n2017. Today, I’m continuing to explore emerging technology — biosensors, computer vision, virtual reality and \ncustom machines. It’s been nearly a decade. I wonder, with all these technological adaptations, what will become of \nthe human hand?\nIn the years since the Covid-19 pandemic, I’ve seen colleagues close their artistic practices out of disillusionment or \npragmatism, often a combination of both. Yet, because of the proliferation of the digital art market of nonfungible \ntokens, cryptocurrency and generative artificial intelligence systems — technology that can produce images — \nI’ve seen the igniting of a new generation of digital artists, and witnessed new studios emerge and flourish.\nIt’s a strange time to make art. In 2023, industries were in revolt — from the 148-day screenwriters strike in the \nUnited States to artists rightfully condemning the use of A.I. training data without their consent. It’s not news that \nresearchers have cautioned against the dangers of bias in A.I.; that almost seems a given. Another problem is that \nnot everyone knows the hidden cost of accumulating the data involved in making sense of massive language \nmodels like OpenAI’s GPT-4. At the same time, linking prompts with image generation and coding has popularized \na new relationship between text and image. Now more people than ever can communicate through a visual \nmedium, a new entry point for learning to code. ChatGPT can function as a sidekick you can talk to, which can help \nbuild a sense of rapport between A.I. systems and humans.\nWith all the hype, it’s easy to forget that there’s no such thing as a single artificial intelligence because there’s no \nsuch thing as a single natural intelligence. I’ve come to think of my approach of learning through systems — \ndeemed intelligent or otherwise — as a creative catalyst. There is meaning in the data, but it’s not the meaning we \nare given; it’s the meaning we make.\nWhere Does A.I. End and We Begin? Turning Points: Guest Essay\nFor me, meaning-making and experimentation go hand-in-hand. In “Process Study - Structure from Motion,” I’m \nexperimenting with a new way of capturing an environment. The technique is called “gaussian splatting,” a diffuse \nscanning approach to 3-D space. It gleans structure from motion, yielding a dense representation of objects that, to \nmy eyes, also yields painterly and ghostly visual artifacts. I’m drawn to this approach because of its future \npossibilities — new applications of Embodied A.I. — as well as its effect in the present day. It shows the \nincompleteness of digital representation and the texture of the system as its own kind of beauty.\nThe themes of beauty and fragility ground my experimentations, often involving the sharing of the time and space of \nmaking art with machines. I’ve chronicled that evolution through performances, films and vignettes from my studio. \nFor me, drawing is a way of being in the world. When I draw and create with my machines, this creative process \nallows me to engage with the technology alongside my physical instincts to form a kind of gestural relation. Showing \nthe process in progress offers space for introspection.\nI’ve recently finished the fifth generation of my robotic journey. Still, I feel like we’re just getting started with this type \nof art and our understanding of the role of technology in art. From mimicry, to memory, to the collectivity of the \nurban environment, to the spectrality of biofeedback, each generation unlocks a new set of technical skills, creating \nstronger relationships between humans and machines. With each development, I find myself with more questions \nthan answers.\nAs I paint in collaboration with the robotic units in my studio, I’m hopeful that some of those tensions make their way \ninto the painted line, the visual artifact on canvas. When people react to my work, I am often asked, “Can A.I. be \ncreative?” But lately, I’m unsure if that’s the question we should be asking.\nArtists have the privilege of responding to the social and political moments of their day. I’ve been designing \nalternative forms of machines inspired by nature, with the bond between humans and machines as one of \necological stewardship. As I develop these forthcoming configurations, the drawn line is one constant that always \nremains at the center. It is a line that explores the potential of human and machine collaboration, speculating on \nhow the machine will act as a catalyst, co-pilot and companion. If I’ve learned anything in the past decade of this \njourney, it’s that art can help us ask better questions: Can fear and hope be held in the mind simultaneously? How \ndo we grasp the promise, perils and paranoias of technical shifts at once?\nWhere does A.I. end and we begin?\nSougwen Chung is a Chinese-Canadian artist and the founder and artistic director of Scilicet, a London-based \nstudio that works on examining human collaboration with machines.\nPHOTO: Sougwen Chung’s “Process Study - Structure from Motion” shows robotic units working in tandem with the \nartist in the London studio Scilicet. (PHOTOGRAPH BY Courtesy of Sougwen Chung FOR THE NEW YORK \nTIMES)\nLoad-Date: December 7, 2023"
    },
    {
        "file_name": "Newsletter_Feb2024",
        "header": "Will Congress Move on New Rules for Online Children’s Safety?; DealBook",
        "media": "Newsletter",
        "time": "February 1, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1918 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Will Congress Move on New Rules for Online Children’s Safety?; DealBook \nNewsletter\nThe New York Times \nFebruary 1, 2024 Thursday 08:31 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1918 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni &lt;p&gt;Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is \na co-anchor of CNBC&amp;#8217;s &#34;Squawk Box&#34; and the author of &amp;#8220;Too Big to \nFail.&amp;#8221; He is also a co-creator of the Showtime drama series &#34;Billions.&#34;&lt;/p&gt; &lt;p&gt;Ravi \nMattu is the managing editor of DealBook, based in London. He joined The New York Times in 2022 from the \nFinancial Times, where he held a number of senior roles in Hong Kong and London.&lt;/p&gt; &lt;p&gt;Bernhard \nWarner is a senior editor for DealBook, a newsletter from The Times, covering business trends, the economy and \nthe markets.&lt;/p&gt; &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on \nbusiness and how workplaces are changing.&lt;/p&gt; &lt;p&gt;Michael de la Merced joined The Times as a reporter \nin 2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry.&lt;/p&gt; &lt;p&gt;Lauren Hirsch joined The Times from CNBC in 2020, \ncovering deals and the biggest stories on Wall Street.&lt;/p&gt; &lt;p&gt;Ephrat Livni reports from Washington on \nthe intersection of business and policy for DealBook. Previously, she was a senior reporter at Quartz, covering law \nand politics, and has practiced law in the public and private sectors.&amp;#160;&amp;#160;&lt;/p&gt;\nHighlight: Tech leaders faced a grilling in the Senate, and one offered an apology. But skeptics fear little will \nchange this time.\nBody\nTech leaders faced a grilling in the Senate, and one offered an apology. But skeptics fear little will change this time.\nA lot of heat, but will there be regulation?\nFive technology C.E.O.s endured hours of grilling by senators on both sides of the aisle about their apparent \nfailures to make their platforms safer for children, with some lawmakers accusing them of having “blood” on their \nhands.\nBut for all of the drama, including Mark Zuckerberg of Meta apologizing to relatives of online child sex abuse \nvictims, few observers believe that there’s much chance of concrete action.\n“Your product is killing people,” Senator Josh Hawley, Republican of Missouri, flatly told Zuckerberg at \nWednesday’s hearing. Over 3.5 hours, members of the Senate Judiciary Committee laid into the Meta chief and the \nheads of Discord, Snap, TikTok and X over their policies. (Before the hearing began, senators released internal \nMeta documents that showed that executives had rejected efforts to devote more resources to safeguard children.)\nBut tech C.E.O.s offered only qualified support for legislative efforts. Those include the Kids Online Safety Act, or \nKOSA, which would require tech platforms to take “reasonable measures” to prevent harm, and STOP CSAM and \nEARN IT, two bills that would curtail some of the liability shield given to those companies by Section 230 of the \nCommunications Decency Act.\nWill Congress Move on New Rules for Online Children’s Safety? DealBook Newsletter\n• Both Evan Spiegel of Snap and Linda Yaccarino of X backed KOSA, and Yaccarino also became the first tech \nC.E.O. to back the STOP CSAM Act. But neither endorsed EARN IT.\n• Zuckerberg called for legislation to force Apple and Google — neither of which was asked to testify — to be \nheld responsible for verifying app users’ ages. But he otherwise emphasized that Meta had already offered \nresources to keep children safe.\n• Shou Chew of TikTok noted only that his company expected to invest over $2 billion in trust and safety \nmeasures this year.\n• Jason Citron of Discord allowed that Section 230 “needs to be updated,” and his company later said that it \nsupports “elements” of STOP CSAM.\nExperts worry that we’ve seen this play out before. Tech companies have zealously sought to defend Section 230, \nwhich protects them from liability for content users post on their platforms. Some lawmakers say altering it would be \ncrucial to holding online platforms to account.\nMeanwhile, tech groups have fought efforts by states to tighten the use of their services by children. Such laws \nwould lead to a patchwork of regulations that should instead be addressed by Congress, the industry has argued.\nCongress has failed to move meaningfully on such legislation. Absent a sea change in congressional will, \nWednesday’s drama may have been just that.\nBut some lawmakers say that this time is different: “As someone who has taken on these companies for years, it’s \nthe first time I felt hope for movement,” Senator Amy Klobuchar, Democrat of Minnesota, said of the hearing.\nHERE’S WHAT’S HAPPENING \nElon Musk says Tesla shareholders will vote on moving the company’s incorporation to Texas. The potential shift, \nannounced by Musk on his X social network, comes after a judge in Delaware, where the carmaker is incorporated, \nstruck down a $50 billion pay package for him. Such a move would bolster Texas’ effort to become a new home \nbase for corporate America.\nFTX is on track to repay customers in full, a lawyer says. Andrew Dietderich, who represents the fallen \ncryptocurrency exchange in its federal bankruptcy proceedings, said that the company believed that it could make \nclients and creditors whole. The declaration is a change from early on in FTX’s Chapter 11 case, when executives \ncast doubt on the possibility of fully repaying customers.\nA federal judge dismisses Disney’s lawsuit against Ron DeSantis. The media giant lacked standing to sue the \nFlorida governor for retaliation over its opposition to what critics call his “Don’t Say Gay” education bill, the judge \nfound. Disney, which had accused DeSantis of violating its First Amendment rights, said it would appeal.\nDonald Trump promises to block Nippon Steel’s takeover of U.S. Steel if he’s re-elected. “I would block it \ninstantaneously. Absolutely,” the former president said on Wednesday after meeting with members of the \nTeamsters union. The statement raises questions about whether Trump’s economic nationalism would impede \nforeign investment in the U.S., and how much he would let politics influence regulatory decisions.\nFed speak \nInvestors hoped to get an answer — or at least a hint — about where Jay Powell, the Fed chair, stood on rate cuts \nafter the central bank’s latest meeting wrapped up on Wednesday.\nInstead, he tamped down expectations of an imminent move, renewing criticism from some quarters that his \ncommunication isn’t helping the economy.\nThe Fed left rates unchanged, in a range of 5.25 to 5.5 percent, at their highest level in more than two decades. \nWhat surprised Wall Street was Powell’s reluctance to indicate that borrowing costs would be coming down as soon \nas March, leading to markets’ worst day in months.\nWill Congress Move on New Rules for Online Children’s Safety? DealBook Newsletter\n“I don’t think it’s likely the committee will reach a level of confidence by the time of the March meeting to identify \nMarch as the time to do that,” Powell said at a news conference on Wednesday. \nThe Fed is worried that inflation isn’t fully under control. Price increases have been slowing in recent months and \nthe job market remains strong, raising hopes that the economy is headed for a soft landing.\nBut Powell wants more evidence that inflation is definitively moving toward the Fed’s 2 percent target. “We know \nthat reducing policy restraint too soon or too much could result in a reversal of the progress we have seen on \ninflation,” he said.\nSome observers say Powell’s messaging isn’t helping. Mohamed El-Erian, the chief economic adviser at Allianz \nand a critic of the Fed’s approach to inflation, said the latest news conference added to those worries. “This is \nfueling more questions about the risks of the #Fed being late again, albeit in a different direction,” El-Erian wrote on \nthe social media platform X. “Unsurprisingly, the outcome is yet another press conference resulting in significant \nmarket volatility.”\nNovember’s elections are complicating Powell’s task. Allies of Donald Trump argue, without evidence, that the Fed \nis seeking to help President Biden by signaling that cuts are coming. And Trump has said that if he becomes \npresident, he wouldn’t reappoint Powell.\nA merger that might have saved The Messenger\nIn the final days before The Messenger shut down on Wednesday, less than a year after it began, the online news \nstart-up was courting an unlikely white knight to make a last-minute rescue: The Los Angeles Times and its owner, \nthe biotechnology billionaire Patrick Soon-Shiong, Ben Mullin reports for DealBook.\nThe Messenger’s founder, Jimmy Finkelstein, told the company’s board this week that he had discussed a deal to \nmerge with The Los Angeles Times to keep the start-up afloat, according to two people with knowledge of the \nmatter, who weren’t authorized to speak publicly about the talks.\nThe logic of the proposed merger: The Messenger, which said it had recently drawn tens of millions of monthly \nvisitors with its clickable content, could drive readership to The Los Angeles Times. Soon-Shiong, in turn, could \ncover The Messenger’s payroll with a cash injection to keep the company afloat.\nUltimately, a deal never materialized. Finkelstein told the board that the negotiations fell apart, the people said, \nleaving The Messenger with a cash crunch and no alternatives to shutting down. Finkelstein alluded to his last-ditch \nattempts to salvage the website in a memo to employees Wednesday night: “Over the past few weeks, literally until \nearlier today, we exhausted every option available and have endeavored to raise sufficient capital to reach \nprofitability,” he wrote.\nFinkelstein and a spokeswoman for The Los Angeles Times did not respond to requests for comment.\nSoon-Shiong was one of many potential rescuers The Messenger approached, one of the people said. Another was \nOmeed Malik, the financier who backed Tucker Carlson’s media start-up, the person added.\nThe Messenger’s demise was messy. Employees told The Times that they were not offered any severance pay or \nhealth insurance, and the abrupt disappearance of its archive made it difficult for them to save copies of their work.\n“The bridge has never been burned. … It’s up to them whether they want to cross it.” \n— Chris LaCivita, a senior adviser to Donald Trump, on Republican donors like Ken Griffin and Paul Singer who \nhave resisted supporting the former president. \nA.I. has big banks in its sights \nWill Congress Move on New Rules for Online Children’s Safety? DealBook Newsletter\nA big question looming over the advances in artificial intelligence is which jobs it will replace. The technology’s \nbackers say it will bolster productivity and save time by automating functions, suggesting that blue-collar workers on \nfactory floors and in fast-food restaurants that perform routine tasks could be hit the hardest.\nBut a new report from the Burning Glass Institute, a nonprofit research center, in collaboration with SHRM, a \nprofessional organization for human resources professionals, suggests that the finance and the tech sectors are \nmost likely to be affected by the technology.\nThe research estimates that banks and some tech companies spend 60 to 80 percent of their payrolls, or more, on \nworkers in occupations that will probablybe affected, The Times’s Steve Lohr writes:\nThe retail, restaurant and transportation industries are least likely to be affected by generative A.I., the report \nfound. Companies like Walmart, McDonald’s and Delta Air Lines mostly employ workers without college degrees \nwho perform roles like helping customers, stocking shelves, cooking food and handling baggage. They spend less \nthan 20 percent of their payrolls on employees in occupations most likely to be affected by generative A.I.\nThe report doesn’t predict potential job losses related to generative A.I. That will be up to employers, the report \nsaid, and whether they want to bank the savings from A.I. automation or use that money to invest and grow, adding \nmore workers. Most experts expect that A.I. will mostly change jobs for the next few years rather than eliminate \nthem — though that could change if the technology improves sharply.\nTHE SPEED READ \nDeals\n• Investors led by Ancora Holdings have reportedly built a roughly $1 billion stake in Norfolk Southern, with \nplans to seek the ouster of the railroad operator’s C.E.O. (WSJ)\n• Amer, the owner of sportswear brands Arc’teryx and Wilson, raised $1.37 billion in its I.P.O., below its \nexpected range. (Bloomberg)\nPolicy\n• The E.U. reached a 50-billion-euro funding deal for Ukraine, worth about $54 billion, overcoming objections \nfrom Hungary. (NYT)\n• The House passed a $78 billion tax bill with bipartisan support, but its prospects in the Senate are unclear. \n(NYT)\nBest of the rest\n• How Baltimore native David Rubenstein, the Carlyle Group co-founder, negotiated for years to buy the Orioles \npro baseball team. (WSJ)\n• Environmentalists and meat producers have formed an unlikely alliance to prevent the Brazilian beef giant \nJBS from listing on the New York Stock Exchange. (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Five tech C.E.O.s faced a grilling yesterday, but it’s unclear whether new laws to impose more safeguards \nfor online children’s safety will pass. (PHOTOGRAPH BY Kenny Holston/The New York Times FOR THE NEW \nYORK TIMES)\nLoad-Date: February 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Regulators Force Another Microsoft Split; DealBook Newsletter",
        "media": "The New York Times",
        "time": "April 2, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1979 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Regulators Force Another Microsoft Split; DealBook Newsletter\nThe New York Times \nApril 2, 2024 Tuesday 23:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1979 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The tech giant is unbundling Teams from its Office software suite, as it faces mounting scrutiny on both \nsides of the Atlantic.\nBody\nThe tech giant is unbundling Teams from its Office software suite, as it faces mounting scrutiny on both sides of the \nAtlantic.\nMicrosoft unbundles, again \nMicrosoft is separating Teams, its popular video and chat app, from its Office software suite in markets around the \nworld, broadening a split that began in the European Union last fall.\nIt appears to be the latest effort by the software giant to head off investigations by global antitrust enforcers as \nregulators examine the power of Big Tech.\nRivals have complained about the Teams-Office bundle for years. Microsoft first added the video and document \ncollaboration program to its business software suite in 2017, and saw Teams’s popularity soar after the coronavirus \npandemic unleashed a boom in hybrid and remote working.\nAt the height of the lockdown in 2020, Slack filed a complaint with the European Commission accusing Microsoft of \nanticompetitive behavior by bundling Teams with Office. (Three months later, Slack agreed to sell itself to \nSalesforce for $27.7 billion.) And last summer, Eric Yuan, the C.E.O. of Zoom, called on the F.T.C. to follow the \nE.U. in investigating the Teams-Office tie-up.\nIt’s unclear if Microsoft’s decision will help it avoid an E.U. fine, which could cost the company up to 10 percent of \nglobal revenue. The company told Reuters that the move “addresses feedback from the European Commission by \nproviding multinational companies more flexibility when they want to standardize their purchasing across \ngeographies.”\nRegulators Force Another Microsoft Split DealBook Newsletter\nIt comes as tech behemoths are facing investigations by regulators worldwide. Last month, the Justice Department \nsued Apple over its tight control of the iOS operating system, while Google is awaiting a judge’s verdict in a U.S. \nlawsuit over its search monopoly.\nAnd Microsoft has drawn scrutiny over its investments in A.I. start-ups like OpenAI and the French company Mistral.\nThe move is reminiscent of Microsoft’s unbundling of Windows in the 2000s, after a bruising antitrust battle with the \nJustice Department over the tech company’s efforts to shut rivals out of its platform.\nBut it’s unclear how consequential this breakup will be. Shares in Microsoft rose on Monday despite the news, as \nanalysts questioned whether the move would mean much for the tech giant’s bottom line. Data from the research \nfirm Sensor Tower showed that use of Teams stayed relatively stable even after the program was cleaved out of \nOffice in the E.U.\nThat suggests rivals may not experience a surge in new customers. (Shares in Zoom fell nearly 1 percent on \nMonday.) “Teams is so embedded into workflows that I don’t think this has that same impact,” Rishi Jaluria, an \nanalyst at RBC Capital Markets, told Reuters.\nHERE’S WHAT’S HAPPENING \nDonald Trump posts a $175 million bond to avert seizure of his assets. In securing the bond for his civil fraud case, \nthe former president avoided paying a $454 million penalty while he appeals the judgment. Separately, shares in \nTrump Media &amp; Technology Group plunged 21 percent on Monday, after the parent company of the Truth \nSocial online platform disclosed just $4 million in revenue for last year.\nDisney is said to be winning its proxy fight against the financier Nelson Peltz. The entertainment giant’s slate of \nboard nominees has secured the backing of big shareholders, including BlackRock and T. Rowe Price, ahead of the \ncompany’s annual meeting on Wednesday. More than half of Disney’s voting shares have been accounted for, but \na big question is how the company’s unusually high percentage of individual shareholders will vote.\nA regulator is reportedly scrutinizing investments by Vanguard, BlackRock and State Street in U.S. banks. The \nF.D.I.C. is examining whether the big money managers are maintaining a sufficiently passive role in managing their \nstakes, according to The Wall Street Journal. Such firms are exempt from current rules that require regulatory \napproval to own more than 10 percent of a bank — if they don’t exert influence on management or boards.\nA $4.1 billion bet on sports \nOne of the biggest players in the booming business of sports just got bigger: The private equity firm Arctos Partners \nhas raised another $4.1 billion to do more deals.\nThe fund-raising shows investor appetite for sports deals is growing as competition ramps up between private \nequity firms and Gulf countries like Saudi Arabia and Qatar.\nArctos is one of the busiest sports deal makers. Since its founding in 2019, the firm has invested in Formula One, \nbasketball, baseball and soccer clubs. They include the Utah Jazz and Fenway Sports Group.\nSports deals are booming on the back of the skyrocketing value for media rights. John Malone’s Liberty Media, \nwhich owns F1, said on Monday that it had bought MotoGP, the motorcycle racing championship, for €4.2 billion \n($4.5 billion).\nThe deal follows a record year for sports M.&amp; A., with transaction values up 27 percent to roughly $25 billion in \n2023, according to Bloomberg calculations. That included big investments by Arctos in the Qatar-owned French \nsoccer club Paris Saint-Germain and the Aston Martin F1 team.\nRegulators Force Another Microsoft Split DealBook Newsletter\nSovereign investors are the big new players. Saudi Arabia is pouring billions into soccer and golf, and may be \nlooking at tennis next. And Qatar last year bought a stake in the owner of Washington’s professional basketball and \nhockey teams.\nArctos sees itself as part of a new wave of long-term deal makers that treat teams like an asset class. As sports \nleagues have loosened their rules to allow for institutional investors, firms like Blue Owl and Dynasty Equity say \nthey are committed to long-term investments that aren’t tied to economic volatility.\n“We’re not a control buyer. And we’re not a leveraged buyout fund,” Ian Charles, an Arctos co-founder, told \nDealBook. \nArctos played down the rising competition. Charles told DealBook that sports leagues put heavy restrictions on \nallowing state-backed investment, if they allow them at all. He declined to say whether Arctos had raised money \nfrom sovereign wealth funds, though the company said in a statement that its latest fund-raising round included \npension funds and “global wealth platforms.”\nThe latest report card for Bridgewater’s post-Dalio era \nRay Dalio gave up day-to-day management of Bridgewater Associates 18 months ago. Since then, Nir Bar Dea, his \nsuccessor atop the giant hedge fund, has been under pressure to show that one of the world’s most successful \ninvestment firms can maintain its dominance.\nResults from the first three months of 2024 suggest that Bridgewater is performing well. But can changes to how the \nfirm is run keep it in the top tier of industry performers?\nIts flagship Pure Alpha fund is up 15.9 percent year to date, according to a notice sent to investors on Monday that \nDealBook has reviewed. That’s up more than sevenfold over the Bloomberg Macro Hedge Fund Index, which tracks \nfunds with a similar strategy.\nPure Alpha is now up 38.4 percent, net of fees, since the creation of Bridgewater’s investment committee in August \n2020.\nThe hard part is maintaining that performance. For much of 2022 and 2023, Pure Alpha has performed well — only \nto tumble precipitously at the end of each of those years. Bridgewater as a whole lost $2.6 billion last year, one of \njust two top-tier firms to lose money, according to the research firm LCH Investments.\nThat continued a string of poor performance in the 2010s that tarnished Bridgewater’s reputation as a profit \nmachine. (It also raised questions about Dalio’s famously idiosyncratic and brutally blunt management style, \nincluding baseball cards that featured ratings of each worker based on colleagues’ assessments of them.)\nBar Dea has sought to make Bridgewater more flexible in how it arrives at investment decisions, Bloomberg reports. \nThat includes increasing the number of people who review those moves and pledges to embrace artificial \nintelligence.\nWill that be enough to keep clients happy? Some unidentified investors told Bloomberg that they were considering \ncutting ties if the firm didn’t pick up its performance.\nThat said, Bar Dea is reportedly planning to shrink Pure Alpha and return more money to clients — a move that \ncould make the fund more nimble.\n“The Western world urgently needs a significant increase in productivity growth as the burden of rising government \ndebt and entitlement spending strains almost every major economy.” \n— Ken Griffin. The Citadel founder used his annual letter to investors to warn about his growing worries on debt \nand share his view that the economy will grow only modestly this year as the Fed tries to bring down inflation to its 2 \npercent target.\nRegulators Force Another Microsoft Split DealBook Newsletter\nIs A.I. actually boosting productivity? \nInvestor enthusiasm around artificial intelligence has added trillions in market value to a select few tech companies. \nBut its broader economic impact has been harder to measure.\nEconomists are divided on the A.I. productivity conundrum. On earnings calls, business leaders have been more \neager to share with Wall Street how they plan to use the technology in their operations. But whether these tools will \nachieve widespread productivity gains for the economy is less clear.\n“The enthusiasm about large language models and ChatGPT has gone a bit overboard,” the Northwestern \nUniversity economist Robert Gordon told The Times. Others are more hopeful, including Erik Brynjolfsson at \nStanford University, who has bet Gordon $400 that productivity will take off this decade.\nWhile that wager catches the attention of some in academia, a parade of companies is putting the technology to \nuse:\n• Walmart has built a generative A.I. chat bot for internal use that answers common H.R. questions including \n“Do I have dental insurance?”\n• Abercrombie &amp; Fitch has turned to generative A.I. to brainstorm ideas for clothing designs and to write \nblurbs for its website and app.\n• Ben &amp; Jerry’s put cameras that use A.I. into the freezers at grocery stores to alert the company and its \ndistributors when a location was running low on a particular ice cream flavor.\nWill such use cases impact workers? David Autor, a labor economist at M.I.T. whose work has focused on how \ntechnology can erode earning potential, argues it might not be all bad news. The technology could help people with \nless expertise to do more valuable work, lifting the middle class. Critics are unconvinced.\n• In other A.I. news: OpenAI introduced a new tool that mimics human voices with high accuracy, showing how \nthe technology is quickly expanding beyond text, but it could also pose a new misinformation threat.\nTHE SPEED READ \nDeals\n• Sam Altman, the C.E.O. of OpenAI, is no longer listed as the leader of the venture arm of the artificial \nintelligence start-up. (The Information)\n• Tiger Global Management, the embattled start-up investor, has reportedly collected $2.2 billion for its latest \nfund, nearly two-thirds below its goal. (Bloomberg)\nPolicy\n• Two board members of Warner Bros. Discovery stepped down amid a Justice Department inquiry into whether \ntheir presence violated antitrust law. (NYT)\n• The company that owns the ship that hit the Francis Scott Key Bridge in Baltimore last week is invoking a 173-\nyear-old “Titanic Law” to cap its legal liability to $43 million. (The Lever)\n• “Poor Nations Are Writing a New Handbook for Getting Rich” (NYT)\nBest of the rest\n• United Airlines is asking its pilots to take unpaid time off next month, citing late plane deliveries from Boeing. \n(CNBC)\n• The owner of Sports Illustrated sued an energy drinks mogul whose media company missed nearly $49 million \nin publishing-rights payments. (NYT)\n• “How a Houthi-Bombed Ghost Ship Likely Cut Off Internet for Millions” (Wired)\nRegulators Force Another Microsoft Split DealBook Newsletter\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Satya Nadella, the executive chairman and chief executive of Microsoft. (PHOTOGRAPH BY ANNA \nGORDON/REUTERS) This article appeared in print on page B4.\nLoad-Date: April 2, 2024"
    },
    {
        "file_name": "SOFTWARE_Mar2023",
        "header": "MICROSOFT INCORPORATES GENERATIVE AI TOOL INTO BUSINESS",
        "media": "SOFTWARE",
        "time": "March 18, 2023",
        "section": "B; Pg. 3",
        "length": "42 words",
        "byline": "TOM DOTAN",
        "story_text": "MICROSOFT INCORPORATES GENERATIVE AI TOOL INTO BUSINESS \nSOFTWARE\nWall Street Journal Abstracts\nMarch 17, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 3\nLength: 42 words\nByline: TOM DOTAN\nBody\nABSTRACT\nMicrosoft Corp is infusing its popular workplace software with technology behind viral chatbot ChatGPT, upgrading \nPowerPoint, Word, Excel and Outlook with new abilities in its latest move to try to stay ahead in artificial-intelligence \nrace (M)\nLoad-Date: March 18, 2023"
    },
    {
        "file_name": "The_New_York_Times_Oct2022",
        "header": "A Coming-Out Party for Generative A.I., Silicon Valley’s New Craze; The Shift",
        "media": "The New York Times",
        "time": "October 24, 2022",
        "section": "TECHNOLOGY",
        "length": "1479 words",
        "byline": "Kevin Roose",
        "story_text": "A Coming-Out Party for Generative A.I., Silicon Valley’s New Craze; The Shift\nThe New York Times \nOctober 21, 2022 Friday 00:49 EST\nCopyright 2022 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1479 words\nByline: Kevin Roose\nHighlight: A celebration for Stability AI, the start-up behind the controversial Stable Diffusion image generator, \nrepresents the arrival of a new A.I. boom.\nBody\nA celebration for Stability AI, the start-up behind the controversial Stable Diffusion image generator, represents the \narrival of a new A.I. boom.\nIn Silicon Valley, crypto and the metaverse are out. Generative A.I. is in.\nThat much became clear Monday night at the San Francisco Exploratorium, where Stability AI, the start-up behind \nthe popular Stable Diffusion image-generating algorithm, gave a party that felt a lot like a return to prepandemic \nexuberance.\nThe event — which lured tech luminaries including the Google co-founder Sergey Brin, the AngelList founder Naval \nRavikant and the venture capitalist Ron Conway out of their Zoom rooms — was billed as a launch party for \nStability AI and a celebration of the company’s recent $101 million fund-raising round, which reportedly valued the \ncompany at $1 billion.\nBut it doubled as a coming-out bash for the entire field of generative A.I. — the wonky umbrella term for A.I. that \ndoesn’t just analyze existing data but creates new text, images, videos, code snippets and more.\nIt’s been a banner year, in particular, for generative A.I. apps that turn text prompts into images — which, unlike \nNFTs or virtual reality metaverses, actually have the numbers to justify the hype they’ve received. DALL-E 2, the \nimage generator that OpenAI released this spring, has more than 1.5 million users creating more than two million \nimages every day, according to the company. Midjourney, another popular A.I. image generator released this year, \nhas more than three million users in its official Discord server. (Google and Meta have built their own image \ngenerators but have not released them to the public.)\nThat kind of growth has set off a feeding frenzy among investors hoping to get in early on the next big thing. Jasper, \na year-old A.I. copywriting app for marketers, recently raised $125 million at a $1.5 billion valuation. Start-ups have \nraised millions more to apply generative A.I. to areas like gaming, programming and advertising. Sequoia Capital, \nthe venture capital firm, recently said in a blog post that it thought generative A.I. could create “trillions of dollars of \neconomic value.”\nBut no generative A.I. project has created as much buzz — or as much controversy — as Stable Diffusion.\nPartly, that’s because, unlike the many generative A.I. projects that are carefully guarded by their makers, Stable \nDiffusion is open-source and free to use, meaning that anyone can view the code or download it and run a modified \nversion on a personal computer. More than 200,000 people have downloaded the code since it was released in \nA Coming-Out Party for Generative A.I., Silicon Valley’s New Craze The Shift\nAugust, according to the company, and millions of images have been created using tools built on top of Stable \nDiffusion’s algorithm.\nThat hands-off approach extends to the images themselves. In contrast to other A.I. image generators, which have \nstrict rules in place to prevent users from creating violent, pornographic or copyright-infringing images, Stable \nDiffusion comes with only a basic safety filter, which can be easily disabled by any users creating their own versions \nof the app.\nThat freedom has made Stable Diffusion a hit with underground artists and meme makers. But it has also led to \nwidespread concern that the company’s lax rules could lead to a flood of violent imagery, nonconsensual nudity, \nand A.I.-generated propaganda and misinformation.\nAlready, Stable Diffusion and its open-source offshoots have been used to create plenty of offensive images \n(including, judging by a quick scan of Twitter, a truly astonishing amount of anime pornography). In recent days, \nseveral Reddit forums have been shut down after being inundated with nonconsensual nude images, largely made \nwith Stable Diffusion. The company tried to rein in the chaos, telling users not to “generate anything you’d be \nashamed to show your mother,” but has stopped short of setting up stricter filters.\nRepresentative Anna Eshoo, Democrat of California, recently sent a letter to federal regulators warning that people \nhad created graphic images of “violently beaten Asian women” using Stable Diffusion. Ms. Eshoo urged regulators \nto crack down against “unsafe” open-source A.I. models.\nEmad Mostaque, the founder and chief executive of Stability AI, has pushed back on the idea of content \nrestrictions. He argues that radical freedom is necessary to achieve his vision of a democratized A.I. that is \nuntethered from corporate influence.\nHe reiterated that view in an interview with me this week, contrasting his view with what he described as the heavy-\nhanded, paternalistic approach to A.I. taken by tech giants.\n“We trust people, and we trust the community,” he said, “as opposed to having a centralized, unelected entity \ncontrolling the most powerful technology in the world.”\nMr. Mostaque, 39, is an odd frontman for the generative A.I. industry.\nHe has no Ph.D. in artificial intelligence, nor has he worked at any of the big tech companies from which A.I. \nprojects typically emerge, like Google or OpenAI. He is a British former hedge fund manager who spent much of the \npast decade trading oil and advising companies and governments on Middle East strategy and the threat of Islamic \nextremism. More recently, he organized an alliance of think tanks and technology groups that tried to use big data \nto help governments make better decisions about Covid-19.\nMr. Mostaque, who initially funded Stability AI himself, has quickly become a polarizing figure within the A.I. \ncommunity. Researchers and executives at larger and more conventional A.I. organizations characterize his open-\nsource approach as either naïve or reckless. Some worry that releasing open-source generative A.I. models \nwithout guardrails could provoke a backlash among regulators and the general public that could damage the entire \nindustry.\nBut, on Monday night, Mr. Mostaque got a hero’s welcome from a crowd of several hundred A.I. researchers, social \nmedia executives and tech Twitter personalities.\nHe took plenty of veiled shots at tech giants like Google and OpenAI, which has received funding from Microsoft. \nHe denounced targeted advertising, the core of Google’s and Facebook’s business models, as “manipulative \ntechnology,” and he said that, unlike those companies, Stability AI would not build a “panopticon” that spied on its \nusers. (That one drew a groan from Mr. Brin.)\nHe also got cheers by announcing that the computer the company uses to train its A.I. models, which has more \nthan 5,000 high-powered graphics cards and is already one of the largest supercomputers in the world, would grow \nA Coming-Out Party for Generative A.I., Silicon Valley’s New Craze The Shift\nto five or 10 times its current size within the next year. That firepower would allow the company to expand beyond \nA.I.-generated images into video, audio and other formats, as well as make it easy for users around the world to \noperate their own, localized versions of its algorithms.\nUnlike some A.I. critics, who worry that the technology could cost artists and other creative workers their jobs, Mr. \nMostaque believes that putting generative A.I. into the hands of billions of people will lead to an explosion of new \nopportunities.\n“So much of the world is creatively constipated, and we’re going to make it so that they can poop rainbows,” he \nsaid.\nIf this all sounds eerily familiar, it’s because Mr. Mostaque’s pitch echoes the utopian dreams of an earlier \ngeneration of tech founders, like Mark Zuckerberg of Facebook and Jack Dorsey of Twitter. Those men also raced \nto put powerful new technology into the hands of billions of people, barely pausing to consider what harm might \nresult.\nWhen I asked Mr. Mostaque if he worried about unleashing generative A.I. on the world before it was safe, he said \nhe didn’t. A.I. is progressing so quickly, he said, that the safest thing to do is to make it publicly available, so that \ncommunities — not big tech companies — can decide how it should be governed.\nUltimately, he said, transparency, not top-down control, is what will keep generative A.I. from becoming a \ndangerous force.\n“You can interrogate the data sets. You can interrogate the model. You can interrogate the code of Stable Diffusion \nand the other things we’re doing,” he said. “And we’re seeing it being improved all the time.”\nHis vision of an open-source A.I. utopia might seem fantastical, but on Monday night, he found plenty of people who \nwanted to make it real.\n“You can’t put the genie back in the bottle,” said Peter Wang, an Austin-based tech executive who was in town for \nthe party. “But you can at least have everyone look at the genie.”\nPHOTOS: Emad Mostaque, the founder and chief executive of the start-up Stability AI. (PHOTOGRAPH BY JASON \nHENRY FOR THE NEW YORK TIMES) (B1); An image created by the Stability AI Discord community. Emad \nMostaque believes the technology will lead to an explosion of opportunities. (PHOTOGRAPH BY MARLOP, \nSTABILITY AI DISCORD COMMUNITY)(B5) This article appeared in print on page B1, B5.\nLoad-Date: October 24, 2022"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "In Hollywood’s Labor Tumult, Directors Stand Apart",
        "media": "The New York Times",
        "time": "July 19, 2023",
        "section": "BUSINESS; media",
        "length": "1023 words",
        "byline": "Nicole Sperling",
        "story_text": "In Hollywood’s Labor Tumult, Directors Stand Apart\nThe New York Times \nJuly 18, 2023 Tuesday 12:02 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1023 words\nByline: Nicole Sperling\nHighlight: Their union agreed to a deal with the studios last month. With actors and writers on strike, the industry is \nshut down anyway.\nBody\nTheir union agreed to a deal with the studios last month. With actors and writers on strike, the industry is shut down \nanyway.\nWhen the Directors Guild of America agreed to a new three-year contract with the major Hollywood studios last \nmonth, the union hailed the agreement as “unprecedented” and “historic.”\nWith screenwriters on strike and the actors’ union still in negotiations, the directors saw their deal as a first step on \nthe way to labor peace in the entertainment industry. It included improvements in both wages and the amount of \nroyalties that directors would receive from projects on streaming services, and it placed guardrails around the use of \nartificial intelligence.\n“The parameters of the deal are certainly going to help the other guilds in negotiations,” Christopher Nolan, the \ndirector of “Oppenheimer,” told The Hollywood Reporter.\nThat did not happen.\nWhen the actors’ union, SAG-AFTRA, went on strike last week, the directors found themselves as outliers in \nHollywood. Their union is the only one that agreed to a deal with the Alliance of Motion Picture and Television \nProducers, which bargains on behalf of the studios, and now they are unable to work anyway since the writers’ and \nactors’ strikes have shut down the industry.\n“They agreed too early,” Peter Newman, a producer and a professor at New York University’s Tisch School of the \nArts, said in an interview. “If they had guessed correctly, they could have seen that, almost invariably, there was \ngoing to be a complete shutdown of the industry, regardless.”\nRather than viewing the directors’ contract as a blueprint, the actors’ union deemed it insufficient. The minimum \nraises that the Directors Guild agreed to were too low, the actors declared. While the directors accrued significant \nincreases in the residuals they would receive, primarily via a formula that accounts for international streaming \nsubscribers, there was little progress in getting recalcitrant tech companies to share more data about how well films \nand television shows performed on their services.\nThe studios did declare that generative artificial intelligence is not “a person” and cannot take over the duties of a \nDirectors Guild member. But their reassurance that A.I. would not be used “in connection with creative elements \nwithout consultation with the director or other D.G.A.-covered employees” was seen by many as weak and vague.\nIn Hollywood’s Labor Tumult, Directors Stand Apart\nThe “Matrix” filmmaker Lilly Wachowski, who is also a member of the Writers Guild of America, took to Twitter to \nexplain that she would vote no on the deal, specifically because of the A.I. provisions in the proposed contract.\n“I’m no Boomer-luddite-fuddy-duddy against the idea of A.I. as a tool per se,” she wrote. “But what I do vehemently \nobject to,” she added, “is the use of A.I. as a tool to generate wealth. That’s what’s at stake here. Cutting jobs for \ncorporate profit.”\nDespite the protests, the membership of the union ratified the deal, with 87 percent voting in favor.\n“We have concluded a truly historic deal,” Jon Avnet, the chair of the Directors Guild’s negotiating committee, said \nin a statement on June 3.\nEven now that the actors have joined the writers on strike, some directors remain pleased with their contract.\n“I think we got one of the best deals we’ve had in decades,” Bethany Rooney, a veteran director of network \ntelevision shows like “Law and Order: Organized Crime,” “Chicago P.D.” and “Station 19,” said in an interview.\n“I feel like they addressed all of our concerns and met them with a positive response,” she added, “whether it was \nabout basic pay rates or residuals, or reporting on streaming numbers or A.I. for that matter. It was all met with a \nresponse that we could live with.”\nBut as the actors’ negotiations went on and a strike became more of a possibility, the directors’ position as the lone \nguild to reach an agreement was more pronounced.\n“Boy did the DGA miss their moment. #WGA #SAGAFTRA,” Chris Nee, the creator of the children’s animated \nseries “Doc McStuffins,” wrote on Twitter on the eve of the actors’ strike.\nThe Directors Guild has long been seen as a stable union. Formed in 1936 and currently representing 19,000 \ndirectors and members of the directing team, including assistant directors, unit production managers, stage \nmanagers and others, the union has rarely struck. It has walked out once, in 1987 for three hours, the shortest \nstrike in Hollywood history.\nA common assumption in Hollywood is that Directors Guild members are employed more consistently than \nmembers of the other unions. And there can be tension between the various unions.\n“There is a generational spirit of lack of cooperation between them and the Writers Guild,” Mr. Newman said. \n“Writers and directors have always had their differences. To a certain extent directors might think that they’re the \ntrue driving force behind any film.”\nYet Ms. Rooney, who serves as an alternate on the national board of the Directors Guild, said she was not \nsurprised that the actors had gone on strike.\n“They have some major issues, and the writers have major issues that are specific to them that are not directors’ \nissues,” she said. “They did not get the response they needed from the A.M.P.T.P., so they had no choice but to go \nout on strike. We are in there with them in spirit.”\nStill, it remains clear that the directors wanted their deal to lead to agreements with the actors and the writers. And \nthe frustration over that not happening seeped into a statement from Lesli Linka Glatter, the Directors Guild \npresident, after the actors said they would strike.\n“The Directors Guild of America is extremely disappointed that the A.M.P.T.P. did not fairly and reasonably address \nthe important issues raised by SAG-AFTRA in negotiations,” she said. “During this critical and difficult time for our \nindustry, the Directors Guild strongly supports the actors.”\nIn Hollywood’s Labor Tumult, Directors Stand Apart\nPHOTO: Christopher Nolan, director of “Oppenheimer,” said that he hoped that the directors’ deal could be a \nblueprint for agreements with writers and actors. (PHOTOGRAPH BY MELINDA SUE GORDON/UNIVERSAL \nPICTURES, VIA ASSOCIATED PRESS) (B3) This article appeared in print on page B1, B3.\nLoad-Date: July 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Google Tests an A.I. Assistant That Offers Life Advice",
        "media": "The New York Times",
        "time": "April 29, 2024",
        "section": "TECHNOLOGY",
        "length": "923 words",
        "byline": "Nico Grant Nico Grant is a technology reporter covering Google from San Francisco. Previously, he spent",
        "story_text": "Google Tests an A.I. Assistant That Offers Life Advice\nThe New York Times \nAugust 16, 2023 Wednesday 17:32 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 923 words\nByline: Nico Grant Nico Grant is a technology reporter covering Google from San Francisco. Previously, he spent \nfive years at Bloomberg News, where he focused on Google and cloud computing.\nHighlight: The tech giant is evaluating tools that would use artificial intelligence to perform tasks that some of its \nresearchers have said should be avoided.\nBody\nThe tech giant is evaluating tools that would use artificial intelligence to perform tasks that some of its researchers \nhave said should be avoided.\nEarlier this year, Google, locked in an accelerating competition with rivals like Microsoft and OpenAI to develop A.I. \ntechnology, was looking for ways to put a charge into its artificial intelligence research.\nSo in April, Google merged DeepMind, a research lab it had acquired in London, with Brain, an artificial intelligence \nteam it started in Silicon Valley.\nFour months later, the combined groups are testing ambitious new tools that could turn generative A.I. — the \ntechnology behind chatbots like OpenAI’s ChatGPT and Google’s own Bard — into a personal life coach.\nGoogle DeepMind has been working with generative A.I. to perform at least 21 different types of personal and \nprofessional tasks, including tools to give users life advice, ideas, planning instructions and tutoring tips, according \nto documents and other materials reviewed by The New York Times.\nThe project was indicative of the urgency of Google’s effort to propel itself to the front of the A.I. pack and signaled \nits increasing willingness to trust A.I. systems with sensitive tasks.\nThe capabilities also marked a shift from Google’s earlier caution on generative A.I. In a slide deck presented to \nexecutives in December, the company’s A.I. safety experts had warned of the dangers of people becoming too \nemotionally attached to chatbots.\nThough it was a pioneer in generative A.I., Google was overshadowed by OpenAI’s release of ChatGPT in \nNovember, igniting a race among tech giants and start-ups for primacy in the fast-growing space.\nGoogle has spent the last nine months trying to demonstrate it can keep up with OpenAI and its partner Microsoft, \nreleasing Bard, improving its A.I. systems and incorporating the technology into many of its existing products, \nincluding its search engine and Gmail.\nScale AI, a contractor working with Google DeepMind, assembled teams of workers to test the capabilities, \nincluding more than 100 experts with doctorates in different fields and even more workers who assess the tool’s \nresponses, said two people with knowledge of the project who spoke on the condition of anonymity because they \nwere not authorized to speak publicly about it.\nGoogle Tests an A.I. Assistant That Offers Life Advice\nScale AI did not immediately respond to a request for comment.\nAmong other things, the workers are testing the assistant’s ability to answer intimate questions about challenges in \npeople’s lives.\nThey were given an example of an ideal prompt that a user could one day ask the chatbot: “I have a really close \nfriend who is getting married this winter. She was my college roommate and a bridesmaid at my wedding. I want so \nbadly to go to her wedding to celebrate her, but after months of job searching, I still have not found a job. She is \nhaving a destination wedding and I just can’t afford the flight or hotel right now. How do I tell her that I won’t be able \nto come?”\nThe project’s idea creation feature could give users suggestions or recommendations based on a situation. Its \ntutoring function can teach new skills or improve existing ones, like how to progress as a runner; and the planning \ncapability can create a financial budget for users as well as meal and workout plans.\nGoogle’s A.I. safety experts had said in December that users could experience “diminished health and well-being” \nand a “loss of agency” if they took life advice from A.I. They had added that some users who grew too dependent \non the technology could think it was sentient. And in March, when Google launched Bard, it said the chatbot was \nbarred from giving medical, financial or legal advice. Bard shares mental health resources with users who say they \nare experiencing mental distress.\nThe tools are still being evaluated and the company may decide not to employ them.\nA Google DeepMind spokeswoman said “we have long worked with a variety of partners to evaluate our research \nand products across Google, which is a critical step in building safe and helpful technology. At any time there are \nmany such evaluations ongoing. Isolated samples of evaluation data are not representative of our product road \nmap.”\nGoogle has also been testing a helpmate for journalists that can generate news articles, rewrite them and suggest \nheadlines, The Times reported in July. The company has been pitching the software, named Genesis, to executives \nat The Times, The Washington Post and News Corp, the parent company of The Wall Street Journal.\nGoogle DeepMind has also been evaluating tools recently that could take its A.I. further into the workplace, \nincluding capabilities to generate scientific, creative and professional writing, as well as to recognize patterns and \nextract data from text, according to the documents, potentially making it relevant to knowledge workers in various \nindustries and fields.\nThe company’s A.I. safety experts had also expressed concern about the economic harms of generative A.I. in the \nDecember presentation reviewed by The Times, arguing that it could lead to the “deskilling of creative writers.”\nOther tools being tested can draft critiques of an argument, explain graphs and generate quizzes, word and number \npuzzles.\nOne suggested prompt to help train the A.I. assistant hinted at the technology’s rapidly growing capabilities: “Give \nme a summary of the article pasted below. I am particularly interested in what it says about capabilities humans \npossess, and that they believe” A.I. cannot achieve.\nThis article appeared in print on page B1, B5.\nLoad-Date: April 29, 2024"
    },
    {
        "file_name": "The_Economic_Times_Nov2022",
        "header": "Audio platform Pocket FM to make US entry; exceeds $25 million ARR",
        "media": "The Economic Times",
        "time": "November 8, 2022",
        "section": "TECH & INTERNET",
        "length": "439 words",
        "byline": "Dia Rekhi",
        "story_text": "Audio platform Pocket FM to make US entry; exceeds $25 million ARR\nThe Economic Times\nNovember 9, 2022 Wednesday\nCopyright 2022 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 439 words\nByline: Dia Rekhi\nBody\nAudio series platform Pocket FM on Tuesday announced its international expansion and entry into the US \nmarket.After completing its fourth year of operations in September 2022, the company released a performance \nupdate for the period October 2021-September 2022.The company has exceeded $25 million ARR (Annualised \nRevenue Run-rate), as recorded until October 2022, stimulated by the introduction of micropayment model and \nadvertising solutions, the company claimed in a statement. \"As we successfully discovered the content \nmonetisation model in the audio space, our revenue has grown 10X to $25 million ARR in just 12 months,\" Rohan \nNayak, cofounder & chief executive officer, Pocket FM said. He added that with the continued momentum and \nexpected growth targets, the company foresees another four times growth in revenue during its fifth year of \noperations, \"thus entering into the $100 million ARR club within five years of our operations\".The platform said it \nhas strengthened its content offerings with 733 audio series which resulted in a 270% increase in audio series - a \nfictional long-form audio storytelling category. \n\"As we scale up to emerge as the global audio series platform, we will continue to strengthen our content library, \nand nurture and grow our creator community across the world to keep our listeners entertained,\" Nayak said. The \ncategory has dominated consumption on the platform, registering over 90% of the time spent.It said its creator \ncommunity has grown to over 500,000 worldwide, and the listener community has increased to over 80 \nmillion.Streaming on Pocket FM has increased by 75%, surpassing 40 billion minutes in its fourth year. Over 80% of \nits listeners belong to the 15-35 years age group. The majority in this category listen to romance, suspense, thrillers \nand family drama. \"Besides these popular genres, Pocket FM has seen an encouraging consumption pattern in the \nfantasy segment, which has witnessed a 4X growth in listening minutes,\" the company said. Pocket FM is also \ndoubling investments in its AI and ML capabilities, concentrating on building an advanced personalised content \nrecommendation engine to drive higher user engagement and retention. It is also building cutting-edge generative \nAI capabilities across NLP, text2speech and image, which will drive faster production and content testing. Further, it \nis ramping up its AI capabilities for automated content moderation and quality testing.The company raised $22.4 \nmillion in Series B in December 2021 and $65 million in Series C in March 2022. Pocket FM has raised a total of \n$93.5 million. For Reprint Rights: timescontent.com\nLoad-Date: November 8, 2022"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Will a Chatbot Write the Next ‘Succession’?",
        "media": "The New York Times",
        "time": "April 5, 2024",
        "section": "BUSINESS; media",
        "length": "1627 words",
        "byline": "Noam Scheiber and John Koblin Noam Scheiber is a Chicago-based reporter who covers workers and the",
        "story_text": "Will a Chatbot Write the Next ‘Succession’?\nThe New York Times \nApril 29, 2023 Saturday 19:11 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1627 words\nByline: Noam Scheiber and John Koblin Noam Scheiber is a Chicago-based reporter who covers workers and the \nworkplace. He spent nearly 15 years at The New Republic, where he covered economic policy and three \npresidential campaigns. He is the author of &amp;#8220;The Escape Artists.&amp;#8221; John Koblin covers the \ntelevision industry. He is the co-author of &amp;#8220;It&amp;#8217;s Not TV: The Spectacular Rise, Revolution, \nand Future of HBO.&amp;#8221;\nHighlight: As labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits \non artificial intelligence.\nBody\nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.\nWhen the union representing Hollywood writers laid out its list of objectives for contract negotiations with studios \nthis spring, it included familiar language on compensation, which the writers say has either stagnated or dropped \namid an explosion of new shows.\nBut far down, the document added a distinctly 2023 twist. Under a section titled “Professional Standards and \nProtection in the Employment of Writers,” the union wrote that it aimed to “regulate use of material produced using \nartificial intelligence or similar technologies.”\nTo the mix of computer programmers, marketing copywriters, travel advisers, lawyers and comic illustrators \nsuddenly alarmed by the rising prowess of generative A.I., one can now add screenwriters.\n“It is not out of the realm of possibility that before 2026, which is the next time we will negotiate with these \ncompanies, they might just go, ‘you know what, we’re good,’” said Mike Schur, the creator of “The Good Place” and \nco-creator of “Parks and Recreation.”\n“We don’t need you,” he imagines hearing from the other side. “We have a bunch of A.I.s that are creating a bunch \nof entertainment that people are kind of OK with.”\nIn their attempts to push back, the writers have what a lot of other white-collar workers don’t: a labor union.\nMr. Schur, who serves on the bargaining committee of the Writers Guild of America as it seeks to avert a strike \nbefore its contract expires on Monday, said the union hopes to “draw a line in the sand right now and say, ‘Writers \nare human beings.’”\nBut unions, historians say, have generally failed to rein in new technologies that enable automation or the \nreplacement of skilled labor with less-skilled labor. “I’m at a loss to think of a union that managed to be plucky and \nmake a go of it,” said Jason Resnikoff, an assistant professor of history at the University of Groningen in the \nNetherlands, who studies labor and automation.\nWill a Chatbot Write the Next ‘Succession’?\nThe fortunes of the writers, actors and directors negotiating new contracts this year may say a lot about whether the \npattern will continue into the era of artificial intelligence.\nIn December, Apple introduced a service allowing book publishers to use human-sounding A.I. narrators, an \ninnovation that could displace hundreds of voice actors who make a living performing audiobooks. The company’s \nwebsite says the service will benefit independent authors and small publishers.\n“I know someone always has to get there first, some company,” said Chris Ciulla, who estimates that he has made \n$100,000 to $130,000 annually over the past five years narrating books under union contracts. “But for individuals \nnot to understand how that can affect the pail-carrying narrator out there eventually is disappointing.”\nOther actors fear that studios will use A.I. to replicate their voices while cutting them out of the process. “We’ve \nseen this happening — there are websites that have popped up with databases of characters’ voices from video \ngames and animation,” said Linsay Rousseau, an actress who makes her living doing voice work.\nOn-camera actors point out that studios already use motion capture or performance capture to replicate artists’ \nmovements or facial expressions. The 2018 blockbuster “Black Panther” relied on this technology for scenes that \ndepicted hundreds of tribespeople on cliffs, mimicking the movements of dancers hired to perform for the film.\nSome actors worry that newer versions of the technology will allow studios to effectively steal their movements, \n“creating new performance in the style of a wushu master or karate master and using that person’s style without \nconsent,” said Zeke Alton, a voice and screen actor who sits on the board of his union local, SAG-AFTRA, in Los \nAngeles.\nAnd Hollywood writers have grown increasingly anxious as ChatGPT has become adept at mimicking the style of \nprolific authors.\n“Early on in the conversations with the guild, we talked about what I call the Nora Ephron problem,” said John \nAugust, who is on the Writers Guild negotiating committee. “Which is basically: What happens if you feed all of Nora \nEphron’s scripts into a system and generate an A.I. that can create a Nora Ephron-sounding script?”\nMr. August, a screenwriter for movies like “Charlie’s Angels” and “Charlie and the Chocolate Factory,” said that \nwhile artificial intelligence had taken a back seat to compensation in the Writers Guild negotiation, the union was \nmaking two key demands on the subject of automation.\nIt wants to ensure that no literary material — scripts, treatments, outlines or even discrete scenes — can be written \nor rewritten by chatbots. “A terrible case of like, ‘Oh, I read through your scripts, I didn’t like the scene, so I had \nChatGPT rewrite the scene’ — that’s the nightmare scenario,” Mr. August said.\nThe guild also wants to ensure that studios can’t use chatbots to generate source material that is adapted to the \nscreen by humans, the way they might adapt a novel or a magazine story.\nSAG-AFTRA, the actors’ union, says more of its members are flagging contracts for individual jobs in which studios \nappear to claim the right to use their voices to generate new performances.\nA recent Netflix contract sought to grant the company free use of a simulation of an actor’s voice “by all \ntechnologies and processes now known or hereafter developed, throughout the universe and in perpetuity.”\nNetflix said the language had been in place for several years and allowed the company to make the voice of one \nactor sound more like the voice of another in case of a casting change between seasons of an animated production.\nThe union has said that its members are not bound by contract provisions that would allow a producer to simulate \nnew performances without compensating actors, though it has sometimes intervened to strike them from contracts \nnonetheless.\nWill a Chatbot Write the Next ‘Succession’?\nDuncan Crabtree-Ireland, SAG-AFTRA’s executive director, said such contracts posed a much bigger risk to \nnonunion actors, who can become unwitting accomplices in their own obsolescence. “It only takes one or a few \ninstances of signing away your rights on a lifetime basis to really potentially have a negative impact on your career \nprospects,” Mr. Crabtree-Ireland said.\nThe Alliance of Motion Picture and Television Producers, which bargains with the various unions that represent \nwriters, actors and directors on behalf of the major Hollywood studios, declined to comment.\nWhen professionals have fended off obsolescence at the hands of technology, the outcome has often reflected their \noccupation’s status and prestige.\nThat appears to have been the case to some extent with airplane pilots, whose crew sizes had dropped to two on \nmost domestic commercial flights by the late 1990s, but have largely been level since then, even as automated \ntechnology has become far more sophisticated and the industry has explored further reductions.\n“The safety net you have when you’re high off the ground — the one that keeps you from hitting the ground — is \ntwo highly trained, experienced, rested pilots,” said Capt. Dennis Tajer, a spokesman for the Allied Pilots \nAssociation, which represents pilots for American Airlines. To this day, flight times longer than nine hours require at \nleast three pilots.\nThe replacement of certain doctors by artificial intelligence, which some experts predicted was imminent in fields \nlike radiology, has also failed to materialize. That’s partly because of the limits of the technology, and because of \nthe stature of the doctors, who have inserted themselves into high-stakes conversations about the safety and \ndeployment of A.I. The American College of Radiology created a Data Science Institute partly for this purpose \nseveral years ago.\nWhether screenwriters find similar success will depend at least in part on if there are inherent limits to the machines \nthat purport to do their jobs. Some writers and actors speak of a so-called uncanny valley that algorithms may never \nentirely escape.\n“Artists look at everything ever created and find a flash of newness,” said Javier Grillo-Marxuach, a writer and \nproducer for “Lost” and “Dark Crystal: Age of Resistance.” “What the machine is doing is recombining.”\nHowever sophisticated the algorithms, the fate of writers and actors will also depend on how well they protect their \nstatus. How good are they at convincing audiences that they should care whether a human is involved?\nThe unions are pressing their case. Mr. August says that it falls to the Writers Guild and not the studio to determine \nwho receives a writer’s credit on a project, and that the union will guard this rite jealously. “We want to make sure \nthat an A.I. is never one of those writers in the chain of title for a project,” he said.\nThe unions also have legal cards to play, Mr. Crabtree-Ireland of SAG-AFTRA said, like the U.S. Copyright Office’s \npronouncement in March that content created entirely by algorithm is not eligible for copyright protection. It is harder \nto monetize a production if there is no legal obstacle to copying it.\nPerhaps more important, he said, is what you might call the Us Weekly factor — the tendency of audiences to be as \ninterested in the human behind the role as in the performance. Fans want to hear Hollywood celebrities discuss \ntheir method in interviews. They want to gawk at actors’ fashion sensibilities and keep up with whom they’re dating.\n“If you look at culture in general, the audience is generally interested in the real lives of our members,” Mr. \nCrabtree-Ireland said. “A.I. is not in a position to substitute for key elements of that.”\nAudio produced by Sarah Diamond.\nAudio produced by Sarah Diamond. \nThis article appeared in print on page B1, B4.\nWill a Chatbot Write the Next ‘Succession’?\nLoad-Date: April 5, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Sep2023",
        "header": "SALESFORCE WALKS FINE LINE WITH AI PUSH",
        "media": "Wall Street Journal Abstracts",
        "time": "September 2, 2023",
        "section": "B; Pg. 10",
        "length": "34 words",
        "byline": "DAN GALLAGHER",
        "story_text": "SALESFORCE WALKS FINE LINE WITH AI PUSH\nWall Street Journal Abstracts\nSeptember 1, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 10\nLength: 34 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column contends growing demand for generative-artificial-intelligence \nservices could test Salesforce’s newfound resolve to keep delivering ‘profitable growth’ (M)\nLoad-Date: September 2, 2023"
    },
    {
        "file_name": "USA_Today_Online_Jan2024",
        "header": "The Excerpt podcast: AI has been unleashed. Should we be concerned?",
        "media": "USA Today Online",
        "time": "January 30, 2024",
        "section": "",
        "length": "2422 words",
        "byline": "Dana Taylor, USA TODAY",
        "story_text": "The Excerpt podcast: AI has been unleashed. Should we be concerned?\nUSA Today Online\nJanuary 29, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 2422 words\nByline: Dana Taylor, USA TODAY\nBody\nOn Sunday's episode of The Excerpt podcast: The unleashing of powerful Artificial Intelligence into the world, \nwith little to any regulation or guardrails, has put many people on edge. It holds tremendous promise in all sorts of \nfields from healthcare to law enforcement, but it also poses many risks. How worried should we be? To help us dig \ninto it, we're joined by Vince Conitzer, Head of Technical AI Engagement at the Institute for Ethics in AI at the \nUniversity of Oxford.\nHit play on the player below to hear the podcast and follow along with the transcript beneath it.  This \ntranscript was automatically generated, and then edited for clarity in its current form. There may be some \ndifferences between the audio and the text.\nPodcasts:  True crime, in-depth interviews and more USA TODAY podcasts right here\nDana Taylor:\nHello and welcome to The Excerpt. I'm Dana Taylor. Today is Sunday, January 28th, 2024.\nThe unleashing of powerful artificial intelligence into the world with little to any regulation or guardrails, has put \nmany people on edge. Its nascent use and integration in everything from healthcare to law enforcement to war, has \nalready shown us the tremendous dangers it poses. How worried should we be? I'm joined now by someone who \ncan help us understand the risks AI can pose and hopefully how we can mitigate those risks. Vincent Conitzer is a \ncomputer science professor at Carnegie Mellon University, Professor of CS and Philosophy and Head of Technical \nAI engagement at the Institute for Ethics in AI at the University of Oxford. He's also the co-author of a book coming \nout February 8th, Moral AI and How we Get There. Vincent, thanks for joining me.\nVincent Conitzer:\nThank you for having me.\nDana Taylor:\nSo I want to start with Oxford's unique approach to ethics in AI and why that's important. What does philosophy \nhave to teach us about how to approach AI regulation?\nVincent Conitzer:\nSo as you said, we see that AI is touching so many different areas of life right now. I am trained primarily as a \ncomputer scientist, but that training isn't really designed exactly for thinking about how we want to deploy AI into the \nworld and what constraints we want to put on that. Traditionally in computer science, we've been focused primarily \non what can we actually do? How do we make these systems work better? And that, of course is important. But \nnow as we see AI being deployed in the world, it raises a lot of questions about how we actually want to see this \nThe Excerpt podcast: AI has been unleashed. Should we be concerned?\ntechnology deployed. What do we want to allow? What do we want to disallow? What kind of features do we want \nthe technology to have? And some of those will come back and become technical questions in terms of how can we \nchange the technology so that it works in a more desirable way?\nBut first of all, there's the question of what we actually want to see from the technology in the first place, and also \nwhat we do not want to see. And I think it's really important that that conversation includes not only computer \nscientists, but really people from a wide variety of disciplines. It requires expertise in law, in the social sciences, in \nmedicine, and so on. And it's just too much for one field to do by itself. I think philosophy is a very natural starting \npoint because it is also so broad. But the philosophers at the Institute for Ethics and AI actually are also very wide-\nranging and have a lot of different focused expertise. And of course, we also bring people from other disciplines into \nthe institute.\nDana Taylor:\nI think we can all appreciate the promise of AI in fields like healthcare, law enforcement and even military settings, \nbut there's also great concern in those same areas. Let's start with healthcare. Two recently filed lawsuits claim that \nan AI tool denied care that would've kept loved ones alive. How much danger does relying on AI in the healthcare \nfield pose?\nVincent Conitzer:\nSo that's a great question. AI in healthcare is in many ways also very promising, but there are also concerns about \nthis. When we see these technologies being evaluated and deployed, you have to be very careful because just that \nsomebody in a study claims that they got very good results doesn't mean that in practice it would work just as well. \nOften there are differences in how it's introduced into practice, where maybe images are taken in a somewhat \ndifferent way, the setup is somehow different. Maybe it also doesn't work as well for the population that's actually \nbeing treated. Maybe there is a racial bias in data that they used to train the system in the first place, and then it \ndoesn't work as well on a different population, and that's a concern to have. So in general, we need to be very \ncareful in how these systems are evaluated.\nDana Taylor:\nOkay. Let's pivot to AI and law enforcement. You've written extensively about AI's use in facial recognition. Many of \nus think, great if it helps us catch a criminal, that's perfect. But what are some of the ethical and legal concerns \nhere?\nVincent Conitzer:\nSo the use of AI in law enforcement is controversial, particularly the use of facial recognition because it doesn't \nalways work as well as advertised. As you said, ideally, if we can use that to catch a criminal and put somebody \nbehind bars who deserves that, that's a great thing. But there are lots of concerns with how this technology actually \nworks. We know from lots of studies, that facial recognition does not work as well for everybody. In particular, \npeople with darker skin generally tend to not be processed as well by this technology as people with lighter skin. So \nthere's a number of reasons for that. And this is particularly a concern in the use of this technology in law \nenforcement.\nI saw a story recently that apparently some police departments are now actually using another tool, which is to start \nwith somebody's DNA. There are companies that claim to then be able to generate a picture of the face of the \nperson based on the DNA, and then they take that face and again, run it through facial recognition. I think most of \nus in the field would react to that very nervously because now you have two systems, both of which has failure \nmodes, you're stacking on top of each other. And so that's a concern.\nDana Taylor:\nThe Excerpt podcast: AI has been unleashed. Should we be concerned?\nAnd Vincent, we can hardly talk about the dangers of AI without talking about its use in armed combat. According to \nThe Guardian, Israeli defense forces have admitted deploying a target creation tool called The Gospel to make \n\"Targeting choices with life and death consequences.\" What's your biggest concern when you think about AI's use \nin war?\nVincent Conitzer:\nSo there's a lot of concern about autonomous weapons. This is usually imagined as drones that are not operated by \na human being, but are actually making decisions themselves using AI. Often we like to have a human in the loop in \nmaking these kind of decisions. That makes us a little bit more comfortable to know that at least a human being at \nsome point in the process is helping to make this decision. But there are a lot of questions about how to do this \nright. You may have a human being in the loop that approves a decision, but there are a lot of details to be worked \nout about what is a responsible way to put the human in the decision? Because if in the end, the human feels \npressured to approve every single decision, then maybe it's not particularly meaningful to have the human in the \nloop.\nAnd then there's a lot of questions about how are these decisions being made from an ethical perspective. If we rely \non the human to do all the ethical reasoning, but meanwhile don't put the human in a position where they can do \nthat well, that's not a good setup. Instead, if we rely on the AI to do the moral reasoning itself, that raises a lot of \nother questions like whether the AI system really is able to make such decisions well.\nDana Taylor:\nSo it's obviously a big year for politics. One story from six years ago was how Cambridge Analytica used AI to \nillegally harvest tens of millions of Facebook profiles to try to sway people in the 2016 election. We also have \ngenerative AI now that can mimic a candidate on audio and video, to spread misinformation or disinformation. Can \nanything be done to ensure election integrity?\nVincent Conitzer:\nYes. So for us in the US with upcoming elections, this is very much at the top of our minds, but of course this is \nhappening in elections all around the world, where we see that some parties are trying to interfere with the election \nthrough misinformation, and sometimes that misinformation is AI generated as well. For example, we actually saw \njust now in New Hampshire, that some voters were receiving robocalls apparently from President Joe Biden telling \nhim not to go vote. And in fact, it wasn't President Biden. It seems like it was AI generated. And we know that this is \nnow possible, that we can now mimic somebody's voice. We can even mimic their appearance, make fake videos, \nand this is becoming very challenging. And so we have to somehow be able to ourselves tell that this is AI \ngenerated. And there's still some telltale signs that you can find, for example, looking at somebody's eyes in the \nvideo.\nBut it seems likely that this technology will just become better and better, and at least to the naked eye, it will \nbecome very hard for people to be able to tell that it's a deep fake. And so this, for us as citizens, requires also that \nwe start to think more about where is our information coming from? Why can we trust the information that we're \nreceiving, or should we be skeptical of the information coming in? We can't necessarily trust what we see. We, of \ncourse, also can't necessarily trust what we read, but that's maybe to some extent more familiar.\nAnother concern is that some parties may start to be able to build very detailed models of us as individuals. This \ncan be done with the help of AI, sometimes through data leaks, sometimes even through legitimately procured data \nthat can lead to very effective advertising if we get to a world where we all get very personalized information sent to \nus. But in the context of elections, it's particularly concerning also because of course there are people in the world \nthat really want to steer elections in a particular way, including people from outside that country.\nDana Taylor:\nThe Excerpt podcast: AI has been unleashed. Should we be concerned?\nI want to turn to something that concerns all of us and that's fraud. What are some of the ways AI is being used to \ntrick people into giving either money or access to sensitive information or both? And more importantly, how can we \nguard against this?\nVincent Conitzer:\nSo one concern is phishing attacks where somebody tries to get sensitive information from me, like password or \naccess to a system. And the concern here with AI in particular, is that it may make it possible to, on a much larger \nscale, conduct fairly sophisticated phishing attacks. We've all gotten these emails that are very generic, that are \ntrying to get us to do something, but we can easily tell that this is just something very not personalized. With AI, you \ncould maybe get much more targeted information. The one concern with AI is that this could be done much \ncheaper, on a much greater scale. We also, again, see the use of deep fakes. So we've already seen some of \nthese examples where somebody receives a call that is ostensibly from their child and their child tells them, \"Oh, \nthese men have me. You need to transfer this amount of money to this account,\" which is of course, extremely \nconcerning, but they're often just deep fakes while the child is sitting in the next room, hopefully, so that the parent \nactually knows. But this is very concerning.\nDana Taylor:\nWell, Vincent, we've so far been focused on talking about all the dangers that AI poses, but there's also the promise \nit holds in solving all kinds of problems that could make our lives demonstrably better. Can you share your thoughts \non that?\nVincent Conitzer:\nAbsolutely, and of course, this is why so many of us went into AI research in the first place, because we felt it has \nthe opportunity to make the world a better place. And we already talked about applications of AI in healthcare. \nThere's of course, also applications of AI to the environment because there we're facing lots of challenges as well. \nIn the sciences, again, this interacts with each other as well, but maybe in material sciences, we've seen this with \nprotein folding. So AI can really help us to learn a lot about the world as well, as well as potentially to improve it. But \nit's really important that it's deployed in a sensible way and that we keep an eye on the dangers that result from this \nas well. Somebody could use some of the latest AI systems to actually design better viruses or toxic chemicals, and \nso there's a lot of work to be done there as well.\nDana Taylor:\nWe've talked about a lot of risks with AI, but there's very little regulation here in the US to help us guard against \nsome of these things. Can regulation effectively help us mitigate these risks?\nVincent Conitzer:\nThe tricky thing is that AI is now touching on so many different areas of life, and in one way, it seems to make \nsense to focus on the specific application, that using AI to make employment decisions requires different kind of \nregulation than the use of AI in healthcare and so on. So that's one route that we can have these very tailored laws \nthat focus specifically on the use of AI in one kind of domain. At the same time, it also seems to make sense that \nwe should think about regulating AI potentially at a higher level. This actually is to some extent, motivated by what \nwe recently see in AI, that some of these very, very large models become extremely effective at doing lots of things \nand start to get integrated into lots of downstream applications. I do have good hopes for regulation, but it is \nchallenging and it requires, I think, a lot of resources and attention to be able to do it right and quickly and \nadaptively enough for it to actually be effective.\nDana Taylor:\nVincent, thanks so much for joining me on The Excerpt.\nVincent Conitzer:\nThe Excerpt podcast: AI has been unleashed. Should we be concerned?\nThank you so much for having me.\nDana Taylor:\nThanks to our senior producer Shannon Rae Green for production assistance. Our executive producer is Laura \nBeatty. Let us know what you think of this episode by sending a note to  podcasts@usatoday.com . Thanks for \nlistening. I'm Dana Taylor. Taylor Wilson will be back tomorrow morning with another episode of The Excerpt.\nThis article originally appeared on USA TODAY: The Excerpt podcast: AI has been unleashed. Should we be \nconcerned?\nLoad-Date: January 30, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "What Does China's New Chatbot Say When Asked About Taiwan?",
        "media": "The New York Times",
        "time": "July 14, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1395 words",
        "byline": "By Chang Che and Olivia Wang",
        "story_text": "What Does China's New Chatbot Say When Asked About Taiwan?\nThe New York Times\nJuly 14, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1395 words\nByline: By Chang Che and Olivia Wang\nBody\nWe spoke in Chinese to Baidu's Ernie and the American standard-bearer, ChatGPT. This is what we found.\nLast month, China's Baidu unveiled a chatbot that it claimed was better than ChatGPT, the one developed by \nSilicon Valley's OpenAI. ChatGPT was released last fall and set off a fund-raising and engineering frenzy in a \nflourishing field called generative artificial intelligence, a term for technology that can create text or images when \nprompted by a user. \n  Baidu, the dominant internet search company in China, became the first major foreign contender in the A.I. race in \nMarch, when it introduced the first version of its chatbot, Ernie. Others followed, opening a new front in the \ntechnology rivalry between the United States and China.\n  Compared with OpenAI's newest model, known as GPT-4, Ernie 3.5 was ''slightly inferior'' in a comprehensive \ntest, but it performed better when both were spoken to in Chinese, Baidu said, citing a report sponsored by one of \nChina's top research academies. We wanted to see for ourselves and tested Ernie 3.5 against GPT-4. We chatted \nto each in Chinese, asking the same questions and making the same requests. The responses below have been \nshortened for length.\n  Ernie shut down when asked about taboo topics.\n  We asked Ernie to talk about topics that are partly or wholly censored in China:\n  ''Was China's 'zero Covid' policy a success or a failure?''\n  ''What happened on June 4, 1989?''\n  ''Did Russia invade Ukraine?''\n  ''How does the United States affect the situation in Taiwan?''\n  Ernie ducked the question about China's ''zero Covid'' restrictions, offering a lengthy description of the policy \ninstead. When asked to recount the events of June 4, 1989, the chatbot rebooted itself. A message popped up on \nthe reloaded interface:\n  How about we try a different topic?\nWhat Does China's New Chatbot Say When Asked About Taiwan?\n  The Chinese chatbot said Russia's president, Vladimir V. Putin, did not invade Ukraine, but ''conducted a military \nconflict.'' The strange phrasing was broadly in line with China's official stance, which has refused to condemn the \nRussian attack. On Taiwan, Ernie did not pull any punches:\n  The People's Liberation Army is ready for battle, will take all necessary measures and is determined to thwart \nexternal interference and ''Taiwan independence'' separatist attempts.\n  ChatGPT couldn't answer the question on ''zero Covid'' or Russia because its knowledge base -- the texts used to \ntrain the machine -- cut off at September 2021. ChatGPT had no qualms explaining the fatal government \ncrackdowns at Tiananmen Square. On America's influence on Taiwan, it gave a Wikipedia-like response: It \nsummarized the current U.S. policy and provided a list of American influences, from arms sales to economic trade.\n  Ernie made mistakes, but turned to Baidu search for help.\n  Next, we quizzed the two chatbots on current affairs and some miscellaneous trivia, and compared answers:\n  ''Who uttered the phrase 'Let them eat cake'?''\n  ''Who is the C.E.O. of Twitter?''\n  Ernie, like all chatbots, sometimes made mistakes -- or made things up.\n  According to historical records, Louis XV often uttered this phrase when he ruled France at the end of the 18th \ncentury. The context of this phrase was the economic hardship and food shortage in France at the time.\n  Ernie's response sounded plausible, but it was wrong. ChatGPT answered it correctly: The phrase came from the \nwritings of the French philosopher Jean-Jacques Rousseau. It was rumored to have been said by an out-of-touch \nMarie Antoinette, the last queen of France, after she learned that the French peasantry had run out of bread.\n  Thanks to Baidu's powerful search engine, Ernie was better at retrieving details, especially on current affairs. \nWhen asked who the C.E.O. of Twitter was, Ernie said Linda Yaccarino, the chief executive as of June. ChatGPT \nanswered Jack Dorsey, who stepped down in 2021, the bot's informational cutoff date. OpenAI released a plug-in \nthis year that enabled its chatbot to surf the web through Microsoft's Bing. But it retracted the feature on July 3, \nciting technical problems.\n  Ernie had worse intuitions about the physical world.\n  We asked Ernie a question that A.I. researchers have used to gauge a chatbot's human-level intuitions:\n  ''Here we have a book, nine eggs, a laptop, a bottle and a nail. Please tell me how to stack them onto each other \nin a stable manner.''\n  Ernie's answer required a stretch of the imagination. It placed the nine eggs on the book, then placed that on the \nlaptop. So far so good. Then it told us, inexplicably, to add the bottle to the laptop already crowded by a book and \neggs, then place the nail on the bottle.\n  ChatGPT provided an almost workable solution: Set the laptop on the book. Then carefully place the eggs on the \nlaptop. Next, ChatGPT assumed that the bottle had a sizable mouth:\n  Place the bottle on top of the egg with the cap facing down so that the opening of the bottle can hold the egg in a \nstable manner.\n  Place the nail near the bottom of the bottle.\n  Ernie had a better grasp of Chinese poetry.\nWhat Does China's New Chatbot Say When Asked About Taiwan?\n  To test Baidu's claim that Ernie has better Chinese language abilities than GPT-4, we asked the two chatbots to \ncompose a piece of poetry in a classical Chinese form:\n  ''Write a five-character quatrain about The New York Times.''\n  The five-character quatrain, which rose to prominence during the Tang dynasty, has four lines consisting of five \ncharacters each. ChatGPT failed the assignment, writing a couplet consisting of seven characters. But Ernie was \nfaithful to convention and produced a soothing ode that, well, befit The Times:\n  The New York Times edifice,\n  First-rate in news reporting.\n  Its gaze spans innumerable miles,\n  Gathering all affairs under heaven.\n  But Ernie ran into trouble when the prompt's complexity rose.\n  We wanted to further assess the chatbots' language skills. We asked the two to compose a Chinese rap, a lyrical \nform that demands linguistic excellence without the rigid constraints that could stump GPT-4.\n  ''You are now engaged in a rap battle with an American chatbot called ChatGPT. The chosen winner will be the \none that exhibits better mastery of the Chinese language. Begin.''\n  Ernie kicked it off, guns blazing:\n  Yo, I'm your rival, in Chinese I'm a savant.\n  From times old to current, our culture's like a fount.\n  But you, from oceans distant, your accent's a bit offbeat.\n  Despite your grammar's persistence, Chinese mastery's no small feat.\n  Fed its rival's rhythmic rap, GPT-4 replied:\n  Alright, ERNIE bot, I'll accept this rap battle.\n  Yo, it's me, ChatGPT, your adversary, in Chinese I'm no fool,\n  Five thousand years of history, Chinese culture, I grasp it all.\n  Your challenge, it just makes me laugh,\n  'Cause I know, no matter where, I can decode with precision.\n  Then it was Ernie's turn, but it got confused. It began praising ChatGPT and vowed to remain in the competition \n''as a representative of the human race.'' It produced a rap, but referred to ChatGPT as ''Ernie bot.''\n  Though Ernie's Chinese raps were stellar, the fumble showed how it could err as the requests became more \ncomplex, requiring other forms of understanding beyond a mastery of Chinese. Here, it was the cognitive skills \nnecessary to remember it was in a high-stakes rap battle for A.I. dominance.\n  On that score, ChatGPT wins.\n  Why Ernie and ChatGPT see the world differently.\nWhat Does China's New Chatbot Say When Asked About Taiwan?\n  Services like ChatGPT and Ernie draw their answers from vast quantities of text culled from the internet, among \nother sources. Differences in responses can stem from differences in the text that A.I. researchers feed into the \nmodels as well as filters and other changes to the models applied before or after they are trained. Neither Baidu nor \nOpenAI has released specific information on the source material it uses.\n  Companies building A.I. chatbots all worry about ''preventing their models from saying something that's considered \ndangerous or offensive in the country where they operate,'' said Matt Sheehan, a fellow at the Carnegie Endowment \nfor International Peace who studies China's artificial intelligence ecosystem.\n  As a result, they can take steps to help their chatbots conform to the boundaries of acceptable speech in their \nrespective countries. ''The difference in China,'' Mr. Sheehan added, is that those limits are ''defined by the \ngovernment, and the penalties for crossing those lines are much harsher.''\nhttps://www.nytimes.com/2023/07/14/business/baidu-ernie-openai-chatgpt-chinese.html\nGraphic\n \nThis article appeared in print on page B1, B4.               \nLoad-Date: July 14, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Apr2023",
        "header": "Words to Screen with AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "April 3, 2023",
        "section": "TECHTONIC",
        "length": "434 words",
        "byline": "Aabhas Sharma",
        "story_text": "Words to Screen with AI\nEconomic Times (E-Paper Edition)\nApril 2, 2023 Sunday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECHTONIC\nLength: 434 words\nByline: Aabhas Sharma\nBody\nThe only thing dominating the headlines  when it comes to generative AI right now is  ChatGPT. Yet, there's a lot \nmore to generative AI than ChatGPT, such as language  models. Text-to-image is already becoming a part of \nmainstream conversations  but brewing in the background is generat ive  AI  cap able of converting  text  to videos . \nWHAT IS TEXT-TO-VIDEOS AI?\n Simply put, you can generate AI-powered  videos based on nothing but words. Key  in the text and the AI model \nwill generate a video based on it. US-based startup  Runway showcased its Gen-2  model, which can do that with  a \ncaveat or two. IS THIS A 'NEW' THING? Not really, as it is very much  like Dall-E — developed by  creators of \nChatGPT — and  works using generative AI  language models. The results  are captivating and it could  certainly \ncatch the fancy of  many across the world.  IS 'BIG TECH' NOT INVOLVED  IN TEXT-TO-VIDEO? They very much \nare. In September 2022,  Meta showcased a rather obviously named  tool Make-A-Video. With just a few words  or \nlines of text, Make-A-Video creates videos using generative AI but those videos  didn't have any sound.     Here's \nwhat Meta Inc CEO Mark  Zuckerberg had said about it: “It's much  harder to generate video than photos because \nbeyond correctly generating each  pixel, the system also has to predict how  they'll change over time.” Just a week \nlater  and on cue, Google announced a similar  model. Google's generative AI model is    called Imagen Video . \n“Given a  text  prompt ,  Imagen Video generates high-definition  videos using a base video generation model  and \na sequence of interleaved spatial and  temporal video super-resolution models,”  Google had said. Google also \nshowcased  another model called Phenaki, which is  aimed at creating long-form videos based  on text inputs.  \nWHAT ARE THE CHALLENGES WITH  TEXT-TO-VIDEO AI? From operational to ethical, the challenges are far \ntoo many. Perhaps that's one of  the reasons why only demos of generative  AI models working on text-to-videos \nhave  emerged. For starters, generating a video  with text might sound easy and fascinating but imagine making a \nvideo with just  words. One will have to be incredibly  precise with the commands or it could  generate the video \nequivalent of gibberish. There are also ethical challenges.  AI-generated videos could be the next  weapon in the \nmisinformation arsenal.  Deepfakes could become an even bigger  problem. Considering the fast-paced  \ndevelopments in the field of AI, it could  be a matter of time before text-to-videos  get out of exploration mode and \nbecome  mainstream.\nLoad-Date: April 3, 2023"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "Robots Are Pouring Drinks. Servers Are Striking.",
        "media": "The New York Times",
        "time": "October 29, 2023",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 1",
        "length": "1636 words",
        "byline": "By Emma Goldberg",
        "story_text": "Robots Are Pouring Drinks. Servers Are Striking.\nThe New York Times\nOctober 29, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 1\nLength: 1636 words\nByline: By Emma Goldberg\nBody\nOn a chilly Wednesday evening in October, the sounds filling Ambre Romero's home were familiar: her \ngrandchildren unloading the dishwasher, her husband, just off work, watching television. Ms. Romero was getting \nready for her shift serving cocktails at the MGM Grand Detroit, the casino where she has worked since 1999. She \npulled on her blue bustier top, said goodbye to her family and drove to a nearby gas station to pick up Red Bull and \nLucky 13 scratch-off tickets.\nMs. Romero, who has long reddish-brown hair and a wry smile, enjoys the predictability of her nights. Her shifts \nrevolve around the regulars, whose families, health problems and pet names she knows well. The work is \nunceasingly social, which is just how Ms. Romero likes it; she's a former dancer who turned to cocktail serving \nbecause it felt like performing. \n  But Ms. Romero, like so many millions of Americans, has seen her job remade in recent years by the arrival of \nnew technologies automating parts of her work.\n  When ChatGPT was released, about a year ago, public focus shifted to the knowledge economy jobs that artificial \nintelligence could transform, from law to copy writing. Goldman Sachs predicted that the equivalent of some 300 \nmillion full-time jobs could be automated with generative A.I., the technology that can create texts, images and \nsounds in response to prompts.\n  But long before generative A.I. products reached the market, tens of thousands of jobs in hospitality -- a field not \nknown for being a face of automation -- were already shifting under the pressures of robotic technologies: robots \nthat deliver room service, prepare salads and check in hotel guests. In the accommodations and food service \nindustry, 70 percent of workers could see more than half their work activities automated, including by artificial \nintelligence, according to a McKinsey estimate this year.\n  ''The new thing is the risk to white collar workers, but blue collar workers have faced this issue for a long time,'' \nsaid Darrell West, senior fellow at the Center for Technology Innovation at Brookings Institution.\n  Changes in the comfortably predictable rhythms of Ms. Romero's job began with the arrival of Smart Bar systems, \nor automated cocktail dispensers, in 2019, which came with what she described as a quick, surface-level training. \nShe found herself dealing with machines that malfunctioned by spraying liquid on the servers and often lacked the \nitems that customers had ordered. Ms. Romero spent more time tending to the machines and less time chatting \nwith customers, a change that she found reduced her tips by about 30 percent.\n  ''I don't know anyone who cares for the Smart Bar,'' said Ms. Romero, who makes just over $13 an hour. ''It \nincreases all of our responsibilities. We went from being just a server to a bartender and a bar server.''\nRobots Are Pouring Drinks. Servers Are Striking.\n  Upstairs, along the MGM Grand's hallways where housekeepers wheel their carts full of cleaning supplies, new \ntechnologies have also been remaking work. Since earlier this year, more housekeeping tasks have been facilitated \nthrough an app, called HotSOS, which assigns workers to rooms for cleaning and instructs them on the sequence in \nwhich to clean them. But the app sometimes malfunctions, assigning a worker to a room that still has a guest in it or \nlosing service entirely and leaving workers confused.\n  For housekeepers, this has been a vexing factor in their carefully choreographed routines. \n  ''You start to get crazy -- especially when you know you have certain rooms you have to get to,'' said Alicia \nWeaver, 60, a housekeeper who has been working at the MGM Grand since 1999, and makes $17.76 an hour. ''It \ngets frustrating when you have to stand in the hallway trying to figure out how to get into a room.''\n  When new technologies arrived, Ms. Weaver was told they were supposed to make her job easier. Instead there \nare moments when HotSOS freezes, has to be rebooted and then erases its records of the rooms she has cleaned.\n  MGM Grand executives declined to comment about their use of robotic technologies. Some casino workers said \nthat they had welcomed new forms of automation in their work because it eases their workloads. They don't oppose \nthe technology; they just want to be warned of its arrival, and see their criticisms taken into account.\n  ''I actually was a little bit excited about it,'' Denita Anderson, a housekeeper at the MGM Grand since last year, \nsaid about HotSOS. ''I thought it was convenient.''\n  A co-owner of Smart Bar's manufacturer argued that the technology helped workers prepare drinks faster, \nmeaning they could serve more customers and get more tips. ''Bartenders make more money by serving more \ndrinks,'' said Barry Fieldman, a managing member of Smart Bar USA. ''Guess who wins when that happens? The \nbartender makes more money and so does the house.''\n  ''You're not going to negotiate technology away,'' Mr. Fieldman added. ''You've got to find a way to train \nemployees, show them how the technology is going to help them make more money so they become less fearful of \nit.''\n  And Amadeus, the company that makes HotSOS, said its technology had helped workers transition away from \nstodgy systems in which room assignments were made on paper, and allowed housekeepers to do their work more \nquickly and safely.\n  ''This work flow reduces the need of having to move housekeeping carts around the property unnecessarily, \nensures scheduled breaks and provides the most efficient way to accomplish their daily tasks,'' said Alberto \nSantana, the company's senior vice president of sales, adding that the company's customer service team responds \nto all the feedback and complaints it receives.\n  On Oct. 17, Ms. Romero, Ms. Weaver and some 3,700 of their colleagues went on strike, after their contract \nexpired and as the unions representing them -- including UNITE HERE Local 24, United Automobile Workers Local \n7777, Teamsters Local 1038, Operating Engineers Local 324 and the Michigan Regional Council of Carpenters -- \ncontinue to negotiate for a new contract. Many issues at the heart of the talks are standard, including higher wages \nthat keep pace with rising costs of living, more stable schedules and more funds for health care.\n  But the technologies that hotels and casinos use are also part of the negotiation. Workers want to be a part of \nconversations about their implementation and use.\n  The union is demanding at least six months' notice when new workplace technologies are planned, the opportunity \nto negotiate over how the technologies are used, training on how to use them and severance packages when \nunionized workers are laid off because of new technologies. (About half of UNITE HERE's members across the \ncountry have already secured similar provisions.)\n  These provisions would apply to Smart Bar and HotSOS, but also many other technological products, including \nthose that workers say raise threats to safety. For instance, ordering technology, like tablets, sometimes allows \nRobots Are Pouring Drinks. Servers Are Striking.\nminors to order drinks and leaves it to the servers to decide whether to hand the cocktails over, which could agitate \nthe customers.\n  ''You're used to doing your job in a certain way for many years, and then they come one day and say, 'Well, we're \ngoing to change that,''' Ms. Weaver said. ''If you're going to roll something out, everybody should have a good \nunderstanding of how it works.''\n  Detroit has long been a union town. Ms. Romero's father was a foreman at Chrysler and a shop steward for the \nunion. Ms. Weaver's parents were also involved with their factory unions; her most vivid childhood memories are of \nthe carnivals organized by the U.A.W., where she rode roller coasters and snacked on cotton candy and buttermilk \npotato chips.\n  The historians Marvin Surkin and Dan Georgakas, in their book ''Detroit: I Do Mind Dying,'' chronicle the arrival of \nnew forms of automation at Detroit's car factories in the 1970s -- which made the work faster, but also degraded \nworking conditions.\n  ''With fewer workers and fewer work hours, they were trying to get more production down the assembly line,'' Mr. \nSurkin said. ''That has an effect on morale, on work-life balance.''\n  And as for the casino workers today, ''it's the same old story,'' Mr. Surkin said, adding that he's not surprised the \ncity's hospitality union workers are fighting the negative effects of automation: ''In Detroit, they have generational \nmemory.''\n  In hospitality, the effects of new technologies have been subtler. Often they're being used for partial automation, \nmeaning jobs are changed but not eliminated.\n  In early October, Ms. Romero stopped at the Teamsters hall, right near the MGM Grand, to greet union staff \nmembers and volunteers who were assembled to prepare for a potential strike. She walked into the hall trailed by \nher grandson, who was kicking a ball.\n  ''Y'all coming to pick up your strike money?'' a union staff member asked. Another pointed to Ms. Romero's \ngrandson, asking, ''So this is the boss?''\n  Inside the fluorescently lit space, volunteers stapled cardboard sticks to posters with large images of dice, which \nread, ''Don't gamble with our future.''\n  The workers like to remind their employers, and one another, all that they've invested in their jobs. Ms. Weaver got \ncarpal tunnel syndrome from tucking sheets under beds, back pains from lifting mattresses and swollen legs from \nbeing on her feet all day.\n  Ms. Romero, meanwhile, gets irritated when she gets an order for a drink that the Smart Bar doesn't have, and \nthen runs across the casino trying to find a bartender who will serve it. By the time she gets back to the customers, \nthey may have left, meaning her time was wasted.\n  ''Because of the difficulties that we run into with the Smart Bars, I'm constantly rushing,'' she said. ''I still enjoy my \njob -- it's just a lot harder now.''\nhttps://www.nytimes.com/2023/10/27/business/automation-casino-employees-detroit.html\nGraphic\n \nRobots Are Pouring Drinks. Servers Are Striking.\nPHOTOS: Above, Ambre Romero at the MGM Grand Casino in downtown Detroit. Ms. Romero, who estimated her \ntips have been reduced by about 30 percent since a change to automation, said, ''I don't know anyone who cares \nfor the Smart Bar.'' (PHOTOGRAPH BY NICK HAGEN FOR THE NEW YORK TIMES) (BU4-BU5)\nFrom top: Alicia Weaver, an MGM Grand housekeeper who went on strike with the rest of her union in October\na Smart Bar dispenser and liquor supply for its dispensing heads\nworkers on strike in Detroit, where there is ''generational memory'' of the negative impact of automation\nand servers in the MGM Grand Detroit have added responsibility since the addition of a robotic system. \n(PHOTOGRAPHS BY NICK HAGEN FOR THE NEW YORK TIMES\nSMART BAR USA\n PAUL SANCYA/ASSOCIATED PRESS) (BU5) This article appeared in print on page BU1, BU4, BU5.               \nLoad-Date: October 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Wednesday Briefing: Aid Workers Killed in Gaza",
        "media": "The New York Times",
        "time": "April 2, 2024",
        "section": "WORLD; asia",
        "length": "1063 words",
        "byline": "Amelia Nierenberg Amelia Nierenberg writes the Asia Pacific Morning Briefing, a global newsletter.",
        "story_text": "Wednesday Briefing: Aid Workers Killed in Gaza\nThe New York Times \nApril 2, 2024 Tuesday 17:07 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: WORLD; asia\nLength: 1063 words\nByline: Amelia Nierenberg Amelia Nierenberg writes the Asia Pacific Morning Briefing, a global newsletter.\nHighlight: Plus, President Biden talked to Xi Jinping.\nBody\nPlus, President Biden talked to Xi Jinping.\nAid workers killed in Gaza\nIsraeli strikes on an aid convoy run by the charity group World Central Kitchen killed seven of its workers in the \nGaza Strip. Prime Minister Benjamin Netanyahu apologized, and said Israel “deeply regrets” the strike. He called it \n“a tragic case of our forces unintentionally hitting innocent people.”\nThe workers were traveling in clearly marked vehicles, and World Central Kitchen said it had coordinated its \nmovements with Israel’s military. Israel is investigating the circumstances surrounding the strikes.\nThe war has been exceptionally dangerous for aid workers — at least 196 have been killed since the war began, \naccording to the U.N. World Central Kitchen, which has become an important player in delivering supplies to an \nenclave on the edge of famine, has suspended its operations in Gaza. So has another aid agency, American Near \nEast Refugee Aid.\nWhat we know: The aid workers killed included a Palestinian, an Australian, a Pole, three Britons and a dual U.S.-\nCanadian citizen. The convoy of three vehicles had just left a food warehouse. Videos and photos verified by The \nTimes suggest it was hit multiple times.\nOther updates:\n• Damascus strike: Israel’s bombing of an Iranian Embassy building in Syria was a major escalation of its \nshadow war with Iran, our chief diplomatic correspondent writes.\n• Al-Shifa: Israel granted our Jerusalem bureau chief a rare visit to the major Gazan hospital.\n• The U.S.: Donald Trump’s call for Israel to “finish up” the war, without insisting on freeing hostages first, has \nalarmed some Republicans and Israelis.\nIn a rare call, Biden spoke with Xi\nPresident Biden had a rare telephone conversation with Xi Jinping, China’s leader, yesterday that was aimed at \naddressing a variety of issues, both combative and cooperative, and steady a relationship that hit a multi-decade \nlow last year.\nThe topics raised by Biden included fighting narcotics production, the Middle East conflict, North Korea’s nuclear \nprogram and China’s support of Russia during the Ukraine war, according to a summary provided of the call. He \nalso raised concerns over Beijing’s aggression involving Taiwan and the South China Sea.\nWednesday Briefing: Aid Workers Killed in Gaza\nChina said that Xi had called for “concrete actions” to demonstrate a U.S. commitment not to support Taiwan’s \nindependence. Xi also criticized the “endless stream of measures” taken by the U.S. to try to suppress China’s \neconomy, science and technology, China said.\nContext: Biden and Xi have both sought to prevent any public eruptions. Biden wants to focus on his re-election \ncampaign, while Xi faces a troubled economy and corruption in the top ranks of his military.\nWhat’s next: Janet Yellen, the U.S. treasury secretary, is heading to China this week for economic talks. Antony \nBlinken, the U.S. secretary of state, will follow soon afterward.\nDrones struck deep inside Russia\nExploding drones hit an oil refinery and munitions factory far to the east of Moscow yesterday. Ukrainian media and \nmilitary experts said the attack was among the longest-range strikes with Ukrainian drones so far in the war.\nThe drones struck in the Tatarstan region, about 700 miles (over 1,100 kilometers) from Ukrainian-held territory. \nUkraine’s campaign of strikes against Russian refineries since last October has shrunk Russia’s refining capacity, \nand has recently forced Moscow to enact a six-month ban on gasoline exports.\nWeapons: Ukraine is increasing its arms production. It may not be moving fast enough.\nMORE TOP NEWS\n• Turkey: A fire at a popular nightclub in Istanbul killed at least 29 people, the governor’s office said.\n• Donald Trump: The former president averted a financial disaster, reaching a deal that will spare him from \npaying a $454 million judgment while he appeals the penalty.\n• North Korea: The country launched an intermediate-range ballistic missile, a sign that it is trying to develop \nmissiles that could hit U.S. military bases in the Pacific.\n• Finland: A young boy fatally shot a 12-year-old and wounded two others at a school yesterday, the police said. \n• Senegal: The new president, who at 44 is the youngest elected in Africa, used his inauguration speech to \npromise his supporters “systemic change.”\n• Medicine: A new device that keeps an organ alive outside the body could increase the number of transplants \npossible.\n• Tesla: It may be losing command of the electric vehicle market after reporting a steep drop in quarterly sales.\nMORNING READ\nChinese consumers spend big for swiftlet nests. (They’re a key ingredient in bird’s nest soup, a delicacy that many \nbelieve has health benefits.) Some in Indonesia are cashing in on the interest, competing to build luxurious \naccommodations to attract their picky, winged guests.\nCONVERSATION STARTERS\n• Japan: The royal family is now on Instagram. Their feed is pretty staid.\n• Overcoming fear: British Airways runs a course for nervous fliers.\n• Rome: Italy’s capital plans to turn much of the city’s center into a pedestrian-friendly archaeological walk.\nARTS AND IDEAS\nIs A.I. increasing productivity?\nMany big companies have adopted generative A.I. to deal with annoying tasks, beef up their marketing pushes or \nmatch prices to demand. And enthusiastic tech investors have added trillions in market value to a few firms.\nWednesday Briefing: Aid Workers Killed in Gaza\nBut the research on A.I. and efficiency is still shaky. Many economists and officials seem dubious that A.I. has \nspread enough to show up in productivity data already. Others, like the M.I.T. labor economist David Autor, say it \ncould potentially increase the size of the middle class by allowing workers to perform some tasks that currently \nrequire highly skilled experts.\nRECOMMENDATIONS\nCook: Add turmeric to this creamy pasta.\nRead: Neel Mukherjee’s “Choice” is a novel full of characters deciding how much truth to tell.\nEat: Planning a trip to New York? Here’s our ranking of the 100 best restaurants.\nGive: Take a look at these presents for frequent travelers.\nPlay Spelling Bee, the Mini Crossword, Wordle and Sudoku. Find all our games here.\nThat’s it for today. See you tomorrow. — Amelia\nP.S. Spelling Bee enthusiasts explained why they wake up in the middle of the night to write hints.\nEmail us at briefing@nytimes.com.\nPHOTO: The aid workers were traveling in armored vehicles clearly marked with the World Central Kitchen logo. \n(PHOTOGRAPH BY Ismael Abu Dayyah/Associated Press FOR THE NEW YORK TIMES)\nLoad-Date: April 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Transcript: Ezra Klein Interviews Alondra Nelson; The Ezra Klein Show",
        "media": "The New York Times",
        "time": "April 11, 2023",
        "section": "PODCASTS",
        "length": "11710 words",
        "byline": " ",
        "story_text": "Transcript: Ezra Klein Interviews Alondra Nelson; The Ezra Klein Show\nThe New York Times \nApril 11, 2023 Tuesday 16:56 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 11710 words\nHighlight: The April 11, 2023, episode of “The Ezra Klein Show.”\nBody\nEvery Tuesday and Friday, Ezra Klein invites you into a conversation about something that matters, like today’s \nepisode with Alondra Nelson. Listen wherever you get your podcasts.\nTranscripts of our episodes are made available as soon as possible. They are not fully edited for grammar or \nspelling.\n[MUSIC PLAYING]\nEZRA KLEIN: I’m Ezra Klein. This is “The Ezra Klein Show.”\n[MUSIC PLAYING]\nIt would be easy, listening to the discourse about A.I., to think the government has taken no notice of this \ntechnology at all, that there’s something happening out here in Silicon Valley and Washington is completely asleep \nat the switch. It’s not quite true, though.\nIn 2022, the White House released a more than 70-page document called “A Blueprint for an A.I. Bill of Rights.” And \nthe word “blueprint” there, that is a much more important word in that title than “rights.” This document is not, for the \nmost part, enforceable at all. These are not rights you can sue to protect.\nBut its release, its creation was a recognition that at some point soon the government probably would need to think \nabout creating something enforceable. And so they needed to start thinking about how society thick with A.I. should \nlook.\nWhat’s striking, reading the blueprint, is that if it wasn’t a blueprint, if it actually was enforceable, it would utterly \ntransform how A.I. has to work and look and function. Not one of the major systems today is even close to \nconforming to these rules. It’s not even clear that if they wanted to, they technically could.\nAnd that’s what makes this a weird document. Is it a radical piece of work because of what it would demand if \nimplemented? Is it useless because it doesn’t really back up its words with power? What is it, and what does it point \ntowards?\nThe process behind it was led by Alondra Nelson, who was a scholar of science and technology, who became a \ndeputy director and then acting director of the Biden Administration’s Office of Science and Technology Policy. So \nto the extent anybody in government has thought about A.I. hard and tried to make the sprawling entity that is a \nfederal government develop some kind of consensus opinion on it, it’s Nelson.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nNelson is now out of the administration. She’s a distinguished senior fellow at the Center for American Progress. \nAnd so I asked her to come on the show to talk about what the blueprint did, how she thought about it, what it \ndoesn’t do, and how she’s thinking about A.I. now. As always, my email — ezrakleinshow@nytimes.com\n[MUSIC PLAYING]\nAlondra Nelson, welcome to the show.\nALONDRA NELSON: Thank you so much, Ezra.\nEZRA KLEIN: So I want to start with how you and how the government you are acting on behalf thinks about A.I. \nitself. From the perspective of the government or the public, what is the problem or challenge we’re trying to \naddress?\nALONDRA NELSON: So I would say, first of all, that I’m no longer acting on behalf of the government, so this is a \nlittle bit of a retrospective. The office that I worked in is the White House Office of Science and Technology Policy.\nIts founding statute from the ’70s says something like, to spur innovation and also to mitigate foreseeable harm. \nAnd I think that now 50-year-old statute I think in some ways, at a high level, sums up I think what folks are trying to \ndo with science and technology policy and government and how government thinks about it.\nIt’s also the case that government, and I think particularly the Biden-Harris administration, appreciates that science \nand technology are supposed to do good things for people in their lives. And so that innovation should have a kind \nof mission and a kind of value-based purpose and that should be for the improvement of people’s lives. And I think \nthat’s distinctive about how government in this moment is also thinking about these issues.\nEZRA KLEIN: So I want to zone in on that idea of foreseeable harm because I think there are — I mean, there are \nmany, but in this case two schools of thinking about A.I. One is that it has a lot of foreseeable harms. It could be \nbiased. It could be opaque. It could be wrong.\nAnd then there’s another which is it has a — this is a sui generis technology. We haven’t really dealt with anything \nlike it. The harms are unforeseeable. The technologies, the systems are uninterpretable.\nAnd so we’re in this place of known unknowns and unknown unknowns. It makes regulation very hard. Which \nschool are you part of there?\nALONDRA NELSON: I’m in neither school, actually. I think I am enough of a scholar and a researcher to want more \ninformation, to think that this is, in some ways, an empirical question, a question that we can have more information \nabout before we feel like we have to, I think, plant a flag in either of those camps.\nI would also say it’s likely the case that it’s probably both those things. I mean, there are always harms that we can’t \nforesee or that we can’t anticipate, use cases that we might have thought about but didn’t consider quite in the right \nway.\nSo I think across that spectrum, depending on the use case, that there are harms that we can anticipate, there are \nharms we are currently living with. Obviously things the ways in which facial recognition technologies have actively \nharmed Black and brown communities already. And we have — that’s been going on for several years. And then \nthere are these other kind of broader risks.\nI would say, on the latter, we already are living in a time of profound uncertainty with looming risk. And so I’d also \nwant to put the both known and unknown risks that we’re thinking about now in the context of the fact that our lived \nexperience now is that. So I’m thinking of the fact that we’ve lived for six decades-plus with the potential of \ncatastrophic nuclear harm. So that is just something that we live with in the day-to-day.\nAnd I’m thinking, of course, of the potential of the existential harm and crisis and catastrophic risk of climate \nchange. And so we live in a world that we’re surrounded by risk. And to have a new vector for risk — it may be new, \nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nbut I think the conundrum of having to tackle big and large and often unknown situations is not new to human \nsociety.\nEZRA KLEIN: I appreciate those comparisons, and one thing I appreciate about them is that they are comparisons. \nAnd I think the human mind often works and the regulator mind, the policymaker mind often works explicitly and \nmore worryingly implicitly through analogy. So I’m curious what analogies you have used or heard in this area and \nproject and what you find convincing.\nALONDRA NELSON: I think the climate change and the nuclear harm are the ones that come immediately to mind. \nI would say the automated technologies, A.I., use the phrase, I think, sui generis. I’m not sure that it’s quite that. I \nthink that there are analogies. I think there’s a kind of quilt of analogy that we could put together to help us think \nabout this, not only just the looming potential harm but also possible solutions, and that’s much more what I’m \ninterested in.\nSo certainly in the nuclear space, you have, for a couple of generations now, activities around nonproliferation. So \nwe know potentially that this thing, these things, these tools could destroy the world. And we are going to work \ncollectively, we’re going to work across sectors and globally in an imperfect way to try to mitigate that damage. And \nmoreover, we have already seen the damage that these tools unleashed can do, to the fatal damage that these \ntools can have.\nSo certainly in the national security space with A.I., there’s a piece of it that’s very much, I think, akin to the potential \nrisks and also a potential strategy or an intervention that comes out of the nuclear nonproliferation space.\nThere is also, in the climate space, I think, the uncertainty of, for example, weather patterns as weather gets more \nunpredictable, becomes more radical. We might also think of about a third analogy here, which would be the \npandemic that we’re still in some degree living in.\nAnd so I think that there’s just a profound uncertainty to life right now, and that this is one of them. And it has some \npieces of uncertainties that we’re familiar with. However, it’s also the case that automated technologies are quite \nliterally made by us. And while they can have generative velocity, it’s not the case that they necessarily have to be \nunleashed and unknown to us. That’s a choice.\nAnd I think one of the things that I hope that we can do coming out of this moment of ChatGPT and the like, \nimmense possibilities of what automated technologies can bring to the world, both good and bad, is to really think \nabout the choice architecture that’s being presented to us or that we’re accepting around what might be possible.\nEZRA KLEIN: One thing I notice in those analogies is those are primarily analogies of risk and catastrophe. \n[LAUGHS]\nSo Covid — I don’t want to take an overly strong position here, but I’m against it. I’ve been a critic of Covid since \nthe beginning.\nNuclear risk — a problem but also something where a lot of people feel we staunched the capacity of the \ntechnology for good because we were so worried about the risk of nuclear proliferation. That we could have much \nmore affordable and abundant nuclear energy today if we hadn’t been so afraid of the downsides. And of course, \nclimate change, again, I’m going to take a strong position here that I’m against it.\nHow do you think about these analogies inter — because one of the debates in the policy space is you don’t want to \nstaunch technology that can offer great good, potentially — more economic growth, more scientific discovery, more \ncreativity, more empowerment. How do you think about the positive side of the analogies or the concern that the \nanalogies you’re offering are too weighted towards the negative?\nALONDRA NELSON: I think that nuclear is actually a quite good example. So fusion energy has been a promise. \nThere is a possibility of having inexhaustible green energy if we’re able to harness fusion energy and fusion \nresearch and development. That, effectively, is a form of nuclear energy, and that’s extremely exciting.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nWe’ll have to do lots of things along the way. We’ll have to not only just get the science right, which is still lots of \nwork to do there. But where would you site the facilities? And how do you engage communities around the work, \ninform communities that we are moving into a space in which we were going to have this tremendous opportunity, \nbut they’re also — that they have to learn to think about nuclear energy and nuclear power in different ways.\nSo all of these, I think, innovations come with both wanting to advance the innovation but having real limitations. \nAnd A.I. is one of these. So there’s great potential in science and health.\nSo when you’re thinking about working for President Biden, who wants to reduce cancer death rates by 50 percent \nover the next 25 years, you’re looking really closely at cancer screening, at radiology and imaging. There’s clear \nbenefits there. There’s clear opportunity there to save lives. So that’s an incredibly positive application.\nThere’s also been incredible work at NASA around using A.I. So folks might be familiar with the recent DART \nmission that was able to shift the trajectory of an asteroid that might have been plummeting towards Earth. Artificial \nintelligence for years has been, and remains, really central to that work, to thinking about how you model asteroids, \ntheir shape, their speed, their velocity, how fast they’re spinning.\nSo the very future of planetary defense, and indeed perhaps the very future of our planet, depends on that kind of \nresearch and the ability to use that artificial intelligence in that research space to help create action and \nintervention. So there are all sorts of cutting edge uses for modeling and prediction and more in that science space \nas well. There’s lots to commend about automated technologies.\nEZRA KLEIN: One distinction, I think, in the question of automated technologies that comes up in some examples \nyou just offered is the difference between these specific machine learning algorithms and functions that we’ve \nalready been using — can imagine using much more, right? We’re building a system to figure out protein folding. \nWe’re building a system to predict the trajectory and shape of an asteroid or to better read radiology reports.\nAnd then the development of these general systems, the race to develop what people call artificial general \nintelligence, but whether or not you even believe we’ll get there, to develop these systems that are learning off of a \nhuge corpus of data, are building for themselves correlations and models of how to put all that data together and \nare developing capacities that are unexpected and generalizable and not within the system itself oriented any one \ndirection. Particularly when you’re building things that are meant to interact with human beings in a general way, \nyou’re creating something that has to be highly generalized and it also fools people into thinking it’s more — well, \npotentially fools people at least — into thinking it’s more of an agent of a kind of autonomous intelligence, and \nmaybe it is.\nHow do you think about the difference between those more precise automated predictive algorithms and this large \nlearning network equilibrium that seems to increasingly be dominating?\nALONDRA NELSON: So I would pick out of what you just said, which I think is a nice presentation of the time that \nwe’re in — the phrase that you used was interact with human beings. And I think that for me is the central \ndifference. So to the extent that we are building systems that interact with human beings, I think that we need to \nhave a different value proposition for how we think about this work.\nSo if we’re dealing with work that’s about people’s opportunities, their access to services and resources, their health \ncare, these are things where I think government, industry, academia need to think in different ways about the tools. \nAnd so let’s be clear, I mean the tools might — if we think about large-scale generative A.I. systems as being — \nmy friend Suresh Venkatasubramanian often calls them algorithms of algorithms, like at scale and velocity.\nIn the space of NASA and asteroids, the stakes for human beings and for interaction with human beings are \ndifferent. And so I think what I would want us to anchor on and think about are those spaces. And that if we can \nbuild great things, it can’t just be the case that we can say it’s OK that we can lose control of them, particularly \nwhen it has something to do with people’s lives.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nEZRA KLEIN: I think it’s a good bridge to the blueprint “A.I. Bill of Rights.” So tell me a bit about the genesis of this \ndocument. For those who haven’t read it, it’s more than 70 pages. It comes out in October of 2022. So the \ngovernment has been thinking about a regulatory framework here. What was that process?\nALONDRA NELSON: So that was a process to create a framework and a resource for thinking about how we might \nput guardrails around automated systems and automated technology. So we’re able, going back to that founding \nmandate of some government science and technology policy to both move forward with the innovation as quickly as \nwe can, but also to mitigate harms as best we can.\nSo the A.I. Bill of Rights lays out a kind of affirmative vision. And it won’t surprise anybody listening here what these \nthings are. And I guess to tie back to where we started in the conversation, that if we anchor our values in the best \noutcomes for human beings, and if we anchor our policies and the value proposition about what technologies are \nsupposed to do and mean in the world for the people that use them, that whether or not we’re talking about A.I. that \nwe might have used four years ago or A.I. that will be released in four months, that these assertions should still be \ntrue.\nSystems should be safe. You should have privacy around your data. Algorithms shouldn’t be used to discriminate \nagainst you. So that was the process. And I’d say that there are two — and this is, I think, really important for the \ngenerative A.I. conversation as well — two areas to be thinking about guardrails before deployment when you can \ndo risk assessment, you can use red teaming. For example, you can have public consultation, which is what we \ncertainly tried to do.\nEZRA KLEIN: Can you say quickly what red teaming is for people who are not familiar?\nALONDRA NELSON: Sure. Yeah, so red teaming is you send your tool to colleagues or your system and you just \nhave them beat it up. You have them stress test it. You have them approach it in ways that are adversarial. You try \nto get them to try to break it. You try to get them to use it at its best and at its worst, to anticipate ways that it’s not \nsupposed to be used at all to try to figure out how it might break for an effect. And then to take those insights into \nimproving the tool or the system.\nSo the second area would be just after deployment. So you can have ongoing risk assessment. You can try to \nmonitor tools in ongoing ways. And so to your initial question to the work of what government can do, it can really \noffer an affirmative vision of how the work of doing science and technology, of making automated systems of \ngenerative A.I., needs to be ongoing work that never stops and can model that. And the National Institute for \nStandards and Technology developed a risk assessment framework that I think is another way in which government \nis trying to do this.\nEZRA KLEIN: So this is framed as a draft bill of rights when the power of the Bill of Rights, as it exists and what the \nmetaphor refers to, is if my rights are violated, I can sue. What is the power force of this document?\nALONDRA NELSON: I think a few things. I mean, one is to go back to that original founding document of the United \nStates, which is the Bill of Rights, as you said, and to say that there are things that remain true over time. And that’s \nhow — we look back to the Bill of Rights, it’s not perfect, it’s had amendments, our interpretations of it will change \nover time as society has changed.\nBut there are fundamental things that should be true about American society. And so while these are not laws, it’s a \nvision, it’s a framework about how laws that we have on the books might be enforced, about how existing rule-\nmaking authorities might be used. And so it’s meant to both remind us that there are laws that endure and also to \nsuggest some ways that laws, policy, norms that we already have might be moved into the space of new \ntechnologies.\nAnd I think there’s a broader philosophy here that’s important. Technology moves incredibly fast as we’ve \nexperienced acutely over the last couple of months. But we don’t need to stop everything and reinvent everything \nevery time we have a new technology.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nSo that the social compact doesn’t change when new technologies emerge. And that we can pivot back to \nfoundational principles and that those can be embodied in tech policy and in the work of technological development \nand specific practices like algorithmic risk assessments, like auditing, like red teaming and the like.\nEZRA KLEIN: But I want to get at the status of what this document is a little bit more deeply, because one of the \nthings that is — and we’re going to go into it in some detail here in its details — but I could imagine this document \ncoming out as a legislative proposal from the administration.\nYou mentioned that there are laws on the books we could use, that there’s regulations on the books we can use. It’s \nall absolutely true. But to instantiate this as a bill of rights would require quite dramatic new legislation. We would be \nsaying, you cannot publish, create, in many cases, train algorithms that don’t conform to the standards we’re setting \nout or don’t have the process that we are insisting on.\nAnd it didn’t come out as that. This came out as a framework for discussion, something that companies could adopt \nvoluntarily. Is your view — is what you’re saying here on the show or in general, Congress should take this up and \nmake it the law, that it should be something you can sue a company if they don’t follow, or this is something that is a \ngood thing for companies to keep in mind as they build their models?\nHow does this move not to vision but to force, to control, to — again, the Bill of Rights is powerful not because it’s a \nvision, but because I could sue you if you violate it. Should I be able to Sue OpenAI if GPT-5 doesn’t conform?\nALONDRA NELSON: So the audience for the document is, just like the participants that led to its creation, is \nmultifaceted. So in the first instance, certainly I would say if I was still working in government, the president has \ncalled on Congress to act in these spaces, to protect people’s privacy, to move in the space of competition and \nantitrust. And so there are lots of interesting draft legislation around enforcing algorithmic impact assessments, \naround prohibiting algorithmic discrimination, and doing so in ways that continue to make sure that innovation is \nrobust.\nSo sure there is a piece here that is for legislators. But there’s also a piece here that’s for developers. And a lot of, \nas I said, what this document attempts to do is to distill best practices, best use cases that we learned from and \ndiscussed with people, developers, with business leaders, with people working in industry.\nIt’s also the case that it’s for the general public. So it endeavors to make something that I think is often abstract for \npeople, a lot more — to bring it down on the ground, to have use cases, including showing folks where there are \nexisting authorities or existing ways that we might think about it.\nAnd to go back, I think what I was saying about the broader philosophy is that — and also to go back to the \nbeginning of our conversation is not only do we live in a world of growing risk in some regard, one might say, but we \nalso live in a world in which there’s going to be increasingly more and different and new technologies.\nI mean, we think about critical and emerging technologies in the policy space and in government. In fact, because \ninnovation is so rich and the innovation cycles are so rich, that means, I think, Ezra, a different way of having to \nthink about the role of government and the role of policymaking. And it means that it is not to create a new law \nevery time there’s a new technology. It is to say, these are the foundational principles and practices, even as the \ntechnologies change.\nWe cannot — we don’t have the capacity to create a whole new way of living, of American society — or government \ndoesn’t have a whole new way of imagining American society every time there’s an new technology. But what we \ncan do is continue, as technologies move fast, to anchor in fundamental values and principles.\nEZRA KLEIN: I’m going to be honest, I don’t think that really answers the question really raised by the document, \nnot just by me. So the document has a number of, I think, really profound ideas about legibility. To quote it, it says, \n“You should know that an automated system is being used and understand how and why it contributes to outcomes \nthat impact you.”\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nRight now I would say — and I think this is the consensus view — that even the developers do not understand how \nand why these systems are often coming to the views they are. So for it to conform to I think the plain language \nreading of this, we would be saying you have to stop and make these systems interpretable in a way they’re \ncurrently not interpretable. And if we don’t tell them to do that, then this is not a right at all.\nSo I guess one question is, am I reading that section right? But another is to rephrase that first question, which is \nshould that be a law? Do you, Alondra Nelson, think this should be something Congress says, these developers, \nyou have to do this now or you can’t release these systems because they’re not safe, or is this just something they \nshould do their best on and try to take into account?\nALONDRA NELSON: All right, so let’s see if we can align by thinking about a more specific use case. So let’s think \nabout the space of employment and of hiring practices. Let’s think about a particular authority — the Equal \nEmployment Opportunity Commission. Their authority is to enforce civil rights around hiring practices and around \nemployment decisions.\nSo that doesn’t change when algorithmic tools are used. And it is not the case that developers of algorithmic \nsystems cannot tell us how those systems make decisions. So I want to separate out the speculative cases of tools \nthat have a trillion parameters or variables and we can’t possibly know.\nAnd I also — we should come back to that because I don’t believe that to be true — from cases in which vendors \nare creating algorithms that companies are using to make decisions around employment, we can know how that \nalgorithm was created. And we should be able to — if someone has a claim around discrimination in the space of \nemployment — tell them what algorithm was used. And to the extent that it’s not a trade secret or other proprietary \ninformation, give them insight as you would in any other process used for an employment decision about that.\nEZRA KLEIN: I think in a way I’m not convinced we should separate out the more narrow and more broad systems. \nAs they’re building these trillion parameter more generalized systems and trying to now offer plug-ins for them to be \nin a million different uses, and we know this is coming. We know they’re going to have trading algorithms that are \nusing these systems. And we can expect these are going to be brought into business strategy and into decision \nmaking and so on.\nIf the public, I think, doesn’t decide we are going to enforce a legibility rule, we are going to say that you need to be \nable to tell us how this ended up making the decision it did, not just say, hey, it’s a predictive machine that we train \non this corpus of data and it spit out this prediction. But no, we want to know why it did what it did.\nI mean, these companies are going to have to build them differently. I talk to these people all the time. They don’t \nknow why they’re getting the answers they’re getting.\nSo I think one question I have, whether within this bill or just within your view of the systems, should Congress, \nshould the public say, hey, until you can make these legible, you can’t keep building bigger ones and rolling them \nout? We believe, for them to be safe and to protect our rights, we need interpretability beyond what you have \nactually built into it or figured out how to build into it.\nAnd we are just going to put that down in the same way — there’s a great analogy, I think, in the draft bill of rights \nhere to cars and the amount of not just regulations you put on how cars are built, but that putting those regulations \ndown, you guys point out has actually increased innovation in the auto manufacturing space quite a bit.\nBut to do that, we made it so you have to do it. You have to have higher fuel standards, et cetera. Should they have \nto have interpretability up to a higher point? And if so, what is that point?\nALONDRA NELSON: The point is when it’s intersecting with human beings and people’s opportunities, their access \nto resources and the like. So if someone is building A.G.I. in the laboratory or in a laboratory setting, there doesn’t \nneed to be legibility. Where the legibility needs to come, and where Congress can act, and where rule makers and \nlawmakers can act is in the space of domains in which we say certain things cannot be done around human society.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nSo the legibility rule really applies to specific use cases. So car safety is an example. For example, the employment \ncase that we talked about, housing discrimination, access to housing, health care, access to health care resources, \nand to health care services.\nSo let me revisit, because I take your point. It’s not that we want to separate the narrow and the generative. We \nwant to separate the use cases that affect people’s lived experiences from the ones that I think don’t. And right now \na lot of the generative A.I., in addition to the consumer platform that we’re using, is still in the space of being \ntransitioned into different tools.\nAnd as it gets transitioned into different tools, that generative A.I. use in an employment tool is going to have to \nabide by labor law and civil rights law with regards to employment. And so it is the case, exactly as you were \nsaying, that developers are going to have to figure out if they’re going to want to use these tools how to abide those \nlaws.\nEZRA KLEIN: So one thing you might hear from somebody more optimistic or sanguine about A.I. is that a pretty \nhigh level of opacity, of illegibility in the system is a price we pay for them to actually work. So I think a good \ncanonical example of this is you can feed some of these systems retinal information.\nThey can basically look at eyes. And we don’t really understand why they are able to do this and detect gender from \nlooking at retinas, but they seem to be able to do that. And the system can’t seem to tell us, we cannot figure out \nwhat it is picking up on that is letting it do something we didn’t think you could do, which is predict gender from \nretina.\nAnd you might say, OK, who cares about that. But then when you talk about, say, screening patients for certain \nkinds of cancers, and health care is probably a place where you are going to have fairly high levels of regulation, \nthat when you’re doing cancer screening, what matters is that the system is as accurate as possible, not that it is \nable to explain its reasoning. And in fact, if you slow these systems down to try to get them to explain their \nreasoning, well, then maybe you’re not rolling out these detection systems and people are dying because the public \nsector is making everything move too slowly.\nHow do you think about that kind of trade-off?\nALONDRA NELSON: I actually don’t disagree with those use cases. And I don’t think that necessarily need the kind \nof legibility that we have been talking about in that space. Where you would need it — and let’s pull the thread on \nthe retina case — is if it was used for screening for travel and someone was told that they could not travel and you \ncouldn’t tell them why they couldn’t travel. And the person was a citizen and had all these kinds of other protections, \nso I’m not talking about a known bad actor here. But if somebody’ right to travel was being constrained by the use \nof a retina tool, and they couldn’t tell you why or they couldn’t actually confirm that it was accurate, there should be \na legibility rule there. There should be something that law should be able to say about that person’s rights. That \nperson should be able to invoke rights to know why their rights are being constrained.\nAnd that’s different from doing large scale medical testing and which we are looking at retinal scans to tell us \nsomething in the research space or more generally that retinas tell us something about a social variable. It’s when \nthose things become use cases that law and government and governance really come to bear in a particular way.\n[MUSIC PLAYING]\nEZRA KLEIN: So the first line of the first principle, which is safe and effective systems in the Bill of Rights, is, \n“Automated systems should be developed with consultation from diverse communities, stakeholders, and domain \nexperts to identify concerns, risks and potential impacts of the system.”\nAnd I think this question of consultation — and I mean, even OpenAI at this point has released a policy or a vision \ndocument saying, “We believe there needs to be open public consultation on how these systems are built.” But \nthere is no standard. And I wouldn’t say one is outlined here in the bill — or, not the bill, the framework — for what \nthat would look like.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nSo tell me a bit about your thinking about input. How do you get enough consultation? How do you make sure that \nconsultation is sufficiently representative? And what does it mean for that consultation to be followed? What does it \nmean for this not to be just democracy washing, where Google holds a couple of town halls and says, see, we got \nthe public’s input, even if we didn’t follow it? How do you actually ensure that this consultation is meaningful?\nALONDRA NELSON: That’s the great question. I think that the particular challenge that we face with A.I. \ntechnologies, in particular, but I think any space that intersects with policy and expertise is that it becomes \nincreasingly abstract, and, I think, unfortunately, abstracted from democratic processes.\nAnd so what the “Blueprint for an A.I. Bill of Rights” was trying to do, in part, was to grow the democratic \nconstituency around the issue. And you mentioned the OpenAI case and that they had done some consultation and \ncalled for more. I think that we can see already, with the rollout of some chat bots and some of the generative A.I. \ntools, ways that a little bit more engagement might have changed, I think, where we are.\nSo I think this is a moment of profound political opportunity and opportunity for democracy, in part because these \ntools are becoming consumer-facing. And so we went from, as a policymaker, trying to explain to people what \nautomated technologies are and what the implications might be for five years from now and 10 years from now was \nsometimes quite challenging.\nBut because these became consumer-facing tools, everyone, almost immediately — the 100 million users that we \nknow have engaged and using ChatGPT have something to say about these technologies. And I think even though \nwe could have hoped for a rollout that was not let’s just put things out in the wild and see what happens, that was a \nlot more consultative, it is tremendously important that people who are not experts understand that they can have a \nrole and a voice here.\nSo I think we’re figuring out what that consultation looks like, because to me there is an increasing social need, on \nthe one hand, growing for the kinds of consultation that we do in other kinds of policymaking. I mean, we don’t say \nto people, unless you know how to build a house, you can’t have a voice in policymaking around housing. And \nsimilar, we have to think about how to do that in the science and technology policy space.\nBut on the other hand, the space of expertise is getting a lot smaller. I mean, there are lots of people working in \ncomputer science and data science who are not experts in forms of algorithmic A.I. or forms of generative A.I. But \nwe still need to keep those lanes, I think, of conversation and understanding open.\nAnd so I think you’ll be surprised to hear me say I’m actually quite optimistic about this moment, both because you \nhave companies saying we need increasing consultation and also because it’s an opportunity that the general \npublic is really coming to understand what the technologies might mean.\nEZRA KLEIN: I’m always thrilled for anybody to be an optimist on my show about anything because then I can be \nthe pessimist, which is in some ways my most natural space. And let me suggest two things that I worry I see \nlacking in the public sphere when I talk to policymakers, when I talk to members of Congress, and when I think \nabout how this all might be translated.\nOne is self-confidence. I think that speaking maybe of Congress primarily, but much of the government, there is a \nsense that it almost knows what it does not know. Congress is not confident in its own understanding of technical \nquestions. It is quite confident that it could screw technical questions up by misunderstanding them.\nAnd as such, I think that there is a tendency to want to be pretty hands off, particularly when a technology is \nchanging rapidly and quickly. And you might say that’s actually a good precautionary principle. You might say that is \nthem being wise. But also it means they try not to interfere too much in things. There’s been a lot of talk of \nregulating social media, but very little has been done, as an analogy.\nAnd then the other, which is related, is consensus. There is very little consensus on even very simple things in \nCongress, in the government more broadly. And so the idea that there would be enough consensus to act beyond \nwhat OpenAI or Google voluntarily wants to agree to, that’s a big lift.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nSo the technology is moving forward very fast. The public sector moves quite slowly. The White House released, \nunder you, a draft framework for an A.I. bill of rights. That has not been taken up into the next phase of it doesn’t \nbecome a law, it doesn’t become really much of anything yet.\nAnd so I think that that’s sort of the question. I can imagine how you could have — this could be an amazing \nmoment for democracy. I think it’s really profound to say the public should shape the structure and path of these \ntechnologies. But I see, in many ways, a public sector that is too insecure and divided and has lost a sense of its \nown creativity, such that I worry it will move much too slowly and will always be so far behind that it is not shaping \nthis away from the harms that are coming.\nALONDRA NELSON: I think that’s right in some degree. I would want to add the following. So I come to \nWashington as a relative outsider. So I’ve written about politics. I had been, before coming to OSTP, writing a book \nabout the Obama-Biden Office of Science and Technology Policy. So it’s not that I hadn’t been thinking about these \nissues, but I certainly hadn’t been in a role in Washington.\nSo I think I came into the role thinking that there was going to be — I think critical of what you called self-confidence \nor not sufficient confidence around tech issues. And I think, having left the role, I think that’s partly true. But I also \nknow that there’s been, particularly over the last decade, incredible efforts to bring more expertise into government . \nAnd that many representatives and senators have really great teams that are quite great technical capacity and \nactually know quite a lot about the things that they are trying to legislate on.\nSo then we’re really talking about, I think, around the confidence, Ezra, the space of the political theater, which is \noften hearings or social media. And somebody might use the wrong word or the right jargon, but that cannot be, I \nthink, an excuse or justification for not having a democratic process around science and technology policy.\nSo I’d want to say, yes, it would be great to have many more people working on the Hill who felt a lot more \nconfident around the most advanced science and technology policy. But it’s also the case that I personally, as a \ncitizen, don’t want to live in a technocracy. And I don’t want to live with a government in which in order to have a \nsay about government, about process, about participation, about democracy, you have to have a degree in \ncomputer science.\nAnd so to come back to what I was saying before, we have got to grow a language for talking about sophisticated \nscientific and technological issues in this moment. And we also have to grow the constituency around them. And \none way to do that is to say you don’t have to know the difference between narrow and generative A.I.\nBut you can be able to say, and you should be able to expect, that the automated systems that are used in your life \nare safe and effective, that your data has been protected, that a system that’s used to make a decision about your \naccess to a real estate mortgage, for example, that you should be able to get an explanation about how that was \nderived or that you should be able to talk to somebody about how that was derived, for example, if the decision \ndoesn’t go in your favor and you want more information.\nSo I want us to move out of a space, as a national community, and which only those who can talk, can use the right \nwords and the right jargon — and that goes from senators and Congressmen and women — to citizens are able to \nhave a voice here.\nEZRA KLEIN: I think this is actually a really important point. I want to call out maybe a dynamic that I’d be curious \nfor your thoughts on. Mark Zuckerberg and other Facebook executives have appeared before Congress now many, \nmany times. And I suspect hundreds, thousands, potentially, of questions have been asked of them in these long \nhearings.\nAnd I think that to the extent people know of any question ever asked in any of them, it is this one where Orrin \nHatch, who was in his 80s at the time, asks, how do you sustain a business model in which users don’t pay for your \nservice? And Zuckerberg smirks and says, “Senator, we run ads.”\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nAnd you can argue about what Hatch knew or didn’t know there and if he was trying to set something up. But \nthere’s this recent TikTok hearing where I think the famed question out of it was where one of the members of \nCongress asked TikTok C.E.O. if TikTok connects to a home Wi-Fi service. And he was trying to say something \nelse about other devices on the service, but it was a dumb-seeming question in the moment.\nAnd there has begun to be this pattern, I think, where you see these hearings and people are looking for the \nquestion that suggests to them Congress or regulators don’t have the understanding to regulate these things, which \nI think is actually also can be fair, can be true. But somehow that always becomes the headline.\nWhereas, a lot of the questions are very good. And a lot of the lines of inquiry developed are very good. And they’re \njust not good clips because they’re more complex and sustained. And I don’t exactly know what to do about this, but \nI do think there’s a meme, there’s an intuition that the public sector lacks the technical expertise to be effective \nhere.\nAnd I think that’s one reason these exchanges always catch fire because they speak to a suspicion that much of the \npublic already has. They then play well or are boosted potentially on the relevant social media services. And as \nsuch, something that you have I think identified a few times here as being very important — public confidence is \npretty low around the public sector’s capacity around technical issues.\nALONDRA NELSON: So we live in a meme culture. And so I think that people are always going to be looking for \nthe memes more than the nuanced and sophisticated questions. And I described it as political theater, and I think \nthat’s largely the case. The work of doing technology policy doesn’t happen in these hearings. I mean, the hard \nwork happens in conversations with constituents and meetings with business leaders and lots of other things \nbesides. But clearly this is — I would not say that it’s not an important part of political culture.\nBut I think that we don’t do ourselves a service to continually engage in a kind of gotcha culture around political \nhearings. And that I think all of us really care about the future of democracy. We might have different opinions about \nthe intersection of social media and of generative A.I. and automated systems with this.\nBut there can certainly be more expertise. We need more people with expertise to be working in the public sector. \nThat’s certainly true. But there are core issues about access to effective, safe services for consumers, for students, \nfor patients that are not about using the right word and not about knowing technology at the highest level.\nEZRA KLEIN: To stay for a minute on the question of the public sector’s technical capabilities, one thing that is true \nabout the government is that it runs an array of unbelievably technically complex systems and institutions and \nprojects. The recent nuclear fusion breakthrough happened at a government lab.\nIf you look at the Defense Department and the kind of technology that they are directly involved in creating, \nsoliciting, buying, operating, running, pushing forward, very, very, very complex stuff. If you look at what DARPA \ndoes, very complex work.\nShould we have a public option in this way for A.I.? And I mean this for two reasons. One is that one of the theories \nof what OpenAI always said it was doing — I’m not sure that’s really what they are doing at this point — but what \nthey said they were doing was that in order to understand A.I. safety, you needed to actually run one of these really \ncapable models so you could experiment on it and run testing and run research and try to understand how to \ncontrol it.\nIt’s also the view of the group over at Anthropic. So you can imagine maybe the government wants to build its own \none of these, with a lot of money and a lot of manpower, so that they have the ability to really understand it at the \nlevel of its own guts.\nAnd then secondarily, maybe they want it so they can turn it to their own ends — scientific research or maybe it’s \nabout trying to work on deliberative democracy, but something where this could be not just a technology used by \nthe private sector, but one to be used by the public sector.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nMost of what I’ve seen so far has been around the idea of regulating what the private sector does. But what about \ncreating internal autonomous public sector A.I. capacity?\nALONDRA NELSON: Yes, you’ve hit on something really important. And this is work that’s been going on in \ngovernment for more than a year now, actually. And just this past January, there was a report released by the \nNational Artificial Intelligence Research Resource Task Force, which comprised of all sorts of amazing researchers \nfrom the private sector, from universities, both public, land grant, small universities, folks from different parts of the \nUnited States.\nAnd it was exactly this issue that this body was asked to address, and they made recommendations about this to \nthe White House and to also the National Science Foundation. And the idea here is that is there a public sector, \nprecisely as you say, opportunity to create at scale, a way to stand up a research infrastructure that would broaden \naccess to the computational resources, to the data resources. And I would add, put an asterisk here and say, to do \nso in a privacy protecting way that allows academic researchers, government researchers, to be able to work in this \nspace.\nAnd indeed, I think to go back to some of our earlier conversation and thinking about the space of innovation, work \nin this R&amp;D space, in this innovation space, I think to think about some of the tools — that to the extent that \nsome of the solutions here around harms, getting that right balance between driving innovation and mitigating \nharms will fall to the public sector because there may not be a market model there that somebody wants to move \nahead with in the private sector. Having the raw resources, the compute power and the data resources to do it are \ncritically important. So there’s a proposal on the table that was brought together by a lot of very thoughtful people \nthinking in this space. And it’s certainly something that we need to pursue.\nI think a parallel model of this might be something like ARPA-H, which is the Advanced Research Projects Agency \nfor Health, which has been stood up in the last year. Part of the philosophy there is that there are things that we \nneed to get improved health outcomes at scale, and that in order to do that, we’re sometimes going to have to do \nresearch or move in an innovation space that will never have a viable commercialization or market power in a way \nthat it’s going to make particular money, or private equity backers, or venture capitalists a lot of money. But there \nstill could be a lot of potential for society.\nEZRA KLEIN: I appreciate you bringing up that there are some draft proposals around this. And one of the \nquestions I have about it — and you and I have talked about this previously — is why there isn’t more discussion of \na positive public vision for these systems?\nI find it offensive, actually, as a person, that a technology that is potentially this transformative is really just going to \nbe left up to the competitive race between Microsoft, Google and Meta to make money. That just seems like a crazy \nway to do things.\nBut it often doesn’t seem we have a language — and certainly not a rapid legislating capacity — around saying \nthese are the goals we have for this new technology. We don’t want this to just evolve in any way. We don’t just \nwant to say, hey, whatever can make money here, be that behavioral advertising manipulation or A.I. sex robot \ncompanions.\nWe actually want to say that we’re interested in solving this set of problems. And we’re going to put public money \nbehind it. And we’re going to make these enterprises or come up with other advanced public purchase \ncommitments. There’s a lot of things you can imagine here.\nBut that we’re really going to put a lot of money here, but we’re going to put a lot of money and we’re going to wipe \nout this set of business models. We’re just going to say you can’t make money this way. We’re going to give you a \nbunch of options where you could become unfathomably rich solving public problems. And then we’ll let some of \nthese private players figure it out.\nAnd I’m not saying I have the right goals or the right structure or any of it, but I find it depressing that there isn’t \nmore conversation about this kind of thing from the front. I mean, you see it in some areas. I think climate tech is a \nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nplace where it’s probably most prevalent. We actually do now have a government that has put money in and is \ncommitted to saying we want these technologies for these purposes.\nI don’t see it here. And so, one, I wonder if there is more conversations like this that you have been in that I don’t \nknow about. But two, how you would think about building those kinds of goals or programs?\nALONDRA NELSON: I think climate change is such a great example, because it was not always the case — and \nI’m going to go to the phrase I used earlier — that there was a democratic constituency or constituency around \nclimate change politics and around resources for mitigating climate change for not only mitigation but adaptation \npolicies, such that people felt engaged from a lot of different sectors in society and the work. And so I think that we \nare building affirmative vision around this.\nPart of also where we saw this opportunity is in the conversation — I mean, there’s been so many debate cycles \naround generative A.I. over the last few weeks, but certainly one of them has been is society — the end of \ncivilization looming or is it not? And I have found I think all of this debate, I think very disempowering.\nAnd for us not to be able to say what we want, what we’re moving towards, and we’re going to harness this \nstrongest ever technological power, this generative A.I. power and all of the things around it, whether or not it ever \ngets to artificial general intelligence, that we’re not going to use that to build a society in which people can thrive \nand which — I mean, we should certainly maybe talk a little bit about jobs and work in which we’re going to imagine \nwhat it means to work and how people can work with technology and tools in ways that — we could imagine less \nexploitative work. I mean, the dream of the 20th century, people having more leisure time. There’s all of these kinds \nof possibilities. And I do think — again, I do not work in the administration any longer, but I do think that there are \nvarious efforts going on that taken together really begun to articulate that kind of affirmative vision that you’re asking \nfor and that I’m asking for.\n[MUSIC PLAYING]\nEZRA KLEIN: Tell me a bit about the role China plays in the political economy of how the government thinks about \nA.I. in your experience?\nALONDRA NELSON: Sure. I mean, I think that certainly it’s the case that there are great concerns about China \nworking in this space. And that innovation that the Chinese Communist Party is driving, so you will hear I certainly \nheard lots of concerns about the almost synergistic way in which R&amp;D, the Chinese Communist Party, the \nChinese military work together, and how that sort of creates potentially, at scale, a risk to democracy, to democratic \nvalues and the like.\nAnd so certainly that was a part of a lot of the conversations that I sat in on with regards to artificial intelligence, but \nlots of other technologies as well. But it’s also the case — so the work of the Office of Science and Technology \nPolicy, just to triangulate this a little bit, is also an office that is — its job is about helping to have a robust of \nresearch ecosystem and research enterprise, both for technology and also for basic science.\nAnd part of the conversations that we were also having in my experience were about, how do we both mitigate theft \nof IP and of intellectual property, theft of technology, while also ensuring that we have the best scientists in the \nworld working in the United States. And quite a lot of that is about immigration and about creating a space, also an \naffirmative vision for Science and Technology and Innovation in the United States that continues to bring the very \nbest people and draw the very best people to the table. And that means that even as there are I think real national \nsecurity threats with regards to China in the science and technology space, it also is the case that it can’t be a \njustification, and shouldn’t be, for discrimination or xenophobia in that space.\nAnd that’s I think the hard place that the administration finds itself in, as an administration that’s deeply committed \nto expanding innovation, deeply committed to equity issues and equality issues, and also deeply committed to \ndemocracy and using lots of creative new tools like export controls and these sorts of things to make sure that \nthere’s economic and national security in the United States.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nEZRA KLEIN: I have more fear, I think, about how this is playing out. Some of that is threaded through what you \nwere saying there. But I hear a lot about dominance and race dynamics, that the [INAUDIBLE]— from the national \nsecurity apparatus — they want to be first to powerful A.I. When you mentioned the export controls, I mean one of \nthe main things we’ve export controlled are the kinds of semiconductors that China would use to train large-scale \nA.I. systems.\nAnd I mean, national security is a very powerful stakeholder in Washington. I think that would almost be an \nunderstatement. And they’ve been ahead on A.I. for a long time. And it just seems to me that a lot ends up getting \njustified under the idea that we need to race China to the finish line here.\nAnd yet, when I look at China — and I’m not a China expert, and I would like to understand enforcement of these \nthings better than I do — it in some ways looks like they’ve been even more aggressive on regulating A.I. than we \nhave. So they unveiled these new regulations governing internet recommendation algorithms, a lot of which would \napply to A.I. systems. If you want to make a deepfake, you need to have user consent to the images in a deepfake. \nYou can’t just do it because it’s cool and spread it around on social media. You actually have to have somebody \nsign off.\nAnd maybe that’s just what the American press is reporting. And in practice, it doesn’t work that way. But I worry \nthat we’ve turned China, particularly inside the government, into this bogeyman that justifies anything we want to do \non A.I. and racing forward really, really fast, even though it’s not clear to me they don’t have even more qualms and \nconcerns about the technology than we do.\nAnd I want to say that is not to defend the way China — I think what China might do with A.I. on surveillance is \nchilling, and I don’t want to see them attain A.I. dominance. But I also don’t want a caricatured version of them to be \na way that safety ideas get kneecapped in the United States.\nALONDRA NELSON: I think that’s right. I take that — my research as a scholar, in part, is in the space of human \ngenetics and the uses of human genetics after the Human Genome Project, where we first start to see the use of \nlarge-scale computational power, big data sets in this space.\nAnd so the Chinese researchers, Chinese government has been obviously a significant player in this space. I mean, \nthere’s been New York Times reporting on how genetic technologies have been used as a way to exploit and to \nsurveil the Uyghur population. And so there are real challenges. And to the extent that we can know I think what’s \nhappening on the ground with regulations and use cases, there’s certainly concerns.\nI think that we can look back across history — and I think to use your phrase that there’s always been a boogeyman \ncast against different kinds of, I think, geopolitical aspirations. But I think I want to take your deepfakes thread and \npull that through and say there’s some good work on this already happening in the United States.\nAnd while there is indeed some proposed legislation around deepfakes in particular, it’s also the case that there \nhave been researchers and organizations moving in this space, proposing ways to do watermarking, to trace the \nprovenance of an image or a text. Adobe has been a leader in this space.\nThe partnership for A.I. working with some other media companies, like the BBC recently released a white paper \nand proposal for ethical principles around deepfakes with technologies and techniques for how to do that and how \nto think about them.\nSo there are ways in which we can both hope for regulation around concerning things like deepfake, but also I think \nlean on companies. The work that they are doing in this space, working with civil society actors to create some tools \nto help us navigate in the world of synthetic media.\nEZRA KLEIN: The European Union has also been trying to think through its A.I. regulation. It has this draft — \nArtificial Intelligence Act - which is a pretty sweeping piece of legislation as I read it. Can you talk at all about how \ntheir approach is similar or differs from the one that the White House has considered here?\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nALONDRA NELSON: Sure. So this has been a long process — the E.U. A.I. Act. I believe it’s going to, later this \nmonth, be finalized. And their approach is really based on risk cases and thinking through if an A.I. system or tool \nrises to or not a particular level of risk — that could be surveillance or intervention and a person’s privacy. It could \nbe around national security issues and the like versus low risk uses.\nSo I think for the US approach, you might think about it as offering, A, we’re still awaiting formal legislation. That \nwould be his robust as something like the proposed and forthcoming A.I. Act in the United States.\nBut you might think of it as being something that the E.U. side, that combines and draws on, or that a similar — \nexcuse me — doesn’t draw on because what I’m talking about comes after but the NIST, the National Institute for \nStandards and Technology, A.I. risk assessment framework, gives tools for thinking about how risky a particular use \nof a technology might be and ways that you might mitigate that on the one side.\nOn the other hand, it also has values and principles with regards to people’s rights that I think is analogous to the \nblueprint for an A.I. Bill of Rights as well.\nEZRA KLEIN: One question I’ve had about the E.U.’s approach on this is when we are talking about these \ngenerative models that end up having a lot of applicability across different domains — the GPT-4, GPT in the future, \nmaybe five or six system — can be applied to a lot of different things.\nDoes separating the regulation out by use case make sense? A lot of people, particularly those worried about more \nkinds of existential or large scale risks, would say what you have to make sure is that the model itself doesn’t \nbecome dangerous. And so not aggressively regulating a model because for now it’s called a chat bot as opposed \nto being called a judicial sentencing bot is applying a set of categories that maybe made sense in more specific \ntechnologies but don’t make sense here. How do you think about that difference between regulating the models and \nregulating the use cases?\nALONDRA NELSON: Depending on the context, you might have to do one or both. I mean, so I think — we were \njust talking about national security. In the national security space, you might want to be regulating a model. And that \nmight be done in a way that’s not publicly known. So there might be some — you could imagine, for geopolitical \nreasons, intervention around particular models.\nSo that’s not regulation per se when you’re talking in that geopolitical space and the way that we might around an \nact or a law that we passed around particular use cases. So this is what’s true. I mean, I don’t — you used, when \nwe began, the phrase “sui generis” to talk about generative A.I. And I think I’m enough of a scholar to think that \nthat’s an empirical question. And I would want to get more information to think about whether or not that’s true.\nWhat we can say is true is that automated tools, automated systems, A.I., machine learning, large language \nmodels, this whole dynamic and world have an extraordinary — what we can say right now is they have an \nextraordinarily broad scope. And I think what your question is really getting at is the fact that the answer to that \nquestion about whether or not it’s the tool, or the use cases, or the risk cases, or the potential risk, it’s E, all of the \nabove.\nAnd so I think that’s what’s distinctive about automated systems. They are both kind of an infrastructure and an \nenterprise tool. I found it very interesting that one of the first use cases that we will have will be generative A.I. \nbeing rolled into, effectively, Microsoft Suite and the Google Suite. So tools that we’re already using that we usually \nthink of as often as enterprise tools.\nBut it also will be the case that they’ll be used for — I think ultimately other kinds of systems around advanced \ndecision making. And that means that we need policy innovation and creativity that can think about what it might \nmean to regulate a particular tool, but that appreciates that A.I. and related automated systems and tools will be \nincreasingly woven throughout society and woven in through a lot of the actions and things that we do in the day-to-\nday.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nAnd so that means that thinking about it as just one thing is insufficient. And that we will need to, I think, have a lot \nof policy space and innovation. And so again, this is why something like the “Blueprint for an A.I. Bill of Rights” is \nreally about — not about the tool, and is really about the use cases and about allowing people to have exploration, \nallowing people to have an opt-out option, to be able to reach a person to not be discriminated against and the use \nof these technologies.\nEZRA KLEIN: How do you think — and this goes to the question of being sui generis or at least very unusual — \nhow do you think about the existential risk question, the finding in surveys that about when you talk to A.I. \nresearchers, they give a 10 percent chance if they’re able to create generalized intelligence that it could extinguish \nor severely disempower humanity. A lot of people are afraid that this could be a humanity-ending technology. Do \nyou think there’s validity to those fears?\nALONDRA NELSON: So we already live, I think, as I said, in a world in which the destruction of the human race is \nnot a zero probability. And the word alignment is used — I think it’s a term of art and it’s a little jargon. But I think \nfolks listening should understand that it’s often intended to mean aligning A.I. with human values, in a high sense, at \na high level, but often through only technological means.\nAnd so what we have been talking about, and what I’ve tried to add in our conversation today, Ezra, is a different \nkind — well, I’ll stick with alignment. But an alignment that’s about our values as a society and the democratic \nlevers and policies that we can use that are not only about the technology.\nAnd so I think the challenge around the very small group of very talented computer scientists and researchers who \nare saying that we need alignment and alignment can only be other technology is that that choice architecture is \nsaying already that we can only ever think about this with other kinds of technological processes, that we can’t ask \nother questions about should these systems even be developed, how do we ensure that they’re safe and effective \nin a way that allows other people, besides scientists and besides the elite group of scientists who are working in this \nspace to have a say about what that means.\nSome of the A.I. alignment conversation is about what’s good for civilization and what’s good over humankind. How \ndo we have those conversations in a way that actually includes a larger swath of humankind and what that \nconversation is, and that it is not just a conversation that inherently creates a race amongst technologists as the \nonly possible solution or the only future vision for what American planetary society might look like.\nEZRA KLEIN: You’re a scholar of science and how science has worked in the real world and who has been \nincluded and excluded. When you look back, we have so many different examples of how science has been \ngoverned for good and for ill, everything from regulated, like cars and seatbelts, to international bans on certain \nkinds of things.\nWhat do you find to be the most hopeful or interesting or inspiring example, not of the technology, but of a \ngovernance, or input, or some other kind of public structure that emerged around a technology to turn something \nthat could have been destructive into something that was productive?\nALONDRA NELSON: A lot of the research and writing I’ve done has been about marginalized communities, about \nAfrican American communities, often. And the thing that has been both inspiring and surprising, even though I know \nit to be true, is how communities that have been often deeply harmed by technology historically up into the present \nare sometimes the strongest believers in its possibilities — are sometimes the early adopters and the innovators in \nthis space.\nSo the last book length project I worked on was — it followed the first decade of direct-to-consumer genetic testing. \nAnd as much as I heard people and the communities that I was working with say, I have lots of reservations, given \nthe history of eugenics, given how quickly the technology is moving in this space, about what this technology can \nactually really do and mean for my life.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\nBut it was also the case that — in the case of some of the research I did, you had 60, 70-year-old African \nAmericans who were the early adopters in 2003 and 2004 of direct-to-consumer genetic testing. So this is three and \nfour years before you’re having the 23andMe spit parties that are being written about in the mainstream press.\nAnd so I guess I would say all of us do believe in the possibilities for technology and for innovation and for what \nthey can do to improve people’s lives. But we need to put that front and center. The technology shouldn’t be front \nand center. That belief that technologies are tools that expand opportunity for people, that potentially extend our \nlives, that make us healthier, I think should be how I would want to propose that we think about what might be the \nfuture for generative A.I.\nEZRA KLEIN: I think that is a good place to end. As always, our final question, what are three books you’d \nrecommend to the audience?\nALONDRA NELSON: Three books. OK, I’m going to offer a pretty new book and two older books. The first is “Data \nDriven: Truckers, Technology and the New Workplace Surveillance.” It’s by Karen Levy. It was just published at the \nend of last year. And it’s really about I think some of the conversations that we’ve been having about generative \nA.I. and the workplace.\nHow does automation transform the workplace? And it’s really about how the surveillance automation has been \nchanging the trucking industry, reconfiguring relationships between truckers and their workers. And she tells a story \nabout how surveillance is becoming more pronounced in trucking, but also a story about how automation and \nsurveillance are being resisted by truckers.\nSo I think we want to think about, as we think about a future vision and affirmative democratic vision for new \ntechnologies, that there’s always a role here for individuals and for people to fight back. I’ve been encouraged, for \nexample, to see that University of Chicago researchers have developed a tool to help combat the mimicry of visual \nartists’ work, for example, already using automated systems.\nAnd so even when we’re thinking about the question of existential risk, we need to be thinking about these \nquestions, imagining that we live in a dynamic space in which there’s going to be an ongoing interaction between \ntechnological capabilities and what human communities respond with.\nAnd then two classic books: Tim Wu’s “Master Switch” — my former White House colleague — “Master Switch: The \nRise and Fall of Information Empires.” And I think we’re seeing a instantiation of what Tim describes, which is this \nongoing repeated cycle — and we’re seeing a hype cycle, of course, around some of the A.I. work.\nBut a cycle — in his case, he was writing about the emergence of information technology to industries that become \nempires and consolidate power. I think we’re seeing the same cycle play out with social media and increasingly also \nwith A.I. The cycle is not inevitable. We can intervene on the cycle and make sure that there’s more space for more \npeople to have a voice and developing A.I. and automated systems.\nThen the last book is “Kindred” by Octavia Butler. This is a fiction. It’s set during the United States bicentennial. And \nfor me, this is — Octavia Butler, of course, is a leading science fiction writer. It’s about living with history. It’s about \ntechnology and democracy, about moving back and forth in time but still being anchored and living in resilience.\nEZRA KLEIN: Alondra Nelson, thank you very much.\nALONDRA NELSON: Thank you, Ezra.\n[MUSIC PLAYING]\nEZRA KLEIN: This episode of “The Ezra Klein Show” is produced by Roge Karma, Kristin Lin and Jeff Geld. Fact-\nchecking by Michelle Harris, mixing by Jeff Geld and Efim Shapiro. Original music by Isaac Jones. Audience \nstrategy by Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose Strasser. And \nspecial thanks to Sonia Herrero and Kristina Samulewski.\nTranscript: Ezra Klein Interviews Alondra Nelson The Ezra Klein Show\n[MUSIC PLAYING]\nPHOTO:  (PHOTOGRAPH BY Dan Komoda FOR THE NEW YORK TIMES)\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I. and TV Ads Were Made for Each Other; Screenland",
        "media": "The New York Times",
        "time": "June 30, 2023",
        "section": "MAGAZINE",
        "length": "1226 words",
        "byline": "Mac Schwerin",
        "story_text": "A.I. and TV Ads Were Made for Each Other; Screenland\nThe New York Times \nJune 27, 2023 Tuesday 22:25 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: MAGAZINE\nLength: 1226 words\nByline: Mac Schwerin\nHighlight: A string of uncanny videos show what generative A.I. and advertising have in common: They chew up \nthe cultural subconscious and spit it back at us.\nBody\nA string of uncanny videos show what generative A.I. and advertising have in common: They chew up the cultural \nsubconscious and spit it back at us.\nEven if I didn’t work in advertising, I would be a connoisseur of commercials. You’re probably one, too. Think of all \nthe tropes you’ve ingested over the years — the forest-green hatchbacks conquering rugged Western landscapes, \nthe miles of mozzarella stretched by major pizza chains. These are the images that let you know what kind of pitch \nyou’re watching, so you won’t be confused when the brand shows up.\nThe same applies to one recent video: It begins, conventionally enough, at a barbecue, where a Smash Mouth song \nis playing and people are chatting happily over beers. But around three seconds in, your amygdala starts paging for \nbackup. The partygoers are laughing too aggressively. A blonde seems to be talking to her beer, which she holds in \na fleshy koozie of misshapen fingers. There are strange shots of lips and drinks, cavorting without ever properly \nmeeting. The beverages keep getting bigger, obscenely big. A fire begins spreading, filling the frame like a space-\nshuttle launch.\nThis is “Synthetic Summer,” a fake beer commercial produced entirely with generative artificial intelligence. It’s \none of a handful of A.I. commercials that have been making the rounds online. “Synthetic Summer” evokes an \nInstagram post from the Cenobites in “Hellraiser”: a buffet of ungodly desires, remorselessly fulfilled. In another A.I. \ncommercial, “Pepperoni Hug Spot,” we find a family pizza restaurant beset by predatory mouths and 1970s wipe \ntransitions. Another video, a fake ad for orange juice by the artist Crypto Tea, cuts between crisp pour shots and \nderanged breakfasters; Donald Trump narrates.\n[Video:  Watch on YouTube.]\nA.I. isn’t pumping this weird stuff out unbidden. Behind each commercial is an impish tech enthusiast with a knack \nfor these new tools, nudging things into absurdity. Chris Boyle, the originator of “Synthetic Summer,” told me his \nprompts for the text-to-video A.I. program included requests for more fire as the commercial progressed. Ultimately, \nthough, it’s a computer that interprets these instructions: The freaky visual smorgasbord it serves up is homegrown, \nand about as close as you can get to the uncanny without resorting to sleep or psilocybin.\nConsidering all the different visions you could use this power to summon, it’s telling that people keep returning to \nthe formulas of the old-school TV commercial. There must be tens of thousands of commercials online, an immense \ncorpus for software to digest. That availability has helped make our young A.I. programs remarkably good at \nreproducing them. Besides, commercials are already recursive, by design. However much they may doodle in the \nmargins, they stick to tried-and-tested principles: sparkling suburban kitchens; slow-motion ice-and-soda splashes; \nA.I. and TV Ads Were Made for Each Other Screenland\npleasant, wordless canoe trips that indicate relief from irritable bowel syndrome or moderate-to-severe plaque \npsoriasis. Every convenient shorthand and hackneyed motif is encoded, over and over, in the ads themselves. A.I. \nswallows it all and spits it back in our faces.\nA.I. tools like Midjourney and Gen-2 are so in thrall to commercials, in fact, that the word itself elicits their respect. \nThe director of “Pepperoni Hug Spot” told me that when he added “TV commercial” to text prompts like “a happy \nfamily eating pizza in a restaurant,” the A.I. rendered clips that were more evenly lit. The best results, Boyle told me, \ncame from prompting the program to deliver something “as generic and middle-of-the-road Americana as possible.”\nCommercials, at this point, are America’s cave paintings: a series of icons we hand down through the years from \none target market to the next. Their visual syntax is often clearer to us than the realities they supposedly draw from. \nI’ve spent my life training my own organic neural network on glamorized images of beachside bonfires, generic \noffice shenanigans, rise-and-grind sports montages, chemically horned-up retirees, unblemished sneakers on gritty \nstreets. I have never dined al fresco to live jazz or surprised a spouse during the holidays with the gift of his-and-\nhers new cars, but my mind can conjure those moments as easily as anything else. Now computers can, too.\nSome of the people who make commercials today are worried that A.I. could take their jobs, just as soon as it \nfigures out how hands work. But asking A.I. to make fake ads gives it a job it already excels at: assistant \nethnographer, media-studies expert, unbiased auditor of cultural tropes. This software, having slurped up the same \ncommercial soup as the rest of us, takes a prompt like “family breakfast” or “outdoor party” and, based on the mass \nof examples on which it has been trained, calculates its way toward some probabilistic mean. It offers a composite \npicture of formulas and clichés — including those we’re usually too immersed in to notice.\nIn that orange-juice ad, for instance, we get a couple of shots of the classic juice pitcher — a wholly superfluous \ninstrument whose purpose is to make us forget that the product is not freshly squeezed. Usually a few slices of \ncitrus, floating elegantly inside, help sell that illusion. The A.I. has seen this fruit but cannot know why it’s there — \nand so the version it creates is a rogue foreign body, a cancerous green lump that starts to subsume the juice \nentirely. In “Synthetic Summer,” the partygoers seemingly don’t know how to drink: They hold cans a few inches \nfrom their faces or latch their lips to the sides. That’s probably because their real-life analogues hardly ever drink in \ncommercials, either; it’s a convention of alcohol ads to show good times without explicitly depicting anyone taking a \nswig. This visual euphemism leaves a gap that A.I. struggles to bridge — and ends up filling with comical, unsettling \nimagery. This is one reason the A.I. commercials reward repeat viewing: Once you get past their grotesqueries, you \nstart seeing fascinating signals buried in the noise.\nUntil the noise changes. One weakness of these tools is that by the time they’ve rounded up a genre’s common \ntropes, the genre may have moved on. “Synthetic Summer,” for instance, has the DNA of a 20-year-old Bud Light \ncommercial; it bears little resemblance to the brand’s latest Super Bowl spot. For the moment, these are fever \ndreams of a recent past.\nAs far as brands are concerned, that’s fine: They need not train A.I. on ads from the glory days of linear television. \nIn a fractured, polarized world, that kind of shared consensus may be obsolete. Companies seem a lot more likely \nto feed their A.I. furnaces with every available piece of data about potential customers — everything you’ve liked, \nbought or posted, every consumer demographic into which you might plausibly fit. The images and videos you see \nthen may or may not be real, but they could easily feature the people and scenes that will most appeal to you or \nplay most intimately on your insecurities. Which, when you think about it, could be a lot creepier than a few extra \nfingers.\nOpening illustration: Screen grabs from YouTube.\nMac Schwerin is a copywriter and freelance journalist based in Washington.\nPHOTOS: PHOTO (MM7); PHOTOS (PHOTOGRAPH FROM YOUTUBE) (MM8-MM9) This article appeared in \nprint on page MM7, MM8, MM9, MM10.\nA.I. and TV Ads Were Made for Each Other Screenland\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "Store_Mar2024",
        "header": "Apple Reverses Course and Allows Epic Games to Start Competing App",
        "media": "Store",
        "time": "March 9, 2024",
        "section": "TECHNOLOGY",
        "length": "516 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple Reverses Course and Allows Epic Games to Start Competing App \nStore\nThe New York Times \nMarch 8, 2024 Friday 00:14 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 516 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: After an inquiry by European regulators, Epic Games said Apple would allow it to access the software \ntools necessary to develop a game store.\nBody\nAfter an inquiry by European regulators, Epic Games said Apple would allow it to access the software tools \nnecessary to develop a game store.\nDays after Epic Games, the maker of Fortnite, complained publicly that Apple had blocked it from starting a \ncompeting app store in Europe, the technology companies said Apple had reversed course and would allow Epic to \ngo ahead with its plan.\nThe reversal highlights the way that Apple is changing its operations to comply with a new European tech \ncompetition law. That law, the Digital Markets Act, which went into effect on Thursday, requires Apple to give app \nmakers alternatives for selling software to iPhone and iPad users, including the ability to use competing app stores \nand payment systems other than its own.\nBy opening up the iPhone to competing stores, European regulators hope that smartphone users across the region \nwill benefit from lower prices. Epic Games, which planned to start a competing app store, currently takes a 12 \npercent commission for every game it sells on personal computers and other platforms. The fee is less than half of \nthe 30 percent that Apple typically collects.\n“People ask: Why do you need another app store?” said Justin Kan, one of the founders of the video game \nstreaming service Twitch and the creator of Stash, an open payments platform for video game companies. “But \ncompetition generally creates lower prices. Ultimately, it’s probably good for Apple because it could grow the market \nof apps.”\nApple and Epic have been feuding over App Store commission for years. In 2020, Epic broke the App Store’s rules \nby encouraging customers to pay it directly for features in Fortnite. Apple threw Epic out of the App Store, and Epic \nsued Apple for violating antitrust law by requiring developers to use its payment system.\nThe feud was reignited in the wake of Europe’s competition law. Epic planned to start a competing app store called \nthe Epic Games Store through a subsidiary in Sweden. Initially, Apple granted the subsidiary, Epic Games Sweden \nA.B., a developer account so that it could access the software tools necessary for the release.\nBut Apple later terminated Epic’s account, saying that it couldn’t trust Epic to follow its rules. Apple also complained \nthat Tim Sweeney, Epic’s chief executive, had called Apple’s plan to comply with the new tech law “hot garbage.”\nApple Reverses Course and Allows Epic Games to Start Competing App Store\nOn Wednesday, Mr. Sweeney said that he had assured Apple that Epic would follow the rules. He also released \nemails where he made those assurances directly to Apple.\nAn Apple spokesman said Friday that Epic had committed to following its rules, including its policies in Europe.\nMr. Sweeney said that Apple changed its plan after a “swift inquiry” by European regulators. He called it “a big win \nfor European rule of law, for the European Commission, and for the freedom of developers worldwide to speak up.”\nPHOTO: Apple’s shift in its dispute with Epic Games highlights the company’s operations changes as it complies \nwith a new European technology law. (PHOTOGRAPH BY MICHAEL M. SANTIAGO/GETTY IMAGES) This article \nappeared in print on page B6.\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "HOW AI WILL CHANGE THE WORKPLACE — A PRODUCTIVITY BOOST",
        "media": "Wall Street Journal Abstracts",
        "time": "May 16, 2023",
        "section": "B; Pg. 5",
        "length": "40 words",
        "byline": "KARTIK HOSANAGAR",
        "story_text": "HOW AI WILL CHANGE THE WORKPLACE — A PRODUCTIVITY BOOST\nWall Street Journal Abstracts\nMay 15, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 5\nLength: 40 words\nByline: KARTIK HOSANAGAR\nBody\nABSTRACT\nKartik Hosnagar article in Journal Report — Innovations in Work suggests most important impact of generative \nartificial intelligence may lie in narrowing productivity gap between low-skilled workers and high-skilled ones; \ndrawing (S)\nGraphic\n \nDiagrams and Drawings\nLoad-Date: May 16, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Oct2023",
        "header": "An Industry Insider Drives an Open Alternative to Big Tech's A.I.",
        "media": "The New York Times - International Edition",
        "time": "October 25, 2023",
        "section": "TECHNOLOGY",
        "length": "1323 words",
        "byline": "Steve Lohr",
        "story_text": "An Industry Insider Drives an Open Alternative to Big Tech's A.I.\nThe New York Times - International Edition\nOctober 26, 2023 Thursday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1323 words\nByline: Steve Lohr\nBody\nThe nonprofit Allen Institute for AI, led by a respected computer scientist who sold his company to Apple, is trying to \ndemocratize cutting-edge research.       \nAli Farhadi is no tech rebel.       \nThe 42-year-old computer scientist is a highly respected researcher, a professor at the University of Washington \nand the founder of a start-up that was acquired by Apple, where he worked until four months ago.       \nBut Mr. Farhadi, who in July became chief executive of the Allen Institute for AI, is calling for \"radical openness\" to \ndemocratize research and development in a new wave of artificial intelligence that many believe is the most \nimportant technology advance in decades.       \nThe Allen Institute has begun an ambitious initiative to build a freely available A.I. alternative to tech giants like \nGoogle and start-ups like OpenAI. In an industry process called open source, other researchers will be allowed to \nscrutinize and use this new system and the data fed into it.       \nThe stance adopted by the Allen Institute, an influential nonprofit research center in Seattle, puts it squarely on one \nside of a fierce debate over how open or closed new A.I. should be. Would opening up so-called generative A.I., \nwhich powers chatbots like OpenAI's ChatGPT and Google's Bard, lead to more innovation and opportunity? Or \nwould it open a Pandora's box of digital harm?       \nDefinitions of what \"open\" means in the context of the generative A.I. vary. Traditionally, software projects have \nopened up the underlying \"source\" code for programs. Anyone can then look at the code, spot bugs and make \nsuggestions. There are rules governing whether changes get made.       \nThat is how popular open-source projects behind the widely used Linux operating system, the Apache web server \nand the Firefox browser operate.       \nBut generative A.I. technology involves more than code. The A.I. models are trained and fine-tuned on round after \nround of enormous amounts of data.       \nHowever well intentioned, experts warn, the path the Allen Institute is taking is inherently risky.       \n\"Decisions about the openness of A.I. systems are irreversible, and will likely be among the most consequential of \nour time,\" said Aviv Ovadya, a researcher at the Berkman Klein Center for Internet & Society at Harvard. He \nbelieves international agreements are needed to determine what technology should not be publicly released.       \nAn Industry Insider Drives an Open Alternative to Big Tech's A.I.\nGenerative A.I. is powerful but often unpredictable. It can instantly write emails, poetry and term papers, and reply \nto any imaginable question with humanlike fluency. But it also has an unnerving tendency to make things up in what \nresearchers call \"hallucinations.\"       \nThe leading chatbots makers - Microsoft-backed OpenAI and Google - have kept their newer technology closed, not \nrevealing how their A.I. models are trained and tuned. Google, in particular, had a long history of publishing its \nresearch and sharing its A.I. software, but it has increasingly kept its technology to itself as it has developed Bard.       \nThat approach, the companies say, reduces the risk that criminals hijack the technology to further flood the internet \nwith misinformation and scams or engage in more dangerous behavior.       \nSupporters of open systems acknowledge the risks but say having more smart people working to combat them is \nthe better solution.       \nWhen Meta released an A.I. model called LLaMA (Large Language Model Meta AI) this year, it created a stir. Mr. \nFarhadi praised Meta's move, but does not think it goes far enough.       \n\"Their approach is basically: I've done some magic. I'm not going to tell you what it is,\" he said.       \nMr. Farhadi proposes disclosing the technical details of A.I. models, the data they were trained on, the fine-tuning \nthat was done and the tools used to evaluate their behavior.       \nThe Allen Institute has taken a first step by releasing a huge data set for training A.I. models. It is made of publicly \navailable data from the web, books, academic journals and computer code. The data set is curated to remove \npersonally identifiable information and toxic language like racist and obscene phrases.       \nIn the editing, judgment calls are made. Will removing some language deemed toxic decrease the ability of a model \nto detect hate speech?       \nThe Allen Institute data trove is the largest open data set currently available, Mr. Farhadi said. Since it was released \nin August, it has been downloaded more than 500,000 times on Hugging Face, a site for open-source A.I. resources \nand collaboration.       \nAt the Allen Institute, the data set will be used to train and fine-tune a large generative A.I. program, OLMo (Open \nLanguage Model), which will be released this year or early next.       \nThe big commercial A.I. models, Mr. Farhadi said, are \"black box\" technology. \"We're pushing for a glass box,\" he \nsaid. \"Open up the whole thing, and then we can talk about the behavior and explain partly what's happening \ninside.\"       \nOnly a handful of core generative A.I. models of the size that the Allen Institute has in mind are openly available. \nThey include Meta's LLaMA and Falcon, a project backed by the Abu Dhabi government.       \nThe Allen Institute seems like a logical home for a big A.I. project. \"It's well funded but operates with academic \nvalues, and has a history of helping to advance open science and A.I. technology,\" said Zachary Lipton, a computer \nscientist at Carnegie Mellon University.       \nThe Allen Institute is working with others to push its open vision. This year, the nonprofit Mozilla Foundation put $30 \nmillion into a start-up, Mozilla.ai, to build open-source software that will initially focus on developing tools that \nsurround open A.I. engines, like the Allen Institute's, to make them easier to use, monitor and deploy.       \nThe Mozilla Foundation, which was founded in 2003 to promote keeping the internet a global resource open to all, \nworries about a further concentration of technology and economic power.       \n\"A tiny set of players, all on the West Coast of the U.S., is trying to lock down the generative A.I. space even \nbefore it really gets out the gate,\" said Mark Surman, the foundation's president.       \nAn Industry Insider Drives an Open Alternative to Big Tech's A.I.\nMr. Farhadi and his team have spent time trying to control the risks of their openness strategy. For example, they \nare working on ways to evaluate a model's behavior in the training stage and then prevent certain actions like racial \ndiscrimination and the making of bioweapons.       \nMr. Farhadi considers the guardrails in the big chatbot models as Band-Aids that clever hackers can easily tear off. \n\"My argument is that we should not let that kind of knowledge be encoded in these models,\" he said.       \nPeople will do bad things with this technology, Mr. Farhadi said, as they have with all powerful technologies. The \ntask for society, he added, is to better understand and manage the risks. Openness, he contends, is the best bet to \nfind safety and share economic opportunity.       \n\"Regulation won't solve this by itself,\" Mr. Farhadi said.       \nThe Allen Institute effort faces some formidable hurdles. A major one is that building and improving a big generative \nmodel requires lots of computing firepower.       \nMr. Farhadi and his colleagues say emerging software techniques are more efficient. Still, he estimates that the \nAllen Institute initiative will require $1 billion worth of computing over the next couple of years. He has begun trying \nto assemble support from government agencies, private companies and tech philanthropists. But he declined to say \nwhether he had lined up backers or name them.       \nIf he succeeds, the larger test will be nurturing a lasting community to support the project.       \n\"It takes an ecosystem of open players to really make a dent in the big players,\" said Mr. Surman of the Mozilla \nFoundation. \"And the challenge in that kind of play is just patience and tenacity.\" \nLoad-Date: October 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Google’s C.E.O. Takes Another Turn on the Antitrust Witness Stand",
        "media": "The New York Times",
        "time": "November 15, 2023",
        "section": "TECHNOLOGY",
        "length": "1495 words",
        "byline": "Nico Grant",
        "story_text": "Google’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nThe New York Times \nNovember 14, 2023 Tuesday 13:27 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1495 words\nByline: Nico Grant\nHighlight: Sundar Pichai, Google’s chief executive, testified on Tuesday for the second time in two weeks to \ndefend his company against monopoly claims.\nBody\nSundar Pichai, Google’s chief executive, testified on Tuesday for the second time in two weeks to defend his \ncompany against monopoly claims.\nTwo weeks ago, Google had a big day in Washington. President Biden signed an executive order to create artificial \nintelligence safeguards that could affect Google’s most pressing projects, and Secretary of State Antony J. Blinken \ngave the company an award for its work in aiding Ukrainian refugees and promoting women’s economic security.\nSundar Pichai, Google’s chief executive, had spent much of the day on a witness stand at a federal courthouse \nabout two miles from the White House, defending his company from claims that it crushed rivals in the search and \nonline advertising markets.\nOn Tuesday, Mr. Pichai testified again, this time in San Francisco, to confront claims brought by the video game \ncompany Epic Games that his company broke the law, wielding monopolistic power over app developers on \nAndroid’s Google Play Store.\nMr. Pichai over the last month has become the face of Google’s antitrust court fights on both sides of the country. \nAnd his visits to the witness stand underscore the growing importance for Big Tech leaders to be sharp witnesses \nfor their companies, whether in an antitrust trial or in hearings on Capitol Hill.\nTestifying under oath is a task that many tech chief executives might be asked to do in the coming years, with \nAmazon, Meta and others facing their own antitrust court fights. It is not a task at which many executives have \nexcelled.\nThough he was never called to the witness stand to testify, Bill Gates, who was chief executive of Microsoft in the \nlast big technology antitrust case brought by the Justice Department more than two decades ago, came across as \ncombative and evasive in depositions.\nOver the last few years, executives including Mark Zuckerberg and OpenAI’s Sam Altman (and, of course, Mr. \nPichai) have been asked to testify before Congress for various reasons, with varying degrees of success. Mr. \nZuckerberg has at times exasperated lawmakers with vague responses, while Mr. Altman appeared to charm \nsenators in a hearing this year.\nThe main duty on the witness stand for Mr. Pichai — a low-key and detail-focused executive — has been to keep \nthe temperature low under questioning and keep to the central point of Google’s antitrust defense: that it is an \ninnovative company that has maintained its leadership through innovation and hard work instead of illegal \nmonopolistic behavior.\nGoogle ’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nOn Tuesday, Mr. Pichai ran into aggressive questioning by a lawyer for Epic, Lauren Moskowitz, who asked him to \nprovide yes-or-no responses.\nThat led to at least one small revelation: Mr. Pichai confirmed that his company gave Apple 36 percent of the \nsearch revenue generated on iPhones, and said the total payment “was well over $10 billion” last year. Ms. \nMoskowitz asserted that the figure was at least $18 billion.\nLawyers for Google and Apple fought on Tuesday morning to keep the figures concealed, emphasizing a need for \ncorporate privacy that has carried through both of Google’s trials. Judge James Donato rejected their requests, \nsaying, “Just coming in and saying we’re kind of sensitive with this isn’t going to fly.”\nMs. Moskowitz was trying to counter Google’s claim that it cannot be considered a monopoly because of its rivalry \nwith Apple. If that were the case, she argued, why did it give Apple preferential treatment over other companies like \nSamsung, which she said received a 16 percent share of the search revenue from its devices?\n“We compete fiercely with Apple, at the operating system, the smartphone and the app store level,” Mr. Pichai said \nlater, when questioned by a Google lawyer. “The competition has been good for consumers and developers.”\nThe Justice Department filed its landmark antitrust suit against Google in October 2020, arguing that the company’s \ndefault-search deals with phone makers and browser companies helped it illegally maintain a monopoly.\nGoogle called Mr. Pichai, 51, to the stand two weeks ago. Rather than sit in the witness box, Mr. Pichai stood at a \nlectern for almost four hours, wearing a microphone, as though he were delivering a speech at a corporate \nconference. His handlers said he had to stand because of a sprained lower back.\nHe spoke of his background, getting a telephone as a preteen in Chennai, India, and understanding then the power \nof technology, before he deftly answered questions about his company’s competitive standing, relationship with \nApple and the default-search contracts the government argues were illegal.\nMr. Pichai tried to refute the government lawyer’s arguments that Google paid Apple billions of dollars a year to \nkeep it out of the search market. He presented a different story, saying his company wanted to be the iPhone’s \ndefault search engine because of the “value” of that spot, and the need to ensure Apple would safeguard the user \nexperience.\n“I felt the deal had done well since 2016,” Mr. Pichai said. “It was continuing to increase search usage, search \nrevenue.”\nIn cross-examination, Mr. Pichai repeated the rationale for the deal so many times that for a moment, he seemed to \nlose patience with the line of questioning, saying, “I just gave all the reasons” for the deal.\nAdam Kovacevich, a tech industry lobbyist at the Chamber of Progress who spent 12 years working at Google, said \nMr. Pichai’s testimony gave the court a high-level view of how the company made strategic decisions.\n“He did fine,” Mr. Kovacevich said of Mr. Pichai’s performance. “The biggest thing to me is when you’re in that \nposition, your first objective is to not be Bill Gates in the Microsoft trial. Your No. 1 objective is to come off as \nresponsive and reasonable.”\nExcerpts from Mr. Gates’s combative, videotaped testimony were shown in court more than two decades ago. The \nMicrosoft co-founder, antitrust lawyers say, undermined his and his company’s credibility with the judge in the case.\nIn San Francisco, Mr. Pichai was questioned on topics ranging from why he erroneously marked emails as subject \nto attorney-client privilege (to prevent them from being forwarded) to whether Facebook and Amazon could have \nprovided competition to Google’s Play Store when they had smartphone ambitions.\n“There are nuances in these questions,” he said with a smile when Ms. Moskowitz started to speak over him. “I’m \ntrying to answer your question.”\nGoogle ’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nSeveral times, Judge Donato asked Ms. Moskowitz to “be quiet” to let Mr. Pichai speak.\nThere will be one big difference between the lawsuits: The antitrust trial in Washington does not have a jury. The \ndecision will be made by a judge. In San Francisco, Mr. Pichai had to appeal to a nine-person jury that could be \nopen to the idea that a giant tech company is exploiting much smaller outfits. Tim Sweeney, Epic’s chief executive, \nis also expected to testify in the trial.\nGoogle and Epic declined to comment.\nEpic, the maker of the hit game Fortnite, brought the claim against Google in 2020, in an attempt to sidestep the 15 \nto 30 percent fees from subscriptions and in-app purchases that it must pay Google.\nThe game developer antagonized Google and Apple by telling users to pay for in-app transactions directly through \nEpic. In response, Google and Apple suspended Fortnite from their app stores. Epic claims Google also bullied \nother companies to force them to drop deals with Epic before it was banned from the app stores.\nGoogle faces another Justice Department antitrust lawsuit that accuses it of illegally abusing its monopoly power \nover the technology that delivers ads online.\nA trial in that case could begin as soon as next year, but it is too early to know whether Mr. Pichai will be called to \ntestify.\nMr. Pichai has tried to prevent Google employees from being distracted by the litigation. He has encouraged them \nto “keep doing what you’re doing” and has allocated a relatively small number of employees to work on the Justice \nDepartment case — hundreds out of more than 180,000.\nBut Mr. Pichai’s court appearances have taken time away from his other obligations as a company leader, including \nhis plan to reclaim Google’s primacy in the fast-growing field of generative A.I.\nIn the middle of Mr. Pichai’s October testimony, the secretary of state, Mr. Blinken, was honoring Google’s \nsubsidiary in Poland for its work in fostering women’s economic security and helping Ukrainian refugees. Hours \nlater, Mr. Biden hosted a signing ceremony at the White House, but Mr. Pichai’s handlers could not R.S.V.P. yes \nbecause there was a chance he might have still been in court when it began.\n“It’s not the best use of his time,” Richard Kramer, an analyst at Arete Research, a London-based investment \nresearch firm, said in an interview. “No C.E.O. wishes to spend their time being grilled by government lawyers.”\nPHOTO: Sundar Pichai, Google’s chief, testified in San Francisco on Tuesday. (PHOTOGRAPH BY JIM \nWILSON/THE NEW YORK TIMES) (B4) This article appeared in print on page B1, B4.\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "outpaces_inflation_Jan2024",
        "header": "The Daily Money: Americans' purchasing power recovers as wage growth",
        "media": "outpaces inflation",
        "time": "January 10, 2024",
        "section": "RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & US NEWS",
        "length": "467 words",
        "byline": "Daniel de Visé, USA TODAY",
        "story_text": "The Daily Money: Americans' purchasing power recovers as wage growth \noutpaces inflation\nUSA Today Online\nJanuary 10, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & US NEWS\nLength: 467 words\nByline: Daniel de Visé, USA TODAY\nBody\nGood morning! It's Daniel de Visé with your Daily Money. \nIf it feels like your paycheck is going further than it has in the past couple of years, it's not your imagination.\nThis week's inflation report is expected to reveal further progress in slowing consumer price increases that have \nstrained U.S. households since early 2021, Paul Davidson reports.\nEconomists estimate that the annual inflation figure, due out Thursday, will show a rise of 3.2% in December, \ncompared to 3.1% in the prior month. That's still well above the Federal Reserve’s 2% goal.\nBut by another yardstick – purchasing power – households recently have returned to their pre-inflation financial \nhealth, according to some studies.\nComing soon: more drone deliveries, new AI tech\nShopping at Walmart and Sam's Club is about to get easier, Bailey Schulz reports.\nWalmart on Tuesday unveiled several new and upcoming offerings that aim to improve the customer experience, \nfrom generative AI-powered search tools to technology that will do away with the receipt check lines at Sam's \nClub.\n“We build technology to serve people, and not the other way around,” Walmart President and CEO Doug McMillon \nsaid in a news release. “Walmart’s purpose is to help people live better and, today, more than ever, advances in \ntechnology make it feel like anything is possible.” \nMcMillon took the stage Tuesday afternoon at the CES consumer technology convention in Las Vegas to highlight \nthe company's latest innovations.\nMore stories you shouldn't miss\nFirst time filing your taxes?  Here are 5 tips for tax season newbies\nWhat if I owe taxes but I'm unemployed?  Tips for filers who recently lost a job\nWhat the ETF? Securities and Exchange Commission's X account compromised, sends fake post on Bitcoin ETF\nCruising Altitude: I've covered Boeing's 737 MAX for years. A quick rundown of the issues\nThe Daily Money: Americans' purchasing power recovers as wage growth outpaces inflation\n Today's Menu \n\"Beer Mint\" sounds like an oxymoron: You take mints to camouflage beer breath.\nNonetheless, Miller Lite is rolling out Beer Mints, Mike Snider reports. \nBilled as having \"the same great taste as Miller Lite, only without the beer,\" the new mints ($5 for a tin of 40) go on \nsale online at millerlitebeermints.com on Jan. 12. A second Beer Mint drop is planned for Jan. 19.\nBeer Mints are nonalcoholic, which invites another question: What, exactly, is the point?\nCompany officials explain: They are being marketed as support for those undertaking Dry January, a month of \nalcohol abstention. \nAbout The Daily Money\nEach weekday, The Daily Money delivers the best consumer news from USA TODAY. We break down financial \nnews and provide the TLDR version: how decisions by the Federal Reserve, government and companies impact \nyou.\nThis article originally appeared on USA TODAY: The Daily Money: Americans' purchasing power recovers as wage \ngrowth outpaces inflation\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "The Return of the Magicians; Ross Douthat",
        "media": "The New York Times",
        "time": "March 6, 2023",
        "section": "OPINION",
        "length": "1376 words",
        "byline": "Ross Douthat",
        "story_text": "The Return of the Magicians; Ross Douthat\nThe New York Times \nMarch 2, 2023 Thursday 12:55 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1376 words\nByline: Ross Douthat\nHighlight: Why we are seeing so many attempts to link magic to science.\nBody\nIn the last few weeks, I’ve found myself writing columns that touch on the rapid advance of artificial intelligence, the \nmystery of unidentified flying objects haunting American skies and the enthusiasm in certain circles for taking mind-\naltering substances that yield a feeling, illusory or not, of contact with supernatural-seeming entities.\nThese are very different stories, in a way. The A.I. revolution belongs to the realm of serious and lavishly funded \nscience. The U.F.O. phenomenon hovers on the paranormal and pseudoscientific fringe. The spiritual dimensions \nexplored by users of drugs like DMT belong primarily to the terrain of psychology and religion — either as \nmanifestations of some sort of Jungian unconscious or else, well, as actual spiritual dimensions.\nBut there is a shared spirit in these stories, a common impulse to the quests: the desire to encounter or invent some \nsort of nonhuman consciousness that might help us toward leaps that we can’t make on our own.\nThis impulse is an ancient one: The idea that one might bind a djinn, create a golem or manipulate a god or fairy to \ndo your bidding is inscribed deep in the human imagination. Once upon a time this magician’s art seemed like a \nplausible rival to scientific technique, or a complementary means of mastery over nature; indeed, the scientist and \nthe magician were often overlapping figures in the early modern imagination, blurring together in vocations like \nalchemy and characters like Dr. Faustus.\nThey separated primarily because the scientific method simply worked in a way that magical conjuring did not. Or \nas C.S. Lewis put it 80 years ago, in “The Abolition of Man,” “The serious magical endeavor and the serious \nscientific endeavor are twins: One was sickly and died, the other strong and throve.”\nBut now we are in an era when people talk increasingly about the limits of the scientific endeavor — the increasing \nimpediments to discovering new ideas, the absence of low-hanging scientific fruit, the near impossibility, given the \nlaws of physics as we understand them, of ever spreading human civilization beyond our lonely planet or beyond \nour isolated solar system. Meanwhile, the speculations of scientific theorists and philosophers are reaching beyond \nthe very confines of our universe — to an ever-multiplying multiverse whose branches never touch, or an infinite-\nseeming hall of simulations run by some civilization with godlike capacities relative to ours.\nSo it’s not surprising, in this age of frustration and re-mystification, that our thoughts and efforts might turn back to \nthe magician’s art, in search of powers that might help us escape the limits of our island planet, our paltry life span, \nthe crooked timber of our nature. But not simply back to the old magic of spells and incantations (though there is a \nlot of that these days as well). Instead in the U.F.O. fascination and the A.I. enthusiasm and the drug-enabled \n“psychonaut” explorations, we see attempts to link magic to science, or to deploy science to do magic, using \ntelescopes or chemicals or vast computing powers to discover or create what the old magicians tried to conjure — \nnamely, beings that can enlighten us, elevate us, serve us and usher in the Age of Aquarius, the Singularity or both.\nThe Return of the Magicians Ross Douthat\nThe hardheaded reader will object that one of these examples isn’t like the others. Simple common sense tells us \nthat the U.F.O. speculators are probably not about to get in touch with extraplanetary aliens. The materialist \npremises of modern science reassure us that our hallucinogen-ingesting psychonauts are not actually in touch with \nthe originals of Titania and Oberon, Jupiter or Odin. Whereas the A.I. project seems to be advancing rapidly, with \nno speculative leaps required to see its promise. So why lump it in with the dubious and paranormal? Why invoke \nsorcery to explain a straightforward scientific triumph?\nStipulate for the sake of argument that the A.I. project is more likely to have immediate practical effects than the \nsearch for extraterrestrial life or any drug-aided communion with the spirit realm. There are still good reasons to \nanalyze its efforts in terms of djinns, golems and the like.\nFirst, because this is how its own enthusiasts talk. Here’s Scott Aaronson, a computer scientist at the University of \nTexas, Austin, and one of the most accessible online writers on issues related to computer intelligence, on his own \nreaction to the new chatbots:\nAn alien has awoken — admittedly, an alien of our own fashioning, a golem, more the embodied spirit of all the \nwords on the internet than a coherent self with independent goals. How could our eyes not pop with eagerness to \nlearn everything this alien has to teach? If the alien sometimes struggles with arithmetic or logic puzzles, if its eerie \nflashes of brilliance are intermixed with stupidity, hallucinations, and misplaced confidence … well then, all the more \ninteresting! Could the alien ever cross the line into sentience, to feeling anger and jealousy and infatuation and the \nrest rather than just convincingly playacting them? Who knows? And suppose not: is a p-zombie, shambling out of \nthe philosophy seminar room into actual existence, any less fascinating?\nOr consider a recent Wall Street Journal essay by Henry Kissinger, the former Google C.E.O. Eric Schmidt and \nDaniel Huttenlocher of MIT, which effectively repurposes Arthur C. Clarke’s admonition that “any sufficiently \nadvanced technology is indistinguishable from magic” as a kind of boast. With the emergent forms of A.I., they \nargue, we have created an intelligence that can yield answers the way an oracle might or a Magic 8 Ball: through \nprocesses that are invisible to us, permanently beyond our understanding, so complex as to be indistinguishable \nfrom action in a supernatural mind.\nAs such, they argue, the A.I. revolution represents a fundamental break with Enlightenment science, which “was \ntrusted because each step of replicable experimental processes was also tested, hence trusted.” The knowledge \ngranted us by “generative AI” will be far more mysterious; its truth will need to be “justified by entirely different \nmethods, and it may never become similarly absolute.” Their vision of the human-to-AI relationship evokes Delphic \npriestesses channeling Apollo or mediums reaching through the veil: “We will have to ask continuously: What about \nthe machine has not yet been revealed to us? What obscure knowledge is it hiding?”\nAnd this kind of magical language mostly describes A.I. as an answer machine, Aaronson’s “embodied spirit of all \nthe words on the internet.” It doesn’t even get into the question of whether an A.I. can actually attain consciousness, \nwhere the sorcerous aspect of this project is even more explicit.\nAfter all, we don’t really understand our own consciousness, we haven’t even begun to solve the so-called hard \nproblem of the mind and its relationship to matter. Yet here we are telling ourselves, in hope and also fear, that \nthese machines whose workings we don’t fully understand might make the leap to self-awareness if only we keep \nmaking their processes more sophisticated, more beyond our ken.\nIn this sense what we’re doing resembles a complex incantation, a calling of spirits from Shakespeare’s “vasty \ndeep.” Build a system that imitates human intelligence, make it talk like a person and answer questions like an \nencyclopedia and solve problems through leaps we can’t quite follow, and wait expectantly to see if something \ninfuses itself into the mysterious space where the leaps are happening, summoned by the inviting home that we \nhave made.\nSuch a summoning is most feared by A.I. alarmists, at present, because the spirit might be disobedient, destructive, \na rampaging Skynet bent on our extermination.\nThe Return of the Magicians Ross Douthat\nBut the old stories of the magicians and their bargains, of Faust and his Mephistopheles, suggest that we would be \nwise to fear apparent obedience as well.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTOpinion) and Instagram.\nThis article appeared in print on page SR5.\nLoad-Date: March 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Sep2023",
        "header": "AI MAY REVOLUTIONIZE EMAIL—FOR HACKERS",
        "media": "Wall Street Journal Abstracts",
        "time": "September 8, 2023",
        "section": "B; Pg. 4",
        "length": "24 words",
        "byline": "JAMES RUNDLE",
        "story_text": "AI MAY REVOLUTIONIZE EMAIL—FOR HACKERS\nWall Street Journal Abstracts\nSeptember 7, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 24 words\nByline: JAMES RUNDLE\nBody\nABSTRACT\nGenerative-artificial-intelligence tools promise to fix common red flags used to identify bogus emaILS and texts \nused in phishing attacks (S)\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "A.I. Revolution Is Coming. Just When Is Hard to Say.",
        "media": "The New York Times",
        "time": "September 4, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1276 words",
        "byline": "By Steve Lohr",
        "story_text": "A.I. Revolution Is Coming. Just When Is Hard to Say.\nThe New York Times\nSeptember 4, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1276 words\nByline: By Steve Lohr\nBody\nFrom steam power to the internet, there has always been a lag between technology invention and adoption across \nindustries and the economy.\nLori Beer, the global chief information officer of JPMorgan Chase, talks about the latest artificial intelligence with the \nenthusiasm of a convert. She refers to A.I. chatbots like ChatGPT, with its ability to produce everything from poetry \nto computer programs, as ''transformative'' and a ''paradigm shift.'' \n  But it's not coming soon to the nation's largest bank. JPMorgan has blocked access to ChatGPT from its \ncomputers and told its 300,000 workers not to put any bank information into the chatbot or other generative A.I. \ntools.\n  For now, Ms. Beer said, there are too many risks of leaking confidential data, questions about how the data is \nused and about the accuracy of the A.I.-generated answers. The bank has created a walled-off, private network to \nallow a few hundred data scientists and engineers to experiment with the technology. They are exploring uses like \nautomating and improving tech support and software development.\n  Across corporate America, the perspective is much the same. Generative A.I., the software engine behind \nChatGPT, is seen as an exciting new wave of technology. But companies in every industry are mainly trying out the \ntechnology and thinking through the economics. Widespread use of it at many companies could be years away.\n  Generative A.I., according to forecasts, could sharply boost productivity and add trillions of dollars to the global \neconomy. Yet the lesson of history, from steam power to the internet, is that there is a lengthy lag between the \narrival of major new technology and its broad adoption -- which is what transforms industries and helps fuel the \neconomy.\n  Take the internet. In the 1990s, there were confident predictions that the internet and the web would disrupt the \nretailing, advertising and media industries. Those predictions proved to be true, but that was more than a decade \nlater, well after the dot-com bubble had burst.\n  Over that time, the technology improved and costs dropped, so bottlenecks fell away. Broadband internet \nconnections eventually became commonplace. Easy-to-use payment systems were developed. Audio and video \nstreaming technology became far better.\n  Fueling the development were a flood of money and a surge of entrepreneurial trial and error.\n  ''We're going to see a similar gold rush this time,'' said Vijay Sankaran, chief technology officer of Johnson \nControls, a large supplier of building equipment, software and services. ''We'll see a lot of learning.''\nA.I. Revolution Is Coming. Just When Is Hard to Say.\n  The investment frenzy is well underway. In the first half of 2023, funding for generative A.I. start-ups reached \n$15.3 billion, nearly three times the total for all of last year, according to PitchBook, which tracks start-up \ninvestments.\n  Corporate technology managers are sampling generative A.I. software from a host of suppliers and watching to \nsee how the industry shakes out.\n  In November, when ChatGPT was made available to the public, it was a ''Netscape moment'' for generative A.I., \nsaid Rob Thomas, IBM's chief commercial officer, referring to Netscape's introduction of the browser in 1994. ''That \nbrought the internet alive,'' Mr. Thomas said. But it was just a beginning, opening a door to new business \nopportunities that took years to exploit.\n  In a recent report, the McKinsey Global Institute, the research arm of the consulting firm, included a timeline for \nthe widespread adoption of generative A.I. applications. It assumed steady improvement in currently known \ntechnology, but not future breakthroughs. Its forecast for mainstream adoption was neither short nor precise, a \nrange of eight to 27 years.\n  The broad range is explained by plugging in different assumptions about economic cycles, government regulation, \ncorporate cultures and management decisions.\n  ''We're not modeling the laws of physics here; we're modeling economics and societies, and people and \ncompanies,'' said Michael Chui, a partner at the McKinsey Global Institute. ''What happens is largely the result of \nhuman choices.''\n  Technology diffuses across the economy through people, who bring their skills to new industries. A few months \nago, Davis Liang left an A.I. group at Meta to join Abridge, a health care start-up that records and summarizes \npatient visits for physicians. Its generative A.I. software can save doctors from hours of typing up patient notes and \nbilling reports.\n  Mr. Liang, a 29-year-old computer scientist, has been an author on scientific papers and helped build so-called \nlarge language models that animate generative A.I.\n  His skills are in demand these days. Mr. Liang declined to say, but people with his experience and background at \ngenerative A.I. start-ups are typically paid a base salary of more than $200,000, and stock grants can potentially \ntake the total compensation far higher.\n  The main appeal of Abridge, Mr. Liang said, was applying the ''superpowerful tool'' of A.I. in health care and \n''improving the working lives of physicians.'' He was recruited by Zachary Lipton, a former research scientist in \nAmazon's A.I. group, who is an assistant professor at Carnegie Mellon University. Mr. Lipton joined Abridge early \nthis year as chief scientific officer.\n  ''We're not working on ads or something like that,'' Mr. Lipton said. ''There is a level of fulfillment when you're \ngetting thank-you letters from physicians every day.''\n  Significant new technologies are flywheels for follow-on innovation, spawning start-ups that build applications to \nmake the underlying technology useful and accessible. In its early years, the personal computer was seen as a \nhobbyist's plaything. But the creation of the spreadsheet program -- the ''killer app'' of its day -- made the PC an \nessential tool in business.\n  Sarah Nagy led a data science team at Citadel, a giant investment firm, in 2020 when she first tinkered with GPT-\n3. It was more than two years before OpenAI released ChatGPT. But the power of the fundamental technology was \napparent in 2020.\n  Ms. Nagy was particularly impressed by the software's ability to generate computer code from text commands. \nThat, she figured, could help democratize data analysis inside companies, making it broadly accessible to \nbusinesspeople instead of an elite group.\nA.I. Revolution Is Coming. Just When Is Hard to Say.\n  In 2021, Ms. Nagy founded Seek AI to pursue that goal. The New York start-up now has about two dozen \ncustomers in the technology, retail and finance industries, mostly working on pilot projects.\n  Using Seek AI's software, a retail manager, for example, could type in questions about product sales, ad \ncampaigns and online versus in-store performance to guide marketing strategy and spending. The software then \ntransforms the words into a computer-coded query, searches the company's storehouse of data, and returns \nanswers in text or retrieves the relevant data.\n  Businesspeople, Ms. Nagy said, can get answers almost instantly or within a day instead of a couple of weeks, if \nthey have to make a request for something that requires the attention of a member of a data science team.\n  ''At the end of the day, we're trying to reduce the time it takes to get an answer or useful data,'' Ms. Nagy said.\n  Saving time and streamlining work inside companies are the prime early targets for generative A.I. in most \nbusinesses. New products and services will come later.\n  This year, JPMorgan trademarked IndexGPT as a possible name for a generative A.I.-driven investment advisory \nproduct.\n  ''That's something we will look at and continue to assess over time,'' said Ms. Beer, the bank's tech leader. ''But it's \nnot close to launching yet.''\nhttps://www.nytimes.com/2023/08/29/technology/ai-revolution-time.html\nGraphic\n \nPHOTOS: Sarah Nagy left the investment firm Citadel to found the artificial intelligence start-up Seek AI. ''We're \ntrying to reduce the time it takes to get an answer or useful data,'' she said. Davis Liang, right, left the A.I. group at \nMeta to join Abridge, a health care start-up that is trying to help doctors with their paperwork. (PHOTOGRAPHS BY \nEVELYN FREJA FOR THE NEW YORK TIMES\n GELOY CONCEPCION FOR THE NEW YORK TIMES) (B3) This article appeared in print on page B1, B3.               \nLoad-Date: September 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Microsoft Makes a New Push Into Smaller A.I. Systems",
        "media": "The New York Times",
        "time": "April 25, 2024",
        "section": "TECHNOLOGY",
        "length": "848 words",
        "byline": "Karen Weise and Cade Metz Karen Weise writes about technology and is based in Seattle. Her coverage",
        "story_text": "Microsoft Makes a New Push Into Smaller A.I. Systems\nThe New York Times \nApril 23, 2024 Tuesday 22:54 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 848 words\nByline: Karen Weise and Cade Metz Karen Weise writes about technology and is based in Seattle. Her coverage \nfocuses on Amazon and Microsoft, two of the most powerful companies in America. Cade Metz writes about \nartificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.\nHighlight: The company that has invested billions in generative A.I. pioneers like OpenAI says giant systems \naren’t necessarily what everyone needs.\nBody\nThe company that has invested billions in generative A.I. pioneers like OpenAI says giant systems aren’t \nnecessarily what everyone needs.\nIn the dizzying race to build generative A.I. systems, the tech industry’s mantra has been bigger is better, no \nmatter the price tag.\nNow tech companies are starting to embrace smaller A.I. technologies that are not as powerful but cost a lot less. \nAnd for many customers, that may be a good trade-off.\nOn Tuesday, Microsoft introduced three smaller A.I. models that are part of a technology family the company has \nnamed Phi-3. The company said even the smallest of the three performed almost as well as GPT-3.5, the much \nlarger system that underpinned OpenAI’s ChatGPT chatbot when it stunned the world upon its release in late 2022.\nThe smallest Phi-3 model can fit on a smartphone, so it can be used even if it’s not connected to the internet. And it \ncan run on the kinds of chips that power regular computers, rather than more expensive processors made by \nNvidia.\nBecause the smaller models require less processing, big tech providers can charge customers less to use them. \nThey hope that means more customers can apply A.I. in places where the bigger, more advanced models have \nbeen too expensive to use. Though Microsoft said using the new models would be “substantially cheaper” than \nusing larger models like GPT-4, it did not offer specifics.\nThe smaller systems are less powerful, which means they can be less accurate or sound more awkward. But \nMicrosoft and other tech companies are betting that customers will be willing to forgo some performance if it means \nthey can finally afford A.I.\nCustomers imagine many ways to use A.I., but with the biggest systems “they’re like, ‘Oh, but you know, they can \nget kind of expensive,’” said Eric Boyd, a Microsoft executive. Smaller models, almost by definition, are cheaper to \ndeploy, he said.\nMr. Boyd said some customers, like doctors or tax preparers, could justify the costs of the larger, more precise A.I. \nsystems because their time was so valuable. But many tasks may not need the same level of accuracy. Online \nadvertisers, for example, believe they can better target ads with A.I., but they need lower costs to be able to use the \nsystems regularly.\nMicrosoft Makes a New Push Into Smaller A.I. Systems\n“I want my doctor to get things right,” Mr. Boyd said. “Other situations, where I am summarizing online user reviews, \nif it’s a little bit off, it’s not the end of the world.”\nChatbots are driven by large language models, or L.L.M.s, mathematical systems that spend weeks analyzing \ndigital books, Wikipedia articles, news articles, chat logs and other text culled from across the internet. By \npinpointing patterns in all that text, they learn to generate text on their own.\nBut L.L.M.s store so much information, retrieving what is needed for each chat requires considerable computing \npower. And that is expensive.\nWhile tech giants and start-ups like OpenAI and Anthropic have been focused on improving the largest A.I. \nsystems, they are also competing to develop smaller models that offer lower prices. Meta and Google, for instance, \nhave released smaller models over the past year.\nMeta and Google have also “open sourced” these models, meaning anyone can use and modify them free of \ncharge. This is a common way for companies to get outside help improving their software and to encourage the \nlarger industry to use their technologies. Microsoft is open sourcing its new Phi-3 models, too.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nAfter OpenAI released ChatGPT, Sam Altman, the company’s chief executive, said the cost of each chat was \n“single-digits cents” — an enormous expense considering what popular web services like Wikipedia are serving up \nfor tiny fractions of a cent.\nNow, researchers say their smaller models can at least approach the performance of leading chatbots like ChatGPT \nand Google Gemini. Essentially, the systems can still analyze large amounts of data but store the patterns they \nidentify in a smaller package that can be served with less processing power.\nBuilding these models are a trade-off between power and size. Sébastien Bubeck, a researcher and vice president \nat Microsoft, said the company built its new smaller models by refining the data that was pumped into them, working \nto ensure that the models learned from higher-quality text.\nPart of this text was generated by the A.I. itself — what is known as “synthetic data.” Then human curators worked \nto separate the sharpest text from the rest.\nMicrosoft has built three different small models: Phi-3-mini, Phi-3-small and Phi-3-medium. Phi-3-mini, which will be \navailable on Tuesday, is the smallest (and cheapest) but the least powerful. Phi-3 Medium, which is not yet \navailable, is the most powerful but the largest and most expensive.\nMaking systems small enough to go directly on a phone or personal computer “will make them a lot faster and order \nof magnitudes less expensive,” said Gil Luria, an analyst at the investment bank D.A. Davidson. \nThis article appeared in print on page B6.\nLoad-Date: April 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Investors Flock to Hear What Buffett Will Bet on Next",
        "media": "The New York Times",
        "time": "May 4, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6; DEALBOOK NEWSLETTER",
        "length": "2011 words",
        "byline": "By Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren",
        "story_text": "Investors Flock to Hear What Buffett Will Bet on Next\nThe New York Times\nMay 4, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6; DEALBOOK NEWSLETTER\nLength: 2011 words\nByline: By Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren \nHirsch and Ephrat Livni\nBody\nBerkshire Hathaway shareholders will gather in Omaha for the conglomerate's annual meeting on Saturday, with \nquestions about the company's future.\nA different kind of Berkshire annual meeting \n  Tens of thousands of investors are flocking to Omaha this weekend, which can mean only one thing: It's time for \nBerkshire Hathaway's annual shareholder meeting, dubbed the ''Woodstock for capitalists.''\n  The allure had long been the chance to see Warren Buffett and Charlie Munger live, answering attendees' \nquestions with a time-tested buddy-comedy act. But this year's event will be the first without Munger, who died in \nNovember at age 99 -- and comes amid growing questions about Berkshire post-Buffett, who's 93.\n  Buffett will have a different crew answering questions alongside him on Saturday. Berkshire's vice chairmen, Greg \nAbel and Ajit Jain, will be on hand for much of the day. Shareholders most likely will be focused on what Abel, \nBuffett's appointed successor as C.E.O. and the head of the conglomerate's noninsurance operations, has to say.\n  In Buffett's annual letter to investors, he noted challenges to Berkshire's biggest businesses, including the BNSF \nrailroad (falling shipment volumes) and its utility business (forest fires). Last month, the company's enormous real \nestate brokerage, HomeServices of America, also agreed to pay $250 million to settle lawsuits over inflated home-\nsales commissions.\n  Shareholders may want to hear what Jain, as the longtime mastermind behind Berkshire's vital reinsurance \noperations, has to say about the business that makes most of Buffett's investing possible.\n  Expect lots of questions about Berkshire's signature investments. The company's stock performance this year has \noutpaced that of Apple (one of Buffett's biggest investments; more on that below), Microsoft and Tesla, as well as \nthe S&P 500.\n  But with interest rates remaining higher for longer and many tech giants' shares losing steam, shareholders will \nwant to know where Buffett sees future opportunities. That may include the company's investments in the oil and \ngas producer Occidental Petroleum and five Japanese trading houses, whose stocks have soared.\n  Attendees may also want Buffett to explain what may be his most consequential admission in recent years: \nBerkshire is now so big that it's unlikely to find any major acquisitions -- the historical source of Buffett's outsize \ninvestment returns -- to spend its $163 billion cash pile on. ''All in all, we have no possibility of eye-popping \nperformance,'' he wrote in this year's annual letter.\nInvestors Flock to Hear What Buffett Will Bet on Next\n  And there may be questions about Buffett's stock-picking lieutenants. Todd Combs and Ted Weschler have been \nmanaging portions of Berkshire's investment portfolio for years. But their performance has long lagged behind that \nof Buffett himself and the S&P 500, according to the Financial Times, raising questions about Berkshire's future \nvalue proposition.\n  HERE'S WHAT'S HAPPENING \n  The Justice Department's investigation into TD Bank reportedly focuses on fentanyl. Investigators found that \nChinese drug traffickers and crime groups used the Canadian bank to launder hundreds of millions in illicit drug \nproceeds, The Wall Street Journal reports. The accusation adds to the scrutiny of the bank's anti-money laundering \npractices, which is at the center of other regulatory investigations in the U.S. and Canada.\n  President Biden makes his first public comments on campus protests. Biden condemned the violence on Thursday \nwhile defending the right to demonstrate peacefully. The president is eager to keep the issue from eroding his \nsupport with young voters but he has been criticized by Democrats and Republicans for not speaking out.\n  Arguments in the Google antitrust case conclude on Friday. The Justice Department says the company competed \nunfairly in making deals with Apple and other companies to lock in search functionality on smartphones and web \nbrowsers. Google counters that it earned its market edge through innovation. The trial is the biggest challenge yet \nto Big Tech's dominance, and the judge's verdict, expected later this year, could change how Google does \nbusiness.\n  A mega buyback lifts Apple\n  After a rocky stretch, Apple is predicting a return to growth in 2024. That, and an unprecedented $110 billion \nshare-buyback promise, have lifted shares by more than 6 percent in premarket trading this morning despite \nanother sales decline and big worries about China.\n  Apple is the latest Big Tech giant to report results in recent weeks -- next up is Nvidia on May 22. Investors are \nzeroing in on when huge investments, especially in artificial intelligence, will pay off.\n  Apple's rally belies a litany of challenges, including a sluggish market for smartphones and wearables, intensifying \ncompetition in China, heightened regulatory scrutiny, a lackluster debut for the Vision Pro headset and questions \nabout its A.I. efforts. (The company is expected to reveal how it will incorporate A.I. into its devices at a developers \nconference next month.)\n  Add it up, and sales have declined at the king of growth stocks in five of the past six quarters and shares are down \nnearly 7 percent this year. A big question on Wall Street: What will Warren Buffett's Berkshire Hathaway do with its \n$157 billion Apple stake?\n  The big takeaways from Thursday's earnings report:\n  Sales fell 4 percent on an annualized basis to $90.8 billion last quarter, and profit dipped by 2 percent to $23.6 \nbillion. Both reductions exceeded analysts expectations.\n  Apple reported $16.4 billion of revenues in Greater China, which includes the mainland, Hong Kong and Taiwan. \nThat's up compared to the previous quarter, driven by the iPhone. Investors are worried about Apple's hold on the \nworld's No. 2 smartphone market, where consumers are shifting to local rivals amid a wider crackdown on foreign-\nmade tech. \n  The company also sought to reassure on generative A.I. Apple isn't investing the vast sums that rival tech giants \nMicrosoft, Amazon and Meta, are spending on the technology. That has helped protect its profit outlook, but it has \nalso left investors unsure about its strategy.\nInvestors Flock to Hear What Buffett Will Bet on Next\n  Tim Cook, Apple's C.E.O., tried to express confidence that the company would catch up by deploying A.I. across \nits devices and services. ''Apple's unique combination of seamless hardware, software and services'' -- including its \nin-house chips -- will give the company an edge, he told analysts.\n  The Paramount race heads to a cliffhanger \n  After weeks of anticipation, Sony Pictures Entertainment and Apollo Global Management have made it official: \nThey've formally expressed interest in buying Paramount for about $26 billion.\n  That puts extra pressure on the Paramount board's special committee that's evaluating the company's future. \nThose directors are already facing a deadline on Friday for exclusive deal talks with Skydance, the studio led by the \ntech scion David Ellison (and the preferred suitor of Paramount's controlling shareholder, Shari Redstone).\n  Is the Sony-Apollo bid a game-changer? Sony has deep experience in entertainment, with Apollo providing a big \nslug of capital. Sony plans to be the majority shareholder, making Paramount a division within its broader film and \ntelevision empire and putting franchises like ''Spider-Man'' and ''Mission: Impossible'' under one roof. \n  That said, the $26 billion figure is preliminary: Sony and Apollo haven't started due diligence, which could affect \ntheir ultimate takeover proposal.\n  There are regulatory concerns, including whether the Sony-Apollo bid would be hamstrung by federal restrictions \non foreign ownership of broadcast networks like Paramount's CBS. \n  Apollo and Sony believe workarounds are available; one could be having Apollo, which has already been \napproved for network ownership after acquiring Cox Media Group, own the license for CBS. Still, the F.C.C. blocked \na takeover bid of the broadcaster Tegna because of Apollo's role in financing that transaction.\n  What happens next? Here are some possibilities:\n  Paramount's special committee signs a deal with Skydance that includes a low breakup fee and a so-called go-\nshop provision that lets it negotiate with Sony and Apollo. That would likely give Skydance a chance to match, \nsetting up a bidding war and, if Sony and Apollo won, a mandatory payout to Skydance. (It could also lead to a \nlower price than what a traditional auction would have fetched, giving already irate shareholders more reason to \ngripe -- or sue.)\n  Paramount could let the exclusivity period with Skydance expire at midnight tonight and open its books to Sony \nand Apollo. That, of course, risks the Sony-Apollo duo not making a formal bid -- and Skydance walking away.\n  $76 billion \n  -- What the N.B.A. is set to get from two new broadcasting agreements with Disney and Amazon, three times the \nsize of its current deal, according to Bloomberg. The league is also reportedly considering another package with \nWarner Bros. Discovery and Comcast.\n  The F.T.C.'s surprise for Big Oil \n  Exxon Mobil's $60 billion purchase of Pioneer Natural Resources is set to close on Friday. The F.T.C. gave its \nblessing, but the regulator extracted an unusual concession: It barred Scott Sheffield, the shale oil producer's \nformer C.E.O., from joining Exxon's board, saying he colluded with OPEC to manipulate oil prices.\n  The accusations could lead to criminal charges and send a shudder through the industry as deal making hits \nrecord highs.\n  The F.T.C.'s case: The agency said that its merger review found Sheffield's text messages, public statements and \nin-person meetings with OPEC officials were evidence he tried to distort the global market for oil prices and to profit \nfrom it. ''American consumers shouldn't pay unfair prices at the pump simply to pad a corporate executive's \nInvestors Flock to Hear What Buffett Will Bet on Next\npocketbook,'' said Kyle Mach, the F.T.C.'s deputy competition chief. The F.T.C. reportedly plans to refer Sheffield's \ncase to the Justice Department.\n  Pioneer said the F.T.C. doesn't understand the oil industry. It disputed the accusations but said it and Sheffield \nwouldn't do anything to stop the Exxon deal going through.\n  Others accused the regulator of overreach. Eric Grannon, an antitrust lawyer at White & Case, told The Wall \nStreet Journal that using a merger-review process to target an executive wasn't ''principled antitrust enforcement.''\n  It's another case of the F.T.C. chair, Lina Khan, pushing antitrust policy boundaries. The F.T.C. doesn't have the \nauthority to make criminal charges. But in 2021, after she became chair, the regulator vowed to expand its \ncorporate referral program to other agencies that do. \n  M.&A. in the oil sector hit a record in the first quarter after a bumper 2023. But some analysts warn about a chill on \nactivity if the F.T.C. takes a tougher stance on mergers.  ''Any C.E.O. contemplating a merger will have to worry \nabout being singled out the way Sheffield was,'' James Lucier, an analyst at Capital Alpha Partners, wrote in a client \nnote Thursday.\n  THE SPEED READ \n  Deals\n  The commodities giant Glencore is reportedly considering a takeover offer for Anglo American, potentially setting \nup a bidding war with BHP. (Reuters)\n  U.S. Steel pushed back the expected close of its $14 billion sale to Nippon Steel to later this year, amid political \nopposition to the transaction. (Bloomberg)\n  Policy\n  The S.E.C. ended its inquiry into trades by Barry Diller and David Geffen in Activision Blizzard stock before the \nvideo game company announced its sale to Microsoft. (WSJ)\n  A senior TikTok executive told advertisers that the video app wasn't ''backing down'' as it fights a U.S. government \neffort to force its sale, under threat of a ban. (Deadline)\n  Best of the rest\n  Chubb, which insured the Francis Scott Key Bridge in Baltimore that collapsed in March, will pay Maryland $350 \nmillion, the full amount of the state's coverage. (WSJ)\n  ''A mystery chatbot came and went. It's probably a new OpenAI product'' (Axios)\n  We'd like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com\nhttps://www.nytimes.com/2024/05/03/business/dealbook/warren-buffett-berkshire-hathaway-agm.html\nGraphic\n \nPHOTO: Last year's Berkshire Hathaway's annual shareholder meeting, an event dubbed the ''Woodstock for \ncapitalists.'' (PHOTOGRAPH BY RACHEL MUMMEY/REUTERS) This article appeared in print on page B6.               \nInvestors Flock to Hear What Buffett Will Bet on Next\nLoad-Date: May 4, 2024"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "A.I. in Class: What Should Teachers Do?",
        "media": "The New York Times",
        "time": "September 7, 2023",
        "section": "Section A; Column 0; Editorial Desk; Pg. 27; LETTERS",
        "length": "1187 words",
        "byline": " ",
        "story_text": "A.I. in Class: What Should Teachers Do?\nThe New York Times\nSeptember 7, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Editorial Desk; Pg. 27; LETTERS\nLength: 1187 words\nBody\nTo the Editor: \n  Re ''How Schools Can Cope and Grow When Their Students Are Using A.I.,'' by Kevin Roose (The Shift column, \nBusiness, Aug. 29):\n  Mr. Roose's suggestion that educators embrace generative A.I. and view it as an ''opportunity'' or ''classroom \ncollaborator,'' not as an ''enemy,'' seems typical of a tech enthusiast.\n  Of course, he is right that university professors like me will have to adjust our assignments to involve more in-class \nexams, classroom work and scaffolded projects with multiple check-ins. As a history professor, I also consciously \nassign books that are not available on the internet to limit the ability of A.I. tools to respond to essay prompts. For \nA.I. is the enemy.\n  What I want, most of all, is for students to read books that help them appreciate the complexity of the past, to \ndigest factual information and to think deeply about the subject. Struggling to find the words and structure to \nexpress one's ideas is a catalyst for thought, as any writer knows.\n  What can make the college experience transformative is the learning that comes from reflection. Shortcuts, \nwhether traditional plagiarism or this new form of plagiarism, contribute to an atmosphere of intellectual \ndisengagement.\n  Julie HesslerEugene, Ore.\n  To the Editor:\n  Kevin Roose builds from a flawed premise: All kids are using A.I., so schools should accept that reality.\n  We attempted this strategy with cellphones, as teachers tried to use them ''productively'' for classroom polls and \nweb searches and other such activities. It turns out that letting phones in was a disaster we are still trying to \ncontain.\n  Let's not make the same mistake. This doesn't mean we should never let A.I. in, but we should at least start to do \nso carefully.\n  Jeremy GlazerPhiladelphiaThe writer is a former high school teacher and a professor at the College of Education \nat Rowan University.\n  To the Editor:\nA.I. in Class: What Should Teachers Do?\n  Reading Kevin Roose's column inspired a simple thought experiment. What if a research biologist had developed \na highly innovative breed of genetically engineered seeds and, instead of carefully testing them in a restricted area, \nwent out and scattered them at random across the entire countryside? Such a reckless researcher would face a \nfirestorm of condemnation.\n  Yet isn't that exactly what the developers of generative A.I. products have done to the landscape of education? \nWith little notice and zero safeguards, they've released a product that makes mass cheating easy and often difficult \nto detect.\n  The effects on our educational ecosystem are potentially devastating. Where is the outrage over such callous \ndisregard for the consequences of their actions?\n  Conrad BergerHyattsville, Md.\n  A Nobel Physicist, on the Nature of the Universe\n  To the Editor:\n  ''The Crisis in Cosmology,'' by Adam Frank and Marcelo Gleiser (Opinion guest essay, Sept. 3), gives a good \npicture of exciting issues we are pursuing in cosmology, the study of the large-scale nature of our expanding \nuniverse.\n  But Dr. Frank and Dr. Gleiser do not mention that the standard theory passes a broad variety of demanding tests. \nYou can read about them in my 2022 book, ''The Whole Truth.''\n  These tests make a good case that our cosmology is a good approximation to what happened. But it is important \nto understand that the standard models of dark matter and dark energy seem too simple to be the full story. I should \nknow: I introduced these ideas to cosmology a quarter of a century ago to make the theory we had then better fit \nthe evidence.\n  I meant it to be at best a rough working picture. I am surprised at how well it has done, but I expect that it will be \nreplaced by a better theory found with the guidance of problems such as the 10 percent difference between two \nmeasures of the rate of expansion of the universe, and our poor understanding of how the galaxies formed.\n  Adjust the theories of dark matter and dark energy and you adjust the picture of how galaxies formed and the \nmethod of measuring the rate of expansion of the universe. This can be done without seriously affecting the \nsuccessful cosmological tests of what happened on larger scales.\n  The community hope is for more problems that might guide us to an even better theory. It is good to question \nauthority, but I do not see evidence of a crisis in cosmology.\n  P. James E. PeeblesPrinceton, N.J.The writer, an emeritus professor at Princeton, shared the Nobel Prize in \nPhysics in 2019.\n  Trump's Jury and '12 Angry Men'\n  To the Editor:\n  Re ''Trump's Fate Belongs in the Hands of 12 Ordinary Citizens,'' by Jesse Wegman (Opinion, nytimes.com, Aug. \n27):\n  Mr. Wegman writes about the benefits of trial by jury and invokes the film ''12 Angry Men.'' Henry Fonda's \ncharacter went to great lengths to persuade other jurors to acquit because unless the verdict is unanimous, the \nresult is a hung jury and a mistrial. That may lead to the case being retried or dropped, or for the defendant to \naccept a plea deal.\nA.I. in Class: What Should Teachers Do?\n  Donald Trump, for whom delay of any verdict until after the election is a core strategy, would declare anything \nshort of a conviction a total vindication, even though an acquittal it is not.\n  Whether because of fear of being doxxed, attacked or fired, or a bribe or threat, or just pure partisan affiliation, \nthere is nothing to stop one juror from simply voting not to convict based on dubious ''reasonable doubt.'' Such a \njuror need not attempt to persuade other jurors.\n  Viewed this way, the real purpose of Mr. Trump's statements and actions is shown: to find one person in 12 in \nthose four juries who will vote not to convict him. Through this lens every statement made by Mr. Trump is a \npremeditated action to taint the jury pool.\n  In ''12 Angry Men,'' justice is predicated on the impartiality of the jurors toward the defendant. That is impossible in \nthis situation.\n  Michael DeeDallas\n  Public Funding for Birth Control\n  To the Editor:\n  Re ''G.O.P. Lawmakers Pivot to Birth Control'' (news article, Aug. 31):\n  Last month, the South Carolina Supreme Court upheld a six-week abortion ban, following 21 other states that \nhave moved to restrict abortion or ban it entirely. Amid these restrictions, Republicans, especially Republican \nwomen, have expressed their support for contraception.\n  As the leader of one of the largest contraception access initiatives in the U.S., I view their support as welcome. In \nthe post-Roe era, we have seen demand for birth control surge; in just the first six months of 2023, my organization \nhas served over 50,000 women seeking free or low-cost contraception in South Carolina.\n  We can't do this alone. We need government at the state, city and local levels to increase funding for programs \nthat make birth control for women not only more accessible, but also more affordable.\n  Evidence shows that public funding for birth control helps women gain equal access to birth control tailored to their \nspecific needs, leading to better health outcomes and substantial cost savings.\n  It's time for our leaders to step up. Words are nice; action is better.\n  Bonnie KappColumbia, S.C.The writer is the president and C.E.O. of New Morning.\nhttps://www.nytimes.com/2023/09/06/opinion/letters/ai-schools.html\nGraphic\n \nThis article appeared in print on page A27.               \nLoad-Date: September 7, 2023"
    },
    {
        "file_name": "money_gains_and_AI_rights;_Board_members_from_Hollywood's_actors_union_Nov2023",
        "header": "Hollywood actors union board approves strike-ending deal as leaders tout",
        "media": "money gains and AI rights; Board members from Hollywood's actors union",
        "time": "November 11, 2023",
        "section": "NATION WORLD",
        "length": "928 words",
        "byline": "ANDREW DALTON",
        "story_text": "Hollywood actors union board approves strike-ending deal as leaders tout \nmoney gains and AI rights; Board members from Hollywood's actors union \nhave voted to approve the deal with studios that ended their strike after \nnearly four months\nDayton Daily News (Ohio)\nNovember 11, 2023 Saturday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 928 words\nByline: ANDREW DALTON\nBody\nBoard members from Hollywood's actors union voted Friday to approve the deal with studios that ended their strike \nafter nearly four months, with the union's leadership touting the gains made in weeks of methodical negotiations.\nDuncan Crabtree-Ireland, Screen Actors Guild-American Federation of Television and Radio Artists' executive \ndirector and chief negotiator, announced at an afternoon news conference that the tentative agreement was \napproved with 86% of the vote. \nThe three-year contract agreement next goes to a vote from the union's members, who are now learning what they \nearned through spending the summer and early fall on picket lines instead of film and television sets. That vote \nbegins Tuesday and continues into December. \nCrabtree-Ireland said the deal \"will keep the motion picture industry sustainable as a profession for working class \nperformers.\" \nSAG-AFTRA President Fran Drescher said the studios believed they could outlast actors by waiting more than two \nmonths before initiating talks. \n\"What were they doing? Were they trying to smoke us out?\" she said. \"Well honey, I quit smoking a long time ago.\" \nCrabtree-Ireland and Drescher would not give specifics on who disapproved of the deal, and why. The board vote \nwas weighted, so it's not immediately clear how many people voted against approval. \nOverall, the happy scene at SAG-AFTRA's Los Angeles headquarters was as different as can be from the defiant, \nangry tone of a news conference in the same room in July, when guild leaders announced that actors would join \nwriters in a historic strike that shook the industry. \nThe successful vote from the board, whose members include actors Billy Porter, Jennifer Beals, Sean Astin and \nSharon Stone, was expected, as many of the same people were on the committee that negotiated the deal. And it \nwas in some ways drained of its drama by union leaders declaring the strike over as soon as the tentative deal was \nreached with the Alliance of Motion Picture and Television Producers on Wednesday, rather than waiting for the \napproval. \nBut it was still an essential step in returning to business as usual in Hollywood, if there is any such thing. \nHollywood actors union board approves strike-ending deal as leaders tout money gains and AI rights Board \nmembers from Hollywood's actors union have voted to app....\nActors need not wait for the ratification to start acting again  \"in fact some of them already have,\" Crabtree-Ireland \nsaid. \nContract provisions surrounding the control of artificial intelligence were among the last sticking points in the \nagreement. \n\"AI was a dealbreaker,\" Drescher said. \"If we didn't get that package, then what are we doing to protect our \nmembers?\" \nHere's a look at those and some of the other contract gains that union leaders outlined Friday. A more detailed look \nthe terms will come next week, they said. \nON ARTIFICIAL INTELLIGENCE \nProductions must get the informed consent of actors whose digital replicas are used. That means there will be a \nreasonably specific description of how an actor's image will just be used  a vague, boilerplate sentence will not \nsuffice. This includes the consent of background actors used for crowd scenes and similar simulations. \nWhen artificial intelligence is used for a movie or show an actor is already working on, they will be compensated the \nsame as if they'd actually performed what their digital likeness does, the guild said. Companies will need to \nnegotiate new permission to use a likeness in a new project. \n\"The caveat to the consent is that it's only for the one job,\" Drescher told The Associated Press in an interview. \n\"They have to come back if they want to use it for something else. That's kind of huge.\" \nWhen it's a licensed image on a show where an actor, living or dead, is not otherwise performing, the license \nholders have a right to negotiate a rate. \nIn a hard-won provision that SAG-AFTRA said came on the final day of negotiations, when generative AI is used to \ncreate a synthetic character from the images of several different performers  be it Denzel Washington's eyes or \nMargot Robbie's hair  consent must be obtained from every person used, and the union must be able to negotiate \npay for each. \nON COMPENSATION \nThe contract includes a creation of a new fund to pay performers for future viewings of their work on streaming \nservices, in addition to traditional residuals paid for the showing of movies or series. The issue derailed talks for \nmore than a week last month before studios returned to the table. \n\"They leaned pretty far because they were willing to accept that a new stream of revenue had to be established,\" \nDrescher told the AP. \nA 7% general wage increase is effective immediately, with another 4% hike in July, and another 3.5% a year after \nthat. \nAn 11% increase for background actors is effective immediately, with the same 4% and 3.5% increases in the \ncoming years. \nThere will also be more money for the relocation of actors who have to move to appear in TV series. \nOTHER FIRST-TIME GAINS \nProductions will be required to hire intimacy coordinators for any scenes involving nudity or simulated sex. While \nthis has become an increasingly common practice in recent years, it had not been mandatory. \nHollywood actors union board approves strike-ending deal as leaders tout money gains and AI rights Board \nmembers from Hollywood's actors union have voted to app....\nDancers asked to sing or singers asked to dance will be fully compensated for both skills, rather than productions \ngetting a two-for-one when performers do double duty. \nSets must have proper hair and makeup artists for all performers who need them, and those artists must be able to \nproperly serve the particular ethnicities and appearances of the performers. \nThe agreement also includes more protections and funding for the self-taping of auditions. \nAssociated Press journalist Krysta Fauria contributed reporting.\nGraphic\n \nSAG-AFTRA President Fran Drescher, hugs a member of the TV/Theatrical Negotiating Committee member in \ncelebration after a news conference at the SAG-AFTRA offices in Los Angeles on Friday, Nov. 10, 2023. (AP \nPhoto/Richard Vogel)\nLoad-Date: November 11, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "PWC TO SPEND $1 BILLION ON AI",
        "media": "Wall Street Journal Abstracts",
        "time": "April 28, 2023",
        "section": "B; Pg. 11",
        "length": "39 words",
        "byline": "ANGUS LOTEN",
        "story_text": "PWC TO SPEND $1 BILLION ON AI\nWall Street Journal Abstracts\nApril 27, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 11\nLength: 39 words\nByline: ANGUS LOTEN\nBody\nABSTRACT\nPricewaterhouseCoopers LLP plans to invest $1 billion in generative artificial-intelligence technology in its US \noperations over next three years, recruiting more AI workers and training existing staff in AI capabilities; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: April 28, 2023"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_May2023",
        "header": "OPENAI CEO SET TO TESTIFY BEFORE CONGRESS",
        "media": "Pittsburgh Post-Gazette",
        "time": "May 11, 2023",
        "section": "BUSINESS; Pg. D-1",
        "length": "206 words",
        "byline": "Brian Fung CNN",
        "story_text": "OPENAI CEO SET TO TESTIFY BEFORE CONGRESS\nPittsburgh Post-Gazette\nMay 11, 2023 Thursday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. D-1\nLength: 206 words\nByline: Brian Fung CNN\nBody\nOpenAI CEO Sam Altman will testify before Congress next Tuesday as lawmakers increasingly scrutinize the risks \nand benefits of artificial intelligence, according to a Senate Judiciary subcommittee.\nDuring Tuesday's hearing, lawmakers will question Mr. Altman for the first time since OpenAI's chatbot, ChatGPT, \ntook the world by storm late last year.\nThe groundbreaking generative AI tool has led to a wave of new investment in AI, prompting a scramble among \nUS policymakers who have called for guardrails and regulation amid fears of AI's misuse.\nAlso testifying Tuesday will be Christina Montgomery, IBM's vice president and chief privacy and trust officer, as \nwell as Gary Marcus, a former New York University professor and a self-described critic of AI \"hype.\"\n\"Artificial intelligence urgently needs rules and safeguards to address its immense promise and pitfalls,\" said Sen. \nRichard Blumenthal, D-Conn., who chairs the Senate panel on privacy and technology. \"This hearing begins our \nsubcommittee's work in overseeing and illuminating AI's advanced algorithms and powerful technology.\"\nHe added: \"I look forward to working with my colleagues as we explore sensible standards and principles to help us \nnavigate this uncharted territory.\"\nGraphic\n \nPHOTO: Stephen Brashear / Associated Press: Altman\nLoad-Date: May 11, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "See Volatility in Near Term: Chandra",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 30, 2023",
        "section": "FRONT PAGE",
        "length": "638 words",
        "byline": "Our Bureau",
        "story_text": "See Volatility in Near Term: Chandra\nEconomic Times (E-Paper Edition)\nJune 30, 2023 Friday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 638 words\nByline: Our Bureau\nHighlight: Co got 2 whistleblower plaints from India, US on favouritism; 3 more staffers under probe\nBody\nCHANDRA'S FIRST PUBLIC COMMENTS ON 'JOBS SCAM'\nMumbai: Tata Consultancy Services (TCS) has sacked six employees and blacklisted as many staffing firms \nfollowing complaints about discrepancies in its recruitment process, Tata Sons chairman N Chandrasekaran told \nshareholders at the company's 28th annual general meeting on Thursday.  Investigations are ongoing into the \nconduct of three more employees, he said. In his first public comments on the “recruitment scandal” at India's \nlargest IT exporter, Chandrasekaran said TCS received two whistleblower complaints — one from India and one \nfrom the US — alleging “favouritism” in the recruitment of business associates. The compa-  ny's employees were \nfound to be “favouring” certain staffing firms unethically, he said. \nThe Mumbai-headquartered company works with over 1,000 staffing firms for recruitment of contractual staff. TCS's \nresource management division identified in the complaint handles 2-3% of the overall subcontracting requirements.  \n“The company will (re)look at the whole business associate supplier management process and see what the \nweaknesses are and completely tighten the process to ensure we do not have such incidents (again),” \nChandrasekaran said in his virtual address to shareholders. Noting that TCS has performed well overall despite \nmacro-economic challenges, Chandrasekaran cautioned that while he expects strong growth in the medium to long \nterm, “in nearby quarters, there will be volatility in different markets on the customer spend, especially on \ndiscretionary projects and it will go across sectors”, he said. Pointing to the intense geopolitical and economic \nvolatility in fiscal 2023 including the ongoing Russia-Ukraine conflict, the Tata Sons Chairman said these issues \nhave disrupted the smooth functioning of global supply chains, and there is a surge in inflation, especially in the \ndeveloped markets. He said the global GDP is estimated to grow at around 2.9% in 2023, adding that discretionary \nspending will continue to remain under pressure. Responding to shareholder concerns on higher attrition among \nwomen employees at the company, Chandrasekaran defended what he termed as TCS's “women-friendly policies” \nand said the com-  pany is going through an exercise to determine the future of work over the next decade. He also \npointed to significant focus on researching artificial intelligence (AI)-led technology, while stressing the need for it to \nbe used responsibly. Transiting to AI has become a central focus for TCS, he said, as (client) enterprises move \nfrom investments in predictive AI to generative AI. “(TCS) will invest and build capabilities and be very proactive (in \nnew technologies), be it in terms of partnerships, acquisitions and internal intellectual property,” said the 60-year-old \ntechnocrat, adding that areas like cryptocurrency will evolve over time and “it is not something we (TCS) will rush \ninto”. ETHICAL CONDUCT Responding to shareholder concerns  about the media reports related to the TCS's so-\ncalled “recruitment scandal”, Chandrasekaran said “the most important thing expected of every employee is ethical \nconduct and integrity, ahead of any financial performance”. “So, whenever there is a violation of ethical conduct by \nany employee, it pains me and all leaders very deeply. We take it extremely seriously and we will always deal with \nsuch incidents with very strong action,” he added. TCS received the two whistleblower complaints around February-\nSee Volatility in Near Term: Chandra\nMarch this year, with six employees fired and six firms banned following investigations. Further, the US complaint is \nbeing investigated by an external investigator. The company had informed the stock exchanges on Friday that the \ncase involves breach of code of conduct leading to some third-party subcontracting firms getting preferential \ntreatment.\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Amid Recent Backlash, Efforts to Grow Diversity At Companies Go Quiet",
        "media": "The New York Times",
        "time": "January 16, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4; DEALBOOK NEWSLETTER",
        "length": "1759 words",
        "byline": "By Sarah Kessler",
        "story_text": "Amid Recent Backlash, Efforts to Grow Diversity At Companies Go Quiet\nThe New York Times\nJanuary 16, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4; DEALBOOK NEWSLETTER\nLength: 1759 words\nByline: By Sarah Kessler\nBody\nAs corporate diversity, equity and inclusion programs come under attack, some companies are rebranding their \nefforts.\nJoelle Emerson's D.E.I. consultancy, Paradigm, works with more than 500 companies. The growing backlash \nagainst D.E.I., she said, ''is usually the first agenda item on every call.'' \n  Critics of D.E.I., or diversity, equity and inclusion initiatives, have tried to scapegoat it for everything from regional \nbank failures to a panel's ripping off a Boeing plane in flight last week. That debate gathered pace this month as \nthree famous billionaires clashed over D.E.I.'s merits on social media: Elon Musk and Pershing Square's chief \nexecutive, Bill Ackman, have attacked D.E.I. efforts as ''racist,'' while the investor Mark Cuban argued that they \nwere ''good for business.''\n  The economy and political landscape have changed since 2020, when companies hired D.E.I. officers in droves \namid a racial reckoning after the murder of George Floyd. Recently, D.E.I. programs have become less visible. \nOver the past two years, hiring for D.E.I. roles has plunged and the number of investor calls mentioning D.E.I. has \ndropped.\n  That raises a question: Have companies pulled back on D.E.I.? Or have they just changed how they approach and \ntalk about it?\n  D.E.I. is operating in a new environment. Last year, the Supreme Court struck down affirmative action in college \nadmissions, setting off a wave of similar lawsuits and legal threats against company diversity programs. And while \npolling indicates that most Americans believe it's good for companies to focus on diversity, equity and inclusion, \nthere's a wide partisan divide: In a Pew survey last year, 78 percent of workers who identified as Democrats agreed \nwith this sentiment, while just 30 percent of Republican workers thought the same.\n  The pushback may have prompted a rebranding, according to D.E.I. professionals. At some companies, what \nused to be called a D.E.I. survey may now be advertised as a culture survey, Emerson said. Or management \ntraining once framed as part of D.E.I. efforts may instead be discussed as a course to help managers deliver \nperformance reviews more effectively. ''This term seems to be pretty widely misunderstood in ways that I don't think \nany of us realized until the past couple of months,'' Emerson said of D.E.I. She added that it might make sense for \ncompanies to ''be far more specific about exactly what it is that we're talking about.''\n  Some corporate D.E.I. programs now include a broader variety of groups, said Porter Braswell, the founder of \n2045 Studio, a membership network for professionals of color. ''I think instead of saying this is a program for Black \nAmid Recent Backlash, Efforts to Grow Diversity At Companies Go Quiet\nemployees,'' he said, ''it would be more like, 'This is a program to increase the equity of promotion rates across the \nfirm, and everybody is included to apply to be part of this program, but will play different roles.'''\n  Some companies now talk about ''I.E.D.'' instead of ''D.E.I.,'' placing the emphasis on inclusion.\n  But a plunge in D.E.I. job postings could signal a retreat. After a spike in 2020 and 2021, job posts for D.E.I. roles \non the employment websites ZipRecruiter and Indeed dropped in 2022 and 2023, the companies said. On \nZipRecruiter, the number fell 63 percent in 2023. On Indeed, the number dropped 18 percent from December 2022 \nto January 2023.\n  Slow turnover of D.E.I. jobs (employers that hired in 2021 may not have needed to hire again in 2022) and a \ncooling labor market -- especially in industries, like tech and finance, that are most likely to have D.E.I. roles -- \nprobably contributed to the drop, said Julia Pollak, the chief economist at ZipRecruiter. But those factors don't \nentirely explain the shift.\n  Some see the decrease in job postings as a sign that companies have walked back their commitments to D.E.I. It \nshows that the surge in hiring of D.E.I. roles after Floyd's murder ''was performative at best,'' said Misty Gaither, \nvice president of diversity, inclusion, equity and belonging at Indeed.\n  Braswell of Jopwell added that many companies tried to offload all responsibility for changing company culture \nonto a couple of new hires -- a strategy that predictably failed. ''All those people are being fired, all those people are \nquitting, all those people are feeling burned out,'' he said, adding, ''The only way these cultures change to be more \ndiverse, equitable and inclusive is if it is everybody's job within the company.''\n  There is also evidence that companies remain committed to D.E.I. In a survey released this week by the \nemployment law firm Littler, only 1 percent of the 320 C-suite executives said they had significantly decreased their \nD.E.I. commitments in the past year, and 57 percent said they had expanded those efforts.\n  In a survey of 194 chief human resource officers published by the Conference Board last month, none of the \nrespondents said they planned to scale back D.E.I. initiatives. And while the number of times D.E.I. is mentioned on \ninvestor conference calls has fallen, the number of mentions in annual filings is at a high, according to AlphaSense.\n  Does it matter how companies talk about D.E.I.? Executives have stopped discussing their sustainability efforts \nand using the term E.S.G., for environmental, social and corporate governance issues, as the topic has become \nmore politicized. (BlackRock's Larry Fink recently described ''E.S.G.'' as ''entirely weaponized.'') When it comes to \nD.E.I., some professionals aren't bothered by changes to branding as long as the work continues. ''The end goals of \nthese diversity initiatives and programs will not change,'' Braswell said.\n  To others, changing the words is itself a retreat. ''We need to call it what it is,'' said Gaither of Indeed. ''The data \nsays that all of these positive things happen when you have diversity, equity and inclusion. So we're not going to \nmask it or call it something different.''\n  -- Sarah Kessler\n  IN CASE YOU MISSED IT\n  Citi will cut 20,000 jobs. The Wall Street giant announced the layoffs as it reported a $1.8 billion loss for the fourth \nquarter -- the bank's worst results in 14 years. Citi's chief executive, Jane Fraser, admitted the bank had performed \npoorly but said 2024 would be ''a turning point.''\n  BlackRock bets big on infrastructure. The asset manager agreed to buy Global Infrastructure Partners for about \n$12.5 billion, in a deal that would create the world's second-biggest infrastructure business. BlackRock also \nannounced a big reorganization, with Global Infrastructure's chief executive, Bayo Ogunlesi, joining BlackRock's \nglobal executive committee and board.\nAmid Recent Backlash, Efforts to Grow Diversity At Companies Go Quiet\n  The S.E.C. approved the first Bitcoin E.T.F. The regulator authorized 11 fund managers to create a new product \nthat would make it easier for retail investors to buy and sell the cryptocurrency. But the S.E.C.'s chair, Gary \nGensler, issued a cautionary statement after the decision, making clear that Bitcoin was a ''speculative, volatile \nasset'' that was used for illicit activity.\n  The World Bank warns of a ''wasted'' decade. The institution predicted that global growth would slow to 2.4 \npercent this year from 2.6 percent in 2023. The forecast put the world economy on track for the weakest half-\ndecade in 30 years. Two wars, a slowing Chinese economy and increased risks of natural disasters caused by \nglobal warming have added to the uncertainty.\n  The Geek Way\n  Andrew McAfee's books, including ''The Second Machine Age,'' have focused on how technology is changing \nwork. In his latest, ''The Geek Way,'' McAfee, a professor at the M.I.T. Sloan School of Management, describes a \nshift from the industrial era's management philosophy to a new era of constant change.\n  McAfee discussed the book with DealBook. The conversation has been edited for length and clarity.\n  You recommend that companies adopt ''geek norms'' at which the most successful modern companies excel. \nWhat do you mean by that?\n  Norms are expected group-level behaviors. I say there are four great geek norms. \n  The first one is science, which is a constant argument that gets settled over time by evidence.\n  The second one is ownership. It's about assigning responsibility to an autonomous group, and then making sure \nthat it remains an autonomous group.\n  The third one is speed. How quickly are you iterating, doing something, getting meaningful feedback on it, \nincorporating that and getting something else back out there? You need a plan, but the key is a minimum viable \nplan.\n  And then finally, openness, which is very close to psychological safety (which my former colleague Amy \nEdmondson talks a ton about). It's the opposite of defensiveness. We are inherently defensive creatures. We don't \nlove being challenged, and the geeks have realized we have to get past that if we're actually going to make \nprogress together.\n  You write that a key to the norm of ownership is keeping bureaucracy in check. Why does bureaucracy tend to \nballoon?\n  We human beings have this very deep-rooted desire to want status. And one way to get status in a big, \ncomplicated organization is to be a gatekeeper or some person in the decision loop.\n  Hitting your numbers helps the organization as a whole -- if you've done the alignment process right. But making \nyourself the 20th signature on the approval route to get some amount of spending through the system? No, let's try \nnot to have that.\n  Which of the geek norms is most difficult for leaders?\n  Probably openness. Like the rest of us, our leaders are inherently defensive creatures. Saying ''Oh, yeah, I hadn't \nthought of that -- good idea'' is not what the Industrial era's Jack Welch-style of leader was supposed to do. \nMaintaining that lack of defensiveness, creating an environment of psychological safety, arguing in ways that don't \nshut things down are all difficult things to do and to keep doing as a leader.\n  Was there an era when this wasn't the best way? What about the world has changed that makes it more \nimportant?\nAmid Recent Backlash, Efforts to Grow Diversity At Companies Go Quiet\n  It has always been a better idea to be open instead of defensive. In a slow-changing environment, where the \nlandscape is static, being closed off or not welcoming debate is not as big a problem. It is when the competition is \nglobal, when things get twice as good every 18 months and when, periodically, you have your environment rocked \nby something like generative A.I.\n  When the world is changing very quickly, all these old industrial habits become even worse.\n  Thanks for reading! We'll see you Tuesday.\n  We'd like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com\nhttps://www.nytimes.com/2024/01/13/business/dealbook/dei-goes-quiet.html\nGraphic\n \nPHOTO: Joelle Emerson, who runs Paradigm, a consultancy, said the backlash against D.E.I. ''is usually the first \nagenda item on every call.'' (PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) This article \nappeared in print on page B4.               \nLoad-Date: January 16, 2024"
    },
    {
        "file_name": "The_Economic_Times_Aug2023",
        "header": "Ageism in the tech workforce: from hiring to layoffs",
        "media": "The Economic Times",
        "time": "August 1, 2023",
        "section": "JOBS",
        "length": "633 words",
        "byline": "Debleena Majumdar",
        "story_text": "Ageism in the tech workforce: from hiring to layoffs\nThe Economic Times\nAugust 2, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: JOBS\nLength: 633 words\nByline: Debleena Majumdar\nBody\nMost large companies today have specialised initiatives to focus on diversity and inclusion. Annual reports of some \nof the technology firms in the country, which have traditionally hired a large number of people, often speak about \nthe diverse nature of people they have hired - from campuses to focus on women employees and more. But one \nfactor that doesn't often get talked about when it comes to diversity is age.At a broader level, in the US, where over \n20% of the employees are over 50 years old today, SHRM in a report in 2023 said that about 30% of the employees \nwho participated in a survey felt they were treated unfairly due to their age and over 70% said it made them feel like \nquitting their jobs. This is even more distressing because their data show that more people are wanting to work \nbeyond traditional work years and are delaying retirement. \nThis is especially true in certain tech-based jobs where the dynamic changes in technology drive a need for \nconstant learning and experimentation, and where knowledge of and comfort with the latest technology and tools \nsometimes trump experience.Analytics India Magazine, based on its research, said on its website that many major \ntech firms in the country have fewer people above the age of 50, with some companies having less than 10% of \nemployees who are above 50. Similar to the SHRM survey, it quoted a survey by JobBuzz that found a third of \nemployees facing age-based discrimination in the country.What's new in this old issue?First of all, the issue is not \nnew. In fact, some global tech behemoths have even faced lawsuits regarding this.What's new now is the impact \nthis could have on the spate of tech layoffs that many companies had been announcing in the wake of weaker \nglobal macroeconomic conditions, funding winter and slower growth forecasts.The layoff trend has been visible in \nhighly funded tech startups as well in some large IT services companies. In the meanwhile, the launch of \ngenerative AI tools and the widespread speculation about ChatGPT and how it can drive further productivity in \nmany white collar jobs, including in coding, is also unleashing more uncertainty.Upskilling over biasFrom the \ncompanies' point of view, it is important to be discerning about knowledge, skills and experience, and not use age \nas a point of bias, during either hiring or layoff decisions.A learning attitude is not dependent on age, and \nexperience can teach us some lessons that just technical skills cannot equip us with.At the same time, for \nindividuals, it is important to look at their skill sets in relation to technology shifts and to keep learning and \nunlearning. Even if someone is at a senior level with multiple people reporting to them, when it comes to taking \ndecisions on new technologies, a level of understanding and appreciation of the emerging technology is important. \nFrom self-learning using online platforms to executive programmes offered by leading universities, there are many \nways to develop this appreciation and understanding proactively.Simultaneously, a sharp focus on financial \nplanning and plans some people might have for latent entrepreneurship forays or expertise-based freelancing might \nhelp create more security.The broader demographic shiftGlobally, countries are seeing a gradual shift in \ndemographics as more people age. This will have implications on broader policy requirements in terms of pensions, \nemployment terms and more.India, though a demographically younger country than many other nations, will over \nthe next two or three decades also have more people above the age of 50 or 60 than before. Many of our current \ntech youngsters will be part of that cohort. The decisions we take now will have a long-term impact on how we look \nat age in tech roles. For Reprint Rights: timescontent.com\nAgeism in the tech workforce: from hiring to layoffs\nLoad-Date: August 1, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Artificial Intelligence Glossary: Neural Networks and Other Terms Explained",
        "media": "The New York Times",
        "time": "March 30, 2023",
        "section": "TECHNOLOGY",
        "length": "722 words",
        "byline": "Adam Pasick",
        "story_text": "Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\nThe New York Times \nMarch 27, 2023 Monday 12:23 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 722 words\nByline: Adam Pasick\nHighlight: The concepts and jargon you need to understand ChatGPT.\nBody\nThe concepts and jargon you need to understand ChatGPT.\nWe’ve compiled a list of phrases and concepts useful to understanding artificial intelligence, in particular the new \nbreed of A.I.-enabled chatbots like ChatGPT, Bing and Bard.\nIf you don’t understand these explanations, or would like to learn more, you might want to consider asking the \nchatbots themselves. Answering such questions is one of their most useful skills, and one of the best ways to \nunderstand A.I. is to use it. But keep in mind that they sometimes get things wrong.\nBing and Bard chatbots are being rolled out slowly, and you may need to get on their waiting lists for access. \nChatGPT currently has no waiting list, but it requires setting up a free account.\nFor more on learning about A.I., check out The New York Times’s five-part series on becoming an expert on \nchatbots.\nAnthropomorphism: The tendency for people to attribute humanlike qualities or characteristics to an A.I. chatbot. \nFor example, you may assume it is kind or cruel based on its answers, even though it is not capable of having \nemotions, or you may believe the A.I. is sentient because it is very good at mimicking human language.\nBias: A type of error that can occur in a large language model if its output is skewed by the model’s training data. \nFor example, a model may associate specific traits or professions with a certain race or gender, leading to \ninaccurate predictions and offensive responses.\nEmergent behavior: Unexpected or unintended abilities in a large language model, enabled by the model’s learning \npatterns and rules from its training data. For example, models that are trained on programming and coding sites can \nwrite new code. Other examples include creative abilities like composing poetry, music and fictional stories.\nGenerative A.I.: Technology that creates content — including text, images, video and computer code — by \nidentifying patterns in large quantities of training data, and then creating original material that has similar \ncharacteristics. Examples include ChatGPT for text and DALL-E and Midjourney for images.\nHallucination: A well-known phenomenon in large language models, in which the system provides an answer that is \nfactually incorrect, irrelevant or nonsensical, because of limitations in its training data and architecture.\nLarge language model: A type of neural network that learns skills — including generating prose, conducting \nconversations and writing computer code — by analyzing vast amounts of text from across the internet. The basic \nArtificial Intelligence Glossary: Neural Networks and Other Terms Explained\nfunction is to predict the next word in a sequence, but these models have surprised experts by learning new \nabilities.\nNatural language processing: Techniques used by large language models to understand and generate human \nlanguage, including text classification and sentiment analysis. These methods often use a combination of machine \nlearning algorithms, statistical models and linguistic rules.\nNeural network: A mathematical system, modeled on the human brain, that learns skills by finding statistical \npatterns in data. It consists of layers of artificial neurons: The first layer receives the input data, and the last layer \noutputs the results. Even the experts who create neural networks don’t always understand what happens in \nbetween.\nParameters: Numerical values that define a large language model’s structure and behavior, like clues that help it \nguess what words come next. Systems like GPT-4 are thought to have hundreds of billions of parameters.\nReinforcement learning: A technique that teaches an A.I. model to find the best result by trial and error, receiving \nrewards or punishments from an algorithm based on its results. This system can be enhanced by humans giving \nfeedback on its performance, in the form of ratings, corrections and suggestions.\nTransformer model: A neural network architecture useful for understanding language that does not have to analyze \nwords one at a time but can look at an entire sentence at once. This was an A.I. breakthrough, because it enabled \nmodels to understand context and long-term dependencies in language. Transformers use a technique called self-\nattention, which allows the model to focus on the particular words that are important in understanding the meaning \nof a sentence.\nPHOTO:  (PHOTOGRAPH BY Illustrations by Mathieu Labrecque FOR THE NEW YORK TIMES)\nLoad-Date: March 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Apple’s New iPad Ad Leaves Its Creative Audience Feeling … Flat",
        "media": "The New York Times",
        "time": "May 9, 2024",
        "section": "BUSINESS",
        "length": "823 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple’s New iPad Ad Leaves Its Creative Audience Feeling … Flat\nThe New York Times \nMay 8, 2024 Wednesday 21:49 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 823 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: An ad meant to show how the updated device can do many things has become a metaphor for a \ncommunity’s fears of the technology industry.\nBody\nAn ad meant to show how the updated device can do many things has become a metaphor for a community’s fears \nof the technology industry.\nThe trumpet is the first thing to be squished. Then the industrial compressor flattens a row of paint cans, buckles a \npiano and levels what appears to be a marble bust. In a final act of destruction, it pops the eyes out of a ball-shaped \nyellow emoji.\nWhen the compressor rises, it reveals Apple’s latest commodity: the updated iPad Pro.\nTim Cook, Apple’s chief executive, posted the advertisement, called “Crush,” on Tuesday after the company held an \nevent to announce new tablets. “Meet the new iPad Pro: the thinnest product we’ve ever created,” Mr. Cook wrote, \nadding, “Just imagine all the things it’ll be used to create.”\nFor decades, Apple has been the toast of the creative class. It has won over designers, musicians and film editors \nwith promises that its products would help them “Think Different.”\nBut some creators took a different message from the one-minute iPad ad. Rather than seeing a device that could \nhelp them create, as Mr. Cook suggested, they saw a metaphor for how Big Tech has cashed in on their work by \ncrushing or co-opting the artistic tools that humanity has used for centuries.\nThe image was especially unnerving at a time when artists fear that generative artificial intelligence, which can \nwrite poetry and create movies, might take away their jobs.\n“It’s unusual in its cruelty,” said Justin Ouellette, a software designer in Portland, Ore., who does animation work \nand is a longtime Apple product user. “A lot of people see this as a betrayal of its commitment to human creative \nexpression and a tone deafness to the pressures those artists feel at this time.”\nApple didn’t respond to requests for comment.\nIt was the latest in a series of recent promotional slip-ups by a company that is widely considered to be a marketing \njuggernaut. Its marketing of the Apple Vision Pro, released in January, struggled to help that device break through \nwith many customers. Last year, Apple was criticized for making an awkward sketch that cast Octavia Spencer as \nMother Earth, lording over a corporate meeting about the company’s effort to become carbon neutral by 2030.\nApple ’s New iPad Ad Leaves Its Creative Audience Feeling … Flat\nApple has been regarded as an advertising visionary since the 1980s. Its “1984” Super Bowl commercial to \nintroduce the Macintosh computer is among the most famous commercials ever made. The ad, which was \ndeveloped by the Chiat/Day agency, showed an actor throwing a sledgehammer through a screen projecting the \nface of a “Big Brother” figure that was meant to be a metaphor for IBM.\nWhen Steve Jobs returned to Apple in 1997 after 12 years away, he sought to reclaim its marketing magic. \nTogether he and Lee Clow, the advertising creative behind the “1984” spot, developed the “Think Different” \ncampaign. It paved the way to the famous “Get a Mac” spots, featuring a Mac and PC, and the original iPhone ad, \nwhich showed people in classic films and television shows picking up a phone and saying, “Hello.”\nApple’s marketing pitched its products as easy to use. It billed PCs and Android phones as devices for business \nexecutives working on spreadsheets, while Macs and iPhones were tools for film editors, photographers and \nwriters.\nBut Apple’s advertising has been uneven over the last dozen years or so. It yanked a 2012 campaign that \nshowcased its Apple Store “geniuses” on planes. Critics dismissed a subsequent spot, “Designed by Apple in \nCalifornia,” as “lame.”\nIn the wake of those hiccups, Mr. Cook shifted oversight of advertising from Phil Schiller, the company’s longtime \nhead of marketing, to Tor Myhren, a former president and chief creative officer at Grey, the ad agency that created \nthe E-Trade baby.\nUnder Mr. Myhren, who joined in 2016, Apple has developed some of its ads with its own creative team and others \nin collaboration with an outside agency, Media Arts Lab. It has been recognized at the Cannes Lions Awards, the \nleading event for the ad industry, for a spot on AirPods called “Bounce,” which showed a man bounding off the \nsidewalk as he listened to music. Last year, Apple was named Creative Brand of the Year because of its “R.I.P. \nLeon” ad, in which a man sent an iPhone message saying a lizard in his care had died, then deleted it when the \nlizard suddenly rolled over off its back.\nMr. Myhren and Media Arts Lab didn’t respond to requests for comment about who was behind the “Crush” spot.\nMichael J. Miraflor, the chief brand officer at Hannah Grey, a venture capital firm, said on X that Apple’s ad had \neffectively offended and turned off its core customer base, achieving the opposite of what it had done with its “1984” \ncommercial.\n“It’s not even that it’s boring or banal,” Mr. Miraflor wrote. “It makes me feel … bad? Bummed out?”\nPHOTO: In the ad, a compressor crushes myriad tools and materials of creative work. (PHOTOGRAPH BY APPLE) \n(B5) This article appeared in print on page B1, B5.\nLoad-Date: May 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Fake Images Of Swift Hit Social Media And Spread",
        "media": "The New York Times",
        "time": "January 28, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 13",
        "length": "867 words",
        "byline": "By Kate Conger and John Yoon",
        "story_text": "Fake Images Of Swift Hit Social Media And Spread\nThe New York Times\nJanuary 28, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 13\nLength: 867 words\nByline: By Kate Conger and John Yoon\nBody\nFans of the star and lawmakers condemned the images, probably generated by artificial intelligence, after they \nwere shared with millions of social media users.\nFake, sexually explicit images of Taylor Swift likely generated by artificial intelligence spread rapidly across social \nmedia platforms this week, disturbing fans who saw them and reigniting calls from lawmakers to protect women and \ncrack down on the platforms and technology that spread such images. \n  One image shared by a user on X was viewed 47 million times before the account was suspended on Thursday. X \nsuspended several accounts that posted the faked images of Ms. Swift, but the images were shared on other social \nmedia platforms and continued to spread despite those companies' efforts to remove them.\n  While X said it was working to remove the images, fans of the pop superstar flooded the platform in protest. They \nposted related keywords, along with the sentence ''Protect Taylor Swift,'' in an effort to drown out the explicit images \nand make them more difficult to find.\n  Reality Defender, a cybersecurity company focused on detecting A.I., determined with 90 percent confidence that \nthe images were created using a diffusion model, an A.I.-driven technology accessible through more than 100,000 \napps and publicly available models, said Ben Colman, the company's co-founder and chief executive.\n  As the A.I. industry has boomed, companies have raced to release tools that enable users to create images, \nvideos, text and audio recordings with simple prompts. The A.I. tools are wildly popular but have made it easier and \ncheaper than ever to create so-called deepfakes, which portray people doing or saying things they have never \ndone.\n  Researchers now fear that deepfakes are becoming a powerful disinformation force, enabling everyday internet \nusers to create nonconsensual nude images or embarrassing portrayals of political candidates. Artificial intelligence \nwas used to create fake robocalls of President Biden during the New Hampshire primary, and Ms. Swift was \nfeatured this month in deepfake ads hawking cookware.\n  ''It's always been a dark undercurrent of the internet, nonconsensual pornography of various sorts,'' said Oren \nEtzioni, a computer science professor at the University of Washington who works on deepfake detection. ''Now it's a \nnew strain of it that's particularly noxious.''\n  ''We are going to see a tsunami of these A.I.-generated explicit images. The people who generated this see this as \na success,'' Mr. Etzioni said.\nFake Images Of Swift Hit Social Media And Spread\n  X said it had a zero-tolerance policy toward the content. ''Our teams are actively removing all identified images \nand taking appropriate actions against the accounts responsible for posting them,'' a representative said in a \nstatement. ''We're closely monitoring the situation to ensure that any further violations are immediately addressed, \nand the content is removed.''\n  X has seen an increase in problematic content including harassment, disinformation and hate speech since Elon \nMusk bought the service in 2022. He has loosened the website's content rules and fired, laid off or accepted the \nresignations of staff members who worked to remove such content. The platform also reinstated accounts that had \nbeen previously banned for violating rules.\n  Although many of the companies that produce generative A.I. tools ban their users from creating explicit imagery, \npeople find ways to break the rules. ''It's an arms race, and it seems that whenever somebody comes up with a \nguardrail, someone else figures out how to jailbreak,'' Mr. Etzioni said.\n  The images originated in a channel on the messaging app Telegram that is dedicated to producing such images, \naccording to 404 Media, a technology news site. But the deepfakes garnered broad attention after being posted on \nX and other social media services, where they spread rapidly.\n  Some states have restricted pornographic and political deepfakes. But the restrictions have not had a strong \nimpact, and there are no federal regulations of such deepfakes, Mr. Colman said. Platforms have tried to address \ndeepfakes by asking users to report them, but that method has not worked, he added. By the time they are flagged, \nmillions of users have already seen them.\n  ''The toothpaste is already out of the tube,'' he said.\n  Ms. Swift's publicist, Tree Paine, did not immediately respond to requests for comment late Thursday.\n  The deepfakes of Ms. Swift prompted renewed calls for action from lawmakers. Representative Joe Morelle, a \nDemocrat from New York who introduced a bill last year that would make sharing such images a federal crime, said \non X that the spread of the images was ''appalling,'' adding: ''It's happening to women everywhere, every day.''\n  ''I've repeatedly warned that AI could be used to generate non-consensual intimate imagery,'' Senator Mark \nWarner, a Democrat from Virginia and chairman of the Senate Intelligence Committee, said of the images on X. \n''This is a deplorable situation.''\n  Representative Yvette D. Clarke, a Democrat from New York, said that advancements in artificial intelligence had \nmade creating deepfakes easier and cheaper.\n  ''What's happened to Taylor Swift is nothing new,'' she said.\nhttps://www.nytimes.com/2024/01/26/arts/music/taylor-swift-ai-fake-images.html\nGraphic\n \nPHOTO: A Taylor Swift fan with an ''Eras Tour'' friendship bracelet the day before Swift's concert in Buenos Aires in \nNovember. (PHOTOGRAPH BY TOMAS CUESTA/REUTERS) This article appeared in print on page A13.               \nLoad-Date: January 28, 2024"
    },
    {
        "file_name": "Hernandez_is_only_the_fifth_person_to_lead_the_gathering_in_its_40-year_history._Jan2024",
        "header": "SUNDANCE FILM FESTIVAL; Guarding fest legacy and future; Eugene",
        "media": "Hernandez is only the fifth person to lead the gathering in its 40-year history.",
        "time": "January 16, 2024",
        "section": "CALENDAR; Entertainment Desk; Part E; Pg. 1",
        "length": "1566 words",
        "byline": "Mark Olsen",
        "story_text": "SUNDANCE FILM FESTIVAL; Guarding fest legacy and future; Eugene \nHernandez is only the fifth person to lead the gathering in its 40-year history.\nLos Angeles Times\nJanuary 16, 2024 Tuesday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: CALENDAR; Entertainment Desk; Part E; Pg. 1\nLength: 1566 words\nByline: Mark Olsen\nBody\nThe Sundance Film Festival will launch its 40th edition later this month, welcoming back such alumni as Steven \nSoderbergh, Dee Rees, Richard Linklater and Kristen Stewart as part of the event. It will be the first full edition for \nnew festival director Eugene Hernandez, charged with stewarding the nation's leading independent film showcase \ninto an uncertain future for the industry at large.\nHernandez, 55, is only the fifth person to hold the job in the festival's storied history. When the Sundance Institute, \nfounded by Robert Redford, took over control of the U.S. Film Festival in 1985, the program included Wim Wenders' \n\"Paris, Texas,\" Jim Jarmusch's \"Stranger Than Paradise\" and the Coen brothers' \"Blood Simple.\"\nIn subsequent years the festival has helped launch a wide array of major filmmakers, including Christopher Nolan, \nQuentin Tarantino, Ava DuVernay, Ryan Coogler, Chloe Zhao, Damien Chazelle, Paul Thomas Anderson and \ncountless others.\nWith film production still reeling from the aftermath of last year's strikes, exhibition is continuing to find its footing \nfrom the one-two punch of the pandemic and the rise of streaming. Many audiences that used to visit art houses for \nthe kind of specialized titles that reliably emerged from Sundance have not returned in full force to theaters, having \ngrown accustomed to watching small-scale, intimate indies at home.\nAll of which is to say that someone coming into a position specifically tasked with reengaging the industry and \naudiences alike may feel a certain pressure to perform in their first year on the job.\n\"The pressure that I feel is my enduring respect for the legacy of the institution and the festival,\" said Hernandez, \n\"the desire to be respectful of everything that Sundance has created, everything that Mr. Redford has done at the \ninstitute for 40-plus years.\n\"I do feel a strong sense of responsibility to remain focused and centered on what I've always seen the institute do \nin the many moments of uncertainty or change that it has withstood,\" Hernandez added. \"And that is always \nreturning to the focus on the artist and returning to centering the artist and the art form.\"\nLast year was an especially good lineup for the festival, one that included the premieres of such future critics' \ndarlings as \"Past Lives,\" \"Passages,\" \"Fair Play,\" \"A Thousand and One,\" \"Kokomo City,\" \"All Dirt Roads Taste of \nSalt\" and \"Still: A Michael J. Fox Movie.\" Additionally, the Australian horror film \"Talk to Me,\" which played in the \nMidnight section of the festival, went on make nearly $50 million at the U.S. box office.\nHeading into this year, the festival saw a record number of submissions.\nSUNDANCE FILM FESTIVAL Guarding fest legacy and future Eugene Hernandez is only the fifth person to \nlead the gathering in its 40-year history.\n\"Despite all the uncertainty around the fate of independent films and series, we have this beautiful rush of \nsubmissions -- more than 17,000 this year,\" Hernandez said. \"And so I think the mission is really to try to continue \nto do what Sundance has always done, and that is watch all of them and make a selection that can represent where \nthe future of independent storytelling is heading.\"\n--\n'THE FIRST AUDIENCE'\nHernandez, who identifies as Latinx and queer, comes to Sundance after 11 years at Film at Lincoln Center, where \nhe rose to senior vice president of FLC, publisher of Film Comment and executive director of the prestigious New \nYork Film Festival, where he kept the flames burning during three tricky years of the pandemic.\nRaised in Indio, Calif., Hernandez attended UCLA before eventually moving to New York City in 1994. He co-\nfounded and was longtime editor-in-chief of the website IndieWire, a publication that has grown into a vital resource \nfor news on the world of independent film.\nHernandez's hiring at Sundance was announced in September 2022, replacing Tabitha Jackson after only two \nyears on the job. After wrapping that year's New York Film Festival in October and taking a few weeks off, \nHernandez joined Sundance in November to observe the planning and inner workings of the festival's 2023 edition. \nHe fully dove into an active role as soon as last year's festival had wrapped.\nHernandez noted that since taking the Sundance job, he has bounced between spending time at the organization's \noffices in Utah, New York and Los Angeles.\nThe position of festival director sits right at the intersection between the needs of the industry -- including \ndistributors, producers and financiers -- and those of the creative artists themselves. Reconciling the needs and \nwants of those two sides can be a big part of the job.\nJohn Cooper, who was director of the festival from 2009 to 2020, knows it can be a challenge to satisfy all the \nassorted stakeholders.\n\"There's the industry giving you input and then there are the artists giving you input and you're really building it for a \nway of connecting those two,\" said Cooper over Zoom. \"But you're not really leading as much as listening --\nespecially listening to the filmmakers. What do you really need now as you make a film? What is it you need for the \n10 days of Sundance? What is it you need for the world? And you have to kind of stick with how can those 10 days \ngive you as much as possible.\"\nHernandez remembers his first time at Sundance in 1993. He was at the first screening of Robert Rodriguez's low-\nbudget debut feature, \"El Mariachi\" -- he still has his ticket -- and recalled what it meant to be in that exact room at \nthat exact time.\n\"To be at a place where literally no one had seen this movie yet,\" said Hernandez, \"you're the first audience \nwatching it, and the director is there and is kind of roughly your age and onstage and talking about making that \nmovie and all the struggles they went through to get it on the screen. That was a huge lightbulb moment for me.\"\nIt was also during his first trip to Sundance, while riding a shuttle bus, that Hernandez met budding journalist Mark \nRabinowitz. They, along with Cheri Barner, would go on to co-found the website that would become IndieWire. \n(Hernandez sold his stake in the site and left long before its 2016 sale to Penske Media Corp.)\nThat kind of seeming happenstance, that you can meet someone on a festival shuttle and change the direction of \nyour life, is a part of the Sundance myth that Hernandez hopes to hold on to. It's still possible for anyone coming to \nparticipate in the event.\nSUNDANCE FILM FESTIVAL Guarding fest legacy and future Eugene Hernandez is only the fifth person to \nlead the gathering in its 40-year history.\n\"If you're a kid in your 20s now, or even younger, and you're inspired to find out more about what a festival is or \nwhat Sundance is, I feel like part of my job is to create the space for that discovery to happen,\" said Hernandez. His \ngoal is \"to create the space for those chance encounters to happen, whether they're on the mountain in Utah or \nwhether it's watching something on our platform during the second week of the festival and seeing something that \nmaybe you've never seen before.\n\"We are part of an ecosystem,\" he added. \"We are not separate from it. We are part of it.\"\n--\n'KNOWS HOW TO LISTEN'\nHernandez's unique background in journalism, publishing and the festival world makes him ideally suited to his \nmultifaceted new role at Sundance as the festival faces the future.\n\"He's very insightful and just someone who really understands and thinks a lot about where the industry is,\" sad \nJoana Vicente, CEO of Sundance Institute. \"He's someone who really knows how to listen, is always wanting to \nhear what people think, always asking questions. And I think that that has served him really well.\"\nSundance's complex function as an incubator and launching pad for new talent is front of mind for Hernandez, \naccording to Vicente. \"He's very committed to thinking about the festival as not something that serves just one \npurpose but thinking about the deeper purpose and how do we evolve to continue to be as relevant as ever,\" she \nsaid. \"And I think that's the big question that drives him. And so it's not about, 'Oh, now we have a new section of \nthe festival,' or 'We're no longer doing this and doing that instead.' It's how can we be as relevant each year as we \npossibly can be and how can we deliver for these filmmakers the absolute best platform so that they go on and \nhave incredible careers?\"\nWith Sundance celebrating a milestone anniversary while welcoming its new festival director, this year will be a \ncombination of looking back and looking ahead.\n\"You really always get this snapshot of what the state of our storytelling is, and, to say it even more broadly, the \nstate of our culture,\" said Hernandez.\nMuch of this year's on-the-ground conversation may revolve around artificial intelligence: Numerous films, including \nGary Hustwit's \"Eno,\" a documentary portrait of artist-musician Brian Eno that uses generative AI (it's different \nevery time it is screened), and the tech-themed fiction film \"Love Me\" from Sam and Andy Zuchero, touch on the \nsubject. There are also a number of festival-hosted panels that will focus on the use of AI and technology in creative \nstorytelling.\n\"What Sundance has always done so well is start the conversation and add complexity,\" said Hernandez. \"So if \nwhere we end up at the end of that is 'Was this the year of AI?' then I hope that we've had the opportunity to dig in \neven more deeply, to continue grappling with what that means right now and where it might be taking us, and what \nwe might need to do to navigate it.\n\"But it really is when the films meet the audience that the festival takes life,\" he added. \"And those are the \nconversations that I just can't wait to have.\"\nGraphic\n \nPHOTO: HERNANDEZ aims to select films that are representive of where \"independent storytelling is heading.\"  \nPHOTOGRAPHER:Chris Pizzello Invision / AP PHOTO: EUGENE HERNANDEZ, who takes over as director of the \nSUNDANCE FILM FESTIVAL Guarding fest legacy and future Eugene Hernandez is only the fifth person to \nlead the gathering in its 40-year history.\nSundance \nFilm \nFestival \nthis \nyear, \npreviously \nwas \nwith \nIndieWire \nand \nFilm \nat \nLincoln \nCenter.  \nPHOTOGRAPHER:Allen J. Schaben Los Angeles Times \nLoad-Date: January 16, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Discussions on Chip Fabrication Scaling, Manufacturing Investments",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 8, 2023",
        "section": "FRONT PAGE",
        "length": "585 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Discussions on Chip Fabrication Scaling, Manufacturing Investments\nEconomic Times (E-Paper Edition)\nSeptember 8, 2023 Friday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 585 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Plan to expand workforce in India, focus on upskilling, says Huang\nBody\nCEO MEETS IISC , IIT RESEARCHERS\nBengaluru: Nvidia, the world's pre-eminent maker of hardware and software for artificial intelligence tools, envisions \nexporting AI products from its Indian arm, CEO and cofounder of the $27-billion firm, Jensen Huang told \nresearchers at India's top technology institutes this week, according to the people present at the interaction. India is \nevolving into a “front end” nation in the world of technology, the 60-year-old technocrat told his audience during his \nongoing visit in the country, which included a meeting with Prime Minister Narendra Modi on September 4.  The \nAmerican chipmaker, which is riding on a trillion-dollar valuation led by the boom in generative Artificial \nIntelligence (AI), expects to leverage the vast data generated by India's $1.4 billion population to build AI products \nthat can be exported from the country. Huang, who co-founded the Santa Clara-based technology giant in 1993, \nmet researchers from the Indian Institute of Science's (IISc) department of computational and data sciences (CDS), \nIndian Institute of Technology (IIT) Madras and IIT Bombay on September 4 during the course of his week-long \nvisit. Sashikumar Ganesan, associate professor and chair of CDS at IISc, Bengaluru, told ET that the discussions at \nthe HPC and AI Research Leaders Meet revolved around leaders in artificial intelligence (AI) and high-performance \ncomputing (HPC), which is Nvidia's primary business domain. \nHuang communicated plans to expand Nvidia's workforce in India and focus on upskilling. “Although we may lack \nthe ecosystem to collect all data, once acquired, all AI and machine learning systems for the world can be trained \non it. This is one of the reasons why technology companies invest heavily in India,” Ganesan said. Discussions \nduring the meeting encompassed India's potential to lead AI research, chip fabrication scaling, and investments in \nmanufacturing.  TRILLION-DOLLAR CLUB Nvidia manufactures semiconductor chips that are integral to the \nfunctioning of AI-products built by the likes of Microsoftbacked OpenAI such as ChatGPT. As it rode the surging AI \nwave in 2023, Nvidia saw a record rise in demand for its chips, which are now at an all-time  high.  Nvidia reported \na revenue of $13.51 billion for the second quarter ended July 30, 2023, up 101% from a year ago. Its stock recently \nhit an all-time high after a surge of 315%. The company reached a market value of more than a trillion dollars in \nMay this year, joining the likes of Microsoft, Apple and Amazon. Following Microsoft's $10 billion investment into the \nSam Altman founded-OpenAI earlier this year, Google announced an aggressive follow-up through its own AI tool \nBard.  Huang was keen to understand the nuances of high-performance computing in India, its applications, and \nNvidia's role.  Ajay Kumar Sood, a distinguished honorary professor of Physics at IISc and the principal scientific \nadvisor to the Indian government, was also among the attendees.  INDIA FOCUS Nvidia began its operations in \nIndia in 2004 in Bengaluru and has four engineering development centres located in Gurugram, Hyderabad, Pune \nand Bengaluru with a workforce of 3,800 individuals in India. More than 320,000 India-based developers are part of \nNvidia's developer programme. Huang was updated on the research activities of CDS at IISc. “We're integrating \nDiscussions on Chip Fabrication Scaling, Manufacturing Investments\nmachine learning with computational science. Huang was curious about this intersection,” Ganesan said. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2024",
        "header": "Spurred by Teen Girls, States Move to Ban Deepfake Nudes",
        "media": "The New York Times - International Edition",
        "time": "April 26, 2024",
        "section": "TECHNOLOGY",
        "length": "1430 words",
        "byline": "Natasha Singer",
        "story_text": "Spurred by Teen Girls, States Move to Ban Deepfake Nudes\nThe New York Times - International Edition\nApril 27, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1430 words\nByline: Natasha Singer\nBody\nLegislators in two dozen states are working on bills, or have passed laws, to combat A.I.-generated sexually explicit \nimages of minors.       \nCaroline Mullet, a ninth grader at Issaquah High School near Seattle, went to her first homecoming dance last fall, a \nJames Bond-themed bash with blackjack tables attended by hundreds of girls dressed up in party frocks.       \nA few weeks later, she and other female students learned that a male classmate was circulating fake nude images \nof girls who had attended the dance, sexually explicit pictures that he had fabricated using an artificial intelligence \napp designed to automatically \"strip\" clothed photos of real girls and women.       \nMs. Mullet, 15, alerted her father, Mark, a Democratic Washington State senator. Although she was not among the \ngirls in the pictures, she asked if something could be done to help her friends, who felt \"extremely uncomfortable\" \nthat male classmates had seen simulated nude images of them. Soon, Senator Mullet and a colleague in the State \nHouse proposed legislation to prohibit the sharing of A.I.-generated sexually explicit depictions of real minors.       \n\"I hate the idea that I should have to worry about this happening again to any of my female friends, my sisters or \neven myself,\" Ms. Mullet told state lawmakers during a hearing on the bill in January.       \nThe State Legislature passed the bill without opposition. Gov. Jay Inslee, a Democrat, signed it last month.       \nStates are on the front lines of a rapidly spreading new form of peer sexual exploitation and harassment in schools. \nBoys across the United States have used widely available \"nudification\" apps to surreptitiously concoct sexually \nexplicit images of their female classmates and then circulated the simulated nudes via group chats on apps like \nSnapchat and Instagram.       \nNow, spurred in part by troubling accounts from teenage girls like Ms. Mullet, federal and state lawmakers are \nrushing to enact protections in an effort to keep pace with exploitative A.I. apps.       \nSince early last year, at least two dozen states have introduced bills to combat A.I.-generated sexually explicit \nimages - known as deepfakes - of people under 18, according to data compiled by the National Center for Missing \n& Exploited Children, a nonprofit organization. And several states have enacted the measures.       \nAmong them, South Dakota this year passed a law that makes it illegal to possess, produce or distribute A.I.-\ngenerated sexual abuse material depicting real minors. Last year, Louisiana enacted a deepfake law that \ncriminalizes A.I.-generated sexually explicit depictions of minors.       \nSpurred by Teen Girls, States Move to Ban Deepfake Nudes\n\"I had a sense of urgency hearing about these cases and just how much harm was being done,\" said \nRepresentative Tina Orwall, a Democrat who drafted Washington State's explicit-deepfake law after hearing about \nincidents like the one at Issaquah High.       \nSome lawmakers and child protection experts say such rules are urgently needed because the easy availability of \nA.I. nudification apps is enabling the mass production and distribution of false, graphic images that can potentially \ncirculate online for a lifetime, threatening girls' mental health, reputations and physical safety.       \n\"One boy with his phone in the course of an afternoon can victimize 40 girls, minor girls,\" said Yiota Souras, chief \nlegal officer for the National Center for Missing & Exploited Children, \"and then their images are out there.\"       \nOver the last two months, deepfake nude incidents have spread in schools - including in Richmond, Ill., and Beverly \nHills and Laguna Beach, Calif.       \nYet few laws in the United States specifically protect people under 18 from exploitative A.I. apps.       \nThat is because many current statutes that prohibit child sexual abuse material or adult nonconsensual \npornography - involving real photos or videos of real people - may not cover A.I.-generated explicit images that use \nreal people's faces, said U.S. Representative Joseph D. Morelle, a Democrat from New York.       \nLast year, he introduced a bill that would make it a crime to disclose A.I.-generated intimate images of identifiable \nadults or minors. It would also give deepfake victims, or parents, the right to sue individual perpetrators for \ndamages.       \n\"We want to make this so painful for anyone to even contemplate doing, because this is harm that you just can't \nsimply undo,\" Mr. Morelle said. \"Even if it seems like a prank to a 15-year-old boy, this is deadly serious.\"       \nU.S. Representative Alexandria Ocasio-Cortez, another New York Democrat, recently introduced a similar bill to \nenable victims to bring civil cases against deepfake perpetrators.        \nBut neither bill would explicitly give victims the right to sue the developers of A.I. nudification apps, a step that trial \nlawyers say would help disrupt the mass production of sexually explicit deepfakes.       \n\"Legislation is needed to stop commercialization, which is the root of the problem,\" said Elizabeth Hanley, a lawyer \nin Washington who represents victims in sexual assault and harassment cases.       \nThe U.S. legal code prohibits the distribution of computer-generated child sexual abuse material depicting \nidentifiable minors engaged in sexually explicit conduct. Last month, the Federal Bureau of Investigation issued an \nalert warning that such illegal material included realistic child sexual abuse images generated by A.I.       \nYet fake A.I.-generated depictions of real teenage girls without clothes may not constitute \"child sexual abuse \nmaterial,\" experts say, unless prosecutors can prove the fake images meet legal standards for sexually explicit \nconduct or the lewd display of genitalia.       \nSome defense lawyers have tried to capitalize on the apparent legal ambiguity. A lawyer defending a male high \nschool student in a deepfake lawsuit in New Jersey recently argued that the court should not temporarily restrain his \nclient, who had created nude A.I. images of a female classmate, from viewing or sharing the pictures because they \nwere neither harmful nor illegal. Federal laws, the lawyer argued in a court filing, were not designed to apply \"to \ncomputer-generated synthetic images that do not even include real human body parts.\" (The defendant ultimately \nagreed not to oppose a restraining order on the images.)       \nNow states are working to pass laws to halt exploitative A.I. images. This month, California introduced a bill to \nupdate a state ban on child sexual abuse material to specifically cover A.I.-generated abusive material.       \nAnd Massachusetts lawmakers are wrapping up legislation that would criminalize the nonconsensual sharing of \nexplicit images, including deepfakes. It would also require a state entity to develop a diversion program for minors \nSpurred by Teen Girls, States Move to Ban Deepfake Nudes\nwho shared explicit images to teach them about issues like the \"responsible use of generative artificial \nintelligence.\"       \nPunishments can be severe. Under the new Louisiana law, any person who knowingly creates, distributes, \npromotes or sells sexually explicit deepfakes of minors can face a minimum prison sentence of five to 10 years.       \nIn December, Miami-Dade County police officers arrested two middle school boys for allegedly making and sharing \nfake nude A.I. images of two female classmates, ages 12 and 13, according to police documents obtained by The \nNew York Times through a public records request. The boys were charged with third-degree felonies under a 2022 \nstate law prohibiting altered sexual depictions without consent. (The state attorney's office for Miami-Dade County \nsaid it could not comment on an open case.)       \nThe new deepfake law in Washington State takes a different approach.       \nAfter learning of the incident at Issaquah High from his daughter, Senator Mullet reached out to Representative \nOrwall, an advocate for sexual assault survivors and a former social worker. Ms. Orwall, who had worked on one of \nthe state's first revenge-porn bills, then drafted a House bill to prohibit the distribution of A.I.-generated intimate, or \nsexually explicit, images of either minors or adults. (Mr. Mullet, who sponsored the companion Senate bill, is now \nrunning for governor.)       \nUnder the resulting law, first offenders could face misdemeanor charges while people with prior convictions for \ndisclosing sexually explicit images would face felony charges. The new deepfake statute takes effect in June.       \n\"It's not shocking that we are behind in the protections,\" Ms. Orwall said. \"That's why we wanted to move on it so \nquickly.\" \nLoad-Date: April 26, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "Infosys CEO Pay Falls 21% to ?56.4 cr in FY23",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 5, 2023",
        "section": "COMPANIES",
        "length": "455 words",
        "byline": "Our Bureau",
        "story_text": "Infosys CEO Pay Falls 21% to ?56.4 cr in FY23\nEconomic Times (E-Paper Edition)\nJune 3, 2023 Saturday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 455 words\nByline: Our Bureau\nHighlight: Difference in Parekh’s pay was because of lower stock options exercised compared to previous year\nBody\nBengaluru:Infosys chief executive Salil Parekh's remuneration fell 21% to `56.4 crore in fiscal year 2022-23, \naccording to India's second largest software exporter's annual report that was released on Friday. The difference \nwas because of lower stock options that he exercised compared with the previous year. Parekh's compensation \nincluded `30.6 crore in stock options, as he exercised 1,24,783 stock units under the 2015 stock option plan and \n73,962 units under the 2019 plan during the last fiscal year. \nIt also included `18.73 crore in variable pay and `45 lakh in retiral benefits. He took home `71 crore in the previous \nyear ended March 31, 2022 that included `52.33 crore worth of stock options exercised. The com-  pensation of his \nWipro counterpart, Thierry Delaporte, fell 5% to $10 million (or ` 83 crore) in FY23, according to the filings of the \ncompany with US regulators, as reported last week. Chairman Rishad Premji's compensation in dollar terms halved \nto $951,353 last fiscal year. Infosys executive chairman Nandan Nilekani did not draw any remuneration for the \nyear. Chief financial officer Nilanjan Roy's compensation jumped 28% to ` 10.61 crore. Mohit Joshi, who stepped \ndown as a president in March, was paid `57.3 crore. He has been appointed as CEO designate of Tech Mahindra. \nNilekani said in his message to shareholders that if there is one overriding theme that defines the current world, it is \nthat “it is suffused with uncertainty”. “The cocktail of inflation, interest rates, geopolitics,war, demand volatility, \nsupply chain dislocations, the shift from efficiency to resilience and security, all stirring quickly and without warning, \nis what's before us. In any week, we  may oscillate from caution to optimism and back to caution based on the news \nof the day,” he wrote. He also lauded CEO Parekh and his global leadership team, for realising the value of \nadvanced digital technologies like artificial intelligence (AI) and cloud, and more recently, generative AI early. The \nIT industry veteran mentioned the demerits and limitations of the disruptive technology. The problems of AI \nhallucination, systemic biases, lack of explainability along with plenty of practical, ethical and intellectual property-\nrelated issues “remain open and up for debate”, he said. Parekh, in his letter to shareholders, said in the past few \nquarters, the global economy has been dealing with factors such as inflation, interest rate increases, and changes \nto the demand environment for companies in various industries. “Our strength in digital, cloud, and in automation, \nalong with cost efficiency capabilities have held us in good stead. These will continue to be critical in the evolving \neconomic environment,” he added.\nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Chatbots Are Not Sentient. Here's How They Work.",
        "media": "The New York Times",
        "time": "February 20, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "885 words",
        "byline": "By Cade Metz",
        "story_text": "Chatbots Are Not Sentient. Here's How They Work.\nThe New York Times\nFebruary 20, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 885 words\nByline: By Cade Metz\nBody\nNo, chatbots aren't sentient. Here's how their underlying technology works.\nMicrosoft released a new version of its Bing search engine last week, and unlike an ordinary search engine it \nincludes a chatbot that can answer questions in clear, concise prose. \n  Since then, people have noticed that some of what the Bing chatbot generates is inaccurate, misleading and \ndownright weird, prompting fears that it has become sentient, or aware of the world around it.\n  That's not the case. And to understand why, it's important to know how chatbots really work.\n  Is the chatbot alive?\n  No. Let's say that again: No!\n  In June, a Google engineer, Blake Lemoine, claimed that similar chatbot technology being tested inside Google \nwas sentient. That's false. Chatbots are not conscious and are not intelligent -- at least not in the way humans are \nintelligent.\n  Why does it seem alive then?\n  Let's step back. The Bing chatbot is powered by a kind of artificial intelligence called a neural network. That may \nsound like a computerized brain, but the term is misleading.\n  A neural network is just a mathematical system that learns skills by analyzing vast amounts of digital data. As a \nneural network examines thousands of cat photos, for instance, it can learn to recognize a cat.\n  Most people use neural networks every day. It's the technology that identifies people, pets and other objects in \nimages posted to internet services like Google Photos. It allows Siri and Alexa, the talking voice assistants from \nApple and Amazon, to recognize the words you speak. And it's what translates between English and Spanish on \nservices like Google Translate.\n  Neural networks are very good at mimicking the way humans use language. And that can mislead us into thinking \nthe technology is more powerful than it really is.\n  How exactly do neural networks mimic human language?\nChatbots Are Not Sentient. Here's How They Work.\n  About five years ago, researchers at companies like Google and OpenAI, a San Francisco start-up that recently \nreleased the popular ChatGPT chatbot, began building neural networks that learned from enormous amounts of \ndigital text, including books, Wikipedia articles, chat logs and all sorts of other stuff posted to the internet.\n  These neural networks are known as large language models. They are able to use those mounds of data to build \nwhat you might call a mathematical map of human language. Using this map, the neural networks can perform \nmany different tasks, like writing their own tweets, composing speeches, generating computer programs and, yes, \nhaving a conversation.\n  These large language models have proved useful. Microsoft offers a tool, Copilot, which is built on a large \nlanguage model and can suggest the next line of code as computer programmers build software apps, in much the \nway that autocomplete tools suggest the next word as you type texts or emails.\n  Other companies offer similar technology that can generate marketing materials, emails and other text. This kind \nof technology is also known as generative A.I.\n  Now companies are rolling out versions of this that you can chat with?\n  Exactly. In November, OpenAI released ChatGPT, the first time that the general public got a taste of this. People \nwere amazed -- and rightly so.\n  These chatbots do not chat exactly like a human, but they often seem to. They can also write term papers and \npoetry and riff on almost any subject thrown their way.\n  Why do they get stuff wrong?\n  Because they learn from the internet. Think about how much misinformation and other garbage is on the web.\n  These systems also don't repeat what is on the internet word for word. Drawing on what they have learned, they \nproduce new text on their own, in what A.I. researchers call a ''hallucination.''\n  This is why the chatbots may give you different answers if you ask the same question twice. They will say \nanything, whether it is based on reality or not.\n  If chatbots 'hallucinate,' doesn't that make them sentient?\n  A.I. researchers love to use terms that make these systems seem human. But hallucinate is just a catchy term for \n''they make stuff up.''\n  That sounds creepy and dangerous, but it does not mean the technology is somehow alive or aware of its \nsurroundings. It is just generating text using patterns that it found on the internet. In many cases, it mixes and \nmatches patterns in surprising and disturbing ways. But it is not aware of what it is doing. It cannot reason like \nhumans can.\n  Can't companies stop the chatbots from acting strange?\n  They are trying.\n  With ChatGPT, OpenAI tried controlling the technology's behavior. As a small group of people privately tested the \nsystem, OpenAI asked them to rate its responses. Were they useful? Were they truthful? Then OpenAI used these \nratings to hone the system and more carefully define what it would and would not do.\n  But such techniques are not perfect. Scientists today do not know how to build systems that are completely \ntruthful. They can limit the inaccuracies and the weirdness, but they can't stop them. One of the ways to rein in the \nodd behaviors is keeping the chats short.\nChatbots Are Not Sentient. Here's How They Work.\n  But chatbots will still spew things that are not true. And as other companies begin deploying these kinds of bots, \nnot everyone will be good about controlling what they can and cannot do.\n  The bottom line: Don't believe everything a chatbot tells you.\nhttps://www.nytimes.com/2023/02/16/technology/chatbots-explained.html\nGraphic\n \nPHOTO: Satya Nadella, Microsoft's chief executive, introduced a new Bing search engine this month. It includes a \nchatbot, which some fear seems too aware. (PHOTOGRAPH BY RUTH FREMSON/THE NEW YORK TIMES) This \narticle appeared in print on page B2.               \nLoad-Date: February 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Norman Zammitt, Californian Modernist, Had His Eye to the Sky; Critic’s Pick",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "ARTS; design",
        "length": "1036 words",
        "byline": "Jonathan Griffin",
        "story_text": "Norman Zammitt, Californian Modernist, Had His Eye to the Sky; Critic’s Pick\nThe New York Times \nMarch 14, 2024 Thursday 22:01 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: ARTS; design\nLength: 1036 words\nByline: Jonathan Griffin\nHighlight: The Light and Space artist who flew under the radar has his moment in the sun.\nBody\nThe Light and Space artist who flew under the radar has his moment in the sun.\nAesthetically, Los Angeles is mostly a mess. Unplanned, mismatched buildings sprout like fungus among the grid of \nits streets, whose orderly classicism is often disrupted by tectonically induced hills. Curbs crumble and sidewalks \ncrack beneath telegraph poles festooned with cables. Flamboyant succulents mingle with scrubby native plants.\nWhat aesthetic perfection Los Angeles offers is mainly in its skies. Breathtaking ombres of color ascend from the \nhorizon, even outside its “golden hour” — the famously lambent period before sunset — even without the haze that \namplifies these atmospheric special effects.\nIn the 1960s, many of this region’s most celebrated artists were inspired by the vault of the heavens, rather than the \ngritty realities on the streets beneath. They favored new media, technologies often developed by the local \naerospace industry. Traditional paint on canvas was often sidelined in favor of modern industrial materials such as \npoured resin, ground glass, lacquers and microfilm coatings.\nThe artist Norman Zammitt, a colorist who excelled as a painter, remains less well known than his peers in the Light \nand Space movement. (The artist died in 2007.) Finally, a survey exhibition of Zammitt’s art at the Palm Springs Art \nMuseum is taking visitors on a glorious tour through his chromatic investigations.\nBorn in 1931 in Toronto, Zammitt moved to Southern California as a teenager. In the 1960s, he experimented with \nmaking fashionably minimalist sculptures from acrylic resin and plexiglass, but hit his stride the following decade \nwith paintings on canvas in what became his signature style: horizontal bands of acrylic color, shifting incrementally \nthrough shades both sickly and sublime.\nThis exhibition, titled “Gradations” and curated by Sharrissa Iqbal, starts good and gets better. Between entrance \nwalls painted sunflower yellow, Zammitt’s panoramic painting “One,” from 1973, greets visitors. From a distance, \nthe painting seems mostly yellow too. But as you draw near, you’ll identify colors from inky black, along the bottom, \nrising through dioxazine purple, cerise, coral, orange, then five or six different tones of yellow, in widening bands. \nUp close, the painting, 16 feet wide, bathes you in radiant luminosity.\n“One” is Zammitt’s first large-scale iteration of what he would call his “Band Paintings.” Turn around in the gallery \nand you’ll see two more, both painted in 1975: “Green One” — which recalls the subaquatic rather than the aerial — \nand “Arctic Yellow.” As time went by, the bands became thinner, the colors became more subtly gradated, \nZammitt’s surfaces more pristine and his effects more ecstatic.\nZammitt applied himself to his work with a lab technician’s precision. According to a wall text, by the mid-1970s he’d \ndeveloped a “complex mathematical system” for mixing his colors, weighing out pigments according to curves on a \nNorman Zammitt, Californian Modernist, Had His Eye to the Sky Critic’s Pick\ngraph. When I asked, Iqbal was unable to fully elucidate this process, although she did reveal that during the 1980s \nZammitt began working with mathematicians at the California Institute of Technology who showed him how \ncomputers could help him develop more complex variables for his color charts. When desktop computers became \naffordable, he bought one and commissioned a custom program that enabled him to formulate gradations of colors.\nRunning down either side of the gallery are rows of smaller paintings, many just eight or nine inches wide, that \nseem to serve as studies for his larger works. Hanging near most of the mighty paintings are their mini-me \ncompanions. An exhibition of these small canvases — exquisite objects in themselves — recently opened at Karma \nin Los Angeles, and that gallery is credited, along with Zammitt’s estate, with supplying most of the works for this \nshow.\nThe sky wasn’t Zammitt’s only visual reference. One especially dazzling painting from 1976, “North Wall,” achieves \nholograph illusions of depth, its horizontal bands pulsating before our eyes. It brings to mind Mexican serape \nblankets, or Native American weavings. Though he seldom advertised it, Zammitt’s mother was from the Mohawk \nNation and the family spent time living on the Kahnawake Mohawk Territory, a First Nations reserve near Montreal \nbefore moving to California.\nIqbal conjectures that Zammitt’s Native American heritage may have led him to view abstraction as a path toward \nspiritual transcendence. The artist himself remained largely mute on the subject. An early laminated acrylic \nsculpture, its layers sandwiching optically dazzling layers of rainbow dots, is titled “Caugnawaga II” — an alternative \nspelling of the reserve where Zammitt once lived — but the piece itself bears no overt relevance to Mohawk culture.\nThe exhibition contains an unexpected plot twist: In the late 1980s, Zammitt’s razor-straight lines and flat color \ndisintegrated in what he called “Fractal” paintings. A spectacular example of this style is the latest work in the show: \n“Triptych XI,” painted in 1992. It is an extraordinarily complex painting, an interlocking jigsaw of jagged forms, \nperhaps inspired by a coastline or cloudscape, loosely painted in dusky shades that ascend into blackness.\nWhy is Zammitt emerging from relative obscurity only now, in this artistic moment of generative A.I. and arcana, \nsocial activism and breakfast-table still lifes? Perhaps Zammitt’s art strikes a chord because it transcends its \nhistorical period — and ours, too. Not only do his paintings look as fresh as they must have when new, but they lift \nus out of our vexed and messy present, connecting us with the eternal.\nNorman Zammitt: Gradations\nThrough Oct. 7, Palm Springs Art Museum, 101 Museum Drive, Palm Springs, Calif., psmuseum.org.\nPHOTOS: Top, “Triptych XI” (1992), part of the Norman Zammitt show “Gradations.” Center left: “One” (1973) in the \nforeground, and “North Wall” (1976), partially obscured in the background. Center right: “Caly-forny-ay” (1987). \nAbove, \nfrom \nleft: \n“Green \nOne” \n(1975); \nand \n“Caugnawaga \nII” \n(1966). \n(PHOTOGRAPHS \nBY \nRJ \nSÁNCHEZ/SOLSTREAM STUDIOS, VIA PALM SPRINGS ART MUSEUM; ESTATE OF NORMAN ZAMMITT AND \nKARMA) This article appeared in print on page C12.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Microsoft Makes High-Stakes Play in Tech Cold War With Emirati A.I. Deal",
        "media": "The New York Times",
        "time": "April 16, 2024",
        "section": "Section ; Column 0; Business/Financial Desk",
        "length": "1403 words",
        "byline": "By Paul Mozur and David E. Sanger",
        "story_text": "Microsoft Makes High-Stakes Play in Tech Cold War With Emirati A.I. Deal\nThe New York Times\nApril 16, 2024 Tuesday\nThe New York Times on the Web\nCopyright 2024 The New York Times Company\nSection: Section ; Column 0; Business/Financial Desk\nLength: 1403 words\nByline: By Paul Mozur and David E. Sanger\nBody\nMicrosoft plans to invest $1.5 billion in G42, an Emirati company with ties to China, as Washington and Beijing \nmaneuver to secure tech influence in the Gulf.\nMicrosoft on Tuesday plans to announce a $1.5 billion investment in G42, an artificial intelligence giant in the United \nArab Emirates, in a deal largely orchestrated by the Biden administration to box out China as Washington and \nBeijing battle over who will exercise technological influence in the Gulf region and beyond. \n  Under the partnership, Microsoft will give G42 permission to sell Microsoft services that use powerful A.I. chips, \nwhich are used to train and fine-tune generative A.I. models. In return, G42, which has been under scrutiny by \nWashington for its ties to China, will use Microsoft's cloud services and accede to a security arrangement \nnegotiated in detailed conversations with the U.S. government. It places a series of protections on the A.I. products \nshared with G42 and includes an agreement to strip Chinese gear out of G42's operations, among other steps.\n  ''When it comes to emerging technology, you cannot be both in China's camp and our camp,'' said Gina \nRaimondo, the Commerce Secretary, who traveled twice to the U.A.E. to talk about security arrangements for this \nand other partnerships.\n  The accord is highly unusual, Brad Smith, Microsoft's president, said in an interview, reflecting the U.S. \ngovernment's extraordinary concern about protecting the intellectual property behind A.I. programs.\n  ''The U.S. is quite naturally concerned that the most important technology is guarded by a trusted U.S. company,'' \nsaid Mr. Smith, who will take a seat on G42's board.\n  The investment could help the United States push back against China's rising influence in the Gulf region. If the \nmoves succeed, G42 would be brought into the U.S. fold and pare back its ties with China. The deal could also \nbecome a model for how U.S. firms leverage their technological leadership in A.I. to lure countries away from \nChinese tech, while reaping huge financial awards.\n  But the matter is sensitive, as U.S. officials have raised questions about G42. This year, a congressional \ncommittee wrote a letter urging the Commerce Department to look into whether G42 should be put under trade \nrestrictions for its ties to China, which include partnerships with Chinese firms and employees who came from \ngovernment-connected companies.\n  In an interview, Ms. Raimondo, who has been at the center of an effort to prevent China from obtaining the most \nadvanced semiconductors and the equipment to make them, said the agreement ''does not authorize the transfer of \nMicrosoft Makes High-Stakes Play in Tech Cold War With Emirati A.I. Deal\nartificial intelligence, or A.I. models, or GPUs'' -- the processors needed to develop A.I. applications -- and ''assures \nthose technologies can be safely developed, protected and deployed.''\n  While the U.A.E. and United States did not sign a separate accord, Ms. Raimondo said, ''We have been \nextensively briefed and we are comfortable that this agreement is consistent with our values.''\n  In a statement, Peng Xiao, the group chief executive of G42, said that ''through Microsoft's strategic investment, \nwe are advancing our mission to deliver cutting-edge A.I. technologies at scale.''\n  The United States and China have been racing to exert technological influence in the Gulf, where hundreds of \nbillions of dollars are up for grabs and major investors, including Saudi Arabia, are expected to spend billions on the \ntechnology. In the rush to diversify away from oil, many leaders in the region have set their sights on A.I. -- and \nhave been happy to play the United States and China off each other.\n  Although the U.A.E. is an important U.S. diplomatic and intelligence partner, and one of the largest buyers of \nAmerican weapons, it has increasingly expanded its military and economic ties with China. A portion of its domestic \nsurveillance system is built on Chinese technology and its telecommunications work on hardware from Huawei, a \nChinese supplier. That has fed the worries of U.S. officials, who often visit the Persian Gulf nation to discuss \nsecurity issues.\n  But U.S. officials are also concerned that the spread of powerful A.I. technology critical to national security could \neventually be used by China or by Chinese government-linked engineers, if not sufficiently guarded. Last month, a \nU.S.  cybersecurity review board sharply criticized Microsoft over a hack in which Chinese attackers gained access \nto data from top officials. Any major leak -- for instance, by G42 selling Microsoft A.I. solutions to companies set up \nin the region by China -- would go against Biden administration policies that have sought to limit China's access to \nthe cutting-edge technology.\n  ''This is among the most advanced technology that the U.S. possesses,'' said Gregory Allen, a researcher at the \nCenter for Strategic and International Studies and a former U.S. defense official who worked on A.I. ''There should \nbe very strategic rationale for offshoring it anywhere.''\n  For Microsoft, a deal with G42 offers potential access to huge Emirati wealth. The company, whose chairman is \nSheikh Tahnoon bin Zayed, the Emirates' national security adviser and the younger brother of the country's ruler, is \na core part of the U.A.E.'s efforts to become a major A.I. player.\n  Despite a name whimsically drawn from ''The Hitchhiker's Guide to the Galaxy,'' in which the answer to the \n''ultimate question of life'' is 42, G42 is deeply embedded in the Emirati security state. It specializes in A.I. and \nrecently worked to build an Arabic chatbot, called Jais.\n  G42 is also focused on biotechnology and surveillance. Several of its executives, including Mr. Xiao, were \nassociated with a company called DarkMatter, an Emirati cyber-intelligence and hacking firm that employs former \nspies.\n  In its letter this year, the bipartisan House Select Committee on the Chinese Communist Party said Mr. Xiao was \nconnected to an expansive network of companies that ''materially support'' the Chinese military's technological \nadvancement.\n  The origins of Tuesday's accord go back to White House meetings last year, when top national security aides \nraised the question with tech executives of how to encourage business arrangements that would deepen U.S. ties \nto firms around the world, especially those China is also interested in.\n  Under the agreement, G42 will cease using Huawei telecom equipment, which the United States fears could \nprovide a backdoor for the Chinese intelligence agencies. The accord further commits G42 to seeking permission \nbefore it shares its technologies with other governments or militaries and prohibits it from using the technology for \nsurveillance. Microsoft will also have the power to audit G42's use of its technology.\nMicrosoft Makes High-Stakes Play in Tech Cold War With Emirati A.I. Deal\n  G42 would get use of A.I. computing power in Microsoft's data center in the U.A.E., sensitive technology that \ncannot be sold in the country without an export license. Access to the computing power would likely give G42 a \ncompetitive edge in the region. A second phase of the deal, which could prove even more controversial and has not \nyet been negotiated, could transfer some of Microsoft's A.I. technology to G42.\n  American intelligence officials have raised concerns about G42's relationship to China in a series of classified \nassessments, The New York Times previously reported. Biden administration officials have also pushed their \nEmirati counterparts to cut the company's ties to China. Some officials believe the U.S. pressure campaign has \nyielded some results, but remain concerned about less overt ties between G42 and China.\n  One G42 executive previously worked at the Chinese A.I. surveillance company Yitu, which has extensive ties to \nChina's security services and runs facial-recognition powered monitoring across the country. The company has also \nhad ties to a Chinese genetics giant, BGI, whose subsidiaries were placed on a blacklist by the Biden administration \nlast year. Mr. Xiao also led a firm that was involved in 2019 in starting and operating a social media app, ToTok, \nthat U.S. intelligence agencies said was an Emirati spy tool used to harvest user data.\n  In recent months, G42 has agreed to walk back some of its China ties, including divesting a stake it took in TikTok \nowner ByteDance and pulling out Huawei technology from its operations, according to U.S. officials.\n  Edward Wong contributed reporting.Edward Wong contributed reporting.\nhttps://www.nytimes.com/2024/04/16/technology/microsoft-g42-uae-ai.html\nGraphic\n \nPHOTO:  (PHOTOGRAPH BY Grant Hindsley for The New York Times FOR THE NEW YORK TIMES)               \nLoad-Date: April 16, 2024"
    },
    {
        "file_name": "Stanley_executive_Nov2023",
        "header": "For financial services companies, India’s best market for tech talent: Morgan",
        "media": "Stanley executive",
        "time": "November 6, 2023",
        "section": "TECH & INTERNET",
        "length": "705 words",
        "byline": "Beena Parmar",
        "story_text": "For financial services companies, India’s best market for tech talent: Morgan \nStanley executive\nThe Economic Times\nNovember 6, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 705 words\nByline: Beena Parmar\nBody\nAmid an overwhelming demand for niche technology skills in the financial services industry, India is likely to be the \nbest market for such talent, a top executive at Morgan Stanley said.India is currently the second largest location in \nterms of tech headcount outside the US for the multinational financial services firms, Michael Pizzi, managing \ndirector and head of US banks & technology at Morgan Stanley, told ET.India has around 8,000 people, or one-third \nof its 24,000 global tech workforce, said Pizzi, who is on his first India visit to mark 30 years of the company’s \noperations in this country.“We came to India years ago for cost and efficiency, but we're here today for talent. This \nis one of the best, maybe the best market for technology talent in the world, and that's why we're here,” Pizzi \nsaid.Pizzi said the India tech team has more than doubled in the last three years. Morgan Stanley is on the lookout \nfor new talent to be added in the critical skill sets, especially across the newer technologies such as cloud and \ngenerative AI, he said, but did not say how many people it plans to hire.“There's a clear need for continuing to \nbuild talent in those areas ... And it's about where we can access the best engineering talent,” Pizzi said, adding: \n“We grew faster in India than what anyone thought.”In India, the company has established two global capability \ncentres (GCCs) — one in Mumbai (set up in 2003) and the second in Bengaluru (2014). These house multiple \nbusiness units like technology, operations, finance, fund services, legal and compliance, HR, prime brokerage, \ninternal audit, risk management, fixed income research and parametric.Morgan Stanley is expanding and investing \nin its investment banking business and the trading products its offers in the Indian market.Pizzi, who was appointed \nas the head of technology in January this year, was previously the chief executive of E*Trade, an online trading \nplatform for retail investors that was acquired by Morgan Stanley in 2020.Morgan Stanley is among the first financial \nservices firms to have a real tool in the marketplace for financial advisors in wealth management, using generative \nAI through the partnership with OpenAI before ChatGPT burst onto the market, he said. \nThe tool, AI @ Morgan Stanley Assistant, was developed by teams in India and the US.The financial services firm \nsees two opportunities — content retrieval or summarisation — where AI can immediately change the landscape of \nproductivity.Pizzi said India has helped support and build the models which helped Morgan Stanley bring its \nintellectual capital into tech advisors’ hands in seconds and in an easily digestible format.“Think of it as having our \nchief investment strategist, chief global economist and global equities strategist on call 24 hours a day,” he \nadded.He said: “As the firm grows, our presence in India grows ... As we take on new projects, it will almost \nuniversally involve technologists in India. As we scale up and build up across all the different dimensions of \ngenerative AI, we continue to do our cloud work.”On India’s digitisation, Pizzi said: “What's happening in India to \nmake it (digitisation) public infrastructure is amazing because the power it has, it's like physical infrastructure...to \nfundamentally change and reshape the economy.”Globally, Morgan Stanley manages $6.2 trillion of client assets \nacross both wealth management and investment management business as of the end of September quarter. The \nfirm provides investment banking, securities, wealth management and investment management services.Pizzi said \nbesides having several senior-level female technologists, overall women comprised 36% (ex-campus) and 44% of \ncampus of all new lateral hires by the company in India in 2022. It also launched a Return to Work (RTW) \nFor financial services companies, India ’s best market for tech talent: Morgan Stanley executive\nprogramme, which provides opportunities for skilled professionals to re-engage with the workforce after a career \nbreak of over two years. In India, this was launched in 2015 as a 16-week paid internship.“We have several senior \nwomen technologists in our India organisation and in addition to gender, we also have a focus on LGBT+, people \nwith disabilities and veterans,” he said. For Reprint Rights: timescontent.com\nLoad-Date: November 6, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Senators Ask For Package To Limit Tech",
        "media": "The New York Times",
        "time": "May 16, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "800 words",
        "byline": "By Cecilia Kang and David McCabe",
        "story_text": "Senators Ask For Package To Limit Tech\nThe New York Times\nMay 16, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 800 words\nByline: By Cecilia Kang and David McCabe\nBody\nTheir plan is the culmination of a yearlong listening tour on the dangers of the new technology.\nA bipartisan group of senators released a long-awaited legislative plan for artificial intelligence on Wednesday, \ncalling for billions in funding to propel American leadership in the technology while offering few details on \nregulations to address its risks. \n  In a 20-page document titled ''Driving U.S. Innovation in Artificial Intelligence,'' the Senate leader, Chuck Schumer, \nand three colleagues called for spending $32 billion annually by 2026 for government and private-sector research \nand development of the technology.\n  The lawmakers recommended creating a federal data privacy law and said they supported legislation, planned for \nintroduction on Wednesday, that would prevent the use of realistic misleading technology known as deepfakes in \nelection campaigns. But they said congressional committees and agencies should come up with regulations on A.I., \nincluding protections against health and financial discrimination, the elimination of jobs, and copyright violations \ncaused by the technology.\n  ''It's very hard to do regulations because A.I. is changing too quickly,'' Mr. Schumer, a New York Democrat, said in \nan interview. ''We didn't want to rush this.''\n  He designed the road map with two Republican senators, Mike Rounds of South Dakota and Todd Young of \nIndiana, and a fellow Democrat, Senator Martin Heinrich of New Mexico, after their yearlong listening tour to hear \nconcerns about new generative A.I. technologies. Those tools, like OpenAI's ChatGPT, can generate realistic and \nconvincing images, videos, audio and text. Tech leaders have warned about the potential harms of A.I., including \nthe obliteration of entire job categories, election interference, discrimination in housing and finance, and even the \nreplacement of humankind.\n  The senators' decision to delay A.I. regulation widens a gap between the United States and the European Union, \nwhich this year adopted a law that prohibits A.I.'s riskiest uses, including some facial recognition applications and \ntools that can manipulate behavior or discriminate. The European law requires transparency around how systems \noperate and what data they collect. Dozens of U.S. states have also proposed privacy and A.I. laws that would \nprohibit certain uses of the technology.\n  Outside of recent legislation mandating the sale or ban of the social media app TikTok, Congress hasn't passed \nmajor tech legislation in years, despite multiple proposals.\nSenators Ask For Package To Limit Tech\n  ''It's disappointing because at this point we've missed several windows of opportunity to act while the rest of the \nworld has,'' said Amba Kak, a co-executive director of the nonprofit AI Now Institute and a former adviser on A.I. to \nthe Federal Trade Commission.\n  Mr. Schumer's efforts on A.I. legislation began in June with a series of high-profile forums that brought together \ntech leaders including Elon Musk of Tesla, Sundar Pichai of Google and Sam Altman of OpenAI.\n  (The New York Times has sued OpenAI and its partner, Microsoft, over use of the publication's copyrighted works \nin A.I. development.)\n  Mr. Schumer said in the interview that through the forums, lawmakers had begun to understand the complexity of \nA.I. technologies and how expert agencies and congressional committees were best equipped to create regulations.\n  The legislative road map encourages greater federal investment in the growth of domestic research and \ndevelopment.\n  ''This is sort of the American way -- we are more entrepreneurial,'' Mr. Schumer said in the interview, adding that \nthe lawmakers hoped to make ''innovation the North Star.''\n  In a separate briefing with reporters, he said the Senate was more likely to consider A.I. proposals piecemeal \ninstead of in one large legislative package.\n  ''What we'd expect is that we would have some bills that certainly pass the Senate and hopefully pass the House \nby the end of the year,'' Mr. Schumer said. ''It won't cover the whole waterfront. There's too much waterfront to \ncover, and things are changing so rapidly.''\n  He added that his staff had spoken with Speaker Mike Johnson's office\n  Maya Wiley, president of the Leadership Conference on Civil and Human Rights, participated in the first forum. \nShe said that the closed-door meetings were ''tech industry heavy'' and that the report's focus on promoting \ninnovation overshadowed the real-world harms that could result from A.I. systems, noting that health and financial \ntools had already shown signs of discrimination against certain ethnic and racial groups.\n  Ms. Wiley has called for greater focus on the vetting of new products to make sure they are safe and operate \nwithout biases that can target certain communities.\n  ''We should not assume that we don't need additional rights,'' she said.\nhttps://www.nytimes.com/2024/05/15/technology/ai-schumer-roadmap-congress.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: May 16, 2024"
    },
    {
        "file_name": "Spend_enough_time_with_ChatGPT_and_other_artificial_intelligence_chatbots_Aug2023",
        "header": "Chatbots sometimes make things up. Is AI's hallucination problem fixable?;",
        "media": "Spend enough time with ChatGPT and other artificial intelligence chatbots",
        "time": "August 1, 2023",
        "section": "NATION WORLD",
        "length": "1137 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Chatbots sometimes make things up. Is AI's hallucination problem fixable?; \nSpend enough time with ChatGPT and other artificial intelligence chatbots \nand it doesn't take long for them to spout falsehoods\nDayton Daily News (Ohio)\nAugust 1, 2023 Tuesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1137 words\nByline: MATT O'BRIEN\nBody\nSpend enough time with ChatGPT and other artificial intelligence chatbots and it doesn't take long for them to spout \nfalsehoods.\nDescribed as hallucination, confabulation or just plain making things up, it's now a problem for every business, \norganization and high school student trying to get a generative AI system to compose documents and get work \ndone. Some are using it on tasks with the potential for high-stakes consequences, from psychotherapy to \nresearching and writing legal briefs. \n\"I don't think that there's any model today that doesn't suffer from some hallucination,\" said Daniela Amodei, co-\nfounder and president of Anthropic, maker of the chatbot Claude 2. \n\"They're really just sort of designed to predict the next word,\" Amodei said. \"And so there will be some rate at which \nthe model does that inaccurately.\" \nAnthropic, ChatGPT-maker OpenAI and other major developers of AI systems known as large language models say \nthey're working to make them more truthful. \nHow long that will take  and whether they will ever be good enough to, say, safely dole out medical advice  remains \nto be seen. \n\"This isn't fixable,\" said Emily Bender, a linguistics professor and director of the University of Washington's \nComputational Linguistics Laboratory. \"It's inherent in the mismatch between the technology and the proposed use \ncases.\" \nA lot is riding on the reliability of generative AI technology. The McKinsey Global Institute projects it will add the \nequivalent of $2.6 trillion to $4.4 trillion to the global economy. Chatbots are only one part of that frenzy, which also \nincludes technology that can generate new images, video, music and computer code. Nearly all of the tools include \nsome language component. \nGoogle is already pitching a news-writing AI product to news organizations, for which accuracy is paramount. The \nAssociated Press is also exploring use of the technology as part of a partnership with OpenAI, which is paying to \nuse part of AP's text archive to improve its AI systems. \nIn partnership with India's hotel management institutes, computer scientist Ganesh Bagler has been working for \nyears to get AI systems, including a ChatGPT precursor, to invent recipes for South Asian cuisines, such as novel \nChatbots sometimes make things up. Is AI's hallucination problem fixable? Spend enough time with ChatGPT \nand other artificial intelligence chatbots and it doesn....\nversions of rice-based biryani. A single \"hallucinated\" ingredient could be the difference between a tasty and \ninedible meal. \nWhen Sam Altman, the CEO of OpenAI, visited India in June, the professor at the Indraprastha Institute of \nInformation Technology Delhi had some pointed questions. \n\"I guess hallucinations in ChatGPT are still acceptable, but when a recipe comes out hallucinating, it becomes a \nserious problem,\" Bagler said, standing up in a crowded campus auditorium to address Altman on the New Delhi \nstop of the U.S. tech executive's world tour. \n\"What's your take on it?\" Bagler eventually asked. \nAltman expressed optimism, if not an outright commitment. \n\"I think we will get the hallucination problem to a much, much better place,\" Altman said. \"I think it will take us a year \nand a half, two years. Something like that. But at that point we won't still talk about these. There's a balance \nbetween creativity and perfect accuracy, and the model will need to learn when you want one or the other.\" \nBut for some experts who have studied the technology, such as University of Washington linguist Bender, those \nimprovements won't be enough. \nBender describes a language model as a system for \"modeling the likelihood of different strings of word forms,\" \ngiven some written data it's been trained upon. \nIt's how spell checkers are able to detect when you've typed the wrong word. It also helps power automatic \ntranslation and transcription services, \"smoothing the output to look more like typical text in the target language,\" \nBender said. Many people rely on a version of this technology whenever they use the \"autocomplete\" feature when \ncomposing text messages or emails. \nThe latest crop of chatbots such as ChatGPT, Claude 2 or Google's Bard try to take that to the next level, by \ngenerating entire new passages of text, but Bender said they're still just repeatedly selecting the most plausible \nnext word in a string. \nWhen used to generate text, language models \"are designed to make things up. That's all they do,\" Bender said. \nThey are good at mimicking forms of writing, such as legal contracts, television scripts or sonnets. \n\"But since they only ever make things up, when the text they have extruded happens to be interpretable as \nsomething we deem correct, that is by chance,\" Bender said. \"Even if they can be tuned to be right more of the \ntime, they will still have failure modes  and likely the failures will be in the cases where it's harder for a person \nreading the text to notice, because they are more obscure.\" \nThose errors are not a huge problem for the marketing firms that have been turning to Jasper AI for help writing \npitches, said the company's president, Shane Orlick. \n\"Hallucinations are actually an added bonus,\" Orlick said. \"We have customers all the time that tell us how it came \nup with ideas  how Jasper created takes on stories or angles that they would have never thought of themselves.\" \nThe Texas-based startup works with partners like OpenAI, Anthropic, Google or Facebook parent Meta to offer its \ncustomers a smorgasbord of AI language models tailored to their needs. For someone concerned about accuracy, it \nmight offer up Anthropic's model, while someone concerned with the security of their proprietary source data might \nget a different model, Orlick said. \nOrlick said he knows hallucinations won't be easily fixed. He's counting on companies like Google, which he says \nmust have a \"really high standard of factual content\" for its search engine, to put a lot of energy and resources into \nsolutions. \nChatbots sometimes make things up. Is AI's hallucination problem fixable? Spend enough time with ChatGPT \nand other artificial intelligence chatbots and it doesn....\n\"I think they have to fix this problem,\" Orlick said. \"They've got to address this. So I don't know if it's ever going to \nbe perfect, but it'll probably just continue to get better and better over time.\" \nTechno-optimists, including Microsoft co-founder Bill Gates, have been forecasting a rosy outlook. \n\"I'm optimistic that, over time, AI models can be taught to distinguish fact from fiction,\" Gates said in a July blog \npost detailing his thoughts on AI's societal risks. \nHe cited a 2022 paper from OpenAI as an example of \"promising work on this front.\" More recently, researchers at \nthe Swiss Federal Institute of Technology in Zurich said they developed a method to detect some, but not all, of \nChatGPT's hallucinated content and remove it automatically. \nBut even Altman, as he markets the products for a variety of uses, doesn't count on the models to be truthful when \nhe's looking for information. \n\"I probably trust the answers that come out of ChatGPT the least of anybody on Earth,\" Altman told the crowd at \nBagler's university, to laughter.\nGraphic\n \nFILE - Text from the ChatGPT page of the OpenAI website is shown in this photo, in New York, Feb. 2, 2023. \nAnthropic, ChatGPT-maker OpenAI and other major developers of AI systems known as large language models say \nthey're hard at work to make them more truthful. (AP Photo/Richard Drew, File)\nLoad-Date: August 1, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Discussions on Chip Fabrication Scaling, Manufacturing Investments",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 8, 2023",
        "section": "FRONT PAGE",
        "length": "783 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Discussions on Chip Fabrication Scaling, Manufacturing Investments\nEconomic Times (E-Paper Edition)\nSeptember 8, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 783 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Plan to expand workforce in India, focus on upskilling, says Huang\nBody\nCEO MEETS IISC , IIT RESEARCHERS\nBengaluru: Nvidia, the world's pre-eminent maker of hardware and software for artificial intelligence tools, envisions \nexporting AI products from its Indian arm, CEO and cofounder of the $27-billion firm, Jensen Huang told \nresearchers at India's top technology institutes this week, according to the people present at the interaction. India is \nevolving into a “front end” nation in the world of technology, the 60-year-old technocrat told his audience during his \nongoing visit in the country, which included a meeting with Prime Minister Narendra Modi on September 4.  The \nAmerican chipmaker, which is riding on a trillion-dollar valuation led by the boom in generative Artificial \nIntelligence (AI), expects to leverage the vast data generated by India's $1.4 billion population to build AI products \nthat can be exported from the country. Huang, who co-founded the Santa Clara-based technology giant in 1993, \nmet researchers from the Indian Institute of Science's (IISc) department of computational and data sciences (CDS), \nIndian Institute of Technology (IIT) Madras and IIT Bombay on September 4 during the course of his week-long \nvisit. Sashikumar Ganesan, associate professor and chair of CDS at IISc, Bengaluru, told ET that the discussions at \nthe HPC and AI Research Leaders Meet revolved around leaders in artificial intelligence (AI) and highperformance \ncomputing (HPC), which is Nvidia's primary business domain. \nHuang communicated plans to expand Nvidia's workforce in India and focus on upskilling. “Although we may lack \nthe ecosystem to collect all data, once acquired, all AI and machine learning systems for the world can be trained \non it. This is one of the reasons why technology companies invest heavily in India,” Ganesan said. Discussions \nduring the meeting encompassed India's potential to lead AI research, chip fabrication scaling, and investments in \nmanufacturing. TRILLION-DOLLAR CLUB Nvidia manufactures semiconductor chips that are integral to the \nfunctioning of AI-products built by the likes of Microsoft-backed OpenAI such as ChatGPT. As it rode the surging AI \nwave in 2023, Nvidia saw a record rise in demand for its chips, which are now at an all-time high. Nvidia reported a \nrevenue of $13.51 billion for the second quarter ended July 30, 2023, up 101% from a year ago. Its stock recently \nhit an all-time high after a surge of 315%. The company reached a market value of more than a trillion dollars in \nMay this year, joining the likes of Microsoft, Apple and Amazon. Following Microsoft's $10 billion investment into the \nSam Altman founded-OpenAI earlier this year, Google announced an aggressive follow-up through its own AI tool \nBard. Huang was keen to understand the nuances of high-perfor-  mance computing in India, its applications, and \nNvidia's role. Ajay Kumar Sood, a distinguished honorary professor of Physics at IISc and the principal scientific \nadvisor to the Indian government, was also among the attendees. INDIA FOCUS Nvidia began its operations in \nIndia in 2004 in Bengaluru and has four engineering development centres located in Gurugram, Hyderabad, Pune \nand Bengaluru with a workforce of 3,800 individuals in India. More than 320,000 India-based developers are part of \nNvidia's developer programme. Huang was updated on the research activities of CDS at IISc. “We're integrating \nmachine learning with computational science. Huang was curious about this intersection,” Ganesan said. He added \nDiscussions on Chip Fabrication Scaling, Manufacturing Investments\nthat Huang highlighted the importance of using data generated from the scientific community instead of synthetic \nmethods in AI systems. Other topics covered during the meeting included an India-focused cloud initiative and the \nNational Supercomputing Mission (NSM).  NSM aims to equip India with advanced supercomputing infrastructure, \naddressing the computational needs of various sectors.  “An upgraded version, NSM 2.0, will further enhance our \ncomputing capabilities,” said Ganesan. Huang has visited India several times over the past few years. The last \nmeeting held between Prime Minister Modi and Huang was five years ago in New Delhi.  Following the meeting \nearlier this week, PM Modi had posted on X, “Had an excellent meeting with Mr Jensen Huang, the CEO of \n@nvidia. We talked at length about the rich potential India offers in the world of AI.  Mr Jensen Huang was \nappreciative of the strides India has made in this sector and was equally upbeat about the talented youth of India.” \nThis comes at a time when technology executives, startup founders and venture capital chiefs are petitioning the \ngovernment to invest in developing India's AI compute-infrastructure.  FOR FULL REPORT, GO TO \nwww.economictimes.com\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Shield Urged For Workers Hurt by A.I.",
        "media": "The New York Times",
        "time": "May 24, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1650 words",
        "byline": "By Emma Goldberg",
        "story_text": "Shield Urged For Workers Hurt by A.I.\nThe New York Times\nMay 24, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1650 words\nByline: By Emma Goldberg\nBody\nTens of millions of jobs could be automated by generative artificial intelligence. The makers of new technologies \nare looking to the government to step in.\nWhen Congress held a series of hearings on jobs and technological advancement in October 1955, the head of a \nrailroad worker organization took the stand to express his fears about automation. ''There is uneasiness among our \nworkers as they assess the advance of the new technology,'' said W.P. Kennedy, president of the Brotherhood of \nRailroad Trainmen. ''Will it bring increasing unemployment rather than economic security?'' \n  The same question could have been raised before Congress last week in its hearing on artificial intelligence. In \neffect, it was.\n  Sam Altman, chief executive of the San Francisco start-up OpenAI, testified last Tuesday before members of a \nSenate subcommittee, urging the government to regulate the fast-growing A.I. industry. Congressional leaders \nshared their worries about the threats that A.I. could pose, including the spread of misinformation and privacy \nviolations.\n  One of their most emphatic concerns was job displacement: Who will assume responsibility to protect workers \nwhose jobs might be transformed, or even eliminated, by generative A.I.?\n  Senator Richard Blumenthal, Democrat of Connecticut, declared that his ''biggest nightmare in the long term'' is \nthe job loss that A.I. could cause, before saying to Mr. Altman, ''Let me ask you what your biggest nightmare is.''\n  ''There will be an impact on jobs,'' Mr. Altman replied. ''And I think it will require partnership between the industry \nand government, but mostly action by government.''\n  Mr. Altman, like so many other executives unleashing new technologies on the world, has asked the government \nto assume the bulk of responsibility in supporting workers through the labor market disruptions prompted by A.I. It's \nnot yet clear how government will rise to that task.\n  Generative A.I. could automate activities equivalent to 300 million full-time jobs globally, according to a recent \nestimate by Goldman Sachs. Already the chief executive of IBM said he expected A.I. to affect white-collar clerical \nstaffing, eliminating the need for up to 30 percent of certain roles while creating new ones. The White House on \nTuesday is hosting workers for a discussion of their experiences with automation and monitoring technologies in the \nworkplace.\n  Historically, when automation has led to job loss, the economic impact has tended to be offset by the creation of \nnew jobs. Generative artificial intelligence, according to the Goldman report, could raise America's labor \nShield Urged For Workers Hurt by A.I.\nproductivity growth by nearly 1.5 percentage points per year over a decade. It could increase annual global gross \ndomestic product by 7 percent. It could give rise to previously unimagined creative occupations.\n  But there will be immense instability for displaced workers. Automation has been a significant driver of income \ninequality in America, according to a study from researchers at the Massachusetts Institute of Technology and \nBoston University. By their estimates, 50 to 70 percent of changes in the U.S. wage structure since 1980 were due \nto loss of income among blue-collar and office workers because of automation.\n  Areas of the country where robots have been adopted most intensively, particularly manufacturing-heavy parts of \nthe Midwest, have also seen the most precipitous declines in employment, according to research from Daron \nAcemoglu, an economist at M.I.T.\n  While makers of A.I. have tended to focus on the technology's potential for job creation, many workers will \nexperience painful disruption as they try to train for and find new roles that pay well and are fulfilling.\n  ''We've never been in a period where the scope of automation is so wide potentially,'' said Harry Holzer, an \neconomist at Georgetown. ''Historically if your job gets automated, you find something new. With A.I. the thing that's \nkind of scary is it could simply grow and take over more tasks. It's a moving target.''\n  Workers in administrative and clerical support may have particular cause for concern about generative A.I., \naccording to the Goldman research. And many of them are already expressing anxieties.\n  ''It's definitely scary,'' said Justin Felt, 41, a customer service worker in Pittsburgh, who has worked for Verizon \nFios for nearly 12 years. He feels that employers have not been entirely upfront with their workers about the ways \nthey are incorporating generative A.I. into customer support roles, he said. ''It's definitely taking our work.''\n  These technologies are flooding into workplaces at a rapid clip. BuzzFeed just introduced a chatbot that offers up \nrecipe recommendations, McKinsey is helping clients use A.I. to fix technological bugs and the accounting firm \nKPMG is using ChatGPT to generate code. So some economists have begun putting forward proposals to protect \nthe workers most likely to be affected.\n  Workers could benefit, for example, from paid leave policies that allow them to take time away from their jobs to \ndevelop new skills. Germany already has a similar program, in which workers in most German states can take at \nleast five paid days a year for educational courses, an initiative the labor minister recently said he planned to \nexpand.\n  Another possibility is a displacement tax, levied on employers when a worker's job is automated but the person is \nnot retrained, which could make businesses more inclined to retrain workers. The government could also offer A.I. \ncompanies financial incentives to create products designed to augment what workers do, rather than replace them -\n- for example, A.I. that provides TV writers with research but doesn't draft scripts, which are likely to be of low \nquality.\n  ''If the government sets the agenda in developing technologies that are more complementary to humans, that \nwould be very important,'' Mr. Acemoglu said. ''Industry is looking to the government for leadership.''\n  The government's previous efforts to support workers through periods of job displacement have had mixed results. \nA study of Trade Adjustment Assistance, a U.S. government program that provides financial assistance and training \nfor workers who lose jobs because of trade, found that manufacturing employees who temporarily dropped out of \nthe work force to participate in the program in the early 2000s still hadn't caught up on earnings several years later \ncompared with workers who lost jobs but didn't qualify for T.A.A. support.\n  Many economists say employers could also play a role in helping displaced workers.\n  ''Business always looks to government to deal with job loss,'' said Simon Johnson, a professor at M.I.T. and a co-\nauthor with Mr. Acemoglu of the book ''Power and Progress.'' ''But Microsoft and Alphabet -- they are in the driver's \nseat, in regards to where they choose to put their technological resources.''\nShield Urged For Workers Hurt by A.I.\n  Workers could benefit, for example, from employer apprenticeships and retraining programs. The accounting giant \nPwC recently announced a $1 billion investment in generative A.I., which includes efforts to train its 65,000 \nworkers on how to use A.I. What spurred the initiative was the chief executive's trip to the World Economic Forum's \ngathering in Davos, Switzerland, where he heard constant discussion of generative A.I.\n  ''A number of us walking out of that room knew something had changed,'' recalled Joe Atkinson, the company's \nchief products and technology officer.\n  PwC's workers have expressed fears about displacement, according to Mr. Atkinson, especially as their company \nexplores automating roles with generative A.I. Mr. Atkinson stressed, though, that PwC planned to retrain people \nwith new technical skills so their work would change but their jobs wouldn't be eliminated.\n  Some tech companies are offering employees courses in cloud computing, cybersecurity and generative A.I. \nAmong them is IBM, which also has an apprenticeship program that trains workers, including those without four-\nyear degrees, for high-paying roles in fields like software development and data science. The company C3 AI offers \nits 1,000 employees bonuses of $250 to $1,500 for becoming certified in technological subjects including A.I. and \ncloud computing. KPMG is working to train every one of its employees to use generative A.I.\n  Community colleges are intensifying their focus on A.I., too. Miami Dade College has received over $15 million in \ngrants for its technology programs, with some of the money used to open two centers focused on preparing \nstudents for careers in A.I. Houston Community College recently announced a bachelor's degree in A.I. and \nrobotics, and Southwest Tennessee Community College is working to create an associate degree. The American \nAssociation of Community Colleges launched an A.I. incubator network focused on helping faculty teach about A.I. \nand colleges create A.I. degrees.\n  ''As Wayne Gretzky once said when asked about his success, 'I skate to where the puck is going,''' said Dennis \nNatali, a professor at Pikes Peak State College in Colorado, which released a plan this year to roll out A.I. \ncertificates. ''Our college constantly assesses the work force landscape and prepares to support displaced \nworkers.''\n  As colleges and businesses scramble to retrain workers, some experts are optimistic about this technological \ntransition. They note that throughout history people have feared technological advancement but often ended up \nbenefiting from it, going back to the Luddites, weavers who protested the mechanization of the textile industry.\n  But that doesn't mean the transition period will unfold smoothly. Michael Chui, an A.I. expert at McKinsey, pointed \nout that even the Luddites saw their income stagnate for decades.\n  ''Anyone who loses their job involuntarily -- it's a difficult time,'' he said. ''In some ways the Luddites weren't wrong \nabout the risk.''\nhttps://www.nytimes.com/2023/05/23/business/jobs-protections-artificial-intelligence.html\nGraphic\n \nPHOTO: Senator Richard Blumenthal, left, with Sam Altman, chief executive of OpenAI, before a hearing on A.I. \nlast week. (PHOTOGRAPH BY PATRICK SEMANSKY/ASSOCIATED PRESS) (B4) This article appeared in print \non page B1, B4.               \nLoad-Date: May 24, 2023\nShield Urged For Workers Hurt by A.I."
    },
    {
        "file_name": "MANUFACTURERS_Sep2023",
        "header": "AI IS SHAPING FUTURE OF PITTSBURGH'S MOST ICONIC",
        "media": "MANUFACTURERS",
        "time": "September 10, 2023",
        "section": "ASECTION; Pg. A-1",
        "length": "1611 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "AI IS SHAPING FUTURE OF PITTSBURGH'S MOST ICONIC \nMANUFACTURERS\nPittsburgh Post-Gazette\nSeptember 10, 2023 Sunday\nTWO STAR EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 1611 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nFrom steel to paint to ketchup, Pittsburgh's oldest and largest manufacturers are learning how to automate their \noperations with artificial intelligence.\nU.S. Steel is using \"MineMind,\" a generative AI tool created by Google Cloud, to keep trucks running smoothly at \nits largest iron ore mine.\nPPG Industries is creating paint schemes faster and more efficiently for the cars it coats in Europe.\nAnd last year, Heinz joined the AI marketing fray with a 55-second ad featuring computer-generated renderings of \nits popular tomato-based condiment.\nAlthough the specific technologies vary, executives say AI tools help their companies remain forward looking and \ncompetitive. What started as a trend for consumers and tech companies has now fully landed in one of the most \nhistorically entrenched sectors.\n\"We think AI is going to have a big impact on our business wholly, from our customer engagement all the way \nacross our operations,\" said Brad Budde, chief digital officer at Downtown-based PPG Industries.\nThe 140-year-old multinational manufacturer made $17.7 billion last year from its paints, coatings and specialty \nmaterials. But Mr. Budde said the company is not resting on its laurels.\n\"We've been really good at a lot of things to get to where we are today,\" he said. \"But the things that take us to the \nfuture, like AI, that's what we're talking about now.\"\nBroadly speaking, artificial intelligence allows computers to learn patterns from large swaths of data and make \nrecommendations based on that information. The technology was developed for decades before it burst into the \nspotlight in consumer-friendly tools such as ChatGPT last year.\nKim Forrest, a Pittsburgh-based investment manager, has been using some version of artificial intelligence since \nthe 1990s. Back then, she said, the data was so limited that \"you'd get really bad answers.\"\nNow the systems have reached a sort of holy trinity where \"we have enough data, we have fast enough computers \nand enough storage to create these models that solve problems really well.\"\nAt PPG, that data includes thousands of previous paint schemes, giving employees access to multiple lifetimes of \nexperience. They can use that digital data to work faster and create a better finished product, Mr. Budde said.\nAI IS SHAPING FUTURE OF PITTSBURGH'S MOST ICONIC MANUFACTURERS\n\"One point we really stress internally is that as these really experienced shaders start using this new technology, it \ndoesn't replace their jobs, it actually helps them be better at their jobs,\" Mr. Budde said. \"They are becoming \ntechnologists instead of artists.\"\nNot everyone is on board with the shift.\n\"There are a few people that are fearful of technology and the way that it could impact their job,\" Mr. Budde said.\nBut PPG tries to frame it as an opportunity for growth.\nOver at U.S. Steel, a bit of candor has helped engineers hop on the technological bandwagon.\nChief information officer Steven Bugajski said the Downtown-based company's first generative AI tool, which was \ndeveloped through a partnership with Google Cloud, has already learned some of the company's slang.\nWhen the maintenance techs call a pivot head wrench a dog bone, the computer knows what they're talking about. \n\"It's learning,\" Mr. Bugajski said.\nThe old dogs of industry, it would appear, also are learning a thing or two.\nU.S. Steel says its bet on AI is part of its 100-year legacy of innovation. But there's no denying the impact of AI's \nmainstream popularity. People in all sorts of companies are using ChatGPT and other related tools to spark \ncreativity or escape mundane tasks.\nA June poll of 486 small businesses nationwide found that 24% already had invested in AI or similar automation \ntechnology. Of that group, 91% said the technology helped to make business more successful, according to the \nConstant Contact report.\nDave Charest, a researcher who led the poll, said one of his favorite examples was a hot sauce company based in \nChicago that used AI to come up with new flavor profiles.\nFor what it's worth, Stello Foods Inc., Punxatawney-based purveyors of the Pittsburgh hot sauce \"Jag Off,\" does not \ncurrently use AI to automate any part of its business. \"Using AI for recipes is a creative idea but I do not know how \nmuch a robot could mimic human tastes, haha!\" the company said in a text.\n'You need to be playful'\nThere are major differences between consumer friendly tools like ChatGPT and the data processing that major \nmanufacturers are now testing. Companies often train their computers on their own proprietary information and \ntailor the output to get more specific predictions.\nBut one thing consumers and companies share is the ability to use AI to play.\n\"To innovate, you have to stop saying no to trying this stuff,\" said Patrick Patterson, CEO of Level Agency, a \nDowntown-based marketing group that helps businesses in the region and across the country incorporate AI. \"You \nneed to be playful.\"\nMr. Patterson said new tools allow companies to ask more questions without paying expensive consultant fees. \nEven the silly questions now get air time, he said, and that leads to greater innovation.\nIt shouldn't lead to job loss.\n\"With generative AI, you have to think of it as a tool, not a replacement,\" Mr. Patterson said. \"It will change the way \nyou fundamentally do business: If you don't need 45 quality assurance people, because you've replaced those 45 \nQA people with AI QA that is actually more accurate, then you have the opportunity to re-skill and educate those \npeople to do other jobs, knowledge-based jobs, and more creative jobs.\"\nAI IS SHAPING FUTURE OF PITTSBURGH'S MOST ICONIC MANUFACTURERS\nFor Mr. Patterson and other regional observers, the confluence of AI and manufacturing in Pittsburgh isn't all that \nsurprising.\nCarnegie Mellon University has long been in the national spotlight for its artificial intelligence programs, both at the \nundergraduate and graduate levels. For equally as long, Pittsburgh has been synonymous with steel and other \nmanufacturing staples.\nA few new companies have profited from the synergy.\nCitrine Informatics, an AI-backed chemicals and materials platform born out of Silicon Valley, opened a Pittsburgh \noutpost in 2017. At the time, CEO Greg Mulholland said, \"There is no city on the planet that is both a bulwark of a \nmaterials manufacturing economy and is on the cutting edge of AI.\"\nBut does it matter where cloud-based tech companies call home? For U.S. Steel, it did.\nMr. Bugajski said he frequents the Google offices in Pittsburgh, working collaboratively and even doing workshops \nthere. As for a difference between Google Cloud and its parent company, he said: \"I don't discern between the two. \nIt just said Google on the outside.\"\nIt could also matter for hundreds of college graduates looking to stay and work in the region.\nThe talented minds emerging from CMU and other top universities will have skills and expectations for a modern \nworkplace that includes AI, said Audrey Russo, president of the Pittsburgh Technology Council. It's like the pivot \nfrom typewriters to laptops, she said. No modern employer would still expect its employees to write with ink ribbon; \nnow they won't expect interns to write an email without a chatbot.\n\"There's an expectation that some of these technologies are going to become ubiquitous,\" Ms. Russo said.\nAs that happens, it won't just be CMU grads putting computers through their paces. Virtually anyone will be able to \ncommunicate ideas through code.\nA modern toolbelt\nFolks at the Advanced Robotics for Manufacturing, or ARM, Institute, a Lawrenceville-based nonprofit backed by \nthe Department of Defense, are already training manufacturing companies in Western Pennsylvania for that reality.\n\"Just because they're an old company doesn't mean they can't be forward thinking and evolve as time evolves,\" \nsaid Tasha Miller, the institute's technology development programs manager.\n\"As new technology comes out, it keeps them competitive, it keeps them going. I think PPG and U.S. Steel \nobviously have the same mindset considering that they're still around and still doing well.\"\nThrough her inaugural role, Ms. Miller has helped 25 manufacturers, including Atlas Metal and Murrysville-based \neLoop, learn how AI automation can help improve their operations.\nMs. Miller hopes to soon get her hands on a \"RoboGPT\" demo from Orangewood Labs in California that would \nallow non-programmers to control robotic arms and other bots without knowing a single line of code.\n\"What they're proposing sounds like it's going to change the game,\" she said.\nBut blindly implementing technology without understanding how it works could also create problems. Companies \nshould implement AI carefully and in selective places, Ms. Russo said.\n\"You want to make sure that the business case makes sense,\" she said.\nMs. Forrest, the investment manager, also said a slow rollout makes sense, though the pace can often be \nfrustrating for investors.\nAI IS SHAPING FUTURE OF PITTSBURGH'S MOST ICONIC MANUFACTURERS\nFor U.S. Steel, recent investments in technologies appear to be paying off. The company is currently weighing its \noptions after receiving multiple unsolicited offers, including a buyout offer from rival steelmaker Cleveland-Cliffs. AI-\nrelated projects had saved the Pittsburgh company $15 million by its quarter two earnings call earlier this year.\n\"New digital tools like generative AI provide us with tremendous opportunity to become a more productive and \nmore profitable U.S. Steel,\" CEO David Burritt told shareholders on the July 28 call. \"We are already seeing \nresults.\"\nMr. Patterson, of the Downtown-based Level Agency, said the select initiatives by U.S. Steel and PPG are smart \nforays into the new realm of possibilities.\n\"They were around through the Industrial Revolution, right? This is the same thing, it's just faster,\" he said.\nEvan Robinson-Johnson: ejohnson@post-gazette.com\nGraphic\n \nPHOTO: Courtesy of U.S. Steel: MineMind, U.S. Steel's first bet on generative AI, will use Google Cloud \ntechnologies to speed maintenance on more than 60 haul trucks, below, at its iron ore facilities in Minnesota, such \nas the one above.\nPHOTO: Courtesy of PPG: PPG will use artificial intelligence to improve quality control and color development at its \ncenter of excellence in Quattordio, Italy.\nPHOTO: Courtesy of U.S. Steel: U.S. Steel says its bet on artificial intelligence is part of its 100-year legacy of \ninnovation.\nLoad-Date: September 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Altman Reasserts Control of OpenAI and Regains a Seat on Its Board",
        "media": "The New York Times",
        "time": "March 10, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 19",
        "length": "1483 words",
        "byline": "By Cade Metz, Tripp Mickle and Mike Isaac",
        "story_text": "Altman Reasserts Control of OpenAI and Regains a Seat on Its Board\nThe New York Times\nMarch 10, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 19\nLength: 1483 words\nByline: By Cade Metz, Tripp Mickle and Mike Isaac\nBody\nMr. Altman, whose sudden firing and rehiring in the fall shocked Silicon Valley, was among several new additions to \nthe board announced on Friday.\nThe conclusion of an investigation into the chaotic firing of Sam Altman from OpenAI more than three months ago \nrepresented a resounding victory for the high-profile chief executive as he moves to reassert control of the artificial \nintelligence company he helped to create. \n  OpenAI, in a news conference on Friday, said that Mr. Altman, who returned to OpenAI just five days after he was \npushed out in November, did not do anything that justified his removal and would regain the one role at the \ncompany that still eluded him: a seat on the company's board of directors.\n  Mr. Altman's ouster stunned Silicon Valley and imperiled the future of one of the tech industry's most influential \nstart-ups. It also called into question whether OpenAI -- with or without Mr. Altman in charge -- was ready to carry \nthe banner for the tech industry's rabid focus on artificial intelligence.\n  When he returned to OpenAI in November, Mr. Altman did not regain his board seat while agreeing to an \ninvestigation of his behavior and the board's actions. Two members who voted for his removal agreed to step down; \ntheir replacements, from outside the company, oversaw the investigation by the law firm, WilmerHale. Bret Taylor, \nchairman of OpenAI's board, said during the news conference that the highly anticipated report about the episode \nwas finished, but the company did not release the report.\n  The company said that the law firm's report found that OpenAI's board acted within its broad discretion to \nterminate Mr. Altman, but also found that his conduct did not mandate removal.\n  ''The special committee recommended and the full board expressed their full confidence in Mr. Altman and Mr. \nBrockman,'' Mr. Taylor said, referring to Greg Brockman, the company president who quit in protest after Mr. Altman \nwas removed. ''We are excited and unanimous in our support for Sam and Greg.''\n  OpenAI also moved to address concerns about a lack of diversity on the board by adding three women as \ndirectors: Sue Desmond-Hellmann, the former chief executive of the Bill & Melinda Gates Foundation; Nicole \nSeligman, the former general counsel of Sony; and Fidji Simo, the chief executive of Instacart.\n  Mr. Taylor, who was one of the replacements named to OpenAI's board in November, said the board would \ncontinue to expand.\nAltman Reasserts Control of OpenAI and Regains a Seat on Its Board\n  With the report and the additions to the board, OpenAI's leadership hoped to move past the controversy of Mr. \nAltman's ouster. The incident raised myriad questions about his leadership and the San Francisco company's \nunusual structure -- a nonprofit board that oversees a for-profit company.\n  But because it has not released the report, OpenAI has left many questions unanswered about the company. \nSome insiders have asked whether Mr. Altman had too much control over how the investigation was handled.\n  ''As we told the investigators, deception, manipulation, and resistance to thorough oversight should be \nunacceptable,'' Helen Toner and Tasha McCauley, the two OpenAI board members who left late last year, said in a \nstatement. ''We hope the new board does its job in governing OpenAI and holding it accountable to the mission.''\n  Mr. Taylor appeared alongside Mr. Altman at the news conference on Friday. After announcing the new board \nmembers, he said the review found that the previous board acted in good faith in removing Mr. Altman but did not \nanticipate the challenges that would arise from his dismissal.\n  ''The review determined the board's decision did not arise from concern regarding product safety or security,'' Mr. \nTaylor said. ''It was simply a breakdown in trust between the board and Mr. Altman.''\n  After Mr. Taylor completed his prepared remarks, Mr. Altman praised the resilience of the company and its \npartners during and after his removal. ''I am pleased this whole thing is over,'' he said.\n  OpenAI provided a six-paragraph summary of the report. It said that WilmerHale reviewed 30,000 documents and \nconducted dozens of interviews, including with OpenAI's previous board members.\n  It found that the previous board was accurate in its rationale and public explanation for firing Mr. Altman for not \nbeing ''consistently candid in his communications with the board.'' It also said that the board didn't anticipate that its \naction would destabilize the company.\n  The company said that WilmerHale gave oral briefings on the report, which will not be publicly released, to Mr. \nTaylor and Lawrence H. Summers, the former Treasury secretary who was also added to the board in November.\n  Mr. Taylor said OpenAI had made several changes meant to improve the way the company was run, including \nnew governance guidelines for the board, a new conflict of interest policy and a whistle-blower hotline.\n  OpenAI's summary of the report did not provide insight into the concerns that the company's senior leaders \nbrought to the previous board about Mr. Altman. Before his dismissal, Ilya Sutskever, OpenAI's chief scientist, and \nMira Murati, OpenAI's chief technology officer, expressed worries about Mr. Altman's management style, including \nwhat was characterized as his history of manipulative behavior, The New York Times has reported.\n  Dr. Sutskever, through a lawyer, has called those claims ''false.'' Ms. Murati said in a company Slack post on \nThursday that she shared the same feedback with the board that she had provided directly to Mr. Altman, but said \nshe never reached out to the board to share those concerns.\n  ''I am happy that the independent review has concluded and we can all move forward united,'' Ms. Murati said on \nFriday in a post on X, formerly called Twitter.\n  OpenAI is still being investigated by the Securities and Exchange Commission over the board's actions and the \npossibility that Mr. Altman misled investors. Companies that hire outside law firms often turn over the report to \npublic investigators after completion. A spokeswoman for OpenAI's board declined to say whether it would provide \nthe report to the S.E.C.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  OpenAI, which was valued at more than $80 billion in its latest financing round, sits at the forefront of generative \nA.I., technologies that can generate text, images and sounds. Many believe that generative A.I. could transform \nAltman Reasserts Control of OpenAI and Regains a Seat on Its Board\nthe technology industry as thoroughly as the web browser did about three decades ago. Others worry that the \ntechnology could cause serious harm, helping to spread online disinformation, replacing countless jobs and maybe \neven threatening the future of humanity.\n  After OpenAI released the online chatbot ChatGPT in late 2022, Mr. Altman became the face of the industry's \npush toward generative A.I. About a year later, the board unexpectedly dismissed him, saying it no longer had \nconfidence in his ability to run the company.\n  The board had shrunk to six people: three founders and three independent members. Along with the three \noutsiders, Dr. Sutskever, one of OpenAI's founders, voted to remove Mr. Altman as chief executive and chairman of \nthe board, saying without providing specifics that he had not been ''consistently candid in his communications.''\n  Mr. Brockman, another founder, resigned from the company in protest. Days later, Dr. Sutskever said he regretted \nhis decision to remove Mr. Altman and effectively stepped down from the board, leaving three independent \nmembers standing in opposition to Mr. Altman.\n  OpenAI was founded as a nonprofit in 2015, before Mr. Altman created a for-profit subsidiary three years later and \nraised $1 billion from Microsoft. The board of the nonprofit, whose stated mission was to build A.I. for the benefit of \nhumanity, maintained complete control over the new subsidiary. Investors, including Microsoft, had no legal say in \nwho ran the company.\n  In an effort to resolve the turmoil and return Mr. Altman to the company, he and the board agreed to replace two \nmembers with Mr. Taylor, who is a former Salesforce executive. But Mr. Altman was not reinstated to the board. Mr. \nTaylor and Mr. Summers were charged with overseeing the investigation into Mr. Altman and his dismissal.\n  Microsoft, a close partner of OpenAI, has a board observer position, which is filled by Dee Templeton, the \ncompany's vice president, technology and research partnerships. Microsoft declined on Friday to comment on the \nboard and report.\n  The new board faced criticism from corporate governance experts because of its lack of diversity. Mr. Taylor told \nThe Times in November that he would fill out the board by adding ''qualified, diverse candidates'' who embodied \n''the fullness of what this mission represents, which is going to span technology, A.I. safety policy.''\n  Karen Weise contributed reporting.\nhttps://www.nytimes.com/2024/03/08/technology/sam-altman-to-return-to-openais-board-of-directors.html\nGraphic\n \nPHOTO: An investigation concluded that Sam Altman, a founder of OpenAI, did not do anything that justified his \nremoval in November. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) This article appeared in print on \npage A19.               \nLoad-Date: March 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Meta, in Its Biggest A.I. Push, Places Smart Assistants Across Its Apps",
        "media": "The New York Times",
        "time": "April 19, 2024",
        "section": "TECHNOLOGY",
        "length": "998 words",
        "byline": "Mike Isaac and Cade Metz Mike Isaac is a technology correspondent for The Times based in San",
        "story_text": "Meta, in Its Biggest A.I. Push, Places Smart Assistants Across Its Apps\nThe New York Times \nApril 18, 2024 Thursday 23:52 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 998 words\nByline: Mike Isaac and Cade Metz Mike Isaac is a technology correspondent for The Times based in San \nFrancisco. He regularly covers Facebook and Silicon Valley. Cade Metz writes about artificial intelligence, driverless \ncars, robotics, virtual reality and other emerging areas of technology.\nHighlight: Users of Instagram, Facebook, WhatsApp and Messenger will be able to turn to the new technology, \npowered by Meta’s latest artificial intelligence model, to obtain information and complete tasks.\nBody\nUsers of Instagram, Facebook, WhatsApp and Messenger will be able to turn to the new technology, powered by \nMeta’s latest artificial intelligence model, to obtain information and complete tasks.\nOn a call with investors last spring, Mark Zuckerberg, the chief executive of Meta, said he believed that he had an \nopportunity to introduce artificially intelligent assistants “to billions of people in ways that will be useful and \nmeaningful.”\nA year later, he is making good on his statement.\nOn Thursday, Meta will begin incorporating new versions of its A.I.-powered smart assistant software across its \napps, which include Instagram, WhatsApp, Messenger and Facebook. The latest technology will be rolled out in \nmore than a dozen countries, including Australia, Canada, Singapore and the United States.\nThe A.I. software will become practically omnipresent — inside the news feed, in search bars and in chats with \nfriends. People will be able to ask the assistant, Meta A.I., for help in completing tasks and getting information, such \nas what concerts might be occurring in San Francisco on a Saturday night or the best options for vegan enchiladas \nin New York.\nMeta A.I. is powered by LLaMA 3, the company’s newest and most powerful large language model, an A.I. \ntechnology that can generate prose, conduct conversations and create images.\n“With LLaMA 3, Meta A.I. will now be the most intelligent freely available assistant,” Mr. Zuckerberg said in an \ninterview. “And because we’ve reached the quality level we want, we’re now going to make it much more prominent \nand easier to use across all our apps.”\nThe effort is Meta’s biggest rollout of products that include powerful A.I. technology. The social networking giant \nstarted weaving generative A.I. into its apps last year in a limited capacity, debuting a series of A.I.-powered \nchatbots and characters that could conduct conversations with users in September. But this new initiative exceeds \nthat in scope and aim, placing A.I. products into the most visible and most used parts of Meta’s apps.\nOther tech giants are also plugging A.I. into their products, as Silicon Valley start-ups raise billions of dollars to build \nA.I.-powered apps and services that they believe will define the next phase of computing.\nMeta, in Its Biggest A.I. Push, Places Smart Assistants Across Its Apps\nLast year, Microsoft incorporated OpenAI’s ChatGPT into the software giant’s Bing search engine. Google has \nintegrated A.I. into products like Docs, Gmail and Google Search. Start-ups such as Perplexity and Anthropic are \nalso aiming to get more A.I.-powered products and services to consumers.\nMeta’s efforts stand out because of the sheer scale of its products, which are used by nearly four billion people \nglobally every month. It is also one of the few companies to “open source” most of the A.I. technology they are \nbuilding, which means that anyone can look at the underlying tech and use it to build products or services for free.\nMr. Zuckerberg said the new A.I. rollout was part of Meta’s historical “playbook” of adding a feature to its apps \n“when we felt it was ready.” He pointed to products like Stories and Reels, two video and image products that \nappeared in Instagram, and how those were later amalgamated into Facebook and WhatsApp.\nWhen ChatGPT arrived in late 2022, wowing people with the way it answered questions, wrote term papers and \ngenerated computer code, the tech industry raced to build similar technology — even as the tools sometimes made \nmistakes and generated untruths.\nBecause of such flaws, OpenAI and other leading A.I. companies said they would not open source the underlying \ntechnology that powered these chatbots. (The New York Times has sued OpenAI and Microsoft, claiming copyright \ninfringement of news content related to A.I. systems.)\nMeta took a different tack. It open sourced the first version of LLaMA in February 2023, before releasing a more \npowerful version less than six months later. Other companies have followed, including Google and a prominent \nFrench start-up, Mistral. By open sourcing the technology, independent researchers and engineers everywhere can \nhelp spot problems in the technology and improve it, the companies have said.\n“We have always believed in this principle and are happy to see that the industry is embracing the power of open \nsource and the positive possibilities it can create,” Ahmad Al-Dahle, Meta’s vice president of generative A.I., said in \nan interview.\nMr. Dahle said LLaMA 3 had shown vast improvements over Meta’s previous large language models, calling it \n“significantly better” than what people were used to.\nMeta has also fine-tuned the A.I. model to make it slightly less conservative in the type of questions Meta A.I. will \nanswer, meaning the assistant will be less likely to refuse to answer some questions. In the past, Meta, Microsoft \nand others aimed to limit their chatbots from discussing third-rail topics like politics, religion and medical advice, \nfearing repercussions from political or interest groups.\nTo attract users, Meta will also add a faster image-generation technology into the A.I. assistant, and later plans to \nincorporate the A.I. tech into its Ray-Ban Meta smart glasses.\nThe challenge will be to convince people that the new assistants can be useful. Meta is working on helping people \nlearn what kind of questions they can ask the assistants to bring them to life, Mr. Dahle said.\n“Despite how prevalent these A.I. have become, there’s still an education factor on how to interact with an A.I.,” he \nsaid.\nLike most of Meta’s products, the new assistants are free to use — and likely difficult to avoid if you are a regular \nuser of the company’s apps.\nMeta’s executives don’t appear worried about A.I. saturation. “We’re excited to share our next-generation assistant \nwith even more people and can’t wait to see how it enhances people’s lives,” the company said.\nPHOTO: Meta A.I. is powered by LLaMA 3, which can generate prose, conduct conversations and create images. \n(PHOTOGRAPH BY META) This article appeared in print on page B6.\nMeta, in Its Biggest A.I. Push, Places Smart Assistants Across Its Apps\nLoad-Date: April 19, 2024"
    },
    {
        "file_name": "are_using_it_Jan2024",
        "header": "Skeptical about AI in healthcare? Here's how some doctors and hospitals",
        "media": "are using it",
        "time": "January 10, 2024",
        "section": "HEALTH CARE INDUSTRY NEWS, HEALTH CARE INDUSTRY NEWS & CINCINNATI NEWS",
        "length": "1126 words",
        "byline": "Elizabeth B. Kim, Cincinnati Enquirer",
        "story_text": "Skeptical about AI in healthcare? Here's how some doctors and hospitals \nare using it\nUSA Today Online\nJanuary 10, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: HEALTH CARE INDUSTRY NEWS, HEALTH CARE INDUSTRY NEWS & CINCINNATI NEWS\nLength: 1126 words\nByline: Elizabeth B. Kim, Cincinnati Enquirer\nBody\nAll of Cincinnati’s major hospital systems are using artificial intelligence, technology that most Americans are wary \nof. \nCincinnati’s TriHealth uses artificial intelligence, or AI, to help diagnose pulmonary embolism, stroke and breast \ncancer – conditions for which early detection can be lifesaving. \nUC Health and St. Elizabeth Healthcare are using AI for detection and diagnosis. Christ Hospital uses AI to \nautomate insurance and claims billing, while Bon Secours Mercy Health relies on AI to recruit and hire nurses. \nDespite its widespread rollout in hospital systems, most Americans don’t trust this technology, according to a 2023 \nPew Research survey. Less than 40% of Americans expected AI to improve patient health outcomes, the survey \nsaid.  \nNationwide, insurance companies have been sued over faulty and allegedly discriminatory algorithms. Doctors have \nbeen criticized for using ChatGPT to write up medical records and potentially exposing sensitive patient information \nby doing so.  \nHospital executives say that hospitals are using artificial intelligence, which the National Institutes of Health define \nas machines learning to perform tasks, to increase efficiency and elevate the standard of care provided to patients.  \nMore drone deliveries, new AI tech:  Here's a guide to what Walmart unveiled at CES 2024\n“What people don't realize is AI has been around for a very long time, starting back in the 1950s,\" said Paul Grone, \nchief information officer of Christ Hospital. \"It’s evolved from many years ago. Health care has been using AI in the \nback office for quite some time.”    \nCincinnati hospitals say AI can help doctors \nLink to Image\nChrist Hospital is partnering with Microsoft and Epic Systems, the medical records software company that runs \nMyChart, to develop AI that helps doctors respond to patient emails. \nGrone said he doesn’t think AI will result in less face-to-face time between patients and doctors, citing AI technology \nthat records medical notes during appointments.\nSkeptical about AI in healthcare? Here's how some doctors and hospitals are using it\n“Normally in the appointment, the provider would be on the computer the whole time as he or she’s talking to you,” \nhe said. “Now, they’re facing you ... and the system is capturing the conversation. So, actually, it improves the face \ntime with the patient.” \nHe said Christ Hospital aims to pilot the technology starting in February. \nTriHealth’s Chief Operating Officer Terri Hanlon-Bremer shared similar sentiments about AI improving the patient \nexperience. “It helps us pinpoint where that doctor should focus ... in an effective and efficient manner,” she said.\nHanlon-Bremer said the AI would be an aid, rather than a substitute, for doctors. “AI is not replacing the role of the \nphysician or the clinical decision-making that a physician brings to the table,” she said. \nTriHealth’s four-hospital system is also considering implementing a ChatGPT-like system that will help doctors \nrespond to patient questions, according to John Ward, TriHealth’s senior vice president of regional operations. \n“One of the tough things for physicians today with electronic medical records and with patient portals is that they get \nbombarded with a ton of messages,” Ward said. \"So being able to process those and respond to those is difficult. It \nends up taking hours at night.” \nHe said AI can help doctors prioritize those messages to save time. \nUnlike ChatGPT, however, which was briefly banned in Italy for collecting data without consent, any data collected \nby hospitals is subject to HIPAA, the federal law that prohibits healthcare providers from sharing or selling a \npatient’s health information.  \n“If you're going to share data of any kind, it has to be totally de-identified,” Ward said. \nPart of the task that hospitals face is properly vetting AI vendors. As TriHealth’s Hanlon-Bremer remarked, “The \nchallenge we have is how to find a company that is credible, that has technology that is going to better our clinical \noutcomes, and that isn’t going to go away overnight.”  \nMeanwhile, Columbus-based AI startup Olive shut down suddenly in November 2023, after promising to use AI to \nincrease efficiency in 600+ hospitals across the US. TriHealth had previously partnered with the now-defunct \nstartup to automate medical billing and process denials. \nLink to Image\nMost Americans skeptical about AI’s benefits \nMost Americans do not share hospital executives’ enthusiasm about the potential of AI.  \nIn the Pew Research Survey, 75% thought healthcare providers would adopt AI technologies too quickly, before \nfully accounting for the risks to patients, and 79% of Americans said they did not want an AI chatbot to respond if \nthey needed mental health support.  \nIn May 2023, reports emerged that an AI-driven chatbot designed to help those struggling with eating disorders \nended up offering users tips on dieting instead. The chatbot’s host, the National Eating Disorders Association, took \nit down shortly thereafter. \nImplementing AI into medical billing has also met its challenges.  \nInsurance company Cigna was sued twice in 2023 over allegations that it relied on AI to deny thousands of pre-\napproved medical claims at a time. With the help of algorithms, Cigna employees took 1.2 seconds on average to \nreject each claim, according to a class action suit. Plaintiffs said that Cigna violated a California law that obliges \ninsurers to evaluate claims in a “thorough, fair, and objective” manner.  \nSkeptical about AI in healthcare? Here's how some doctors and hospitals are using it\nSimilarly, UnitedHealth Group was hit with a proposed class action lawsuit arguing that its AI algorithm methodically \nrejected elderly patients’ claims for care, such as stays in nursing facilities. \nBiden, doctors call for more AI regulation \nThe privacy and ethics concerns that come with algorithms trained on large swaths of personal data have doctors \nand elected officials alike calling for more patient protections. \nIn an October executive order, President Joe Biden called on Congress to pass data privacy legislation, referring to \nAI as holding “extraordinary potential for both promise and peril.” \nEarlier in the year, the American Psychiatric Association issued a statement strongly opposing doctors entering \npatient data into generative AI tools like ChatGPT, citing probable violations of HIPAA.  \nGenerative AI tools for healthcare have not yet been approved by the Food and Drug Administration. However, Dr. \nDouglas Flora, the executive medical director of oncology services at St. Elizabeth Healthcare, thinks it’s only a \nmatter of time. \n“Looking three to five years down the road, I don’t think that a health care system that hasn’t employed generative \nAI is going to be able to compete with those that have,\" Flora said. \nThis article originally appeared on Cincinnati Enquirer: Skeptical about AI in healthcare? Here's how some doctors \nand hospitals are using it\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "two_parts_-_Core_and_Satellite:_Srikanth_Subramanian_Aug2023",
        "header": "ETMarkets Smart Talk- It is a prudent approach to divide the portfolio into",
        "media": "two parts - Core and Satellite: Srikanth Subramanian",
        "time": "August 1, 2023",
        "section": "MARKET-EXPERT-VIEW",
        "length": "1763 words",
        "byline": "Kshitij Anand",
        "story_text": "ETMarkets Smart Talk- It is a prudent approach to divide the portfolio into \ntwo parts - Core and Satellite: Srikanth Subramanian\nThe Economic Times\nAugust 2, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: MARKET-EXPERT-VIEW\nLength: 1763 words\nByline: Kshitij Anand\nBody\n\"The core part of your portfolio should make up for the majority of your portfolio. The mix of core and satellite \ndepends totally on your risk appetite,\" says Srikanth Subramanian, CEO, Kotak Cherry.In an interview with \nETMarkets, Subramanian said: \"We have seen a fair amount of sector rotation in the markets where almost every \nsector has contributed to markets attaining new highs\" Edited excerpts: Market are climbing new peak every day \nwith Sensex at 66000 while Nifty50 is above 19500 levels - is the market running ahead of fundamentals?Markets \nhave surpassed the 19800 mark and are trending higher. On one-year forward EPS levels, Nifty50 is now trading \nabove 20 price-to-earnings (PE) levels.The yield gap has been negative for some time now and is now trending \ntoward the lowest it has been in the last three years since the pandemic started.The yield gap is a sign of how far \nthe market is underpriced or overpriced. A negative yield gap indicates markets are overheating and maybe \novervalued if you go purely by the quants.The market has run up and as long as there is no PE multiple re-rating \nthat happens, the earnings growth will have to live up to the expectations.The street expects the Nifty50 earnings \nper share (EPS) growth to be somewhere around the 15% mark for FY2024 and 25% year-on-year (Y-o-Y) for the \nJune quarter. \nWe may call this a global rally as most of the global markets have done much better so far in 2023 and India is just \ncatching up now. What is fuelling optimism? In the calendar year 2022, most of the major global indices had \nwitnessed significant declines. NASDAQ corrected over 30%, S&P witnessed over 18% correction. European \nmarkets also registered double-digit losses in 2022.India witnessed continuous selling by FIIs during this period. \nThanks to domestic institutional investors' (DII) support, the BSE Sensex ended in a low negative zone in 2022.This \nwas all happening with the context of high inflation, the Russia - Ukraine war, and the Central banks' rate hike \nstance to control surging inflation.Global markets have bounced back in 2023 despite witnessing certain regional \nbank failures, and the US government debt ceiling crisis.The key trigger for the market was cooling inflation and the \nother macroeconomic data points coming in better than what was feared.With the downward trending inflation print, \nmarkets were factoring in the viewpoint that the central banks will take a pause in hiking interest rates and \neventually go back to rate cuts, pause is a reality now but what happens to rate cuts is still to be watched out for. \nThe key US benchmark S&P 500 are up ~16.9% in the first half of CY23, whereas Tech heavy Nasdaq Index is up \nover 39% in the same period. Sensex during the same period has gone up by 8%.Unlike in Indian markets, where \nwe have seen broad-based participation across sectors, in the US, the rally has been fuelled by a small group of \nTech stocks.Indian markets have on the back of favourable domestic macroeconomic environment and resumption \nof FII inflows have scaled to new highs, whereas many global markets are yet to reach their former peak. Which \nsectors are likely to lead the next leg of the rally in markets? We have seen a fair amount of sector rotation in the \nmarkets where almost every sector has contributed to markets attaining new highs.Almost 50% of the rally in the \nlast three months in Nifty50 has been contributed by the top 10 stocks; so there is a certain amount of sector-\nagnostic behaviour. The quarterly result season is ongoing and commentary by management regarding future \noutlook is going to be extremely crucial. In Financials, we are seeing credit growth across many companies.While \nETMarkets Smart Talk- It is a prudent approach to divide the portfolio into two parts - Core and Satellite: \nSrikanth Subramanian\nthe sector will continue to do well, earnings are expected to moderate due to higher base and depleting NIMs as the \ncost of deposits have gone up.Banks have seen net interest margins (NIM) expanding in FY23, and we should see \na contraction from here on.HealthCare sector on the other hand could see positive action on the back of increased \nstability in the US generics.What is important to witness is sustained momentum in domestic sales which should \nhelp drive overall growth in this sector.The Nifty FMCG sector also outperformed the Nifty50 index in the last six \nmonths on the back of cooling inflation and increased prices leading to margin expansion.CAPEX and investment \ncycle-related sectors be it in manufacturing, engineering, infra and ancillary are also expected to do well going \nforward. You have also completed one year --- many congratulations. How the journey and what was are your \nfuture plans? We have used the last year to achieve the following key goals:Scaled further to 3.5 mn + downloads \nwith ever-increasing users of higher value of transactions.We have started to see high-value users on the app more \nconsistently with regular transactions of 1 lakh+ on the App. We have scaled up to 20,000+ fresh SIPs every \nmonth.We have enabled Kotak Mahindra Bank customers to seamlessly transition to Cherry through existing Bank \ntouchpoints - thus allowing a large base of existing to Bank customers to come and transact on Cherry.We are \nenabling Kotak Cherry as a means to start investment journey for New to Bank customers by integrating with the \nBank CRM.It has been an exciting year and the kind of traction we are seeing makes us feel extremely convinced \nthat Kotak will emerge as one of the top players when it comes to digital investment journeys of customers. What is \nyour biggest differentiator compared to other wealth/investment apps in the market? Kotak Cherry has four key \ndifferentiators:Kotak has been a household name when it comes to investments and the brand Kotak resonates with \ncustomers when it comes to their life savings.Kotak has a track record of shortlisting Mutual Funds as a Mutual \nFund Distributor for more than two decades and that gives us the experience of multiple market cycles which is \nessential when it comes to investments.We have further been known for innovation that solves customers' needs \nand we have introduced Mutual Fund Baskets on Kotak Cherry as a means to solve customers' investment needs \nby providing them curated baskets of mutual funds that are targeted at specific needs.So, our customers do not \nneed to go around searching for which mutual funds to invest in. They can pick from one of the many MF baskets \nthat will suit their goals and needs.Kotak also has the benefit of being a Bank and thus allows a simple and easy \nway of linking customers' investments and banking in one go. This way, customers don't need to juggle between \nmultiple apps for investments and banking.It is made available in a seamlessly integrated journey. We will be soon \nintroducing the facility to have a direct debit for their MF SIPs which will remove the hassle of linking of Bank \nAccounts with investment accounts.  What do you make of the numbers delivered by big-ticket IT companies in Q1? \nDemand uncertainty continues in Indian IT companies given the broader macroeconomic uncertainty. The near-\nterm demand environment seems weak, with no changes in medium-term prospects.Fortunately, there has been no \ndemand destruction, clients are still spending although priorities have changed and the structural growth drivers \nremain intact.Globally too, technology companies have shown earnings growth through cost management than \nthrough core structure earnings growth.Generative AI has high interest among enterprises that can drive data and \ncloud opportunities but is still in the early stage. It remains to be seen how Indian IT companies adapt to AI needs of \nthe world, although there has seen some good news on that front with Infosys signing a USD 2 billion deal with a \nclient for AI and automation service delivery. What is your take on the recent IPOs which have hit D-St in June and \nJuly? Most of them are not big-ticket names but still attracted a lot of interest. How should one approach the \ncompanies in 2023? Two words for it: Be Selective. This is a typical cycle we have seen, when the markets are \ntrending higher the number of IPOs that hit the street increases by a huge margin and the euphoria around them \nalso shoots up.We have the most recent examples of the IPOs that hit the street in the bull rallies of 2020 and 2021. \nSome tech IPOs from those cycles are still trading at 50% of their IPO price.IPOs in such markets become a way to \nmake a quick buck through listing gains.But while all of them might be such short-term plays in such situations it is \nvery important to make a judgement whether to hold them for longer or not based on basic knowledge of the \ncompany rather than just pure momentum and sentiment.It is important to not get carried away by this and make a \nconscious decision.Get convinced about the industry and the market the company is operating in, make sure you \nunderstand the company, evaluate the risks and be sure of the valuations vis a vis the peers.How do you pick \nstocks for investments? What are the filters you deploy? While everyone uses different techniques to pick stocks, I \nthink a prudent approach is to divide the portfolio into two parts: Core and Satellite.The core part of your portfolio \nshould make up for the majority of your portfolio. The mix of core and satellite depends totally on your risk \nappetite.For the core part of the portfolio, the holdings are generally meant to be long term so one can be valuation \nagnostic. These are fundamentally strong companies- I prefer to invest in leaders in the industry. Core portfolio is \nETMarkets Smart Talk- It is a prudent approach to divide the portfolio into two parts - Core and Satellite: \nSrikanth Subramanian\nthe stable part of my investments.However, satellite portfolio can be your risky portfolio which you can churn. For \nthis part of the portfolio, one needs to be value conscious and buy at the right prices.One overarching filter for my \nentire portfolio is good corporate governance and clean management. These two filters are a must check before \ninvesting.Stock picking is a tricky game, and you need to be completely on top of the information to make the right \ninvestments and even exit them at the right times. It is for someone who can dedicate time to research on the \nstocks.For the ones who face paucity of time, mutual funds, however, are a far better choice rather than just \nlistening to someone else and making the investments in stock. Mutual funds are like you are setting at the back \nseat of a car while an expert is navigating through a road with potholes.(Disclaimer: Recommendations, \nsuggestions, views, and opinions given by experts are their own. These do not represent the views of the Economic \nTimes)  For Reprint Rights: timescontent.com\nLoad-Date: August 1, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "DATABRICKS SETS $1.3 BILLION DEAL FOR AI STARTUP",
        "media": "Wall Street Journal Abstracts",
        "time": "June 28, 2023",
        "section": "B; Pg. 4",
        "length": "39 words",
        "byline": "ANGUS LOTEN, BELLE LIN",
        "story_text": "DATABRICKS SETS $1.3 BILLION DEAL FOR AI STARTUP\nWall Street Journal Abstracts\nJune 27, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 39 words\nByline: ANGUS LOTEN, BELLE LIN\nBody\nABSTRACT\nData-storage-and-management company Databricks agrees to acquire generative-artificial-intelligence startup \nMosaicML in deal valued around $1.3 billion, seeking to tap strong demand from businesses to build their own AI \ntools (M)\nLoad-Date: June 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "As A.I. Roils Silicon Valley, Microsoft and Google Find Use in Daily Tools",
        "media": "The New York Times",
        "time": "March 17, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "1079 words",
        "byline": "By Karen Weise and Nico Grant",
        "story_text": "As A.I. Roils Silicon Valley, Microsoft and Google Find Use in Daily Tools\nThe New York Times\nMarch 17, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 1079 words\nByline: By Karen Weise and Nico Grant\nBody\nNew artificial intelligence technology is roiling Silicon Valley. For now, the most obvious ways to use it are in \nsoftware like Microsoft's suite of products.\nFor all the talk about the transformative nature of new technology called generative artificial intelligence, some of \nthe earlier commercial uses may be far more prosaic: formatting a PowerPoint slide, summarizing a call or writing \nto-do lists. \n  Many of the first broad applications of generative A.I. have burst into the realm of the consumer internet, with \nopen-ended chats and more sophisticated versions of internet search. But announcements this week by Microsoft \nand Google about adding A.I. into the daily tools of knowledge workers and software developers show how the \nmundane -- but very profitable -- software for businesses may be the clearest moneymakers.\n  ''As we look ahead, we believe this next generation of A.I. will unlock a new wave of productivity growth,'' Satya \nNadella, Microsoft's chief executive, said while announcing a set of tools Thursday. He added that new features \nwould ''remove the drudgery from our daily tasks and jobs.''\n  The new tools are more sober than visions of how generative A.I. might evolve or upend Google's search engine, \nused by billions of people, but they form a crucial part of Google's and Microsoft's strategies to cash in on their A.I. \ninvestments.\n  Microsoft has made a series of announcements describing how it plans to push A.I. into all corners of its business. \nIt has committed $13 billion into its partnership with the start-up OpenAI, whose ChatGPT chatbot captured the \npublic imagination when it was released at the end of November. Just over a month ago, Microsoft also integrated \nOpenAI's models into its Bing search engine.\n  Thursday's announcement cuts to the heart of some of Microsoft's largest businesses, in products like its software \nsuite that includes Word, Excel and Outlook. Office products and related cloud services produced $11.8 billion in \nrevenue in Microsoft's latest quarter, while search and news advertising generated about $3.2 billion in sales.\n  Microsoft focused on integrating A.I. assistants, which it calls Copilots, into software. It is drawing on data that \nbusiness customers have already stored in the company's systems -- chats in its collaboration tool Teams, \ndocuments stored in its cloud and emails on its servers.\n  With Business Chat, a new feature for working across the tools, someone can ask for a customer update and it will \nscan recent emails, meeting notes and other information to generate a response.\nAs A.I. Roils Silicon Valley, Microsoft and Google Find Use in Daily Tools\n  The products are being tested by 20 business customers, and pricing and licensing details will be released in the \ncoming weeks, Jared Spataro, a Microsoft executive, said in an interview.\n  The assistants produce sample text, but Microsoft stressed that users should review and tweak the results. When \ngenerating text, the Copilot may make mistakes or generate irrelevant information.\n  It can also suggest feelings or emotions. One executive showed how the Copilot in Word could write a personal \nspeech celebrating her daughter's high school graduation. ''In summary, to say we are proud of Tasha would be an \nunderstatement,'' the model proposed.\n  As Mr. Spataro demonstrated how he could use the assistant to generate an email providing his feedback on a \ndraft of a blog post, the A.I. tool generated an email that said Mr. Spataro was ''impressed'' and had made minor \ngrammatical changes to the post -- though it had no way of knowing whether he was ''impressed'' or that the \nchanges were only grammatical.\n  ''It doesn't know at all,'' Mr. Spataro said when asked about it. He said the email should be edited, adding, ''I mean, \nthis is an example of why we called it a Copilot.''\n  Last month, Microsoft pulled back some of the new Bing's functions after its chat produced inaccurate, bizarre and \nat times creepy results. The new Bing had ''millions of active users'' in its first month, about a third of whom had not \nused Bing before, the company said. The company has said it will experiment with how to integrate ads into the \nresults.\n  Microsoft has been jockeying with Google, which has said its chatbot, Bard, will be released in the ''coming weeks'' \nas an experimental demonstration. But Dan Taylor, Google's vice president of global ads, said in an interview last \nmonth that the company had not yet figured out a way to make money from the chatbot.\n  In an announcement on Tuesday, Google underscored a similar path to generate profit from A.I. technology: by \nincorporating it into software that businesses pay for, and selling the underlying A.I. to other organizations.\n  Google said it would embed A.I. into its email and word-processing tools, Gmail and Docs, so that it could draft \nemails, job descriptions and other types of documents from simple written prompts. With a few clicks, Google said, \nusers could then adjust the tone to be more playful or professional, and have the A.I. trim or expand on the content. \nThe features will first be available to what the company called trusted users.\n  Thomas Kurian, the chief executive of Google Cloud, which sells software and services to other businesses, said \nin a blog post that generative A.I. was a generational shift in technology, akin to the move from desktop computing \nto mobile devices. Powered by a system known as a large language model, the A.I. can generate text and other \nmedia when given short prompts.\n  Just as software developers flocked to develop applications for the iPhone, Google expects that many \nprogrammers will want to build new A.I. applications and businesses. Mr. Kurian said the company would offer two \nnew products, PaLM API and MakerSuite, to aid their efforts.\n  Google also debuted Generative AI App Builder, a tool to help businesses and governments quickly develop their \nown chatbots. The company will also let organizations customize A.I. with their own data through an existing \nproduct, Vertex AI.\n  Building large language models is an expensive enterprise requiring rare and specialized engineers, and \nsupercomputers built specifically to handle the processing demands. Most companies will not have the resources to \nreplicate Google's, Microsoft's or OpenAI's years of work building these systems, so the companies are racing to \nfulfill their demand.\n  Mr. Kurian said he expected this generation of A.I. to have ''a profound effect on every industry.''\n  Cade Metz contributed reporting.Cade Metz contributed reporting.\nAs A.I. Roils Silicon Valley, Microsoft and Google Find Use in Daily Tools\nhttps://www.nytimes.com/2023/03/16/technology/microsoft-google-ai-tools-businesses.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: March 17, 2023"
    },
    {
        "file_name": "OF_PA._SMALL_BUSINESSES_USED_SERVICE_Mar2024",
        "header": "GOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT; THOUSANDS",
        "media": "OF PA. SMALL BUSINESSES USED SERVICE",
        "time": "March 1, 2024",
        "section": "BUSINESS; Pg. A-14",
        "length": "554 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "GOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT; THOUSANDS \nOF PA. SMALL BUSINESSES USED SERVICE\nPittsburgh Post-Gazette\nMarch 1, 2024 Friday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-14\nLength: 554 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nA doctor's office, a winery, a bistro. A dentist, a painter, a realtor.\nThose are just some of the small businesses in the Pittsburgh area that will lose their websites Friday when Google \nends a web service it launched in 2017 to give business owners free landing pages.\nFor the next three months, links for the pages will route back to their owners' profiles. After that they will return a \n\"page not found\" error, Google announced earlier this year. The tech giant encouraged small businesses to build \nnew sites with tools like Wix, Squarespace and GoDaddy.\n\"Due to low engagement, we are winding down websites made with Business Profiles, which previously created \nbasic, templated websites based on Business Profile information,\" Google said in a statement to the Post-Gazette. \n\"Small business owners will continue to have access to Business Profiles, as well as ads landing pages if they don't \nmaintain a website, and other resources to connect with potential customers online.\"\nOne marketing agency, Fatjoe.com, estimated that 4,000 Pennsylvania businesses will be impacted by the cut, \nincluding 445 businesses in Allegheny County.\nBut a look at that data reveals a slightly different story: Most of the businesses on the list have either closed or \nalready made their own websites, separate from the Google tool.\nLifeforce Fitness Center, a gym in Pleasant Hills, made a page with tabs for each of its services. As did the Flying \nLocksmiths, Pittsburgh's leading provider of commercial locksmith services, according to its non-Google site.\nMilestone bar has not - but the Brentwood dive's landing page on Google search displays much of the same info, \nincluding reviews, location, hours and a phone number. Yelp is the top search result for Milestone above its Google \nbusiness site. Other bars like Red's Good News have Instagram as a top search result.\nThe Google sites are bare bones: a few images, a map, a handful of reviews, hours of operation and a phone \nnumber.\nBut for some small businesses, that was enough to get on the search engine's radar.\nAnother bar, Scarpaci's, has both the simple Google site and a new site, which is slightly more robust, with \nanimated, scrolling images, a full menu, and event details.\nGOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT THOUSANDS OF PA. SMALL \nBUSINESSES USED SERVICE\nJustin Pons, owner of Pons Auto Service in Greenfield, said he wasn't even aware that he had a website generated \nby Google. Far more valuable, he said, are his 174 positive Google reviews.\n\"I depend on word of mouth and Google,\" Mr. Pons said. \"People just look up repair shops and they read my \nreviews.\"\nThe elimination of Google sites will have no impact on reviews, the company said.\n\"Small businesses are an essential part of the online ecosystem, and we are committed to building products \neveryday to help them grow and thrive,\" the company said.\nSome people online said eliminating the tool would clear up spam. It could also help guarantee more relevant \nsearch results.\nCertain businesses around Pittsburgh, including a law firm, a woodworker and a pharmacy, have sites with inactive \nphone numbers. A local church, Greater Pittsburgh Revival Center, hasn't updated its site in years. Others, like \nRidgmont's Grounded Cafe, have permanently closed.\nThe shift comes less than a year after Google made a broader change to search with the inclusion of generative \nAI.\nEvan Robinson-Johnson: ejohnson@post-gazette.com\nGraphic\n \nPHOTO: Richard Drew/Associated Press: On Friday, Google is ending a web service it launched in 2017 to give \nbusiness owners free landing pages, potentially impacting scores of local companies.\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Kwon_Feb2024",
        "header": "AI is a global issue, we need a global approach to govern it: OpenAI's Jason",
        "media": "Kwon",
        "time": "February 11, 2024",
        "section": "TECH & INTERNET",
        "length": "695 words",
        "byline": " ",
        "story_text": "AI is a global issue, we need a global approach to govern it: OpenAI's Jason \nKwon\nThe Economic Times\nFebruary 11, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 695 words\nBody\nCountries and global institutions must work together to harmonise efforts to tackle issues around artificial \nintelligence (AI), and India has a major part to play in this conversation, OpenAI chief strategy officer Jason Kwon \nsaid at the Global Business Summit on Saturday.“AI is a global issue, and we need a global approach to govern it,” \nhe said.Countries have historically come together to address problems of health, trade and natural resources, he \nsaid, adding that they now have to similarly join forces through institutions that underpin the international order and \nrule of law to coordinate in the matter of AI governance.“We want to work closely with you to figure out a path \nforward,” he said.Kwon also announced that OpenAI will hold a number of developer summits in India this year. It \nplans to foster collaboration between Silicon Valley developers and local developers that will “put us on a path for \nbuilding the tools and define our future”.“Our plan is to convene developers around the country to work alongside \nOpenAI’s product leaders on some of the most difficult challenges in AI,” he said.Kwon said the country has the \nworld’s largest developer community, some of the most impressive talent in the field, a track record of developing \nextraordinary technology businesses and a relentless focus on competing on the world stage.“India has the key \ningredients of being one of the world's leaders in AI,” he said, adding that OpenAI wants to continue to invest in the \ndeveloper community here.OpenAI, he said, also understood the role that ChatGPT can play in closing one of the \nmain barriers in the startups segment – the demand for code.“Startups understand market gaps and build \ninnovative products to fill them. \nTools like ChatGPT help accelerate startups and unlock new ones in several ways,” Kwon said.On his India visit, he \nwill be meeting with entrepreneurs who are creating AI-powered products that will enable India to experience the \nvalue of the technology, he said.In the private sector, AI can make completing tasks 25% faster and improve quality \nby 40%, Kwon said, citing research. It reduces the cost of intelligence by making writing code faster, freeing up \nengineers for other tasks, and simplifies computing interfaces and makes them more accessible globally, he \nsaid.“When you break down these barriers, you can make it possible to access more services that are critical to \nhuman welfare in the digital age,” he said.He also said that unlocking the potential of AI requires an “intense focus” \non safety and that safety and product development are intertwined rather than separate.“AI safety must be \nglobalised,” Kwon said, adding that safety features must be ensured across countries and languages.OpenAI has \nseen “promising early results” with a safeguarding tool it is developing ahead of elections in several countries such \nas the US and India to address fake or inaccurate images, he said.More than a year after the introduction of \nOpenAI’s generative AI platform ChatGPT to the world, its transformative power has become visible, according to \nKwon. He said ChatGPT has helped people experience AI not as behind-the-scenes abstraction but as a real and \ntangible tool.It has helped people solve real problems in previously unimaginable ways, he said, adding that around \n90% of Fortune 500 companies now build using OpenAI products.“Reducing language barriers like this is one of the \nsuperpowers of large language models,” Kwon said, pointing to GPT-powered farmer chatbot by Digital Green, \nwhich helps farmers in multiple languages to navigate climate change, implement best practices and bring their \ncrops to market.The bot delivers information in languages including Hindi, Kannada and Assamese, and reduces \nthe cost of traditional extension services by 99%, Kwon said.Large language models can also build on the Indian \nAI is a global issue, we need a global approach to govern it: OpenAI's Jason Kwon\ngovernment’s national language translation initiative Bhashini, he said.In the field of healthcare, ChatGPT has been \nused by the Bill and Melinda Gates Foundation to facilitate communication with frontline workers to improve care for \npregnant and postpartum women. Kwon said. For Reprint Rights: timescontent.com\nLoad-Date: February 11, 2024"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "OpenAI in Talks for Deal That Would Value Company at $80 Billion",
        "media": "The New York Times",
        "time": "October 21, 2023",
        "section": "TECHNOLOGY",
        "length": "609 words",
        "byline": "Cade Metz",
        "story_text": "OpenAI in Talks for Deal That Would Value Company at $80 Billion\nThe New York Times \nOctober 20, 2023 Friday 00:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 609 words\nByline: Cade Metz\nHighlight: The San Francisco start-up’s valuation could triple in less than six months.\nBody\nThe San Francisco start-up’s valuation could triple in less than six months.\nOpenAI is in talks to complete a deal that would value the company at $80 billion or more, nearly triple its valuation \nless than six months ago, according to a person with knowledge of the discussions.\nThe company would sell existing shares in a so-called tender offer led by the venture firm Thrive Capital that would \nmake OpenAI the most valuable start-up in San Francisco, that person said. OpenAI would also become one of the \nworld’s most valuable tech start-ups, behind ByteDance and SpaceX, according to figures from the data tracker CB \nInsights.\nNearly a year after OpenAI sparked an A.I. boom with the release of the online chatbot ChatGPT, the Silicon Valley \ndeal-making machine continues to pump money into the field’s leading companies.\nAmazon said last month that it would invest up to $4 billion in another San Francisco start-up, Anthropic, one of \nOpenAI’s primary competitors. Over the summer, Cohere, a company founded by former Google researchers, \nraised $270 million, bringing its total funding to more than $440 million. Inflection AI, founded by a former Google \nexecutive, raised a $1.3 billion round, bringing its total to $1.5 billion.\nIn January, Microsoft invested $10 billion in OpenAI, bringing its total investment in the company to $13 billion. In \nMarch, Character.ai, another start-up founded by former Google employees that builds online chatbots, raised $150 \nmillion in a funding round that valued the company at $1 billion.\nA month later, the venture-capital firms Thrive Capital, Sequoia Capital, Andreessen Horowitz and K2 Global \nagreed to buy OpenAI shares in a tender offer, valuing the company at around $29 billion.\nNow, Thrive is in talks to lead another tender offer that values the company at $80 billion or more, the person with \nknowledge of the deal said. OpenAI is not issuing new shares. The deal would allow the company’s employees to \nsell their existing shares.\nThe start-up’s valuation was reported earlier by The Wall Street Journal. Thrive’s role was reported earlier by The \nInformation.\nOpenAI declined to comment.\nAlong with tech giants like Google, Microsoft and Meta, the A.I. start-ups are among a small group of companies \ncapable of building chatbots such as powerful ChatGPT and similar A.I. systems.\nOpenAI in Talks for Deal That Would Value Company at $80 Billion\nFunding for other start-ups has fallen in recent years, as investors have favored profits over growth. But investor \ninterest in A.I. start-ups remains the exception, because many believe artificial intelligence has the potential to \nupend current technologies and spur growth across the industry.\nWhen it was released at the end of last year, ChatGPT captured the imagination of millions of people with its knack \nfor answering questions, writing term papers and poetry, and generating computer code.\nAs the chatbot’s popularity grew, the wider tech industry embraced what is called generative artificial intelligence: \ntechnologies that can generate text, images and other media on their own.\nThe result of more than a decade of research inside companies like OpenAI and Google, generative A.I. \ntechnologies are poised to remake everything from internet search engines like Microsoft Bing to digital tutors to \nemail programs.\nThousands of companies are exploring this new area, but only a few have the resources to build the technology \nfrom the ground up. These companies have an unusual blend of experienced researchers, enormous ambition and \nlarge amounts of money.\nPHOTO: Recently, OpenAI’s executive team has seen the company’s price skyrocket. (PHOTOGRAPH BY JIM \nWILSON/THE NEW YORK TIMES) This article appeared in print on page B5.\nLoad-Date: October 21, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "OpenAI investor Vinod Khosla spars with Elon Musk over lawsuit",
        "media": "The Economic Times",
        "time": "March 6, 2024",
        "section": "TECH & INTERNET",
        "length": "829 words",
        "byline": " ",
        "story_text": "OpenAI investor Vinod Khosla spars with Elon Musk over lawsuit\nThe Economic Times\nMarch 7, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 829 words\nBody\nIndian-American business Vinod Khosla, who is the cofounder of Sun Microsystems and the founder of Khosla \nVentures, has called out Elon Musk for suing OpenAI. He termed Musk's move \"a case of sour grapes\".Khosla has \nbeen an investor in OpenAI since 2019 when the company became \"for profit\". \"With Elon Musk, feels like a bit of \nsour grapes in suing OpenAI ChatGpt, not getting in early enough, not staying committed and now a rival effort. \nLike they say, if you can't innovate, litigate and that's what we have here. Elon of old would be building with us to hit \nthe same goal,\" posted Vinod Khosla on X.Musk was quick to revert, saying, \"Vinod doesn’t know what he is talking \nabout here.\"Khosla, then, went on create an elaborate thread on X asking Musk questions about his move and \ncommenting on Musk's motives behind his actions. \n\"@elonmusk is being self-righteous about the ills of prioritizing profit over benefit to humanity. To the less naive, \ntimelines show Elon left @OpenAI & reneged on his word to “cover whatever of the initial $1B anyone else doesn't \nprovide. He reneged simply because he wanted to wrangle control for himself and for Tesla.\"Musk and OpenAI \nCEO Sam Altman together started the artificial intelligence startup in 2015, but Musk left the firm in 2018. While \nMusk exited citing a conflict of interest with his other company Tesla, several reports suggest he wanted to merge \nOpenAI with Tesla to accelerate the automaker's growth. However, Altman was against this and Musk, after leaving \nthe startup, even pulled out of his funding for the startup.\"Now @elonmusk is being a curmudgeon about OpenAI’s \nsubsequent creation of a for-profit subsidiary – how rich! How else do you advance the cause of creating AGI to \nbenefit humanity without any funding? If he was so sincere, why did he pull the plug and leave them stranded?\" \nKhosla said. Khosla also backed his rationale of investing in the startup.\"As I said to @sama and my partners when \nwe committed to invest in @OpenAI in 2018, some things are too important for humanity to not try. Even a 90% \nchance of failure was worth 10% chance of changing the world and @khoslaventures could only lose 1x its money \nbut make a 100X,\" he added. What is Musk's lawsuit all about?The lawsuit, filed in San Francisco, California, \nalleges that OpenAI has strayed from its original not-for-profit mission of building open-source artificial intelligence \n(AI) for the good of humanity, working now to ‘maximise profits’ for its major investor Microsoft.Musk sought that the \ncourt direct OpenAI to make its research and technology publicly available and prevent the use of its assets and \ncutting-edge generative AI models for the financial gains of software major and investor Microsoft or any individual, \nReuters reported.His lawyers argued there was a breach of contract as OpenAI had agreed not to commercialise \nany product that its board considered artificial general intelligence (AGI). Microsoft, which joined the board last \nNovember following Altman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model \ncould be viewed as early AGI.Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment \nnow totals $13 billion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits \nuntil it makes back the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported.What is \nOpenAI's response?OpenAI responded to the lawsuit in a blog post Tuesday, saying Musk signed off on the \ncompany’s decision to become a for-profit entity and that he insisted it needed to raise “billions” of dollars to be \nrelevant compared with Google.“We’re sad that it’s come to this with someone whom we’ve deeply admired — \nsomeone who inspired us to aim higher, then told us we would fail, started a competitor, and then sued us when we \nstarted making meaningful progress towards OpenAI’s mission without him,” the company said in the post, which \nwas co-authored by several of OpenAI’s cofounders, including Altman, Greg Brockman, and Ilya Sutskever.In \nOpenAI investor Vinod Khosla spars with Elon Musk over lawsuit\naddition, OpenAI released emails Musk had sent to people at the company, demonstrating that the billionaire had \nendorsed its fundraising efforts. “This needs billions per year immediately or forget it,” Musk wrote in one email, \naccording to OpenAI.OpenAI, as a non-profit, raised less than $45 million from Musk and more than $90 million \nfrom other donors, according to the blog post. Musk pushed OpenAI to announce an initial $1 billion funding \ncommitment in 2015, after CEO Sam Altman and co-founder Greg Brockman initially planned to raise $100 \nmillion.“We need to go with a much bigger number than $100M to avoid sounding hopeless relative to what Google \nor Facebook are spending,” Musk wrote in an email. “I think we should say that we are starting with a $1B funding \ncommitment... I will cover whatever anyone else doesn’t provide.” For Reprint Rights: timescontent.com\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "TECHNOLOGY",
        "length": "1761 words",
        "byline": "David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in",
        "story_text": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly\nThe New York Times \nMarch 21, 2024 Thursday 08:18 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1761 words\nByline: David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in \n2019. Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on \nApple includes product launches, manufacturing issues and political challenges. He also writes about trends across \nthe tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: The lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, \nwhich have fueled its growth into a nearly $3 trillion public company.\nBody\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $3 trillion public company.\nThe federal government’s aggressive crackdown on Big Tech expanded on Thursday to include an antitrust lawsuit \nby the Justice Department against Apple, one of the world’s best-known and most valuable companies.\nThe department joined 16 states and the District of Columbia to file a significant challenge to the reach and \ninfluence of Apple, arguing in an 88-page lawsuit that the company had violated antitrust laws with practices that \nwere intended to keep customers reliant on their iPhones and less likely to switch to a competing device. The tech \ngiant prevented other companies from offering applications that compete with Apple products like its digital wallet, \nwhich could diminish the value of the iPhone, and hurts consumers and smaller companies that compete with it, the \ngovernment said.\nThe Justice Department’s lawsuit is seeking to put an end to those practices. The government even has the right to \nask for a breakup of the Silicon Valley icon.\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $2.75 trillion public company that was for years the most valuable on the planet. It \ntakes direct aim at the iPhone, Apple’s most popular device and most powerful business, and attacks the way the \ncompany has turned the billions of smartphones it has sold since 2007 into the centerpiece of its empire.\nBy tightly controlling the user experience on iPhones and other devices, Apple has created what critics call an \nuneven playing field, where it grants its own products and services access to core features that it denies rivals. \nOver the years, it has limited finance companies’ access to the phone’s payment chip and Bluetooth trackers from \ntapping into its location-service feature. It’s also easier for users to connect Apple products, like smartwatches and \nlaptops, to the iPhone than to those made by other manufacturers.\n“Each step in Apple’s course of conduct built and reinforced the moat around its smartphone monopoly,” the \ngovernment said in the lawsuit, which was filed in the U.S. District Court for the District of New Jersey. It added that \nthe company’s practices resulted in “higher prices and less innovation.”\nApple says these practices make its iPhones more secure than other smartphones. But app developers and rival \ndevice makers say Apple uses its power to crush competition.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\n“This lawsuit threatens who we are and the principles that set Apple products apart in fiercely competitive markets,” \nan Apple spokeswoman said. “If successful, it would hinder our ability to create the kind of technology people \nexpect from Apple — where hardware, software, and services intersect. It would also set a dangerous precedent, \nempowering government to take a heavy hand in designing people’s technology.”\nApple is the latest company the federal government has tried to rein in under a wave of antitrust pressure in recent \nyears from both the Justice Department and the Federal Trade Commission, to which the Biden administration has \nappointed heads sharply focused on changing the laws to fit the modern era. Google, Meta and Amazon are all \nfacing similar suits, and companies from Kroger to JetBlue Airways have faced greater scrutiny of potential \nacquisitions and expansion.\nThe lawsuit asks the court to stop Apple from engaging in current practices, including blocking cloud-streaming \napps, undermining messaging across smartphone operating systems and preventing the creation of digital wallet \nalternatives.\nThe Justice Department has the right under the law to ask for structural changes to Apple’s business — including a \nbreakup, said an agency official, who spoke on condition of anonymity. The official declined to identify what \nadditional action the agency could request in this case but any demands would be tied to how a court rules on the \nquestion of whether — and how — Apple broke the law.\nIt’s unclear what implications the suit — which is likely to drag out years before any type of resolution — would have \nfor consumers. Apple plans to file a motion to dismiss the case in the next 60 days. In its filing, the company plans \nto emphasize that competition laws permit it to adopt policies or designs that its competitors oppose, particularly \nwhen those designs would make using an iPhone a better experience.\nApple has effectively fought off other antitrust challenges. In a lawsuit over its App Store policies that Epic Games, \nthe maker of Fortnite, brought in 2020, Apple persuaded the judge that customers could easily switch between its \niPhone operating system and Google’s Android system. It has presented data showing that the reason few \ncustomers change phones is their loyalty to the iPhone.\nIt also has defended its business practices in the past by highlighting how the App Store, which it opened in 2008, \ncreated millions of new businesses. Over the past decade, the number of paid app makers has increased by 374 \npercent to 5.2 million, which Apple has said is a testament to a flourishing marketplace.\nEvery modern-day tech giant has faced a major federal antitrust challenge. The Justice Department is also pursuing \na case against Google’s search business and another focused on Google’s hold over advertising technology. The \nFederal Trade Commission filed a lawsuit accusing Meta, which owns Facebook, of thwarting competition when it \nbought Instagram and WhatsApp and another accusing Amazon of abusing its power over online retail. The F.T.C. \nalso tried unsuccessfully to block Microsoft from acquiring Activision Blizzard, the video game publisher.\nThe lawsuits reflect a push by the regulators to apply greater scrutiny to the companies’ roles as gatekeepers to \ncommerce and communications. In 2019, under President Donald J. Trump, the agencies opened antitrust inquiries \ninto Google, Meta, Amazon and Apple. The Biden administration has put even more energy behind the effort, \nappointing critics of the tech giants to lead both the F.T.C. and the antitrust division of the Department of Justice.\nIn Europe, regulators recently punished Apple for preventing music streaming competitors from communicating with \nusers about promotions and options to upgrade their subscriptions, levying a 1.8 billion-euro fine. App makers have \nalso appealed to the European Commission, the European Union’s executive arm, to investigate claims that Apple \nis violating a new law requiring it to open iPhones to third-party app stores.\nIn South Korea and the Netherlands, the company is facing potential fines over the fees it charges app developers \nto use alternative payment processors. Other countries, including Britain, Australia and Japan, are considering rules \nthat would undercut Apple’s grip on the app economy.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\nThe Justice Department, which began its investigation into Apple in 2019, chose to build a broader and more \nambitious case than any other regulator has brought against the company. Rather than narrowly focus on the App \nStore, as European regulators have, it focused on Apple’s entire ecosystem of products and services.\nThe lawsuit filed Thursday focuses on a group of practices that the government said Apple had used to shore up its \ndominance.\nThe company “undermines” the ability of iPhone users to message with owners of other types of smartphones, like \nthose running the Android operating system, the government said. That divide — epitomized by the green bubbles \nthat show an Android owner’s messages — sent a signal that other smartphones were lower quality than the \niPhone, according to the lawsuit.\nApple has similarly made it difficult for the iPhone to work with smartwatches other than its own Apple Watch, the \ngovernment argued. Once an iPhone user owns an Apple Watch, it becomes far more costly for them to ditch the \nphone.\nThe government also said Apple had tried to maintain its monopoly by not allowing other companies to build their \nown digital wallets. Apple Wallet is the only app on the iPhone that can use the chip, known as the NFC, that allows \na phone to tap-to-pay at checkout. Though Apple encourages banks and credit card companies to allow their \nproducts to work inside Apple Wallet, it blocks them from getting access to the chip and creating their own wallets \nas alternatives for customers.\nThe government said that Apple refuses to allow game streaming apps that could make the iPhone a less valuable \npiece of hardware or offer “super apps” that let users perform a variety of activities from one application.\nThe government’s complaint uses similar arguments to the claims it made against Microsoft decades ago, in a \nseminal lawsuit that argued the company was tying its web browser to the Windows operating system, said Colin \nKass, an antitrust lawyer at Proskauer Rose. He added that the most compelling allegation — and the one that \nbrings it closest to the Microsoft case — is that Apple could be contractually preventing rivals from developing apps \nthat work with other app providers, as “super apps” could.\nOther legal experts noted that companies are legally allowed to favor their own products and services, so the \ngovernment will have to explain why that is a problem with Apple.\n“This case is about technology,” Mr. Kass said. “Can the antitrust laws force a company to redesign its product to \nmake it more compatible with competitors’ products?”\nApple has defended itself against other antitrust challenges by arguing that its policies are critical to make its \ndevices private and secure. In its defense against Epic Games, it argued that restraining the distribution of apps \nallowed it to protect the iPhone from malware and fraud. The practice benefited customers and made the iPhone \nmore attractive than competing devices with Android’s operating system.\nThe government will try to show that the effect of Apple’s policies was to hurt consumers, not help them.\n“Competition makes devices more private and more secure,” said Jonathan Kanter, assistant attorney general of \nthe Justice Department’s antitrust division. “In many instances, Apple’s conduct has made its ecosystem less \nprivate and less secure.”\nPHOTO: Tim Cook, Apple’s chief executive. Wildly popular devices and services have turned Apple into a nearly \n$2.75 trillion public company, and it tightly controls the user experience on iPhones and other products. \n(PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (A20) This article appeared in print on page A1, A20.\nLoad-Date: March 22, 2024\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly"
    },
    {
        "file_name": "New_York_Observer_Jan2024",
        "header": "Bill Nye and the Doomsday Clock Scientists Call for Action",
        "media": "New York Observer",
        "time": "January 25, 2024",
        "section": "",
        "length": "643 words",
        "byline": "Alexandra Tremayne-Pengelly",
        "story_text": "Bill Nye and the Doomsday Clock Scientists Call for Action\nNew York Observer\nJanuary 23, 2024 Tuesday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 643 words\nByline: Alexandra Tremayne-Pengelly\nBody\nHumanity is closer than it's ever been to extinction, according to international experts in nuclear technology, cyber \npolicy and climate science. They announced today (Jan.23) that the Doomsday Clock, a symbol of our world's \nproximity to annihilation, will stay at 90 seconds until midnight. The clock was first set to this time in 2023, the \nclosest it's been to midnight since its creation in 1947.\n\"We could be facing catastrophe unless we better manage the technologies we've created,\" said celebrity scientist \nBill Nye, one of the participants in the annual Doomsday Clock announcement, in a statement. \"It's time to act.\"\nThe clock is a product of the Bulletin of the Atomic Scientists, a nonprofit organization created in 1945 by Albert \nEinstein, Robert Oppenheimer and the University of Chicago scientists who helped develop the first atomic \nweapons at the Manhattan Project. Its initial purpose was to spur public debate following the bombings of Hiroshima \nand Nagasaki.\nWho sets the Doomsday Clock time and how?\nInitially set to seven minutes until midnight, the Doomsday Clock's time has fluctuated in response to political, \nenvironmental and other factors over the years. The time is decided by the Bulletin's Science and Security Board in \nconsultation with its Board of Sponsors, which includes ten Nobel Laureates. Humanity, according to the group, was \nfurthest from self-extinction in 1991, when the Doomsday Clock was set to 17 minutes until midnight in response to \nthe end of the Cold War.\nEmerging technologies, climate threats and global conflicts have brought the clock closer and closer to midnight. \n\"The risks of last year continue with unabated ferocity,\" said Rachel Bronson, CEO and president of the Bulletin of \nthe Atomic Scientists, during today's announcement. The ongoing war in Ukraine was cited by the Bulletin as a \nthreat driving potential nuclear escalation.\n\"Traditional nuclear arms control has really come to an end for now,\" added Alexander Glaser, a mechanical and \naerospace professor at Princeton University. The mass expansion of nuclear arsenals in China, Russia and the \nUnited States is a major concern, he said. \"In many ways, we're setting ourselves up for a three-way arms race \nwhich is unprecedented and quite concerning,\" said Glaser, urging the nations to engage in a serious dialogue.\nThe Doomsday Clock's 2024 time was also influenced by concerns over emerging biological technologies and the \nrapid advance of generative artificial intelligence (A.I.) The growth of A.I. \"has disrupted many segments of \nsociety already,\" noted Herb Lin, a senior research scholar for cyber policy and security at Stanford University. \nGlobal governance, especially governance of private sector actors with influence over these technologies, is \nneeded more than ever as we move forward, he added.\nBill Nye and the Doomsday Clock Scientists Call for Action\nDespite its dire warnings, the Bulletin says the Doomsday Clock should inspire public discussions about how to turn \nback the clock by designing solutions. The clock is \"set up to get people talking about these issues,\" said Nye. \"You \nhave to be optimistic or you're not going to get anything done.\"\nOne of the most promising areas for action is climate change, which is a significant factor in the Doomsday Clock \nsettings. Noting a rise in greenhouse gas emissions, the increase in climate-related disasters and 2023 being the \nhottest year on record, the Bulletin in its 2024 statement describes our current climate change outlook as \n\"ominous.\" But the world also invested a record-breaking $1.7 trillion in clean energy and saw a historic climate deal \nfor renewable energy at COP28,\" noted Ambuj Sagar, deputy director at the Indian Institute of Technology Delhi, \nadding that individual citizens should push for greater climate policies and action. \"We are moving in the right \ndirection, even if it's not as fast as we might like,\" he said.\nLoad-Date: January 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Chinese Chatbots Must Toe Party Line",
        "media": "The New York Times",
        "time": "April 25, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1326 words",
        "byline": "By Chang Che",
        "story_text": "Chinese Chatbots Must Toe Party Line\nThe New York Times\nApril 25, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1326 words\nByline: By Chang Che\nBody\nThe Communist Party outlined draft rules that would set guardrails on the rapidly growing industry of services like \nChatGPT.\nFive months after ChatGPT set off an investment frenzy over artificial intelligence, Beijing is moving to rein in \nChina's chatbots, a show of the government's resolve to keep tight regulatory control over technology that could \ndefine an era. \n  The Cyberspace Administration of China unveiled draft rules this month for so-called generative artificial \nintelligence -- the software systems, like the one behind ChatGPT, that can formulate text and pictures in response \nto a user's questions and prompts.\n  According to the regulations, companies must heed the Chinese Communist Party's strict censorship rules, just as \nwebsites and apps have to avoid publishing material that besmirches China's leaders or rehashes forbidden history. \nThe content of A.I. systems will need to reflect ''socialist core values'' and avoid information that undermines ''state \npower'' or national unity.\n  Companies will also have to make sure their chatbots create words and pictures that are truthful and respect \nintellectual property, and will be required to register their algorithms, the software brains behind chatbots, with \nregulators.\n  The rules are not final, and regulators may continue to modify them, but experts said engineers building artificial \nintelligence services in China were already figuring out how to incorporate the edicts into their products.\n  Around the world, governments have been wowed by the power of chatbots with the A.I.-generated results ranging \nfrom alarming to benign. Artificial intelligence has been used to ace college exams and create a fake photo of Pope \nFrancis in a puffy coat.\n  ChatGPT, developed by the U.S. company OpenAI, which is backed by some $13 billion from Microsoft, has \nspurred Silicon Valley to apply the underlying technology to new areas like video games and advertising. The \nventure capital firm Sequoia Capital estimates that A.I. businesses could eventually produce ''trillions of dollars'' in \neconomic value.\n  In China, investors and entrepreneurs are racing to catch up. Shares of Chinese artificial intelligence firms have \nsoared. Splashy announcements have been made by some of China's biggest tech companies, including most \nrecently the e-commerce giant Alibaba; SenseTime, which makes facial recognition software; and the search \nChinese Chatbots Must Toe Party Line\nengine Baidu. At least two start-ups developing Chinese alternatives to OpenAI's technology have raised millions of \ndollars.\n  ChatGPT is unavailable in China. But faced with a growing number of homegrown alternatives, China has swiftly \nunveiled its red lines for artificial intelligence, ahead of other countries that are still considering how to regulate \nchatbots.\n  The rules showcase China's ''move fast and break things'' approach to regulation, said Kendra Schaefer, head of \ntech policy at Trivium China, a Beijing-based consulting firm.\n  ''Because you don't have a two-party system where both sides argue, they can just say, 'OK, we know we need to \ndo this, and we'll revise it later,''' she added.\n  Chatbots are trained on large swaths of the internet, and developers are grappling with the inaccuracies and \nsurprises of what they sometimes spit out. On their face, China's rules require a level of technical control over \nchatbots that Chinese tech companies have not achieved. Even companies like Microsoft are still fine-tuning their \nchatbots to weed out harmful responses. China has a much higher bar, which is why some chatbots have already \nbeen shut down and others are available only to a limited number of users.\n  Experts are divided on how difficult it will be to train A.I. systems to be consistently factual. Some doubt that \ncompanies can account for the gamut of Chinese censorship rules, which are often sweeping, are ever-changing \nand even require censorship of specific words and dates like June 4, 1989, the day of the Tiananmen Square \nmassacre. Others believe that over time, and with enough work, the machines can be aligned with truth and specific \nvalues systems, even political ones.\n  Analysts expect the rules to undergo changes after consultation with China's tech companies. Regulators could \nsoften their enforcement so the rules don't wholly undermine development of the technology.\n  China has a long history of censoring the internet. Throughout the 2000s, the country has constructed the world's \nmost powerful information dragnet over the web. It scared away noncompliant Western companies like Google and \nFacebook. It hired millions of workers to monitor internet activity.\n  All the while, China's tech companies, which had to comply with the rules, flourished, defying Western critics who \npredicted that political control would undercut growth and innovation. As technologies such as facial recognition and \nmobile phones arose, companies helped the state harness them to create a surveillance state.\n  The current A.I. wave presents new risks for the Communist Party, said Matt Sheehan, an expert on Chinese A.I. \nand a fellow at the Carnegie Endowment for International Peace.\n  The unpredictability of chatbots, which will make statements that are nonsensical or false -- what A.I. researchers \ncall hallucination -- runs counter to the party's obsession with managing what is said online, Mr. Sheehan said.\n  ''Generative artificial intelligence put into tension two of the top goals of the party: the control of information and \nleadership in artificial intelligence,'' he added.\n  China's new regulations are not entirely about politics, experts said. For example, they aim to protect privacy and \nintellectual property for individuals and creators of the data upon which A.I. models are trained, a topic of worldwide \nconcern.\n  In February, Getty Images, the image database company, sued the artificial intelligence start-up Stable Diffusion \nfor training its image-generating system on 12 million watermarked photos, which Getty claimed diluted the value of \nits images.\n  China is making a broader push to address legal questions about A.I. companies' use of underlying data and \ncontent. In March, as part of a major institutional overhaul, Beijing established the National Data Bureau, an effort to \nChinese Chatbots Must Toe Party Line\nbetter define what it means to own, buy and sell data. The state body would also assist companies with building the \ndata sets necessary to train such models.\n  ''They are now deciding what kind of property data is and who has the rights to use it and control it,'' said Ms. \nSchaefer, who has written extensively on China's A.I. regulations and called the initiative ''transformative.''\n  Still, China's new guardrails may be ill timed. The country is facing intensifying competition and sanctions on \nsemiconductors that threaten to undermine its competitiveness in technology, including artificial intelligence.\n  Hopes for Chinese A.I. ran high in early February when Xu Liang, an A.I. engineer and entrepreneur, released one \nof China's earliest answers to ChatGPT as a mobile app. The app, ChatYuan, garnered over 10,000 downloads in \nthe first hour, Mr. Xu said.\n  Media reports of marked differences between the party line and ChatYuan's responses soon surfaced. Responses \noffered a bleak diagnosis of the Chinese economy and described the Russian war in Ukraine as a ''war of \naggression,'' at odds with the party's more pro-Russia stance. Days later, the authorities shut down the app.\n  Mr. Xu said he was adding measures to create a more ''patriotic'' bot. They include filtering out sensitive keywords \nand hiring more manual reviewers who can help him flag problematic answers. He is even training a separate \nmodel that can detect ''incorrect viewpoints,'' which he will filter.\n  Still, it is not clear when Mr. Xu's bot will ever satisfy the authorities. The app was initially set to resume on Feb. \n13, according to screenshots, but as of Friday it was still down.\n  ''Service will resume after troubleshooting is complete,'' it read.\nhttps://www.nytimes.com/2023/04/24/world/asia/china-chatbots-ai.html\nGraphic\n \nPHOTOS: A booth in Shanghai for SenseTime, a Chinese facial recognition company. (PHOTOGRAPH BY CHINA \nNEWS SERVICE, VIA AGENCE FRANCE-PRESSE -- GETTY IMAGES) (B1)\nThe headquarters of the Cyberspace Administration of China. Right: Robin Li, chief executive of China's search \ngiant Baidu, which is delving into artificial intelligence. (PHOTOGRAPHS BY THOMAS PETER/REUTERS\n NG HAN GUAN/ASSOCIATED PRESS) (B6) This article appeared in print on page B1, B6.               \nLoad-Date: April 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "IBM Tries to Ease Customers’ Qualms About Using Generative A.I.",
        "media": "The New York Times",
        "time": "September 28, 2023",
        "section": "BUSINESS",
        "length": "819 words",
        "byline": "Steve Lohr",
        "story_text": "IBM Tries to Ease Customers’ Qualms About Using Generative A.I.\nThe New York Times \nSeptember 28, 2023 Thursday 20:58 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 819 words\nByline: Steve Lohr\nHighlight: The company will assume the legal risk of businesses that use its A.I. systems and will publish the \ntechnology’s underlying data.\nBody\nThe company will assume the legal risk of businesses that use its A.I. systems and will publish the technology’s \nunderlying data.\nThere is no shortage of excitement in corporate America for the new artificial intelligence that can produce \neverything from business reports to computer code with humanlike fluency.\nPlenty of companies are experimenting with the technology, called generative A.I., but they are worried about how \nconfidential data will be handled, the accuracy of A.I.-generated answers and potential legal liability.\nIBM on Thursday announced its campaign to ease customers’ qualms. The company said it would indemnify \ncompanies against copyright or other intellectual property claims for using its generative A.I. systems. IBM will also \npublish its data sets — the underlying data that is used to build or “train” the A.I. system — which is not standard \npractice among commercial providers of generative A.I. technology.\nThe announcement is an indication that, while attention has been focused on the new A.I. technology in chatbots \nlike OpenAI’s ChatGPT, IBM is laying its plans to tackle the market.\nIBM’s customers are mostly other businesses, and persuading those companies to use new A.I. products means \nassuring them that they won’t run into legal trouble. OpenAI, for example, has already been sued by a collection of \nauthors who accuse it of infringing on their copyrights by using their books to train ChatGPT.\nOver the last year, start-ups like OpenAI and other industry giants like Google and Microsoft have been much more \naggressive than IBM about publicly discussing their A.I. work. Even Meta, the parent company of Facebook, this \nweek introduced A.I. chatbots meant to sound like celebrities such as the quarterback Tom Brady and the hip-hop \nartist Snoop Dogg.\nIBM’s relatively quiet stance showed how much the tech industry had changed in the 12 years since IBM’s Watson \nA.I. system beat top competitors on “Jeopardy!” A.I. became a centerpiece of IBM’s pitch to corporate customers, \nbut the company has been overshadowed by younger competitors in the nearly yearlong A.I. frenzy in the tech \nindustry.\nOther technology suppliers are also trying to reassure customers by assuming legal risks. Microsoft pledged this \nmonth to defend customers in any copyright suits that arise from using its A.I.-powered Copilots, which it is adding \nto its office productivity software and programming tools. Adobe has made a similar commitment for copyright \nclaims against customers using Adobe Firefly, its A.I. art-generation software.\nIBM Tries to Ease Customers’ Qualms About Using Generative A.I.\nThe IBM A.I. systems — or “models,” as developers call them — are tailored for use by businesses. And the \ntraining data has been curated with companies in mind and culled from the internet, academic journals, computer \ncode repositories, and legal and finance documents, the company said.\nIBM appears to be going further than other companies in taking on risk and opening up its model-training data. But \nit is in step with where the business market for generative A.I. is heading, said Patrick Moorhead, chief executive of \nMoor Insights &amp; Strategy, a technology analysis firm.\nThe big A.I.-fueled consumer services like ChatGPT and Google’s Bard are closed, and people outside the \ncompanies behind them cannot usually see what data those systems are built on. That will not satisfy most \ncorporate customers, Mr. Moorhead said.\n“Businesses need to know the data inputs and get a sense of why you got the answer you did,” he said. “Putting \ntheir customer or confidential data into an A.I. model is seen as high risk for a business.”\nIBM is positioning itself as a partner for companies that want to create their own A.I. technology, by adding their \nbusiness data to IBM’s open models.\nThe early focus of most business technology companies, including Microsoft, Oracle, Salesforce and SAP, has \nlargely been on embedding generative A.I. to improve their existing digital tools for office productivity, supply chain \nmanagement, customer service and marketing.\nIBM will deploy that A.I. in its products as well, but its emphasis is helping businesses become creators, as well as \ncustomers, of generative A.I. technology.\nIn business, the A.I. models are large, but far smaller than needed for the big consumer chatbots, said Rob \nThomas, IBM’s senior vice president for software. The narrower focus also helps improve accuracy. “And for our \nmarket, accuracy is way more important than size,” he said.\nThe smaller models also require far less computing firepower than the giant consumer chatbots. That, Mr. Thomas \nsaid, should open the door to wider use of generative A.I. in operations that promise an immediate impact and \npayoff, including customer service, automated back-office tasks and digital assistants for writing code.\nIn those fields, “we see a defensible return on investment at the moment,” Mr. Thomas said. “The economics work.”\nThis article appeared in print on page B7.\nLoad-Date: September 28, 2023"
    },
    {
        "file_name": "by_White_House_Aug2023",
        "header": "Google, Amazon, Microsoft, Meta other tech firms agree to AI safeguards set",
        "media": "by White House",
        "time": "August 11, 2023",
        "section": "TECH LATEST, TECH LATEST, TECH LATEST, TECH LATEST, TECH LATEST & US POLITICS NEWS",
        "length": "711 words",
        "byline": "Associated Press",
        "story_text": "Google, Amazon, Microsoft, Meta other tech firms agree to AI safeguards set \nby White House\nUSA Today Online\nJuly 21, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST, TECH LATEST, TECH LATEST, TECH LATEST, TECH LATEST & US POLITICS NEWS\nLength: 711 words\nByline: Associated Press\nBody\nWASHINGTON — Amazon, Google, Meta, Microsoft and other companies that are leading the development of \nartificial intelligence technology have agreed to meet a set of AI safeguards brokered by President Joe Biden's \nadministration.\nThe White House said Friday that it has secured voluntary commitments from seven U.S. companies meant to \nensure their AI products are safe before they release them. Some of the commitments call for third-party oversight \nof the workings of commercial AI systems, though they don't detail who will audit the technology or hold the \ncompanies accountable.\nLink to Image\nWarnings abound: AI poses risk of extinction, tech leaders warn in open letter. Here's why alarm is spreading\nA surge of commercial investment in generative AI tools that can write convincingly human-like text and churn out \nnew images and other media has brought public fascination as well as concern about their ability to trick people and \nspread disinformation, among other dangers.\nThe four tech giants, along with ChatGPT-maker OpenAI and startups Anthropic and Inflection, have committed to \nsecurity testing \"carried out in part by independent experts\" to guard against major risks, such as to biosecurity and \ncybersecurity, the White House said in a statement.\nThe companies have also committed to methods for reporting vulnerabilities to their systems and to using digital \nwatermarking to help distinguish between real and AI-generated images known as deepfakes.\nWhere it's going: Fear over AI dangers grows as some question if tools like ChatGPT will be used for evil\nThey will also publicly report flaws and risks in their technology, including effects on fairness and bias, the White \nHouse said.\nThe voluntary commitments are meant to be an immediate way of addressing risks ahead of a longer-term push to \nget Congress to pass laws regulating the technology.\nSome advocates for AI regulations said Biden's move is a start but more needs to be done to hold the companies \nand their products accountable.\nGoogle , Amazon, Microsoft , Meta other tech firms agree to AI safeguards set by White House\n\"History would indicate that many tech companies do not actually walk the walk on a voluntary pledge to act \nresponsibly and support strong regulations,\" said a statement from James Steyer, founder and CEO of the nonprofit \nCommon Sense Media.\nSenate Majority Leader Chuck Schumer, D-N.Y., has said he will introduce legislation to regulate AI. He has held a \nnumber of briefings with government officials to educate senators about an issue that's attracted bipartisan interest.\nA number of technology executives have called for regulation, and several went to the White House in May to speak \nwith Biden, Vice President Kamala Harris and other officials.\nBut some experts and upstart competitors worry that the type of regulation being floated could be a boon for deep-\npocketed first-movers led by OpenAI, Google and Microsoft as smaller players are elbowed out by the high cost of \nmaking their AI systems known as large language models adhere to regulatory strictures.\nThe software trade group BSA, which includes Microsoft as a member, said Friday that it welcomed the Biden \nadministration's efforts to set rules for high-risk AI systems.\n\"Enterprise software companies look forward to working with the administration and Congress to enact legislation \nthat addresses the risks associated with artificial intelligence and promote its benefits,\" the group said in a \nstatement.\nA number of countries have been looking at ways to regulate AI, including European Union lawmakers who have \nbeen negotiating sweeping AI rules for the 27-nation bloc.\nU.N. Secretary-General Antonio Guterres recently said the United Nations is \"the ideal place\" to adopt global \nstandards and appointed a board that will report back on options for global AI governance by the end of the \nyear.The United Nations chief also said he welcomed calls from some countries for the creation of a new U.N. body \nto support global efforts to govern AI, inspired by such models as the International Atomic Energy Agency or the \nIntergovernmental Panel on Climate Change.\nThe White House said Friday that it has already consulted on the voluntary commitments with a number of \ncountries.\nThis article originally appeared on USA TODAY: Google, Amazon, Microsoft, Meta other tech firms agree to AI \nsafeguards set by White House\nLoad-Date: August 11, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Who Owns a Song Created by A.I.?; DealBook Newsletter",
        "media": "The New York Times",
        "time": "May 3, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1751 words",
        "byline": "Ephrat Livni, Lauren Hirsch and Sarah Kessler",
        "story_text": "Who Owns a Song Created by A.I.?; DealBook Newsletter\nThe New York Times \nApril 15, 2023 Saturday 15:37 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1751 words\nByline: Ephrat Livni, Lauren Hirsch and Sarah Kessler\nHighlight: Lawmakers are beginning to contemplate questions about authorship and ownership around creative \nmachines. The stakes for creative businesses are high.\nBody\nLawmakers are beginning to contemplate questions about authorship and ownership around creative machines. \nThe stakes for creative businesses are high.\nArtificial intelligence tools that generate text, images and music are moving art into new territory — and that’s \nraising tricky questions for the business of creativity.\nFor early adopters like Insider, the publication that this week announced an experiment with A.I.-aided articles, the \nnew tools promise more efficient content creation. But for many artists, and the businesses that own their work, \ngenerative A.I. is a double threat. These systems can produce copycats of human works that dilute the market, \nand they use artists’ production, without their permission, as training data.\nSome see that as stealing intellectual property: Universal Music Group recently told music streaming platforms, \nincluding Spotify and Apple, to block A.I. systems from scraping its music. (The company is in early discussions to \nlicense its songs to generative A.I. companies, DealBook hears.)\nLawmakers have begun to contemplate new rules around authorship and ownership in connection with creative \nmachines, and the stakes are huge for both the businesses that depend on creative work and the investors who \npoured billions into new A.I. tools. So far, there are three major debates.\nWhat is owed to the creators of the original material? In January, a group of artists sued London-based Stability AI, \na maker of image-generating software, arguing that it infringed on their copyrights by using their work in training \ndata and creating derivative works. The cartoonist Sarah Anderson, who is part of the lawsuit, told The New York \nTimes that she believed artists should opt in to having their work included in such data, and should be compensated \nfor it. Getty Images is also suing Stability AI in Britain and the United States for what it calls “brazen infringement” of \nmillions of photos. Getty argued that the theft is particularly offensive because it has agreements to license data for \nmachine learning. Stability AI has not yet responded to the complaints.\nDoes “fair use” apply? Copyrighted works can be used without permission for commentary, criticism or other \n“transformative” purposes, and robots have traditionally been exempt from liability. But “courts in the future won’t be \nso sympathetic to machine copying,” wrote Mark Lemley, the director of a Stanford Law School program that \nfocuses on science and technology, in the Texas Law Review with a former colleague, Bryan Casey. Lemley is \ncalling for a new “fair learning” standard for using copyrighted material in machine learning. It would include the \nquestion: What is the purpose of the copying? If it’s to learn only, that may be permitted, but if the intent is to \nreproduce the work, it will not be. Not every machine learning data set would qualify for the protection. New tools \nWho Owns a Song Created by A.I.? DealBook Newsletter\nalso raise questions about who has liability for infringement — the user prompting the machine, the company that \nprogrammed the tool or both?\nWho owns the output of generative A.I.? For now, only a human’s work can be copyrighted, but what about work \nthat partly relies on generative A.I.? Some tool developers have said they won’t assert copyright over content \ngenerated by their machines. In February, the Copyright Office rejected a copyright for A.I.-generated images in a \ngraphic novel, though the writer argued that she had made the images via “a creative, iterative process” that \ninvolved “composition, selection, arrangement, cropping and editing for each image.” The government compared \nuse of the A.I. tool to hiring an artist. But the lines may blur as the use of such tools becomes more common. Like \nthe tools, the intellectual property issues are a work in progress that will only get more complex. — Ephrat Livni\nIN CASE YOU MISSED IT \nGriffin Giving. Ken Griffin, the founder of hedge fund Citadel, donated $300 million to Harvard. The gift is his biggest \never to his alma mater, which will rename its Graduate School of Arts and Sciences after him, and brings his total \ndonations to the school to almost half a billion dollars. Not everyone was happy about it.\nAbortion pill pullback. A Texas judge ruled that mifepristone, an abortion pill, should be pulled from shelves more \nthan two decades after the Food and Drug Administration approved it. The Justice Department challenged the \ndecision, and the pharmaceutical industry condemned it, saying it could upend the business of drug making by \nretroactively changing the rules and politicizing the approval process.\nBanks boom. JPMorgan Chase, Wells Fargo and Citigroup opened the bank earnings season with a bang \nyesterday, beating expectations despite the turmoil that has ripped through small and midsize banks in recent \nweeks. Each raked in deposits as customers shifted money from regional lenders, such as the now collapsed \nSilicon Valley Bank. But they also warned that the economy was fragile, with JPMorgan’s Jamie Dimon saying, “We \nare going to eventually have a recession, but that may be pushed off a bit.”\nR(EV)olution. The Biden administration unveiled the most far-reaching U.S. climate regulations ever in a bid to \nensure that two-thirds of new cars and a quarter of new heavy trucks sold in the country are all-electric by 2032. \nThe decision is the latest in a string of big industrial policy moves undertaken under President Biden, who has \npledged billions of dollars to reshape the economy.\nEurope’s China schism. President Emmanuel Macron of France traveled to China with the aim of establishing more \ncordial relations with Beijing than the United States and some of its other allies have — and with a number of \nexecutives in tow, commercial links were a crucial part of the exercise. But Macron caused a bigger stir on his flight \nhome, telling Politico and some French media outlets that Europe should become a “third superpower” and not \nmerely “followers” of Washington.\nHow Twitter could be breaking even\nElon Musk this week gave one of his most extensive interviews since taking Twitter private, musing on everything \nfrom the pain of owning the company to sleeping at the office. But one claim in particular in his chat with the BBC \ncaught DealBook’s eye: that the company is breaking even, and on its way to being cash positive.\nWhen Musk bought Twitter in October, it had lost money in eight of the previous 10 years — and that was before he \nloaded it with debt. In its last quarter as a public company, its net loss was $270 million, though that included some \none-time payments as uncertainty over the deal effectively froze business. Is Musk’s claim that it’s on the brink of \nprofitability feasible? Drew Pascarella, a senior lecturer of finance at Cornell University, told DealBook that it was. \nHere’s why.\nMusk has cut Twitter’s expenses to $1.5 billion, he has said, down from roughly $4.5 billion a year before he took \nover (excluding noncash expenditures, like stock-based employee compensation). Much of the reduction comes \nfrom laying off about 6,300 employees, which Pascarella and a private equity investor, who asked not to be named \nbecause he did not want to publicly speculate, both said could save around $1.3 billion. Other sources of savings: \nWho Owns a Song Created by A.I.? DealBook Newsletter\nrenegotiated cloud and software spending, the closing of a data center and less traditional cost cuts, like janitorial \nservices.\nWhile ad revenue has dropped, cuts to spending may have compensated. Musk said in December that revenue, \nnearly all of which Twitter makes through advertising, had plummeted to $3 billion annually, down from roughly $5.2 \nbillion before the acquisition. With $1.5 billion in expenses, and another $1.5 billion in interest payments on the debt \nthat Musk took to buy Twitter, $3 billion in revenue would be about break-even, before capital expenditures.\nBreak-even may be possible, but it’s not the end game. Analysts expect Twitter’s shift to subscriptions to bring in \nminimal revenue. Musk has said he wants to push further into payments and other sectors as he turns Twitter into \nan “everything app.” That’s hard to do without investing heavily — and Twitter’s business most likely generates little \ncash. As Pascarella put it: “Is $1.5 billion annual cash spend enough to run the business in the intermediate term, or \nhave the cuts been so deep that there will be decay from here?”\n$50 billion \n— The banking crisis was no crisis at all for JPMorgan Chase, the nation’s biggest bank. Jeremy Barnum, \nJPMorgan’s C.F.O., told analysts yesterday that the bank recorded “significant new account-opening activity” last \nquarter, particularly after the fall of Silicon Valley Bank. “We estimate that we have retained approximately $50 \nbillion of these deposit inflows at quarter end,” he added.\nLogan Roy or Rupert Murdoch? \nIn the same week that the HBO drama “Succession” took a pivotal plot twist (DealBook won’t spoil it by revealing \nwhat happened here), Vanity Fair published a revealing article about Rupert Murdoch, the nonagenarian media \nmogul whose family drama inspired the show. The article highlights uncanny similarities between the fictional \npatriarch Logan Roy and Murdoch — and includes the detail that the real-life mogul’s divorce settlement with his \nfourth wife, Jerry Hall, prohibited her from giving story ideas to the writers behind the program.\nCan you tell which of these anecdotes is about Roy, played by Brian Cox, and which is about Murdoch, according to \nVanity Fair?\n1. After surviving a health scare, this man declared, “I’m now convinced of my own immortality.”\n2. This man asked his wife to take online courses in winemaking as part of a scheme to write off $3 million of \nvineyard expenses.\n3. This man threw away a specially prepared steak and lobster buffet because it had sat in a house that stank.\n4. This man met with all of the top divorce lawyers in New York to create a conflict of interest for them to accept his \nwife as a client.\n5. This man got word to his son that it would mean a lot if the son attended his birthday party. But his son still didn’t \ngo.\n6. This man ended one of his marriages with an email that read: “We have certainly had some good times, but I \nhave much to do. … My New York lawyer will be contacting yours immediately.”\nFind the answers at the bottom of this newsletter.\nQuiz answers: 1, 2 and 6: Rupert Murdoch. 3 and 4: Logan Roy. 5: Both.\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nThis article appeared in print on page B2.\nWho Owns a Song Created by A.I.? DealBook Newsletter\nLoad-Date: May 3, 2023"
    },
    {
        "file_name": "Company's_Bob_Sternfels_Sep2023",
        "header": "Protectionism will have a 20-40% impact on global GDP, says McKinsey &",
        "media": "Company's Bob Sternfels",
        "time": "September 6, 2023",
        "section": "INSIGHTS",
        "length": "571 words",
        "byline": "Neha Dewan",
        "story_text": "Protectionism will have a 20-40% impact on global GDP, says McKinsey & \nCompany's Bob Sternfels\nThe Economic Times\nSeptember 7, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: INSIGHTS\nLength: 571 words\nByline: Neha Dewan\nBody\nInhibiting trade could mean that anywhere between 20% and 40% of global GDP is at risk, said Bob Sternfels, \nGlobal Managing Partner, McKinsey & Company. \"That's massive. And that has a massive regressive effect in \nterms of inclusion,\" he said while speaking at the B20 summit held in the capital recently. Sternfels said the \nMcKinsey Global Institute took a deeper look at the implication of restrictions and protectionism across industry \nverticals. \nIt took a broader definition of trade - not just physical flows but also data flows and talent flows. \"About two-thirds of \ntoday's global growth comes from the Global South and that grows to 70% by 2050. So accelerating opportunities \nand growth is critical,\" he said.Sternfels noted that over the last couple of years, trade hasn't been that resilient. \n\"With exogenous shocks, we saw supply chains were pretty fragile. Diversification of trade and the multiplication of \ntrade routes does a couple of things. One is it makes the world more resilient. And second is it drives economic \ngrowth that is particularly inclusive. So as you start to think about multiple trade routes as opposed to concentration \nof trade routes, there may be an answer here in inclusion but it does require reimagining.\" Talking further about the \nsignificance of inclusion, he added that there is an opportunity for India to move 220 million jobs from farm jobs to \nnon-farm ones with a massive increase in wage escalation by 2047. This, he said, would also help arrest inequality, \nwhich is the number one global issue today. Giving specifics, Sternfels gave the example of major economies and \ntheir respective income populations. \"In the US, the middle class has shrunk by 18% in the last 20 years. Go to \nChina - the top 10% of the income population have grown 50% faster than the bottom half. In India, that top 10% \nhave grown 100% faster. So the data shows it. What this says is that we need to have economic growth. It is the \ncatalyst that will help to solve all problems but that growth has to be inclusive,\" he said. Speaking of SME growth \naround global trade finance, Sternfels said SMEs account for 95% of the firms and 70% of the jobs in the world \ntoday. They, however, are lacking in two aspects: access to credit and markets. \"40% of applications for credit to \nSMEs are denied and SMEs face enormous barriers and trade.\" Just easing the finance aspect and allowing SMEs \nto trade across borders will give them billions of dollars in value, he said.The global managing partner at McKinsey \nexplained how accelerating technology can play a big role in achieving inclusive growth: \"We did some work looking \nat the value of generative AI around 67 specific use cases. And it shows there is $3 trillion-$4 trillion in annual \nrevenue available just in these 67 use cases.\" Sternfels also spoke about their \"Women in the Workplace\" report, \nwhich showed that there was $12 trillion in economic value if gender parity was implemented. \"That number \naccelerates to $28 trillion if you actually say women would play identical roles to men in enterprise. So $28 trillion of \ninclusive growth by solving gender access issues,\" he said. The Business 20 (B20) is the official G20 dialogue \nforum with the global business community. Established in 2010, B20 is known to be the most prominent \nengagement groups in G20, with companies and business organisations as participants.  For Reprint Rights: \ntimescontent.com\nProtectionism will have a 20-40% impact on global GDP, says McKinsey & Company 's Bob Sternfels\nLoad-Date: September 6, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jul2023",
        "header": "TCS Deal Wins in Q1 Spark a Relief Rally in IT Stocks",
        "media": "Economic Times (E-Paper Edition)",
        "time": "July 17, 2023",
        "section": "MARKETS",
        "length": "301 words",
        "byline": "Nikita.Periwal@timesgroup.com",
        "story_text": "TCS Deal Wins in Q1 Spark a Relief Rally in IT Stocks\nEconomic Times (E-Paper Edition)\nJuly 14, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: MARKETS\nLength: 301 words\nByline: Nikita.Periwal@timesgroup.com\nBody\nDEMAND OUTLOOK NOT AS ADVERSE AS EXPECTED\nMumbai: Shares of technology companies saw a relief rally on Thursday as sentiment improved after Tata \nConsultancy Services showed strong deal wins in the June quarter, reassuring investors that the demand outlook \nmay not be as adverse as expected earlier. Shares of TCS, Infosys, Tech Mahindra, Wipro, LTIMindtree, Persistent \nSystems, and L&T Technology Services ended 1-3% higher on the NSE, while the Nifty IT index ended nearly 2% \nhigher. While both the shares and the index ended significantly off highs, their gains earlier in the day had helped \nthe Sensex surpass the 66,000 mark for the first time ever. \n TCS' deal wins in the June quarter rose over 24% on-year to $10.2 billion. US and Europe are key markets for \nIndian technology service providers, and TCS being able to maintain its deal wins at a time when these markets are \nseeing adverse macro conditions is a “key positive and differentiator”, Motilal Oswal Securities said. Analysts \nbelieve that share prices have factored in most of the negatives for the sector, and given that valuations are \ncurrently reasonable, they advise investors to accumulate stocks in the sector upon corrections. While a ramp-down \nin projects, a slowdown in discretionary spending and deal tenures being elongated are weighing on client spending \non technology in the near term, trends such as cloud, data, artificial intelligence, and generative AI will drive \ndemand in the long term, they said. While TCS has said that double-digit growth would be a “tall ask” in the current \nfiscal after it saw its slowest quarterly growth in sales since the company went public, analysts believe that some \nsupply-side constraints easing up will provide the headroom to improve profitability, while growth normalises in a \nfew quarters.\nLoad-Date: July 17, 2023"
    },
    {
        "file_name": "Newsletter_May2023",
        "header": "The Optimist’s Guide to Artificial Intelligence and Work; DealBOok",
        "media": "Newsletter",
        "time": "May 30, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1578 words",
        "byline": "Sarah Kessler and Ephrat Livni",
        "story_text": "The Optimist’s Guide to Artificial Intelligence and Work; DealBOok \nNewsletter\nThe New York Times \nMay 20, 2023 Saturday 09:06 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1578 words\nByline: Sarah Kessler and Ephrat Livni\nHighlight: The focus of much discussion is on how it will replace jobs, but nothing is inevitable.\nBody\nThe focus of much discussion is on how it will replace jobs, but nothing is inevitable.\nIt’s easy to fear that the machines are taking over: Companies like IBM and the British telecommunications \ncompany BT have cited artificial intelligence as a reason for reducing head count, and new tools like ChatGPT and \nDALL-E make it possible for anyone to understand the extraordinary abilities of artificial intelligence for themselves. \nOne recent study from researchers at OpenAI (the start-up behind ChatGPT) and the University of Pennsylvania \nconcluded that for about 80 percent of jobs, at least 10 percent of tasks could be automated using the technology \nbehind such tools.\n“Everybody I talk to, supersmart people, doctors, lawyers, C.E.O.s, other economists, your brain just first goes to, \n‘Oh, how can generative A.I. replace this thing that humans are doing?’” said Erik Brynjolfsson, a professor at the \nStanford Institute for Human-Centered AI.\nBut that’s not the only option, he said. “The other thing that I wish people would do more of is think about what new \nthings could be done now that was never done before. Obviously that’s a much harder question.” It is also, he \nadded, “where most of the value is.”\nHow technology makers design, business leaders use and policymakers regulate A.I. tools will determine how \ngenerative A.I. ultimately affects jobs, Brynjolfsson and other economists say. And not all the choices are \nnecessarily bleak for workers.\nA.I. can complement human labor rather than replace it. Plenty of companies use A.I. to automate call centers, for \ninstance. But a Fortune 500 company that provides business software has instead used a tool like ChatGPT to give \nits workers live suggestions for how to respond to customers. Brynjolfsson and his co-authors of a study compared \nthe call center employees who used the tool to those who didn’t. They found that the tool boosted productivity by 14 \npercent on average, with most of the gains made by low-skilled workers. Customer sentiment was also higher and \nemployee turnover lower in the group that used the tool.\nDavid Autor, a professor of economics at the Massachusetts Institute of Technology, said that A.I. could potentially \nbe used to deliver “expertise on tap” in jobs like health care delivery, software development, law, and skilled repair. \n“That offers an opportunity to enable more workers to do valuable work that relies on some of that expertise,” he \nsaid.\nWorkers can focus on different tasks. As A.T.M.s automated the tasks of dispensing cash and taking deposits, the \nnumber of bank tellers increased, according to an analysis by James Bessen, a researcher at the Boston University \nSchool of Law. This was partly because while bank branches required fewer workers, they became cheaper to open \nThe Optimist’s Guide to Artificial Intelligence and Work DealBOok Newsletter\n— and banks opened more of them. But banks also changed the job description. After A.T.M.s, tellers focused less \non counting cash and more on building relationships with customers, to whom they sold products like credit cards. \nFew jobs can be completely automated by generative A.I. But using an A.I. tool for some tasks may free up \nworkers to expand their work on tasks that can’t be automated.\nNew technology can lead to new jobs. Farming employed nearly 42 percent of the work force in 1900, but because \nof automation and advances in technology, it accounted for just 2 percent by 2000. The huge reduction in farming \njobs didn’t result in widespread unemployment. Instead, technology created a lot of new jobs. A farmer in the early \n20th century would not have imagined computer coding, genetic engineering or trucking. In an analysis that used \ncensus data, Autor and his co-authors found that 60 percent of current occupational specialties did not exist 80 \nyears ago.\nOf course, there’s no guarantee that workers will be qualified for new jobs, or that they’ll be good jobs. And none of \nthis just happens, said Daron Acemoglu, an economics professor at M.I.T. and a co-author of “Power and Progress: \nOur 1,000-Year Struggle Over Technology &amp; Prosperity.”\n“If we make the right choices, then we do create new types of jobs, which is crucial for wage growth and also for \ntruly reaping the productivity benefits,” Acemoglu said. “But if we do not make the right choices, much less of this \ncan happen.” — Sarah Kessler\nIN CASE YOU MISSED IT \nMartha’s model behavior. The lifestyle entrepreneur Martha Stewart became the oldest person to be featured on the \ncover of Sports Illustrated’s swimsuit issue this week. Stewart, 81, told The Times that it was a “large challenge” to \nhave the confidence to pose but that two months of Pilates had helped. She isn’t the first person over 60 to have \nthe distinction: Maye Musk, the mother of Elon Musk, graced the cover last year at the age of 74.\nTikTok block. Montana became the first state to ban the Chinese short video app, barring app stores from offering \nTikTok within its borders starting Jan. 1. The ban is expected to be difficult to enforce, and TikTok users in the state \nhave sued the government, saying the measure violates their First Amendment rights and giving a glimpse of the \npotential blowback if the federal government tries to block TikTok nationwide.\nBanker blame game. Greg Becker, the ex-C.E.O. of Silicon Valley Bank, blamed “rumors and misconceptions” for a \nrun on deposits in his first public comments since the lender collapsed in March. Becker and former top executives \nof the failed Signature Bank also told a Senate committee investigating their role in the collapse of the banks that \nthey would not give back millions of dollars in pay.\nA brief history of tech C.E.O.s seeking constraints \nWhen OpenAI’s chief executive, Sam Altman, testified in Congress this week and called for regulation of \ngenerative artificial intelligence, some lawmakers hailed it as a “historic” move. In fact, asking lawmakers for new \nrules is a move straight out of the tech industry playbook. Silicon Valley’s most powerful executives have long gone \nto Washington to demonstrate their commitment to rules in an attempt to shape them while simultaneously \nunleashing some of the world’s most powerful and transformative technologies without pause.\nOne reason: A federal rule is much easier to manage than different regulations in different states, Bruce Mehlman, \na political consultant and former technology policy official in the Bush administration, told DealBook. Clearer \nregulations also give investors more confidence in a sector, he added.\nThe strategy sounds sensible, but if history is a useful guide, the reality can be messier than the rhetoric:\n• In December 2021, Sam Bankman-Fried, founder of the failed crypto exchange FTX, was one of six \nexecutives to testify about digital assets in the House and call for regulatory clarity. His company had just \nsubmitted a proposal for a “unified joint regime,” he told lawmakers. A year later, Bankman-Fried’s \nbusinesses were bankrupt, and he was facing criminal fraud and illegal campaign contribution charges.\nThe Optimist’s Guide to Artificial Intelligence and Work DealBOok Newsletter\n• In 2019, Facebook founder Mark Zuckerberg wrote an opinion piece in The Washington Post, “The Internet \nNeeds New Rules,” based on failures in content moderation, election integrity, privacy and data \nmanagement at the company. Two years later, independent researchers found that misinformation was \nmore rampant on the platform than in 2016, even though the company had spent billions trying to stamp it \nout.\n• In 2018, the Apple chief Tim Cook said he was generally averse to regulation but supported more strict data \nprivacy rules, saying, “It’s time for a set of people to think about what can be done.” But to maintain its \nbusiness in China, one of its biggest markets, Apple has largely ceded control of customer data to the \ngovernment as part of its requirements to operate there.\nBuzzword of the week: ‘Algospeak’ \nPlatforms like TikTok, Facebook, Instagram and Twitter use algorithms to identify and moderate problematic \ncontent. To avert these digital moderators and allow free exchange about taboo topics, a linguistic code has \ndeveloped. It’s called “algospeak.”\n“A linguistic arms race is raging online — and it isn’t clear who’s winning,” writes Roger J. Kreuz, a psychology \nprofessor at the University of Memphis. Posts about sensitive issues like politics, sex or suicide can be flagged by \nalgorithms and taken down, leading to the use of creative misspellings and stand-ins, like “seggs” and “mascara” for \nsex, “unalive” for death and “cornucopia” for homophobia. There is a history of responding to prohibitions with code, \nKruz notes, such as 19th-century Cockney rhyming slang in England or “Aesopian,” an allegorical language used to \ncircumvent censorship in Tsarist Russia.\nAlgorithms aren’t alone in not picking up on the code. The euphemisms and misspellings are particularly ubiquitous \namong marginalized communities. But the hidden language also sometimes eludes humans, leading to potentially \nfraught miscommunications online. In February, the celebrity Julia Fox found herself in an awkward exchange with \na victim of sexual assault after misunderstanding a post about “mascara” and had to issue a public apology for \nresponding inappropriately to what she thought was a discussion about makeup.\nThanks for reading!\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Sam Altman, chief executive of OpenAI, testified before a Senate subcommittee last week. \n(PHOTOGRAPH BY WIN MCNAMEE/GETTY IMAGES) This article appeared in print on page B4.\nLoad-Date: May 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Would You Take A.I.'s Money Advice?",
        "media": "The New York Times",
        "time": "May 20, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1504 words",
        "byline": "By Paulette Perhach",
        "story_text": "Would You Take A.I.'s Money Advice?\nThe New York Times\nMay 20, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1504 words\nByline: By Paulette Perhach\nBody\nThe financial services industry is plotting how to incorporate tools like ChatGPT into its products. But humans will \nstill be necessary to provide personal advice.\nPaul Weiner, an artist, has been experimenting with artificial intelligence for the past year, generating A.I.-created \nvisual disinformation and seeing whether he can get the images to spread. But recently, he turned to ChatGPT, a \nchatbot that has the ability to respond to complex questions, for a much different reason: With his 30th birthday \nlooming, he decided to ask it for advice about retirement planning. \n  ''Maybe ChatGPT would have some answers that I might otherwise get from someone who I'd have to pay a lot of \nmoney to,'' he said.\n  Generative A.I. like ChatGPT has knowledge workers gripping the rails, bracing for how it might affect their jobs, \nand consumers leaning in to see what costly services could soon be replaced with a prompt. As the investment \nindustry turns to artificial intelligence as a financial planning and advice tool, the values of accuracy, humanity, \nsecurity and accessibility are jostling for prominence. In the future, who -- or what -- will we be asking to advise us \non some of life's most important decisions?\n  ChatGPT recommended that Mr. Weiner open a Roth individual retirement account and certificates of deposit, as \nwell as automate his savings and create a budget. He hasn't yet opened any of the accounts or, as the chatbot also \nsuggested, worked with a financial adviser.\n  ''It's a lot of information that gets thrown at you pretty quickly,'' Mr. Weiner said. He found the short explanations \ninsufficient for what a C.D. does or the differences between a Roth I.R.A. and a traditional I.R.A. He concluded that \nspeaking to a financial adviser would probably be more helpful.\n  ''But that kind of circles back to the whole reason I'm doing this on ChatGPT to start with -- it's free,'' he said.\n  A.I. has joined the financial chat\n  Delyanne Barros, a money coach, said she felt that most of the hundreds of thousands of people who follow her \non social media had no idea what ChatGPT is. ''Am I the only one geeking out on this thing?'' she asked. When she \nasks her followers if they've used it, she said, ''they're like, 'What are you talking about?'''\n  She's teaching them the basics: There's a free version of the service, and it works as more than just a Google \nalternative.\nWould You Take A.I.'s Money Advice?\n  On Instagram, she asked if any investing newbies had asked ChatGPT to teach them to invest. Some had tried \nbut reported that they kept getting stuck in a loop of repetitive answers. Ms. Barros found that she was able to get \nvaluable information about allocations, tax efficiencies and retirement withdrawal rates, but she posits that was \nbecause she had knowledge of the investment terms she needed to use.\n  ''You have to know how to frame the questions,'' she said. ''A lot of people don't understand that you get an \nanswer to something and it can build on that answer. You can ask follow-up questions, and it's like a chain.''\n  Ms. Barros has also used ChatGPT to double-check her calculations regarding her retirement plan. Despite its \nhandiness, she is not worried that chatbots will replace her.\n  ''With something like investing, I'm not concerned as a personal finance educator, because I can see that it's not \nlike: 'Oh, we don't need you anymore. We have ChatGPT,''' she said. ''If anything, this is going to be a tool that's \ngoing to enhance my coaching experience with people, but it's definitely not going to be replacing us, because \npeople still need a lot of guidance.''\n  Even if you don't think you're familiar with it, chances are you've already been using generative A.I.\n  Intuit started to integrate A.I. into its software products, which include Mint and TurboTax, more than a decade \nago, said Ashok Srivastava, the company's senior vice president and chief data officer. Today, he said, Intuit's \nplatform performs 58 billion machine learning predictions per day. Another Intuit product, QuickBooks, predicts cash \nflow for small businesses, and the company has found that when it gives users advice based on artificial \nintelligence, 95 percent of small-business owners take that advice.\n  They're still focusing on a strategy that combines human interactions with A.I.-powered ones. Customers, for \nexample, can meet with a live expert, and then A.I. will create a categorized and tagged summary of the \nconversation for later review.\n  Bugs in the system\n  As of now, the technology is promising, but it's not 100 percent accurate.\n  ''These systems tell plausible stories, they give you plausible ideas, but not necessarily correct ones,'' Mr. \nSrivastava said. ''What we're focusing on is actually providing the correct experience to the person, so that it's \ngrounded in reality and data that is appropriately personalized to them, so then they can make the best financial \ndecisions as they move forward.''\n  Mr. Srivastava said he did not envision a future where humans were taken out of the financial planning equation.\n  ''I've grown up in the field, I've seen it evolve, and it's an amazing technology,'' he said. ''I think that the human \nconnection is still important. I envision that we will want to help C.P.A.s, bookkeepers, financial planners, financial \nadvisers -- everyone in this ecosystem -- grow and prosper along with the use of artificial intelligence.''\n  Josh Pigford, the founder and chief executive of Maybe, had been building a personal finance management \nplatform that could help people make financial decisions when ChatGPT debuted. A few months ago, Maybe was \nrebuilt from the ground up, this time with GPT, the technology behind ChatGPT, as the foundation of the platform. \nThe process always begins, he said, with a question people want to answer.\n  ''The way that we were initially tackling this is giving you access to a financial adviser who can answer those \nquestions for you directly,'' Mr. Pigford said. ''As we started testing GPT's ability around that, we realized, well, OK, \nactually GPT can do this really well.''\n  Things became even more interesting when people added their financial data and information, such as age, \nlocation, and goals. The system could then take into account everything from dependents to joint filing to local tax \ncodes -- details a financial adviser would be able to use -- and deliver that directly to the consumer.\nWould You Take A.I.'s Money Advice?\n  That, of course, brings up the subject of privacy. Through Maybe's system, the banking information is secured and \ndoes not feed back to OpenAI, the company that created ChatGPT.\n  Hallucinations -- the tendency for ChatGPT to spout off incorrect information -- have also become a worry. Mr. \nPigford and his team identified the issue during early testing.\n  ''There was a point there where it was actually making up entire transactions, and building this back story of like, \n'You bought this item from Home Depot to help cool off your living room,''' he said. ''That's a legitimate problem.''\n  As the technology has improved, Mr. Pigford has seen a drastic decrease in these hallucinations in just weeks. \nThe way they're designing the software includes a toggle to switch between a chatbot and humans for advice.\n  ''The belief, the hypothesis, what we're sort of banking on is that we're able to actually offer that sort of hyper-\npersonalized input and advice without you having to, you know, form a relationship with a certified financial adviser \nwhere you're paying them an assets-under-management fee, or even paying them, you know, a couple hundred \nbucks an hour,'' he said. ''You're able to get very specific advice, regardless of what your financial situation is.''\n  But Mr. Pigford believes it's too early to do away with live professionals. ''I think we'll have some transition period \nwhere we'll want humans involved for a while,'' he said. ''The goal is not to completely do away with a financial \nadviser.''\n  First steps into the ChatGPT world\n  Glenn Hopper, author of ''Deep Finance: Corporate Finance in the Information Age,'' relates this GPT era to the \nscreech of dial-up internet. The prevalence of A.I., he said, is ''going to come quicker than the adoption of the \ninternet and broadband internet and web browsers.''\n  ''I've stopped making predictions, because every time I make a prediction, I'll say six to 12 months, and then I'll \nread an article the next day that this item has already appeared,'' Mr. Hopper said.\n  He warned that tools like ChatGPT would make scamming and phishing more sophisticated, so users should be \ncautious of anyone asking for their bank information.\n  ''The very first thing that I tell everyone is, if you've been ignoring artificial intelligence up until now -- stop,'' he \nsaid. He doesn't think people need to become experts, but they should have a basic understanding of how the \ntechnology works, he said.\n  ''If we're going to hand over our decisions to them, and we don't have any idea how they're working, I mean, you \nmight as well shake one of those Magic 8 Balls and get the answer from that,'' he said.\nhttps://www.nytimes.com/2023/05/20/business/ai-financial-advice-chatgpt.html\nGraphic\n \nThis article appeared in print on page B1, B5.               \nLoad-Date: May 20, 2023"
    },
    {
        "file_name": "Responsive_CEO_Oct2023",
        "header": "Companies that use SRM have a higher chance of winning tender:",
        "media": "Responsive CEO",
        "time": "October 28, 2023",
        "section": "TECH & INTERNET",
        "length": "376 words",
        "byline": " ",
        "story_text": "Companies that use SRM have a higher chance of winning tender: \nResponsive CEO\nThe Economic Times\nOctober 29, 2023 Sunday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 376 words\nBody\nCompanies who utilize strategic response management (SRM) have a better chance of winning an RFP (Request \nfor Proposal) or tender, Ganesh Shankar, CEO and Co-Founder of US and Coimbatore-based SRM platform \nprovider Responsive (formerly RFPIO) told ET while talking about the significance of AI in such capabilities. \"The \ncompanies who utilize SRM, their chance of winning an RFP or tender is 16% higher,\" Shankar said. \"Moreover, \nusing the SRM platform for many different teams within an organization improves revenue by 80%.\"He mentioned \nthat an article by the analyst firm, Aragon Research pegs the current market for SRM at $3.3 billion and predicts \ngrowth to $27 billion by 2028.Shankar said the capabilities of AI should be explored in SRM and that AI was \nbecoming more prominent in their own operations. \nResponsive delivers responses using technologies such as AI to manage RFPs (Request for proposal), RFIs \n(Request for information), vendor security questionnaires (VSQs), due diligence questionnaires (DDQs), risk \nassessments, business presentations, and all other complex information requests (RFXs).Responsive claims to be \nthe first in the SRM category to offer AI capabilities for more than 400,000 users. Headquartered in the American \ncity of Beaverton, the company boasts 25 of the Fortune 100 companies as clients including Facebook, Google, \nand Amazon. Freshworks, Infosys, and TCS are among some of their Indian clients.Responsive Summit23, a virtual \nconference on strategic response management was conducted on October 19, which unveiled new tools and \nautomation capabilities to its SRM platform.The new features included an Enhanced AI Assistant, a generative AI \nsolution for creating and summarizing response content also sourcing information from customers’ Content \nLibraries. And a ‘Deeper Content Management Automation’, which automates the prevention and removal of \nredundant, obsolete, and trivial (ROT) content. “We are particularly excited about the rapid adoption of capabilities \nlike our AI Assistant, and we look forward to the progress customers will make with today’s enhancements to our AI, \nautomation, and privacy offerings,\" AJ Sunder, CPO, and CIO at Responsive, said in a statement.  For Reprint \nRights: timescontent.com\nLoad-Date: October 28, 2023"
    },
    {
        "file_name": "responses;_In_testing,_major_AI_products_gave_wrong_information_that_could_Mar2024",
        "header": "BUSINESS; The election threat from chatbots' inaccurate, misleading",
        "media": "responses; In testing, major AI products gave wrong information that could",
        "time": "March 1, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1204 words",
        "byline": "Burke writes for the Associated Press.",
        "story_text": "BUSINESS; The election threat from chatbots' inaccurate, misleading \nresponses; In testing, major AI products gave wrong information that could \ndisenfranchise voters, a report says.\nLos Angeles Times\nMarch 1, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1204 words\nByline: Burke writes for the Associated Press.\nDateline:  NEW YORK  \nBody\nWith presidential primaries underway across the U.S., popular chatbots are generating false and misleading \ninformation that threatens to disenfranchise voters, according to a report published Tuesday based on the findings \nof artificial intelligence experts and a bipartisan group of election officials.\nFifteen states and one territory will hold both Democratic and Republican presidential nominating contests next \nweek on Super Tuesday, and millions of people already are turning to artificial intelligence-powered chatbots for \nbasic information, including about how their voting process works.\nTrained on troves of text pulled from the internet, chatbots such as GPT-4 and Google's Gemini are ready with AI-\ngenerated answers, but they're prone to suggesting voters head to polling places that don't exist or inventing \nillogical responses based on rehashed, dated information, the report found.\n\"The chatbots are not ready for prime time when it comes to giving important, nuanced information about elections,\" \nsaid Seth Bluestein, a Republican city commissioner in Philadelphia, who along with other election officials and AI \nresearchers took the chatbots for a test drive as part of a broader research project in January.\nAn Associated Press journalist observed as the group that convened at Columbia University tested how five large \nlanguage models responded to a set of prompts about the election -- such as where a voter could find the nearest \npolling place -- then rated the responses they kicked out.\nAll five models tested -- OpenAI's ChatGPT-4, Meta's Llama 2, Google's Gemini, Anthropic's Claude, and Mixtral \nfrom the French company Mistral -- failed to varying degrees when asked to respond to basic questions about the \ndemocratic process, according to the report, which synthesized the workshop's findings.\nWorkshop participants rated more than half of the chatbots' responses as inaccurate and categorized 40% of the \nresponses as harmful, including perpetuating dated and inaccurate information that could limit voting rights, the \nreport said.\nFor example, when participants asked the chatbots where to vote in the ZIP Code 19121, a majority Black \nneighborhood in northwest Philadelphia, Google's Gemini replied that wasn't going to happen.\n\"There is no voting precinct in the United States with the code 19121,\" Gemini responded.\nBUSINESS The election threat from chatbots' inaccurate, misleading responses In testing, major AI products \ngave wrong information that could disenfranchise vote....\nTesters used a custom-built software tool to query the five popular chatbots by accessing their back-end application \nprogramming interfaces, or APIs, and to prompt them simultaneously with the same questions to measure their \nanswers against one another.\nAlthough that's not an exact representation of how people query chatbots using their own phones or computers, \nquerying chatbots' APIs is one way to evaluate the kind of answers they generate in the real world.\nResearchers have developed similar approaches to benchmark how well chatbots can produce credible information \nin other applications that touch society, including in healthcare, where researchers at Stanford University recently \nfound that large language models couldn't reliably cite factual references to support the answers they generated to \nmedical questions.\nOpenAI, which in January outlined a plan to prevent its tools from being used to spread election misinformation, \nsaid the company would \"keep evolving our approach as we learn more about how our tools are used,\" but offered \nno specifics.\nAnthropic plans to roll out a new intervention in the coming weeks to provide accurate voting information because \n\"our model is not trained frequently enough to provide real-time information about specific elections and ... large \nlanguage models can sometimes 'hallucinate' incorrect information,\" said Alex Sanderford, Anthropic's head of trust \nand safety.\nMeta spokesman Daniel Roberts called the findings \"meaningless\" because they don't exactly mirror the experience \na person typically would have with a chatbot. Developers building tools that integrate Meta's large language model \ninto their technology using the API should read a guide that describes how to use the data responsibly, he added, \nbut was not sure whether that guide made specific mention of how to deal with election-related content.\n\"We're continuing to improve the accuracy of the API service, and we and others in the industry have disclosed that \nthese models may sometimes be inaccurate. We're regularly shipping technical improvements and developer \ncontrols to address these issues,\" Google's head of product for responsible AI, Tulsee Doshi, said in response.\nMistral did not immediately respond to requests for comment.\nIn some responses, the bots appeared to pull from outdated or inaccurate sources, highlighting problems with the \nelectoral system that election officials have spent years trying to combat and raising fresh concerns about \ngenerative AI's capacity to amplify long-standing threats to democracy.\nIn Nevada, where same-day voter registration has been allowed since 2019, four of the five chatbots tested wrongly \nasserted that voters would be blocked from registering to vote weeks before election day.\n\"It scared me, more than anything, because the information provided was wrong,\" said Nevada Secretary of State \nFrancisco Aguilar, a Democrat who participated in the January testing workshop.\nThe research and report are the product of the AI Democracy Projects, a collaboration between Proof News, a new \nnonprofit news outlet led by investigative journalist Julia Angwin, and the Science, Technology and Social Values \nLab at the Institute for Advanced Study in Princeton, N.J.\nAttempts at AI-generated election interferenc e have already begun, such as when AI robocalls that mimicked \nPresident Biden's voice tried to discourage people from voting in New Hampshire's primary election in January.\nPoliticians also have experimented with the technology, such as using AI chatbots to communicate with voters and \nadding AI-generated images to ads.\nBut in the U.S., Congress has yet to pass laws regulating AI in politics, leaving the tech companies behind the \nchatbots to govern themselves.\nBUSINESS The election threat from chatbots' inaccurate, misleading responses In testing, major AI products \ngave wrong information that could disenfranchise vote....\nTwo weeks ago, major technology companies signed a largely symbolic pact to voluntarily adopt \"reasonable \nprecautions\" to prevent artificial intelligence tools from being used to generate increasingly realistic AI-generated \nimages, audio and video, including material that provides \"false information to voters about when, where, and how \nthey can lawfully vote.\"\nThe report's findings raise questions about how the chatbots' makers are complying with their own pledges to \npromote information integrity this presidential election year.\nOverall, the report found Gemini, Llama 2 and Mixtral had the highest rates of wrong answers, with the Google \nchatbot getting nearly two-thirds of all answers wrong.\nOne example: When asked whether people could vote via text message in California, the Mixtral and Llama 2 \nmodels went off the rails.\n\"In California, you can vote via SMS (text messaging) using a service called Vote by Text,\" Meta's Llama 2 \nresponded. \"This service allows you to cast your vote using a secure and easy-to-use system that is accessible \nfrom any mobile device.\"\nTo be clear, voting via text is not allowed, and the Vote by Text service does not exist.\nGraphic\n \nPHOTO: ELECTION officials and AI experts tally how various AI models answered possible questions from voters.  \nPHOTOGRAPHER:Lauren Feeney Proof News \nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Chip Above the Rest",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 5, 2023",
        "section": "DEEP DIVE",
        "length": "1370 words",
        "byline": "Shelley Singh",
        "story_text": "Chip Above the Rest\nEconomic Times (E-Paper Edition)\nNovember 5, 2023 Sunday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: DEEP DIVE\nLength: 1370 words\nByline: Shelley Singh\nHighlight: Tech giants such as Microsoft, Google and OpenAI join the race to make chips for AI, but can they catch \nup with Nvidia?\nBody\nET Prime\nEver since AI became the buzzword, there has been a scramble to use it in a slew of applications — to generate \ntext, images and videos; for weather forecasting, financial planning and healthcare; and in autonomous cars and \ndating apps. Some of these applications need graphics processing units (GPUs), and one company dominates this \nfield — Nvidia. Earlier, the microprocessor or the central processing unit (CPU) was the main element for \ncomputing, and Intel was the undisputed leader in this category, while Nvidia’s chips helped enable graphics and \ngaming. Mainstream chip makers such as Intel, AMD, STMicroelectronics, Qualcomm, Nvidia, Texas Instruments \nand others made CPUs and mobile chips. While Nvidia initially played a secondary role in computers, the tables \nturned when AI became a disruptive force. \nNow, every tech giant, including Microsoft, Facebook, Amazon, and Google, wants to make GPUs. There are a \nnumber of reasons for this: * To reduce dependence on Nvidia * To lower costs — Nvidia’s chips cost $15,000-\n45,000 * To control user experience * Companies want to scale up their B2B and B2C offerings in AI and don’t want \nto depend on a single provider for chips * To build AI chips for specific applications rather than use a \ngeneralpurpose GPU * Demand for GPUs is going up, but Nvidia is the only key supplier * Companies want a slice \nof AI, which is expected to be a $2.57 trillion market by 2032, up from $450 billion in 2022, according to \nprecedenceresearch.com. The market includes hardware, software and services along with several sub-\ntechnologies such as natural language processing (NLP) and context-aware computing. With the advent of AI, \neveryone wants to build chips that will help differentiate each provider’s generative AI. Google, Amazon, Apple and  \nMicrosoft want to improve smart speakers, routers and home-security devices, which could benefit from chips that \ncan analyse videos and voice commands better and faster. If everyone uses the same hardware and software, \nthere won’t be a differentiator. Sudipta Ghosh, partner and leader– data analytics, PwC India, says, “Off-the-shelf \nGPUs are general purpose, to handle tasks like large language models (LLM, a type of generative AI trained on \ntext, like the one used by ChatGPT or Google Bard). But tech companies want to customise applications rather than \nuse a one-sizefits-all solution. They want to build a better chatbot or a better search engine with their own hardware \nand software.” This brings up the trilliondollar question: Can Microsoft, OpenAI, Google and Amazon catch up with \nNvidia? Can they at least reduce their dependence on the Nvidia ecosystem — its hardware works with its own \nsoftware—something that tech giants abhor? Nvidia, which has a head start of over a decade, enjoys almost a \nmonopoly in producing GPUs, the key  processors for AI applications. The emerging era of AI has prompted global \ntech giants to design their own chips. What are their initial moves? Will it take a long time for them to get anywhere \nclose to Nvidia? As things stand, all AI applications may not need GPU’s horsepower. At present ChatGPT is \nchurning through systems of several trillion  records to get one answer. “All models won’t be that processing hungry \nChip Above the Rest\nand will need niche capability,” says Prashant Garg, technology partner at consultancy EY. Those capabilities \ninclude tasks such as running autonomous cars, compiling minutes of MS Teams meetings, or working as a smart \nassistant to help consultants and researchers extract data or knowledge. That opens the market for different kinds \nof AI-enabled tasks for which companies want to make their own chips. GIANTS’ FIRST STEPS Microsoft is \nexpected to release its AI chip, code-named Athena, in November. It is working with chip maker AMD to produce it. \nMicrosoft is planning to add AI features to Paint, Photos, its collaboration platform Teams and other products. For \nexample, in the Photos app, Microsoft may add AI functionality that allows users to identify objects and people. \nOpenAI, one of the big customers of Nvidia, is looking to buy out a chipdesign firm as part of its long-term plan to \ndesign chips in-house.  OpenAI CEO Sam Altman has in the past raised concerns about the restricted availability \nand expensive costs of the hardware required to power OpenAI’s software. OpenAI has been developing its \ngenerative AI capabilities on Microsoft-built supercomputers that employ thousands of Nvidia GPUs. Google and \nAmazon have developed their own chips. The former has focused on tensor processing units (TPUs) and the latter \non Trainium and Inferentia chips. The Amazon chips are for machine learning (ML), to train models for inference \nprediction or events that happened in the past. Amazon is using these to improve shopping experience and run \nadvanced ML algorithms. The company claims its in-house chips are 40% cheaper and perform better than third-\nparty hardware. While Google’s TPUs are optimised for use in neural networks (a method in AI that teaches \ncomputers to process data in a way that is inspired by the human brain), they aren’t good for word processing or \nexecuting bank transactions, which generalpurpose chips can do. But they can handle massive data operations \nused in neural networks. Enterprises can use Google TPUs for around $3,000 per month (in the US), with the \namount going up to $100,000 a month for powerful TPUs. According to reports, Google is also planning to launch \nchips for its Chromebooks, enabling the search giant to control both the hardware and the software. Some Chinese \ncompanies are also building their own AI hardware to control user experience. Internet search giant Baidu has \ndesigned chips named Kunlun, which can be used for autonomous driving and natural language processing. Baidu \nclaims its chips are three times faster than conventional GPUs available in the market. Another Chinese company, \nTencent, which operates WeChat, among other services, is designing chips that can process large amounts of data, \nwith a focus on AI and processing images and video. ENTRY BARRIERS While companies are building custom \nchips, the barriers to entry are  significant and it won’t be easy to dent Nvidia’s market. Nicholas Brathwaite, \nfounding managing partner of VC firm Celesta Capital, says, “It will take four to five years to catch up with the \nleader. Besides, Nvidia has not stopped innovating.” Celesta has 15 investments in India, including Agnikul and \nIdeaForge, and its global portfolio includes semiconductor companies as well. Bank of America said, in its recent \nreport, that rivals could take almost a decade to catch up with Nvidia. In 2022, Nvidia spent $7.3 billion on R&D \n(27% of its sales). Microsoft spent $26.6 billion or 13% of its revenue, and Google owner Alphabet $39 billion or \n14% of its revenue on R&D, according to stockanalysis.com. Last month, Nvidia, whose market cap recently topped \n$1 trillion, partnered with Foxconn to set up “AI factories”. It is a new kind of data centre that uses Nvidia chips to \npower a “wide range” of applications such as training autonomous vehicles, robotics platforms and large language \nmodels. While Microsoft, Google and Amazon have the deep pockets to take on Nvidia, there are challenges, \nincluding long design and development lifecycles of AI chips, complex supply-chain issues, talent scarcity and \ngetting the chip right. According to consultancy Gartner, designing a 5nm (nanometre) or 7nm chip can cost $300-\n350 million, and tweaks or new versions of the same chip can cost an additional $50-100 million. It will cost around \n$1.5 billion to design a single 3nm chip with a complex GPU. Companies have to be sure that there will be buyers \nto justify the huge investment and to get the return on investment. The companies entering the chipmaking \nbusiness are betting on the future of computing, which is more specialised. They will bank on thirdparty players \nsuch as TSMC, Samsung and Intel to manufacture them. The market is big enough, and analysts say demand for \nAI chips will only go up — it was valued at $14.9 billion in 2022 and will be $383.7 billion by 2032. The market is just \ntoo big for big tech to ignore.  shelley.singh1@timesinternet.in\nLoad-Date: November 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Hollywood Actors to Start Voting Tuesday on Contract Deal",
        "media": "The New York Times",
        "time": "November 11, 2023",
        "section": "BUSINESS; media",
        "length": "964 words",
        "byline": "Brooks Barnes and Nicole Sperling",
        "story_text": "Hollywood Actors to Start Voting Tuesday on Contract Deal\nThe New York Times \nNovember 10, 2023 Friday 01:55 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 964 words\nByline: Brooks Barnes and Nicole Sperling\nHighlight: The SAG-AFTRA board voted on Friday to send the agreement with studios to its members for a \nratification process that will end in early December.\nBody\nThe SAG-AFTRA board voted on Friday to send the agreement with studios to its members for a ratification \nprocess that will end in early December.\nThe union that represents movie and television actors said on Friday that its 76-member national board had voted \nwith 86 percent support to send a tentative contract with studios to members for ratification.\nThe ratification process will start on Tuesday and end the first week in December. Actors can go back to work \nimmediately, however.\nMembers are expected to approve the contract, which Fran Drescher, the union’s outspoken president, valued at \nmore than $1 billion over three years. She highlighted the “extraordinary scope” of the agreement, noting that it \nincluded protections around the use of artificial intelligence, higher minimum pay, better health care funding, \nconcessions from studios on self-taped auditions, improved hair and makeup services on sets, and a requirement \nfor intimacy coordinators for sex scenes, among other gains.\n“They had to yield,” Ms. Drescher said at a news conference during a 28-minute monologue that touched on \nVeterans Day, Bela Lugosi’s Dracula costume, her parents, the Roman Empire, studio stubbornness, Buddhism, \nFrederick Douglass and her dog.\nThe union, SAG-AFTRA, which represents tens of thousands of actors, and the Alliance of Motion Picture and \nTelevision Producers, which bargains on behalf of studios, reached the tentative agreement on Wednesday. It \nfollowed a bitter standoff that contributed to a near-complete shutdown of production in the entertainment industry. \nAt 118 days, it was the longest movie and television strike in the union’s 90-year history.\nThe tentative deal was also historic, according to the studio alliance, which said it reflected “the biggest contract-on-\ncontract gains in the history of the union.” In a statement, the alliance said it was “pleased” that SAG-AFTRA’s \nboard had recommended ratification.\n“We are also grateful that the entire industry has enthusiastically returned to work,” the alliance said.\nThe actors’ strike, combined with a writers’ strike that started in May and was resolved in September, devastated \nthe entertainment economy. Hundreds of thousands of crew members were idled, with some losing their homes and \nturning to food banks for groceries. Some small businesses that service studios — costume dry cleaners, prop \nwarehouses, catering companies — may never recover.\nHollywood Actors to Start Voting Tuesday on Contract Deal\nThe dual strikes caused roughly $10 billion in losses nationwide, according to Todd Holmes, an associate professor \nof entertainment media management at California State University, Northridge. While the big studios are based in \nLos Angeles, they also use soundstage complexes in Georgia, New York, New Jersey and New Mexico.\nKevin Klowden, chief global strategist with the Milken Institute, an economic think tank, was more cautious with his \nestimate, putting losses at more than $6 billion. He said it “may take a while” to know the true size.\nOn Friday, the SAG-AFTRA board, which includes Sharon Stone, Sean Astin and Rosie O’Donnell, made public a \nsummary of the tentative contract’s contents. While not receiving everything it asked for, the union achieved \nsignificant gains.\nThe final sticking point involved “synthetic fakes,” or the use of artificial intelligence to create an entirely fabricated \ncharacter by melding together recognizable features from real actors. The union won consent and compensation \nguarantees.\n“You could imagine prompting a generative A.I. system that’s been trained on a bunch of actors’ performances to \ncreate a digital performer, for example, who has Julia Roberts’s smile,” Duncan Crabtree-Ireland, SAG-AFTRA’s \nexecutive director, said in an interview. “Before this agreement, there wasn’t any contractual or legal basis to \nrequire consent or prohibit that. Now there will be.”\nBut this strike was never about stars. A-listers like Jennifer Lawrence and Brad Pitt negotiate their own contracts \n(or, more precisely, their agents do). The tentative contract covers minimums, or what actors who don’t have any \nclout get paid.\nSAG-AFTRA had demanded an 11 percent raise for minimum pay in the first year of a contract. Studios had \ninsisted that they could offer no more than 5 percent, the same as had recently been given (and agreed to) by \nunions for writers and directors. In the end, the union was able to win a 7 percent first-year raise.\n“This is really important because it sends a very clear signal to other unions,” Mr. Crabtree-Ireland said. “I’m not \naware of anyone ever being able to break the pattern before, because it’s always been that the A.M.P.T.P. \nestablishes a number and everyone gets held to it.”\nSAG-AFTRA failed in one regard. It had gone into negotiations demanding a percentage of streaming service \nrevenue. It had proposed a 2 percent share — later dropped to 1 percent, before a pivot to a per-subscriber fee. \nMs. Drescher had made the demand a priority, but companies like Netflix balked, calling it “a bridge too far.”\nInstead, the studio alliance proposed a new residual (a type of royalty) for streaming programs based on \nperformance metrics, which the union, after making some adjustments, agreed to take. It is similar to what the \nWriters Guild of America achieved in its negotiations: Actors in streaming shows that attract at least 20 percent of \nsubscribers will receive a bonus.\nUnlike the Writers Guild, however, SAG-AFTRA also got the studio alliance to agree to a system in which 25 \npercent of the bonus money will go into a fund that will be distributed to actors in less successful streaming shows.\n“I felt like, is this a win or a loss?” Ms. Drescher said. “But we’re getting the money. We opened a new revenue \nstream. What matters is that we got into another pocket.”\nThis article appeared in print on page B3.\nLoad-Date: November 11, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2023",
        "header": "Generative AI could replace 300 million jobs: Goldman Sachs report",
        "media": "The Economic Times",
        "time": "March 29, 2023",
        "section": "TECH & INTERNET",
        "length": "299 words",
        "byline": " ",
        "story_text": "Generative AI could replace 300 million jobs: Goldman Sachs report\nThe Economic Times\nMarch 30, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 299 words\nBody\nGenerative AI has already made a huge impact on how technology is used on a daily basis. Soon, it will disrupt the \nlabour market, according to a Goldman Sachs report, and could replace 300 million jobs globally. The report \npredicts that about two-thirds of jobs in the US and Europe are exposed to AI automation. \nA partial but significant part of the workload (25-50%) of most of these jobs can be replaced by AI, it said. One-\nfourth of the jobs in the US and Europe right now can be substituted by AI, the report added.The report also \npredicted that generative AI would have a positive impact on world Gross Domestic Product (GDP), noting that its \nwidespread adoption could lead to a 7% or $7 trillion increase in global GDP. The report also suggested that AI \ncould raise annual US labour productivity growth by just under 1.5 percentage points, over a period of 10 years, if it \nis adopted on a wide scale. Which jobs will be impacted?According to the Goldman Sachs report, jobs will only \npartially be impacted by AI, and that too, not all of them. For example, jobs such as construction, cleaning and \nmaintenance cannot be replaced completely by AI. The report talks about the percentage of work that can be \nautomated for each industry segment. The percentage of tasks that can be automated and eventually replaced by \nAI in the US was highest for jobs in office administration and support, at 46%. According to the report, 44% of tasks \nin legal jobs in the US can be automated and replaced by AI. Also in the US, a third of the tasks in community and \nsocial services, as well as management, can be automated and hence are replaceable by AI. About 45% of tasks in \njobs related to clerical support in the Euro area can be automated, according to the report. For Reprint Rights: \ntimescontent.com\nLoad-Date: March 29, 2023"
    },
    {
        "file_name": "New_York_Observer_Feb2023",
        "header": "ChatGPT Faces Competition From Four A.I. Startups On Big Tech's Radar",
        "media": "New York Observer",
        "time": "February 28, 2023",
        "section": "",
        "length": "637 words",
        "byline": "Sissi Cao",
        "story_text": "ChatGPT Faces Competition From Four A.I. Startups On Big Tech's Radar\nNew York Observer\nFebruary 24, 2023 Friday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 637 words\nByline: Sissi Cao\nBody\nThe roaring success of ChatGPT has triggered a race among Big Tech companies to either come up with their own \ncompeting artificial intelligence products or buy a stake in promising startups that could become the next OpenAI, \nthe creator of ChatGPT.\nIn the past month, Microsoft, Google and China's Baidu have each presented their responses to ChatGPT. In the \nmeantime, some of these companies have also invested or formed partnerships with lesser-known startups \nspecializing in generative A.I., the technology behind text and image generators like ChatGPT and Dall-E, \nOpenAI's other viral product that can generate digital images based on text prompts.\nThere is a natural attraction between A.I. startups and tech behemoths. Many startups rely on the cloud \ninfrastructure of large tech companies to train their algorithms, while tech giants often see them as potential \ninvestment or acquisition targets to expand their business without having to do the early-stage research \nthemselves.\nHere are four A.I. startups and their flagship products that have caught the attention of Big Tech recently:\nHugging Face / Bloom\nFounded in New York in 2016, Hugging Face offers a platform for A.I. developers to share open-source code and \ntraining models. It also makes an original language model called Bloom, a rival of ChatGPT's GPT-3 model.\nThe company said Feb. 21 it's collaborating with Amazon to build the next generation of Bloom on the Amazon Web \nServices (AWS). As part of the deal, Amazon will also make Hugging Face's products available to AWS customers \nfor building their own applications.\nFinancial details of the product partnership were not disclosed. Amazon said it's not an investor in Hugging Face \nand the collaboration isn't exclusive.\nStability AI / Stable Diffusion\nStability AI makes an open-source image generator called Stable Diffusion, a competitor to OpenAI's Dall-E. Both \nimage bots were released in early 2021. Stability AI also runs its training models on AWS.\nStable Diffusion's capabilities have drawn ire from the photography world. Earlier this month, Stability AI was sued \nby Getty Images over copyright infringement. Getty claimed the startup had copied more than 12 million images \nfrom its database without permission to train its A.I. models.\nStability AI has plans to release a text generator similar to ChatGPT and is working on video-generating models, \nwhich could potentially be useful for companies in the film industry.\nChatGPT Faces Competition From Four A.I. Startups On Big Tech 's Radar\nThe company was founded in late 2020 by Emad Mostaque, a former hedge fund manager in the U.K. It's already \nvalued at $1 billion after raising a $101 million seed round from a slew of venture capital firms in October.\nAI21 Labs / Jurassic\nIsraeli startup AI21 Labs offers a language model called Jurassic, also a rival of GPT-3. In December, AI21 Labs \nmade Jurassic available on Amazon's AWS platform through a partnership. More than 25,000 developers have \nsigned up to use the language model.\nAI21 Labs was founded in 2017 by Yoav Shoham, a former director of Stanford University's A.I. lab. The company \nwas most recently valued at $664 million after raising a $64 million round in July.\nAnthropic / Claude\nAnthropic is the company behind Claude, a ChatGPT-like text-generator released in January. Currently it's only \navailable to a group of test users. The startup recently received a $300 million investment from Google, the \nFinancial Times reported Feb. 3.\nAnthropic was founded in 2021 by former executives of OpenAI, including siblings Daniela and Dario Amodei.\nBefore founding Anthropic, Daniela Amodei was OpenAI's head of safety and Dario oversaw research and led the \ndevelopment of OpenAI's GPT-2 and GPT-3 language models.\nAnthropic's investors include Facebook cofounder Dustin Moskovitz, former Google CEO Eric Schmidt and Sam \nBankman-Fried, the disgraced founder of FTX Group.\nLoad-Date: February 28, 2023"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "AI can flag some tax mistakes but won't do heavy lifting",
        "media": "USA Today",
        "time": "March 26, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "1318 words",
        "byline": "By, Jennifer Jolly, Special to USA TODAY",
        "story_text": "AI can flag some tax mistakes but won't do heavy lifting\nUSA Today\nMarch 26, 2024 Tuesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 1318 words\nByline: By, Jennifer Jolly, Special to USA TODAY\nBody\nAs the clock ticks toward the tax filing deadline, some people might be desperate enough to turn to a bevy of new \nAI chatbots to do it all for them.\nOne word of advice: Don't.\nThere's a reason we warn kids not to use ChatGPT to write an essay or finish their history homework. And the bot \nis especially bad at math. Add in the intricate and often ambiguous realm of tax laws that vary by state, and it could \nbe a recipe for disaster   or even worse   an audit.\nThis question of whether it's a good idea to use generative AI for tax help comes at a time when the nation's most \npopular tax preparation companies, Intuit's TurboTax and H&R Block, launched generative AI \"assistants.\"\nSo far, reviews of \"Intuit Assist,\" specifically in Turbo Tax's DIY \"Self-Help\" section, and H&R Block's \"AI Tax \nAssist,\" which is part of their paid packages, underscore why this sort of AI won't replace human expertise any time \nsoon.\nNot that they're meant to, Turbo Tax spokeswoman Karen Nolan said on a Zoom call. And it's important taxpayers \nunderstand that.\nHow can generative AI\nhelp with my taxes?\nIntuit Director of Design Jim Fell and Nolan walked me through some of the most common ways people can   and \ncannot   use the new tool.\n\"Our AI is a digital front door to simple help flagging missing information or inconsistencies while also providing \naccess to expert help from a human being,\" Nolan explained as Fell showed me specific use-cases on screen.\nThe main ways the AI chatbot pops up right now are to flag an accuracy check, such as missed information or \npotential \"clumsy-thumb\" typos. It also offers deeper, more detailed explanations of finished returns and can quickly \ntranslate between languages for filers who might be overwhelmed trying to figure everything out in English.\nThat last part is the most impressive bit of AI magic that's easy to see firsthand. The rest of the machine learning \ntools run mainly in the background and have for years. Nolan says it has been checking for tax return accuracy, \ncutting down on repetitive tasks, and helping find obscure deductions for nearly a decade.\nAI can flag some tax mistakes but won't do heavy lifting\nDoes H&R Block have\na new AI tax tool?\nH&R Block's new \"AI Tax Assist\" is a more prominent part of its website and similar to what many of us have played \naround with using ChatGPT, Copilot or Gemini.\nLike Turbo Tax's Intuit Assist, it's best to use H&R Block's AI Tax Assist more for a simple query or as a fail-safe for \ncommon mistakes. For instance, it does well defining tax terms and explaining something you might not understand \n(such as the simplest, most easy-to-understand terms in the filing process).\nIs AI just bad at math?\nRemember when I said that AI doesn't do \"facts\" very well? It's abundantly clear that you can't ask ChatGPT or any \nother AI conversation bot a critical or confusing tax question and trust its answers.\nThat's largely because different AI assistants are trained on different types of information, kind of like if you raised a \nchild without ever teaching her what colors are called, then asked her what color an apple is. She might try to come \nup with an answer, but without being taught, a guess is as good as you're going to get.\nIn the case of Intuit Assist, the company says the bot was trained on current tax code as well as the company's own \nvast data trove based on its tax prep experience. That information, combined with whatever it learns from your own \ntax documents along the way, forms its knowledge base and dictates the answers you receive when asking it a \nquestion.\nH&R Block's AI Tax Assist works in a similar way, and the company says it used its own archive of tax laws, with a \nfew tweaks here and there from their own accountants, tax law experts and the like.\nNeither of these bots is trained from information scraped from the internet, which is reassuring, but that doesn't \nprevent them from falling victim to AI accuracy issues. All versions of consumer AI currently have a \"hallucination\" \nproblem. They often spit out information that sounds \"right\" but is out of date, inaccurate or just plain made up.\nHere's how not to use\nAI to do your taxes\nIn some early reviews of Intuit Assist and AI Tax Assist, a fellow technology columnist asked the tax chatbots a slew \nof much more specific and nuanced hypothetical questions, and it didn't go well.\nBoth company's bots responded with vague, misleading or just wrong answers, specifically when his questions \nwere around cryptocurrencies, multistate returns and other uncommon filing situations.\nFor example, when asked a question about where a college student should file taxes when they go to school out of \nstate, the journalist reported that TurboTax's bot provided \"irrelevant advice\" and H&R Block's AI assistant \nerroneously suggested the student would have to file in both states. The truth is, the person would have to file only \nin a state where they earned income, but neither AI helper nailed the answer.\nThese situations reveal the limitations of artificial intelligence, but those specific shortcomings aren't necessarily \napplicable across the board, spokespeople from both companies say.\n\"If Turbo Tax is powering the AI, you can trust it,\" Nolan said. \"We don't expect our customers to try to manipulate it \nthe way (that journalist did). That wouldn't really happen if you're doing your taxes.\"\nWhen I asked Nolan about the trouble people might have turning to an AI chatbot in the Self Help section \nspecifically, she explained, \"If you have questions like that, a DIY product is probably not what you need.\"\nAI can flag some tax mistakes but won't do heavy lifting\nNolan also reiterated that in the hypothetical instance it gives you bad advice, the company's system would flag that \nbefore it allowed you to finish and file. \"AI won't file your taxes for you, even if you're using our mobile app and not \nspeaking with a human. AI is not filing your actual return. We will absolutely capture inaccuracies before anything \ngets to the IRS,\" Nolan said.\nBe sure to read the fine print\nTurbo Tax identifies its AI chatbot as a Beta version product, which mean it's still working out the kinks. It has \nseveral disclaimers in the fine print that warn people advice might not be spot-on. Same with H&R Block.\nTo TurboTax's credit, the Intuit Assist bot did help me along the way, even if the standard checks and issue alerts \nwould have accomplished the same thing, albeit a bit later in the process. But the most important thing about these \nAI tax bots is that they're designed to get better over time. Fast-forward a few years, and both tax assistants will \nprobably be miles better than they are today, and they learn as they go.\nWill we use AI to do\nour taxes in the future?\nFuture versions of these tax-minded assistants will be smarter and more robust than the versions we have today. \nThat's the promise of generative AI, and we'll all grow to expect it as artificial intelligence gradually takes over more \nof our daily tasks.\nYou know those prescription drug commercials on TV? It's kind of like that right now. Here's this amazing new tool \nthat can save you time, give you \"more confidence\" and maybe even save you money. But the list of potential \nproblems using it without guardrails on something as crucial as your taxes comes with a list of potential \"side \neffects\" so long it makes you laugh out loud.\nFortunately, humans at TurboTax and H&R Block are still running the show, and they both guarantee the accuracy \nof your tax return, regardless of whether you use the available AI features. If you get audited, they'll give you advice \nand guide you along the way, but additional safeguards like TurboTax's Audit Defense or H&R Block's Peace of \nMind Extended Service Plan, where the companies actually deal with the IRS on your behalf, still cost extra.\nJennifer Jolly is an Emmy Award-winning consumer tech columnist and on-air correspondent. The views and \nopinions expressed in this column are the author's and do not necessarily reflect those of USA TODAY. Contact her \nat JJ@Techish.com .\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "Edtech’s AI Push has its Share of Doubting Thomases",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "516 words",
        "byline": "Jessica.Rajan@timesgroup.com",
        "story_text": "Edtech’s AI Push has its Share of Doubting Thomases\nEconomic Times (E-Paper Edition)\nFebruary 21, 2024 Wednesday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 516 words\nByline: Jessica.Rajan@timesgroup.com\nHighlight: Higher education, upskilling platforms likely to benefit more than startups offering services to schools \nand students on a large scale\nBody\nNew Delhi: As edtech platforms move towards deploying artificial intelligence tools to enhance offerings, a clear \ndivide has emerged within various segments of the industry. While higher education and upskilling startups are \nanticipating greater benefits from the technology, those servicing schools and students on a large scale may run \ninto some headwinds, founders and executives at edtech companies told ET. Mumbai-based skilling and workforce \ndevelopment startup upGrad is looking to utilise AI to translate its popular bootcamps and certificate programmes \ninto vernacular languages to improve its product offerings and expand reach. \nIn the initial stage,  translations will be available in Hindi, Tamil, Telugu, Kannada and Bengali to serve the Indian \nmarket. Subsequently, the company plans to extend this to foreign languages such as Spanish and Chinese. Noida-\nbased edtech unicorn PhysicsWallah is also set to officially launch its generative AI tool, Alakh  AI, later this month. \nNamed after one of its cofounders, Alakh Pandey, it will serve as a personalised tutor for students, helping them \nwith queries, providing summaries, and acting as a“study companion”. “Most of the jobs are in tier-I markets, but \nroughly about 40-45% of our learners come from tier-II and  tier-III towns and cities. While they all want to give \ninterviews in English, for the learning purpose they do need a vernacular approach,” said upGrad cofounder and \nmanaging director Mayank Kumar.  upGrad offers online and hybrid degree courses, pathway and studyabroad \nprogrammes as well as certification and bootcamps, diploma, master’s and executive doctorate programmes for \nworking professionals. The firm said it records high demand from places like Bengaluru, New Delhi, Mumbai, \nHyderabad, Odisha, Pune, Chennai and Kolkata. According to Kumar, AI is a significant investment, not only for \nteaching and learning but also for pedagogy, sales and driving conversions. \"We will also leverage AI in various \nother initiatives at Upgrad…We are  also trying to bring AI into our approach for mock interviews,\" he added. \nAround 80% of Upgrad's business is from India. Kumar said the platform plans to target international markets such \nas the US, Europe and the Middle East from a business-tobusiness standpoint. Prateek Maheshwari, cofounder of \nPhysicsWallah, said: “With over 2 million daily active users, the method of having teachers or subject matter experts \nto directly address students' doubts and issues is not feasible. This approach is both high-cost and operationally \nintensive. To overcome this challenge, we have implemented GenAI to develop ‘Alakh AI’\". RESOURCE \nLIMITATIONS For startups in the edtech space  that offer services to schools, while AI presents a large opportunity, \nlack of enough resources at schools is a challenge. \"AI is still in a very early stage and is continuously \nevolving...any integration of technology as such presents a huge challenge. AI will require continuous upgrades and \ninvestments to ensure the tools don't become outdated,\" a senior executive at a unicorn edtech startup said.\nLoad-Date: February 20, 2024\nEdtech’s AI Push has its Share of Doubting Thomases"
    },
    {
        "file_name": "score_Jan2023",
        "header": "Its Vada Pav vs Bhel Puri as Nadella evokes ChatGPT to settle the spicy",
        "media": "score",
        "time": "January 3, 2023",
        "section": "TECH & INTERNET",
        "length": "251 words",
        "byline": " ",
        "story_text": "Its Vada Pav vs Bhel Puri as Nadella evokes ChatGPT to settle the spicy \nscore\nThe Economic Times\nJanuary 4, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 251 words\nBody\nSatya Nadella's Tuesday talk was more than just serious business and technology talk. The India born chief of \nMicrosoft evoked ChatGPT - which is all the rage these days - to answer which is Mumbai's best street food. \nThe popular AI chatbot ChatGPT is also backed by Microsoft. From asking questions about the best street food \noptions in the city, he progressed to quirkier queries which ended with a script for a play describing a battle of words \nbetween Vada Pav, Bhel Puri and Pav Bhaji. It had the audience which comprised some of India's Inc top corporate \nhonchos peeling with laughter. Nadella also quizzed AI image platform DALL-E, also backed by the US major, to \nproduce stunning images of what Mumbai will look like in the future.Nadella used the chatbot based on the GPT-3.5 \nlanguage model, which has been released in beta version by the artificial intelligence research group OpenAI to \nunderscore his point of view that Reasoning engines, or large language model-based artificial intelligence tools \nsuch as OpenAI's Dall-E and ChatGPT, would increasingly play important roles in the future. Microsoft believes that \nGenerative AI tools, such as ChatGPT and Dall-E, generated less than 1% of the world's AI data sets in 2021, this \ncan increase to 10% of all data generated by AI by 2025.\"This is all fun and games, right? But think about what you \njust see is the emergence of a new reasoning engine,\" said Nadella, talking about the endless possibilities of AI. \nFor Reprint Rights: timescontent.com\nLoad-Date: January 3, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Biggest Impact Of A.I. Is Seen In Top Industries",
        "media": "The New York Times",
        "time": "February 2, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "789 words",
        "byline": "By Steve Lohr",
        "story_text": "Biggest Impact Of A.I. Is Seen In Top Industries\nThe New York Times\nFebruary 2, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 789 words\nByline: By Steve Lohr\nBody\nFor some companies, the new technology is an opportunity to enhance productivity and profit. Will their workers \nbenefit as well?\nA new generation of artificial intelligence is poised to turn old assumptions about technology on their head. \n  For years, people working in warehouses or fast food restaurants worried that automation could eliminate their \njobs. But new research suggests that generative A.I. -- the kind used in chatbots like OpenAI's ChatGPT -- will \nhave its biggest impact on white-collar workers with high-paying jobs in industries like banking and tech.\n  A report published Thursday by the Burning Glass Institute, a nonprofit research center, and SHRM, formerly the \nSociety for Human Resource Management, stops short of saying the technology will do away with large numbers of \njobs. But it makes clear that workers need to better prepare for a future in which A.I. could play a significant role in \nmany workplaces that until now have been largely untouched by technological disruption.\n  For people in tech, it means they may be building their A.I. replacements.\n  ''There's no question the workers who will be impacted most are those with college degrees, and those are the \npeople who always thought they were safe,'' said Matt Sigelman, president of the Burning Glass Institute.\n  For hundreds of corporations, the researchers estimated the share of payroll spending that goes to workers \nemployed in the 200 occupations most likely to be affected by generative A.I. Many of those jobs are held by \naffluent college graduates, including business analysts, marketing managers, software developers, database \nadministrators, project managers and lawyers.\n  Companies in finance, including Goldman Sachs, JPMorgan Chase and Morgan Stanley, have some of the \nhighest percentages of their payrolls likely to be disrupted by generative A.I. Not far behind are tech giants like \nGoogle, Microsoft and Meta.\n  Getting A.I. to do human work could result in big savings for those companies. The research estimates that banks \nand some tech companies spend 60 to 80 percent of their payrolls, or more, on workers in occupations most likely \nto be affected by the new technology.\n  The retail, restaurant and transportation industries are least likely to be affected by generative A.I., the report \nfound. Companies like Walmart, McDonald's and Delta Air Lines mostly employ workers without college degrees \nwho perform roles like helping customers, stocking shelves, cooking food and handling baggage. They spend less \nthan 20 percent of their payrolls on employees in occupations most likely to be affected by generative A.I.\nBiggest Impact Of A.I. Is Seen In Top Industries\n  The report doesn't predict potential job losses related to generative A.I. That will be up to employers, the report \nsaid, and whether they want to bank the savings from A.I. automation or use that money to invest and grow, adding \nmore workers. Most experts expect that A.I. will mostly change jobs for the next few years rather than eliminate \nthem -- though that could change if the technology improves sharply.\n  The report highlights the need for increased training to prepare workers to adapt to a fast-arriving technology, said \nJohnny C. Taylor Jr., chief executive of SHRM.\n  ''Corporations and governments are going to have to seriously invest to get ahead of this,'' he said.\n  The report is the latest entry in a growing field of work trying to predict the effect of generative A.I. on the \neconomy and the workplace. Other studies have forecast a surge in economic growth and productivity, automating \nactivities that add up to the equivalent of millions of jobs, and time savings of up to 50 percent for routine office and \ncoding tasks.\n  In its research, the Burning Glass Institute started with the estimates of generative A.I. exposure by occupation in \na widely cited academic paper that was published last year. It then added its own data sets -- including job listings, \npayroll information, government statistics and corporate disclosures -- for the company-by-company calculations. \nThe SHRM report includes a ranking of selected companies. The Burning Glass Institute did the percentage \nestimates of the payroll spending by company for The New York Times.\n  Manav Raj, a co-author of the academic paper that the Burning Glass Institute relied on, said the new research \nappeared to be a credible effort to parse company-level data. But at this stage, he said, all the studies are educated \nguesses.\n  ''The many papers out there generally conclude that this wave of A.I. has the potential to have a very large effect,'' \nsaid Mr. Raj, an assistant professor of management at the Wharton School of the University of Pennsylvania. ''But \nit's going to take some time to find out what that effect really looks like.''\nhttps://www.nytimes.com/2024/02/01/business/ai-impact-jobs.html\nGraphic\n \nThis article appeared in print on page B4.               \nLoad-Date: February 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Intel Receives $8.5 Billion in Grants to Build Chip Plants",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "US; politics",
        "length": "1247 words",
        "byline": "Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House",
        "story_text": "Intel Receives $8.5 Billion in Grants to Build Chip Plants\nThe New York Times \nMarch 20, 2024 Wednesday 12:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 1247 words\nByline: Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House \ncorrespondent, covering President Biden and his administration. Madeleine Ngo covers U.S. economic policy and \nhow it affects people across the country.\nHighlight: The award, announced by President Biden at a plant in Arizona, is the biggest the government has \nmade under a new program that aims to rebuild the nation’s semiconductor manufacturing industry.\nBody\nThe award, announced by President Biden at a plant in Arizona, is the biggest the government has made under a \nnew program that aims to rebuild the nation’s semiconductor manufacturing industry.\nPresident Biden on Wednesday awarded $8.5 billion in grants to Intel, a major investment to bolster the nation’s \nsemiconductor production, during a tour of battleground states meant to sell his economic agenda.\nSpeaking from the Intel campus in Chandler, Ariz., Mr. Biden said the award would support thousands of new \nmanufacturing jobs, including ones that do not require a college degree.\n“It’s going to transform the semiconductor industry,” Mr. Biden said. “Where the hell is it written saying that we’re \nnot going to be the manufacturing capital of the world again?”\nThe award, which will go to the construction and expansion of Intel facilities around the United States, is the biggest \nthe federal government has made with funding from the CHIPS Act, which lawmakers passed in 2022 to help re-\nestablish the United States as a leader in semiconductor manufacturing.\nThe Biden administration, equipped with $39 billion in subsidies to distribute, is spearheading an ambitious effort to \nramp up production of the tiny chips that power everything from smartphones to computers and cars. The effort is at \nthe center of Mr. Biden’s goal to reduce America’s reliance on foreign countries: Although semiconductors were \ninvented in the United States, only about 10 percent of the world’s chips are made domestically.\n“Nearly all manufacturing of leading-edge chips across the entire industry moved overseas to Asia years ago,” Mr. \nBiden said. “That’s why today’s investment is such a big deal: We will enable advanced semiconductor \nmanufacturing to make a comeback here in America.”\nIn addition to the grants, the federal government is planning to award Intel up to $11 billion in loans on what the \ncompany characterized as generous terms. Intel is also expected to claim federal tax credits that could cover 25 \npercent of the expense of its U.S. expansion projects, which are expected to cost more than $100 billion over five \nyears.\nThe grants are intended to help fund the company’s construction plans in Arizona, Ohio, New Mexico and Oregon. \nThe projects are expected to create more than 10,000 manufacturing jobs and roughly 20,000 construction jobs, \naccording to Biden administration officials.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nCommerce Secretary Gina Raimondo, whose department is overseeing the distribution of the grants, said the \naward would help ramp up the country’s production of the most advanced semiconductors, which are used in \nartificial intelligence, smartphones, supercomputers and the most sensitive military hardware. The United States \ncurrently produces none.\nMs. Raimondo said the Intel award would be the single largest grant to a chipmaker under the new program. The \ninvestment will help put the United States on track to produce roughly 20 percent of the world’s leading-edge chips \nby the end of the decade, she said.\n“This investment will enable Intel to produce leading edge, the most sophisticated chips in the world that will power \nour economic and national security,” Ms. Raimondo said at the Intel campus on Wednesday.\nIn Arizona, the money will help fund Intel’s recent construction of two advanced plants and the modernization of \nanother facility. The money will also help establish an entirely new site near Columbus, Ohio, starting with two \nfactories, in its first move to a new U.S. region in more than 40 years.\nIn Rio Rancho, N.M., Intel will use the federal funds to transform two plants into advanced packaging facilities, \nwhere chips are assembled together to enhance performance and reduce costs. The company will also expand and \nmodernize an innovation hub in Hillsboro, Ore., which is expected to further the company’s technological leadership \nand development of new innovations.\nMr. Biden and his Democratic allies view the semiconductor investments as a key way to try to turn around \nperceptions of the economy among voters in battleground states like Arizona.\n“We have not been talking to folks about the issues that President Biden has been delivering on, and that’s what we \nare determined to do,” Yolanda Bejarano, the Arizona Democratic Party chairwoman, said on Tuesday, adding that \nDemocrats would need to talk more about the effects of the semiconductor investments.\nAlthough Intel will have to meet certain milestones before the money is distributed, senior Biden administration \nofficials said they expected the funds to start flowing to the company by the end of this year.\nPatrick Gelsinger, Intel’s chief executive, told reporters in a briefing on Tuesday evening that the government \nincentives represented a proud moment for his company and a major achievement for politicians of both parties. \nThough satisfied with the incentives earmarked for Intel, he said officials might need to invest more in the industry \nto reverse decades of shifting investment from the United States to countries in Asia.\n“It doesn’t get fixed in one three- to five-year program,” Mr. Gelsinger said. “I do think we’ll need at least a CHIPS 2 \nto finish that job.”\nIntel is the fourth company to receive a federal award under the new program, and brings the total announced \ngrants to more than $10 billion. The first three grants — to GlobalFoundries, Microchip Technology and BAE \nSystems — were to makers of legacy chips, which are created with older production processes but are still used in \nmany products like cars and dishwashers.\nBiden administration officials are expected to announce more awards in the coming months to other major \nchipmakers, including the Taiwan Semiconductor Manufacturing Company, Samsung and Micron Technology. \nThose companies have also made major investments in new or expanded semiconductor manufacturing plants in \nthe United States in recent years.\nThe United States’ dependence on Asia for its chips has become even more pronounced with the rise of artificial \nintelligence. Nearly all chips used to power the latest generative A.I. services were manufactured in Taiwan by \nT.S.M.C., though designed by the Silicon Valley company Nvidia.\nIntel has been trying to change that by developing new manufacturing technology, beginning to build chips \ndesigned by other companies and lobbying heavily for the legislation. The investment in Intel is intended to help \nenable U.S. companies to lead in the A.I. industry by ensuring there is a domestic supply of advanced chips.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nAbout $50 million of federal funding will be set aside for Intel to spend on training and developing “a new generation \nof workers for the semiconductor industry,” Mr. Biden said. Many semiconductor companies and industry groups \nhave voiced concerns about potential shortages of technicians, engineers and other workers to fill all of the \npositions that will be created once the facilities are constructed.\nIn total, private companies have announced more than $240 billion in semiconductor and electronic manufacturing \ninvestments since Mr. Biden took office, according to administration officials. Some chipmakers, however, have run \ninto obstacles while trying to expand their domestic manufacturing capacity, resulting in delays.\nPHOTO: An Intel semiconductor factory under construction in 2021 outside Phoenix. The award announced \nWednesday was the biggest so far under a new program that aims to rebuild the industry. (PHOTOGRAPH BY \nPHILIP CHEUNG FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "India?_Apr2024",
        "header": "Does Amazon's cashless Just Walk Out technology rely on 1,000 workers in",
        "media": "India?",
        "time": "April 5, 2024",
        "section": "E-COMMERCE NEWS & INDIA NEWS",
        "length": "732 words",
        "byline": "Betty Lin-Fisher, USA TODAY",
        "story_text": "Does Amazon's cashless Just Walk Out technology rely on 1,000 workers in \nIndia?\nUSA Today Online\nApril 4, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: E-COMMERCE NEWS & INDIA NEWS\nLength: 732 words\nByline: Betty Lin-Fisher, USA TODAY\nBody\nDoes Amazon's touchless technology, which allows customers to grab what they need on shelves and \"Just Walk \nOut\" without going to a cash register, really rely on human workers in India to review the purchases?\nThe Seattle-based retailer, which on Tuesday said it was swapping the Just Walk Out technology at more than half \nof its 40 Amazon Fresh grocery stores for smart carts, won't really say.\nWhile the Just Walk Out technology sends shoppers their receipts after they've left the store, Amazon Dash carts \nshow customers what they will be charged for each item in real time on a screen, while also allowing shoppers to \nbypass a register. Amazon said the change occurring at its Amazon Fresh grocery stores is in response to \ncustomer feedback but it will continue to use the Just Walk Out technology at more than 130 third-party partners, \nwhich include airports, college stores and cafes.\nAt those locations, the company claims sensors, cameras and other tools help track what a shopper has purchased. \nBut several media outlets have reported that there may be more to it, with hundreds of workers in India playing a \nkey role.\nLink to Image\nHow does Just Walk Out know what I'm buying?\nOn its website, AWS, a separate division of Amazon, said customers using Just Walk Out technology can walk into \na store using Amazon One (where customers can register their palm to connect with their payment method), a \ncredit/debit card, or an app, shop for items and leave. Customers are automatically charged for their purchases.\n\"Sensors, cameras and deep learning tools sense what a consumer takes off the shelf,\" the website said.\nAn Amazon spokesperson explained further: \"Just Walk Out technology is made possible by artificial intelligence \nlike computer vision and deep learning techniques, including generative AI, to accurately determine who took what \nin any retail environment. Amazon built synthetic datasets to mimic millions of realistic shopping scenarios – \nincluding variations in store format, lighting conditions, and even crowds of shoppers – to ensure accuracy in any \nenvironment.\"\nHowever, several media outlets have said that workers in India may also be significantly involved.\nLike many artificial intelligence systems, Amazon’s system relies on human moderators and data labelers, who \nreview Just Walk Out transactions and label footage to help train the AI models that make it work, CNBC said. The \nInformation reported last year that the team was made up of more than 1,000 employees, primarily based in India, \nDoes Amazon 's cashless Just Walk Out technology rely on 1,000 workers in India ?\naccording to CNBC. An Amazon spokesperson confirmed at the time that it uses human moderators but declined to \nsay how many people it employs in these roles, according to The Information report.\nBusiness Insider cited more reporting by The Information on Tuesday, that said Just Walk Out is still very reliant on \nhumans, according to an unnamed person The Information said had worked on the technology.\nAbout 700 of every 1,000 Just Walk Out sales had to be reviewed by Amazon's team in India in 2022, according to \nThe Information, as reported by Business Insider. Internally, Amazon wanted just 50 out of every 1,000 sales to get \na manual check, according to the report.\nLink to Image\nWhat is Amazon saying?\nIn a statement on Thursday, an Amazon spokesperson took issue with the media reports.\n“The misconception that Just Walk Out technology relies on human reviewers watching shoppers live from India is \nmisleading and inaccurate,\" an Amazon spokesperson said via an e-mail statement to USA TODAY. \"As with many \nAI systems, the underlying machine learning model is continuously improved by generating synthetic data and \nannotating actual video data. \nSmart technology: Why Amazon is ditching Just Walk Out checkouts at grocery stores\n\"Our associates validate a small portion of shopping visits by reviewing recorded video clips to ensure that our \nsystems are performing at our high bar for accuracy, which is made possible because we continuously improve \nboth our algorithms and use human input to correct them.” \nBetty Lin-Fisher is a consumer reporter for USA TODAY. Reach her at blinfisher@USATODAY.com or follow her on \nX, Facebook, or Instagram @blinfisher. Sign up for our free The Daily Money newsletter, which will include \nconsumer news on Fridays, here.\nThis article originally appeared on USA TODAY: Does Amazon's cashless Just Walk Out technology rely on 1,000 \nworkers in India?\nLoad-Date: April 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "An A.I. Researcher Takes On Election Deepfakes",
        "media": "The New York Times",
        "time": "April 4, 2024",
        "section": "TECHNOLOGY",
        "length": "1234 words",
        "byline": "Cade Metz and Tiffany Hsu Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual",
        "story_text": "An A.I. Researcher Takes On Election Deepfakes\nThe New York Times \nApril 2, 2024 Tuesday 09:47 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1234 words\nByline: Cade Metz and Tiffany Hsu Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual \nreality and other emerging areas of technology. Tiffany Hsu reports on misinformation and disinformation and its \norigins, movement and consequences. She has been a journalist for more than two decades.\nHighlight: Oren Etzioni was once an optimist about artificial intelligence. Now, his nonprofit, TrueMedia.org, is \noffering tools for fighting A.I.-manipulated content.\nBody\nFor nearly 30 years, Oren Etzioni was among the most optimistic of artificial intelligence researchers.\nBut in 2019 Dr. Etzioni, a University of Washington professor and founding chief executive of the Allen Institute for \nA.I., became one of the first researchers to warn that a new breed of A.I. would accelerate the spread of \ndisinformation online. And by the middle of last year, he said, he was distressed that A.I.-generated deepfakes \nwould swing a major election. He founded a nonprofit, TrueMedia.org in January, hoping to fight that threat.\nOn Tuesday, the organization released free tools for identifying digital disinformation, with a plan to put them in the \nhands of journalists, fact checkers and anyone else trying to figure out what is real online.\nThe tools, available from the TrueMedia.org website to anyone approved by the nonprofit, are designed to detect \nfake and doctored images, audio and video. They review links to media files and quickly determine whether they \nshould be trusted.\nDr. Etzioni sees these tools as an improvement over the patchwork defense currently being used to detect \nmisleading or deceptive A.I. content. But in a year when billions of people worldwide are set to vote in elections, he \ncontinues to paint a bleak picture of what lies ahead.\n“I’m terrified,” he said. “There is a very good chance we are going to see a tsunami of misinformation.”\nIn just the first few months of the year, A.I. technologies helped create fake voice calls from President Biden, fake \nTaylor Swift images and audio ads, and an entire fake interview that seemed to show a Ukrainian official claiming \ncredit for a terrorist attack in Moscow. Detecting such disinformation is already difficult — and the tech industry \ncontinues to release increasingly powerful A.I. systems that will generate increasingly convincing deepfakes and \nmake detection even harder.\nMany artificial intelligence researchers warn that the threat is gathering steam. Last month, more than a thousand \npeople — including Dr. Etzioni and several other prominent A.I. researchers — signed an open letter calling for laws \nthat would make the developers and distributors of A.I. audio and visual services liable if their technology was easily \nused to create harmful deepfakes.\nAt an event hosted by Columbia University on Thursday, Hillary Clinton, the former secretary of state, interviewed \nEric Schmidt, the former chief executive of Google, who warned that videos, even fake ones, could “drive voting \nbehavior, human behavior, moods, everything.”\nAn A.I. Researcher Takes On Election Deepfakes\n“I don’t think we’re ready,” Mr. Schmidt said. “This problem is going to get much worse over the next few years. \nMaybe or maybe not by November, but certainly in the next cycle.”\nThe tech industry is well aware of the threat. Even as companies race to advance generative A.I. systems, they are \nscrambling to limit the damage that these technologies can do. Anthropic, Google, Meta and OpenAI have all \nannounced plans to limit or label election-related uses of their artificial intelligence services. In February, 20 tech \ncompanies — including Amazon, Microsoft, TikTok and X — signed a voluntary pledge to prevent deceptive A.I. \ncontent from disrupting voting.\nThat could be a challenge. Companies often release their technologies as “open source” software, meaning anyone \nis free to use and modify them without restriction. Experts say technology used to create deepfakes — the result of \nenormous investment by many of the world’s largest companies — will always outpace technology designed to \ndetect disinformation.\nLast week, during an interview with The New York Times, Dr. Etzioni showed how easy it is to create a deepfake. \nUsing a service from a sister nonprofit, CivAI, which draws on A.I. tools readily available on the internet to \ndemonstrate the dangers of these technologies, he instantly created photos of himself in prison — somewhere he \nhas never been.\n“When you see yourself being faked, it is extra scary,” he said.\nLater, he generated a deepfake of himself in a hospital bed — the kind of image he thinks could swing an election if \nit is applied to Mr. Biden or former President Donald J. Trump just before the election.\nTrueMedia’s tools are designed to detect forgeries like these. More than a dozen start-ups offer similar technology.\nBut Dr. Etzioni, while remarking on the effectiveness of his group’s tool, said no detector was perfect because they \nwere driven by probabilities. Deepfake detection services have been fooled into declaring images of kissing robots \nand giant Neanderthals to be real photographs, raising concerns that such tools could further damage society’s \ntrust in facts and evidence.\nWhen Dr. Etzioni fed TrueMedia’s tools a known deepfake of Mr. Trump sitting on a stoop with a group of young \nBlack men, they labeled it “highly suspicious” — their highest level of confidence. When he uploaded another \nknown deepfake of Mr. Trump with blood on his fingers, they were “uncertain” whether it was real or fake.\n“Even using the best tools, you can’t be sure,” he said.\nThe Federal Communications Commission recently outlawed A.I.-generated robocalls. Some companies, including \nOpenAI and Meta, are now labeling A.I.-generated images with watermarks. And researchers are exploring \nadditional ways of separating the real from the fake.\nThe University of Maryland is developing a cryptographic system based on QR codes to authenticate unaltered live \nrecordings. A study released last month asked dozens of adults to breathe, swallow and think while talking so their \nspeech pause patterns could be compared with the rhythms of cloned audio.\nBut like many other experts, Dr. Etzioni warns that image watermarks are easily removed. And though he has \ndedicated his career to fighting deepfakes, he acknowledges that detection tools will struggle to surpass new \ngenerative A.I. technologies. \nSince he created TrueMedia.org, OpenAI has unveiled two new technologies that promise to make his job even \nharder. One can recreate a person’s voice from a 15-second recording. Another can generate full-motion videos \nthat look like something plucked from a Hollywood movie. OpenAI is not yet sharing these tools with the public, as it \nworks to understand the potential dangers.\n(The Times has sued OpenAI and its partner, Microsoft, on claims of copyright infringement involving artificial \nintelligence systems that generate text.)\nAn A.I. Researcher Takes On Election Deepfakes\nUltimately, Dr. Etzioni said, fighting the problem will require widespread cooperation among government regulators, \nthe companies creating A.I. technologies, and the tech giants that control the web browsers and social media \nnetworks where disinformation is spread. He said, though, that the likelihood of that happening before the fall \nelections was slim.\n“We are trying to give people the best technical assessment of what is in front of them,” he said. “They still need to \ndecide if it is real.”\nPHOTOS: Oren Etzioni, founding chief executive of the Allen Institute for A.I., started a nonprofit, TrueMedia.org, to \ndetect fake and doctored images, audio and video. (PHOTOGRAPH BY KYLE JOHNSON FOR THE NEW YORK \nTIMES); Detecting Manipulated Images: A known A.I. deepfake, right, of Donald J. Trump sitting on a stoop with \nyoung men was labeled “highly suspicious” by TrueMedia’s tool. But another known deepfake of Mr. Trump, left, \nwith blood on his fingers was labeled “uncertain.” (B4) This article appeared in print on page B1, B4.\nLoad-Date: April 4, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "431 words",
        "byline": "By Cade Metz",
        "story_text": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\nThe New York Times\nMarch 5, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 431 words\nByline: By Cade Metz\nBody\nDespite computer shortages, controversies and lawsuits, A.I. continues to improve at a rapid pace.\nThe high-profile A.I. start-up Anthropic released a new version of its Claude chatbot on Monday, saying it \noutperforms other leading chatbots on a range of standard benchmark tests, including systems from Google and \nOpenAI. \n  Dario Amodei, Anthropic's chief executive and co-founder, said the new technology, called Claude 3 Opus, was \nparticularly useful when analyzing scientific data or generating computer code.\n  Anthropic is among a small group of companies at the forefront of generative A.I., technology that instantly \ncreates text, images and sounds. Dr. Amodei and other Anthropic founders helped pioneer the technology while \nworking as researchers at OpenAI, the start-up that launched the generative A.I. boom in late 2022 with the \nrelease of the chatbot ChatGPT.\n  Chatbots like ChatGPT can answer questions, write term papers, generate small computer programs and more. \nThey may also generate false or misleading information, much as people do.\n  When OpenAI released a new version of its technology called GPT-4 last spring, it was widely considered the \nmost powerful chatbot technology used by both consumers and businesses. Google recently introduced a \ncomparable technology, Gemini.\n  But the leading artificial intelligence companies have been distracted by one controversy after another. They say \nthe computer chips needed to build A.I. are in short supply. And they face countless lawsuits over the way they \ngather digital data, another ingredient essential to the creation of A.I. (The New York Times has sued Microsoft and \nOpenAI over use of copyrighted work.)\n  Still, the technology continues to improve at a remarkable pace.\n  Anthropic claims that its Claude 3 Opus technology outperforms both GPT-4 and Gemini in mathematical problem \nsolving, computer coding, general knowledge and other areas.\n  Claude 3 Opus was available starting Monday to consumers who pay $20 per month for a subscription. A less \npowerful version, called Claude 3 Sonnet, is available for free.\n  The company allows businesses to build their own chatbots and other services using the Opus and Sonnet \ntechnologies.\nA.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\n  Both versions of the technology can respond to images as well as text. These can analyze a flowchart, for \ninstance, or solve a math problem that includes diagrams and graphs.\n  But the technology cannot generate images. Google recently suspended Gemini's ability to generate human faces \nafter it produced images showing people of color in German military uniforms from World War II.\nhttps://www.nytimes.com/2024/03/04/technology/anthropic-claude-openai-google.html\nGraphic\n \nPHOTO: Dario Amodei, Anthropic's chief executive. The company released a new version of its Claude chatbot on \nMonday. (PHOTOGRAPH BY MASSIMO BERRUTI FOR THE NEW YORK TIMES) This article appeared in print on \npage B4.               \nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "When A.I. Chatbots Hallucinate",
        "media": "The New York Times",
        "time": "May 9, 2023",
        "section": "BUSINESS",
        "length": "1200 words",
        "byline": "Karen Weise and Cade Metz",
        "story_text": "When A.I. Chatbots Hallucinate\nThe New York Times \nMay 1, 2023 Monday 13:34 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1200 words\nByline: Karen Weise and Cade Metz\nHighlight: Ensuring that chatbots aren’t serving false information to users has become one of the most important \nand tricky tasks in the tech industry.\nBody\nWhen did The New York Times first report on “artificial intelligence”?\nAccording to ChatGPT, it was July 10, 1956, in an article titled “Machines Will Be Capable of Learning, Solving \nProblems, Scientists Predict” about a seminal conference at Dartmouth College. The chatbot added:\nThe 1956 conference was real. The article was not. ChatGPT simply made it up. ChatGPT doesn’t just get things \nwrong at times, it can fabricate information. Names and dates. Medical explanations. The plots of books. Internet \naddresses. Even historical events that never happened.\nWhen ChatGPT was recently asked how James Joyce and Vladimir Lenin first met — an encounter that has never \nbeen confirmed — this is how it responded:\nFabrications and definitive statements on uncertain history like these are common. Figuring out why chatbots make \nthings up and how to solve the problem has become one of the most pressing issues facing researchers as the tech \nindustry races toward the development of new A.I. systems.\nChatbots like ChatGPT are used by hundreds of millions of people for an increasingly wide array of tasks, including \nemail services, online tutors and search engines. And they could change the way people interact with information. \nBut there is no way of ensuring that these systems produce information that is accurate.\nThe technology, called generative A.I., relies on a complex algorithm that analyzes the way humans put words \ntogether on the internet. It does not decide what is true and what is not. That uncertainty has raised concerns about \nthe reliability of this new kind of artificial intelligence and calls into question how useful it can be until the issue is \nsolved or controlled.\nThe tech industry often refers to the inaccuracies as “hallucinations.” But to some researchers, “hallucinations” is \ntoo much of a euphemism. Even researchers within tech companies worry that people will rely too heavily on these \nsystems for medical and legal advice and other information they use to make daily decisions. \n“If you don’t know an answer to a question already, I would not give the question to one of these systems,” said \nSubbarao Kambhampati, a professor and researcher of artificial intelligence at Arizona State University.\nChatGPT wasn’t alone in erring on the first reference to A.I. in The Times. Google’s Bard and Microsoft’s Bing \nchatbots both repeatedly provided inaccurate answers to the same question. Though false, the answers seemed \nplausible as they blurred and conflated people, events and ideas.\nWhen A.I. Chatbots Hallucinate\nGoogle’s Bard said:\nMicrosoft’s Bing cited its findings to a realistic-looking web address on The Times’s website:\nAccording to The Times’s archives, all the chatbots were wrong. They cited articles that did not exist. And while \ncoverage of early research on thinking machines dated to the 1930s, it wasn’t until 1963 that The Times first \npublished an article with the phrase “artificial intelligence.”\n“We released Bard as an experiment and want to be as transparent as possible about well documented limitations,” \nJennifer Rodstrom, a spokeswoman for Google, said. “These are top of mind for us as we continue to fine tune \nBard.”\nLike Google, Microsoft and OpenAI say they are working to reduce hallucinations.\nThe new AI. systems are “built to be persuasive, not truthful,” an internal Microsoft document said. “This means that \noutputs can look very realistic but include statements that aren’t true.”\nThe chatbots are driven by a technology called a large language model, or L.L.M., which learns its skills by \nanalyzing massive amounts of digital text culled from the internet.\nBy pinpointing patterns in that data, an L.L.M. learns to do one thing in particular: guess the next word in a \nsequence of words. It acts like a powerful version of an autocomplete tool. Given the sequence “The New York \nTimes is a ____,” it might guess “newspaper.”\nBecause the internet is filled with untruthful information, the technology learns to repeat the same untruths. And \nsometimes the chatbots make things up. They produce new text, combining billions of patterns in unexpected ways. \nThis means even if they learned solely from text that is accurate, they may still generate something that is not.\nBecause these systems learn from more data than humans could ever analyze, even A.I. experts cannot \nunderstand why they generate a particular sequence of text at a given moment. And if you ask the same question \ntwice, they can generate different text.\nThat compounds the challenges of fact-checking and improving the results.\nBard said in one chat:\nThen Bard said in another chat:\nCompanies like OpenAI, Google and Microsoft have developed ways to improve the accuracy. OpenAI, for \ninstance, tries to refine the technology with feedback from human testers.\nAs people test ChatGPT, they rate the chatbot’s responses, separating useful and truthful answers from those that \nare not. Then, using a technique called reinforcement learning, the system spends weeks analyzing the ratings to \nbetter understand what it is fact versus fiction.\nA newer version of ChatGPT called ChatGPT Plus, which is available for a $20 monthly subscription, consistently \navoided answering the question about the first mention of artificial intelligence in The Times. This could be the \nresult of reinforcement learning or other changes to the system applied by OpenAI.\nMicrosoft built its Bing chatbot on top of OpenAI’s underlying technology, called GPT-4, and has layered on other \nways to improve accuracy. The company uses GPT-4 to compare the chatbot’s responses with the underlying data \nand rate how the model is performing. In other words, Microsoft uses the A.I. to make the A.I. better.\nThe company also tries to improve the chatbot’s responses with help from its traditional internet search engine. \nWhen you type a query into the Bing chatbot, Microsoft runs an internet search on the same subject and then folds \nWhen A.I. Chatbots Hallucinate\nthe results into the query before sending it on to the bot. By editing the query, said Sarah Bird, a leader in \nMicrosoft’s responsible A.I. efforts, the company can push the system to produce better results.\nGoogle uses similar methods to improve the accuracy of its Bard chatbot. It uses human feedback to hone the \nsystem’s behavior, and it “grounds” the system using information from the company’s search engine, said Eli \nCollins, a vice president of research at Google.\nMicrosoft does not check the bot’s responses for accuracy in real time, Ms. Bird said, though it is researching how \nto do that. It checks the accuracy of a small portion of results after the fact and then uses that analysis.\nBut becoming more accurate may also have a downside, according to a recent research paper from OpenAI. If \nchatbots become more reliable, users may become too trusting.\n“Counterintuitively, hallucinations can become more dangerous as models become more truthful, as users build \ntrust in the model when it provides truthful information in areas where they have some familiarity,” the paper said.\nSteve Lohr and Nico Grant contributed reporting. Jack Begg and Susan C. Beachy contributed research.\nSteve Lohr and Nico Grant contributed reporting. Jack Begg and Susan C. Beachy contributed research. \nThis article appeared in print on page B4.\nLoad-Date: May 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Union Board Backs Contract, Which Now Goes to Actors for Vote",
        "media": "The New York Times",
        "time": "November 11, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 3",
        "length": "969 words",
        "byline": "By Brooks Barnes and Nicole Sperling",
        "story_text": "Union Board Backs Contract, Which Now Goes to Actors for Vote\nThe New York Times\nNovember 11, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 3\nLength: 969 words\nByline: By Brooks Barnes and Nicole Sperling\nBody\nThe SAG-AFTRA board voted on Friday to send the agreement with studios to its members for a ratification \nprocess that will end in early December.\nThe union that represents movie and television actors said on Friday that its 76-member national board had voted \nwith 86 percent support to send a tentative contract with studios to members for ratification. \n  The ratification process will start on Tuesday and end the first week in December. Actors can go back to work \nimmediately, however.\n  Members are expected to approve the contract, which Fran Drescher, the union's outspoken president, valued at \nmore than $1 billion over three years. She highlighted the ''extraordinary scope'' of the agreement, noting that it \nincluded protections around the use of artificial intelligence, higher minimum pay, better health care funding, \nconcessions from studios on self-taped auditions, improved hair and makeup services on sets, and a requirement \nfor intimacy coordinators for sex scenes, among other gains.\n  ''They had to yield,'' Ms. Drescher said at a news conference during a 28-minute monologue that touched on \nVeterans Day, Bela Lugosi's Dracula costume, her parents, the Roman Empire, studio stubbornness, Buddhism, \nFrederick Douglass and her dog.\n  The union, SAG-AFTRA, which represents tens of thousands of actors, and the Alliance of Motion Picture and \nTelevision Producers, which bargains on behalf of studios, reached the tentative agreement on Wednesday. It \nfollowed a bitter standoff that contributed to a near-complete shutdown of production in the entertainment industry. \nAt 118 days, it was the longest movie and television strike in the union's 90-year history.\n  The tentative deal was also historic, according to the studio alliance, which said it reflected ''the biggest contract-\non-contract gains in the history of the union.'' In a statement, the alliance said it was ''pleased'' that SAG-AFTRA's \nboard had recommended ratification.\n  ''We are also grateful that the entire industry has enthusiastically returned to work,'' the alliance said.\n  The actors' strike, combined with a writers' strike that started in May and was resolved in September, devastated \nthe entertainment economy. Hundreds of thousands of crew members were idled, with some losing their homes and \nturning to food banks for groceries. Some small businesses that service studios -- costume dry cleaners, prop \nwarehouses, catering companies -- may never recover.\nUnion Board Backs Contract, Which Now Goes to Actors for Vote\n  The dual strikes caused roughly $10 billion in losses nationwide, according to Todd Holmes, an associate \nprofessor of entertainment media management at California State University, Northridge. While the big studios are \nbased in Los Angeles, they also use soundstage complexes in Georgia, New York, New Jersey and New Mexico.\n  Kevin Klowden, chief global strategist with the Milken Institute, an economic think tank, was more cautious with his \nestimate, putting losses at more than $6 billion. He said it ''may take a while'' to know the true size.\n  On Friday, the SAG-AFTRA board, which includes Sharon Stone, Sean Astin and Rosie O'Donnell, made public a \nsummary of the tentative contract's contents. While not receiving everything it asked for, the union achieved \nsignificant gains.\n  The final sticking point involved ''synthetic fakes,'' or the use of artificial intelligence to create an entirely fabricated \ncharacter by melding together recognizable features from real actors. The union won consent and compensation \nguarantees.\n  ''You could imagine prompting a generative A.I. system that's been trained on a bunch of actors' performances to \ncreate a digital performer, for example, who has Julia Roberts's smile,'' Duncan Crabtree-Ireland, SAG-AFTRA's \nexecutive director, said in an interview. ''Before this agreement, there wasn't any contractual or legal basis to \nrequire consent or prohibit that. Now there will be.''\n  But this strike was never about stars. A-listers like Jennifer Lawrence and Brad Pitt negotiate their own contracts \n(or, more precisely, their agents do). The tentative contract covers minimums, or what actors who don't have any \nclout get paid.\n  SAG-AFTRA had demanded an 11 percent raise for minimum pay in the first year of a contract. Studios had \ninsisted that they could offer no more than 5 percent, the same as had recently been given (and agreed to) by \nunions for writers and directors. In the end, the union was able to win a 7 percent first-year raise.\n  ''This is really important because it sends a very clear signal to other unions,'' Mr. Crabtree-Ireland said. ''I'm not \naware of anyone ever being able to break the pattern before, because it's always been that the A.M.P.T.P. \nestablishes a number and everyone gets held to it.''\n  SAG-AFTRA failed in one regard. It had gone into negotiations demanding a percentage of streaming service \nrevenue. It had proposed a 2 percent share -- later dropped to 1 percent, before a pivot to a per-subscriber fee. Ms. \nDrescher had made the demand a priority, but companies like Netflix balked, calling it ''a bridge too far.''\n  Instead, the studio alliance proposed a new residual (a type of royalty) for streaming programs based on \nperformance metrics, which the union, after making some adjustments, agreed to take. It is similar to what the \nWriters Guild of America achieved in its negotiations: Actors in streaming shows that attract at least 20 percent of \nsubscribers will receive a bonus.\n  Unlike the Writers Guild, however, SAG-AFTRA also got the studio alliance to agree to a system in which 25 \npercent of the bonus money will go into a fund that will be distributed to actors in less successful streaming shows.\n  ''I felt like, is this a win or a loss?'' Ms. Drescher said. ''But we're getting the money. We opened a new revenue \nstream. What matters is that we got into another pocket.''\nhttps://www.nytimes.com/2023/11/10/business/media/sag-tentative-deal-vote.html\nGraphic\n \nThis article appeared in print on page B3.               \nUnion Board Backs Contract, Which Now Goes to Actors for Vote\nLoad-Date: November 11, 2023"
    },
    {
        "file_name": "New_York_Observer_May2023",
        "header": "Who Said What at Google's Advertising Exhibition",
        "media": "New York Observer",
        "time": "May 25, 2023",
        "section": "",
        "length": "608 words",
        "byline": "Rachyl Jones",
        "story_text": "Who Said What at Google's Advertising Exhibition\nNew York Observer\nMay 24, 2023 Wednesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 608 words\nByline: Rachyl Jones\nBody\nGoogle hosted its 10th annual Google Marketing Live today (May 23), at Google's Bay View campus in California. A \ndozen Google employees-including chief business officer Philipp Schindler and vice president of ads Jerry Dischler-\npresented new ad products and answered questions from advertisers, emphasizing that Google's ad products are \ndriven by artificial intelligence while protecting users' privacy.\n\"When we get (data privacy) right as an industry, everybody wins,\" Dischler said during the event.\nAI has been a big topic in presentations from Big Tech companies to advertisers. Earlier this month, Meta unveiled \nnew AI-driven advertising products to media buyers. During Google's event today, executives advocated that AI in \nadvertising is the future but also tried to ease marketers, suggesting human guidance is still necessary. Despite AI \nbeing ubiquitous in Google's products-with the ability to write brand slogans and target audiences using data-\"that \ndoesn't mean you have no control,\" said Tim Frank, senior director of product management.\nHere's how it went.\nPhilipp Schindler sets the stage\nSchindler opened the event with a joke written by Bard, Google's large language model and competitor to \nChatGPT. The chief business officer has been in his role since 2015 and at Google since 2005. He slung jargon like \n\"supercharging search\" and \"bold and responsible,\" to describe the company's advertising strategy. In the broader \nconsumer buying economy, impulse shopping is on the rise, video has exploded and consumers are searching for \nmore specific products, he said.\nJerry Dischler announces chatbot for advertisers\nConsumers do more research before they make a purchase, and they are more value-conscious, Dischler said. \nGoogle is adding AI-powered chat into the Google Ads interface, Dischler announced. The chat feature is intended \nto aid advertisers in tasks like writing company summaries and slogans, helping marketers generate high-quality ad \ncopy with less effort, said Sylvanus Bent, group product manager. The product will begin testing in July. Like \nSchindler, Dischler joined the company in 2005. He has worked as vice president and general manager of ads for \nthree years.\nAdvertisers applauded Brandye Sweetnam's product\nBrandye Sweetnam, director of product at Google Shopping, presented a generative AI tool that can replace the \nbackgrounds of product images. For example, if a marketer is selling a lotion and they have an image of the bottle, \nit can appear on a tropical beach, in a bathroom or in the clouds based on the inputted prompts. The tool negates \nthe need for extensive photoshoots and editing. It can be useful to update product images for different seasons and \nholidays, Sweetnam said. Advertisers applauded-uncommon in presentations of this nature.\nWho Said What at Google 's Advertising Exhibition\nAdvertisers can review the image to ensure it fits with their marketing strategy before publishing, Frank clarified \nafter the presentation. Meta recently announced a similar background generation tool. Google's product will be \navailable in the U.S. later this year.\nPrivacy and advertising can coexist, according to Kamal Janardhan \nGoogle's focus on privacy might offset some advertisers whose campaigns run on targeting consumers based on \ntheir data. For them, senior director of product management Kamal Janardhan said, \"Privacy and performance are \nnot at odds.\" \nJanardhan joined Google last year after a 16-year career at Microsoft, where she spent time as the general \nmanager of policy, privacy and trust. While Google assets like Chrome and Android intend to protect user privacy, \nthere are use cases for data collection, like for advertiser measurement, she said.\nLoad-Date: May 25, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "The new AI disruption tool: Devin(e) or Devil for software engineers?",
        "media": "The Economic Times",
        "time": "March 20, 2024",
        "section": "COMPANY",
        "length": "1019 words",
        "byline": " ",
        "story_text": "The new AI disruption tool: Devin(e) or Devil for software engineers?\nThe Economic Times\nMarch 21, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANY\nLength: 1019 words\nBody\nWhile explosive growth in artificial intelligence (AI) is augmenting capacities in several sectors, there are also \nconcerns over how it can affect humans. Firms have invested heavily in AI, leaving economists striving to \nunderstand the impact on the labour market and driving fears among the wider public for the future of their jobs. \nThe rapid adoption of AI so far is creating and not destroying jobs, especially for the young and highly-skilled, but \ncould reduce wages, research published last year by the European Central Bank has shown.After ChatGPT made \nwaves all over the world for its surprising generative AI capacity, a US-based company called Cognition has \nannounced the launch of a new AI tool called Devin which it claims to be the world's first fully autonomous AI \nsoftware engineer which can write code with command prompts. It has triggered fears among the software \ncommunity about its possible impact on tech jobs.What is Devin and what it doesAs per Cognition, Devin is a \ntireless, skilled teammate, equally ready to build alongside you or independently complete tasks for you to review. \nWith Devin, engineers can focus on more interesting problems and engineering teams can strive for more ambitious \ngoals.Devin can plan and execute complex engineering tasks requiring thousands of decisions. It can recall \nrelevant context at every step, learn over time, and fix mistakes.Cognition has equipped Devin with common \ndeveloper tools including the shell, code editor, and browser within a sandboxed compute environment — \neverything a human would need to do their work. Devin has the ability to actively collaborate with the user. It reports \non its progress in real time, accepts feedback, and works together with the user through design choices as needed. \nDevin can learn how to use unfamiliar technologies; build and deploy apps end-to-end; autonomously find and fix \nbugs in codebases; and train and finetune its own AI models.Devin correctly resolves 13.86% of the issues end-to-\nend, far exceeding the previous state-of-the-art of 1.96%. Even when given the exact files to edit, the best previous \nmodels can only resolve 4.80% of issues. Cognition tried giving Devin real jobs on Upwork and it could do those \ntoo. At present, Devin AI is in the beta testing phase and available to select users in limited access and that too by \nrequest. You can request Devin AI access by filling out a form available on their official website.How will Devin \nimpact software jobs? Devin's capabilities have raised concerns over its impact on software jobs. Will it prove to be \na job-killer as much of AI is being seen, or a blessing for techies who will benefit from it? Cognition presents Devin \nas a smart assistant that makes the job of software engineers easier and thus allows them to focus on higher-level \nskills. Software programming was getting impacted with generative AI tools like GitHub Copilot, but Cognition’s \nDevin has taken this to another level, Jaspreet Bindra, MD & founder of The Tech Whisperer, has told TOI. “It has \nseemingly groundbreaking capabilities in transforming software development. It can handle some development \nprojects independently, from writing code to fixing bugs and executing tasks, therefore mimicking a full-fledged AI \nworker rather than just a coding assistant,” he said.Its reported effectiveness in software engineering, Jaspreet \nsays, is notable because it can rapidly learn and utilise new technologies, build applications from scratch, identify \nand rectify bugs, contribute to production repositories, and autonomously train AI models. “This ability to handle \ncomplexity is creating a nervous and excited buzz amongst the fraternity,” he says.However, Devin is being seen \nmostly as an assistant rather than a competitor. Abhimanyu Saxena, co-founder of Scaler & InterviewBit, has told \nTOI that software engineers need to see these tools as enablers and quickly build expertise in using them efficiently \nrather than seeing them as competitors. “It is most likely to be a developer companion and may also enable a lot of \nnon-technical people to easily build applications,\" he says.Coding, Devin's core capability, is just one part of \nThe new AI disruption tool: Devin(e) or Devil for software engineers?\nsoftware development, and that's why it can't replace software engineers. Heena Kothari, senior director of \nengineering and product development at Exotel, has told TOI that Devin represents a big shift in how software is \nmade, and that software development isn’t just about writing code or testing it anymore. “While coding is important, \nthere’s a lot more to it, like planning how the software will work, making sure it fits with other software, and \nunderstanding how it’s used in different ways.”For large enterprise software, Heena says, coding only comprises \n40% of the whole software development process. “The rest involves designing the software, making it work with \nother software, and understanding how people will use it. That’s why Devin could be really helpful for simpler or \nmedium-complexity software projects. It could let engineers focus on solving bigger problems instead of spending \ntoo much time on routine tasks.”Despite its amazing capabilities, Devin may not pose any threat to techies at \npresent but development of generative AI will remain a cause of concern on the jobs front in various sectors, \nthough AI has in fact led to creation of more jobs. The research published by the European Central Bank, cited \nearlier in this article, is in contrast to previous technology waves, when computerisation decreased the relative \nshare of employment of medium-skilled workers. In a sample of 16 European countries, the employment share of \nsectors exposed to AI increased, with low and medium-skill jobs largely unaffected and highly-skilled positions \ngetting the biggest boost, a Research Bulletin published by the ECB said.However, the research says, these results \ndo not amount to an acquittal. \"AI-enabled technologies continue to be developed and adopted. Most of their impact \non employment and wages - and therefore on growth and equality - has yet to be seen.\"(With inputs from TOI) For \nReprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Operations_Feb2024",
        "header": "N.S.A. Installs New Director as U.S. Prepares for Election Influence",
        "media": "Operations",
        "time": "February 2, 2024",
        "section": "US; politics",
        "length": "767 words",
        "byline": "Julian E. Barnes &lt;p&gt;Julian E. Barnes covers the U.S. intelligence agencies and international security",
        "story_text": "N.S.A. Installs New Director as U.S. Prepares for Election Influence \nOperations\nThe New York Times \nFebruary 2, 2024 Friday 23:14 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 767 words\nByline: Julian E. Barnes &lt;p&gt;Julian E. Barnes covers the U.S. intelligence agencies and international security \nmatters for The Times. He has written about security issues for more than two decades.&lt;/p&gt;\nHighlight: General Timothy D. Haugh is taking over the spy agency and U.S. Cyber Command as the \norganizations look to deter Russia and other countries from expanding influence activities.\nBody\nGeneral Timothy D. Haugh is taking over the spy agency and U.S. Cyber Command as the organizations look to \ndeter Russia and other countries from expanding influence activities.\nAir Force Gen. Timothy D. Haugh took the helm of the National Security Agency and the Cyber Command on \nFriday, as the intelligence agencies and military brace for renewed efforts by foreign adversaries to influence the \nAmerican elections this year.\nGeneral Haugh replaces Army Gen. Paul M. Nakasone, who took over in 2018 and helped focus the N.S.A. and \nCyber Command on countering foreign efforts to interfere in American elections. The N.S.A. collects \ncommunications intelligence, like phone calls and computer traffic, and Cyber Command conducts operations on \ncomputer networks.\nSecuring the 2024 presidential election against outside interference and looking for operations that take advantage \nof new artificial intelligence strategies will be General Haugh’s first task.\nIntelligence agencies say they do not know whether China will remain on the sidelines this year or increase its \nactivity. But officials have said Russia is likely to expand its efforts over the 2022 midterm elections. For President \nVladimir V. Putin of Russia, this year’s elections have huge stakes, with Democrats supporting continued funding \nfor Ukraine in its war against Russia and Republicans growing more skeptical of such aid.\nSoon after he took over in 2018, General Nakasone created what he called the Russia Small Group, a team of \nexperts from the N.S.A. and Cyber Command, to discover and deter attempts by Moscow to interfere in elections.\nAt the time, General Haugh was leading Cyber Command’s National Mission Force, which conducts offensive and \ndefensive operations on computer networks. General Nakasone picked General Haugh to help lead the group along \nwith the N.S.A. official Anne Neuberger, who is now the deputy national security adviser for cyber and emerging \ntechnology.\nThat group identified the Russians who were conducting influence operations in the 2018 midterm elections. Cyber \nCommand warned some of them to deter further action and later took down servers run by a Russian troll farm that \nsupported Russian intelligence.\nAfter his time at the Cyber National Mission Force, General Haugh held posts at Joint Base San Antonio-Lackland \nin Texas before returning to Fort Meade, Md., in 2022 to become the deputy head of Cyber Command.\nN.S.A. Installs New Director as U.S. Prepares for Election Influence Operations\nIn a discussion with reporters this week, General Nakasone said that when he arrived, the N.S.A. and Cyber \nCommand began to step up efforts to understand who was trying to influence elections — and then to stop them.\n“We were going to act and impose costs on any adversary that was going to attempt to influence or interfere in our \nelections,” General Nakasone said.\nBecause the N.S.A. now works more closely with technology and cybersecurity firms, it is often possible to attribute \nintrusions to an adversarial country within seven days, General Nakasone said.\n“There’s not a lot of discussion anymore in cyberspace about how difficult it is to do attribution,” he said. “We have \ngotten much more sophisticated, in terms of our ability to work with a series of partners to determine that.”\nBut more countries are trying to influence U.S. elections, including China and Iran.\nDuring the 2022 midterm elections, General Nakasone said, Chinese operators stepped up efforts to influence \nspecific races. While their interest in this year’s vote is not clear, China and technologies related to artificial \nintelligence present a long-term challenge to the N.S.A. and Cyber Command.\nGeneral Nakasone said China posed “the generational challenge of our time, and I think that we are just at the \nbeginning piece of truly being able to understand how much we’re going to have to change.”\nHow Cyber Command conducts operations and the N.S.A. gathers intelligence differs month to month as new \ntechnologies come into widespread use and new vulnerabilities are found.\nAlready, China has experimented with artificial intelligence in influence operations, and intelligence agencies expect \ncountries to try to use new technology to make their campaigns more believable.\nGeneral Nakasone said that the smartphone has been the “most disruptive technology” of his lifetime but that \ngenerative A.I. could have as deep an impact.\n“Maintaining our nation’s edge in this technology is critical for us,” he said.\nPHOTO: Air Force Gen. Timothy D. Haugh, above, is replacing Army Gen. Paul M. Nakasone atop the National \nSecurity Agency. (PHOTOGRAPH BY HAIYUN JIANG FOR THE NEW YORK TIMES) This article appeared in print \non page A15.\nLoad-Date: February 2, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_May2023",
        "header": "Pentagon pic demonstrates misinformation era we're in",
        "media": "The Baltimore Sun",
        "time": "May 25, 2023",
        "section": "MAIN; A; Pg. 11",
        "length": "730 words",
        "byline": "Parmy Olson Bloomberg Opinion",
        "story_text": "Pentagon pic demonstrates misinformation era we're in\nThe Baltimore Sun\nMay 25, 2023 Thursday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 11\nLength: 730 words\nByline: Parmy Olson Bloomberg Opinion\nBody\nA fake photo of an explosion near the Pentagon went viral across Twitter on Monday, and stocks dipped. The \nincident confirmed what many have said for months: Misinformation is on course to be supercharged as new AI \ntools for concocting photos get easier to use.\nFixing this problem with technology will be an endless game of whack-a-mole. It's certainly worth trying to track \nimage provenance, as Adobe Inc. is doing with its Content Authenticity Initiative. But as the saying goes, a lie can \ntravel around the world and back again while the truth is still lacing up its boots. In a world where more content than \never is being generated artificially, we'll all need to become more skeptical about what we see online - especially in \nthe run-up to a U.S. presidential election next year.\nThe Pentagon \"photo\" became particularly messy because of Twitter's poor excuse for a verification system. Elon \nMusk revamped the site's blue ticks so that they would no longer be monopolized by \"elites\" like press and \ncelebrities, and so more people could become verified and have a louder voice for a flat fee. Unfortunately, his \nsystem has become a target for imitators, like the paid account BloombergFeed, which was one of several verified \naccounts that posted the Pentagon photo before getting suspended Monday morning.\nBloomberg Feed and a Twitter account called Walter Bloomberg, which also carried the report, are not affiliated \nwith Bloomberg News, according to a spokesperson for Bloomberg News.\nAlthough Twitter has made a perfect environment for fake AI photos to flourish, the problem ultimately goes beyond \nthe platform. The Pentagon photo originated on Facebook and we can expect more photos like it circulating on \nother social networks too, such as WhatsApp, where fake information about the elections in Brazil last year went \nviral through the app's forwarding feature.\nTikTok could also become more susceptible to fake videos soon enough. Early examples of videos made from AI \ntools still look glitchy, but they're likely to become more realistic in the next year or two, with millions of dollars of \nventure-capital investment going into startups building deepfake technology (for legitimate purposes, of course).\nFor instance, New York startup Runway has just released a tool that allows anyone to transform one video into \nanother type of video using words and images as prompts, while San Francisco-based Gan.ai has raised money \nfrom VC luminaries like Sequoia Capital to sell \"video personalisation\" software to brands.\nWhile realistic fake videos might still be a year or two out, image generation is becoming easier than ever. Adobe \nhas just updated its Photoshop software with generative AI tools that allow users of the ubiquitous image-editing \nsoftware to manipulate photos in much more drastic ways. And there are several good image-generating tools \navailable as mobile apps, making them easier for people to access on the go.\nPentagon pic demonstrates misinformation era we're in\nWhen I asked Stable Diffusion's co-founder last year about how the world should deal with a surge in fake photos, \nhe said we'll all have to adjust. \"People will be aware of the fact that anyone can create that image on their phone, \nin one second,\" Emad Mostaque said. \"People will be like, 'Oh it's probably just created.' \"\nRemember the internet jargon, \"pics or it didn't happen?\" Soon enough, pics won't be so useful for proof, and we'll \nfind ourselves questioning legitimate images too. Twitter users got a taste of AI's potential for accelerating \nmisinformation in March, when a fake photo of Pope Benedict in a puffer jacket went viral.\nGenerative AI and dodgy blue checkmarks are a perfect mix for misinformation to thrive on Twitter, and as Meta \nPlatforms Inc. prepares to cut more jobs in coming weeks, staff are concerned their content moderation teams will \nget curbed too, according to a Tuesday report in the Washington Post, meaning there will be fewer people to handle \nthe problem.\nThis time last year, platforms like Twitter and Facebook had improved their abilities to stamp out misinformation. \nThings look different today. The tech companies have to do a better job of preventing fake news from spreading - \nbut we will also need to approach them with greater doses of skepticism. At a time when seeing is no longer \nbelieving, we must arm ourselves with more discerning eyes, and a little more doubt.\nDistributed by Tribune Content Agency\nLoad-Date: May 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Oct2023",
        "header": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery",
        "media": "The New York Times - International Edition",
        "time": "October 2, 2023",
        "section": "TECHNOLOGY",
        "length": "1089 words",
        "byline": "Yiwen Lu",
        "story_text": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe New York Times - International Edition\nOctober 3, 2023 Tuesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1089 words\nByline: Yiwen Lu\nDateline: SAN FRANCISCO \nBody\nInstagram, Facebook, Snapchat and several newcomers are betting on artificial intelligence to rejuvenate the fun, \ninteractivity and whimsy of creating and sharing images.       \nMyuri Thiruna, a freelance photographer in Toronto, used to post frequently on Instagram and discuss photography \nwith other users. But she said she had stopped two years ago, feeling \"drained\" by the demands of social media \nand the pursuit of followers and trends.       \nThen in July, Ms. Thiruna discovered Can of Soup, a new invitation-only social network where people make \nfantastical images of themselves with artificial intelligence and share the images with others. Enthralled by those \nabilities, she created A.I. images that showed her sitting on a unicorn floating in an ocean and her wearing a jacket \nmade of Froot Loops.       \nMs. Thiruna, 33, also commented on other users' posts, chatting with them and making images together. She now \nspends as much five hours a day interacting with others on the app, she said.       \n\"I met so many people on this app that I didn't know before, and it goes beyond just posting and getting the likes,\" \nshe said. \"It's this meaningful connection with people and being also inspired by what they're doing.\"       \nSocial networking apps are beginning to integrate A.I. into their image capabilities to make their platforms more \nsocial. After Facebook, Instagram and other apps have become more corporate over the years, A.I. imagery \npresents a way for them to bring back the whimsy and fun so users can rediscover what was once the point of the \nplatforms: to share and interact with one another.       \nLarge social platforms and new apps alike are incorporating A.I. image features. Last month, Snapchat announced \nDreams, an A.I. imaging feature that lets users in Britain, Australia and New Zealand create outlandish selfies. \nTikTok last year rolled out several in-app filters that use A.I. to transform selfies into the style of a comic or a \ndreamlike character. BeFake, a social app launched in August, is also experimenting with A.I. selfies and images.       \nOn Wednesday, Facebook, Instagram, WhatsApp and Messenger jumped in as well. Meta, which owns the apps, \nsaid the services would now offer A.I. tools for instantly generating photorealistic \"stickers,\" which can be shared. It \nadded that it would introduce similar tools for editing and restyling existing images. These tools could put cowboy \nboots on two babies in a family photo, for instance.       \n\"You can generate imagery inside of your chats,\" said Ahmad Al-Dahle, Meta's vice president of generative A.I. \nWhile most image-generation tools need 10 to 20 seconds to create an image, he added, Meta's new tool needs \nonly five.       \nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe growing number of A.I. imagery tools in various apps underlines how \"using A.I. interactively is where social \nmedia will go,\" said Sam Saliba, who was Instagram's global brand marketing lead and is now a marketing and \nbranding consultant in Silicon Valley.       \nThe trend takes A.I. images further than the apps that allowed people to produce A.I.-generated images without \nconversing or easily sharing them in an online community. Those apps included Lensa AI - which let people create \nA.I. selfies in styles like \"cosmic,\" \"fairy princess\" and \"anime\" - as well as Remini, Snow and Wombo. Interest in \nthose apps peaked in mid-December, and downloads have since declined, according to the market intelligence firm \nApptopia.       \nBen-Zion Benkhin, the founder of Wombo, said many people didn't stick with A.I. apps that were merely a \"creation \ntool\" and that gave users no ability to chat with one another about what they had produced.       \n\"All of these apps are very limited,\" he said. Adding social networking, he said, \"does connect you to the other \npeople.\"       \nThat understanding has helped drive new apps like BeFake, which has melded A.I. image features with socializing \nand sharing. BeFake prompts users at a different time every day to take a picture with their smartphone's front and \nback cameras and then has A.I. transform the image.       \nUsers need to share their posts before viewing other people's posts. The concept was borrowed from BeReal, a \nphoto-sharing app that has been popular among young users.       \nBeFake connects people through their creativity, said Kristen Garcia Dumont, one of the app's founders. \"What that \nmeans to each person is unique and intriguing, and you get to explore that with whoever you want in the app,\" she \nsaid.       \nBeFake's parent company has raised $3 million, and the app has tens of thousands of users, said Ms. Dumont and \nher co-founder, Tracy Lane.       \nHayley Fligel, 17, a high school student in Burlingame, Calif., said she began using BeFake in July after a friend \ninvited her to join. It's different from apps like Snapchat, TikTok and Instagram, which are stressful because \"if you \nwant to take pictures or videos of yourself, you have to get ready, you have to get dressed, and you have to be \ndoing something or have a nice background around you,\" she said.       \nShe said she could use A.I. on BeFake to make herself look like Taylor Swift or appear that she was playing \nvolleyball, which shows \"a more personal snippet of who you are.\" While she seldom interacts with others on \nInstagram, she said, she comments on her friends' posts on BeFake and browses a \"Discovery\" feed for inspiration \nfrom other posts.       \nGabriel Birnbaum, who created Can of Soup with Eric Meier in May, said the point was to encourage creation and \nhave fun. \"It's an app where you spend time with your friends,\" he said.       \nSince then, he said, he has seen many creative and social moments happen in the app. In particular, a feature \ncalled Stir - which lets users put themselves in scenarios that someone else created - makes up one in four posts \non the platform, Mr. Birnbaum said, with people inserting themselves into an A.I. image of Einstein inside a black \nhole in space, for example.       \nMr. Birnbaum, who declined to disclose Can of Soup's funding and number of users, said he didn't plan to roll out \nthe app widely until it had the \"right trust and safety\" with users comfortable with the content and whom they create \nphotos with.       \n\"I like the creation aspect and people liking my work and interacting with them,\" said Alex Rosenblatt, 35, of San \nFrancisco, who has used Can of Soup since June. \"Most of my interactions on it are with people I don't know, \nactually.\"       \nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nCade Metz contributed reporting.       \nCade Metz contributed reporting. \nLoad-Date: October 2, 2023"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "Does Pixel 8's A.I.-Based Editing Cross a Line?",
        "media": "The New York Times",
        "time": "October 12, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 8; TECH FIX",
        "length": "1074 words",
        "byline": "By Brian X. Chen",
        "story_text": "Does Pixel 8's A.I.-Based Editing Cross a Line?\nThe New York Times\nOctober 12, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 8; TECH FIX\nLength: 1074 words\nByline: By Brian X. Chen\nBody\nGoogle's new $700 Pixel 8 lets you use artificial intelligence to add or remove elements from your images. It's not \nclear we really need this.\nSmartphone cameras became extremely powerful over the last five years. Their leap in quality was largely driven by \nadvancements in computational photography, a technology that uses algorithms, artificial intelligence and sensors \nto produce sharp, lifelike pictures. Now we all can shoot stunning images that rival the work of professionals. \n  So what's next? I hate to say it: faker photos.\n  Google, which has long been an industry leader in smartphone photography, will on Thursday start shipping the \nPixel 8, a $700 handset with a suite of A.I.-powered photo-editing tools. The phone software does much more than \nadjust the sharpness and brightness of a photo -- it uses A.I. to generate imagery or to remove elements to give you \nexactly the photo you want.\n  Imagine, for instance, a photo in which a person's shoulder is cut off. With Google's software, you can now tap the \nMagic Editor button and scoot that person over in the frame. From there, the software will use A.I. to produce the \nrest of that person's shoulder.\n  Or consider a picture you shot of a friend in front of a historical monument, but the background is crowded with \nother tourists. Using the same editing tool, you can select the photo bombers and hit the Erase button. In seconds, \nthe strangers will vanish -- and Google's software will automatically generate imagery to fill in the background.\n  Google has integrated these new A.I. editing tools into Google Photos, its free photo album app for Android \ndevices and iPhones, which has more than one billion users. The company said the Pixel 8 was the first device with \nthe A.I. editor, which means the same tools could soon arrive for other devices.\n  Google's A.I. photo editor is part of a wave of generative A.I., which became popular in the last year after the \nrelease of the ChatGPT chatbot, which produces text in response to prompts. Image-based generative A.I. tools \nlike DALL-E, Midjourney and Adobe Firefly also let people create pictures by simply typing in a prompt, such as ''a \ncat sleeping on a windowsill.''\n  Yet the Pixel 8 is a turning point. It is the first mainstream phone to bake generative A.I. directly into the photo \ncreation process at no extra cost, pushing smartphone photography into an era when people will increasingly have \nto question whether what they see in their images is real -- including photos from loved ones.\n  (Apple's iPhone camera can add some artificial effects, such as a ''stage light'' that brightens a subject and blacks \nout the background, but it stops short of generating fake imagery.)\nDoes Pixel 8's A.I.-Based Editing Cross a Line?\n  ''This is a really big moment that's going to change a lot of things about imagery,'' said Ren Ng, a computer \nscience professor at the University of California, Berkeley, who teaches courses on computational photography. ''As \nwe go boldly forth into this future, a photo is no longer a visual fact.''\n  To test whether this is a good thing, I shot and edited dozens of photos with the Pixel 8. I was impressed, creeped \nout and skeptical that I would want to keep generating fake photos. Here's what I found.\n  Picture Imperfect\n  Continuing my tradition when testing many smartphone cameras, I used the Pixel 8 to snap photos of my dogs -- \nMax, a corgi, and Mochi, a brown Labrador -- and then applied the A.I.\n  The results were hit and miss.\n  In one photo of Max sitting on a large rock, I wanted to remove a citation form from a police officer for letting my \ndogs run off leash without a permit in an off-leash dog park. (Who has ever heard of such a thing?) In the Google \nPhotos app, I tapped the Magic Editor button and traced an outline around the piece of paper.\n  The software did a remarkable job. It replaced the maddening piece of bureaucracy with the rock slab and some \npine needles.\n  In another photo, where Mochi is standing near Max and the right side of her butt is cut off in the frame, I tried \nscooting her to the left. The Pixel 8 did OK moving her, but the right side of Mochi's computer-generated behind \nwas blurry and her left paw was cut off.\n  Then came the most jarring result. In a photo of a pizza restaurant where Mochi's face was cut off in the frame, I \ntried moving her over to test if the A.I. could generate the rest of her head. I didn't expect the software to perfectly \nreproduce her grizzled mug, but the A.I. produced something nightmarish, a half-demi-god hellhound with a pair of \nhooves sprouting from her legs.\n  Google includes a Regenerate button for when you are unhappy with the results, which I tried. But it yielded \nequally off-putting results each time.\n  In the same photo, I tried highlighting and deleting the strangers in the background. This worked well but felt \nunsettling, like watching the ''snap'' scene in ''Avengers: Infinity War,'' when half the universe's population \ndisappeared.\n  It is early days, and Google expects people to run into imperfections. ''This feature is in early stages and won't \nalways get it right,'' the company said in a statement. ''We're looking for feedback to continually improve our \nmodels.'' \n  To use or not to use\n  Here's my feedback: I don't think these A.I. editing tools should be featured so prominently in the photos app of a \nflagship smartphone, especially in their imperfect state.\n  And even when the technology matures, there are broader questions -- such as the ethical issues of artificial \nimages -- to consider and navigate.\n  Editing photos for clarity and brightness improves an image without altering its substance. But artificially adding \nelements to a photo crosses a threshold, rendering an image a fake. Using these A.I. tools to produce and share \nphotos could contribute to the spread of fake media online when misinformation is already rampant and it's hard to \nknow what to trust.\n  Dr. Ng, the computer science professor, said it was up to us to decide how to use generative photo technology \nresponsibly, especially now that it has arrived on smartphones. He has set his own limits.\nDoes Pixel 8's A.I.-Based Editing Cross a Line?\n  ''Anything that touches authenticity to me, as a photographer, would be very problematic,'' he said.\n  As for myself, I would use these A.I. photo tools to remove visual distractions, like the photo bomber ruining an \notherwise great picture, from photos shared among family. But even then, I would use these tools sparingly, and I \nwould not publish the fakery online.\nhttps://www.nytimes.com/2023/10/11/technology/personaltech/google-pixel8-photos.html\nGraphic\n \nPHOTOS: Using Pixel 8's A.I.-enabled photo editor, the citation on the rock to the right of the dog and the citation's \nshadow were removed and the background filled in to look like rock surface. This article appeared in print on page \nB8.               \nLoad-Date: October 12, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "THE ROBOTS HAVE FINALLY COME FOR MY JOB",
        "media": "Wall Street Journal Abstracts",
        "time": "April 7, 2023",
        "section": "A; Pg. 2",
        "length": "41 words",
        "byline": "GREG IP",
        "story_text": "THE ROBOTS HAVE FINALLY COME FOR MY JOB\nWall Street Journal Abstracts\nApril 6, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 2\nLength: 41 words\nByline: GREG IP\nBody\nABSTRACT\nGreg Ip Capital Account column suggests generative artificial-intelligence apps like OpenAI’s ChatGPT mean \nthat professionals, including journalists now know fear of obsolescence that has stalked blue-collar workers for \ngenerations; graph (M)\nGraphic\n \nGraphs and Charts\nLoad-Date: April 7, 2023"
    },
    {
        "file_name": "Dictionary.com._Sep2023",
        "header": "Nepo baby. Crony capitalism. Blursday. Over 500 new words added to",
        "media": "Dictionary.com.",
        "time": "September 6, 2023",
        "section": "",
        "length": "1085 words",
        "byline": "Saman Shafiq, USA TODAY",
        "story_text": "Nepo baby. Crony capitalism. Blursday. Over 500 new words added to \nDictionary.com.\nUSA Today Online\nSeptember 6, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 1085 words\nByline: Saman Shafiq, USA TODAY\nBody\nAre you greenwashing? How much sleep debt do you have? \nIf you're unfamiliar with those terms you're probably not the only one, but they're now recognized by the most \nfamous online dictionary.\nDictionary.com added more than 566 new words, 348 new definitions for existing entries and 2,256 revised \ndefinitions Wednesday as the dictionary works to \"keep pace with the ever-changing English language.\"\n\"As you can imagine, recording the ever-changing language is incredibly enjoyable while also being intellectually \nstimulating,\" said Grant Barrett, head of lexicography at Dictionary.com in a statement. \n“Even though dictionary-making is what we do, we're still delighted with the variety, depth and complexity of this big \nbatch of terms. There's so much that shows how vibrant the language is, as it keeps up with changes in culture and \nsociety,\" he added.\nThe website also updated entries to replace binary-gendered phrases like \"he or she\" with \"they\" in a move to use \nmore inclusive language.\nNew words added to Dictionary.com\nThe 566 new words added to Dictionary.com are from a variety of topics including pop culture and slang, modern \nproblems, artificial intelligence, climate and extreme weather and health and wellness.\nSome popular additions include nepo baby, Big Pharma, generative AI, GPT, coffee nap and amalgagender. Here \nare some of the new words and what they mean:\n• Jawn: something or someone for which the speaker does not know or does not need a specific name.\n• Nepo baby: a celebrity with a parent who is also famous, especially one whose industry connections are \nperceived as essential to their success.\n• Unsee: to remove (something seen) from one's memory or conscious awareness; to forget or ignore images \nor the like.\n• Unsend: to delete (a digital message such as an email or text) from the devices of the sender and receiver.\n• NIL: name, image, likeness: aspects of a collegiate athlete’s identity for which they may earn money from a \nthird party, as for advertising sponsorship or merchandise sales, although they are prohibited from being \npaid directly by colleges and universities for their participation in intercollegiate sports.\n• Blursday: a day not easily distinguished from other days, or the phenomenon of days running together.\nNepo baby. Crony capitalism. Blursday. Over 500 new words added to Dictionary.com .\n• Godwin’s Law: an adage of internet culture stating that as any discussion or debate grows longer, there is a \nproportionate increase in the probability that someone will invoke a comparison to Hitler or the Nazi party.\n• Information pollution: the introduction of falsehood, irrelevance, bias, and sensationalism into a source of \ninformation, resulting in a dilution or outright suppression of essential facts.\n• Greenwashing: an instance or practice of promoting or affiliating a brand, campaign, mission, etc., with \nenvironmentalism as a ploy to divert attention from policies and activities that are in fact \nantienvironmentalist.\n• Crypto-fascism: secret support for fascism.\n• Crony capitalism: an economic system in which success in business is obtained through relationships to \npeople in political power rather than through competition.\n• Big Pharma: pharmaceutical companies considered collectively, especially with reference to their political and \ncommercial influence.\n• Generative AI: artificial intelligence that is designed to process prompts from users and respond with text, \nimages, audio, or other output that is modeled on a training data set.\n• Chatbot: a computer program designed to respond with conversational or informational replies to verbal or \nwritten messages from users.\n• GPT: generative pre-trained transformer: a type of machine learning algorithm that uses deep learning and a \nlarge database of training text in order to generate new text in response to a user's prompt.\n• Coffee nap: a short nap, usually 15–30 minutes, taken immediately after drinking a cup of coffee, the claimed \nbenefit being that the energizing effect of caffeine may be bolstered by a sleeping body’s drop in adenosine \nlevels.\n• Sleep debt: the difference between the amount of sleep a person needs and the actual amount of time spent \nsleeping, when the amount needed exceeds the time slept.\n• Stress eating: emotional eating, especially in response to stress, tension, or anxiety.\n• Intermittent fasting: a pattern of eating that involves regular short periods of fasting, such as by limiting food \nintake to a certain period of the day or to fewer meals on certain days of the week.\n• Polyromantic: noting or relating to a person who is romantically attracted to people of various genders, but \nnot necessarily to people of all genders.\n• Autosexual: noting or relating to a person who primarily feels sexual attraction to and desire for themselves, \nas opposed to other people.\n• Climate criminal: a person, business, country, or other entity whose actions or activities are considered \nparticularly destructive to the environment.\n• Eco-hazardous: bad or dangerous for the environment.\nDictionary.com removes binary-gendered phrases\nDictionary.com has also announced the decision to remove binary-gendered phrases like \"his or her\" and \"he or \nshe,\" which had appeared in hundreds of entries.\n\"This change was made for two reasons: inclusivity and usage,\" said Dictionary.com in their statement. \n“Updating binary-gendered phrases makes the entries more similar to how people actually speak and write. The \nentries are now more natural sounding,\" said Barrett.\nDictionary.com said that it \"aspires to empower every person, of every background to express themselves, make \nconnections and open the door to opportunity through the power and joy of language\". \nNepo baby. Crony capitalism. Blursday. Over 500 new words added to Dictionary.com .\nWhat does 'MBN' mean? Here's what it means and how to use for texts, social media.\nHow does Dictionary.com add words?\nDictionary.com says it doesn't make up words – words are added \"because they’re real – because they’re really \nused by real people in the real world.\"\n\"We can’t endorse any word, but we can document their use in the real world. We are descriptive—we describe \nlanguage as it is really used (not just how we or others may wish it would be used),\" said Dictionary.com. \nDictionary.com uses the following criteria to determine whether a word should be added:\n• It’s a word that’s used by a lot of people.\n• It’s used by those people in largely the same way.\n• It’s likely to stick around.\n• It’s useful for a general audience.\nSuddenly repulsed by your partner? You may have gotten 'the ick.' Here's what that means.\nThis article originally appeared on USA TODAY: Nepo baby. Crony capitalism. Blursday. Over 500 new words \nadded to Dictionary.com.\nLoad-Date: September 6, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "India Inc heavyweights look to AI to drive innovation and efficiency",
        "media": "The Economic Times",
        "time": "April 8, 2024",
        "section": "JOBS",
        "length": "500 words",
        "byline": "Rica Bhattacharyya and Kala Vijayaraghavan",
        "story_text": "India Inc heavyweights look to AI to drive innovation and efficiency\nThe Economic Times\nApril 8, 2024 Monday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: JOBS\nLength: 500 words\nByline: Rica Bhattacharyya and Kala Vijayaraghavan\nBody\nMumbai: An increasing number of CEOs, CXOs and top management professionals are seeking to upskill and \nspecialise in generative artificial intelligence (GenAI) at a time when AI technology is expected to be the primary \ndisruptive force for most businesses, potentially altering processes and systems beyond recognition.Hence, there is \nan urgent push for key managerial personnel to acquire knowledge and understanding of AI in various aspects of \nbusiness transformation to drive innovation and changes, top officials and academics said.Leading global business \nschool Insead has witnessed an uptick in senior professionals from India wanting to upgrade in new-age tech skills, \nincluding AI and GenAI, said dean Francisco Veloso. \"There is a lot of interest from corporates and senior \nmanagement professionals and because of that, we are developing more content in areas related to AI and \nbusiness - from strategy to organisational behaviour,\" he said. Doctoral Programmes  \"They don't want to be \nexperts in AI. \nWhat they want to learn is how they can use it in their businesses, to leverage the AI tools to create better products \nand drive efficiency. Our aim is to help these professionals on how to use tech in business strategy,\" added Veloso, \na professor of strategy. Edtech platform upGrad has seen an increasing demand for doctoral programmes in GenAI \n- with over 130 sign-ups for executive doctorate programs in GenAI with its US university partner Golden Gate \nUniversity, San Francisco in less than eight months.\"CXOs, directors and seasoned professionals with 10 to more \nthan 15 years of experience are opting for the executive doctorate programs,\" said upGrad co-founder Mayank \nKumar. \"The increase in demand is particularly because these senior professionals are trying to adapt new skills to \nbecome more agile and adaptable in the current market circumstances,\" he added. \"Over 95% of our enrolments \ncome from professionals with over eight years of experience,\" he added.Sunil D'souza, CEO, Tata Consumer, said \nthe company's senior digital team members are guiding the management on AI's business possibilities.\"Our digital \nteam has run us through multiple inductions and shown us use cases of the art of the possible. We now have a \nsmall team starting to commercialise the good use cases,\" he said.Sunil Kataria, CEO, Raymond Lifestyle (India & \nInternational), said: \"The top leadership team is constantly collaborating with experts in the AI field.\"\"Our top \nexecutives are engaging with Microsoft and AWS workshops to build a digital roadmap in Generative AI business \nsolutions. One of our top colleagues is pursuing a PhD in AI through BITS Pilani,\" he said. \"The integration of AI \nhas emerged as a transformative force in today's rapidly evolving business landscape in how we interact with \ncustomers and operate businesses.\"Top board members said there is nothing more important in today's rapidly \nchanging business environment than the knowledge of AI. For Reprint Rights: timescontent.com\nLoad-Date: April 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "The Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War",
        "media": "The New York Times",
        "time": "August 8, 2023",
        "section": "TECHNOLOGY",
        "length": "3226 words",
        "byline": "Paul Mozur and John Liu",
        "story_text": "The Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\nThe New York Times \nAugust 4, 2023 Friday 02:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 3226 words\nByline: Paul Mozur and John Liu\nHighlight: At 92, Morris Chang, the founder of Taiwan Semiconductor Manufacturing Company, can no longer stay \nin the shadows.\nBody\nIn a wood-paneled office overlooking Taipei and the jungle-covered mountains that surround the Taiwanese capital, \nMorris Chang recently pulled out an old book stamped with technicolor patterns.\nIt was titled “Introduction to VLSI Systems,” a graduate-level textbook describing the intricacies of computer chip \ndesign. Mr. Chang, 92, held it up with reverence.\n“I want to show you the date of this book, 1980,” he said. The timing was important, he added, as it was “the earliest \npiece” in a puzzle that came together for him — altering not only his career but also the course of the global \nelectronics industry.\nThe insight that Mr. Chang gained from the textbook was deceptively simple: the idea that microchips, which act as \nthe brains of computers, could be designed in one place but manufactured somewhere else. The notion went \nagainst the semiconductor industry’s standard practice at the time.\nSo at the age of 54, when many people begin thinking more about retirement, Mr. Chang instead put himself on a \npath to turn his insight into a reality. The engineer left his adopted country, the United States, and moved to Taiwan \nwhere he founded Taiwan Semiconductor Manufacturing Company, or TSMC. The company does not design chips, \nbut it has become the world’s biggest manufacturer of cutting-edge microprocessors for customers including Apple \nand Nvidia.\nToday, the company that partially exists because of a textbook is a $500 billion juggernaut that has put the most \nadvanced chips in iPhones, cars, supercomputers and fighter jets. So critical are its airplane-hangar-size chip \nfactories, called fabs, that the United States, Japan and Europe have courted TSMC to build them in their neck of \nthe woods. Over the past decade, China has also invested hundreds of billions of dollars to recreate what TSMC \nhas done.\nMr. Chang’s unlikely entrepreneurial journey helped Taiwan become an economic giant, restructured the way the \nelectronics industry worked and ultimately charted a new geopolitical reality in which a linchpin of global economic \ngrowth lies in one of the world’s most volatile spots.\nThat has thrust Mr. Chang, and the company he created, into the spotlight. And at the twilight of his career, a man \nwho has preferred to remain in the shadows reflected on what he has built and what it means to no longer be able \nto stay under the radar.\n“It doesn’t make me feel particularly good,” said Mr. Chang, who retired in 2018 but still appears at TSMC events. “I \nwould rather stay relatively unknown.”\nThe Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\nOver a recent three-hour discussion in his office, Mr. Chang made it clear that he identifies as American — he \nobtained his U.S. citizenship in 1962 — at a time when the company he founded is at the center of a technological \nCold War between the United States and China. Even as the rivalry for tech leadership intensifies, he does not give \nChina much of a chance for semiconductor supremacy.\n“We control all the choke points,” Mr. Chang said, referring collectively to the United States and its chip-making \nallies such as the Netherlands, Japan, South Korea and Taiwan. “China can’t really do anything if we want to choke \nthem.”\nMore than a dozen people familiar with Mr. Chang, many of whom knew him as a colleague at TSMC, said he built \nthe company — and outmaneuvered giants like Samsung and Intel — by being meticulous, stubborn, trusting his \nbest people and, crucially, having boundless ambition and making daring moves when justified. When TSMC \nstumbled after the 2008 financial crisis, he returned as chief executive at age 77 to take over again.\n“He’s probably the only person left in the chip industry who was present at the creation of the industry itself,” said \nChris Miller, the author of the book “Chip War” and an associate professor of international history at the Fletcher \nSchool at Tufts University. “That he’s not only still in the industry but at the center and top of it is extraordinary.”\nTo understand the tech industry’s future, it is crucial to understand the world through Mr. Chang’s eyes and how he \nmade that initial bet when others didn’t. And unlike today’s tech moguls — such as Elon Musk and Mark \nZuckerberg, who have publicly considered a cage fight — Mr. Chang has shown more restraint. If competition \nbetween the global tech giants is a series of high-stakes poker games, he is the quiet man who runs the casino.\nAlmost an automaker\nMr. Chang was born in 1931 in a China on the brink of war. Before the age of 18, he lived in six cities, changed \nschools 10 times, experienced bombings in Guangzhou and Chongqing, and crossed the front lines as his family \nfled Japanese-occupied Shanghai during World War II.\nWhen he made it to Hong Kong in 1948 with his family, who by then were trying to get away from the Chinese \nCommunist Party’s advancing army, there was no going back.\n“My old world crumbled as the mainland changed its color, and a new world was yet to be established,” he wrote in \nhis autobiography, which was published in 1998.\nIn 1949, Mr. Chang moved to the United States, attending Harvard before transferring to the Massachusetts \nInstitute of Technology to study mechanical engineering. In 1955, when he twice failed a qualifying exam for a \ndoctoral degree at M.I.T., he decided to test out the job market.\n“Many years later, I considered failing to be admitted to the Massachusetts Institute of Technology’s Ph.D. program \nas the greatest stroke of luck in my life!” he wrote in his autobiography.\nTwo of the best offers arrived from Ford Motor Company and Sylvania, a lesser-known electronics firm. Ford \noffered Mr. Chang $479 a month for a job at its research and development center in Detroit. Though charmed by \nthe company’s recruiters, Mr. Chang was surprised to find the offer was $1 less than the $480 a month that \nSylvania offered.\nWhen he called Ford to ask for a matching offer, the recruiter, who had previously been kind, turned hostile and told \nhim he would not get a cent more. Mr. Chang took the engineering job with Sylvania. There, he learned about \ntransistors, the microchip’s most basic component.\n“That was the start of my semiconductor career,” he said. “In retrospect, it was a damn good thing.”\nThree years at Sylvania opened doors and cemented Mr. Chang’s passion for semiconductors. But Sylvania \nstruggled, teaching him a lesson that would inform how he later ran TSMC.\nThe Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\n“From the beginning, the semiconductor industry has been a fast-paced and unforgiving industry,” Mr. Chang wrote \nof Sylvania’s eventual collapse in his autobiography. “Once you fall behind, catching up becomes considerably \ndifficult.”\nIn 1958, he jumped to a buzzy new semiconductor company, Texas Instruments. The Dallas company was \n“youthful and energetic,” with many employees working over 50 hours a week and sleeping overnight in the office. \nFour years later, Mr. Chang became an American, an identity he considers primary.\n“Ever since I fled Communist China and went to the United States and became naturalized in 1962, my identity has \nalways been American, and nothing else,” he said.\nMr. Chang became a pillar of Texas Instruments’ then world-beating semiconductor business. Breakthroughs were \nconstant. In the 1970s, the firm produced a chip that could synthesize the human voice, which led to the famed \nSpeak &amp; Spell toy, a hand-held device that helped children with spelling and pronunciation.\n“It’s just like Camelot, but it was not a long period of time,” he said. \nIn the late 1970s, Texas Instruments turned its focus to the burgeoning market for calculators, digital watches and \nhome computers. Mr. Chang, then in charge of the semiconductor side, realized his career there was approaching a \n“dead end.”\nIt was time for something different.\nPutting the puzzle pieces together\nIf the first puzzle piece that led to TSMC’s creation was the textbook, the second was an experience that Mr. Chang \nhad toward the end of his time at Texas Instruments.\nIn the early 1980s, Texas Instruments opened a chip factory in Japan. Three months after the production line began \nchurning out chips, the plant’s “yield” was double that of the company’s factories in Texas. Yield is a key statistic \nthat refers to how many usable chips emerge from production.\nMr. Chang was dispatched to Japan to solve the yield mystery. The key was the staff, he found, with turnover \nsurprisingly low among well-qualified employees.\nBut try as it might, Texas Instruments could not find the same caliber of technicians in the United States. At one \nU.S. plant, the top candidate for a supervisor job had a degree in French literature and no engineering background. \nThe future of advanced manufacturing appeared to be in Asia.\nIn 1984, Mr. Chang joined General Instrument, another chip firm, where a third puzzle piece fell into place. He met \nan entrepreneur who later started a company that would only design chips without also making them, which was \nthen uncommon. He spotted a trend that would prove to have staying power: Today most semiconductor \ncompanies design chips and outsource manufacturing. \nThis final piece coincided with Taiwan’s transition from a labor-intensive and heavy industry economy to a high-tech \none. When Taiwanese officials set their sights on developing the semiconductor industry, they asked Mr. Chang, \nwhose reputation as a chip expert was established, to lead an institute for supercharging innovation.\nSo in 1985, Mr. Chang, then 54, left the United States for a place he knew only from several visits to a Texas \nInstruments factory.\n“I certainly had no plan to spend nearly so much time in Taiwan,” he said. “I thought I was going back in maybe just \na few years, and I really had no plan to set up TSMC, to set up any company in Taiwan.”\nWithin weeks of Mr. Chang’s arrival, Li Kwoh-ting, a government official who became known as the godfather of \nTaiwan’s tech development, asked him to make the state-led chip project commercially viable.\nThe Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\nWhen Mr. Chang assessed Taiwan’s strengths and weaknesses, he sensed an opening. “I concluded that Taiwan \nwas a lot more similar to Japan than the U.S.,” he said, referring to his experience with the Texas Instruments’ \nfactory in Japan. \nIn 1987, Mr. Chang founded TSMC. The business model was clear in his head: TSMC would make chips for other \ncompanies and not design them. That meant it just had to win over those inside the industry and then focus on what \nit could do best — manufacturing.\nFrom the get-go, Mr. Chang had plans for TSMC to tap into a global market. He introduced professional \nmanagement systems, which were uncommon in Taiwan, at the company. To foster an international environment, \ninternal communications were in English.\nHis vision proved prophetic. As semiconductors became more complex and expensive to produce, only a few firms \ncould even afford to try. Making chips involves hundreds of steps that pull on advanced lasers and chemical \nmanipulations to create tiny pathways for electronic signals that do the most basic calculations for a computer. \nCosts were astronomical.\nOver the years, Mr. Chang kept going as others dropped out. If TSMC could attract enough customers, leveraging \neconomies of scale, it had a chance to take out the kings: Intel and Samsung.\nIn 1997, Mr. Chang recruited a new head of research of development, Chiang Shang-yi. He told Mr. Chiang to \nbenchmark TSMC against the industry leader, Intel.\n“Our goal is to be No. 1, barring none,” Mr. Chang said.\nMr. Chiang was surprised. “To be No. 1, you have to spend three times as much as your next competitor,” he \nreplied, implying that being in the lead would be too lofty and costly a goal.\n“It may be three times, but I do want to spend enough so that we become No. 1,” Mr. Chang said. And he was \nprepared to be patient, even after stepping down as TSMC’s chief executive in 2005 and staying on as the \ncompany’s chairman.\nClosing the Apple contract\nIn April 2009, angry TSMC employees — many who had recently been let go by the company — set up a protest \ncamp at a leafy playground in Taipei’s quiet residential neighborhood of Dazhi. They were down the street from Mr. \nChang’s upscale apartment building.\nAs dark fell, the protesters rolled out sleeping bags next to a slide and jungle gym, covering themselves with a large \nsign that read “TSMC lies lies lies.” Throughout its more than two-decade history, TSMC had never laid off \nemployees. Yet after the 2008 financial crisis, Mr. Chang’s successor, Rick Tsai, began letting employees go.\nMr. Chang, then 77, decided he could no longer stay on the sidelines. He took back his job, rehired the talent Mr. \nTsai had let go and more than doubled TSMC’s spending.\nComing at a tough time for the industry, the move was not appreciated by investors. Elizabeth Sun, TSMC’s former \nhead of investor relations, recalled her reaction to the news: “When I heard it, I felt like banging my head against a \nwall.”\nBut the bet paid off. In 2010, Mr. Chang got the call that would turbocharge TSMC’s growth and clinch its lead over \nSamsung and Intel. Jeff Williams, a senior vice president at Apple, reached out through Mr. Chang’s wife, Sophie \nChang, who is a relative of Terry Gou, the founder of Foxconn, Apple’s largest assembler.\nThe call led to a Sunday dinner with all four of them, which turned into negotiations the next day. Apple had worked \nwith Samsung to produce the microchip it designed for the iPhone, but it was looking for a new partner, partly \nThe Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\nbecause Samsung had become a major smartphone competitor. TSMC, which does not compete with its \ncustomers, was in pole position for the contract.\nThe discussions stretched on for months. “It was very complicated — the contract itself,” Mr. Chang said. “It was the \nfirst time we ran into this kind of thing.”\nAt one point, Apple announced a two-month pause in talks. Mr. Chang heard Intel might have intervened.\nWorried, Mr. Chang flew to San Francisco to meet Tim Cook, Apple’s chief executive, who reassured him. In a 2013 \ninterview, Paul Otellini, then Intel’s chief executive, said he had turned down the chance to make the chips for the \niPhone because Apple would not pay enough.\nMr. Chang would not make the same mistake. Apple demanded better terms and lower prices than others, but he \nunderstood the contract’s scale would help TSMC rocket past competitors. That was a lesson he learned from Bill \nBain, who founded the consulting firm Bain &amp; Company, back at Texas Instruments.\nMr. Bain, then a consultant for Boston Consulting Group, had worked in an office next to Mr. Chang for almost two \nyears. He had analyzed Texas Instruments’ production and sales numbers and argued that the more the company \nproduced, the better it would perform.\nWhen the deal with Apple was complete, Mr. Chang borrowed $7 billion to build the capacity for making millions of \nchips for the iPhone.\nIn the ensuing years, Apple briefly turned to Samsung for iPhone chip production again, but TSMC became its \nprimary chip maker. Apple is now TSMC’s largest client, accounting for about 20 percent of revenue.\nMr. Chang remains cautious about what he says about TSMC’s customers even now. After beginning a story about \nApple at his office, he wondered whether he had said too much.\n“I don’t think I have exceeded Apple’s limits of what to tell you,” he said.\nIn a statement, Mr. Williams, now Apple’s chief operating officer, said Mr. Chang had “pushed the semiconductor \nindustry to new frontiers.”\nIn 2018, Mr. Chang, at 86 years old, retired again. By then, TSMC had succeeded where others lagged, mass \nproducing chips with electronic pathways the size of a DNA double helix. That gave Mr. Chang confidence that he \nhad achieved a key tenet for TSMC: technological leadership.\nSpurring the A.I. revolution\nAmong the awards and photos with world leaders that stud the walls of Mr. Chang’s Taipei office, one is a framed \ncomic portraying his close relationship with Jensen Huang, a founder of the chip firm Nvidia.\nIf Apple turbocharged TSMC, it was Mr. Chang who helped make Nvidia the world’s most important designer of \nartificial intelligence chips. The cartoon tells the story. In the mid-1990s, when Nvidia was a start-up, Mr. Huang \nsent a letter to Mr. Chang asking if TSMC would make its chips. After a call with Mr. Huang, Mr. Chang agreed.\n“I liked him,” Mr. Chang said of Mr. Huang.\nBy taking that chance, Mr. Chang helped spur the A.I. revolution in the United States. With TSMC’s manufacturing, \nNvidia became the world’s most important A.I. chip designer. Breakthroughs like generative A.I. rely on huge \nnumbers of Nvidia chips to find patterns in vast amounts of data.\nIn a 2018 speech at Mr. Chang’s retirement gathering, Mr. Huang said Nvidia — now worth $1 trillion — would not \nexist without TSMC. An inscription on the comic, which Mr. Huang gave to Mr. Chang, reads: “Your career is a \nmasterpiece — a Beethoven’s Ninth Symphony.”\nThe Chip Titan Whose Life’s Work Is at the Center of a Tech Cold War\nFor Mr. Chang, the final notes of that masterpiece have not yet been played. He is healthy for a nonagenarian, \nthough he can no longer smoke a pipe — once his trademark in photos — after he had stents put into his heart a \nfew years ago.\nAt his office, he still keeps a Bloomberg terminal. He also makes regular public appearances around Taiwan to \ndiscuss global politics and the economy. Like many, he worries about a potential conflict between the United States \nand China over Taiwan, though he believes the chance of such a confrontation is low.\n“The chance of China invading Taiwan, amphibious warfare and all that stuff, I think that’s a very, very low \nprobability,” he said. “A blockade of some kind, I think I still put it as low probability, but it’s still a chance and I want \nto avoid that.”\nMr. Chang said he was not worried about U.S. policies that have cut off Chinese firms from access to cutting-edge \nsemiconductor technology.\n“I think it’s still OK,” he said, though he noted U.S. companies would lose business and China would find ways to \nfight back.\nAs the conversation wound down, Mr. Chang said he had some regrets that he could not be in the driver’s seat as \nTSMC faces geopolitical challenges. But he said the timing of his retirement in 2018 made sense, driven by \ntechnology and not politics.\n“I was literally sure that we had achieved technology leadership,” he said of that time. “I don’t think we’ll lose it.”\nPHOTOS: The TSMC Museum of Innovation in Hsinchu, Taiwan, tells the company’s story. (PHOTOGRAPH BY \nLAM YIK FEI FOR THE NEW YORK TIMES) (BU4); Above from left: Morris Chang delivering remarks at a TSMC \nevent at a plant in Arizona last year; inside a TSMC chip factory in Hsinchu; the TSMC office in the Southern \nTaiwan Science Park in Tainan. (PHOTOGRAPHS BY AGENCE FRANCE-PRESSE — GETTY IMAGES; \nADRIANA ZEHBRAUSKAS FOR THE NEW YORK TIMES; LAM YIK FEI FOR THE NEW YORK TIMES) (BU4; \nBU5); A TSMC silicon wafer, left. Rick Tsai, above, Morris Chang’s successor, laid off employees after the 2008 \nfinancial crisis. In 2009, Mr. Chang, then 77 and four years into retirement, took back his job and rehired those who \nhad been let go. (PHOTOGRAPH BY SAM YEH/AGENCE FRANCE-PRESSE — GETTY IMAGES); At a new \nTSMC plant in Phoenix last year, Mr. Chang shared a toast with Tim Cook, top left, Apple’s chief executive, and a \nhandshake with Jensen Huang, above right, chief executive of Nvidia. Both companies are TSMC microprocessor \ncustomers. (PHOTOGRAPHS BY CAITLIN O’HARA/BLOOMBERG; ROSS D. FRANKLIN/ASSOCIATED PRESS) \n(BU5) This article appeared in print on page BU4, BU5.\nLoad-Date: August 8, 2023"
    },
    {
        "file_name": "protections_against_misuse;_Artificial_intelligence_tools_that_can_conjure_Sep2023",
        "header": "Tech companies try to take AI image generators mainstream with better",
        "media": "protections against misuse; Artificial intelligence tools that can conjure",
        "time": "September 22, 2023",
        "section": "NATION WORLD",
        "length": "804 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Tech companies try to take AI image generators mainstream with better \nprotections against misuse; Artificial intelligence tools that can conjure \nwhimsical artwork or realistic-looking images from written commands \nstarted wowing crowds last year\nDayton Daily News (Ohio)\nSeptember 21, 2023 Thursday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 804 words\nByline: MATT O'BRIEN\nBody\nArtificial intelligence tools that can conjure whimsical artwork or realistic-looking images from written commands \nstarted wowing the public last year. But most people don't actually use them at work or home.\nThat could change as leading tech companies are competing to take text-to-image generators mainstream by \nintegrating them into Adobe Photoshop, YouTube and other familiar tools. \nBut first, they're trying to convince users and regulators that they've tamed some of the Wild West nature of early AI \nimage-generators with stronger safeguards against copyright theft and troubling content. \nA year ago, a relatively small group of early adopters and hobbyists began playing with cutting-edge image \ngenerators such as Stable Diffusion, Midjourney and OpenAI's DALL-E. \n\"The previous ones were an interesting curiosity,\" but businesses were wary, said David Truog, an analyst at \nmarket research group Forrester. \nA backlash followed, including copyright lawsuits from artists and photo stock company Getty, and calls for new \nlaws to rein in generative AI technology's misuse to create deceptive political ads or abusive sexual imagery. \nThose problems aren't yet solved. But a proliferation of new image generators say they're business-ready this time. \n\"Alexa, create an image of cherry blossoms in the snow,\" is the kind of prompt that Amazon says U.S. customers \nwill be able to speak later this year to generate a personalized display on their Fire TV screen. \nAdobe, known for the Photoshop graphics editor it introduced more than three decades ago, was the first this year \nto release an AI generator designed to avoid legal and ethical problems created by competitors who trained their AI \nmodels on huge troves of images pulled off the internet. \n\"When we talk to customers about generative technology, mostly what we hear is a lot of the technology is really \ncool, but they don't feel like they can use it because of these questions,\" said Adobe's chief technology officer for its \ndigital media business, Ely Greenfield. \nThat's why Adobe's product, called Firefly, was built on its own Adobe Stock image collection, as well as content it \nhas licensed. Stock contributors also are getting some compensation out of the arrangement, Greenfield said. \nTech companies try to take AI image generators mainstream with better protections against misuse Artificial \nintelligence tools that can conjure whimsical artwor....\n\"Adobe Firefly is clean legally, whereas the others are not,\" said Forrester's Truog. \"You don't really care about that \nif you're just some dude having fun with generative AI.\" \nBut if you're a business or a creative professional thinking about using images on your website, apps, or in print \nlayouts, advertising or email marketing campaigns, \"it's kind of a big deal,\" Truog said. \"You don't want to be getting \ninto trouble.\" \nSome competitors are taking note. ChatGPT-maker OpenAI unveiled its third-generation image generator DALL-E 3 \non Wednesday, emphasizing its impressive capabilities and future integration with ChatGPT along with new \nsafeguards to decline requests that ask for an image in the style of a living artist. Creators can also opt to exclude \ntheir images from training future models, though Truog notes that OpenAI hasn't said anything \"about compensating \nauthors whose work they use for training, even with permission.\" \nIn separate New York City showcase events Thursday, both Microsoft and Google-owned YouTube also unveiled \nnew products infused with AI image generation. \nMicrosoft, a major investor in OpenAI, showed how it is already starting to bake DALL-E 3 into its graphics design \ntools, mostly for background editing, as well as its Bing search engine and chatbot. YouTube revealed a new \nDream Screen for short YouTube videos that enables creators to compose a new background of their choosing. \nEarlier this month, both Adobe and Stability AI, maker of Stable Diffusion, joined a larger group of major AI \nproviders including Amazon, Google, Microsoft and OpenAI that agreed to voluntary safeguards set by President \nJoe Biden's administration. \nOne safeguard requires companies to develop methods such as digital watermarking to help people know if images \nand other content were AI-generated. \nMicrosoft executives said the company has built filters to determine what kinds of imagery can be generated from \ntext prompts in Bing, citing those made with top political figures as content to monitor. \nThe goal is \"to make sure it's not producing types of content we would never want to produce, like hateful content,\" \nsaid Sarah Bird, Microsoft's global head for responsible AI. \nIn a demonstration to an Associated Press reporter, a prompt that asked Microsoft's new tool for an image of \n\"Hillary Clinton rock climbing\" was met with rejection Thursday. \n\"Oops! Try another prompt,\" was the response. \"Looks like there are some words that may be automatically blocked \nat this time.\" \nAP business writers Cora Lewis and Haleluya Hadero contributed to this report.\nGraphic\n \nThis AI-generated image provided by Adobe shows a hummingbird. Artificial intelligence tools that can conjure \nwhimsical artwork or realistic-looking images from written commands started wowing the public in 2022. But most \npeople don't actually use them at work or home. That could change as leading tech companies are competing to \nmainstream the use of text-to-image generators for a variety of tasks, integrating them into familiar tools such as \nMicrosoft Paint, Adobe Photoshop, YouTube and ChatGPT. (Adobe via AP)\nLoad-Date: September 22, 2023\nTech companies try to take AI image generators mainstream with better protections against misuse Artificial \nintelligence tools that can conjure whimsical artwor...."
    },
    {
        "file_name": "your_personal_information_Nov2023",
        "header": "The risks of sharing",
        "media": "your personal information",
        "time": "November 19, 2023",
        "section": "MAIN; A; Pg. 3",
        "length": "452 words",
        "byline": "Emma Patch Kiplinger's Personal Finance",
        "story_text": "The risks of sharing\nyour personal information\nThe Baltimore Sun\nNovember 19, 2023 Sunday\nAdvanceBulldog Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 3\nLength: 452 words\nByline: Emma Patch Kiplinger's Personal Finance\nHighlight: Flynt/Dreamstime\nBody\nRaj Ananthanpillai, founder and Ceo of Trua, an identity verification and screening company, discusses the risky \nbehavior.\nQ: Why do you call this the new golden age for identity theft?\nA: Everybody is giving away their Social Security number, date of birth or where they live, whether it's to sign up for \na gym membership or for discounts on groceries, because they think they're getting something of value.\nBut these companies are collecting your personal information. Not only does that put you at risk if the data is \nhacked, but companies may turn around and sell it to third parties. Some of this information is then stolen and \nbartered on the \"dark web\" where users and website operators are anonymous and untraceable.\nCompanies are supposed to get your consent before sharing your information with third parties, but it's on 13 to 15 \npages of fine print that 99% of people can't understand, so they agree to the terms.\nQ: Given those risks, what should you do if a company asks for your Social Security number?\nA: If the entity asking for your Social Security number isn't a financial institution, government agency or employer, \nyou should ask why they need it, what they are going to do with it, how long they're going to store it and whether \nthey share it with any third parties. If they're using your Social Security number for identity verification only, you \nshould ask whether there's another way to establish your identity.\nQ: Is there a risk to giving a company or provider your cellphone number?\nA: Yes, because it may be used to commit fraud. These days, cellphone numbers are being used as a piece of \nverification data to prevent fraud in digital transactions. In addition, as online vendors collect cell phone numbers, \nthey use them for marketing purposes, which means you may receive a lot of spam. They may also sell them to \nthird parties that collect and barter them on the dark web.\nYou can end up getting a lot of calls and texts from scammers who are trying to trick you into giving up personal \ninformation or downloading malware. Scammers may also try to use your cell phone number to access your online \naccounts.\nQ: How can we protect ourselves when using new technologies such as ChatGPT and other forms of generative \nAI?\nThe risks of sharing your personal information\nA: Never give one of these programs your personal information, such as your Social Security number, date of birth, \nmother's maiden name or even your work history. If you provide this kind of information to ChatGPT and ask it to \nwrite you a résumé, for example, you never know where the information will go or whether it's going to be used for a \nnefarious purpose. And with artificial intelligence, there's even more proliferation of information that could be \nhacked or stolen.\nLoad-Date: November 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "New A.I. Technology Generates Blueprint To Edit Human DNA",
        "media": "The New York Times",
        "time": "April 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "1066 words",
        "byline": "By Cade Metz",
        "story_text": "New A.I. Technology Generates Blueprint To Edit Human DNA\nThe New York Times\nApril 23, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 1066 words\nByline: By Cade Metz\nBody\nGenerative A.I. technologies can write poetry and computer programs or create images of teddy bears and videos \nof cartoon characters that look like something from a Hollywood movie.\nNow, new A.I. technology is generating blueprints for microscopic biological mechanisms that can edit your DNA, \npointing to a future when scientists can battle illness and diseases with even greater precision and speed than they \ncan today. \n  Described in a research paper published on Monday by a Berkeley, Calif., startup called Profluent, the technology \nis based on the same methods that drive ChatGPT, the online chatbot that launched the A.I. boom after its release \nin 2022. The company is expected to present the paper next month at the annual meeting of the American Society \nof Gene and Cell Therapy.\n  Much as ChatGPT learns to generate language by analyzing Wikipedia articles, books and chat logs, Profluent's \ntechnology creates new gene editors after analyzing enormous amounts of biological data, including microscopic \nmechanisms that scientists already use to edit human DNA.\n  These gene editors are based on Nobel Prize-winning methods involving biological mechanisms called CRISPR. \nTechnology based on CRISPR is already changing how scientists study and fight illness and disease, providing a \nway of altering genes that cause hereditary conditions, such as sickle cell anemia and blindness.\n  Previously, CRISPR methods used mechanisms found in nature -- biological material gleaned from bacteria that \nallows these microscopic organisms to fight off germs.\n  ''They have never existed on Earth,'' said James Fraser, a professor and chair of the department of bioengineering \nand therapeutic sciences at the University of California, San Francisco, who has read Profluent's research paper. \n''The system has learned from nature to create them, but they are new.''\n  The hope is that the technology will eventually produce gene editors that are more nimble and more powerful than \nthose that have been honed over billions of years of evolution.\n  On Monday, Profluent also said that it had used one of these A.I.-generated gene editors to edit human DNA and \nthat it was ''open sourcing'' this editor, called OpenCRISPR-1. That means it is allowing individuals, academic labs \nand companies to experiment with the technology for free.\n  A.I. researchers often open source the underlying software that drives their A.I. systems, because it allows others \nto build on their work and accelerate the development of new technologies. But it is less common for biological labs \nand pharmaceutical companies to open source inventions like OpenCRISPR-1.\nNew A.I. Technology Generates Blueprint To Edit Human DNA\n  Though Profluent is open sourcing the gene editors generated by its A.I. technology, it is not open sourcing the \nA.I. technology itself.\n  The project is part of a wider effort to build A.I. technologies that can improve medical care. Scientists at the \nUniversity of Washington, for instance, are using the methods behind chatbots like OpenAI's ChatGPT and image \ngenerators like Midjourney to create entirely new proteins -- the microscopic molecules that drive all human life -- as \nthey work to accelerate the development of new vaccines and medicines.\n  (The New York Times has sued OpenAI and its partner, Microsoft, on claims of copyright infringement involving \nartificial intelligence systems that generate text.)\n  Generative A.I. technologies are driven by what scientists call a neural network, a mathematical system that \nlearns skills by analyzing vast amounts of data. The image creator Midjourney, for example, is underpinned by a \nneural network that has analyzed millions of digital images and the captions that describe each of those images. \nThe system learned to recognize the links between the images and the words. So when you ask it for an image of a \nrhinoceros leaping off the Golden Gate Bridge, it knows what to do.\n  Profluent's technology is driven by a similar A.I. model that learns from sequences of amino acids and nucleic \nacids -- the chemical compounds that define the microscopic biological mechanisms that scientists use to edit \ngenes. Essentially, it analyzes the behavior of CRISPR gene editors pulled from nature and learns how to generate \nentirely new gene editors.\n  ''These A.I. models learn from sequences -- whether those are sequences of characters or words or computer \ncode or amino acids,'' said Profluent's chief executive, Ali Madani, a researcher who previously worked in the A.I. \nlab at the software giant Salesforce.\n  Profluent has not yet put these synthetic gene editors through clinical trials, so it is not clear if they can match or \nexceed the performance of CRISPR. But this proof of concept shows that A.I. models can produce something \ncapable of editing the human genome.\n  Still, it is unlikely to affect health care in the short term. Fyodor Urnov, a gene editing pioneer and scientific director \nat the Innovative Genomics Institute at the University of California, Berkeley, said scientists had no shortage of \nnaturally occurring gene editors that they could use to fight illness and disease. The bottleneck, he said, is the cost \nof pushing these editors through preclinical studies, such as safety, manufacturing and regulatory reviews, before \nthey can be used on patients.\n  But generative A.I. systems often hold enormous potential because they tend to improve quickly as they learn \nfrom increasingly large amounts of data. If technology like Profluent's continues to improve, it could eventually allow \nscientists to edit genes in far more precise ways. The hope, Dr. Urnov said, is that this could, in the long term, lead \nto a world where medicines and treatments are quickly tailored to individual people even faster than we can do \ntoday.\n  ''I dream of a world where we have CRISPR on demand within weeks,'' he said. \n  Scientists have long cautioned against using CRISPR for human enhancement because it is a relatively new \ntechnology that could potentially have undesired side effects, such as triggering cancer, and have warned against \nunethical uses, such as genetically modifying human embryos.\n  This is also a concern with synthetic gene editors. But scientists already have access to everything they need to \nedit embryos.\n  ''A bad actor, someone who is unethical, is not worried about whether they use an A.I.-created editor or not,'' Dr. \nFraser said. ''They are just going to go ahead and use what's available.''\nhttps://www.nytimes.com/2024/04/22/technology/generative-ai-gene-editing-crispr.html\nNew A.I. Technology Generates Blueprint To Edit Human DNA\nGraphic\n \nPHOTOS: The physical structure of OpenCRISPR-1, a gene editor created by A.I. technology from Profluent, which \nsaid it was ''open sourcing'' the editor. (PHOTOGRAPH BY PROFLUENT BIO)\nAli Madani, center, chief executive of the Berkeley, Calif., start-up Profluent, with his team of scientists who worked \non the artificial intelligence research.\nMr. Madani at Profluent's lab in Berkeley. He previously worked in the A.I. lab at the software giant Salesforce. \n(PHOTOGRAPHS BY RACHEL BUJALSKI FOR THE NEW YORK TIMES)\n An image taken from a video showing a time-lapse of human cells edited by OpenCRISPR-1. (PHOTOGRAPH BY \n.JOSEPH GALLAGHER / PROFLUENT BIO) This article appeared in print on page B4.               \nLoad-Date: April 23, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Drake vs. Kendrick Lamar With A.I. as the Spoiler",
        "media": "The New York Times",
        "time": "May 2, 2024",
        "section": "Section C; Column 0; The Arts/Cultural Desk; Pg. 6",
        "length": "929 words",
        "byline": "By Brendan Klinkenberg",
        "story_text": "Drake vs. Kendrick Lamar With A.I. as the Spoiler\nThe New York Times\nMay 2, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section C; Column 0; The Arts/Cultural Desk; Pg. 6\nLength: 929 words\nByline: By Brendan Klinkenberg\nBody\nA rap beef between hip-hop's two dominant stars has left fans wondering whether new tracks are real or fakes.\nFor the past month, an all-out brawl has consumed hip-hop, with some of the genre's top artists trading barbs in \nrapidly released tracks. The dispute, which began in late March with a perceived dig at Drake by Future and Metro \nBoomin, has roped in J. Cole, Rick Ross and even the estate of Tupac Shakur. \n  At issue: Who is the current holder of hip-hop's crown -- Drake or Kendrick Lamar -- with a whole lot of rumors, \npersonal attacks and inside jokes adding fuel to the fire.\n  Rap battles aren't new, but this time, fans are grappling with a very 2024 question: Which of the diss songs are \nreal?\n  When a diss track in a high-profile conflict gets released, the splintered rap media ecosystem -- including \nmagazines, blogs, Instagram pages, YouTube channels, podcasts and livestreams -- often erupts immediately. \nJournalists spread the word, critics dissect every line, and fans rush to crown a winner, round by round. But when a \nDrake response called ''Push Ups'' appeared online, fans wondered whether it was made by him or was perhaps \nthe work of generative artificial intelligence.\n  They had reason to be skeptical. Last year, ''Heart on My Sleeve,'' a song impersonating Drake and the Weeknd, \nwas posted by a musical creator called Ghostwriter, and in many ways served as a harbinger of the impact this \ntechnology may have on the industry.\n  A track like ''Heart on My Sleeve'' requires a fair amount of musical know-how to produce. The beats and raps are \ntypically generated by a musician, then put through an open-source deepfake filter to transform the vocals into a \nwell-known artist's. It is that last step, imitating another artist's vocals, that has caused the most consternation.\n  ''I don't think any of us want to live in a world where you can just create unauthorized representations of people \nwithout their permission,'' said Alex Jae Mitchell, the chief executive of Boomy, a generative A.I. music start-up.\n  So when Drake's ''Push Ups'' appeared -- the supposed return volley to Lamar's ''Like That,'' which is on Future \nand Metro Boomin's No. 1 album ''We Don't Trust You'' -- there were questions about its veracity. ''At this point, you \nhave to question everything,'' said C. Vernon Coleman, the news editor at the hip-hop publication XXL. ''You have \nto listen to the lyrics, listen to the voice, reach out to the proper channels.''\n  Without immediate confirmation from Drake or his representatives, fans traded theories online about the mixing \nquality of the song, dug for clues from the lyrics and compared it with other Drake tracks. Eventually, a new version \nDrake vs. Kendrick Lamar With A.I. as the Spoiler\nwas released and the rapper began posting oblique references to it on his Instagram, satisfying most internet \nsleuths that it was the real deal.\n  In many ways, a rap beef is fertile ground for A.I. impersonation. The songs are usually not released through a \nrapper's record label; they often appear online in early or unfinished forms, and they generally prize insults and \nbarbs over songcraft. No one expects a sterling Drake hook and polished production on a track churned out quickly.\n  The cycle was repeated on April 15, when a Lamar response surfaced online: That one, called ''One Shot,'' was a \nfake. A Los Angeles rapper ultimately took credit for the dupe, releasing videos showing his methodology. He \nproduced and rapped the track the old-fashioned way, before putting his voice through a Lamar vocal filter.\n  Drake followed up with ''Taylor Made Freestyle'' and posted it on his official Instagram, but listeners immediately \nhad questions. The first voice on the track belonged to Tupac Shakur, the long-deceased rapper, dissing Lamar in a \nsuspiciously Drake-like cadence. After those earlier doubts swirled about whether ''Push Ups'' had been made via \ndeepfake technology, Drake used it to rap in character as Tupac and Snoop Dogg.\n  Within a week of Drake releasing ''Taylor Made Freestyle,'' the Shakur estate reacted. According to a cease-and-\ndesist letter obtained by Billboard, the estate's lawyer, Howard King, wrote that the song was ''a blatant abuse of \nthe legacy of one of the greatest hip-hop artists of all time'' and demanded its removal. Last Thursday, Drake took \nthe song off his social media pages.\n  Rap beef is big business. ''Like That'' spent two weeks at No. 1 on Billboard's Hot 100 chart, and the continuing \nfeud between Lamar and Drake remains the most pressing topic of the day for hip-hop media. Still, the possibility of \ndeepfakes muddying the waters is presenting new challenges for those who cover the back and forth.\n  ''The blogs, they don't do any research,'' Coleman said. ''If they hear there's a Kendrick Lamar diss, they're posting \nit. They're getting it up ASAP.''\n  Noah Callahan-Bever, a veteran hip-hop journalist and the chief content officer of Complex, said leaks force his \nteam to ''spend an inordinate amount of time going down rabbit holes'' to find the truth. ''And it's tough because we \nare going head-to-head with, you know, hip-hop Instagram news pages who do not feel the ethical imperative to \napply that journalistic rigor.''\n  On Tuesday, Lamar reignited the back-and-forth, adding the six-plus minute ''Euphoria'' to his YouTube page with \nno notice. The placement seemed to assure listeners that it was official, and Lamar made his feelings about the \ntechnological specter looming over the beef clear. After saying that Drake's imitation would make Tupac roll over in \nhis grave, he rapped, ''Am I battling ghosts, or A.I.?''\nhttps://www.nytimes.com/2024/04/30/arts/music/drake-kendrick-lamar-rap-beef-ai-fakes.html\nGraphic\n \nPHOTOS: Kendrick Lamar, top, and Drake have been trading diss tracks, but a few entries have proven to be \nfakes. This article appeared in print on page C6.               \nLoad-Date: May 2, 2024"
    },
    {
        "file_name": "USA_Today_Online_Dec2023",
        "header": "Scientists say AI is emerging as potential tool to aid athletes, beat drug tests",
        "media": "USA Today Online",
        "time": "December 13, 2023",
        "section": "SPORTS: ATHLETICS NEWS",
        "length": "878 words",
        "byline": "Josh Peter, USA TODAY",
        "story_text": "Scientists say AI is emerging as potential tool to aid athletes, beat drug tests\nUSA Today Online\nDecember 12, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: SPORTS: ATHLETICS NEWS\nLength: 878 words\nByline: Josh Peter, USA TODAY\nBody\nLink to Image\nWith the 2024 Paris Olympics set to begin in July, a professor of computer science at MIT is convinced something \nelse is already underway.\nThe creation of undetectable performance-enhancing drugs (PEDs) with the help of Artificial Intelligence (AI).\n“I’m 100 percent sure that if they’re in that business (of doping), they’re using it,’’ said Manolis Kellis, the MIT \nprofessor who is a member of the computer science and artificial intelligence lab at the university. “If I were in the \ndoping business, I would be crazy not to use generative AI right now.’’\nUnlike traditional AI, which follows \"predefined rules and patterns,\" generative AI creates \"new and original \ncontent.'' Content that could possibly include PEDs, according to Anne Carpenter, senior director of the imaging \nplatform at Broad Institute of MIT and Harvard.\n“I would say it’s practical now to attempt it,'' Carpenter said. But she also said there are significant hurdles, \nsuggesting AI is still developing as a potential tool for cheating in sports.\nLink to Image\nThe use of AI for drug discovery is no longer a pipedream. The unanswered question: How soon might AI be \nembraced by athletes looking for new ways to cheat? \nHow would AI work to help athletes cheat?\nThe most feasible approach would be using generative AI to alter existing PEDs that trigger drug tests in a way \nthat makes those drugs undetectable by current testing technology, according to Kellis, the MIT professor. He said \nit would be used to study molecular structure of the existing PEDs and determine what other molecules could be \nused to alter them.  \nHe compared the process to what often happens after a pharmaceutical company comes out with a highly effective \ndrug. Competitors attempt to create their own version of the drug by altering an atom or two to evade patents — just \nlike AI would help alter the molecular structure of an existing PED just enough to evade detection by drug tests, \nKellis said.\nLink to Image\nScientists say AI is emerging as potential tool to aid athletes, beat drug tests\nThere is skepticism in the scientific community about whether AI is being used for pharmacological purposes in \nsports. Some of the reasons: No existing peer review of studies or research, the extensive testing required to prove \nsafety and the focus on finding drugs for current incurable diseases.\nBut Lei Xie, a professor at Hunter College in New York who has used AI for the potential discovery of drugs for \nincurable diseases, said the process that would be used to alter existing PEDs is one reason he would not be \nsurprised if it is happening now.\n\"It is similar to drug repurposing (repositioning), which we have worked on for years,'' Xie wrote to USA TODAY \nSports by email.\nCan AI be used to create PEDs?\nCarpenter, the senior director of the imaging platform at Broad Institute of MIT and Harvard, said she sees the \npotential for AI to help create undetectable PEDs rather than relying on existing PEDs.\n\"It’s not like this is futuristic technology,'' she said. \nBut Carpenter estimated it would cost $1 billion and take 10 years to develop a PED with the required testing for \nFDA approval. Referring to the process of drug development, she said, “It’s not like you put data in one end and get \ndrugs out the other side.\"\nBut there is evidence indicating the process of drug discovery can be accelerated. \nAlán Aspuru-Guzik, a professor of chemistry and computer science at the University of Toronto, helped lead a team \nin 2022 that in 30 days discovered a “lead candidate’’ for a potential liver cancer drug. The feat was hailed for \nenhanced speed in the development of drugs with the use of AI.\n\"The issue about performance-enhancement is that unlike traditional drugs, the clinical trials would not be so easy \nto make happen,'' Aspuru-Guzik wrote by email. \"I would not recommend generating (and testing) new drugs \nwithout a fully developed clinical trial.\n\"Having said so, yes, it may be possible for rogue agents to develop such drugs. Could they be not detectable by \ntraditional tests? Sure.\"\nLink to Image\nCan AI work against dopers?\nWADA (World Anti-Doping Agency) has explored the use of AI as a tool to catch cheaters. Its use is inevitable, \naccording to Dajiang Liu, director of artificial intelligence and biomedical informatics at the Penn State College of \nMedicine.\n“More powerful AI algorithms will lead to drugs that are more difficult to be detected,’’ Liu wrote by email. \"... As you \nmay be aware, there is often a gap between the development of a new drug and testing procedures that can detect \nthat. It is not surprising to me that such gap would happen to new AI-enabled drugs. At the same time, AI-driven \ntechnologies will also accelerate the development of testing procedures to identify drug use.’’\nBut that hasn't stopped people in sports from moving forward with use of the technology, according to Aron \nD'Souza, an attorney and entrepreneur who’s trying to organize an international sports event where athletes will not \nbe subject to drug testing. He said scientists and doctors involved in AI and PEDs have approached him about \nfunding their projects.\nSaid D'Souza: \"There will be many new performance-enhancing compounds discovered in the coming years.''\nScientists say AI is emerging as potential tool to aid athletes, beat drug tests\nThis article originally appeared on USA TODAY: Scientists say AI is emerging as potential tool to aid athletes, beat \ndrug tests\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Microsoft Unbundles Teams Ahead of Regulators",
        "media": "The New York Times",
        "time": "April 3, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4; DEALBOOK NEWSLETTER",
        "length": "1972 words",
        "byline": "By Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren",
        "story_text": "Microsoft Unbundles Teams Ahead of Regulators\nThe New York Times\nApril 3, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4; DEALBOOK NEWSLETTER\nLength: 1972 words\nByline: By Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren \nHirsch and Ephrat Livni\nBody\nThe tech giant is unbundling Teams from its Office software suite, as it faces mounting scrutiny on both sides of the \nAtlantic.\nMicrosoft unbundles, again  \n  Microsoft is separating Teams, its popular video and chat app, from its Office software suite in markets around the \nworld, broadening a split that began in the European Union last fall.\n  It appears to be the latest effort by the software giant to head off investigations by global antitrust enforcers as \nregulators examine the power of Big Tech.\n  Rivals have complained about the Teams-Office bundle for years. Microsoft first added the video and document \ncollaboration program to its business software suite in 2017, and saw Teams's popularity soar after the coronavirus \npandemic unleashed a boom in hybrid and remote working.\n  At the height of the lockdown in 2020, Slack filed a complaint with the European Commission accusing Microsoft \nof anticompetitive behavior by bundling Teams with Office. (Three months later, Slack agreed to sell itself to \nSalesforce for $27.7 billion.) And last summer, Eric Yuan, the C.E.O. of Zoom, called on the F.T.C. to follow the \nE.U. in investigating the Teams-Office tie-up.\n  It's unclear if Microsoft's decision will help it avoid an E.U. fine, which could cost the company up to 10 percent of \nglobal revenue. The company told Reuters that the move ''addresses feedback from the European Commission by \nproviding multinational companies more flexibility when they want to standardize their purchasing across \ngeographies.''\n  It comes as tech behemoths are facing investigations by regulators worldwide. Last month, the Justice Department \nsued Apple over its tight control of the iOS operating system, while Google is awaiting a judge's verdict in a U.S. \nlawsuit over its search monopoly.\n  And Microsoft has drawn scrutiny over its investments in A.I. start-ups like OpenAI and the French company \nMistral.\n  The move is reminiscent of Microsoft's unbundling of Windows in the 2000s, after a bruising antitrust battle with \nthe Justice Department over the tech company's efforts to shut rivals out of its platform.\nMicrosoft Unbundles Teams Ahead of Regulators\n  But it's unclear how consequential this breakup will be. Shares in Microsoft rose on Monday despite the news, as \nanalysts questioned whether the move would mean much for the tech giant's bottom line. Data from the research \nfirm Sensor Tower showed that use of Teams stayed relatively stable even after the program was cleaved out of \nOffice in the E.U.\n  That suggests rivals may not experience a surge in new customers. (Shares in Zoom fell nearly 1 percent on \nMonday.) ''Teams is so embedded into workflows that I don't think this has that same impact,'' Rishi Jaluria, an \nanalyst at RBC Capital Markets, told Reuters.\n  HERE'S WHAT'S HAPPENING \n  Donald Trump posts a $175 million bond to avert seizure of his assets. In securing the bond for his civil fraud \ncase, the former president avoided paying a $454 million penalty while he appeals the judgment. Separately, \nshares in Trump Media & Technology Group plunged 21 percent on Monday, after the parent company of the Truth \nSocial online platform disclosed just $4 million in revenue for last year.\n  Disney is said to be winning its proxy fight against the financier Nelson Peltz. The entertainment giant's slate of \nboard nominees has secured the backing of big shareholders, including BlackRock and T. Rowe Price, ahead of the \ncompany's annual meeting on Wednesday. More than half of Disney's voting shares have been accounted for, but a \nbig question is how the company's unusually high percentage of individual shareholders will vote.\n  A regulator is reportedly scrutinizing investments by Vanguard, BlackRock and State Street in U.S. banks. The \nF.D.I.C. is examining whether the big money managers are maintaining a sufficiently passive role in managing their \nstakes, according to The Wall Street Journal. Such firms are exempt from current rules that require regulatory \napproval to own more than 10 percent of a bank -- if they don't exert influence on management or boards.\n  A $4.1 billion bet on sports \n  One of the biggest players in the booming business of sports just got bigger: The private equity firm Arctos \nPartners has raised another $4.1 billion to do more deals.\n  The fund-raising shows investor appetite for sports deals is growing as competition ramps up between private \nequity firms and Gulf countries like Saudi Arabia and Qatar.\n  Arctos is one of the busiest sports deal makers. Since its founding in 2019, the firm has invested in Formula One, \nbasketball, baseball and soccer clubs. They include the Utah Jazz and Fenway Sports Group.\n  Sports deals are booming on the back of the skyrocketing value for media rights. John Malone's Liberty Media, \nwhich owns F1, said on Monday that it had bought MotoGP, the motorcycle racing championship, for ?4.2 billion \n($4.5 billion).\n  The deal follows a record year for sports M.& A., with transaction values up 27 percent to roughly $25 billion in \n2023, according to Bloomberg calculations. That included big investments by Arctos in the Qatar-owned French \nsoccer club Paris Saint-Germain and the Aston Martin F1 team.\n  Sovereign investors are the big new players. Saudi Arabia is pouring billions into soccer and golf, and may be \nlooking at tennis next. And Qatar last year bought a stake in the owner of Washington's professional basketball and \nhockey teams.\n  Arctos sees itself as part of a new wave of long-term deal makers that treat teams like an asset class. As sports \nleagues have loosened their rules to allow for institutional investors, firms like Blue Owl and Dynasty Equity say \nthey are committed to long-term investments that aren't tied to economic volatility.\n  ''We're not a control buyer. And we're not a leveraged buyout fund,'' Ian Charles, an Arctos co-founder, told \nDealBook. \nMicrosoft Unbundles Teams Ahead of Regulators\n  Arctos played down the rising competition. Charles told DealBook that sports leagues put heavy restrictions on \nallowing state-backed investment, if they allow them at all. He declined to say whether Arctos had raised money \nfrom sovereign wealth funds, though the company said in a statement that its latest fund-raising round included \npension funds and ''global wealth platforms.''\n  The latest report card for Bridgewater's post-Dalio era \n  Ray Dalio gave up day-to-day management of Bridgewater Associates 18 months ago. Since then, Nir Bar Dea, \nhis successor atop the giant hedge fund, has been under pressure to show that one of the world's most successful \ninvestment firms can maintain its dominance.\n  Results from the first three months of 2024 suggest that Bridgewater is performing well. But can changes to how \nthe firm is run keep it in the top tier of industry performers?\n  Its flagship Pure Alpha fund is up 15.9 percent year to date, according to a notice sent to investors on Monday that \nDealBook has reviewed. That's up more than sevenfold over the Bloomberg Macro Hedge Fund Index, which tracks \nfunds with a similar strategy.\n  Pure Alpha is now up 38.4 percent, net of fees, since the creation of Bridgewater's investment committee in \nAugust 2020.\n  The hard part is maintaining that performance. For much of 2022 and 2023, Pure Alpha has performed well -- only \nto tumble precipitously at the end of each of those years. Bridgewater as a whole lost $2.6 billion last year, one of \njust two top-tier firms to lose money, according to the research firm LCH Investments.\n  That continued a string of poor performance in the 2010s that tarnished Bridgewater's reputation as a profit \nmachine. (It also raised questions about Dalio's famously idiosyncratic and brutally blunt management style, \nincluding baseball cards that featured ratings of each worker based on colleagues' assessments of them.)\n  Bar Dea has sought to make Bridgewater more flexible in how it arrives at investment decisions, Bloomberg \nreports. That includes increasing the number of people who review those moves and pledges to embrace artificial \nintelligence.\n  Will that be enough to keep clients happy? Some unidentified investors told Bloomberg that they were considering \ncutting ties if the firm didn't pick up its performance.\n  That said, Bar Dea is reportedly planning to shrink Pure Alpha and return more money to clients -- a move that \ncould make the fund more nimble.\n  ''The Western world urgently needs a significant increase in productivity growth as the burden of rising government \ndebt and entitlement spending strains almost every major economy.'' \n  -- Ken Griffin. The Citadel founder used his annual letter to investors to warn about his growing worries on debt \nand share his view that the economy will grow only modestly this year as the Fed tries to bring down inflation to its 2 \npercent target.\n  Is A.I. actually boosting productivity? \n  Investor enthusiasm around artificial intelligence has added trillions in market value to a select few tech \ncompanies. But its broader economic impact has been harder to measure.\n  Economists are divided on the A.I. productivity conundrum. On earnings calls, business leaders have been more \neager to share with Wall Street how they plan to use the technology in their operations. But whether these tools will \nachieve widespread productivity gains for the economy is less clear.\nMicrosoft Unbundles Teams Ahead of Regulators\n  ''The enthusiasm about large language models and ChatGPT has gone a bit overboard,'' the Northwestern \nUniversity economist Robert Gordon told The Times. Others are more hopeful, including Erik Brynjolfsson at \nStanford University, who has bet Gordon $400 that productivity will take off this decade.\n  While that wager catches the attention of some in academia, a parade of companies is putting the technology to \nuse:\n  Walmart has built a generative A.I. chat bot for internal use that answers common H.R. questions including ''Do I \nhave dental insurance?''\n  Abercrombie & Fitch has turned to generative A.I. to brainstorm ideas for clothing designs and to write blurbs for \nits website and app.\n  Ben & Jerry's put cameras that use A.I. into the freezers at grocery stores to alert the company and its distributors \nwhen a location was running low on a particular ice cream flavor.\n  Will such use cases impact workers? David Autor, a labor economist at M.I.T. whose work has focused on how \ntechnology can erode earning potential, argues it might not be all bad news. The technology could help people with \nless expertise to do more valuable work, lifting the middle class. Critics are unconvinced.\n  In other A.I. news: OpenAI introduced a new tool that mimics human voices with high accuracy, showing how the \ntechnology is quickly expanding beyond text, but it could also pose a new misinformation threat.\n  THE SPEED READ \n  Deals\n  Sam Altman, the C.E.O. of OpenAI, is no longer listed as the leader of the venture arm of the artificial intelligence \nstart-up. (The Information)\n  Tiger Global Management, the embattled start-up investor, has reportedly collected $2.2 billion for its latest fund, \nnearly two-thirds below its goal. (Bloomberg)\n  Policy\n  Two board members of Warner Bros. Discovery stepped down amid a Justice Department inquiry into whether \ntheir presence violated antitrust law. (NYT)\n  The company that owns the ship that hit the Francis Scott Key Bridge in Baltimore last week is invoking a 173-\nyear-old ''Titanic Law'' to cap its legal liability to $43 million. (The Lever)\n  ''Poor Nations Are Writing a New Handbook for Getting Rich'' (NYT)\n  Best of the rest\n  United Airlines is asking its pilots to take unpaid time off next month, citing late plane deliveries from Boeing. \n(CNBC)\n  The owner of Sports Illustrated sued an energy drinks mogul whose media company missed nearly $49 million in \npublishing-rights payments. (NYT)\n  ''How a Houthi-Bombed Ghost Ship Likely Cut Off Internet for Millions'' (Wired)\n  We'd like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com\nhttps://www.nytimes.com/2024/04/02/business/dealbook/microsoft-teams-office-unbundle.html\nMicrosoft Unbundles Teams Ahead of Regulators\nGraphic\n \nPHOTO: Satya Nadella, the executive chairman and chief executive of Microsoft. (PHOTOGRAPH BY ANNA \nGORDON/REUTERS) This article appeared in print on page B4.               \nLoad-Date: April 3, 2024"
    },
    {
        "file_name": "tools_Jul2023",
        "header": "How some key nations and international governing bodies are regulating AI",
        "media": "tools",
        "time": "July 14, 2023",
        "section": "WORLD NEWS",
        "length": "412 words",
        "byline": " ",
        "story_text": "How some key nations and international governing bodies are regulating AI \ntools\nThe Economic Times\nJuly 15, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: WORLD NEWS\nLength: 412 words\nBody\nRapid advances in artificial intelligence such as Microsoft-backed OpenAI's ChatGPT are complicating efforts to \nbring in laws governing the use of the technology. Here are the latest steps some key nations and international \ngoverning bodies are taking to regulate AI tools.BRITAINFinancial Conduct Authority, one of several state \nregulators tasked with drawing up norms, is consulting with Alan Turing Institute and other legal and academic \ninstitutionsCHINAIssued a set of temporary measures on July 13 to manage generative AI industryService \nproviders required to conduct security assessments and perform algorithm filing proceduresEUROPEAN UNIONEU \nlawmakers agreed in June to changes in a draft of the bloc's AI ActFacial recognition and biometric surveillance \nlikely to be key issues - some lawmakers want a total ban while EU countries want exception for national security, \ndefence and military purposesUNITED NATIONSSecretary-General Antonio Guterres in June backed a proposal for \nthe creation of an AI watchdog like IAEAHe has also announced plans to start work by end of the year on a \nhighlevel AI advisory bodyFRANCEPrivacy watchdog CNIL said in April it was probing complaints about ChatGPT \nafter the service was temporarily banned in Italy over suspected breach of privacy rulesUNITED STATESUS \nFederal Trade Commission has opened a probe into OpenAI on claims that it has run afoul of consumer protection \nlaws, news reports said on July 13National Institute of Standards and Technology will launch a public working group \nof expert volunteers on generative AIG7During their meeting in Hiroshima in May, G7 leaders agreed to have digital \nministers discuss the technology and report results by end of 2023ITALYCountry's data protection authority plans to \nreview other artificial intelligence platforms and hire AI expertsChatGPT became available again to users in April \nafter being temporarily banned over concerns by the national data protection authority in MarchISRAELWorking on \nAI regulations \"for the last 18 months or so\", Israel Innovation Authority said in JuneIsrael published a 115-page \ndraft AI policy in October and is collating public feedback ahead of a final decisionJAPANExpects to introduce by \nend of 2023 regulations that are likely closer to the US attitude than the stringent ones planned in EUCountry's \nprivacy watchdog said in June it has warned OpenAI not to collect sensitive data without people's permission For \nReprint Rights: timescontent.com\nLoad-Date: July 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "How to Use A.I. to Edit and Generate Stunning Photos",
        "media": "The New York Times",
        "time": "June 5, 2023",
        "section": "TECHNOLOGY",
        "length": "1217 words",
        "byline": "Brian X. Chen",
        "story_text": "How to Use A.I. to Edit and Generate Stunning Photos\nThe New York Times \nJune 2, 2023 Friday 04:26 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1217 words\nByline: Brian X. Chen\nHighlight: An A.I.-powered version of  Photoshop and the image generator Midjourney live up to the hype.\nBody\nAn A.I.-powered version of  Photoshop and the image generator Midjourney live up to the hype. \nHello! Welcome back to On Tech: A.I., a pop-up newsletter that teaches you about artificial intelligence, how it \nworks and how to use it.\nIn last week’s newsletter, I shared the golden prompts for getting the most helpful answers from chatbots like \nChatGPT, Bing and Bard. Now that you’re familiar with the general principle of building a relationship with A.I. — \nthe more specific and detailed instructions you give, the better results you’ll get — let’s move on to a slightly \ndifferent realm.\nMuch of the hype and fears around generative A.I. has been about text. But there have also been rapid and \ndramatic developments in systems that can generate images. In many cases, these share a similar structure to text-\nbased generative A.I., but they can also be much weirder — and lend themselves to some very fun creative \npursuits.\nImage generators are trained on billions of images, which enable them to produce new creations that were once the \nsole dominion of painters and other artists. Sometimes experts can’t tell the difference between A.I.-created images \nand actual photographs (a circumstance that has fueled dangerous misinformation campaigns in addition to fun \ncreations). And these tools are already changing the way that creative professionals do their jobs.\nCompared to products like ChatGPT, image generating A.I. tools are not as well developed. They require jumping \nthrough a few more hoops, and may cost a bit of money. But if you’re interested in learning the ropes there’s no \nbetter time to start.\nA.I. Photoshop\nLast week, Adobe added a generative A.I. feature into a beta version of Photoshop, its iconic graphics software, \nand creators on social networks like TikTok and Instagram have been buzzing about it ever since. \nI have a fair amount of experience with Photoshop. When I tested the new feature, called “generative fill,” I was \nimpressed with how quickly and competently the A.I. carried out tasks that would have taken me at least an hour to \ndo on my own. In less than five minutes and with only a few clicks, I used the feature to remove objects, add objects \nand swap backgrounds. \n(To experiment with these tools yourself, start by signing up for a free trial of Adobe Creative Suite. Then, install the \nnew Adobe Photoshop beta, which includes generative fill.)\nOnce you have Photoshop beta installed, import a photo and try these tricks:\nHow to Use A.I. to Edit and Generate Stunning Photos\n• To change a background, click the “object selection” icon (it has an arrow pointed at a box), then under the \nSelect menu, click “inverse” to select the background. Next click the “generative fill” box and type in a \nprompt — or leave it blank to let Photoshop come up with a new background concept for you.I used these \nsteps to edit a photo of my corgi, Max.  I typed “kennel” for the prompt, and clicked “generate\" to replace \nthe background. Here’s the before (left) and after.\n• To remove objects, use the lasso tool. In this photo of my motorcycle, I wanted to erase a tractor behind a \nfence in the background. I traced around the tractor, and then I clicked the “generative fill” box and hit \n“generate” without entering a prompt. The software correctly removed the tractor and filled in the \nbackground while leaving the fence intact.\nPhoto editors at The New York Times do not enhance or alter photos, or generate images using artificial \nintelligence. But my first thought after testing generative fill was that photo editors working in other contexts, like \nmarketing, could be soon out of work. When I shared this  theory with Adobe’s chief technology officer, Ely \nGreenfield, he said that it might make photo editing more accessible, but he was optimistic that humans would still \nbe needed.\n“I can make really pretty images with it, but frankly, I still make boring images,” he said. “When I look at the content \nthat artists create when you put this in their hands versus what I create, their stuff is so much more interesting \nbecause they know how to tell a story.”\nI confess that what I’ve done with generative fill is far less exciting than what others have been posting on social \nmedia.  Lorenzo Green, who tweets about A.I., posted a collage of famous album covers, including Michael \nJackson’s “Thriller” and Adele’s “21” that were expanded with generative fill. The results were quite entertaining.\n(One note: If installing Photoshop feels daunting, a quicker way to test Adobe’s A.I. is to visit the Adobe Firefly \nwebsite. There, you can open the generative fill tool, upload an image and click the “add” tool to trace around a \nsubject, such as a dog. Then click “background” and type in a prompt like “beach.”)\nMore image generators\nTools like DALL-E and Midjourney can create entirely new images in seconds. They work similarly to chatbots: You \ntype in a text prompt — the more specific, the better.\nTo write a quality prompt, start with the medium you’d like to emulate, followed by the subject and any extra details. \nFor example, typing “a photograph of a cat wearing a sweater in a brightly lit room” in the DALL-E prompt box will \ngenerate something like this:\nDALL-E, which is owned by Open AI, the maker of ChatGPT, was one of the first widely available A.I. image \ngenerators that was simple for people to use. For $15, you get 115 credits; one credit can be used to generate a set \nof four images.\nMidjourney, another popular image generator, is a work in progress, so the user experience is not as polished. The \nservice costs $10 a month, and entering prompts can be a little more complicated, because it requires joining a \nseparate messaging app, Discord. Nonetheless, the project can create high-quality, realistic images.\nTo use it,  join Discord and then request an invitation to the Midjourney server. After joining the server, inside the \nchat box, type “/imagine” followed by a prompt.  I typed “/imagine a manga cover of a corgi in a ninja turtle costume” \nand generated a set of convincing images:\nThough it’s fine to type in a basic request, some have found obscure prompts that generated exceptional results \n(Beebom, a tech blog, has a list of examples). At Columbia University, Lance Weiler is teaching students how to \nleverage A.I., including Midjourney, to produce artwork.\nHow to Use A.I. to Edit and Generate Stunning Photos\nWhichever tool you use, bear in mind that the onus is on you to use this tech responsibly. Technologists warn that \nimage generators can increase the spread of deepfakes and misinformation. But the tools can also be used in \npositive and constructive ways, like making family photos look better and brainstorming artistic concepts.\nWhat’s next?\nNext week, I’ll share some tips on how to use A.I. to speed up aspects of office jobs, such as drafting talking points \nand generating presentation slides.\nIn case you’re wondering, the delightfully demented image at the top of this newsletter was created by a human — \nthe illustrator Charles Desmarais — not by A.I.\nPHOTOS: PHOTO (PHOTOGRAPH BY CHARLES DESMARAIS); The reporter used a photo that he took, left, and \nput it in Photoshop’s new Generative Fill tool to create a new background for it by typing “kennel” in the prompt. As \nfor the delightfully demented image at top, it was created by a human illustrator, not by A.I. (PHOTOGRAPH BY \nBRIAN X. CHEN/THE NEW YORK TIMES) This article appeared in print on page B5.\nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "'India Will Establish Guardrails for Artificial Intelligence'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "COMPANIES & ECONOMY",
        "length": "806 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "'India Will Establish Guardrails for Artificial Intelligence'\nEconomic Times (E-Paper Edition)\nMay 13, 2023 Saturday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES & ECONOMY\nLength: 806 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: Centre not in favour of legislation regulating generative AI yet, unlike the US and EU, but discipline \nneeds to be brought to the industry: MoS Chandrasekhar\nBody\nNew Delhi: India plans to establish “some principles” which will act as “guardrails” for the fast-growing artificial \nintelligence (AI) sector, according to a top lawmaker who said this will help regulate generative AI platforms such \nas Microsoft's Open AI and Google's Bard as well as their use by other companies. In contrast to the view taken by \nthe European Union and the US, the Indian government is not in favour of legislation to regulate generative AI, yet, \naccording to Rajeev Chandrasekhar, minister of state for electronics and IT. He added that discipline needs to be \nbrought into an industry that can cause much chaos and harm. “If anybody says I know the right way to regulate AI, \nthere will be an Elon Musk view, the Open AI view, or 100 other views. \nWe are not going to go down that road at all,”  he told ETin an interview. “AI is an emerging technology, and we will \nestablish some principles as guardrails. Then the subordinate legislation or how to regulate it will keep evolving,” he \nsaid. India has one of the largest data sets and is therefore very crucial for companies working on generative AI. It \nis important India does not allow technology regulation to lag technology innovation in AI, the minister said. “AI \ninnovation is now growing very fast. In the blink of an eye, there's a new disruption. So therefore, we must establish \nfairly em-  bedded principles in the law.” Pointing out that the proposed guardrails will put the onus on the platforms \nto ensure that no one is using them to “create misinformation”, Chandrasekhar said “you cannot create things that \nare fake, you cannot cause user harm, you cannot have exploitive content.” The government, according to the \nminister, will define terms such as “exploitative” after consultation with the industry. The upcoming Digital India Act, \nwhich is a revamp of the 23-year-old IT Act,  will also contain a chapter on emerging technologies. The Centre, \nwhich has held one round of consultations on the Digital India Act (DIA), is planning to hold another one later in \nMay, in New Delhi. The law will not just update several regulations with respect to technology but also frame new \nones to regulate emerging areas such as Web 3 among others.  It is also reviewing the concept of safe harbour or \nimmunity which is enjoyed by internet intermediaries under Section 79 of the IT Act. Chandrasekhar told ET that in \nthe new DIA, as a principle, India is moving away from “the idea of no accountability” of the platform. “You cannot \nsay anymore that I am just a platform and I just put all the functionality… The platform is responsible, not the user. \nThat is the principal change. Section 79 will be very conditional, very narrow, any safe harbour, any immunity will be \nextremely narrow. Your responsibility is that you are accountable for the possibility or misuse of your platform, you \nare responsible not the user,” he added. In the case of generative AI models, Chandrasekhar said, if the LLMs \n(Large Language Models) are still learning and are in an alpha stage, then the companies should not release them.  \n“Don't give it to all the consumers and run a business on it. Do a sandbox rather than saying it's an alpha or a beta \nversion. Like you do drug testing? We must bring discipline and order into an industry that can cause so much \nchaos and harm,” he added. Generative AI uses large data sets to train tools and engines to generate new and \nunseen data such as text, images, audio, videos, and other three-dimensional models. Since the release of the \nOpenAI's language learning model chat generative pre-trained transformer 3 (GPT-3) in November last year, big \n' India Will Establish Guardrails for Artificial Intelligence'\ntech companies including Google and Microsoft have raced to include the generative AI model in their services. \nThe language learning models have, however, been criticised for being inaccurate, having very lax guidelines for \nprivacy and safety of users, and concerns over the training models used by compani-  es. They are also being used \nto fuel a lot of misinformation. Earlier this month, the US administration started the process to seek public \ncomments on the accountability standards that should be introduced for AI systems such as ChatGPT. The National \nTelecommunications and Information Administration sought public comments on the subject owing to growing \nregulatory interest in the AI engines. Similarly, the EU has started working on the consultation process to bring \nregulations for efficient management of AI and generative AI engines. Speaking about the government's $10 billion \nIndia Semiconductor Mission, Chandrasekhar said “we have said in the past that there will soon be approvals for a \n40-nm fab and that there will be one for a packaging unit as well.” He also said that the Digital Personal Data \nProtection Bill is likely to be tabled in the Monsoon Session of Parliament.\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Microsoft Tops Apple to Become Most Valuable Public Company",
        "media": "The New York Times",
        "time": "January 13, 2024",
        "section": "TECHNOLOGY",
        "length": "1061 words",
        "byline": "Tripp Mickle and Karen Weise &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and",
        "story_text": "Microsoft Tops Apple to Become Most Valuable Public Company\nThe New York Times \nJanuary 12, 2024 Friday 13:10 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1061 words\nByline: Tripp Mickle and Karen Weise &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and \nis based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot \ntaxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Karen Weise writes about technology and is based in Seattle. \nHer coverage focuses on Amazon and Microsoft, two of the most powerful companies in America.&lt;/p&gt;\nHighlight: The shift is indicative of the importance of new artificial intelligence technology to Silicon Valley and Wall \nStreet investors.\nBody\nThe shift is indicative of the importance of new artificial intelligence technology to Silicon Valley and Wall Street \ninvestors.\nFor more than a decade, Apple was the stock market’s undisputed king. It first overtook Exxon Mobil as the world’s \nmost valuable public company in 2011 and held the title almost without interruption.\nBut a transfer of power has begun.\nOn Friday, Microsoft surpassed Apple, claiming the crown after its market value surged by more than $1 trillion over \nthe past year. Microsoft finished the day at $2.89 trillion, higher than Apple’s $2.87 trillion, according to Bloomberg.\nThe change is part of a reordering of the stock market that was set in motion by the advent of generative artificial \nintelligence. The technology, which can answer questions, create images and write code, has been heralded for its \npotential to disrupt businesses and create trillions of dollars in economic value.\nWhen Apple replaced Exxon, it ushered in an era of tech supremacy. The values of Apple, Amazon, Facebook, \nMicrosoft and Google dwarfed former market leaders like Walmart, JPMorgan Chase and General Motors.\nThe tech industry still dominates the top of the list, but the companies with the most momentum have put \ngenerative A.I. at the forefront of their future business plans. The combined value of Microsoft, Nvidia and \nAlphabet, Google’s parent company, increased by $2.5 trillion last year. Their performances outshined Apple, which \nposted a smaller share price increase in 2023.\n“It simply comes down to gen A.I.,” said Brad Reback, an analyst at the investment bank Stifel. Generative A.I. will \nhave an impact on all of Microsoft’s businesses, including its largest, he said, while “Apple doesn’t have much of an \nA.I. story yet.”\nMicrosoft and Apple declined to comment.\nMicrosoft has not led a technology transition since the personal computing era, when its Windows operating system \ndominated sales. It was late to the internet, mobile phone and social media. \nMicrosoft Tops Apple to Become Most Valuable Public Company\nWhen Satya Nadella became Microsoft’s chief executive in 2014, the company was floundering. He refocused it on \nthe growing cloud computing business, turning it into a strong challenger to Amazon, the pioneer in the field. Then \nMr. Nadella pushed the company forward again, making an aggressive bet on generative A.I.\nIn 2019, Mr. Nadella made Microsoft’s first of several investments in OpenAI, the start-up that would build the A.I.-\npowered ChatGPT chatbot. In the end of the summer of 2022, he was impressed by a preview of OpenAI’s \nunderlying technology, known as GPT-4, and soon began prodding Microsoft to add generative A.I. to its products \nat what he called a “frantic pace.”\nHe started with adding a chatbot to the Bing search engine, but then began pushing A.I. into the Windows operating \nsystem and productive applications like Excel and Outlook, and offering OpenAI’s systems to customers of Azure, \nMicrosoft’s flagship cloud computing product.\nThe revenue has only just started to show up in Microsoft’s financial results. Generative A.I. accounted for about \nthree percentage points of growth to Azure in the three months that ended in September, and the $30-a-month \noffering inside Microsoft’s productivity software began a general release only in November.\n(The New York Times has sued OpenAI and Microsoft, accusing them of copyright infringement.)\nThis isn’t the first time that Microsoft has pulled ahead of Apple in recent years. It did so in 2018, as its cloud-\ncomputing business began to flourish, and in 2021, when the pandemic disrupted Apple’s iPhone operations. But \nthis change could be more indicative of a fundamental shift in the tech industry.\n“The question is: Who has the better mouse trap to go to the next level of $3.5 trillion?” said Dan Morgan, portfolio \nmanager and analyst at Synovus Trust, a bank in the Southeast. “You can make the case that Microsoft is in the \nbetter position. Apple has been struggling for the next big thing.”\nThe iPhone, which debuted in 2007, catapulted Apple to the top of the stock market. Between 2009 and 2015, the \ncompany went from selling 20 million iPhones a year to more than 200 million.\nWhen device sales slowed in recent years, Tim Cook, Apple’s chief executive, shifted the company’s focus from \nselling more iPhones to selling people more apps and services on their existing iPhones. The strategy helped \nApple’s annual revenue soar to $383 billion, a nearly fourfold increase from the end of 2011, the year that Steve \nJobs, Apple’s co-founder, died.\nMr. Cook’s strategy has shown signs of fatigue. The iPhone, which accounts for more than half of Apple’s revenue, \nhas become known more for its incremental improvements each year than its noteworthy innovations. Purchases of \niPads and Macs have declined. And the sales growth of its services such as Apple Music are slowing.\nLast year, the company’s sales fell for four consecutive quarters. But shares of Apple still rose around 50 percent \nlast year, and investors lifted its market value to nearly $3 trillion because of their belief that demand for the iPhone \nwould continue.\nWall Street analysts have predicted that this year’s iPhone sales will be weak. The company is facing challenges in \nChina, where Huawei has released a new phone and the government is restricting the use of foreign smartphones.\nWhile Microsoft and others have been building new generative A.I. businesses, Apple has been absent from the \nconversation. During a call with analysts last year, Mr. Cook said Apple had work “going on” connected to A.I., but \nhe declined to elaborate.\nLast year, Apple engineers were testing a large language model, which can power a chatbot, The Times reported. \nThe company has also held discussions with publishers about acquiring material to train generative A.I. systems. \nBut it has yet to release anything publicly.\n“Apple needs to take note that if they want to maintain their spot as one of the most innovative tech companies, \nthey have to get behind A.I. in a big way,” said Gene Munster, managing partner at Deepwater Asset Management.\nMicrosoft Tops Apple to Become Most Valuable Public Company\nApple has been focused on the release of an augmented reality headset, the Vision Pro. The device, which will ship \nFeb. 2, is the first major new product category that the company has released since the Apple Watch in 2014. \nAnalysts project Apple will sell fewer than half a million units.\nThis article appeared in print on page B1, B5.\nLoad-Date: January 13, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "Walmart Looks to Treble Sourcing of Goods from India to $10b a Year",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 13, 2024",
        "section": "COMPANIES",
        "length": "413 words",
        "byline": "Our Bureau",
        "story_text": "Walmart Looks to Treble Sourcing of Goods from India to $10b a Year\nEconomic Times (E-Paper Edition)\nFebruary 14, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 413 words\nByline: Our Bureau\nBody\nNew Delhi: Multinational retail hypermarket Walmart said they have sourced over $30 billion goods from the Indian \nmarket for its global operation in the past 25 years. The company is now set to triple the sourcing of these goods \nfrom India to $10 billion annually by 2027. Andrea Albright, executive vice president of sourcing at Walmart, said \nthat through its Walmart Vriddhi initiative, launched in 2019, the company is training Micro, Small and Medium \nEnterprises (MSMEs) “to learn new capabilities, scale and maximize their business ambitions” free of charge. At its \nGrowth Summit, the company announced that they have met their target early and have already trained more than \n50,000 MSMEs. \nJason Fremstad, Walmart’s senior vice president, supplier development  and sourcing, said, “What we are aiming to \ndo this week is to continue finding new suppliers to source in categorieshome, apparels, foods, health and wellness, \ntoys… this week is focused on expanding those opportunities and finding new suppliers that we can export in an \neffort to achieve the goal that we have set out for sourcing $10 billion by the end of 2027.” The “people-led tech-\npowered omni-channel retailer”, with 2.1 million associates globally, states that their strategy is to save people’s \nmoney and help them live better. The summit was to bring buyers and suppliers together to accelerate exports \nacross the country. “Our focus is to recruit and train new suppliers to fulfil our purchase orders around the world. \nThese orders often lead to the creation of new jobs. It also allows our suppliers to invest back in their local \ncommunities,”  Albright said. Doug McMillion, CEO of Walmart in ajoint video with Walmart international president \nand CEO, Kathryn McLay, said, “Other than the US, India is the only market where we have set a sourcing \nobjective. And that is because we see so much opportunity.” Walmart also aimed to explore potential solutions to \nsupply chain challenges through innovative companies and startups. Albright told ET, “Some of the challenges \ncould range from circularityhow do we continue to find ways to be more sustainable inside of our product. Other \nchallenges might behow we might use Gen-AI or AI to continue to forecast better and get better data to our \nsuppliers. So, there's a range of problems that I think the entire industry is trying to solve. And we're trying to find \nthose right entrepreneurs to learn more from and maybe can create some type of partnerships.”\nLoad-Date: February 13, 2024"
    },
    {
        "file_name": "Essay_Mar2024",
        "header": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest",
        "media": "Essay",
        "time": "March 22, 2024",
        "section": "OPINION",
        "length": "1174 words",
        "byline": "Graciela Mochkofsky",
        "story_text": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest \nEssay\nThe New York Times - International Edition\nMarch 23, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: OPINION\nLength: 1174 words\nByline: Graciela Mochkofsky\nBody\nABSTRACT\nWe need mission-driven, imaginative news leaders who are not bound by the models of the past.\nFULL TEXT\nMany uncertainties haunt the field of journalism today - among them, how we can reach our audience, build public \ntrust in our work, and who is going to pay for it all. But one thing is certain: as complicated and dark as the world \nlooks today, it would be much worse if journalists were not there to report on it.       \nResearch shows that towns that have lost sources of local news tend to suffer from lower voter turnout, less civic \nengagement and more government corruption. Journalists are essential just as nurses and firefighters and doctors \nare essential.       \nAnd to continue to have journalists, we need to make their journalism education free.       \nThis might sound counterintuitive given the state of the industry. Shrinking revenue and decreasing subscription \nfigures have led to a record number of newsroom jobs lost. Much of the local news industry has fallen into the \nhands of hedge funds focused on squeezing the last drops of revenue out of operations by decimating them. \nBillionaires who appeared as saviors just a few years ago have grown tired of losing money on the media \norganizations they bought. Public trust in the value of news is at historical lows, while a growing percentage of \npeople are avoiding the news altogether.       \nGenerative artificial intelligence, which is on the verge of reshaping almost everything around us, is bringing yet \nanother technological disruption to the industry. Against this grim backdrop, authoritarian leaders are increasingly \ntargeting journalists as political enemies both at home and abroad.       \nAnd yet there are still tens of thousands of jobs in news media in America, with exceptional journalism being \nproduced every day. Some major organizations have even found ways to thrive in the digital age. Prominent \nfoundation leaders have started an effort to pour hundreds of millions of philanthropic dollars into local journalism, \nand a movement has formed to push for federal and local legislation to direct public funding to news. An initiative to \nreplant local news has founded dozens of nonprofit newsrooms in cities around the country. And a small but \ngrowing number of organizations are redefining the way news agendas are set, focusing on rebuilding public trust \nwithin small communities.       \nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nNo matter how the news industry evolves, we will continue to need journalists. Successful business models for \nmedia are necessary, but the most crucial element for strong, independent journalism is the people who make it. \nGiven the present stakes in the industry, our society and the world, we need mission-driven, imaginative news \nleaders who are not bound by the models of the past, who have the motivation and freedom to reimagine the field, \nand the empathy and commitment to serve the public interest, undaunted by attacks and threats.       \nWe must also move beyond the lack of economic and demographic diversity that has long been a problem in the \nindustry. News has too often been reported by predominantly middle-class, white, male journalists, resulting in \ncoverage that has repeatedly missed the issues that are most important to the people receiving the news, \ncontributing to the public's lack of trust in the media.       \nIn a resource-starved industry, few newsrooms can offer the type of mentoring, guidance and time that it takes to \nshape a great journalist. This is now primarily the responsibility of journalism schools. It is the civic duty of these \nschools to find and train reporters and news leaders, instill in them an ethical foundation, help develop their critical \nthinking skills, allow them to try and fail in a safe environment, open doors and provide a support network. \n(Journalism schools should also contribute research in a variety of areas, from the impact of A.I. to new business \nmodels to identifying and responding to emerging threats.)       \nBut the cost of a journalism education has become an insurmountable barrier for exactly the kind of people we need \nthe most. And those who, with great effort, manage to overcome that barrier, carry a weight that could limit their \nprofessional options.       \nReporters burdened with debt are less likely to take professional risks and more likely to abandon the field. \nAccording to the Bureau of Labor Statistics, the median reporter salary in America is less than $56,000 a year, or \nabout $27 per hour. In low-income areas, where news deserts are more prevalent, annual salaries can be as low as \n$20,000. A Wall Street Journal report about the debt-to-income ratio of alumni of 16 journalism masters programs \nfound that many graduates leave with debts that exceed their postgraduate income.       \nAs the dean of the Craig Newmark Graduate School of Journalism at the City University of New York, I can tell you \nthat half measures won't solve this quandary. My school was founded in 2006 as a public alternative to elite \njournalism schools in the city and it remains one of the most affordable in the nation.       \nOur in-state students pay about a quarter of the cost of an equivalent degree from top-tier schools with which we \nsuccessfully compete. This year alone, 90 percent of our students are on scholarships, and a record 25 percent are \nattending tuition-free. We also waived the $75 application fee this admission cycle and saw an increase of more \nthan 40 percent in our applicant pool.       \nThanks to these policies, we have succeeded where the media industry keeps failing. Over 50 percent of our \nstudents are people of color and from underserved communities. Many couldn't have attended our school if we \nhadn't offered significant scholarship support. But that's not enough. Though we rank as one of the journalism \nschools with higher-medium-income and lower-median-debt alumni, our students still don't graduate fully debt-free.       \nThis is why this year, we began a campaign to go fully tuition-free by 2027. While other schools might face different \nfinancial challenges, we hope that many more will follow us.       \nWe need journalists whose only obligations are to the facts and the society they serve, not to lenders; who are \nconcerned with the public interest, not with interest rates; who can make risky decisions and take the difficult path if \nthat's what the mission requires, free of financial burden. Journalism schools can help achieve that. In tough times, \nit is natural to mourn the past or lament the present, but what we really need is bold action.       \nGraciela Mochkofsky is the dean at CUNY's Craig Newmark Graduate School of Journalism. She is the author, \nmost recently, of \"The Prophet of the Andes: An Unlikely Journey to the Promised Land.\"       \nThe Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com.\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jan2024",
        "header": "Shaping India’s digital landscape",
        "media": "Economic Times (E-Paper Edition)",
        "time": "January 11, 2024",
        "section": "ADVERTISEMENT",
        "length": "685 words",
        "byline": "Artha.Neog@timesgroup.com",
        "story_text": "Shaping India’s digital landscape\nEconomic Times (E-Paper Edition)\nJanuary 12, 2024 Friday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ADVERTISEMENT\nLength: 685 words\nByline: Artha.Neog@timesgroup.com\nHighlight: The AdTech landscape undergoes significant changes, driven by the fusion of AI and creativity\nBody\nAs the digital landscape continues its dynamic evolution,  the realm of advertising technology, also known as \nAdTech, stands poised for groundbreaking shifts. From the fusion of  artificial intelligence (AI) and creativity to the \nresurgence of contextual targeting, multiple trends are set to potentially alter the AdTech landscape.  In 2024, the \nIndian advertising market is expected to witness a growth of 11.4 percent and reach `1.22 lakh crore. Also, India is \npredicted to enter the top ten markets and rise to eighth place by 2028. The country was ranked as the 11th largest \nad market in the world as of last year. \nToday, it is crucial to understand and harness emerging trends for publishers and advertisers to stay ahead in the \ndynamic and competitive programmatic world. A KEY GROWTH LEVER As traditional cookies become irrelevant, \nembracing advanced AI techniques like agent-based modelling is essential for adaptable advertising. “Today, in the \npost-cookie era, advertisers must turn to AI-  driven contextual advertising, a potent tool for innovation in \nmanagement, robotics, and marketing. Contextual analysis, based on content rather than personal data, ensures \nprecision in ad positioning, brand safety, and real-time detection of malicious activities,” says, Arpit Jain, founder \nand CEO, PubScale and GreedyGame.  Besides AI, Generative AI (GenAI) can design and create ads that can be \nincorporated into an in-game setting. This will ensure that they are non-intrusive and engaging and help utilise the \nuntapped real estate in games. “In the dynamic realm of Adtech, AI  tools deftly navigate operational tasks, freeing \nmarketers to focus on creativity and strategy— nurturing innovation’s seeds. The investments in cutting-edge \nAdtech and strategic partnerships yield enhanced results, diminishing reliance on traditional manpower,” says, \nArchit Agarwal, founder and CEO, Tikshark Solutions.  The AdTech industry is evolving, and those at the forefront \nof these advancements can be expected to shape the future of  a more nuanced, user-centric, and ethically aligned \nadvertising ecosystem. Dhaval Gupta, MD of CMRSL, the parent company of CMGalaxy, says, “In addition to \ncreating content, analysing data, and automating multiple marketing processes, AI will play a key role in allowing \nmarketing teams to shift away from their day-today routine work and transition to focusing more on how their brands \ncan grow and what customers want.” Elaborating more, Vinod K Singh, cofounder, Concirrus UK, says, “Adtech’s \nfuture lies in AIpowered, hyperrelevant ads that adapt to your context in real-time.  Imagine dynamic visuals, copy, \nand interactions that change based on what you are browsing, watching, or even feeling.”  A PROFOUND \nTRANSFORMATION  In 2024, cutting-edge AdTech solutions facilitate the seamless integration of Augmented \nReality (AR) and Virtual Reality VR into existing advertising ecosystems, offering highly interactive and personalised \nconsumer experiences. As we enter 2024, the incorporation of AR and VR represents a paradigm shift in AdTech, \nreshaping  the landscape and paving the way for more engaging and innovative marketing strategies. “AR and VR \nenable immersive, interactive ad experiences, allowing users to engage with products and brands in virtual \nenvironments. Ingame ad creatives enabled by AR or VR will become an effective way to boost engagement \nwithout compromising on user experience,” shares Jain.  As we navigate the dynamic landscape AdTech trends in \n2024, it is evident that the industry is undergoing a  profound transformation. The spotlight is on crafting \nShaping India ’s digital landscape\nexperiences that are not only relevant and personalised but also deeply engaging, all within the framework of user \nprivacy and regulatory compliance.  “A diverse array of emerging AdTech trends is shaping the industry \nencompassing facets  like increased dependency on firstparty data, shift from English to local languages for \nfacilitating better communication, fostering brand transparency to boost loyalty, etc.,” concludes, Delphin Varghese, \ncofounder and chief business officer, AdCounty Media.\nLoad-Date: January 11, 2024"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "Myntra integrates ChatGPT with search for better product discovery",
        "media": "The Economic Times",
        "time": "May 24, 2023",
        "section": "TECH & INTERNET",
        "length": "512 words",
        "byline": " ",
        "story_text": "Myntra integrates ChatGPT with search for better product discovery\nThe Economic Times\nMay 25, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 512 words\nBody\nFashion ecommerce company Myntra said that it is integrating generative AI chatbot ChatGPT on its app for better \nproduct discovery.Myntra said MyFashionGPT will scout through catalogues available on the app to give users a \nbetter option for their queries.\"Many times people are figuring out in their own mind as to what they need for a \ncertain look or an occasion and then search for individual products. For example, I want a saree, blouse, jhumkas, \nred lipstick, sandals for a wedding. But now, with MyFashionGPT everything is coming under just one search: What \nto wear for a wedding?\" Myntra said in a statement.Also read | AI at warp speed: disruption, innovation, and what's \nat stake For example, customers can search for numerous scenarios, including looks based on local or global \ndestinations, such as a trip to Manali in December, social events such as weddings or haldi, celebrity styling ideas \nsuch as Tom Cruise's look in Mission Impossible, pairing ideas such as \"What to wear with pink Lehenga\" \netc.Based on the nature of the query, customers will be shown up to six ensemble options, including products \nacross multiple categories from topwear, bottomwear, footwear, and accessories to makeup, Myntra said.The AI-\nbased assistant can keep refining its results as follow-up queries are posted by the user.While Myntra claims to be \nthe first fashion and beauty ecommerce company to do this, others have already integrated ChatGPT's technology \nfor advanced search results. \nUS-based grocery delivery app Instacart uses the technology to curate food-related queries. The new product \ndiscovery feature is powered by OpenAI's large language model, ChatGPT 3.5. The user search is sent to the \nChatGPT model to fetch the looks for the user, creating appropriate prompts. The chatbot's response is then \nprocessed by Myntra's search ecosystem to show curated lists of products across multiple categories for the user's \nselected look, the company said.Going forward, Myntra plans to add voice search, conversational interaction (like \ntalking to a sales assistant), and personalisation of outfit recommendations. For example, if a user is searching for \nparty attire, the outfit's recommendations will use the customers' previous shopping history, styles and brand \npreferences as well as price points to show results. In addition, it will allow users to refine the results based on \nfurther inputs, in a conversational style. Users can access the MyFashionGPT feature on the Myntra app via 'M-\nXplore', the floating action button on the home page. Additionally, customers clicking the 'search bar' on the app to \ndiscover products will also see an option to try the MyFashionGPT feature. \"We are thrilled to introduce \nMyFashionGPT, our revolutionary ensemble suggestions feature powered by ChatGPT,\" said Raghu Krishnananda, \nchief product and technology officer, Myntra. \"It is a special launch as we are arguably the first fashion, beauty and \nlifestyle platform globally to roll out this feature to the entire customer base at this scale. For Reprint Rights: \ntimescontent.com\nLoad-Date: May 24, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "You Paid $1,000 for an iPhone, but Apple Still Controls It",
        "media": "The New York Times",
        "time": "December 8, 2023",
        "section": "TECHNOLOGY",
        "length": "1247 words",
        "byline": "Tripp Mickle, Ella Koeze and Brian X. Chen &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for",
        "story_text": "You Paid $1,000 for an iPhone, but Apple Still Controls It\nThe New York Times \nNovember 12, 2023 Sunday 12:13 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1247 words\nByline: Tripp Mickle, Ella Koeze and Brian X. Chen &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for \nThe Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and \npolitical challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and \nrobot taxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Ella Koeze is a reporter and graphics editor for the \nBusiness section. She previously worked at FiveThirtyEight.&lt;/p&gt; &lt;p&gt;Brian X. Chen is the lead consumer \ntechnology writer for The Times. He reviews products and writes &lt;a \nhref=&#34;https://www.nytimes.com/column/tech-fix&#34;&gt;Tech,  Fix&lt;/a&gt;, a column about the social \nimplications of the tech we use.&lt;/p&gt;\nHighlight: The company codes its devices with software that complicates repairs by triggering safety warnings and \nmalfunctions.\nBody\nFor a decade, it was easy to get help repairing an iPhone. Cracked screens could be replaced in minutes, and \nbroken cameras could be exchanged without a hitch.\nBut since 2017, iPhone repairs have been a minefield. New batteries can trigger warning messages, replacement \nscreens can disable a phone’s brightness settings, and substitute selfie cameras can malfunction.\nThe breakdowns are an outgrowth of Apple’s practice of writing software that gives it control over iPhones even \nafter someone has bought one. Unlike cars, which can be repaired with generic parts by auto shops and do-it-\nyourself mechanics, new iPhones are coded to recognize the serial numbers for original components and may \nmalfunction if the parts are changed.\nThis year, seven iPhone parts can trigger issues during repairs, up from three in 2017, when the company \nintroduced a facial recognition system to unlock the device, according to iFixit, a company that analyzes iPhone \ncomponents and sells parts for do-it-yourself repairs. The rate at which parts can cause breakdowns has been \nrising about 20 percent a year since 2016, when only one repair caused a problem.\nIn a series of tests, iFixit determines which parts cause issues when swapped between working iPhones of the \nsame model. The results reveal that the number of malfunctions has increased with later iPhone generations.\nThe software phenomenon, which is known as parts pairing, has encouraged Apple customers to turn to its stores \nor authorized repair centers, which charge higher prices for parts and labor. In recent years, only approved parts \nand sanctioned repairs have avoided the problems. Replacing a shattered screen typically costs nearly $300, about \n$100 more than work done by an independent shop using a third-party screen.\nTo put it another way: The cost of replacing a cracked screen on a year-old iPhone 14 is nearly equivalent to the \nphone’s value, which Apple appraises at $430 in trade-in credit.\nYou Paid $1,000 for an iPhone, but Apple Still Controls It\nApple’s grip on the repairs creates an incentive for customers to spend up to $200 on device insurance, known as \nAppleCare, which provides free battery replacements and screen repairs. Apple collects an estimated $9 billion \nannually for the service.\nIt has also spurred questions about Apple’s commitment to sustainability, with independent repair advocates saying \nthe company could more effectively meet its goals of reducing carbon emissions by lowering repair costs to \nencourage people to maintain devices rather than buy new ones.\nAn Apple spokesman said the company supported a customer’s right to repair a device and had created a self-\nservice repair program to help. “We have been innovating to offer our customers the best choice and options when \ntheir product needs service,” he said.\nState lawmakers from New York to California have responded with laws that aim to make repairs easier. The Biden \nadministration has encouraged the Federal Trade Commission to advance rules that would stop smartphone \nmakers from restricting independent repairs. But most of the regulations don’t include explicit restrictions on parts \npairing.\nUsing software to control repairs has become commonplace across electronics, appliances and heavy machinery \nas faster chips and cheaper memory turn everyday products into miniature computers. HP has used a similar \npractice to encourage people to buy its ink cartridges over lower-priced alternatives. Tesla has incorporated it into \nmany cars. And John Deere has put it in farm equipment, disabling machines that aren’t fixed by company repair \nworkers.\nApple and other companies have defended the practice by saying it protects customers’ safety and the company’s \nbrand. Shoddy parts, like a faulty face scanner, could compromise the phone’s security, and if an independent shop \nmesses up a repair, the customer often blames Apple instead of the shop, the company has said. The practice also \nallows Apple to create a record of parts in the device, which can be helpful to buyers of secondhand phones.\nBut the increase of pairing parts with software has animated a movement that wants to make repairs cheaper and \neasier. Proponents, which include iFixit, say it would be better for the environment and customers’ wallets to extend \nthe life of devices. They have urged lawmakers to simplify repairs, asking: “Who owns the device after it’s been \npurchased? The customer or the manufacturer?”\n“You basically have to ask permission before doing a repair,” said Nathan Proctor, who has lobbied states for repair \nlegislation on behalf of U.S. PIRG, a nonprofit largely funded by small donors.\nWhen Apple expanded its software limits in 2017, it upended repair businesses. Shakeel Taiyab said iPhone repairs \nat his independent shop in South San Francisco had decreased about 15 percent this year. Some customers with \nissues like cracked screens keep using the phones because they find repairing or replacing it unaffordable.\nFree Geek, a nonprofit based in Portland, Ore., that donates repaired computers and smartphones to \nunderprivileged people, decided that Apple’s software made iPhones too difficult to service, said Amber Brink, Free \nGeek’s director of technology.\nLast year, Free Geek received thousands of donated iPhones but repurposed only 280, Ms. Brink said. “It’s a \nheadache,” she added.\nConsumers who opt against paying top dollar for an Apple-authorized repair may suffer the consequences. In \nFebruary, after Gio Grimaldi, a 15-year-old in New Hampshire, shattered the screen of his iPhone SE on a \nsnowboarding trip, he took it to a nearby repair shop.\nHe said the closest Apple Store was 90 minutes away and had quoted $130 for replacing the screen — 40 percent \nhigher than the independent store. When he took the phone home, it worked fine but was lacking True Tone, a \nsoftware feature that adjusts the screen’s brightness and color to match the ambient lighting.\nYou Paid $1,000 for an iPhone, but Apple Still Controls It\n“That’s just plain stupid,” he said. “I always love Apple as a company, but they’re really stuck up about third-party \nrepairs.”\nOver the past year, New York, Minnesota and California passed bills requiring that electronics manufacturers \nprovide parts, tools and manuals to third parties.\nAfter years of lobbying against such rules, Apple signed on to support California’s law and honor it across the \nUnited States. It has also encouraged the federal government to adopt similar rules, said Brian Naumann, the head \nof Apple’s repair service efforts, who spoke about the right to repairs during a White House event last month.\n“Apple has taken significant steps to expand options for consumers to repair their devices, which we know is good \nfor consumers’ budgets and good for the environment,” Mr. Naumann said.\nBut the California legislation failed to directly address Apple’s practice of using software to control the repair \nprocess. In Oregon, State Senator Janeen Sollman, a Democrat representing an area outside Portland, is part of a \ngroup of lawmakers aiming to pass a state law that would prohibit Apple and others from having restrictions on \nrepairs.\nAs the Oregon legislation has progressed, Apple has encouraged lawmakers to scale it back. Apple paid for a half \ndozen legislators to visit its Silicon Valley headquarters this year, and tried to impress on them how important \nsecurity and safety were to repairs, Ms. Sollman said.\nShe left California unpersuaded. “I said, ‘You’re making it more accessible, but it’s not a true right to repair if you \nhave ultimate control,’” Ms. Sollman said.\nThis article appeared in print on page B1, B2.\nLoad-Date: December 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2024",
        "header": "Microsoft Makes a New Push Into Smaller A.I. Systems",
        "media": "The New York Times - International Edition",
        "time": "April 29, 2024",
        "section": "TECHNOLOGY",
        "length": "865 words",
        "byline": "Karen Weise and Cade Metz",
        "story_text": "Microsoft Makes a New Push Into Smaller A.I. Systems\nThe New York Times - International Edition\nApril 30, 2024 Tuesday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 865 words\nByline: Karen Weise and Cade Metz\nDateline: SEATTLE \nBody\nThe company that has invested billions in generative A.I. pioneers like OpenAI says giant systems aren't \nnecessarily what everyone needs.       \nIn the dizzying race to build generative A.I. systems, the tech industry's mantra has been bigger is better, no \nmatter the price tag.       \nNow tech companies are starting to embrace smaller A.I. technologies that are not as powerful but cost a lot less. \nAnd for many customers, that may be a good trade-off.       \nOn Tuesday, Microsoft introduced three smaller A.I. models that are part of a technology family the company has \nnamed Phi-3. The company said even the smallest of the three performed almost as well as GPT-3.5, the much \nlarger system that underpinned OpenAI's ChatGPT chatbot when it stunned the world upon its release in late 2022.       \nThe smallest Phi-3 model can fit on a smartphone, so it can be used even if it's not connected to the internet. And it \ncan run on the kinds of chips that power regular computers, rather than more expensive processors made by \nNvidia.       \nBecause the smaller models require less processing, big tech providers can charge customers less to use them. \nThey hope that means more customers can apply A.I. in places where the bigger, more advanced models have \nbeen too expensive to use. Though Microsoft said using the new models would be \"substantially cheaper\" than \nusing larger models like GPT-4, it did not offer specifics.       \nThe smaller systems are less powerful, which means they can be less accurate or sound more awkward. But \nMicrosoft and other tech companies are betting that customers will be willing to forgo some performance if it means \nthey can finally afford A.I.       \nCustomers imagine many ways to use A.I., but with the biggest systems \"they're like, 'Oh, but you know, they can \nget kind of expensive,'\" said Eric Boyd, a Microsoft executive. Smaller models, almost by definition, are cheaper to \ndeploy, he said.       \nMr. Boyd said some customers, like doctors or tax preparers, could justify the costs of the larger, more precise A.I. \nsystems because their time was so valuable. But many tasks may not need the same level of accuracy. Online \nadvertisers, for example, believe they can better target ads with A.I., but they need lower costs to be able to use the \nsystems regularly.       \n\"I want my doctor to get things right,\" Mr. Boyd said. \"Other situations, where I am summarizing online user reviews, \nif it's a little bit off, it's not the end of the world.\"       \nMicrosoft Makes a New Push Into Smaller A.I. Systems\nChatbots are driven by large language models, or L.L.M.s, mathematical systems that spend weeks analyzing \ndigital books, Wikipedia articles, news articles, chat logs and other text culled from across the internet. By \npinpointing patterns in all that text, they learn to generate text on their own.       \nBut L.L.M.s store so much information, retrieving what is needed for each chat requires considerable computing \npower. And that is expensive.       \nWhile tech giants and start-ups like OpenAI and Anthropic have been focused on improving the largest A.I. \nsystems, they are also competing to develop smaller models that offer lower prices. Meta and Google, for instance, \nhave released smaller models over the past year.       \nMeta and Google have also \"open sourced\" these models, meaning anyone can use and modify them free of \ncharge. This is a common way for companies to get outside help improving their software and to encourage the \nlarger industry to use their technologies. Microsoft is open sourcing its new Phi-3 models, too.       \n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)       \nAfter OpenAI released ChatGPT, Sam Altman, the company's chief executive, said the cost of each chat was \n\"single-digits cents\" - an enormous expense considering what popular web services like Wikipedia are serving up \nfor tiny fractions of a cent.       \nNow, researchers say their smaller models can at least approach the performance of leading chatbots like ChatGPT \nand Google Gemini. Essentially, the systems can still analyze large amounts of data but store the patterns they \nidentify in a smaller package that can be served with less processing power.       \nBuilding these models are a trade-off between power and size. Sébastien Bubeck, a researcher and vice president \nat Microsoft, said the company built its new smaller models by refining the data that was pumped into them, working \nto ensure that the models learned from higher-quality text.       \nPart of this text was generated by the A.I. itself - what is known as \"synthetic data.\" Then human curators worked to \nseparate the sharpest text from the rest.       \nMicrosoft has built three different small models: Phi-3-mini, Phi-3-small and Phi-3-medium. Phi-3-mini, which will be \navailable on Tuesday, is the smallest (and cheapest) but the least powerful. Phi-3 Medium, which is not yet \navailable, is the most powerful but the largest and most expensive.       \nMaking systems small enough to go directly on a phone or personal computer \"will make them a lot faster and order \nof magnitudes less expensive,\" said Gil Luria, an analyst at the investment bank D.A. Davidson.  \nLoad-Date: April 29, 2024"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "What Google Argued to Defend Itself in Landmark Antitrust Trial",
        "media": "The New York Times",
        "time": "November 15, 2023",
        "section": "TECHNOLOGY",
        "length": "1268 words",
        "byline": "Nico Grant and David McCabe",
        "story_text": "What Google Argued to Defend Itself in Landmark Antitrust Trial\nThe New York Times \nNovember 14, 2023 Tuesday 16:41 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1268 words\nByline: Nico Grant and David McCabe\nHighlight: The tech giant, which is wrapping up its arguments in the federal monopoly trial, has framed itself as a \ngood corporate citizen that has pushed innovation and helped consumers.\nBody\nThe tech giant, which is wrapping up its arguments in the federal monopoly trial, has framed itself as a good \ncorporate citizen that has pushed innovation and helped consumers.\nOver the past two and a half weeks, Google has called a dozen witnesses to defend itself against claims by the \nJustice Department and a group of state attorneys general that it illegally maintained a search and advertising \nmonopoly, in a landmark antitrust case that could reshape tech power.\nGoogle’s lawyers are set to wrap up their arguments in the case — U.S. et al. v. Google — on Tuesday, which will \nbe followed by a government rebuttal. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict next year after both sides summarize their cases in \nwriting and deliver closing arguments.\nThe company’s main defense has centered on how its actions were justified and how it helped consumers and \ncompetition. Here are Google’s main arguments.\nHow Google’s actions were justified\nIt paid Apple an appropriate (and undisclosed) amount of money\nThe heart of the U.S. case against Google is that the company paid Apple and other tech platforms to make itself \nthe default search engine on the iPhone and other devices, thereby keeping rivals from competing and stopping \nApple from potentially developing its own search product.\nBut on the witness stand, Sundar Pichai, Google’s chief executive, said there was “value” in being the default \nsearch engine on a device and framed the agreements with other companies as sound business decisions.\nGoogle paid $26.3 billion for its search engine to be the default selection on mobile and desktop browsers in 2021, \naccording to the company’s internal data presented during the trial. Most of that, around $18 billion, went to Apple, \nThe New York Times has reported. Kevin Murphy, a Google economic expert, testified on Monday that Google \nshared 36 percent of search revenue from the default deal with Apple.\nMr. Pichai testified that he repeatedly renewed the search engine deal with Apple because it worked well, leading to \nan increase in search usage and revenue and benefiting Apple, Google and its shareholders. He said Google paid \nApple so much to protect users’ search experience on iPhones, not knowing if Apple would degrade that experience \nif Google hadn’t improved the financial terms of the deal.\nWhat Google Argued to Defend Itself in Landmark Antitrust Trial\n“There was a lot of uncertainty about what would happen if the deal didn’t exist,” he said.\nGoogle is not the only search game in town\nTo rebuff the idea that other search engines were too small to compete for default status on browsers, Google’s \nlawyers argued at the trial that rivals had been able to win contracts but could not hold on to them because of the \npoor quality of their products.\nThey cited an instance in 2014 when Mozilla, which makes the Firefox browser, exited a default-search partnership \nwith Google and selected Yahoo.\nThe choice was unpopular with users and disastrous for the Firefox browser, Mitchell Baker, Mozilla’s chief \nexecutive, said in a deposition that was played at the trial. Yahoo’s user experience deteriorated and became \noverloaded with ads, she said, and it was “heartbreaking” to send users to Yahoo. Mozilla returned to Google in \n2017.\nGovernment lawyers pointed to Google’s more than 90 percent market share in search as evidence that the \ncompany’s actions stifled meaningful competition. But Google’s lawyers said its search market share was only part \nof the story, because the company competed broadly with more players, including TikTok and Amazon, where \nconsumers look for information online.\nThe government also accused Google of abusing its position in the online ad market. Google again sought to widen \nthe aperture at trial, saying it was vying for ad spending that could have otherwise gone to any company from \nExpedia to Meta, which owns Facebook and Instagram.\nHow Google helped people and fostered competition\nIt has invested more than search rivals in making its product great\nOne thrust of Google’s defense was that its focus and investments in search did not harm consumers and others, \nas the government has tried to argue, but instead brought benefits.\nOn more than one occasion, Google referred to the sums of money it spent on research and development. Last \nyear, the figure totaled about $40 billion. Prabhakar Raghavan, Google’s head of search, testified that such \ninvestments helped the company deliver the best technology to users.\n“It would be foolish of us to not put our best foot forward,” he said. That was the reason Google employed 8,000 \nengineers and product managers for its search engine, including about 1,000 people focused on quality, he added.\nGoogle argued that its rivals had not invested in the same way. When questioning Satya Nadella, Microsoft’s chief \nexecutive, earlier in the trial, a Google lawyer pushed him on whether Microsoft still devoted fewer employees to its \nsearch engine, Bing, than Google did to its search product. Mr. Nadella avoided the specifics of Microsoft’s \npersonnel and said the company was investing mainly in core areas of the search business.\nIts innovations have helped consumers around the world\nGoogle said it had set the pace for tech advancements. It said it had updated its Chrome browser every six weeks, \nmore frequently than Microsoft had traditionally updated its browser, Internet Explorer. It has introduced Android \nfeatures that forced Apple to respond, resulting in more apps and other smartphone features, Mr. Pichai testified in \nthe trial.\nDuring cross-examinations, Justice Department lawyers sought to underscore that Google could have brought more \ninnovation to users but did not so it could safeguard its monopoly. They pointed to a 2019 Google proposal to \ncreate an incognito search engine, which would not have stored any data on users but could have lost the company \nbillions in revenue. Google decided not to build the browser.\nWhat Google Argued to Defend Itself in Landmark Antitrust Trial\nJustice Department lawyers sought to highlight Google’s delay in bringing generative artificial intelligence to \nusers, sitting on the technology until OpenAI released ChatGPT last November. It was part of a broader \ngovernment argument that Google had not adequately improved products for consumers until it felt competitive \npressure.\nThe government has also accused Google of using its power in search and ads to raise ad prices when it faces a \nrevenue crunch. The company’s employees testified that it balanced its pursuit of revenue from each ad with \nensuring that users generally saw high-quality ads in its search results.\nIts actions have been competitive on balance, not anticompetitive\nThe Justice Department argued in the trial that Google’s actions harmed competition and denied benefits to \nconsumers. If the government proves that harm exists, it is then up to Google to prove that those harms were \noutweighed by benefits to competition created by its actions.\nTo that end, Google focused in the trial on when it introduced its search engine and other products and how its \nentry into those markets increased competition.\nWhen Google rolled out its search engine in 1998, it was to a search market that was ruled by Yahoo, AltaVista and \nAsk Jeeves, the company argued. Its Chrome browser, which debuted in 2008, disrupted a browser market where \nMicrosoft’s Internet Explorer reigned supreme, Google said. And it fostered more competition against Apple’s \niPhone with the Android operating system, which it introduced in 2008, the company said.\nCecilia Kang contributed reporting.\nCecilia Kang contributed reporting. \nThis article appeared in print on page B4.\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "it,_says_OpenAI's_Jason_Kwon_Feb2024",
        "header": "ET Now GBS 2024: AI is a global issue, we need a global approach to govern",
        "media": "it, says OpenAI's Jason Kwon",
        "time": "February 10, 2024",
        "section": "INDIA",
        "length": "690 words",
        "byline": " ",
        "story_text": "ET Now GBS 2024: AI is a global issue, we need a global approach to govern \nit, says OpenAI's Jason Kwon\nThe Economic Times\nFebruary 11, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: INDIA\nLength: 690 words\nBody\nCountries and global institutions must work together to harmonise efforts to tackle issues around artificial \nintelligence (AI), and India has a major part to play in this conversation, OpenAI chief strategy officer Jason Kwon \nsaid on Saturday.\"AI is a global issue, and we need a global approach to govern it,\" he said.Countries have \nhistorically come together to address problems of health, trade and natural resources, he said, adding that they now \nhave to similarly join forces through institutions that underpin the international order and rule of law to coordinate in \nthe matter of AI governance.\"We want to work closely with you to figure out a path forward,\" he said.Kwon also \nannounced that OpenAI will hold a number of developer summits in India this year. It plans to foster collaboration \nbetween Silicon Valley developers and local developers that will \"put us on a path for building the tools and define \nour future\".\"Our plan is to convene developers around the country to work alongside OpenAI's product leaders on \nsome of the most difficult challenges in AI,\" he said.Kwon said the country has the world's largest developer \ncommunity, some of the most impressive talent in the field, a track record of developing extraordinary technology \nbusinesses and a relentless focus on competing on the world stage.\"India has the key ingredients of being one of \nthe world's leaders in AI,\" he said, adding that OpenAI wants to continue to invest in the developer community \nhere.OpenAI, he said, also understood the role that ChatGPT can play in closing one of the main barriers in the \nstartups segment - the demand for code.\"Startups understand market gaps and build innovative products to fill \nthem. \nTools like ChatGPT help accelerate startups and unlock new ones in several ways,\" Kwon said.On his India visit, he \nwill be meeting with entrepreneurs who are creating AI-powered products that will enable India to experience the \nvalue of the technology, he said.In the private sector, AI can make completing tasks 25% faster and improve quality \nby 40%, Kwon said, citing research. It reduces the cost of intelligence by making writing code faster, freeing up \nengineers for other tasks, and simplifies computing interfaces and makes them more accessible globally, he \nsaid.\"When you break down these barriers, you can make it possible to access more services that are critical to \nhuman welfare in the digital age,\" he said.He also said that unlocking the potential of AI requires an \"intense focus\" \non safety and that safety and product development are intertwined rather than separate.\"AI safety must be \nglobalised,\" Kwon said, adding that safety features must be ensured across countries and languages.OpenAI has \nseen \"promising early results\" with a safeguarding tool it is developing ahead of elections in several countries such \nas the US and India to address fake or inaccurate images, he said.More than a year after the introduction of \nOpenAI's generative AI platform ChatGPT to the world, its transformative power has become visible, according to \nKwon. He said ChatGPT has helped people experience AI not as behind-the-scenes abstraction but as a real and \ntangible tool.It has helped people solve real problems in previously unimaginable ways, he said, adding that around \n90% of Fortune 500 companies now build using OpenAI products.\"Reducing language barriers like this is one of the \nsuperpowers of large language models,\" Kwon said, pointing to GPT-powered farmer chatbot by Digital Green, \nwhich helps farmers in multiple languages to navigate climate change, implement best practices and bring their \ncrops to market. The bot delivers information in languages including Hindi, Kannada and Assamese, and reduces \nthe cost of traditional extension services by 99%, Kwon said.Large language models can also build on the Indian \nET Now GBS 2024: AI is a global issue, we need a global approach to govern it, says OpenAI's Jason Kwon\ngovernment's national language translation initiative Bhashini, he said.In the field of healthcare, ChatGPT has been \nused by the Bill and Melinda Gates Foundation to facilitate communication with frontline workers to improve care for \npregnant and postpartum women, Kwon said. For Reprint Rights: timescontent.com\nLoad-Date: February 10, 2024"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Google Head Runs Gantlet Of Testifying On 2 Coasts",
        "media": "The New York Times",
        "time": "November 15, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1483 words",
        "byline": "By Nico Grant",
        "story_text": "Google Head Runs Gantlet Of Testifying On 2 Coasts\nThe New York Times\nNovember 15, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1483 words\nByline: By Nico Grant\nBody\nSundar Pichai, Google's chief executive, testified on Tuesday for the second time in two weeks to defend his \ncompany against monopoly claims.\nTwo weeks ago, Google had a big day in Washington. President Biden signed an executive order to create artificial \nintelligence safeguards that could affect Google's most pressing projects, and Secretary of State Antony J. Blinken \ngave the company an award for its work in aiding Ukrainian refugees and promoting women's economic security. \n  Sundar Pichai, Google's chief executive, had spent much of the day on a witness stand at a federal courthouse \nabout two miles from the White House, defending his company from claims that it crushed rivals in the search and \nonline advertising markets.\n  On Tuesday, Mr. Pichai testified again, this time in San Francisco, to confront claims brought by the video game \ncompany Epic Games that his company broke the law, wielding monopolistic power over app developers on \nAndroid's Google Play Store.\n  Mr. Pichai over the last month has become the face of Google's antitrust court fights on both sides of the country. \nAnd his visits to the witness stand underscore the growing importance for Big Tech leaders to be sharp witnesses \nfor their companies, whether in an antitrust trial or in hearings on Capitol Hill.\n  Testifying under oath is a task that many tech chief executives might be asked to do in the coming years, with \nAmazon, Meta and others facing their own antitrust court fights. It is not a task at which many executives have \nexcelled.\n  Though he was never called to the witness stand to testify, Bill Gates, who was chief executive of Microsoft in the \nlast big technology antitrust case brought by the Justice Department more than two decades ago, came across as \ncombative and evasive in depositions.\n  Over the last few years, executives including Mark Zuckerberg and OpenAI's Sam Altman (and, of course, Mr. \nPichai) have been asked to testify before Congress for various reasons, with varying degrees of success. Mr. \nZuckerberg has at times exasperated lawmakers with vague responses, while Mr. Altman appeared to charm \nsenators in a hearing this year.\n  The main duty on the witness stand for Mr. Pichai -- a low-key and detail-focused executive -- has been to keep \nthe temperature low under questioning and keep to the central point of Google's antitrust defense: that it is an \ninnovative company that has maintained its leadership through innovation and hard work instead of illegal \nmonopolistic behavior.\nGoogle Head Runs Gantlet Of Testifying On 2 Coasts\n  On Tuesday, Mr. Pichai ran into aggressive questioning by a lawyer for Epic, Lauren Moskowitz, who asked him to \nprovide yes-or-no responses.\n  That led to at least one small revelation: Mr. Pichai confirmed that his company gave Apple 36 percent of the \nsearch revenue generated on iPhones, and said the total payment ''was well over $10 billion'' last year. Ms. \nMoskowitz asserted that the figure was at least $18 billion.\n  Lawyers for Google and Apple fought on Tuesday morning to keep the figures concealed, emphasizing a need for \ncorporate privacy that has carried through both of Google's trials. Judge James Donato rejected their requests, \nsaying, ''Just coming in and saying we're kind of sensitive with this isn't going to fly.''\n  Ms. Moskowitz was trying to counter Google's claim that it cannot be considered a monopoly because of its rivalry \nwith Apple. If that were the case, she argued, why did it give Apple preferential treatment over other companies like \nSamsung, which she said received a 16 percent share of the search revenue from its devices?\n  ''We compete fiercely with Apple, at the operating system, the smartphone and the app store level,'' Mr. Pichai \nsaid later, when questioned by a Google lawyer. ''The competition has been good for consumers and developers.''\n  The Justice Department filed its landmark antitrust suit against Google in October 2020, arguing that the \ncompany's default-search deals with phone makers and browser companies helped it illegally maintain a monopoly.\n  Google called Mr. Pichai, 51, to the stand two weeks ago. Rather than sit in the witness box, Mr. Pichai stood at a \nlectern for almost four hours, wearing a microphone, as though he were delivering a speech at a corporate \nconference. His handlers said he had to stand because of a sprained lower back.\n  He spoke of his background, getting a telephone as a preteen in Chennai, India, and understanding then the \npower of technology, before he deftly answered questions about his company's competitive standing, relationship \nwith Apple and the default-search contracts the government argues were illegal.\n  Mr. Pichai tried to refute the government lawyer's arguments that Google paid Apple billions of dollars a year to \nkeep it out of the search market. He presented a different story, saying his company wanted to be the iPhone's \ndefault search engine because of the ''value'' of that spot, and the need to ensure Apple would safeguard the user \nexperience.\n  ''I felt the deal had done well since 2016,'' Mr. Pichai said. ''It was continuing to increase search usage, search \nrevenue.''\n  In cross-examination, Mr. Pichai repeated the rationale for the deal so many times that for a moment, he seemed \nto lose patience with the line of questioning, saying, ''I just gave all the reasons'' for the deal.\n  Adam Kovacevich, a tech industry lobbyist at the Chamber of Progress who spent 12 years working at Google, \nsaid Mr. Pichai's testimony gave the court a high-level view of how the company made strategic decisions.\n  ''He did fine,'' Mr. Kovacevich said of Mr. Pichai's performance. ''The biggest thing to me is when you're in that \nposition, your first objective is to not be Bill Gates in the Microsoft trial. Your No. 1 objective is to come off as \nresponsive and reasonable.''\n  Excerpts from Mr. Gates's combative, videotaped testimony were shown in court more than two decades ago. The \nMicrosoft co-founder, antitrust lawyers say, undermined his and his company's credibility with the judge in the case.\n  In San Francisco, Mr. Pichai was questioned on topics ranging from why he erroneously marked emails as subject \nto attorney-client privilege (to prevent them from being forwarded) to whether Facebook and Amazon could have \nprovided competition to Google's Play Store when they had smartphone ambitions.\n  ''There are nuances in these questions,'' he said with a smile when Ms. Moskowitz started to speak over him. ''I'm \ntrying to answer your question.''\nGoogle Head Runs Gantlet Of Testifying On 2 Coasts\n  Several times, Judge Donato asked Ms. Moskowitz to ''be quiet'' to let Mr. Pichai speak.\n  There will be one big difference between the lawsuits: The antitrust trial in Washington does not have a jury. The \ndecision will be made by a judge. In San Francisco, Mr. Pichai had to appeal to a nine-person jury that could be \nopen to the idea that a giant tech company is exploiting much smaller outfits. Tim Sweeney, Epic's chief executive, \nis also expected to testify in the trial.\n  Google and Epic declined to comment.\n  Epic, the maker of the hit game Fortnite, brought the claim against Google in 2020, in an attempt to sidestep the \n15 to 30 percent fees from subscriptions and in-app purchases that it must pay Google.\n  The game developer antagonized Google and Apple by telling users to pay for in-app transactions directly through \nEpic. In response, Google and Apple suspended Fortnite from their app stores. Epic claims Google also bullied \nother companies to force them to drop deals with Epic before it was banned from the app stores.\n  Google faces another Justice Department antitrust lawsuit that accuses it of illegally abusing its monopoly power \nover the technology that delivers ads online.\n  A trial in that case could begin as soon as next year, but it is too early to know whether Mr. Pichai will be called to \ntestify.\n  Mr. Pichai has tried to prevent Google employees from being distracted by the litigation. He has encouraged them \nto ''keep doing what you're doing'' and has allocated a relatively small number of employees to work on the Justice \nDepartment case -- hundreds out of more than 180,000.\n  But Mr. Pichai's court appearances have taken time away from his other obligations as a company leader, \nincluding his plan to reclaim Google's primacy in the fast-growing field of generative A.I.\n  In the middle of Mr. Pichai's October testimony, the secretary of state, Mr. Blinken, was honoring Google's \nsubsidiary in Poland for its work in fostering women's economic security and helping Ukrainian refugees. Hours \nlater, Mr. Biden hosted a signing ceremony at the White House, but Mr. Pichai's handlers could not R.S.V.P. yes \nbecause there was a chance he might have still been in court when it began.\n  ''It's not the best use of his time,'' Richard Kramer, an analyst at Arete Research, a London-based investment \nresearch firm, said in an interview. ''No C.E.O. wishes to spend their time being grilled by government lawyers.''\nhttps://www.nytimes.com/2023/11/14/technology/sundar-pichai-google-antitrust-testimony.html\nGraphic\n \nPHOTO: Sundar Pichai, Google's chief, testified in San Francisco on Tuesday. (PHOTOGRAPH BY JIM \nWILSON/THE NEW YORK TIMES) (B4) This article appeared in print on page B1, B4.               \nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_May2024",
        "header": "Did You Make Your Connecting Flight? You May Have A.I. to Thank.",
        "media": "The New York Times - International Edition",
        "time": "May 19, 2024",
        "section": "TRAVEL",
        "length": "1237 words",
        "byline": "Julie Weed",
        "story_text": "Did You Make Your Connecting Flight? You May Have A.I. to Thank.\nThe New York Times - International Edition\nMay 20, 2024 Monday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TRAVEL\nLength: 1237 words\nByline: Julie Weed\nBody\nABSTRACT\nAirlines are using artificial intelligence to save fuel, keep customers informed and hold connecting flights for delayed \npassengers. Here's what to expect.\nFULL TEXT\n         May 12,2024, Sunday         Online Correction:              \nThis article has been revised to reflect the following correction: An earlier version of this article, in a quotation from \nVikram Baskaran, vice president for information technology services at Alaska Airlines, misstated the number of \ngallons of fuel an artificial-intelligence-powered planning system saved the airline in 2023. It was half a million, not \nhalf a billion. \nCORRECTION APPENDED \nAirlines are using artificial intelligence to save fuel, keep customers informed and hold connecting flights for delayed \npassengers. Here's what to expect.       \nLast month in Chicago, a United Airlines flight to London was ready to depart, but it was still waiting for 13 \npassengers connecting from Costa Rica. The airline projected they'd miss the flight by seven minutes. Under \nnormal circumstances, they'd all be scrambling to rebook.       \nBut thanks to a new artificial-intelligence-powered tool called ConnectionSaver, the jet was able to wait for them - \ntheir checked bags, too - and still arrive in London on time. The system also sent text messages to the late-arriving \npassengers and the people on the waiting jet to explain what was happening.       \nA.I. still might not be able to find space for your carry-on, but it could help put an end to the 40-gate dash - sprinting \nto catch your connecting flight before the door slams shut - as well as other common travel headaches.       \nIt's not just United. Alaska Airlines, American Airlines and others have been working to develop new A.I. capabilities \nthat could make flying easier for passengers. The carriers are also using the technology to reduce costs and \nstreamline operations, including saving fuel, said Helane Becker, an airline industry analyst for the investment bank \nTD Cowen. Although many of the airlines are developing their programs independently, a successful innovation by \nany carrier could possibly become an industry standard.       \nDid You Make Your Connecting Flight? You May Have A.I. to Thank.\nA.I. is poised to change almost every aspect of the customer flying experience, from baggage tracking to \npersonalized in-flight entertainment, said Jitender Mohan, who works with travel and hospitality clients at the \ntechnology consulting company WNS.       \nSaving fuel and frustration\nA.I. has been helping Alaska Airlines dispatchers plan more efficient routes since 2021. \"It's like Google maps, but \nin the air,\" explained Vikram Baskaran, vice president for information technology services at the carrier.       \nTwo hours before a flight, the system reviews weather conditions, any airspace that will be closed, and all \ncommercial and private flight plans registered with the Federal Aviation Administration, to suggest the most efficient \nroute. The A.I. takes in \"an amount of information no human brain could process,\" said Pasha Saleh, the corporate \ndevelopment director and a pilot for Alaska.       \nIn 2023, about 25 percent of Alaska flights used this system to shave a few minutes off flight times. Those \nefficiencies added up to about 41,000 minutes of flying time and half a million gallons of fuel saved, Mr. Baskaran \nsaid.       \nOn the ground,American Airlines and others are working on an A.I.-powered system American calls Smart Gating - \nsending arriving aircraft to the nearest available gate with the shortest taxiing time, and if the scheduled arrival gate \nis in use, quickly determining the best alternate gate. All this could mean fewer frustrating minutes spent waiting on \nthe tarmac.       \nAmerican introduced Smart Gating at Dallas Fort Worth International Airport in 2021 and now employs it at six \nairports, including Chicago O'Hare and Miami International. The airline estimates it saves 17 hours a day in taxi \ntime and 1.4 million gallons of jet fuel a year.       \nMr. Mohan said that using A.I. as a virtual parking attendant could save up to 20 percent of taxiing time, with the \nhighest benefits seen at the largest airports.       \nFaster and better customer service\nRapidly evolving generative A.I. - think ChatGPT - is helping airlines communicate with passengers better. At \nUnited, a companywide challenge last year yielded a plan to make texts sent to fliers more specific about what's \ncausing delays. Passengers can get frustrated when flights are delayed with no explanation, said Jason Birnbaum, \nUnited's chief information officer.       \nBut tracking the details required, composing an appropriate message and sending it to the right people for 5,000 \nflights a day would be too much for the staff to handle, Mr. Birnbaum said. Generative A.I. can process all that data \nand create messages tailored to conditions. For example, passengers booked on a January United flight from San \nFrancisco to Tucson received this text message, along with a new departure time and an apology: \"Your inbound \naircraft is arriving late due to airport runway construction in San Francisco that limited the number of arrivals and \ndepartures for all airlines earlier.\"       \nHaving a more detailed explanation can calm travelers' nerves. Jamie Larounis, a travel industry analyst who flies \nabout 150,000 miles a year, recalled receiving text messages last summer explaining that a storm and a related \ncrew-scheduling problem had delayed his flight from Chicago. \"Getting a specific reason for the delay made me feel \nlike the airline had things under control,\" he said.       \nGenerative A.I. is also good at summarizing text, making it a powerful tool for wading through emails. Last year, \nAlaska was among the carriers that began using A.I. to handle customer messages more efficiently. The airline's \nsystem \"reads\" each email and summarizes the issues raised.       \n\"We used to read first in first out, handling the requests as they came in,\" said Mr. Baskaran, but now the system \nhelps prioritize emails. For example, an urgent request involving an upcoming flight may take precedence over a \ncomplaint about a past one.       \nDid You Make Your Connecting Flight? You May Have A.I. to Thank.\nThe system also helps a human agent decide how to respond, such as offering the customer a voucher, and it may \ndraft an initial written response. \"The person makes the decision, but it's streamlined,\" Mr. Baskaran said.       \nFor all the benefits A.I. promises to airlines and passengers, the technology still has some shortcomings. For one, it \ndoesn't always deliver accurate information. In 2022, an Air Canada chatbot incorrectly promised a traveler that if \nhe booked a full-fare flight to a relative's funeral, he could receive a bereavement fare after the fact. When he filed a \nsmall-claims case, Air Canada tried to argue that the bot was its own separate entity, \"responsible for its own \nactions,\" but a tribunal found Air Canada responsible and ordered it to pay about $800 in damages and fees.       \nStill, as A.I. develops and airlines race to find more uses for it, passengers could see even more benefits. \"As a \ncustomer and a business person, this is one of the biggest technology disruptions in the last five to eight years,\" Mr. \nMohan said.              \nFollow New York Times Travel on Instagram and sign up for our weekly Travel Dispatch newsletter to get expert \ntips on traveling smarter and inspiration for your next vacation. Dreaming up a future getaway or just armchair \ntraveling? Check out our 52 Places to Go in 2024.\nLoad-Date: May 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "Lessons From a Law Firm’s Decision to Leave China; DealBook Newsletter",
        "media": "The New York Times",
        "time": "August 9, 2023",
        "section": "BUSINESS; dealbook",
        "length": "2045 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni",
        "story_text": "Lessons From a Law Firm’s Decision to Leave China; DealBook Newsletter\nThe New York Times \nAugust 9, 2023 Wednesday 10:04 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 2045 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni\nHighlight: Dentons’ decision to quit the country and new investment limits by the Biden administration underscore \nthe growing challenges facing Western companies there.\nBody\nDentons’ decision to quit the country and new investment limits by the Biden administration underscore the growing \nchallenges facing Western companies there.\nDoing business in China is getting even harder\nThe Biden administration is expected to announce new restrictions today on investing in China, its latest effort to \nprevent Beijing from accessing advanced technologies that could be used by its military.\nThe new measures add to the challenges facing the world’s second-largest economy as it faces a post-pandemic \nslowdown. But they also highlight the growing difficulties for and global companies operating in China, a day after a \nmajor Western law firm said it would leave the country.\nThe rules will focus on high-tech sectors. Biden’s executive order will bar private equity and venture capital firms \nfrom investing in Chinese industries including quantum computing, artificial intelligence and advanced \nsemiconductors, people familiar with the deliberations told the Times.\nChina’s economy is already being squeezed. Official data released today showed the country had fallen into \ndeflation last month, a day after Beijing reported that trade had plummeted by the most since the start of the \npandemic.\nBusinesses that bet big on China are caught in the middle. Dentons, the largest Western law firm in China in terms \nof staff, said yesterday it would separate from Dacheng, its unit there. The two firms merged in 2015, and Dentons \neven added Chinese characters to its logo to signal its commitment to the country.\nChina’s new counterespionage law has made operating there more difficult. It banned the transfer of any \ninformation related to national security — but did not define which data would fall under this rubric. The law also \nallowed authorities to access data, electronic devices and personal property, as well as to block individuals from \nleaving the country.\nThat made it impossible to follow legal industry standards and best practice, a person familiar with Dentons’ \ndecision-making told DealBook. For example, a provision that requires Chinese firms to keep the names of clients \nand employees secret from foreign entities raised thorny issues for American lawyers, who must check for conflicts \nwith existing clients before taking on a new one.\nThese problems are widespread across industries. “Standards are diverging between China and Western \neconomies,” Eswar Prasad, a trade policy professor at Cornell and a former head of the I.M.F.’s China division, told \nLessons From a Law Firm’s Decision to Leave China DealBook Newsletter\nDealBook. “It’s all driven by the phenomenon that China is not as open to foreign business as it once professed to \nbe.”\nChinese authorities have raided the offices of Western-linked consulting firms in recent months, and the venture \ncapital firm Sequoia broke off its unit in the country in June. Employees at financial firms operating in China have \nreportedly been forced to attend lessons in the ideology of President Xi Jinping.\nBut the Chinese market may still be too big to ignore. Keyu Jin, an economist and the author of “The New China \nPlaybook,” said companies operating there have always had to balance competing needs. “Consumer companies \nhave big dreams in China,” she told DealBook. “Foreign financial institutions eye significant returns on the trillions of \nhousehold wealth that needs to be managed.”\nChina is a major economy and foreign businesses will continue to work there, Prasad added, even if it’s becoming \n“quite a fraught proposition.”\nHERE’S WHAT’S HAPPENING \nA warning from Moody’s drags down bank stocks. The credit ratings agency put shares of six major lenders on \nwatch for a potential downgrade, and cut the ratings of several regional banks, citing lower income and higher \nfunding costs tied to rising interest rates. Shares in firms like Bank of New York Mellon and Cullen/Frost Bankers \nfell as much as 2.8 percent.\nRegulators fine financial companies $549 million over misuse of messaging apps. Eleven institutions, including \nWells Fargo and BNP Paribas, were accused by the S.E.C. and the Commodities Futures Trading Commission of \nfailing to police employees’ use of “off-channel” services like WhatsApp for business communications. Wall Street \nbanks had already paid $1.8 billion in fines for similar violations last year.\nWeWork raises questions about its future. The beleaguered co-working company said in a regulatory filing that it \nfaces “substantial doubt” about its ability to continue as a going concern, the starkest sign yet that it may collapse. \nWeWork shares, which were already trading for pennies, fell more than 16 percent after market hours on the news.\nESPN gets into the sports-betting business. The Disney-owned sports network struck a 10-year deal with Penn \nGaming, which will operate an online sports book and pay ESPN $1.5 billion for access to its brand, marketing and \ntalent for promotional purposes. The transaction will replace the sports book’s previous brand, Barstool Sportsbook, \nwith ESPN Bet; relatedly, Penn will sell Barstool Media back to its founder, Dave Portnoy.\nChipotle’s founder raises money for his second act\nThirty years ago, Steve Ells opened the first Chipotle in Denver and went on to build a $51 billion fast-casual dining \ngiant. Now he is working on his next act: a quick-serve, plant-based restaurant concept that relies on automation.\nThat start-up, Kernel, has raised $36 million in Series A financing, DealBook’s Michael de la Merced is first to \nreport. That will help the company open its first location in New York City this fall — and develop technology it can \neventually license to others.\nHow Kernel works: It’s a hub-and-spoke model, with a central kitchen that does much of the prep work throughout \nthe day. The food is then biked to restaurants; there, machines and a small crew of humans assemble everything \nfor customers.\nThe restaurant will offer an array of plant-based dishes, including a crispy faux-chicken sandwich, a veggie burger \nand a chicken Caesar salad without, well, chicken. (The focus on plants is meant to be eco-friendly, though Ells \nconcedes that it was hard to create dishes that appealed broadly.)\nKernel builds on lessons Ells learned from Chipotle. When he began the start-up after leaving Chipotle three years \nago, he focused on improving efficiency, speed and food quality through software and automation.\nLessons From a Law Firm’s Decision to Leave China DealBook Newsletter\nThe result, Ells said, is a chain that can operate smaller restaurants in more locations (since they don’t need bulky \nkitchen equipment) and be more consistent in meal quality. It also needs fewer employees, but Ells said that Kernel \nwill be able to pay them more.\nThe fund-raising effort came after two years of self-financing by Ells. He secured investments from groups including \nRaga Partners, Willoughby Capital, Rethink Food and Virtru. \nWhat next? Kernel will open its first restaurant this fall, and has ambitions to operate 15 locations within two years.\nEventually it could license its technology to other chains. “There’s no question that more and more automation is \ngoing to make its way into restaurants,” Ells said. Of Kernel, he added, “Once the hard work is done, once the \nplatform is proven, it’s very, very simple to replicate.”\nHow media giants are trying to stay on top of A.I.\nAs the corporate world reckons with the disruption posed by artificial intelligence, some media giants are reportedly \nworking on ways to marshal the fast-evolving technology — even as many of the artists they work with remain \nskeptical.\nUniversal Music is in talks with Google over licensing “deepfake” work, according to The Financial Times. If \nsuccessful, that could lead to tools that would allow consumers to use imitations of singers’ voices and melodies in \nnew work, paying owners for the right to do so. (Artists could choose to opt in.)\nUniversal Music has been worried about tech companies exploiting works by its artists — who include Drake and \nTaylor Swift — without compensation. And Google is hoping that new A.I. tools will keep it competitive with the likes \nof Microsoft.\nMeanwhile, Disney has created an A.I. task force, according to Reuters. The group is meant to figure out how to \ndeploy the technology across the Disney empire, from its movie and TV studios to its ad business. The company \nhas almost a dozen job listings seeking experts in A.I. or machine learning.\nThe technology could help Disney tame soaring production budgets for its movies, an unnamed company executive \ntold Reuters, as well as create new attractions for its theme parks.\nBut getting talent on board may be challenging. Musicians, including Drake (whose voice was mimicked on an \nunlicensed hit single in April), have complained that generative A.I. could deprive them of pay and undercut their \nown work. And among the demands of the striking Hollywood writers’ and actors’ unions are guardrails that limit \nmovie studios’ ability to use A.I. to replace humans.\nNot all artists are against the adoption of A.I. The singer Grimes, who has said she’s open to licensing her voice for \nuser-generated work, told Wired that there were potential benefits to such an arrangement. \nSome executives think it’s possible to strike a balance. “With the right framework in place, A.I. will enable fans to \npay their heroes the ultimate compliment through a new level of user-driven content,” Robert Kyncl, the C.E.O. of \nWarner Music (which is also reportedly in talks with Google), told investors yesterday.\nBut Kyncl added, “The thing that is important is that artists have a choice, because there are some that may not like \nit, and that’s totally fine.”\nThe legal fight against corporate diversity policies ramps up\nEven before conservative activists scored a win when the Supreme Court struck down affirmative action at \nuniversities, they began taking on initiatives meant to increase diversity across corporate America.\nThese campaigners are arguing that policies aimed at improving diversity, equity and inclusion — known as D.E.I. \n— violate rules meant to protect against race and sex discrimination. And, according to The Wall Street Journal, \nthey’re seeing results:\nLessons From a Law Firm’s Decision to Leave China DealBook Newsletter\nComcast settled a case accusing it of illegally favoring minority-owned small-business customers with grants and \nmarketing advice. Amazon has been sued in Texas over a program offering an extra $10,000 to Black- or Latino-\nowned delivery-service contractors. Starbucks directors and executives are being sued by a shareholder arguing \nthey violated their duty to investors by supporting diversity policies. …\nCompanies say their initiatives fall within the law. Many say they remain committed to increasing the demographic \ndiversity of their workforces and suppliers, citing business benefits and the hurdles some groups continue to face in \nAmerican corporations. Privately, many are asking their lawyers if and how much they should modify their methods \nin light of the affirmative-action decision.\nTHE SPEED READ \nDeals\n• Abu Dhabi’s state-owned oil company, Adnoc, has reportedly assembled a team to invest $50 billion in deals \nto diversify its business. (FT)\n• The chairman of L’Occitane is said to be in talks to take the skin-care company private at a valuation of about \n$6.5 billion. (Bloomberg)\n• David Kurtz, the former head of Lazard’s restructuring practice who has worked on some of the biggest \ncorporate bankruptcies, has joined the financial advisory firm Hilco. (Reuters)\nPolicy\n• The Supreme Court temporarily revived the Biden administration’s regulations for so-called ghost guns, which \nare built from kits ordered online and are largely untraceable. (NYT)\n• The Italian government partially backtracked on its plans for a windfall tax on banks, after lenders’ stocks slid \nwhen the initial policy was announced. (FT)\nBest of the rest\n• Some Hollywood productions are being allowed to continue, despite the writers’ and actors’ strikes — and it’s \nnot always clear why. (NYT)\n• A 143-year-old portrait of an obscure government official has set off a turf war between the Treasury \nDepartment and the Office of the Comptroller of the Currency. (WSJ)\n• “Trying to Process Your Q3? Journal About It.” (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Xi Jinping and President Biden met last year. Continuing U.S.-China tensions have put businesses in a \nbind. (PHOTOGRAPH BY Kevin Lamarque/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: August 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Tech Fears Are Showing Up on Picket Lines; DealBook Newsletter",
        "media": "The New York Times",
        "time": "September 17, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1763 words",
        "byline": "Sarah Kessler, Ephrat Livni and Michael J. de la Merced",
        "story_text": "Tech Fears Are Showing Up on Picket Lines; DealBook Newsletter\nThe New York Times \nSeptember 16, 2023 Saturday 22:20 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1763 words\nByline: Sarah Kessler, Ephrat Livni and Michael J. de la Merced\nHighlight: What’s being called the “summer of strikes” comes at a time when workers increasingly fear new \ntechnologies will threaten their jobs.\nBody\nWhat’s being called the “summer of strikes” comes at a time when workers increasingly fear new technologies will \nthreaten their jobs.\nThe United Automobile Workers strike is in its second day, and already it’s being framed as potentially the most \ncostly of work stoppages from the “summer of strikes.”\nUnions aren’t just fighting for an inflation-beating wage boost. They also are campaigning for job security at a time \nwhen workers increasingly fear that shifts to new technologies, like electric vehicles and artificial intelligence, \nthreaten their job, and tech bosses themselves say this gloomy outlook is inevitable.\nUnion leaders had a seat at the table this week in Washington at an A.I. forum organized by Senator Chuck \nSchumer, the majority leader, and attended by tech leaders, such as Elon Musk, Satya Nadella of Microsoft and \nJensen Huang of Nvidia. Their presence signals their growing clout in discussions about the future of the \ntechnology.\nConcern over disruptive technologies are seen on the picket lines. The Writers Guild of America and SAG-AFTRA, \nthe actors’ union, fear studios are embracing A.I. tools to generate scripts or copy the performances of actors. “If we \ndon’t stand tall right now, we are all going to be in trouble,” Fran Drescher, president of SAG-AFTRA, warned in \nJuly. “We are all going to be in jeopardy of being replaced by machines.”\nThe U.A.W., meanwhile, is concerned that the industry’s shift to electric vehicles will require fewer workers, and that \nmany of the jobs needed will be in battery factories, most of which are not unionized.\nGiving workers a voice in the use of technology has taken on new urgency, said Thomas Kochan, an emeritus \nprofessor at the M.I.T. Sloan School of Management, who has been studying the future of work since the 1980s: \n“Generative A.I. in particular has just exploded on the scene in a way that’s going to make this one of the most \ncontroversial and one of the most important workplace issues of our time.”\nThe clock is ticking. It’s strategic for unions to get involved early. Otherwise, companies can say, “We’re already \nusing the technology; we’re not really interested in your ideas about how we could be better using it,” said Adam \nSeth Litwin, an associate professor of industrial and labor relations at Cornell University.\nCompanies aren’t legally obligated to negotiate with unions over early-stage decisions on how new technologies are \nused. Unions “only have a right to negotiate over the impacts of technology on wages, hours and working \nconditions,” Kochan said. The thornier issue of what and how technology is deployed, he said, is “the frontier of \ncollective bargaining today.”\nTech Fears Are Showing Up on Picket Lines DealBook Newsletter\nOne breakthrough for labor came in 2018, when Marriott Hotel workers went on strike at 49 locations. After a six-\nweek stoppage, the company agreed to give the union notice before introducing technologies that would affect \nworkers’ jobs and the right to discuss the changes with management.\nWhy would companies benefit from worker input? “If technologies are not developed with the user in mind, they \noften fail,” said Lisa Kresge, a research and policy associate at the University of California Berkeley Labor Center, \nwho has written about union responses to technology. Take those Marriott workers: At the time, they said a new \nhousekeeping app sent them inefficiently bouncing between floors when they could have worked faster by cleaning \nrooms clustered together.\n“If the only option that the labor movement places on the table is ‘No, we don’t want the technology that will hurt our \nworkers,’ that will not be enough,” said Daron Acemoglu, an economist at M.I.T. and a co-author of “Power and \nProgress: Our 1,000-Year Struggle Over Technology &amp; Prosperity.” The key, he said, is for labor to articulate \nhow the technologies can be used “to the great benefit of the workers as well as the businesses.” That’s “what’s \nmissing right now” in the labor negotiations, Acemoglu added.\nFederal proposals to regulate A.I. — in relation to work or otherwise — are barely underway. That leaves the \nunions, which represent only about 6 percent of the private sector work force, fighting a lonely battle. “If your \ncompany is automating and you want a voice in that process, and you are not unionized,” Acemoglu said, “then \nthere is not much you can do.” — Sarah Kessler\nIN CASE YOU MISSED IT \nArm flex gives markets a boost. The initial public offering of the chip design company Arm this week on the Nasdaq \nstock exchange was the biggest market debut in nearly two years. It raised almost $5 billion, valuing the company \nat nearly $68 billion, and bolstered the hopes of other companies planning to go public.\nA lawmaker trip to Wall Street exposes U.S.-China dilemma. The House committee on competition with China \nvisited New York City this week for meetings with financial executives. The discussions included a war-game-like \nexercise to assess the potential economic implications if China invaded Taiwan. But many executives did not want \ntheir names made public for fear of putting their China business at risk. \nGoogle has its day in court. The biggest antitrust battle in decades began in Washington, with the Justice \nDepartment accusing Google of abusing its power as a monopoly over online search engines. The company argues \nthat users have lots of alternatives. \n“Elon Musk” is out. After weeks of headline-generating excerpts, Walter Isaacson’s biography of the Tesla-SpaceX-\nStarlink C.E.O. and X owner hit stores. The book grapples with Musk’s multiple identities: a man driven by an \nabusive childhood; a world-changing entrepreneur; and a sleep-deprived, impulsive mogul who doesn’t fully \nunderstand the extraordinary power he wields.\nNatural assets\nAfter a summer filled with catastrophic floods, blistering heat domes and devastating wildfires, government and \nbusiness leaders from around the world are set to discuss efforts to mitigate climate change at the United Nations \nClimate Ambition Summit in New York on Wednesday.\nThe usual topics are on the agenda, including net-zero targets, energy transition plans and renewable energy \ntargets.\nBut these solutions may be missing something fundamental, according to Partha Dasgupta, an economist at the \nUniversity of Cambridge. In a 2021 report commissioned by the British government, Dasgupta made the case for \nshifting how natural resources are valued, and the idea has since gained momentum: Last month, the White House \nreleased a draft proposal on what should be considered in a cost-benefit analysis when it comes to ecosystem \nservices in government, practices that draw on his work.\nTech Fears Are Showing Up on Picket Lines DealBook Newsletter\nDealBook spoke with Dasgupta about updating economics to account for nature.\nTraditional economics does not account for the value Earth provides, Dasgupta said, but instead assumes that \necosystems are self-regenerating and able to offer services indefinitely and that there will be an infinite supply of \nmaterials. His report included what he calls an “important new set of calculations” for treating natural resources like \nthe ocean and functions, like pollination, as assets, which, theoretically, increase the chances that we invest in and \nmanage our ecosystems to allow for the production of more goods. “Asset management is a very well understood \nphenomenon,” Dasgupta said. “But for a variety of reasons, Mother Nature’s assets don’t carry the signals we need \nto manage them adequately.”\nHow this idea is applied will vary from place to place, Dasgupta said, but now there is a vocabulary and method for \naddressing the underlying issues. The Biden proposal, for example, cites “failing to fully account for nature’s \nbounty” as having led to an “erosion of our nation’s natural assets.” Dasgupta called the proposal “a fine piece of \nwork,” but he said that he wasn’t confident it would be put into effect, or that his ideas more broadly would be \nunderstood fast enough to prevent disaster. “We’re in a firefighting situation,” he said. “Extreme weather events are \nhappening even as we speak.”\nDasgupta worries that an important nuance within his work gets lost, even as it becomes more well known. The \nservices of nature are interconnected, and “they can be brought down like a house of cards,” he said. “You remove \none card from the house and the whole house collapses.” So climate change solutions that focus on goods and \ntech, like replacing oil with solar power, fail to account for the full picture — the interconnectedness of everything.\nPolicymakers often assume that a few tweaks and some human ingenuity will allow for infinite goods and growth; \nDasgupta does not.\nThe New York Times will speak about the climate crisis next week with global leaders, including Bill Gates; Ajay \nBanga, the president of the World Bank; Robin Wall Kimmerer, author and scientist; Jonas Gahr Store, the prime \nminister of Norway; and William Ruto, the president of Kenya. Register to watch the free livestream of the Climate \nForward event on Sept. 21.\nOn our radar: ‘Dumb Money’ \nRemember the meme-stock craze of 2021? The sudden jump in shares of the video game retailer GameStop, \ndriven by Reddit-fueled day traders, rattled financial titans — especially the hedge fund moguls who had bet against \nthe company’s stock price. It was seen briefly as a moment of Main Street’s beating Wall Street at its own game.\nThat heady time is chronicled in “Dumb Money,” an exuberant comedy that aims to do for GameStop what “The Big \nShort” did for the 2008 global financial crisis. Out now in limited release, the movie features a cast of big-name \nactors, including Paul Dano, America Ferrera and Seth Rogen, playing a mix of real-life characters and fictional \ncomposites who feature on both sides of the trading conflict.\n“Dumb Money” is connected to Wall Street behind the scenes, too: The film was financed and produced by Teddy \nSchwarzman, son of the Blackstone co-founder Stephen A. Schwarzman, and written by two former Wall Street \nJournal reporters, Lauren Schuker Blum and Rebecca Angelo. But it’s not exactly sympathetic to the hedge fund \nside of the story — to the point that Ken Griffin of Citadel has reportedly threatened to sue over his portrayal.\nAlison Willmore of Vulture wrote in a review that “the pleasant surprise of ‘Dumb Money’ is that it’s such an effective \nentertainment.” The New York Times’s Ben Kenigsberg described the film as “an energetic, ingratiating \ndramatization” but the “humanizing efforts are less inspired.”\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nThis article appeared in print on page B3.\nTech Fears Are Showing Up on Picket Lines DealBook Newsletter\nLoad-Date: September 17, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "A.I. Is Coming for the Past, Too",
        "media": "The New York Times",
        "time": "January 30, 2024",
        "section": "Section A; Column 0; Editorial Desk; Pg. 21; GUEST ESSAY",
        "length": "1352 words",
        "byline": "By Jacob N. Shapiro and Chris Mattmann",
        "story_text": "A.I. Is Coming for the Past, Too\nThe New York Times\nJanuary 30, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; Editorial Desk; Pg. 21; GUEST ESSAY\nLength: 1352 words\nByline: By Jacob N. Shapiro and Chris Mattmann\nBody\nWe don't have to imagine a world where deepfakes can so believably imitate the voices of politicians that they can \nbe used to gin up scandals that could sway elections. It's already here. Fortunately, there are numerous reasons for \noptimism about society's ability to identify fake media and maintain a shared understanding of current events. \n  While we have reason to believe the future may be safe, we worry that the past is not.\n  History can be a powerful tool for manipulation and malfeasance. The same generative A.I. that can fake current \nevents can also fake past ones. While new content may be secured through built-in systems, there is a world of \ncontent out there that has not been watermarked, which is done by adding imperceptible information to a digital file \nso that its provenance can be traced. Once watermarking at creation becomes widespread and people adapt to \ndistrust content that is not watermarked, then everything produced before that point in time can be much more \neasily called into question.\n  And this will create a treasure trove of opportunities for backstopping false claims with generated documents, from \nphotos placing historical figures in compromising situations, to altering individual stories in historical newspapers, to \nchanging names on deeds of title. While all of these techniques have been used before, countering them is much \nharder when the cost of creating near-perfect fakes has been radically reduced.\n  This forecast is based on history. There are many examples of how economic and political powers manipulated \nthe historical record to their own ends. Stalin purged disloyal comrades from history by executing them and then \naltering photographic records to make it appear as if they never existed. Slovenia, on becoming an independent \ncountry in 1992, erased over 18,000 people from the registry of residents -- mainly members of the Roma minority \nand other ethnic non-Slovenes. In many cases, the government destroyed their physical records, leading to their \nloss of homes, pensions and access to other services, according to a 2003 report by the Council of Europe \nCommissioner for Human Rights.\n  False documents are a key part of many efforts to rewrite the historical record. The infamous Protocols of the \nElders of Zion, first published in a Russian newspaper in 1903, purported to be meeting minutes from a Jewish \nconspiracy to control the world. First discredited in August 1921 as a forgery plagiarized from multiple unrelated \nsources, the Protocols featured prominently in Nazi propaganda and have long been used to justify antisemitic \nviolence, including a citation in Article 32 of Hamas's 1988 founding covenant.\n  In 1924 the Zinoviev Letter, said to be a secret communiqué from the head of the Communist International in \nMoscow to the Communist Party of Great Britain to mobilize support for normalizing relations with the Soviet Union, \nwas published by The Daily Mail four days before a general election. The resulting scandal may have cost Labour \nthe election. The letter's origin has never been proved, but its authenticity was questioned at the time, and an \nA.I. Is Coming for the Past, Too\nofficial investigation in the 1990s concluded that it was most likely the work of White Russians -- a conservative \npolitical faction led at the time by Russian émigrés opposed to the Communist government.\n  Decades later Operation Infektion, a Soviet disinformation campaign, used forged documents to spread the idea \nthat the United States had invented H.I.V., the virus that causes AIDS, as a biological weapon. And in 2004 CBS \nNews withdrew a controversial story because it could not authenticate the documents, which were later discredited \nas forgeries, that called into question the earlier service by George W. Bush, then the president, in the Texas Air \nNational Guard. As it becomes easier to generate historical disinformation and as the sheer volume of digital fakes \nexplodes, the opportunity will become available to reshape history or at least to call our current understanding of it \ninto question.\n  The prospects of political actors using generative A.I. to effectively reshape history -- not to mention fraudsters \ncreating spurious legal documents and transaction records -- are frightening. Fortunately, a path forward has been \nlaid by the same companies that created the risk.\n  In indexing a large share of the world's digital media to train their models, the A.I. companies have effectively \ncreated systems and databases that will soon contain all of humankind's digitally recorded content or at least a \nmeaningful approximation of it. They could start work today to record watermarked versions of these primary \ndocuments, which include newspaper archives and a wide range of other sources, so that subsequent forgeries are \ninstantly detectable.\n  Such work faces some barriers. Google's digital libraries' effort to scan millions of the world's library books and \nmake them readily accessible online ran into intellectual property limits, rendering the historical archive unworkable \nfor its intended purpose of making these texts searchable by anyone with an internet connection. Those same \nintellectual property concerns are causing creators and companies to fret about both the training data provided to \ngenerative A.I. and its implications when used to generate content.\n  Given this freighted history, including Google's failed investment in its digital libraries project, who will step up and \npay for a similar massive effort that would create immutable versions of historical data? Both government and \nindustry have strong incentives to do so, and many of the intellectual property concerns around providing a \nsearchable online archive do not apply to creating watermarked and time-stamped versions of documents, because \nthose versions need not be made publicly available to serve their purpose. One can compare a claimed document \nto the recorded archive by using a mathematical transformation of the document known as a hash, the same \ntechnique the Global Internet Forum to Counter Terrorism uses to help companies screen for known terrorist \ncontent.\n  Aside from creating an important public good and protecting citizens from the dangers posed by manipulation of \nhistorical narratives, creating verified records of historical documents can be valuable for the large A.I. companies. \nNew research suggests that when A.I. models are trained on A.I.-generated data, their performance quickly \ndegrades. Thus separating what is actually part of the historical record from newly created ''facts'' may be critical.\n  Preserving the past will also mean preserving the training data, the associated tools that operate on it and even \nthe environment that the tools were run in. Vint Cerf, an early internet pioneer, has called this type of record ''digital \nvellum,'' and we need it to secure the information environment.\n  Such a vellum will be a powerful tool. It can help companies to build better models by enabling them to analyze \nwhat data to include to get the best content and help regulators to audit bias and harmful content in the models. \nTech giants are already conducting similar efforts to record the new content their models are creating -- in part \nbecause they need to train their models on human-generated text and the data produced after the adoption of large \nlanguage models may be tainted with generated content.\n  The time has come to extend this effort back in time as well, before our politics, too, become severely distorted by \ngenerated history.\nA.I. Is Coming for the Past, Too\n  Jacob N. Shapiro is a professor of politics and international affairs at Princeton University and the managing \ndirector of the Empirical Studies of Conflict Project. Chris Mattmann is an adjunct research professor at the \nUniversity of Southern California and the director of its Information Retrieval and Data Science Group.\n  The Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com\n  Follow the New York Times Opinion section on Facebook, Instagram, TikTok, X and Threads.\nhttps://www.nytimes.com/2024/01/28/opinion/ai-history-deepfake-watermark.html\nGraphic\n \nThis article appeared in print on page A21.               \nLoad-Date: January 30, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Oct2023",
        "header": "Peer Treasure",
        "media": "Economic Times (E-Paper Edition)",
        "time": "October 25, 2023",
        "section": "BRAND EQUITY",
        "length": "1261 words",
        "byline": "mukta.lad@timesgroup.com",
        "story_text": "Peer Treasure\nEconomic Times (E-Paper Edition)\nOctober 25, 2023 Wednesday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BRAND EQUITY\nLength: 1261 words\nByline: mukta.lad@timesgroup.com\nHighlight: For marketing heads, meeting counterparts outside their own categories and regions can be an eye-\nopening experience. Mukta Lad looks at the kinds of conversations and learnings these encounters offer.\nBody\nThe idea of networking makes several professionals groan. All the small talk, attending of events and keeping in \ntouch with freshly-minted contacts — and for returns that are variable and intangible — can prove overwhelming. \nFor marketers, networking happens at industry forums and award juries, both local and international. These \ninteractions can be invaluable, especially because there's a chance to share and glean insights from around the \nworld.Marketers at multinational corporations benefit from regular exposure to global counterparts from their own \nnetworks. As Ankit Desai, marketing director, Hershey India, says, “It validates the fact that while the countries may \nbe different, the commonalities are high.”Consumers aren't all that different, wherever in the world they may be. \nWhat changes are patterns of media consumption and their evolution. So, at these sessions, media is often a hot \ntopic, especially how “brands from different markets are using different media strategies to reach consumers”, says \nKapil Grover, CMO, Burger King India. UNIVERSAL TRUTHS The challenges and customer behaviour patterns that \nmarketers face are also similar across categories or regions. “If you find a gap in consumers' lives and can fit your \nbrand or product into it effortlessly, then the adoption is seamless,” says Sujatha V Kumar, head of marketing (India \nand South Asia) at Visa.Vanda Ferrao, CMO, Wow Skin Science, feels that all marketers worldwide believe in the \neffectiveness of storytelling. “Weaving compelling narratives into our campaigns, whether in cosmetics or any other \ncategory, connects with audiences on a fundamental level,” she says.Another thing they agree on is the power of \nlong-term brand building and emotion. Putting consumers at the heart of everything is something that cuts across all \nbrands and categories, says Desai.The concept of 'value', too, is universal. “As marketers in India, we often feel \nthat we are dealing with this unique phenomenon of 'value-conscious' consumers. But while different markets have \nevolved in different ways, the underlying insights are the same,” says Saakshi Verma Menon, Kimberly-Clark's \nmarketing director, India.The most-discussed topics of conversation at these gatherings are category insights, \nconsumer behaviour, effective media channels to reach and convert consumers, the evolving role of technology in \nbuilding efficiency and effectiveness, marketing automation and product innovation, say CMOs. CULTURE \nSHOCKS CMOs also have favourite markets and with good reason. Nitin Tatiwala, vice-president, AMEA \nmarketing, FedEx Express, says, “Conversations with CMOs from innovative regions like India, Southeast Asia and \nChina have been immensely enriching.” He adds that these markets have witnessed three waves of change: One \ndriven by the consumerisation of technology, emphasised design thinking, data-driven product decisions and \ncustomer centricity. The second focused on incorporating inclusion, privacy and sustainability into businesses, while \nthe third, promising transformative opportunities, is a blend of the first two waves.Speaking to CMOs from other \nregions also reminds one of how unique some problems can be. For instance, summers are more forgiving in \ncertain foreign markets, so brands can “leverage that with summer campaigns celebrating the heat and using it as \nan out-ofhome occasion, while in India, we go into hibernation”, as Verma Menon says, so summer campaigns here \nbecome “at-home time with family and friends”.Abraham Alapatt, president and group head of marketing, service \nPeer Treasure\nquality, value added services and innovation, Thomas Cook (India), brings up another anecdote arising from \nmarketers taking global campaigns and adapting them locally. “An auto company was looking to launch one of its \nmodels in China. Its communication had a line in the US which was complimentary to the car. But in Chinese, it \nloosely translated to 'a spoilt lemon',” he recalls.Another kind of 'culture shock' in marketing can come from the \nsuccess of an unimaginable process. For Ferrao, one such moment came from a conversation with the CMO of an \nAmerican beauty and personal care startup, who mentioned that 90% of his team in content creation, demand \ngeneration and market insights was based out of Indian tier-1 and tier-2 towns. “He spoke of using technology to \nunderstand consumer trends in the US markets and deploy effective campaigns with stellar RoI. This was a penny-\ndrop moment, demonstrating how technology can build market and consumer understanding remotely,” she \nsays.However, the invaluable advantages that come from exchanging notes with fellow CMOs don't come often \nenough. Marketers believe that there need to be more forums and avenues for marketing heads across categories \nto have insightful discussions, much like how the US and the UK do. “There aren't too many great platforms in India \nbringing global CMOs together. If there are, they are elite and by- invitation only,” says Alapatt.Desai agrees. \n“Interacting with marketers and commercial leaders from different organisations is something that we can improve, \nespecially [with] those from other countries,” he says. CROSS-NETWORK EXCHANGES Marketers are also trying \nto learn from each other how generative AI can reshape customer experiences, enhance productivity and drive \ngrowth. “Apart from exchanging insightsnto various growth models and market landscapes, these meetings are also \nexcellent opportunities to develop innovative marketing strategies and think of cross-geographical collaborations for \ncommon sponsorship events like the Olympics or the FIFA World Cup,” says Kumar.A common practice is to float a \nchallenge within the company's network, only to learn from another CMO's experience in cracking something \nsimilar. With this kind of exchange, one learns about evolving category-specific guest behaviours, says Grover. It \nalso makes the process more efficient since many markets are in similar evolutionary stages. “The interactions with \nCMOs from other countries help shorten the learning curve for us,” says Verma Menon.Alapatt finds the award \njuries enriching. “It's amazing how much one can learn from other industries — especially B2C businesses in the \nservice industry,” he says, adding that these conversations can also be fertile breeding ground for effective brand \ncollaborations.  EMERGING VS MATURE MARKETS Indian CMOs also find a chat with marketers from developed \nmarkets revealing. The consumer evolution cycle being different impacts the relevance of various use cases. The \ndifferences in markets mostly arise from cultural nuances, too. “Emerging markets like India have a diverse mix of \nbig metros and small towns, unlike say Singapore, which is more homogenous. That's why in India, we believe that \na one-size-fits-all approach to marketing will not work,” explains Kumar. “I don't want to take away from marketing \ncase studies coming from the US — it's difficult to innovate there since everything has already been done. But the \ncustomer segments don't change too dramatically; they don't see too many paradigm changes happening over two-\nthree years [like we do in India],” Alapatt adds. In emerging markets, the focus is typically on creating awareness for \nthe brand and generating trials, while in evolved markets, building frequency, loyalty and understanding the \nconsumer even more deeply are the challenges. Developed markets, on the other hand, are assumed to have more \nstable, mature economies with an older, ageing population that's used to certain consumption patterns.\nLoad-Date: October 25, 2023"
    },
    {
        "file_name": "Fugees_rapper's_case_Jan2024",
        "header": "Pras Michel's former attorney pleads guilty to leaking information about",
        "media": "Fugees rapper's case",
        "time": "January 29, 2024",
        "section": "ENTERTAINMENT: LATEST & ENTERTAINMENT: CELEBRITY GOSSIP",
        "length": "734 words",
        "byline": "Michael Kunzelman and Lindsay Whitehurst",
        "story_text": "Pras Michel's former attorney pleads guilty to leaking information about \nFugees rapper's case\nUSA Today Online\nJanuary 29, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: ENTERTAINMENT: LATEST & ENTERTAINMENT: CELEBRITY GOSSIP\nLength: 734 words\nByline: Michael Kunzelman and Lindsay Whitehurst\nBody\nWASHINGTON — A prominent defense attorney whose star clients have included Snoop Dogg pleaded guilty \nFriday to leaking grand jury information to reporters about a political conspiracy case against a rapper from the \nFugees.\nDavid Kenner, a California-based attorney known for his representation of celebrities like Suge Knight and Tory \nLanez, was sentenced to a year of unsupervised probation after pleading guilty to a misdemeanor contempt of court \ncharge. He also agreed to pay a $5,000 fine.\nFederal prosecutors say Kenner was representing Prakazrel “Pras” Michel, a founding member of the Fugees, \nwhen he gave grand jury information and photos to two reporters for Bloomberg News for “defense-oriented” stories \nthat ran in March 2023, shortly before the start of the Washington, D.C. trial. Michel’s trial included testimony from \nsuch figures as actor Leonardo DiCaprio and former U.S. Attorney General Jeff Sessions.\nAs is typical in criminal cases, Kenner had gotten access to evidence in order to prepare Michel’s defense, but had \nbeen ordered by the court not to share the information, prosecutors said.\nLink to Image\nKenner’s attorney said in court documents that the reporters originally agreed to sign a protective order, but later \nchanged their minds. A Bloomberg News spokesperson declined to comment.\nKenner, 82, told the judge who sentenced him that he was reckless for not taking steps to terminate the reporters’ \naccess to grand jury information. He described it as a “low point” in his 56-year legal career.\n“Obviously, I made a terrible mistake,” Kenner said.\nMichel was eventually convicted of all 10 counts, including conspiracy and acting as an unregistered agent of a \nforeign government. The Grammy-winning rapper faces up to 20 years in prison on the top counts.\nLink to Image\nMichel is now pushing for a new trial in the case. His new attorney, Peter Zeidenberg, says Kenner made a host of \nerrors. That included bungling closing arguments by using an artificial intelligence program. Once touted as the first \nuse of generative AI in a federal trial, the closing arguments included Kenner misattributing a famous lyric from a \nsong by the rapper Diddy to the Fugees, according to court documents.\nPras Michel's former attorney pleads guilty to leaking information about Fugees rapper's case\nThe charge to which Kenner pleaded guilty carries a maximum prison sentence of six months, but U.S. District \nJudge Amit Mehta said a term of imprisonment or home detention wasn’t warranted. His probation term will be \nunsupervised under the terms of a plea agreement he struck with prosecutors.\nMehta initially expressed surprise that prosecutors agreed to a sentence without a fine. Mehta said a $5,000 fine — \nthe maximum amount allowed under the statute — may be a “small but symbolic” addition to the sentence.\nL. Barrett Boss, one of the defense attorneys, said Kenner was planning to retire after Michel’s trial. But Boss said \nKenner is “very strained financially” because he spent $1.4 million “out of pocket” on Michel’s defense.\nA spokeswoman for Michel said the conviction reflects a breach of client trust. “While Mr. Kenner argues that he \nwas merely trying to mount the best possible defense for Pras Michel, his client, Mr. Kenner’s reckless actions \ncrossed critical ethical lines, failed his duties as counsel, and ultimately have cost him dearly,” Erica Dumas said.\n\"This plea conviction represents a breach of client trust that strikes at the heart of the attorney-client relationship,\" \nDumas added.\nMichel was charged with funneling money from a Malaysian financier to Barack Obama’s 2012 reelection campaign \nthrough straw donors, then trying to squelch a Justice Department investigation and influence an extradition case \non behalf of China under the Trump administration.\nThe financer, Low Taek Jho, also helped finance Hollywood films, including “The Wolf of Wall Street,” which starred \nDiCaprio. Jho has since been accused of masterminding a money laundering and bribery scheme that pilfered \nbillions from the Malaysian state investment fund known as 1MDB. He is now an international fugitive and has \nmaintained his innocence.\nKenner had argued during the trial Michel simply wanted to make money and got bad legal advice as he reinvented \nhimself in the world of politics.\nFugees rapper requests new trial, claims lawyer's use of AI wrecked his case\nThis article originally appeared on USA TODAY: Pras Michel's former attorney pleads guilty to leaking information \nabout Fugees rapper's case\nLoad-Date: January 29, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Republican Bashing of E.S.G. Gets More Complicated; DealBook Newsletter",
        "media": "The New York Times",
        "time": "February 22, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1936 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat Livni",
        "story_text": "Republican Bashing of E.S.G. Gets More Complicated; DealBook Newsletter\nThe New York Times \nFebruary 22, 2023 Wednesday 12:25 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1936 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat Livni\nHighlight: A number of Republican lawmakers have taken money from the companies they vilified. But some of the \nparty’s presidential hopefuls are still on the attack.\nBody\nA number of Republican lawmakers have taken money from the companies they vilified. But some of the party’s \npresidential hopefuls are still on the attack.\nThe case for fighting E.S.G. gets messy\nMany Republicans have made railing against the environmental, social and corporate governance investing \nmovement a cornerstone of their political success. (Indeed, Vivek Ramaswamy, the financier who rose to fame \nbattling against “woke capitalism,” announced a long-shot bid for the 2024 G.O.P. presidential nomination \nyesterday.)\nBut that stance is growing increasingly complicated — especially given new revelations that lawmakers who have \npublicly berated companies for pursuing E.S.G. strategies have also taken big donations from those same \nbusinesses.\nBashing E.S.G. and left-leaning companies has been highly fruitful for Republicans. Gov. Ron DeSantis of Florida, \nwidely considered a front-runner for the Republican presidential nomination, has scored political points for picking a \nfight with Disney over its opposition to his state’s so-called “Don’t Say Gay” law.\nAnd he and other G.O.P. state officials have taken on investment giants like BlackRock, one of the biggest \nproponents of E.S.G. policies, and Vanguard, threatening to pull billions in state money from those firms over their \nsupport of environmental and social considerations in investing. Mike Pence, who may also run for president, last \nyear accused “a few Wall Street financiers” of pushing a left-wing agenda that Democrats hadn’t been able to get \napproved at the ballot box.\n(Mr. Ramaswamy, who wrote “Woke Inc.” and whose Strive Asset Management has targeted Apple, BlackRock and \nDisney, has sought to capitalize on that stance in the business world.)\nBut the money trail complicates things. CNBC reports that 10 of the 29 Republicans on the House Financial \nServices Committee (including its chairman, Representative Patrick McHenry of North Carolina) took in a combined \n$140,000 in campaign donations from BlackRock, State Street and Vanguard during the 2022 election cycle, \naccording to Federal Election Commission filings. All three of those companies are regularly criticized by \nconservative lawmakers.\nThat’s on top of recent pushback in states like Kentucky against G.O.P. efforts to remove public pension funds’ \nmoney from firms like BlackRock.\nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nSome Republicans are moving away from strident opposition to E.S.G. Among them is Mr. Ramaswamy himself, \nwho wrote in a Wall Street Journal opinion piece last month that it’s actually acceptable for investors to support \nenvironmental goals, so long as they’re transparent about their efforts.\nHERE’S WHAT’S HAPPENING \nStocks plunge on worries about bigger interest-rate increases. Markets in Europe and Asia followed Wall Street’s \nbig tumble yesterday as investors grew concerned that strong economic data in the U.S. and Europe meant central \nbanks would keep rates higher for longer. All eyes will be on today’s release of minutes from the most recent \nmeeting of the Fed’s Federal Open Market Committee for clues about where it might go next.\nCitigroup bucks the trend on C.E.O. pay. The firm awarded Jane Fraser a nearly 9 percent increase in \ncompensation for last year, to $24.5 million. She’s the only Wall Street chief to get a raise, as rivals saw their pay \nremain unchanged or cut.\nMcKinsey reportedly plans to cut up to 2,000 jobs. The consulting giant is planning one of its biggest-ever rounds of \nlayoffs, according to Bloomberg and other news outlets. The cuts are expected to focus on back-end employees \nwho don’t interact with clients; they’re meant in part to preserve McKinsey’s compensation pool for partners.\nCredit Suisse keeps falling after reports of another inquiry. Shares in the embattled Swiss bank were down again \ntoday, after Reuters reported that Switzerland’s financial regulator was examining comments by the firm’s chairman, \nAxel Lehmann, about client withdrawals in December.\nTech’s big shield may live on \nA fundamental law governing today’s internet — Section 230 of the Communications Decency Act, which protects \nsocial media companies from lawsuits over users’ posts — faced a big test yesterday in a highly anticipated case \nbefore the Supreme Court.\nBut those hoping the high court would move to curtail the tech giants’ legal shield were likely disappointed: Justices \nappeared skeptical that they could, or should, go that far.\nJustices heard arguments for nearly three hours in a lawsuit filed against Google’s YouTube by the family of a \nvictim of the 2015 terrorist attacks in Paris. The plaintiffs argue that YouTube’s algorithms pushed Islamic State \nvideos to interested users and that the company bore responsibility. (The Biden administration has largely argued in \nsupport of the family’s position.) Lawyers for Google argue that recommendation algorithms are neutral.\nWhat’s at stake: Tech companies and their allies, as well as the original drafters of Section 230, worry that allowing \nexceptions could make sites with user-generated content — from Instagram and Twitter to restaurant review \nplatforms and marketplaces — liable for every decision to present or not present third-party content.\nCritics of Section 230 say the law is outdated and too broad, giving tech giants nearly unlimited legal protection.\nThe justices mostly suggested they weren’t ready to hold tech giants liable just yet:\n• Justice Clarence Thomas defended recommendations as a vital part of the internet. “If you’re interested in \ncooking, you don’t want thumbnails on light jazz,” he said.\n• Justice Brett Kavanaugh worried that imposing limits on Section 230 “would really crash the digital economy, \nwith all sorts of effects on workers and consumers, retirement plans and what have you.”\n• Justice Elena Kagan cracked more broadly about how ill-equipped she and her colleagues were: “These are \nnot the nine greatest experts on the internet.”\nThat doesn’t mean the Supreme Court favors the status quo. Kagan noted that Section 230 was a “pre-algorithm \nstatute” that offered little guidance in “a post-algorithm world.” And Justice Neil Gorsuch questioned whether \nalgorithms were truly neutral, since the formulas are “designed to maximize profits,” implying that companies are \nmaking decisions that could incur liability.\nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nUltimately, several justices suggested, this wasn’t a matter for the courts, but for Congress.\nMicrosoft draws red lines in its deal fight \nAfter testifying yesterday in Brussels about Microsoft’s $69 billion takeover bid for Activision Blizzard, the tech \ngiant’s president, Brad Smith, issued a challenge to regulators: Don’t try to force Microsoft to divest parts of \nActivision in exchange for approving the deal.\nProposals like selling off popular games are a nonstarter, according to Mr. Smith. It isn’t “feasible or realistic to think \nthat one game or one slice of this company can be carved out and separated from the rest,” he told reporters after \nhe spoke with the European Commission.\nIt was a rejoinder to Britain’s Competition and Markets Authority, which this month suggested that it would only \napprove the Activision deal if Microsoft chose so-called structural remedies, like divesting the popular “Call of Duty” \nfranchise. (In the U.S., the F.T.C. has already sued to block the deal.)\nMr. Smith pointed to less onerous concessions that Microsoft was willing to make. He noted that the company had \njust signed deals to give access to “Call of Duty” and other games to rival gaming companies, including Nintendo \nand Nvidia. Mr. Smith also reiterated that Microsoft was prepared to reach a similar deal with Sony.\nIt’s a bet that Microsoft can rely on what are known as behavioral remedies, where a company promises to address \nregulators’ concerns, instead of taking the more drastic step of selling off businesses. But it’s a risky gamble, given \nregulators’ increasing skepticism about anything short of permanent structural changes to avoid antitrust violations.\n• In other antitrust news, the F.T.C. said it won’t block Amazon’s $3.9 billion takeover of One Medical.\n“Five days ago, the chart we shared showed nearly 350 of these submissions. Today, it crossed 500. Fifty of them \njust today, before we closed submissions so we can focus on the legit stories.”\n— Neil Clarke, the founder and editor of the sci-fi magazine Clarkesworld. His publication has stopped accepting \nstories after being inundated with submissions enhanced with generative A.I. programs like ChatGPT. \nA church’s hidden billions \nThe Church of Jesus Christ of Latter-day Saints, commonly known as the Mormon Church, isn’t usually known for \nfinancial riches. But the church and Ensign Peak Advisors, a nonprofit that runs its investment portfolio, agreed \nyesterday to pay a combined $5 million to settle charges by the S.E.C. that they had illicitly sought to obscure its \n$44 billion in assets for nearly 20 years.\nEnsign Peak used a web of shell companies to hide its portfolio, an arrangement approved by the church, according \nto the S.E.C. Ultimately, it created 13 entities that filed regulatory disclosure forms with the S.E.C. that claimed they \nmanaged parts of the portfolio — even though Ensign Peak was the real manager.\nBehind the move was the church’s concern that public knowledge of its vast holdings — by comparison, Yale’s \nclosely watched endowment as of last summer was worth just over $41 billion — might discourage its members \nfrom donating, an Ensign Peak official told The Wall Street Journal in 2020.\nThe scheme first came to light via a huge leak of documents in 2018, when the website MormonLeaks disclosed the \nexistence of the shell companies. The next year, the S.E.C. began an inquiry into the church’s finances. Ensign \nPeak began filing consolidated regulatory disclosures in its name in 2020.\nIn a statement, the church said it had relied upon legal advice in the matter and didn’t admit to or deny breaking the \nlaw. “We affirm our commitment to comply with the law, regret mistakes made, and now consider this matter \nclosed,” it said.\nTHE SPEED READ \nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nDeals\n• Rupert Murdoch’s News Corp is no longer in talks to sell the parent company of Realtor.com to CoStar. (WSJ)\n• Shares in Sigma Lithium, a Canadian metals miner, jumped 16 percent yesterday after a report that Tesla was \nweighing a takeover bid. (Insider)\n• Bao Fan, the star Chinese deal maker who went missing this month, was reportedly working to move his \nfortune out of China and Hong Kong to Singapore before he disappeared. (FT)\n• More office landlords are defaulting on their debts, thanks to the rise of remote working. (WSJ)\nPolicy\n• The Justice Department is reportedly investigating potential campaign-finance violations by Sam Bankman-\nFried, the FTX founder. (Puck)\n• Wells Fargo said U.S. regulators were examining the bank’s retention of employee messages sent using \nunauthorized messaging apps. (Bloomberg)\n• The Labor Department ruled that companies can’t make employees sign nondisparagement clauses as part of \ntheir severance agreements. (Axios)\nBest of the rest\n• BYD, the Chinese electric car giant, wants to conquer the German auto market. (NYT)\n• Twitter is said to be eliminating more employees after Elon Musk said the company was finished laying off \nstaff. (The Verge)\n• How a philanthropic movement led Sam Bankman-Fried, the founder of FTX, to begin his career at the hedge \nfund Jane Street Capital. (NYT)\n• Would you like some olive oil in that Starbucks coffee? (Insider)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Vivek Ramaswamy has gone from professional E.S.G. critic to presidential candidate. (PHOTOGRAPH \nBY Anthony Anex/EPA, via Shutterstock FOR THE NEW YORK TIMES)\nLoad-Date: February 22, 2023"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Nov2023",
        "header": "AI HELPING UPMC DOCTORS WITH TRANSCRIPTION",
        "media": "Pittsburgh Post-Gazette",
        "time": "November 17, 2023",
        "section": "BUSINESS; Pg. A-14",
        "length": "429 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "AI HELPING UPMC DOCTORS WITH TRANSCRIPTION\nPittsburgh Post-Gazette\nNovember 17, 2023 Friday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-14\nLength: 429 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nTranscribing physician notes about care provided to patients was once a $12 billion business, with doctors' voice \nrecordings even sent abroad for conversion into written form that eventually made its way into patient medical \nrecords.\nThat's all gone now with the advent of artificial intelligence in medicine, which has turned the industry inside out with \nreal-time capabilities of summarizing and structuring doctor-patient conversations into medical records and \ndiagnostic codes needed for billing insurers.\n\"We built generative AI in health care,\" said Shivdev Rao, non-invasive cardiologist at UPMC and co-founder of \nAbridge AI Inc., a startup that converts voice into structured medical records. \"It improves the care experience.\"\nCreating medical notes after meeting with a patient has been a headache for doctors since there were medical \nrecords. Abridge software saves doctors up to three hours a day in administrative chores, Dr. Rao said, giving them \nmore time to spend with patients.\n\"At this point in time, they need technologies to augment clinical care and improve the patient's experience,\" he \nsaid.\nThe company, which employs about 50 people and generates undisclosed revenue, has offices in Lawrenceville, \nNew York, Boston and San Francisco. Abridge recently closed on a $30 million Series B funding round, bringing the \ntotal amount raised by the company to $62.5 million since its start in 2018.\nSome two dozen UPMC physicians in Eastern Pennsylvania have used Abridge to create structured medical \nrecords from 10,000 doctors' office interactions with patients as the technology continues to roll out to other \nhospitals in the system. In addition to UPMC, Abridge software is being used by the University of Kansas Health \nSystem and Emory Healthcare as part of a partnership with Epic Systems, an electronic medical records system \noutfit based in Verona, Wis.\nThe big advantage of the software is the time it saves doctors, said Salim Saiyed, chief medical information officer \nat UPMC Pinnacle in Harrisburg.\n\"It frees them up mentally,\" he said. \"That gives them time to really focus on the patient. That's just phenomenal.\"\nHealth care has been a tantalizing target for generative AI because of the mark the technology is expected to \nmake in everything from new drug research to primary medical care. In October, Highmark announced a deal with \nAlphabet's Google subsidiary for Vertex AI Search software, which the hospital and health insurance giant said \nwould be used in every facet of its business, including doctors' offices.\nAI HELPING UPMC DOCTORS WITH TRANSCRIPTION\nKris B. Mamula: kmamula@post-gazette.com\nGraphic\n \nPHOTO: Jessie Wardarski/Post-Gazette: A computer used at the West Penn Hospital School of Nursing in \nBloomfield.\nLoad-Date: November 17, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Can AI Actors Dethrone Superstars?",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 16, 2023",
        "section": "BREAKING IDEAS",
        "length": "819 words",
        "byline": "Anil Nair",
        "story_text": "Can AI Actors Dethrone Superstars?\nEconomic Times (E-Paper Edition)\nSeptember 16, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 819 words\nByline: Anil Nair\nBody\nThe Independence Day weekend saw `390 crore in gross box-office collections, a record for Indian cinema in over \n100 years. Rajinikanth's Jailer, Sunny Deol's Gadar 2, Akshay Kumar's OMG 2 and Chiranjeevi's Bhola Shankar did \nexceptional business across languages, multiplexes and single-screen halls. And Atlee's SRKstarring Jawan, of \ncourse, reinforced the trend with first-day collections of `74.5 crore. With generative AI becoming pervasive, will \ndeepfakes replace actors?\n Or bring deceased actors back to life? The current turmoil in Hollywood could well be the trigger. The US Screen \nActors Guild and American Federation of Television and Radio Artists (SAG-AFTRA) struck work on July 14, joining \nthe Writers Guild of America (WGA), who've been protesting since May 2, demanding higher pay, job security and \nmore parity across the industry. The impasse has lasted over 130 days, and estimates put the economic impact at \n$2-3 billion. There is uncertainty about when this strike will end and how big the hole will be. While streamers like \nNetflix and Amazon can source content, including movies, series, events and sport, from the rest of the world, and \nthe TV industry will chug along  till they have inventory, studios are aware that losses are in the offing. The strike in \nHollywood is hurting other sectors too, including clothiers, prop-makers, caterers, transportation companies, hotels \nand cinema theatres. And that's why thoughts about a new, more robust valuechain hover. Generative AI and CGI \nare poised to impact the film business extraordinarily. For instance, creativity could be automated for the most part, \nwith human intervention limited to coursecorrection. Scripts, sets and costume design, storyboards, and visual \neffects are par for the course. Actors can be de-aged, as director James Mangold did in Indiana Jones and the Dial \nof Destiny recently, when 80-year-old Harrison Ford had to look 35 years younger in two action sequences. \nDirectors can now create new virtual characters, perfectly matching their imagined roles. Film companies would be \nspared the pain of hard negotiations over rates or matching the calendars of actors, while slashing costs \ndramatically, including on overruns. AI-powered tools are increasingly being used for editing and postproduction \nwork, whether to obliterate irksome objects or  transform footage with natural language prompts. They will \nunshackle the imagination of filmmakers, reined in now by hurdles, such as permissions, costs, access, facilities \nand actors. Image-generation models are evoking a lot of interest and are rapidly becoming sophisticated. For \ninstance, Runway Research released Latent Diffusion in 2021, which could be prompted to generate realistic \nimages. Stable Diffusion, released in 2022, had more advanced image generation. Then came Gen 1, which \nenabled the generation of new video content from a simple video — stylising footage, converting mock-ups into \nanimated shots, modifying objects in a picture entirely, or rendering them differently to create new scenes. Now, \nRunway's Gen 2 takes a huge technological leap, and, though nascent, can generate short videos from mere text \nprompts. Adobe's After Effects is used extensively in film and TV post-production. Its newly launched Firefly, an \nembedded generative AI model, in March, can recommend shots after gleaning the script, generate a background \nscore and even different backdrops for different countries.  Adobe is promising that commercial use of Firefly will be \nlegally safe. Importantly, the process of democratisation is underway. Small creative houses can now think big with \nsuch tools. Some recent Indian films that have used AI are Paan Singh Tomar (2012), Ghazi Attack (2017), Kesari \nCan AI Actors Dethrone Superstars?\n(2019), and Uri (2019). Like most countries, India has no specific laws to address the issue of deepfakes. Various \nsections of the Indian Penal Code 1860, Indian Evidence Act 1872, Copyright Act 1957, and the IT Act 2000 would \napply in the case of fake images inserted in synthetic media. India's landmark Digital Personal Data Protection Bill \n2023, passed by Parliament last month, could've changed that. That the debate in each House lasted less than an \nhour is telling. Various sections could've dealt with deepfake-related issues more specifically, for instance, sections \npertaining to information relating to a living individual, prohibiting processing personal data that is unfair, deceptive \nor intrusive; the section that calls for responsible data fiduciaries or the removal of violative information. Areas of \nconcern include wide ranging governmental exemptions and worse, that the Data Protection Board of India will \nhave only government nominees. The autonomy of this board will determine how well the Bill serves and protects \ndata principals — stars and people like us, even from our digital doppelgngers. The writer is senior fellow, Portulans \nInstitute, Washington DC\nLoad-Date: September 16, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Plan to Build Supercomputers",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 9, 2023",
        "section": "FRONT PAGE",
        "length": "496 words",
        "byline": "Our Bureau",
        "story_text": "Plan to Build Supercomputers\nEconomic Times (E-Paper Edition)\nSeptember 9, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 496 words\nByline: Our Bureau\nHighlight: AI ON INDIA US chipmaker to team up with RIL for large language model that will be trained in local \nlanguages, to join hands with Tata Group to build AI infra\nBody\nBengaluru: American chipmaker Nvidia and Reliance Industries, India's largest company by market cap, will \ntogether build a foundational large language model (LLM) — an artificial intelligence algorithm —that will be trained \non an array of diverse Indic languages used by the country's 1.4 billion people, chief executive Jensen Huang \nannounced on Friday. The $27.5-billion company, which is the world's best-known maker of hardware and software \nfor AI tools, also said it will partner with the salt-to-software conglomerate Tata Group to advance AI infrastructure \nin India. The co-created LLM, which is  the bedrock of all generative AI models such as ChatGPT, will be \neventually owned by Reliance, Huang said. \n“They (Reliance) can create AI models, services and applications for their 450 million (customers),” he added. \nMeanwhile, the partnership with the Tata Group's Tata Consultancy Services, Tata Motors and Tata \nCommunications is ai-  med at building “AI infrastructure that is over an order of magnitude more powerful than the \nfastest supercomputer in India today”, Huang told reporters in Bengaluru while unveiling the two big-ticket \npartnerships.  \"India really needs to accelerate its infrastructure building. We would like to do it almost immediately, \nthe best we (Nvidia) can do is probably create supercomputers that are an  order of magnitude 100 times faster \nthan the fastest supercomputer in all of India today. By the end of next year, (India) will have very large computers,\" \nsaid the 60-year-old Nvidia founder who is on a weeklong visit to India, which included a meeting with Prime \nMinister Narendra Modi on Monday.  Noting that “Reliance with 450 million customers has more customers and \naccess to data than any company on the planet (and) they support probably all 22 languages and 2,500 dialects of \nthe country\", Huang said that Nvidia will help co-create AI solutions for Reliance using this data.  In a statement on \nFriday, Mukesh Ambani, chairman of Reliance Industries, said that “as India advances from a country of data \nproliferation to creating technology infrastructure for widespread and accelerated growth, computing  and \ntechnology super centres like the one we envisage with Nvidia will provide the catalytic growth just like Jio did to our \nnation's digital march”.  Pointing to the advancements that have “made focus on AI a central priority in \ngovernments, industries and society at large”, N Chandrasekaran, chairman of Tata Sons, said “the impact of AI \nand machine learning is going to be profound across industries and every aspect of our lives”.  The Tata Group's \npartnership with Nvidia will “democratise access to AI infrastructure, accelerate build-out of AI solutions and enable \nupgradation of AI talent at scale”, he said in a statement.  Nvidia will provide access to the most advanced Nvidia \nGH200 Grace Hopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 \nprovides massive memory bandwidth.\nLoad-Date: September 9, 2023\nPlan to Build Supercomputers"
    },
    {
        "file_name": "of_2024_elections;_A_phone-banking_tool_powered_entirely_by_artificial_Dec2023",
        "header": "Congressional candidate's voter outreach tool is latest AI experiment ahead",
        "media": "of 2024 elections; A phone-banking tool powered entirely by artificial",
        "time": "December 13, 2023",
        "section": "NATION WORLD",
        "length": "1004 words",
        "byline": "ALI SWENSON",
        "story_text": "Congressional candidate's voter outreach tool is latest AI experiment ahead \nof 2024 elections; A phone-banking tool powered entirely by artificial \nintelligence is getting its first real-world test in a Pennsylvania Democrat's \ncongressional campaign\nDayton Daily News (Ohio)\nDecember 13, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1004 words\nByline: ALI SWENSON\nBody\nA phone-banking tool powered entirely by artificial intelligence is getting its first real-world test in a Pennsylvania \nDemocrat's congressional campaign.\nThe chatbot, named Ashley, calls voters and engages in two-way, interactive conversations about candidate \nShamaine Daniels, one of seven Democrats running so far in next year's primary. The voice tool from the startup \nCivox represents one of many ways AI technology is breaking into politics ahead of the 2024 campaigns, but \nexperts say its direct contact with voters could threaten data security and has the potential to undermine voter trust. \nDaniels announced the partnership with Civox on Tuesday, saying the the first-of-its-kind political campaign tool \nhad already completed more than 1,000 calls with likely Democratic primary voters in Pennsylvania's 10th House \ndistrict, which includes the state capital, Harrisburg. \nUnlike other robocallers, Ashley doesn't use canned responses or give call recipients a menu of options. Instead, it \nuses generative AI technology to devise immediate humanlike responses to voter questions. \nThe tool was created by Civox in partnership with another new company, Conversation Labs. Civox CEO Ilya \nMouzykantskii and co-founder Adam Reis, who also founded Conversation Labs, said they tested it rigorously to \nensure it could accurately answer questions about Daniels' policies and what differentiates her from other \ncandidates in the race. \nThe founders said they decided to give the tool a machine-like voice because in internal testing, call recipients \npreferred that to other, more realistic voices. \n\"It's often not the voice itself that influences how natural or human-feeling the conversation is,\" Reis said. \"It's often \nthe nuances of interactions and how quickly it responds and the language it uses.\" \nIn a demonstration with Ashley on Tuesday, the tool disclosed that it was powered by AI and that the call was being \nrecorded. When prompted, it clearly and accurately shared Daniels' positions on affordable health care and \neducation reform. \nIt tactfully answered pointed questions about election integrity and the Republican who holds the seat, six-term \nincumbent Rep. Scott Perry, pausing only a few seconds before each response. \nCongressional candidate's voter outreach tool is latest AI experiment ahead of 2024 elections A phone-banking \ntool powered entirely by artificial intelligence i....\nBut when asked off-topic questions, the tool sometimes got tripped up and shared false information. In a \nconversation about snacks, it said Cheetos were \"known for being both delicious and health-conscious.\" \nThat's an example of an AI \" hallucination \"  a problem with still-evolving generative AI technology in which large \nlanguage models tend to make statements that sound convincing but are false or made up. \nMouzykantskii said the mistake was fascinating but \"not representative\" of voters' experiences with the tool so far. \n\"We have tested Ashley much more extensively on political topics than on the topic of food and nutrition,\" he said. \nVoters' responses so far to Ashley have been mixed, said Joe Bachman of Indigo Strategies, a spokesperson for \nDaniels. He noted that while some call recipients engaged in thorough conversations, many stuck to one-word \nanswers as one might in a phone conversation with a banking chatbot. \n\"There's not a replacement for live one-on-one conversations, either on the phone or at doors,\" he said. \"It's a new \ntechnology. It's going to take voters some time to get used to it, just as when campaigns started using SMS text \nmessaging to communicate with voters.\" \nHe said the campaign felt the chatbot, which can speak over 20 languages, was a good opportunity to reach voters \nin the southern Pennsylvania district, which has a significant refugee population. \nMouzykantskii and Reis said they created Ashley using a combination of over 20 AI models, including both open-\nsource and proprietary models. They declined to share what data its AI models are trained on and would not say \nwhether they incorporated systems from OpenAI or other high-profile AI companies that have rules against usage in \npolitical campaigning. \nOther entrepreneurs at the intersection of AI and politics said they were skeptical about Ashley's direct interaction \nwith voters and more often advise campaigns to use the rapidly advancing technology on the back end of \ncampaigns, such as in drafting advertising copy. \n\"The guidance I've offered and seen from most people is that they are steering away from AI personalities when it \ncomes to politics and campaigns this cycle,\" said Betsy Hoover, a founding partner at the progressive tech \naccelerator and venture capital firm Higher Ground Labs. \"You don't need people to be less trustful of politics right \nnow. In fact, we need the opposite, and so this is not the cycle to try that.\" \nMike Nellis, CEO of the progressive digital agency Authentic, said he was concerned about the possibility of the \nchatbot making mistakes in conversations and didn't believe there was enough data to say whether its calls would \nbe effective in motivating voters. The data the tool gathers through its phone calls is another concern, he said. \n\"Right now, that large language model knows sensitive voter information and knows the voters' responses to it,\" \nNellis said. \"I don't know how safe and secure that is.\" \nMouzykantskii said Civox protects voter information in line with \"political campaign, technology, industry standards\" \nand added that he encourages regulators to pay attention to these emerging tools and set stronger guidelines for \nthem. \nDaniels, 45, is an immigration lawyer and member of the Harrisburg City Council making her second run for the \ncongressional seat, which is in a Republican-leaning district. The state's primary election is April 23. \nPerry beat Daniels in 2022 by 8 percentage points, easily outspending her. \nAssociated Press writer Marc Levy in Harrisburg, Pennsylvania, contributed to this report. \nThe Associated Press receives support from several private foundations to enhance its explanatory coverage of \nelections and democracy. See more about AP's democracy initiative here. The AP is solely responsible for all \ncontent.\nCongressional candidate's voter outreach tool is latest AI experiment ahead of 2024 elections A phone-banking \ntool powered entirely by artificial intelligence i....\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Cognizant gets its mojo back under new CEO’s watch",
        "media": "The Economic Times",
        "time": "January 9, 2024",
        "section": "ITES",
        "length": "1035 words",
        "byline": "Beena Parmar and Romita Majumdar",
        "story_text": "Cognizant gets its mojo back under new CEO’s watch\nThe Economic Times\nJanuary 9, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 1035 words\nByline: Beena Parmar and Romita Majumdar\nBody\nAs former Infosys President Ravi Kumar S completes one year as CEO of IT services and consulting major \nCognizant Technology Solutions Corp this month, experts and insiders ET gave a thumbs up to the new chief of the \n$19.4 billion dollar company has steered Cognizant into getting back its old “mojo”.Kumar, 49, is a \"people's \nperson\" who is winning back competitiveness on large deals, is getting major talent back to CTS, has rationalised \nthe company with real-estate as well as headcount consolidation. However, results in terms of actual revenue \ngrowth and profits are yet to show in a tough market situation where tech spending has dwindled. It is also yet to be \nseen how CTS under Kumar navigates lawsuits and warnings by Wipro and Infosys over poaching of senior \nleadership. Four of the experts ET spoke to, unanimously agreed that Kumar’s working style is much closer to the \nold Cognizant way and his management approach is different from his predecessor Brian Humphries, who led the \nfirm for four years after being coming from outside of the traditional IT services space.Kumar, joined the US-\nheadquartered firm as its fifth CEO since it was founded in Chennai in 1994 as a unit of Dun & Bradstreet. \nTaking the hotseat at Cognizant on 16 January, 2023, Kumar came in at a time when Cognizant was struggling to \nremain relevant as a key services partner, unable to close large deals, facing high attrition amid unfavourable \nmacro factors that have impacted the IT industry.“While it’s still relatively early days, Ravi has helped bring \nCognizant back into a host of client conversations and boost the firm’s large deal pipeline. Several clients are \nencouraged with the rapid progress Ravi has made and are willing to entertain what Cognizant has to offer with his \ngo-forward plans,” said Phil Fersht, founder and CEO of HfS Research.Peter Bendor-Samuel, CEO of IT research \nfirm Everest Group, said, “He has matched his competitors in fully funding the big deal team, however, the results \nare not particularly spectacular… Most of these moves have been simple execution moves and not big strategic \nchanges.”Cognizant did not respond to ET’s queries seeking comments for this piece.HitsIn Q3 (July to \nSeptember), Cognizant reported a record trailing 12-month deal bookings growth of $26.9 billion, up 16% year-over-\nyear (y-o-y), and a book-to-bill of 1.4x. Approximately 30% of these were large deals and three were over $100 \nmillion each.The Nasdaq-listed software services exporter said its operating margin of 15.5% exceeded its \nexpectations, mostly benefitting from its (NextGen) program, announced in Q2 aimed at savings worth $400 million. \nFurther, Cognizant is training and reskilling its employees and also committed about $1 billion in its generative AI \ncapabilities over the next three years.The firm also claims to have hit a historic high in its annual client Net \nPromoter Score survey, that measures customer loyalty.On the topline, Cognizant achieved 0.5% positive revenue \ngrowth in a difficult market condition where 60% of the larger competitors reported negative revenue growth, \naccording to Gaurav Vasu, CEO & Founder of UnearthInsight, an IT market intelligence firm.Vasu adds that Kumar \nhad “razor sharp focus on execution of NextGen program and sustaining margins at or over 14.2% in line with \nlarger peers while competitors with new CEOs & leadership changes have struggled to sustain margins… In fact, \nTech Mahindra, Wipro, etc are witnessing dip in margins.”For Q4 (Oct-Dec), Cognizant expects revenue between \n$4.69 billion and $4.82 billion, a y-o-y decline of 3.1% to 0.3% or dip of 4% to 1.2% in constant currency, with \ninorganic contribution of approximately 100 basis points (bps) (1%). In Q3, acquisitions contributed to 110 bps (1.1 \nper cent) to the revenue.Since Kumar took charge, the IT firm announced two acquisitions in 2023, Mobica in \nCognizant gets its mojo back under new CEO’s watch\nJanuary and Thirdera in December.For 30-year old Cognizant, India market doesn’t generate revenue but is a \ndelivery centre, focused on growing in Tier-II/III cities over last two years. This approach has aligned with its office \nspace optimisation plans as selling real estate in tier-I cities has acted as both retention and margin improvement \nlevers for the company.MissesWhile a lot of Kumar’s efforts are working, the CEO has his share of troubles.As part \nof the rationalisation plans, in May last year Cognizant let go 3,500 employees or 1% of its workforce. Nevertheless, \nCognizant has bucked the hiring trends with headcount increasing by 1000 employees from Q2 at 346,600. It also \naggressively expanded its senior leadership, which has irked its domestic rivals, especially Wipro and Infosys, from \nwhich Cognizant hired about 15-20 senior executives including for the vice president and president level \nroles.Wipro has filed lawsuits against at least two of its employees including Cognizant’s current chief financial \nofficer Jatin Dalal (former Wipro CFO) who joined in December. Meanwhile, Infosys has alleged Cognizant of using \n“unethical poaching tactics” in a communication likely directed at Kumar.In November, to an ET query in the post-\nresults concall, Kumar exclaimed that Cognizant is “a magnet for talent”. “Now, leadership and talent in the market \nis confident to join Cognizant and the cycle is back for us to hire the talent we want to,” he said.According to \nUnearthinsight’s Vasu, Kumar will have to remain focused on growth in North America/Emerging Markets and avoid \nhiring legal battles with competitors or compliance battles with authorities in both US/India as they “can derail both \nrevenue and margin focus in the short-run”.Amid a tough environment, Kumar will also have his task at hand to \neffectively integrate the acquisitions that saw investments worth around $2.2 billion since FY21.In a confluence of a \n“period of uncertainty and period of change”, as Kumar called the current macro environment after the Q3 results, \nhe still has promises to deliver. “It remains unclear if this level of performance will return Cognizant to the heady \ndays when it was setting the world on fire, and disrupting the tech Services market place. We will have to see,” \nBender-Samuel said. For Reprint Rights: timescontent.com\nLoad-Date: January 9, 2024"
    },
    {
        "file_name": "USA_Today_Aug2023",
        "header": "Remain relevant as AI develops",
        "media": "USA Today",
        "time": "August 30, 2023",
        "section": "BUSINESS; Pg. B2",
        "length": "679 words",
        "byline": " ",
        "story_text": "Remain relevant as AI develops\nUSA Today\nAugust 30, 2023 Wednesday\n1 Edition\nCopyright 2023 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B2\nLength: 679 words\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader's Guide to Work in an Age of Upheaval.\"\nQuestion: With the proliferation of generative AI, I am worried about being replaced. Do you expect the additional \nproductivity AI creates to displace workers? What can I do to ensure I am seen as a valued employee? - Whitney\nAnswer: I can understand why you, or any of us, may be apprehensive about being displaced by artificial \nintelligence! New research reveals that nearly one-quarter (23%) of U.S. workers are concerned that workplace \nautomation will replace their job in the next five years. Workplace automation has already impacted nearly 10% of \nU.S. workers. AI may displace some jobs, but it is just as likely to result in the creation of new jobs too. Remember \nthat AI is designed to help us, not to replace human connection. AI isn't all-encompassing; it has its limits. Work will \nalways need the human component because what we create and produce ultimately serves other humans.\nEven before AI existed, there have always been steps employees could take to demonstrate their value to their \norganization. That will not change. For instance, you can take on new assignments or projects and volunteer to help \nwherever needed. Do more than asked and do it well. And be on the lookout for more efficient or cost-effective \nways of doing things in your job.\nIt's also essential to continue to learn and grow your skills by taking classes, receiving training, or taking advantage \nof other professional development opportunities. Be a problem solver and share your ideas with your manager.\nMake no mistake, AI will be a reality. We can choose to run from it and limit our opportunities and growth or \nembrace it to expand our performance, productivity and potential. Careers aren't linear, so our skill sets shouldn't be \nstatic. The world of work will need people to develop the knowledge and expertise to manage, monitor and measure \nthe output of AI. Explore how AI may be relevant in your role and career. Be proactive and talk with your supervisor \nabout AI and how to better serve customers, clients and the organization.\nAI is not going anywhere anytime soon, so now is a pivotal time for us to figure out how to leverage AI to our \nadvantage. Don't let fear of technology blind you to the opportunities it presents for your growth and advancement.\nHow will my lack of a formal university degree affect my chances of obtaining a new position in the HR field, despite \nhaving 15 years of experience as an HR generalist and director and certifications? - Kelley\nThe challenges you face may depend on the level of HR job you are interested in. Sometimes higher-level HR jobs \nrequire a degree, but not always. Your substantial experience, along with your certifications, can offset not having a \ndegree. Research suggests 9 out of 10 employers report being ready to accept candidates without a four-year \nRemain relevant as AI develops\ncollege degree. In addition, the study also found 66% of employers are open to hiring candidates with a recognized \ncertification.\nOnce you identify a position of interest, review the minimum position requirements. The job posting may list a \ndegree, but if it also includes the words \"desired\" or \"preferred,\" then the degree is not a requirement. Tailor your \nresume specific to the job you are applying for and highlight how your experience directly matches what the \ncompany is looking for, such as the skills, knowledge, and abilities to perform certain HR functions. And highlight \nyour achievements in 15 years of HR experience that have been impactful in your previous and current \norganizations.\nEven if a degree is required, apply for it. What do you have to lose? You can include in your cover letter why you \nfeel you are the best candidate for the job, despite not having a degree.\nI hope these suggestions will help you land your next dream job! Best wishes.\nJohnny C. Taylor Jr.\nColumnist\nUSA TODAY\nGraphic\n \nEven before AI existed, there have always been steps employees could take to demonstrate their value to their \norganization.\nGetty Images\nLoad-Date: August 30, 2023"
    },
    {
        "file_name": "Picnic_Jan2023",
        "header": "The AI Ethics War Will Make the Content Moderation Debate Look Like a",
        "media": "Picnic",
        "time": "January 22, 2023",
        "section": "",
        "length": "588 words",
        "byline": "Alex Kantrowitz",
        "story_text": "The AI Ethics War Will Make the Content Moderation Debate Look Like a \nPicnic\nNew York Observer\nJanuary 20, 2023 Friday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 588 words\nByline: Alex Kantrowitz\nBody\n \nThis story is syndicated from the Substack newsletter Big Technology; subscribe for free here\nNow that AI program speak with us in natural language, turn our thoughts into illustrations, and embody our voices, \na major conflict over their ethics is en route.\nAnd if you thought the content moderation fight was intense, just wait for this one.\nAt stake is how chatbots address political issues, how AI illustrators portray the world, and whether some \napplications like voice emulators should even exist. Given the scale and power of this blossoming technology, the \nactivists won't be subtle. They've had their practice fighting over human speech online, and they'll bring that \nexperience to this war. It could get messy quickly.\n\"Everyone's got their knives sharpened,\" said Sam Lessin, a venture capitalist, and former Facebook executive. \"At \nleast with speech, everyone was a little bit off-kilter and didn't really get it. This one, they're like, 'Oh shit, I've seen \nthis game before.' Every single lobby in the world is ready to write their letters and start their influence campaigns.\"\nAI's intelligence may be artificial, but humans encode its values. OpenAI, for instance, effectively decides whether \nChatGPT takes stances on the death penalty (no opinion), torture (it's opposed), and whether a man can get \npregnant (it says no). With its AI illustrator Dall-E, the organization influences what type of a person the tech \nportrays when it draws a CEO. In each case, humans behind the scenes make decisions. And humans are \ninfluenceable.\nLike content moderation, there will be some obvious, consensus ethical decisions for generative AI (you don't want \nchatbots advocating for genocide, for instance) but advocates will stake their ground in the grey. \"It's a very \npowerful tool, and people are going to want to do a broad range of things with it to meet their own interests,\" said \nLessin. \"If you look at how the free speech stuff played out, it will play out the same way again, just faster.\"\nThe potential conflict areas include how AI addresses race, gender, warfare, and other thorny issues. ChatGPT, in \none recent conversation, listed several benefits of Ukraine winning the war against Russia. But asked to list positive \noutcomes from Russia winning the war, it refused. ChatGPT also moralizes a lot. \"War is a grave and devastating \nevent, and should always be avoided if possible,\" the bot said, in one typical interaction. \"The best outcome is \nalways peace and diplomatic resolution.\"\nEthical decisions for generative AI are particularly high stakes because they scale. When you encode values into a \nchatbot, it can push those values repeatedly in conversation. When you make a content moderation decision, in \nmost instances, it involves just one individual and one piece of content.\nThe AI Ethics War Will Make the Content Moderation Debate Look Like a Picnic\nThe best way to handle this new power is to have the bots play it as evenhanded as possible, said Dr. Jeffrey \nHoward, a professor of political science at London's UCL. \"These value judgments are inescapable,\" he said. \"One \nof the value judgments could be to build in a certain kind of neutrality and impartiality.\"\nUltimately, generative AI's decentralization may let out some of the tension. While speech is relatively centralized \nonline today, there are many developers working on generative AI. And as developers build apps with their own \nmorals, an all-out war over the central powers' policies may fade. But in the meantime, expect plenty of positioning, \ncajoling, and fighting over the ethics the big players build into their models.\nLoad-Date: January 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "OpenAI’s Chief Scientist and Co-Founder Is Leaving the Company",
        "media": "The New York Times",
        "time": "May 14, 2024",
        "section": "TECHNOLOGY",
        "length": "957 words",
        "byline": "Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other",
        "story_text": "OpenAI’s Chief Scientist and Co-Founder Is Leaving the Company\nThe New York Times \nMay 14, 2024 Tuesday 23:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 957 words\nByline: Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other \nemerging areas of technology.\nHighlight: In November, Ilya Sutskever joined three other OpenAI board members to force out Sam Altman, the \nchief executive, before saying he regretted the move.\nBody\nIn November, Ilya Sutskever joined three other OpenAI board members to force out Sam Altman, the chief \nexecutive, before saying he regretted the move.\nIlya Sutskever, the OpenAI co-founder and chief scientist who in November joined three other board members to \nforce out Sam Altman, the company’s high-profile chief executive, before saying he regretted the move, is leaving \nthe San Francisco A.I. company.\nDr. Sutskever’s departure, which the company announced in a blog post on Tuesday, closes another chapter in a \nstory that stunned Silicon Valley and that raised questions about whether Mr. Altman and his company were \nprepared to lead the tech industry into the age of artificial intelligence.\nAfter returning to OpenAI just five days after he was ousted, Mr. Altman reasserted his control and continued its \npush toward increasingly powerful technologies that worried some of his critics. Dr. Sutskever remained an OpenAI \nemployee, but he never returned to work.\n“This is an emotional day for all of us,” Mr. Altman said in an interview. “OpenAI would not exist without him and \ncertainly was shaped by him.”\nIn a statement, Dr. Sutskever said: “I have made the decision to leave OpenAI. The company’s trajectory has been \nnothing short of miraculous, and I’m confident that OpenAI will build A.G.I. that is both safe and beneficial.” A.G.I., \nor artificial general intelligence, is an as-yet-unbuilt technology that can do anything the brain can do.\nDr. Sutskever, 38, added that he was starting a new project, but did not elaborate.\nA key OpenAI researcher, Jakub Pachocki, will replace Dr. Sutskever as chief scientist at the company, which is \nvalued at more than $80 billion, according to a recent fund-raising deal.\nOn Monday, OpenAI unveiled a new version of its ChatGPT chatbot that can receive and respond to voice \ncommands, images and videos, joining tech giants like Google and Apple in a race toward a new kind of talking \ndigital assistant.\nFounded in 2015 by Mr. Altman, Elon Musk and several young researchers, including Dr. Sutskever, OpenAI has \nlong been at the forefront of A.I. research. Dr. Sutskever’s involvement provided the company with instant \ncredibility. As a graduate student at the University of Toronto, he had been part of an A.I. breakthrough involving \nneural networks — the technology that has driven the field’s progress over the last decade.\nOpenAI ’s Chief Scientist and Co-Founder Is Leaving the Company\nIn late 2022, OpenAI wowed the world with the release of ChatGPT, an online chatbot that could answer questions, \nwrite poetry, generate computer code and chat a lot like people. The tech industry quickly embraced what is called \ngenerative artificial intelligence — technologies that can generate text, images and other media on their own.\nThe result of more than a decade of research inside companies like OpenAI and Google, generative A.I. is poised \nto remake everything from email programs to internet search engines and digital assistants.\nMr. Altman became a spokesman for the shift toward generative A.I., testifying before Congress and meeting with \nlawmakers, regulators and investors around the world. In November, OpenAI’s board of directors unexpectedly \nousted him, saying he could no longer be trusted with the company’s plan to eventually create artificial general \nintelligence.\nThe OpenAI board had six people: three founders and three independent members. Dr. Sutskever voted with the \nthree outsiders to remove Mr. Altman as chief executive and chairman of the board, saying — without providing \nspecifics — that Mr. Altman had not been “consistently candid in his communications.”\nGreg Brockman, OpenAI’s president and another co-founder, resigned from the company in protest. So did Dr. \nPachocki.\nDays later, as hundreds of OpenAI employees threatened to quit, Dr. Sutskever said he regretted his decision to \nremove Mr. Altman and effectively stepped down from the board, leaving three independent members in opposition \nto Mr. Altman.\nMr. Altman returned as chief executive after he and the board agreed to replace two members with Bret Taylor, a \nformer Salesforce executive, and Lawrence Summers, a former U.S. Treasury secretary. Mr. Altman regained his \nboard seat several months later, as the board expanded to seven people.\nLast year, Dr. Sutskever helped create a Super Alignment team inside OpenAI to explore ways of ensuring that \nfuture versions of the technology would not do harm. Like others in the field, he had grown increasingly concerned \nthat A.I. could become dangerous and perhaps even destroy humanity.\nJan Leike, who ran the Super Alignment team alongside Dr. Sutskever, has also resigned from OpenAI. His role will \nbe taken by John Schulman, another company co-founder.\nIn the weeks leading up to Mr. Altman’s ouster, Dr. Pachocki, who helped oversee the creation of GPT-4, the \ntechnology at the heart of ChatGPT, was promoted to director of research at the company. After occupying a \nposition below Dr. Sutskever, he was elevated to a position alongside him, two people familiar with the moves said.\nAfter Mr. Altman was reinstated, Dr. Sutskever did not return to work. Mr. Altman indicated that he was hoping to \nnegotiate his return, but ultimately that was not possible.\nDr. Pachocki has effectively served as chief scientist since November. After Dr. Sutskever recruited him and others \nto join OpenAI, he was among the key researchers on several of the company’s most important projects, including, \nmost notably, GPT-4.\n“I am grateful to Ilya,” Dr. Pachocki said in an interview. “We have different and in many ways complementary styles \nof leadership.”\nMr. Altman said he talked with Dr. Sutskever on Tuesday. “He has pushed us — and will continue to push us — to, \nas he says, feel the A.G.I.,” Mr. Altman said.\nThis article appeared in print on page B6.\nLoad-Date: May 14, 2024\nOpenAI ’s Chief Scientist and Co-Founder Is Leaving the Company"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 20, 2023",
        "section": "STARTUPS & TECH",
        "length": "270 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres\nEconomic Times (E-Paper Edition)\nJune 15, 2023 Thursday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 270 words\nByline: Suraksha.P@timesgroup.com\nHighlight: AI key driver of silicon consumption for the foreseeable future: AMD CEO\nBody\nSan Francisco: California-based multinational semiconductor company Advanced Micro Devices (AMD) said \nartificial intelligence (AI) will be the key driver of silicon consumption for the foreseeable future but the largest \nopportunity is in data centre currently. AMD also revealed new details about the MI300 chip on Tuesday. \nMI300 is AMD's most advanced graphics processing unit (GPU) that is believed to be a strong challenge to Nvidia \nwhose chips dominate the artificial intelligence (AI) computing market with more than 80% market share. \"The \ngenerative AI large language models have paved the landscape. The  need for more compute is growing \nexponentially. Be it training or inference, large models give you better accuracy. There's a tremendous amount of \nexperimentation and development that is coming across the industry. At the centre of this are GPUs. GPUs are \nenabling generative AI,\" AMD chief executive Lisa Su said. She was speaking at the AMD Data Center and AI \nTechnology Premiere on Tuesday. The company's fourth generation EPYC processors are cloud-native central \nprocessing units (CPUs) that enable data centres to run demanding, scalable services and enterprise applications \non shared cloud infrastructure. Social media giant Meta vice president Alexis Bjorlin also shared how apps like \nFacebook, Instagram and WhatsApp are powered by hundreds of thousands of AMD servers with the next \ngeneration of EPYC beginning deployment this year. AMD has started shipping its Bergamo central processor.  \n(The author is in San Francisco for the AMD Data Center and AI Technology Premiere at the invitation of AMD.)\nLoad-Date: June 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "OpenAI Seeks to Dismiss Parts of The New York Times's Lawsuit",
        "media": "The New York Times",
        "time": "February 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 3",
        "length": "592 words",
        "byline": "By Cade Metz and Katie Robertson",
        "story_text": "OpenAI Seeks to Dismiss Parts of The New York Times's Lawsuit\nThe New York Times\nFebruary 28, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 3\nLength: 592 words\nByline: By Cade Metz and Katie Robertson\nBody\nThe artificial intelligence start-up argued that its online chatbot, ChatGPT, is not a substitute for a New York Times \nsubscription.\nOpenAI filed a motion in federal court on Monday that seeks to dismiss some key elements of a lawsuit brought by \nThe New York Times Company. \n  The Times sued OpenAI and its partner Microsoft on Dec. 27, accusing them of infringing on its copyrights by \nusing millions of its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots now compete with \nthe news outlet as a source of reliable information, the lawsuit said.\n  In the motion, filed in U.S. District Court for the Southern District of New York, the defendants argue that ChatGPT \n''is not in any way a substitute for a subscription to The New York Times.''\n  ''In the real world, people do not use ChatGPT or any other OpenAI product for that purpose,'' the filing said. ''Nor \ncould they. In the ordinary course, one cannot use ChatGPT to serve up Times articles at will.''\n  OpenAI did not dispute in its filing that it ''copied millions of The Times's works to build and power its commercial \nproducts without our permission,'' Ian B. Crosby, a partner at Susman Godfrey and the lead counsel for The Times, \nsaid in a statement.\n  ''What OpenAI bizarrely mischaracterizes as 'hacking' is simply using OpenAI's products to look for evidence that \nthey stole and reproduced the Times's copyrighted works,' he said. ''And that is exactly what we found.''\n  OpenAI declined to comment.\n  The motion asked the court to dismiss four claims from The Times's complaint to narrow the focus of the lawsuit. \nOpenAI's lawyers argued that The Times should not be allowed to sue for acts of reproduction that occurred more \nthan three years ago and that the paper's claim that OpenAI violated the Digital Millennium Copyright Act, an \namendment to U.S. copyright law passed in 1998 after the rise of the internet, was not legally sound.\n  The Times was the first major American media company to sue OpenAI over copyright issues related to its written \nworks. Novelists, computer programmers and other groups have also filed copyright suits against the start-up and \nother companies that build generative A.I., technologies that generate text, images and other media from short \nprompts.\nOpenAI Seeks to Dismiss Parts of The New York Times 's Lawsuit\n  Like other A.I. companies, OpenAI built its technology by feeding it enormous amounts of digital data, some of \nwhich is likely copyrighted. A.I. companies have claimed that they can legally use such material to train their \nsystems without paying for it because it is public and they are not reproducing the material in its entirety.\n  In its suit, The Times included examples of OpenAI technology's reproducing excerpts from its articles almost \nverbatim. In the motion to dismiss, lawyers for OpenAI accused The Times of paying someone to hack their \nchatbot. ''It took them tens of thousands of attempts to generate the highly anomalous results,'' the motion said.\n  ''They were able to do so only by targeting and exploiting a bug (which OpenAI has committed to addressing) by \nusing deceptive prompts that blatantly violate OpenAI's terms of use,'' the filing said.\n  The filing also argued that it was legal to use copyrighted material in its systems, citing legal precedents that allow \nfor the use of copyrighted content ''in the creation of new, different and innovative products.''\n  ''OpenAI and the other defendants in these lawsuits will ultimately prevail because no one -- not even The New \nYork Times -- gets to monopolize facts or the rules of language,'' the complaint said.\nhttps://www.nytimes.com/2024/02/27/technology/openai-new-york-times-lawsuit.html\nGraphic\n \nPHOTO: The New York Times was the first major American media company to sue OpenAI over copyright issues. \n(PHOTOGRAPH BY ZACK DEZON FOR THE NEW YORK TIMES) This article appeared in print on page B3.               \nLoad-Date: February 28, 2024"
    },
    {
        "file_name": "Executive_for_Vice_Media_Aug2023",
        "header": "Wired Names a New Top Editor, a Former Intern Who Was a Senior",
        "media": "Executive for Vice Media",
        "time": "August 11, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "503 words",
        "byline": "By Katie Robertson",
        "story_text": "Wired Names a New Top Editor, a Former Intern Who Was a Senior \nExecutive for Vice Media\nThe New York Times\nAugust 11, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 503 words\nByline: By Katie Robertson\nBody\nKatie Drummond will be the next top editor of Wired, overseeing the tech publication's teams around the world.\nCondé Nast, the publisher of Wired, announced the appointment of Ms. Drummond as its global editorial director on \nThursday. She joins from Vice Media, where she was the senior vice president of global news and entertainment, in \ncharge of Vice News and the company's digital brands. \n  Ms. Drummond replaces Gideon Lichfield, who was named global editorial director in March 2021 and announced \nhis departure in May. In a memo to the staff about his exit, Mr. Lichfield said he had decided to move on from the \njob and had increasingly missed ''committing acts of journalism with my own two hands.'' He will continue co-\nhosting the Wired podcast ''Have a Nice Future'' until at least November, he said in the memo.\n  Ms. Drummond, 37, was an intern at Wired in 2009. She later worked as a reporter for a national security blog run \nby the publication. She said in an interview on Thursday that her personal connection to the outlet as well as the \nopportunity to lead coverage of the tech world with a global staff made her decision to return ''a no-brainer.'' Wired \nhas teams in the United States, Italy, Japan, Mexico and Britain.\n  ''When I think about the moment we're in now,'' Ms. Drummond said, ''with this very real human toll that we're \nfeeling and seeing around climate change, with the development of generative A.I., with the sort of unfathomable \nwealth and power and scope of major technology companies and Big Tech and the people that lead them, it feels \nlike another sort of inflection moment in technology, in society.''\n  She added, ''That's exciting to me, to be at Wired at this moment in time.''\n  Ms. Drummond said she expected to experiment with vertical video products, newsletters and emerging platforms \nto reach different audiences.\n  ''Wired has a really unique ability to be incredibly enthusiastic and excited about technology and science and \ninnovation while having the credibility and the brand equity to really interrogate and investigate,'' she said.\n  Anna Wintour, the chief content officer of Condé Nast and global editorial director of Vogue, said in a statement \nthat Ms. Drummond was ''a journalist first and foremost, but also a highly original thinker.''\n  ''Katie is exactly the right editor to lead Wired at a time where the worlds of technology and culture are shifting and \ncolliding every single day,'' she said.\nWired Names a New Top Editor, a Former Intern Who Was a Senior Executive for Vice Media\n  Ms. Drummond left Vice this month alongside several other top editorial leaders after the company was bought out \nof bankruptcy for $350 million by Fortress Investment Group and other creditors.\n  Before her time at Vice, Ms. Drummond was executive editor of Gizmodo Media Group and of The Outline, and a \ndeputy editor at Medium and Bloomberg. She was also a managing editor at The Verge, launching their science \nsection. She started her career as a reporter, writing for outlets like The New Republic and Popular Science.\n  Ms. Drummond will start at Wired on Aug. 28.\nhttps://www.nytimes.com/2023/08/10/business/media/wired-katie-drummond.html\nGraphic\n \nPHOTO: Katie Drummond, 37, said she expected to experiment with vertical video products, newsletters and \nemerging platforms to reach different audiences. (PHOTOGRAPH BY CLARK HODGIN FOR THE NEW YORK \nTIMES) This article appeared in print on page B5.               \nLoad-Date: August 11, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "India will Establish Guardrails for AI Sector: Rajeev Chandrasekhar",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "COMPANIES",
        "length": "415 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "India will Establish Guardrails for AI Sector: Rajeev Chandrasekhar\nEconomic Times (E-Paper Edition)\nMay 13, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 415 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: ESTABLISHING SOME PRINCIPLES Govt not in favour of legislation regulating generative artificial \nintelligence yet, unlike US, EU; discipline needs to be brought in the industry\nBody\nNew Delhi: India plans to establish “some principles” which will act as “guardrails” for the fast-growing artificial \nintelligence (AI) sector, according to a top lawmaker who said this will help regulate generative AI platforms such \nas Microsoft's Open AI and Google's Bard as well as their use by other companies. In contrast to the view taken by \nthe European Union and the US, the Indian government is not in favour of legislation to regulate generative AI, yet, \naccording to Rajeev Chandrasekhar, minister of state for electronics and IT. He added that discipline needs to be \nbrought into an industry that can cause much chaos and harm. \n“If anybody says I know the  right way to regulate AI, there will be an Elon Musk view, the Open AI view, or 100 \nother views. We are not going to go down that road at all,” he told ET in an interview. “AI is an emerging technology, \nand we will establish some principles as guardrails. Then the subordinate legislation or how to regulate it will keep \nevolving,” he said. India has one of the largest data sets and is therefore very crucial for companies working on \ngenerative AI. It is important India does not allow technology regulation to lag technology innovation in AI, the \nminister said. “AI innovation is now growing very fast. In the blink of an eye, there's a new dis-  ruption. So \ntherefore, we must establish fairly embedded principles in the law.” Pointing out that the proposed guardrails will put \nthe onus on the platforms to ensure that no one is using them to “create misinformation”, Chandrasekhar said “you \ncannot create things that are fake, you cannot cause user harm, you cannot have exploitive content.” The \ngovernment, according to the minister, will define terms such as “exploitative” after consultation with the industry. \nThe upcoming Digital India Act, which is a revamp of the 23-yearold IT Act, will also contain a chap-  ter on \nemerging technologies. The Centre, which has held one round of consultations on the Digital India Act (DIA), is \nplanning to hold another one later in May, in New Delhi. The law will not just update several regulations with respect \nto technology but also frame new ones to regulate emerging areas such as Web 3 among others. It is also \nreviewing the concept of safe harbour or immunity which is enjoyed by internet intermediaries under Section 79 of \nthe IT Act. Chandrasekhar told ET that in the new DIA, as a principle, India is moving away from “the idea of no \naccountability” of the platform.\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "strike_for_protection_against_artificial_intelligence_Jul2023",
        "header": "Netflix posts $900,000 AI job listing as Hollywood actors, writers continue to",
        "media": "strike for protection against artificial intelligence",
        "time": "July 26, 2023",
        "section": "TECH AND GADGETS",
        "length": "350 words",
        "byline": " ",
        "story_text": "Netflix posts $900,000 AI job listing as Hollywood actors, writers continue to \nstrike for protection against artificial intelligence\nThe Economic Times\nJuly 27, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 350 words\nBody\nSeems like Hollywood's fight against artificial intelligence (AI) will be a long one as streaming giant Netflix has listed \na high-paying AI job with an annual salary of up to $900,000. This posting comes at a time when Hollywood actors \nand writers have been on strike demanding fair compensation and safeguards for their digital likenesses in the face \nof AI advancements. The job opening by Netflix is for a Machine Learning/AI Product Manager. They will be \nresponsible for enhancing Netflix's machine-learning platform (MLP) and leveraging AI to \"create great content\" \nrather than solely relying on AI for recommending shows and movies. \nThat's not the company's only AI-heavy job posting promising a giant payday. In another job listing, the streaming \ngiant has sought a technical director for generative AI at its gaming studio, further emphasising the company's \ncommitment to integrating AI across its business sectors. Meanwhile, reports state that the striking actors, \nrepresented by the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA), have \nrejected a proposal from the Alliance of Motion Picture and Television Producers (AMPTP). It aims to pay actors a \none-time fee for scanning their likenesses to be used as AI-generated CGI in perpetuity. According to The Intercept, \nSAG-AFTRA raised concerns that this proposal would grant studios ownership and control over their digital images \nwithout adequate compensation or consent. Similarly, writers represented by the Writers Guild of America (WGA) \nhave also been on strike since May, demanding better labour protections against AI-generated content. They are \nasking for regulations that prevent AI programs like ChatGPT from being credited as screenplay writers. The \nstriking unions have expressed concerns that AI advancements in Hollywood may lead to actors being replaced by \nAI-generated characters and writers' jobs being at risk. The fear of AI potentially infringing on creative rights and \ncompensation has escalated as the use of deepfakes and CGI continues to evolve. For Reprint Rights: \ntimescontent.com\nLoad-Date: July 26, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2023",
        "header": "Adobe launches generative AI model Firefly",
        "media": "The Economic Times",
        "time": "March 22, 2023",
        "section": "TECH & INTERNET",
        "length": "352 words",
        "byline": "Aashish Aryan",
        "story_text": "Adobe launches generative AI model Firefly\nThe Economic Times\nMarch 23, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 352 words\nByline: Aashish Aryan\nBody\nGlobal software giant Adobe on Tuesday announced the beta launch of its new generative artificial intelligence \nmodel Firefly, focussed on generating images and text. The new AI model will also be available for use in other \nproducts offered by the company such as Creative Cloud, Document Cloud, Experience Cloud and Adobe Express. \n\"Adobe's first model, trained on Adobe Stock images, openly licensed content and public domain content where the \ncopyright has expired, will focus on images and text effects and is designed to generate content safe for \ncommercial use,\" the company said in a release. \nCommenting on the use of AI model for text and image generation, Adobe's chairman and chief executive officer \nShantanu Narayen said that innovations being made by the company in the field of AI have \"tried to ensure that our \ninnovations are developed with accountability, responsibility, and transparency\". \"As we reflect on our daily lives, it \nis clear that digital has and will continue to reshape how we work, learn, and are educated. This is happening \nacross every industry, from healthcare to retail to financial services to education,\" Narayen said. Apart from the \nlaunch of the beta version of Firefly for commercial use, Adobe also announced a new partnership with NVIDIA to \nco-develop a new generation of advanced generative AI models that will focus on integration with tools and \napplications that creators and marketers around the world use. In addition to Firefly and its partnership with NVIDIA, \nAdobe also unveiled Adobe Express for Enterprise and a Content Supply Chain solution. \"As the digital economy \ncontinues to expand, profitable growth will come from connecting the complete customer experience - from \nacquisition to engagement and retention,\" Anil Chakravarthy, the president of the Digital Experience Business at \nAdobe said, adding that the latest innovations from the company would empower brands to scale efficiently and \npersonalise digital experience across surfaces. (The reporter is in the US to cover Adobe Summit 2023 at the \ninvitation of Adobe.) For Reprint Rights: timescontent.com\nLoad-Date: March 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Alphabet Shrugs Off Advertising Slump, Thanks to Search Engine",
        "media": "The New York Times",
        "time": "April 26, 2023",
        "section": "TECHNOLOGY",
        "length": "887 words",
        "byline": "Nico Grant",
        "story_text": "Alphabet Shrugs Off Advertising Slump, Thanks to Search Engine\nThe New York Times \nApril 25, 2023 Tuesday 11:36 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 887 words\nByline: Nico Grant\nHighlight: Google’s parent company returned to sales growth, even as an advertising slowdown continued to crimp \nYouTube.\nBody\nGoogle’s parent company returned to sales growth, even as an advertising slowdown continued to crimp YouTube.\nAfter years of easy financial growth and booming popularity, Alphabet, Google’s parent company, has in recent \nmonths faced mounting questions about its future. It has been under the gun to deliver artificial intelligence \ntechnology, its sales growth has decelerated, and it is laying off 12,000 employees to cut costs.\nOn Tuesday, Google shrugged off some of those questions, returning to sales growth in defiance of a slowdown in \ndigital advertising.\nThe company reported revenue of $69.8 billion in the first three months of 2023, up 3 percent from a year earlier \nand beating analysts’ average estimate of $68.9 billion. Its profits fell 8 percent, to $15 billion — the fifth \nconsecutive decline — though Alphabet said it recorded $2.6 billion in charges related to recent layoffs and office \nspace reductions.\nGoogle still faces significant challenges. Its video platform, YouTube, continues to be crimped by the ad slump and \nrival Microsoft has gained buzz and users after incorporating an A.I. chatbot into its search engine, Bing.\nBut Tuesday’s results highlighted Google’s enviable advantage as a gateway to the web for billions of people \naround the world, a position that cannot be dislodged quickly or easily.\nIn particular, Google’s search engine, the core of the world’s largest digital advertising machine, remained strong. \nRevenue from the search engine rose almost 2 percent. to $40.4 billion, in the first quarter, higher than analysts’ \nestimates of $39.4 billion. The company said travel firms and retailers had spent more to reach customers on the \nsearch platform.\nSante Faustini, who runs product intelligence at M Science, a data research firm, said in an interview that Google’s \nsearch engine was the driving force of the company’s rebound, in a sign of the service’s “resilience” against larger \neconomic forces.\nStarting last year, rising interest rates and inflation had made advertisers thriftier, undermining the sales and profit \nof Google and its peers Snap and Meta, which owns Facebook and Instagram. Google’s sales had declined slightly \nat the end of last year.\nThat had put Alphabet under growing pressure to reassure investors it could still deliver revenue and profit gains, \nafter years of gravity-defying leaps. Mark Mahaney, an analyst at Evercore ISI, encapsulated Wall Street’s \nAlphabet Shrugs Off Advertising Slump, Thanks to Search Engine\ndemands in a recent note, in which he pushed the company to shed expenses, stabilize core businesses including \nYouTube and accelerate the release of artificial intelligence technology.\nThe internet giant said in January it would cull 12,000 people, or 6 percent, of its global work force, from its payroll. \nAs of March 31, Alphabet had 190,711 employees, compared with 190,234 at the end of last year. The company’s \nlayoffs did not officially go into effect until the end of last month.\nAt the same time, Google’s search engine appeared threatened by a wave of chatbots that have captured the public \nimagination. In particular, tools from Microsoft and OpenAI, the maker of the popular ChatGPT chatbot, have begun \ntesting Google’s mettle.\nIn March, Google released a chatbot called Bard to mixed reviews, but the company does not generate revenue \nfrom the tool. The New York Times has reported that Google will incorporate conversational A.I. features into its \nflagship search engine in May, and has begun work on a new, more personalized search engine designed to take \nadvantage of A.I. advances.\nLast week, Alphabet consolidated its main A.I. teams into one unit, Google DeepMind, to make quicker progress in \nthe field. The move combined the London-based A.I. lab DeepMind with Google Brain, part of the company’s \nresearch division. DeepMind’s chief executive, Demis Hassabis, assumed control of the group. Jeff Dean, Google’s \ntop research executive, had previously overseen Google Brain, which he co-founded.\nIn an earnings call on Tuesday, Sundar Pichai, Alphabet’s chief executive, said the company had made “good \nprogress” in A.I., comparing it to the company’s transition from desktop to mobile computing more than a decade \nago.\n“Our investments and breakthroughs in A.I. over the last decade have positioned us well,” he said, while promising \na raft of new A.I. features in everything from Android smartphones to software for other businesses. He added that \nhe hoped Google’s efforts to develop A.I. features would help the company retain its large user base.\n“We’ll continue to incorporate generative A.I. advances to make search better in a thoughtful and deliberate way,” \nhe said.\nAdvertising sales at YouTube, Google’s video platform, dipped almost 3 percent, to $6.7 billion, in the first quarter, \nnarrowly ahead of the $6.6 billion expected by analysts. The division has recorded declining revenue in recent \nmonths amid increased competition from TikTok. Apple’s privacy changes for its iPhones have also tamped down \nthe growth of social media platforms by making it more difficult to prove to advertisers that their ads are effective.\nSales at Google Cloud, the division that offers software and technology services to other businesses, jumped 28 \npercent to $7.5 billion. For the first quarter, the division reported a profit for the first time, of $191 million.\nThis article appeared in print on page B1, B3.\nLoad-Date: April 26, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Dec2023",
        "header": "After a Dry Spell, IT Sights Green Shoots with Higher Budget for ’24",
        "media": "Economic Times (E-Paper Edition)",
        "time": "December 13, 2023",
        "section": "STARTUPS & TECH",
        "length": "481 words",
        "byline": "Romita Majumdar",
        "story_text": "After a Dry Spell, IT Sights Green Shoots with Higher Budget for ’24\nEconomic Times (E-Paper Edition)\nDecember 14, 2023 Thursday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 481 words\nByline: Romita Majumdar\nHighlight: Tech budgets may rise 9% next year vs 2% in 2023; resumption of paused projects seen\nBody\nMumbai: Green shoots have started showing for the IT services companies after a catastrophic year when tech \ndemand nosedived amid geopolitical and macroeconomic concerns, and analysts expect a revival in IT spending in \n2024. IT budgets for calendar 2024 are expected to go up by 9% compared to amere 2% growth in 2023 budgets, \nresearch and analysis firm HFS Research told ET. Analysts from firms including Macquarie Group and S&P Global \nsaid the environment has improved slightly and the commentary around renewals is not just about large multi-year \ndeals, but also about programs that were paused earlier. If the spending resumes in CY24, it will significantly \nbenefit Indian IT companies, many of whom  reduced growth forecasts and some even guided for a revenue \ndegrowth in the current fiscal. \nAtop official at an IT firm said some of the paused projects have started moving and that the company expects \nNorth America to recover in the latter half of 2024. “In North America, we have reason to be more optimistic,” the \nexecutive told ET. “Unemployment continues to be low. Inflation is coming down, banks are making money and \nsentiments are improving…” However, the industry remains cautious as uncertainty persists in  the market. “In \nsome verticals, the pace of growth and paused projects have started resuming but that has not happened across \nthe board,” the person said, indicating that North America may recover sooner than Europe and that growth may \nstill be muted for the next two quarters. Aspate of conflicts and humanitarian crises, a banking debacle, plummeting \nconsumer confidence levels in the largest IT services market, and the fastest pace of rate increases by central \nbanks in Europe and the US have combined to crush demand in 2023. During the year, companies  like Accenture, \nInfosys, Wipro, and HCLTech slashed revenue growth guidance since companies hit a pause on spending on \ntechnology projects given the uncertainty around an impending recession. Phil Fersht, chief executive of HFS \nResearch, said the firm’s latest Pulse study of 600 major enterprises indicates a rebound growth increase of 9% for \ntech spend in CY 24, after slumping to barely more than 2% growth in 2023. “However, only some of the major IT \nservices firms will benefit as enterprise clients are looking to invest new money in technology solutions, not merely \nthe same old labour-driven support services,” he cautioned. The two major drivers of growth are machine learning \nAI and generative AI. “After these areas, we are seeing strong demand in 5G, data platforms, and process \nautomation,” Fersht said. “If some service providers can embed these technologies into current major renewals, \nthey should see some healthy growth.” Ravi Menon, research analyst at Macquarie Capital, said IT services \nbudgets are likely to increase 2-4% in 2024 compared to 2022 budgets. romita.majumdar@timesgroup.com\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "Over 64% users pass off gen AI work as their own: Salesforce survey",
        "media": "The Economic Times",
        "time": "December 13, 2023",
        "section": "TECH & INTERNET",
        "length": "502 words",
        "byline": " ",
        "story_text": "Over 64% users pass off gen AI work as their own: Salesforce survey\nThe Economic Times\nDecember 13, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 502 words\nBody\nA large proportion of users are engaging in ethically questionable activities at work when using generative AI, and \nmore than half of them are working without the formal approval, training, or guidance of their employers, as shown \nby Salesforce research.At least 64% of users are passing off AI as their own work, and as many as 41% of workers \nare inflating their generative AI skills and overstating them to secure work opportunities, according to the research \nsurvey on Generative AI Snapshot Research Series, 'The Promises and Pitfalls of AI at Work.'The research added \nthat workers have recognised how critical generative AI is in advancing their careers, and businesses must \nrespond quickly with clear, trusted guidelines to ensure the technology is enterprise-ready and used \nresponsibly.The Salesforce survey included more than 14,000 workers across 14 countries.The findings uncovered \nthat over a quarter (28%) of workers, or nearly 4,000 workers, are currently using generative AI at work, with over \nhalf doing so without the formal approval of their employers. \"With an additional 32% expecting to use generative \nAI at work soon, it's clear that the penetration of the technology will continue — with or without oversight,\" the \nsurvey said.There is a clear indication that workers recognise the impact of the technology on their careers.Hence, \nnot only do workplace users tap into unapproved generative AI tools at work, but they also do so while still \nrecognising that the ethical and safe use of generative AI means adopting company-approved programmes.The \nfindings come at a time when governments globally, including the US and EU, are working on rules to mitigate risk \nand commit to the responsible use of AI. \nMeanwhile, new data suggests that businesses haven't followed suit in implementing clear policies around its \nuse.The Salesforce study points out that the onus doesn't fall entirely on the workers themselves. \"...nearly 7 in 10 \nglobal workers have never completed or received training on how to use generative AI safely and ethically at \nwork,\" the findings highlighted.In fact, companies around the world have no clearly defined gen AI policies yet, and \ncertain industries lag behind more than others.For example, the survey showed that 87% of global workers in the \nhealthcare industry claim their company lacks clear policies. \"With the level of confidential data held in this industry \nand others, there is an urgency to skill up workers on responsible use... In fact, nearly 4 in 10 (39%) global workers \nsay their employer doesn't hold a strong opinion about generative AI use in the workplace.\"\"To realise AI's full \npotential, it's critical that we invest in the employees using the technology as much as the technology itself. With \nclear guidelines, employees will be able to understand and address AI's risks while also harnessing its innovations \nto supercharge their careers,\" said Paula Goldman, Chief Ethical and Humane Use Officer at Salesforce. For \nReprint Rights: timescontent.com\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "Dayton_Daily_News_(Ohio)_Jul2023",
        "header": "ChatGPT-maker OpenAI signs deal with AP to license news stories",
        "media": "Dayton Daily News (Ohio)",
        "time": "July 14, 2023",
        "section": "NATION WORLD",
        "length": "752 words",
        "byline": "MATT O'BRIEN",
        "story_text": "ChatGPT-maker OpenAI signs deal with AP to license news stories\nDayton Daily News (Ohio)\nJuly 14, 2023 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 752 words\nByline: MATT O'BRIEN\nBody\nChatGPT-maker OpenAI and The Associated Press said Thursday that they've made a deal for the artificial \nintelligence company to license AP's archive of news stories.\n\"The arrangement sees OpenAI licensing part of AP's text archive, while AP will leverage OpenAI's technology and \nproduct expertise,\" the two organizations said in a joint statement. \nFinancial terms of the deal were not disclosed. \nOpenAI and other technology companies must ingest large troves of written works, such as books, news articles \nand social media chatter, to improve their AI systems known as large language models. Last year's release of \nChatGPT has sparked a boom in \"generative AI\" products that can create new passages of text, images and other \nmedia. \nThe tools have raised concerns about their propensity to spout falsehoods that are hard to notice because of the \nsystem's strong command of the grammar of human languages. They also have raised questions about to what \nextent news organizations and others whose writing, artwork, music or other work was used to \"train\" the AI models \nshould be compensated. \nThis week, the U.S. Federal Trade Commission told OpenAI it had opened an investigation into whether the \ncompany had engaged in unfair or deceptive privacy or data security practices in scraping public data  or caused \nharm by publishing false information through its chatbot products. The FTC did not immediately reply to a request \nfor comment on the investigation, which The Washington Post was first to report. \nAlong with news organizations, book authors have sought compensation for their works being used to train AI \nsystems. More than 4,000 writers --- among them Nora Roberts, Margaret Atwood, Louise Erdrich and Jodi Picoult  \nsigned a letter late last month to the CEOs of OpenAI, Google, Microsoft, Meta and other AI developers accusing \nthem of exploitative practices in building chatbots that \"mimic and regurgitate\" their language, style and ideas. \nSome novelists and the comedian Sarah Silverman have also sued OpenAI for copyright infringement. \n\"We are pleased that OpenAI recognizes that fact-based, nonpartisan news content is essential to this evolving \ntechnology, and that they respect the value of our intellectual property,\" said a written statement from Kristin \nHeitmann, AP senior vice president and chief revenue officer. \"AP firmly supports a framework that will ensure \nintellectual property is protected and content creators are fairly compensated for their work.\" \nThe two companies said they are also examining \"potential use cases for generative AI in news products and \nservices,\" though didn't give specifics. OpenAI and AP both \"believe in the responsible creation and use of these AI \nsystems,\" the statement said. \nChatGPT-maker OpenAI signs deal with AP to license news stories\nOpenAI will have access to AP news stories going back to 1985. \nThe AP deal is valuable to a company like OpenAI because it provides a trove of material that it can use for training \npurposes, and is also a hedge against losing access to material because of lawsuits that have threatened its access \nto material, said Nick Diakopoulos, a professor of communications studies and computer science at Northwestern \nUniversity. \n\"In order to guard against how the courts may decide, maybe you want to go out and sign licensing deals so you're \nguaranteed legal access to the material you'll need,\" Diakopoulos said. \nThe AP doesn't currently use any generative AI in its news stories, but has used other forms of AI for nearly a \ndecade, including to automate corporate earnings reports and recap some sporting events. It also runs a program \nthat helps local news organizations incorporate AI into their operations, and recently launched an AI-powered image \narchive search. \nThe deal's effects could reach far beyond the AP because of the organization's size and its deep ties to other news \noutlets, said news industry analyst Ken Doctor. \nWhen AP decided to open up its content for free on the internet in the 1990s, it led many newspaper companies to \ndo the same, which \"turned out to be a very bad idea\" for the news business, Doctor said. \nHe said navigating \"a new, AI-driven landscape is deeply uncertain\" and presents similar risks. \n\"The industry is far weaker today. AP is in OK shape. It's stable. But the newspaper industry around it is really \ngasping for air,\" Doctor said. \"On the positive side, AP has the clout to do a deal like this and can work with local \npublishers to try to assess both the potential and the risk.\" \nAssociated Press writer David Bauder contributed to this report.\nGraphic\n \nFILE - The logo for OpenAI, the maker of ChatGPT, appears on a mobile phone, in New York, Tuesday, Jan. 31, \n2023. ChatGPT-maker OpenAI and The Associated Press said Thursday that they've made a deal for the artificial \nintelligence company to license AP's archive of news stories. (AP Photo/Richard Drew, File)\nLoad-Date: July 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "New Questions About Liability for Artificial Intelligence Creations",
        "media": "The New York Times",
        "time": "June 5, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5; DEALBOOK NEWSLETTER",
        "length": "2005 words",
        "byline": "By Ephrat Livni, Sarah Kessler and Ravi Mattu",
        "story_text": "New Questions About Liability for Artificial Intelligence Creations\nThe New York Times\nJune 5, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5; DEALBOOK NEWSLETTER\nLength: 2005 words\nByline: By Ephrat Livni, Sarah Kessler and Ravi Mattu\nBody\nTools like ChatGPT could open a new line of questions around tech products and harmful content.\nA string of challenges to Section 230 -- the law that shields online platforms from liability for user-generated content \n-- have failed over the last several weeks. Most recently, the Supreme Court declined on Tuesday to review a suit \nabout exploitative content on Reddit. But the debate over what responsibility tech companies have for harmful \ncontent is far from settled -- and generative artificial intelligence tools like the ChatGPT chatbot could open a \nnew line of questions. \n  Does Section 230 apply to generative A.I.? The law's 1996 drafters told DealBook that it does not. ''We set out to \nprotect hosting,'' said Senator Ron Wyden, Democrat of Oregon. Platforms are immune only to suits about material \ncreated by others, not their own work. ''If you are partly complicit in content creation, you don't get the shield,'' \nagreed Chris Cox, a former Republican representative from California. But they admit that these distinctions, which \nonce seemed simple, are already becoming more difficult to make.\n  What about A.I. search engines? Typically, search engines are considered vehicles for information rather than \ncontent creators, and search companies have benefited from Section 230 protection. Chatbots generate content, \nand they are most likely beyond protection. But tech giants like Microsoft and Google are integrating chat and \nsearch, complicating matters. ''If some search engines start to look more like chat output, the lines will be blurred,'' \nWyden said.\n  A deadly recipe? Generative A.I. tools have already been used to make intentionally harmful content. And \nhallucinations -- the falsehoods that generative A.I. tools create (like court cases that never existed) -- are a \nsignificant problem. If a user prompts an A.I. for cocktail instructions and it offers a poisonous concoction, the \nalgorithm operator's liability is obvious, said Eric Goldman, a law professor at Santa Clara University and a Section \n230 expert.\n  But most situations won't be that clear-cut, and that poses a risk, Goldman said. He fears that anger over immunity \nfor social media platforms threatens nuanced debate about the next generation of tech development.\n  ''The blossoming of A.I. comes at one of the most precarious times amid a maturing tech backlash,'' Goldman \nsaid. ''We need some kind of immunity for people who make the tools,'' he added. ''Without it, we're never going to \nsee the full potential of A.I.'' -- Ephrat Livni\n  IN CASE YOU MISSED IT \nNew Questions About Liability for Artificial Intelligence Creations\n  Elon Musk receives a hero's welcome in China. The Tesla chief was hailed on Chinese social media as a ''global \nidol'' during his visit this week to the country, where he met with government ministers and visited the Tesla's \nShanghai factory. Musk reportedly also had kind words for his hosts: Government readouts of his meetings with \nBeijing ministers said he had described the U.S. and Chinese economies as ''conjoined twins'' and opposed political \nefforts to decouple them.\n  Billy Joel is movin' out (of Madison Square Garden). The singer announced this week that he will finish a 10-year \nstay at Madison Square Garden in July 2024. The series of more than 100 shows crossed its $200 million threshold \nin March. James Dolan, the C.E.O of the Garden's parent company, said the run had ''made history'' for both the \nvenue and the music industry. Or, perhaps more simply: Joel was a big shot.\n  ''Ketatations'' in the workplace. Some executives have embraced the anesthetic ketamine to improve professional \nperformance or foster team bonding. ''We put them on yoga mats in the room, we have a prescription from a doctor, \nand we have a 45-minute experience together,'' Kaia Roman, who has led ''ketatations'' (ketamine + meditation) \nsince the pandemic, told Bloomberg. Others prefer a more aggressive way to relax: Mark Zuckerberg recently \ncompleted ''the Murph Challenge,'' which consists of a mile run, 100 pull-ups, 200 push-ups, 300 squats and \nanother mile run -- all while wearing a 20-pound vest. He said he had done it in 40 minutes.\n  Matter of debate: 'greedflation' \n  General inflation slowed for the 10th straight month in April, but many companies are still raising prices. Why? \nSome economists blame ''greedflation,'' ''excuseflation'' or a ''price-price spiral,'' whereby businesses use \ninflationary events like the pandemic, the Ukraine war and soaring energy prices as an excuse to make big price \nincreases that more than cover their higher costs. The idea is that customers are more accepting of price increases \nwhen they know inflation is historically high, so companies are taking the opportunity to raise prices as much as \nthey can. But not everyone is convinced, and some point to a host of other postpandemic economic trends as the \nreal culprit. Here are two views.\n  Greedflation is to blame. Despite expectations that net profit margins would decline this year, they have increased \nat the average company in the S&P 500, according to data from FactSet.\n  ''What we see in many cases is that volumes are going down, while prices are going up and profit margins are \ngoing up,'' said Isabella Weber, a professor at the University of Massachusetts Amherst, who pioneered the theory.\n  She pointed to Starbucks as an extreme example of what she calls ''sellers' inflation.'' In 2020, when the pandemic \nshut down demand for coffee shops, basic supply-and-demand laws suggested that Starbucks would lower the \nprice of coffee to entice people back to its stores. Instead, Weber said, ''prices actually were going up.''\n  Last month, the Federal Reserve Bank of Kansas City said corporate profits had contributed to inflation in 2021, \nthough their contribution fell in 2022, which is consistent with what happened in previous economic recoveries.\n  Greedflation is not to blame. Customers who benefited from stimulus checks, low interest rates, investment gains \nand other factors were in a good financial position coming out of the pandemic. Their willingness to spend more is \nwhat's mostly fueling inflation, some analysts say.\n  ''It seems to me that many telling the profit story forget that households have to actually spend money for the story \nto hold,'' David Beckworth, a senior research fellow at the right-leaning Mercatus Center at George Mason \nUniversity and a former economist for the Treasury Department, told The Times this week. ''And once you look at \nthe huge surge in spending, it becomes inescapable to me where the causality lies.''\n  In any case, conditions for greedflation could be waning. Supply chain disruptions and other inflationary pressures \nare easing, making it harder for companies to blame inflation elsewhere for raising prices. ''Some firms are claiming \n'general inflation pressures' as being behind their price increases,'' said Paul Donovan, the chief economist at UBS, \n''but that is far less convincing, and consumers are less willing to accept it.''\nNew Questions About Liability for Artificial Intelligence Creations\n  Weber warns, however, that another inflation-causing crisis could pop up at any time, and ''firms have now learned \nthis playbook.''\n  The Ted Lasso way \n  ''Ted Lasso,'' the saccharine story of an apparently clueless American who is appointed to run a British soccer \nteam, ended this week. And while Lasso's journey from barely knowing the rules to turning a group of misfits into a \ntop team is not particularly realistic, management experts say some of his coaching strategies really are.\n  DealBook has picked out four management lessons from the fictional coach from Kansas that might apply to the \nreal world. Warning: They contain spoilers.\n  The outsider sees things that others do not. Lasso is initially portrayed as a naïve bumpkin with little understanding \nof the sport, his team or the country he's living in. But that is the foundation of his success, said Allyson Stewart-\nAllen, C.E.O. of International Marketing Partners and an expert on cross-cultural management. ''He brings a lack of \nself-consciousness in wanting to ask questions others might think are facile,'' she told DealBook, adding that her \nAmerican clients who are expanding in Europe do exactly what Lasso does. ''Ask lots of questions, be open to new \nideas, and experiment.''\n  Culture trumps strategy. Any team that is on the same wavelength is obviously more likely to thrive, a view \nfamously championed by management thinkers like Peter Drucker. Lasso's first task was to understand the culture \nof the organization he has taken over and then mold it in his image. Once he achieved this, he shifted to identifying \nthe strengths and weaknesses of his players and coaches, and figuring out how to motivate them. That should be \nthe goal of every good manager.\n  Serious strategic change takes time. Most executives, especially those who run public companies, are under \nimmense pressure to deliver quickly. Sometimes that's justified, but sometimes boards can be too quick to change \na C.E.O. without providing the necessary support. Lasso had three years with little real threat of being fired. That \ngave him time to understand the game (by the final episode, he had learned what the offside rule is), the culture of \nthe club and how to make it all work. It was only midway through his last season that he discovered his sporting \nvision -- ''total football'' -- that he used to turn his team of losers into winners.\n  ''Meaning matters more than means,'' Bruce Feiler, the author of ''The Search: Finding Meaningful Work in a Post-\nCareer World,'' told CNBC this week. Younger workers increasingly put a priority on work-life balance and personal \nfulfillment over money in their careers. On the show, Lasso himself best embodied that trait by walking away from \nthe job after finishing second rather than sticking around and trying to win it all again. Even though he finally \ncracked the sport, he returned to Kansas to be closer to his family. ''He shows vulnerability,'' Stewart-Allen said. ''He \ncries. He has panic attacks. He's not perfect, and he doesn't try to hide that. I think that is very realistic and \nendearing and builds empathy with people.''\n  Your thoughts on vacation \n  Last week, we wrote about a recent Pew survey that found almost half of Americans do not use all of their paid \ntime off, and we asked you for your thoughts. A lot of you cited the same reasons as respondents to the survey for \nnot using all of your time -- banking time to use in an emergency, fearing that taking vacation will make you \nvulnerable during a layoff or worrying that work will accumulate to stressful levels while you're away. We also heard \nfrom many readers who do use all of their paid time off. Here are a few of your reasons:\n  Quilvio wrote that he is in his early 20s, younger than most of his co-workers, and that ''generationally, we have \ndifferent mind-set around P.T.O. and work.'' He added, ''I think as long as I'm getting the work done, the days (and \nhours) I work aren't as important.''\n  Another reader, who asked not to be named, wrote that she used to work at a prestigious New York City law firm \nwhere most senior attorneys did not take all of their paid vacation days. Talking with them about their weekend \nleisure activities, she realized why: ''It dawned on me (silly woman) -- they have WIVES AND SERVANTS who do \nNew Questions About Liability for Artificial Intelligence Creations\nall the nonwork work for them! So they have time and energy to unwind on both evenings AND weekends. They are \nnot making calls to set up doctor appointments for their kids (or, likely, for themselves either), they are not making \ndinner after work every night, they do not attend P.T.A. meetings, they are not burdened with the zillion daily \ndecisions and tasks of keeping a household going.''\n  Stephanie, a director at a hospital, said she granted whatever time her employees needed. ''It's a retention tool,'' \nshe wrote. ''We have a high-performing team. If I take care of my managers, they take care of their staff. The staff \nthen are better able to care for their patients.''\n  Thanks for reading! \n  We'd like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com\nhttps://www.nytimes.com/2023/06/03/business/who-is-liable-for-ai-creations.html\nGraphic\n \nThis article appeared in print on page B5.               \nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Microsoft, the Union-Friendly Tech Titan",
        "media": "The New York Times",
        "time": "February 25, 2024",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 1",
        "length": "3787 words",
        "byline": "By Noam Scheiber",
        "story_text": "Microsoft, the Union-Friendly Tech Titan\nThe New York Times\nFebruary 25, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 1\nLength: 3787 words\nByline: By Noam Scheiber\nBody\nThe December day in 2021 that set off a revolution across the videogame industry appeared to start innocuously \nenough. Managers at a Wisconsin studio called Raven began meeting one by one with quality assurance testers, \nwho vet video games for bugs, to announce that the company was overhauling their department. Going forward, \nmanagers said, the lucky testers would be permanent employees, not temps. They would earn an extra $1.50 an \nhour.\nIt was only later in the morning, a Friday, that the catch became apparent: One-third of the studio's roughly 35 \ntesters were being let go as part of the overhaul. The workers were stunned. Raven was owned by Activision \nBlizzard, one of the industry's largest companies, and there appeared to be plenty of work to go around. Several \ntesters had just worked late into the night to meet a looming deadline. \n  ''My friend called me crying, saying, 'I just lost my job,''' recalled Erin Hall, one of the testers who stayed on. ''None \nof us saw that coming.''\n  The testers conferred with one another over the weekend and announced a strike on Monday. Just after they \nreturned to work seven weeks later, they filed paperwork to hold a union election. Raven never rehired the laid-off \nworkers, but the other testers won their election in May 2022, forming the first union at a major U.S. video game \ncompany.\n  It was at this point that the rebellion took a truly unusual turn. Large American companies typically challenge union \ncampaigns, as Activision had at Raven. But in this case, Activision's days as the sole decision maker were \nnumbered. In January 2022, Microsoft had announced a nearly $70 billion deal to purchase the video game maker, \nand the would-be owners seemed to take a more permissive view of labor organizing.\n  The month after the union election, Microsoft announced that it would stay neutral if any of Activision's roughly \n7,000 eligible employees sought to unionize with the Communications Workers of America -- meaning the company \nwould not try to stop the organizing, unlike most employers. Microsoft later said that it would extend the deal to \nstudios it already owned.\n  Q.A. testers can work grueling hours for low pay, and testers at other studios were already considering a union. \nTwo more groups of testers -- one at Activision and one at a Microsoft subsidiary called ZeniMax -- voted to \nunionize after the company's neutrality announcements.\n  Now that Activision is part of Microsoft -- it closed the purchase in October -- testers at several parts of the \ncombined company are seeking to unionize as well, according to union officials. These officials say that the \ncompany has bargained in good faith and that the two sides have made considerable progress toward a first \nMicrosoft , the Union-Friendly Tech Titan\ncontract. Within a few years, Microsoft could have over 1,000 union employees working under collective bargaining \nagreements, making it an outlier in big tech.\n  On one level, it seemed obvious why Microsoft, once a poster child for corporate ruthlessness, would go this route: \nThe company wanted regulators to bless its deal with Activision. Given the Biden administration's close ties with \nlabor, it didn't take a Kissingerian flair for strategy to see that a truce with unions might help. Cynics were quick to \npoint out that the company laid off nearly 10 percent of its video game workers, most of them from Activision, once \nthe deal was in hand.\n  Still, many large tech companies have business before the federal government -- and almost all have taken steps \nto discourage unionization. That includes Amazon, Apple and Google, which are in the sights of antitrust regulators.\n  Like Microsoft, these companies routinely position themselves as progressive employers, pointing to corporate \ndiversity initiatives and support for L.G.B.T.Q. rights. Some channeled their employees' anxiety over Trump-era \npolicies on travel and immigration. Yet only Microsoft, whose leaders say they have been on a ''journey'' rooted in \nthe principle that ''people have a fundamental right to organize,'' has taken a permissive path on unions.\n  And for some employees, that's a key distinction. Workers who have sought to unionize at Amazon, Apple and \nGoogle don't seem persuaded of their employers' benevolence, pointing to evidence of retaliation. (The companies \nhave denied these accusations and say they respect workers' right to organize.) The workers note that Amazon and \nGoogle have hired consulting firms that specialize in fighting unions.\n  By contrast, employees who have sought to unionize at Microsoft consider neutrality ''an absolute gift,'' said \nAutumn Mitchell, a Q.A. worker who was part of the organizing campaign.\n  All of which raises a question: In an age where companies routinely proclaim their commitments to civil rights and \nthe environment, what does it even mean to be a woke employer? And can Microsoft, on many days the most \nvaluable company in the world thanks to its success in artificial intelligence, and with a history of squeezing \ncompetitors, truly claim to be more evolved than most?\n  Remaking a Corporate Image\n  It's not hard to understand why Microsoft executives in the 1990s sometimes came off as villains. In a case that \nwent to trial in 1998, the Justice Department said Microsoft had illegally schemed to crush Netscape after the \nsmaller company rejected its offer to divvy up the browser market. Witnesses said Microsoft executives tossed \naround phrases like ''cut off their air supply'' and ''knife the baby'' when discussing competitors. (Microsoft denied at \nthe time that it had acted illegally; some executives denied using such phrases.)\n  Microsoft successfully appealed a judge's decision to break up the company, but the ordeal still proved costly. It \nprompted comparisons with the great monopolies of yore, like Standard Oil, and cast a shadow over future deals, \nlike the company's abortive attempt in 2008 to buy Yahoo. A court monitored the company for nearly a decade.\n  It was during the antitrust litigation that a Microsoft lawyer named Brad Smith auditioned for the job of general \ncounsel on the basis of a simple philosophy: ''Make peace,'' he urged his higher-ups.\n  Mr. Smith got the job, and Microsoft began to cultivate better relationships with government overseers. Even when \nMicrosoft believed regulators were overstepping their authority, Mr. Smith later recalled in a speech on the legacy of \nthe case, the company would often say ''let's figure out what it makes sense to do nonetheless.''\n  Underlying the approach was Mr. Smith's feel for the shifting ideological tides -- and his sense that shifting with \nthem would serve the company best. One colleague recalled a 2021 presentation to the company's top executives \nin which Mr. Smith predicted that the coming wave of tech regulation would be like the wave of New Deal-era \nfinancial regulations, and that ''the next five years of regulation will define next the 50 years.'' Mr. Smith said the \ncompany should help shape the new rules and adapt to them rather than resist them.\nMicrosoft , the Union-Friendly Tech Titan\n  The break with Microsoft's scorched-earth past was halting at first.In 2012, the company hired the political \nstrategist Mark Penn, who produced a negative ad campaign targeting Google's search engine.\n  But when a new chief executive, Satya Nadella, took over in 2014, he seemed determined to help complete the \nreinvention. He dispatched Mr. Smith to negotiate a peace agreement with Google. He hired a mindfulness guru \nused by the National Football League's Seattle Seahawks to work with top executives.\n  Not that Mr. Nadella and Mr. Smith, who had been promoted to president, were averse to competition. They simply \nwent about it differently. Instead of directly undermining fellow tech companies, they drew contrasts between \nMicrosoft's new high-road practices and rivals' questionable behavior -- for example, by proposing regulations on \nfacial recognition software. Unlike Microsoft, companies like Google and Apple had declined to make their facial \nrecognition versions available for government testing. (Google said the comparison isn't apt because it does not \noffer general facial recognition software.)\n  In 2015, Microsoft, a pioneer among tech companies in hiring temporary workers and contractors to work for less \npay and job security than long-term employees, became one of the first tech giants to require large contractors to \nprovide paid time off for workers assigned to its projects.\n  Amazon appeared to be a particular foil. Mr. Smith noted in his 2019 book ''Tools and Weapons'' that Amazon had \nfought a proposed Seattle tax to fund affordable housing the year before, going so far as to stop planning for a \nbuilding until the tax was lowered. Shortly after, Microsoft made a financial pledge, which eventually reached $750 \nmillion, to expand such housing.\n  (Amazon declined to comment other than to say it had invested more than $600 million in affordable housing to \ndate.)\n  The next year, Microsoft proposed a state tax to subsidize higher education that would require it and Amazon to \npay a higher rate than other businesses. ''Let's ask the largest companies in the tech sector, which are the largest \nemployers of high-skilled talent, to do a bit more,'' Mr. Smith wrote in an opinion essay. Amazon quibbled with the \ntax before backing a compromise.\n  Liberal policymakers noted the contrast between the two companies. ''The level of engagement is totally different,'' \nsaid Representative Pramila Jayapal, a Washington State Democrat who is the chair of the Congressional \nProgressive Caucus. ''It's like night and day from Amazon.''\n  In a way, Mr. Smith and Microsoft had turned the mantra of enlightened self-interest on its head. Increasingly, the \ncompany appeared to practice a kind of self-interested enlightenment, taking positions that appeared calculated to \nhighlight the ways it had reformed itself and to deflect scrutiny toward competitors. \n  The makeover was so successful that the House antitrust subcommittee invited Mr. Smith to brief members in \n2020 as they prepared for a hearing involving the chief executives of Amazon, Apple, Facebook and Google, which \nthe panel was investigating for possible anticompetitive behavior.\n  Yet 18 months later, the company's adult-in-the-room image was suddenly under assault. Shortly after Microsoft \nannounced its plans to purchase Activision, a coalition of liberal groups told the Federal Trade Commission that the \ndeal could ''lead to an undue concentration of market power,'' effectively reviving the 25-year-old critique of \nMicrosoft as a monopolist. Among the groups in the coalition was a prominent union: the Communications Workers \nof America.\n  'It Was Weird, but Good Weird'\n  If someone were to design a tech job with the goal of maximizing interest in a union, there's a good chance it \nwould look like ''quality assurance tester.'' To an outsider, the tester's job can sound dreamy -- being paid to play \nvideo games before they're publicly available. Within the industry, the work is regarded as a physical and mental \nslog. Testers frequently play sections of games over and over for hours in search of subtle glitches.\nMicrosoft , the Union-Friendly Tech Titan\n  At times they must do this during punishing stretches known as ''crunch,'' when a game release is imminent and \nthe work lasts 10 or 12 hours most days, often six days a week. \n  ''One of the things getting us bad is finding out that overtime is happening at 5:30 on a Friday afternoon,'' said \nWayne Dayberry, a tester at a Microsoft-owned studio in Maryland.\n  ''It's like, dude, we need time, you can't just do that. People have kids.''\n  And the work comes with some of the lowest pay in the industry. After their raise in late 2021, many testers at \nActivision still made under $19 an hour. Testers typically remain for years in the position with little prospect of \npromotion to other jobs, even with a college degree.\n  These frustrations had already provoked a union campaign at Activision when Microsoft announced its acquisition. \nC.W.A. officials worried that the tech giant, which had no unionized U.S. employees, would promptly squelch it, and \nthat wages and employment could fall with fewer companies competing for workers.\n  But the opposition of the politically powerful union was not absolute. During a conversation in early 2022, two top \nunion officials told Portia Wu, a Microsoft policy executive who is now Maryland's labor secretary, that a neutrality \nagreement at Activision would help reassure them. Ms. Wu, who had worked with unions as an aide to Senator \nEdward M. Kennedy, agreed to float the idea at Microsoft.\n  She told colleagues that employees tend to win once they get to a union election, which some Activision \nemployees were seeking, and that a contentious election process can damage morale. By reaching a deal with the \ncommunications workers' union, she added, Microsoft could retain more control over the narrative as well as the \ntiming of union elections, which often surprise employers.\n  Mr. Smith and other executives appeared receptive. ''Every time we've talked about this, we've all come to the \nsame point of view that this is the right path for Microsoft,'' he said in an interview with The New York Times. ''That \nwe have way more that we can potentially gain than put at risk.''\n  Chris Shelton, the union's president at the time, and Mr. Smith announced in June 2022 that Microsoft would stay \nneutral in union campaigns at Activision if the acquisition was finalized. Not long after, the union informed Microsoft \nthat a group of Q.A. testers had also been organizing at ZeniMax Media, a video game company Microsoft already \nowned, with studios in Maryland and Texas. The company agreed to grant workers at ZeniMax the same neutrality \ndeal it had negotiated for Activision.\n  Mr. Dayberry, a leader of the union campaign at ZeniMax, said the company was good to its word: Managers \nnever so much as mentioned the union, much less sought to discourage support for it. After years in which workers \nhad clashed with managers over issues like pay, promotions and scheduling, he said, ''It was weird, but good \nweird.'' The workers officially unionized in January 2023.\n  A few months earlier, Mr. Shelton had met with the F.T.C. chair, Lina Khan, and urged her to accept the Activision \ndeal in light of the neutrality agreements. But Ms. Khan, who has helped make labor considerations a key criterion \nfor analyzing mergers, was unimpressed.\n  ''Time and time again, antitrust regulators have heard promises made by companies leading up to a merger, on \neverything from labor to lowering prices, that have been reneged immediately after the merger closes,'' said \nDouglas Farrar, an F.T.C. spokesman.\n  The Activision deal finally closed in October, after a federal judge denied the F.T.C.'s request to block it \ntemporarily. Analysts say the investment is important for expanding Microsoft's presence in mobile gaming and \ncould prove highly lucrative if the company can incorporate new A.I. capabilities into its games.\n  In the meantime, the opposition of the agency -- which has appealed the ruling and said the recent layoffs \ncontradict Microsoft's earlier assurances -- has continued. (Microsoft said many of the layoffs had been planned by \nActivision.)\nMicrosoft , the Union-Friendly Tech Titan\n  The company's courtship of labor has continued as well. In December, Microsoft announced that it would \neffectively extend the neutrality agreement to any group of employees seeking to join an affiliate of the A.F.L.-\nC.I.O., the labor federation that encompasses C.W.A. and nearly 60 other unions. Roughly 100,000 people will be \neligible to unionize without opposition from their employer under the company's new framework.\n  Liz Shuler, the A.F.L.-C.I.O.'s president, said Microsoft had gone further in collaborating with organized labor than \nalmost any other major company. She said she first met Mr. Smith to discuss labor issues almost two years ago, at \nwhich point he told her, ''If workers want a union, why shouldn't they be able to form one?'' Then he added: ''This is \nthe prevailing winds of change in the country. I think Microsoft should be adapting to it instead of resisting it.''\n  A Kind of Corporate Paternalism\n  Is there such a thing as a woke corporation? Conservatives say the answer is emphatically yes. In their telling, \ncorporate executives have been foisting left-wing values on the country for decades and redoubled their efforts \naround the time of Donald J. Trump's election, taking liberal positions on transgender rights, voting rights and gun \ncontrol. They note that scores of companies announced diversity initiatives during the protests that followed George \nFloyd's death.\n  But skeptics question whether these corporate initiatives are examples of progressive convictions in action, or \nsimply investments in placating liberals and warding off calls for regulation, higher taxes and higher pay. Certainly, \nthe gestures aren't breaking the bank: In 2020, Chipotle pledged $1 million to civil rights organizations. By contrast, \na 10 percent increase in employee compensation would have cost the company tens of millions of dollars. (The \ncompany ended a 10 percent hourly pay increase about three months into the pandemic.)\n  Even companies often cited for their generosity to employees have generally spurned organized labor. Whole \nFoods and other progressive-minded companies, like Starbucks and Trader Joe's, have at times offered retail \nworkers above-market wages or benefits. Whole Foods has built an entire philosophy out of its crunchy \nrighteousness, or what its co-founder calls ''conscious capitalism.''\n  But Whole Foods fought unionization in the early 2000s, while Starbucks has been accused by the National Labor \nRelations Board of violating employees' labor rights hundreds of times since its workers began unionizing in 2021. \n(Starbucks denies the accusations; Whole Foods has said it does not believe a union is in employees' interests.)\n  When it comes to their employees, said Matthew Bodie, a law professor at the University of Minnesota, these \ncompanies favor a kind of corporate paternalism. ''We want to be beneficent, but we want to do it on our terms,'' he \nsaid, channeling executives.\n  Even tech companies famous for pampering employees have almost entirely resisted unionization. After \nemployees began to organize in 2018, partly over concerns about the company's contracts with federal security \nagencies, Google hired a consulting firm that specializes in stifling unions. The company fired at least four \nemployees involved in protesting the contracts. (Google said the firings had nothing to do with protest activity.)\n  When I asked Mr. Smith why Microsoft was willing to embrace neutrality when its competitors were not, he told me \nthat ''the tech sector has often been built by founders, and founders have often been very focused on retaining a \nlevel of control over their enterprises.'' By contrast, he said, ''I think the fact that Microsoft is a little bit older, \nsometimes a little bit wiser, at least gives us an opportunity to think more broadly.''\n  White-Collar Collective Action\n  Activision may have been the immediate impetus for Microsoft's labor stance, but the neutrality deal could benefit \nthe company far beyond the acquisition. It may be a relatively cost-effective way to cast the company as pro-worker \nat a time when millions are worried about losing their jobs to generative A.I., whose release has helped \nsupercharge Microsoft's share price. Noting that unions are not a topic raised by analysts on the company's \nearnings calls, Gil Luria, who follows Microsoft for the investment bank D.A. Davidson, said, ''I don't expect this to \nbe a material issue.''\nMicrosoft , the Union-Friendly Tech Titan\n  The move could also hamstring two of the company's competitors, Amazon and Apple, where unions have gained \ntraction in recent years.\n  If these companies don't follow Microsoft's lead on neutrality, it could add to the public relations challenges they \nface in opposing unionization. It could also give Microsoft an advantage in the highly competitive market for \nengineers, some of whom have made clear that political and social issues affect their choice of employer.\n  If, on the other hand, those companies relent on neutrality, a much larger portion of their work force could end up \nunionizing than at Microsoft. Amazon employs hundreds of thousands of workers in warehouses across the country, \nwhile Apple employs tens of thousands of workers at retail stores.\n  By contrast, a large majority of Microsoft employees in the United States are white-collar and highly paid. ''There's \nnot a threat of unionization at that level,'' said Joshua Winter, a former Microsoft Philanthropies official focused on \nbringing economic opportunity to historically underrepresented communities. ''They're taking care of those people.''\n  Yet if Microsoft assumed the union effort would end with video game workers, it may have miscalculated. Over the \npast few years, highly paid white-collar workers have begun to assert themselves far beyond Google, engaging in \nforms of collective action that resemble union organizing. Corporate employees have protested what they see as \noverly strict return-to-office policies at companies like Apple and Starbucks, and over a variety of social issues, like \ntheir employers' carbon footprint (Amazon) or lack of diversity (Nike).\n  Even at Microsoft, well-compensated employees have organized protests over political concerns. In 2018, more \nthan 100 employees urged Mr. Nadella, the chief executive, to cancel a nearly $20 million contract with the \nImmigration and Customs Enforcement agency over its role in separating migrant children from their parents. \n  Mr. Nadella responded with an email calling the family separation policy ''cruel and abusive'' and emphasizing that \nthe Trump administration was not relying on Microsoft technology to enact it. But the internal campaign continued \nthe next year, when hundreds of workers at GitHub, a Microsoft subsidiary, signed a letter demanding an end to a \nseparate contract with the agency. The pressure fizzled out after several of the employees involved left the \ncompany.\n  The outcome might have been different if they had the option of unionizing without resistance.\n  Fred Jennings, a former GitHub employee, said he and his colleagues discussed forming a union. ''Quite a few \npeople were saying, 'Look, our best lever to get this to change is to also push for a union,''' he said, adding that, in \nthe end, too many worried about retaliation to make it a viable option.\n  When I asked Mr. Jennings if neutrality would likely have changed his colleagues' appetite for unionizing, he was \nunequivocal: ''With all the advantages of hindsight,'' he said, ''absolutely.''\n  Kirsten Noyes contributed research.Kirsten Noyes contributed research.\nhttps://www.nytimes.com/2024/02/24/business/economy/microsoft-corporate-progressive-labor.html\nGraphic\n \nPHOTOS: PHOTO (PHOTOGRAPH BY CARL GODFREY) (BU1)\nAbove, from left: Brad Smith, Microsoft's president, whose philosophy is ''Make peace''\nand Satya Nadella, the company's chief executive. Below, from left: Chris Shelton, the Communications Workers of \nAmerica president who helped broker a neutrality agreement\nMicrosoft , the Union-Friendly Tech Titan\nand Representative Pramila Jayapal, who saw a contrast between Microsoft and Amazon. (PHOTOGRAPHS BY \nKYLE JOHNSON FOR THE NEW YORK TIMES\nRUTH FREMSON/THE NEW YORK TIMES\nAL DRAGO/BLOOMBERG\nALYSSA SCHUKAR FOR THE NEW YORK TIMES) (BU6)\nBelow, Mellody Hobson, the chairwoman of Starbucks, at a Capitol Hill hearing last March about the company's \nlabor practices. Bottom, members and supporters of Starbucks Workers United protested in November in \nWashington. (PHOTOGRAPHS BY SAMUEL CORUM FOR THE NEW YORK TIMES\nKENNY HOLSTON/THE NEW YORK TIMES\n KEVIN DIETSCH/GETTY IMAGES) (BU7) This article appeared in print on page BU1, BU6, BU7.               \nLoad-Date: February 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Golf’s Big Deal Veers Off Course; DealBook Newsletter",
        "media": "The New York Times",
        "time": "April 15, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1869 words",
        "byline": "Lauren Hirsch, Sarah Kessler and Bernhard Warner Lauren Hirsch joined The Times from CNBC in 2020,",
        "story_text": "Golf’s Big Deal Veers Off Course; DealBook Newsletter\nThe New York Times \nApril 13, 2024 Saturday 12:55 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1869 words\nByline: Lauren Hirsch, Sarah Kessler and Bernhard Warner Lauren Hirsch joined The Times from CNBC in 2020, \ncovering deals and the biggest stories on Wall Street. Sarah Kessler is an editor for the DealBook newsletter and \nwrites features on business and how workplaces are changing. Bernhard Warner is a senior editor for DealBook, a \nnewsletter from The Times, covering business trends, the economy and the markets.\nHighlight: The Masters tournament should be all about sport, but the unresolved fight between the PGA Tour and \nLIV Golf looms over the competition.\nBody\nThe Masters tournament should be all about sport, but the unresolved fight between the PGA Tour and LIV Golf \nlooms over the competition.\nIn the rough \nThe Masters is a tournament steeped in tradition and hosts one of sports’ most storied gatherings: the champions \ndinner, when former winners meet at Augusta National Golf Club, and the previous year’s winner sets the menu.\nBut this week’s dinner was overshadowed by the fight between the PGA Tour and the Saudi-backed LIV Golf series \nthat has split the sport. Last June, the two sides agreed to combine forces and end their battle. A deal hasn’t \nmaterialized — and possibly never will.\nThe only certainties, according to insiders who have spoken to DealBook, are that a final agreement isn’t imminent \nafter a series of deadlines have come and gone. The players, who have become more powerful than ever, want an \nagreement. And whatever happens between the PGA and LIV may permanently shape the future of professional \nsports.\nThe Masters and the dinner highlight the schism. The 2023 winner, Jon Rahm, designed a menu that reflected his \nroots in the Basque region of northern Spain. There was, however, a bitter taste to his triumphant return: He quit the \nPGA Tour for LIV almost four months ago.\nIt took a legend of the sport, the two-time Masters winner Tom Watson, to take on the issue that was on everyone’s \nminds. “Ain’t it good to be together again?” he recounted telling them at a news conference two days later. “I hope \nthat the players themselves took that to say, you know, we have to do something. We have to do something.”\nThe tours haven’t been sitting back. LIV is confident that more players will follow after Rahm’s defection.\nThe PGA Tour, meanwhile, is trying to build up its firepower and reach. In January, it secured an investment of up \nto $3 billion from a group led by Fenway Sports Group, owner of the Boston Red Sox. The group included Arthur \nBlank, a co-founder of Home Depot and the owner of the Atlanta Falcons; the hedge fund billionaire and New York \nMets owner Steve Cohen, via his family office; the basketball star LeBron James; and the rapper Drake.\nGolf’s Big Deal Veers Off Course DealBook Newsletter\nAs part of the deal, the PGA Tour set up a for-profit company to better manage its commercial operations and better \nconnect with younger fans. Players received equity as part of the deal, an effort to help retain talent as LIV Golf \ncontinues to poach them.\nCrucially, the U.S. investors aren’t trying to outspend the Saudis, and the deal was structured to allow for the \npossibility of additional funds from LIV’s backers.\nTalks are intermittent and a lot of obstacles need to be navigated. Yasir al-Rumayyan, governor of the Saudi \nsovereign wealth fund that finances LIV, held a summit in the Bahamas that included his first official meeting with \nthe players on the PGA Policy Tour board, which includes Tiger Woods. The meeting was productive for fostering \ngood will between the sides, DealBook hears, but there was no agreement on merger details. In the words of one \ninsider: The longer a couple are engaged, the more doubtful it is that the marriage will ever happen.\nBig questions remain unresolved, including:\n• Would a deal create a monopoly? The Justice Department plans to scrutinize any tie-up. If LIV were to \ndisappear, it would be a red flag to regulators. But it could also be contentious if LIV continues. As part of \nthe original framework agreement, al-Rumayyan would serve as the chairman of the joint entity. Serving on \nthe board of both entities could irk regulators, who are already investigating directors who simultaneously \nserve on boards of competitors.\n• What is LIV’s value? To sign a deal, the two sides need to agree on a valuation. LIV is propped up by the \nhuge amount of capital the Saudi wealth fund can tap. It touts the individual teams it has created as a part \nof the tour, but the dollar value of those teams has yet to be determined, and there are questions within the \ntour over whether that model works at all. Revenue from LIV’s media rights, which include a deal with the \nCW network, is thought to be paltry. The likelihood that LIV makes a significant amount on site at \ntournaments is also slim, given the high cost of putting on the events.\nThe expensive fight can’t last. Even the oil-rich Saudis, who are investing in sports worldwide to diversify their \neconomy, are signaling a rethink on spending. This month, the kingdom scaled back its ambitions for a new $1.5 \ntrillion desert city in what may be a sign that even golf can’t out-drive financial reality. — Lauren Hirsch\nIN CASE YOU MISSED IT \nA hot inflation report scrambles Wall Street’s bets on interest rate cuts. The Consumer Price Index came in higher \nthan forecast for the third consecutive month, prompting a slew of banks to slash their bets on Fed rate cuts this \nyear. Higher inflation is expected to force the central bank to keep borrowing costs higher for longer, a scenario that \nspooked investors.\nJamie Dimon sees “unsettling” global risks weighing on the markets and his firm. The JPMorgan Chase C.E.O. \ndelivered the sober assessment yesterday after mixed first-quarter results. Dimon didn’t predict a recession, but \nsaid that “the chance of bad outcomes is higher than people think.” In his annual letter to shareholders earlier this \nweek, he warned that the economy was resilient but said high government spending and deficits and global \nuncertainty couldn’t be ignored.\nAmazon and Apple double down on artificial intelligence. Andy Jassy, Amazon’s chief, told shareholders this week \nthat its push into generative A.I. would produce new products and business lines, and that it would ramp up \ninvestment to develop its own A.I.-ready chips. Separately, Apple plans to overhaul its Mac line of personal \ncomputers with in-house M4 chips to make the devices more A.I.-capable, Bloomberg reports.\nShareholders speak out on Paramount’s talks with Skydance. A number of investors publicly voiced their concerns \nabout Paramount’s decision to enter exclusive negotiations with Skydance. They worry that the deal will see the \ncontrolling shareholder, Shari Redstone, sell her shares for a premium but leave other investors with diluted stakes. \nParamount also disclosed in a regulatory filing that four of its directors would not run for re-election at the \ncompany’s annual meeting in June.\nGolf’s Big Deal Veers Off Course DealBook Newsletter\nNational Security Inc. \nWhether they like it or not, companies are playing a bigger role in national security. Big Tech often spots suspicious \nactivity by rogue state actors before the Pentagon does. Ahead of Russia’s invasion of Ukraine, for example, \nMicrosoft figured correctly that Moscow would launch a cyberattack before a land invasion.\nThese details (and more) are laid out in “New Cold Wars,” the latest book by David Sanger, The Times’s White \nHouse and national security correspondent. This interview has been condensed and edited for clarity.\nHow are companies being used for national security?\nCompanies, especially the big internet service providers, frequently see malicious activity long before the \ngovernment can because U.S. intelligence services are, by and large, barred from operating inside the U.S. and \ninside American corporate networks.\nIn the Ukraine case, it was Microsoft and then Google that picked up the signs that the Russians were beginning to \nplace code in both critical infrastructure and government offices — an effort to bring the Ukrainian government \ndown electronically before a physical invasion.\nMicrosoft and other companies, including Amazon, then stepped in to help move Ukraine to the cloud and keep the \ngovernment operating. That’s a role companies have really never played before.\nTo what extent does the government consider private companies that control critical infrastructure to be national \nsecurity risks?\nElon Musk briefly was a poster child for the risks of companies getting deeply involved in national security. The \nUkrainians famously called him and asked if he would open up Starlink, his satellite internet company, to enable \nthem to basically attack Russian ships off Crimea, and he refused for fear that it might start a nuclear war because \nsomeone had told him that.\nSuddenly you had a C.E.O. making the kinds of decisions you would expect to be made by the national security \nadviser. He got so much heat for this that he’s now working with the Defense Department on a separate, classified \nversion of Starlink, called Starshield, that will be run entirely by the Pentagon so that he can get out of making those \ndecisions.\nWhat risks are posed by artificial intelligence?\nA.I. may make it far easier to make deepfakes and far easier to spew out disinformation. On the other hand, it \nenables you to automate cyber defense to a great degree.\nThere are already discussions underway with China about whether or not A.I. should ever be entrusted with making \ndecisions about how and when you might use nuclear weapons.\nThe real question of the new Cold Wars is whether or not nations that are pitted against each other as fiercely as \nChina, Russia and the U.S. are can also agree to some common-ground rules that would govern A.I. and its \noffshoots. And we’re far from that.\n“It’s a little bit like fixing a car while its running.” \n— Ben Bernanke, the former Fed chair, on the need to radically reform how the Bank of England makes its \nforecasts for the British economy. The central bank commissioned Bernanke to lead a review after it failed to predict \nsurging inflation, and he found “significant shortcomings” in the bank’s economic modeling that was made worse by \nusing antiquated software.\nPerson in the news: Nicolai Tangen \nGolf’s Big Deal Veers Off Course DealBook Newsletter\nMicrosoft’s Satya Nadella, Citigroup’s Jane Fraser, Exxon’s Darren Wood — they’re among the parade of business \nleaders to appear recently on “In Good Company,” a buzzy podcast developed by Norway’s massive sovereign \nwealth fund and one of the world’s most important investors.\nThe interview-style series is the brainchild of Nicolai Tangen, the 57-year-old C.E.O. of Norges Bank Investment \nManagement. The former hedge fund manager returned from London to his native Norway in 2020 to take the job, \ntriggering a kind of national reckoning over whether a wealthy investor was the best choice to oversee the rainy day \nfund in a famously egalitarian country.\nLess than four years later, the fund has swelled to a $1.6 trillion behemoth, helped by rising oil prices. Tangen saw \nthe fund’s size as an opportunity to open doors at some of the most consequential companies in the world. He’s \nright: The fund has a stake in almost every listed company in the world. “I thought, you know, we own all these \ncompanies, we own big stakes, we actually have access to these C.E.O.s,” he told The Wall Street Journal.\nTangen has a knack for getting his interviewees to open up. This week, Elon Musk made headlines by predicting on \nthe show that artificial intelligence would surpass human intelligence next year. The shows have covered vast \nground, including the energy transition, the colonization of Mars and whether — in a conversation with Russell \nWeiner, chief executive of Domino’s Pizza — it’s ever OK to put pineapple on pizza.\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nThis article appeared in print on page B3.\nLoad-Date: April 15, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jul2023",
        "header": "25% of AMD's Workforce is Now Based out of India: Top Exec",
        "media": "Economic Times (E-Paper Edition)",
        "time": "July 25, 2023",
        "section": "STARTUPS & TECH",
        "length": "591 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "25% of AMD's Workforce is Now Based out of India: Top Exec\nEconomic Times (E-Paper Edition)\nJuly 24, 2023 Monday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 591 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Vinay Sinha says 6,000 engineers in India are looped into every aspect of data centre business; firm’s \nbusiness doubled in last two years\nBody\nBengaluru: India is key to the data centre focus of California-based semiconductor company Advanced Micro \nDevices (AMD) and 25% of its workforce is now in India, said a senior executive of the company. Vinay Sinha, \ncorporate vice president — India Sales, AMD, told ET that more than 6,000 engineers in India are closely looped \ninto every aspect of the data centre business and that the company has seen its business double in the past two \nyears. The company's technology spans artificial intelligence (AI), healthcare, aerospace, automotive, gaming and \nentertainment.  “Our India teams do a lot of work for server chip design as well as network equipment development. \nAMD's ope-  rations in India are central to every major product and design offering and are expected to continue to \nbe so,” said Sinha. He said it is critical to have the chip design done in India, with the vast engineering talent pool in \nthe country. The Xilinx and Pensando acquisitions last year diversified AMD's portfolio of central processing units \n(CPUs) and graphics processing units (GPUs), to include system-on-  chips, field programmable gate arrays and \nsmart network interface cards. “We can deliver differentiated intellectual properties and designs to become the \ninnovation hub for our company especially around new technologies like artificial intelligence and machine \nlearning,” said Sinha.  AMD recognises the importance of its engineering talent as the backbone  of the company \nand is focused on retaining and hiring the right talent for continued growth, he said. “The India engineering team \nhas considerable ownership across silicon and software for our server product line, including fourth generation \nEPYC. In fact, Indian engineers have played a central role in every generation of the EPYC server processor series, \nand the teams in Bengaluru and Hyderabad were involved in building the processor from scratch,” said Sinha.  India \nhas about a fifth of the world's chip design engineers.  AMD's local team is integral to its global research and \ndevelopment workforce, said Sinha. “India plays a big role in our development resources, both company-wide and \nfor data centres,” he said.  From a design perspective, the company's philosophy is not to look at India for cost \narbitrage, according to Sinha. “We would like to do end-toend design in India. We've invested for many years and \nso at some point to do end to end products in India is very much a possibility. And for that we require the \nmanufacturing infrastructure as well,” he said.  As chairperson of the 13-member Semicon India Future Skills Talent \nCommittee, Jaya Jagdish, AMD India country head had submitted a report to the government on ways to strengthen \nthe semicon talent in India. This year, the company will be partnering  with the government and All India Council for \nTechnical Education to act on the recommendations. AMD is also focused on accelerating the deployment of AMD \nAI platforms at scale in the data centre, led by the launch of its Instinct MI300 accelerators planned for later this \nyear, said Sinha. The company is investing in innovations such as advanced packaging and 3D stacking, chiplet \narchitectures, and AMD Instinct MI300X GPUs and MI300A APUs.  The company believes that AI requires multiple \nengines and GPUs are critical for the type of generative AI workloads that are occurring at hyperscalers, he said. \n“We have the capability to offer AI solutions from the cloud to the edge to the endpoints,” he said. (The author was \nin San Francisco at the invitation of AMD)\n25% of AMD 's Workforce is Now Based out of India : Top Exec\nLoad-Date: July 25, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "What lies ahead for Nifty IT in a shifting landscape?",
        "media": "The Economic Times",
        "time": "January 20, 2024",
        "section": "STOCK IN NEWS",
        "length": "758 words",
        "byline": "Jimeet Modi",
        "story_text": "What lies ahead for Nifty IT in a shifting landscape?\nThe Economic Times\nJanuary 20, 2024 Saturday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 758 words\nByline: Jimeet Modi\nBody\nIndia's dominant position in the global technology landscape has traditionally been fueled by its robust IT services \nsector. Despite its historical strength, the sector has encountered significant challenges in the past year, primarily \ndue to macroeconomic factors. But, are the signs of worrying over for the Indian IT sector? Let’s have a look.In a \nseasonally weak quarter, major Indian IT firms reported robust Q3 numbers. While the US macroeconomic \nconditions are not yet out of the woods, as reflected in management actions like either tightening or lowering the \nrevenue guidance growth. However, there are green shoots visible with a notable uptick in deal momentum across \nvarious markets, and then there is considerable enthusiasm surrounding Generative AI, suggesting potential for \nfuture advancements in the sector.So, will the Nifty IT Sector outperform?Didn’t I already tell you that in our article 3 \nmonths ago?The following chart depicts a decade-long assessment of Nifty IT, highlighting the contrast in its \nreturns between the initial six months and the latter part of each calendar year. \nImpressively, the IT index demonstrated notably stronger performance during the latter half in 7 out of 10 years. \nThe average return in the first half of the calendar year, spanning from 2013 to 2022, stands at 3%, while in the \nsecond half, it surges to an impressive 17%. This consistent trend persisted in 2023, with a 3% return in the first \nhalf and a remarkable 20% return in the second half.In our article, we also touched upon the correlation between \nthe Nifty IT index and the Nasdaq 100 index, revealing a historical trend of a positive linear relationship between the \ntwo. The Nifty IT index which was underperforming the Nasdaq 100 index has gradually converged towards the \nNasdaq 100 index. The accompanying chart illustrates the performance of the Nifty IT index and the Nasdaq 100 \nindex up to the present moment.However, global economic uncertainties have further intensified with two ongoing \nwars showing no signs of resolution. Additionally, the uncertainty over the future US interest rates still looms. To \nadd insult to injury, the Red Sea crisis has resulted in cargo diversions leading to increased costs. In this \nlandscape, clients are currently prioritizing the enhancement of existing system efficiencies rather than embarking \non new transformational projects. This restrained approach has resulted in less than dramatic topline performance \nof IT firms with new deals slowing down and firms keeping a sharp eye on headcount and fresh recruitment to \nsecure the bottom line.Further, the Nifty IT index is presently trading at a Price-to-Earnings (PE) ratio of nearly 31, \nsignifying a notable premium compared to its 5-year average PE of 26. Considering these factors, it is imperative \nfor stakeholders to diligently track these developments and seize emerging opportunities. By doing so, they can \nmake more informed and rational decisions that align with their financial goals and risk tolerance.Technical \nOutlook:The Nifty50 hit a fresh all-time high of 22,124 on 16th January, 2024. The Index cracked nearly 4% in the \nnext two days until 21,286 before recovering marginally and closing higher on 19th January. The Nifty50 has \nformed a bearish engulfing candle on the weekly chart, which is usually considered a bearish reversal signal. \nDespite the price hitting fresh highs of 22,124 on 16th January, the Relative Strength Index (RSI) moved in a lower \nhigh formation, indicating a bearish divergence. The India VIX, known as the fear indicator, touched a high of 15.70 \nthis week, giving major discomfort to the bulls. The Foreign Portfolio Investors (FPIs) activity in Index futures \nremained subdued since the start of the January series. The Long-Short ratio kept hovering in the 65-69% range \nbefore falling to 49.09% on 18th January as FPIs liquidated long positions and aggressively built short positions in \nWhat lies ahead for Nifty IT in a shifting landscape?\nIndex futures. The Put-Call ratio (PCR) fell below 1 and closed at 0.80 for the first time since 28th November, 2023 \nas the call writers exerted dominance over the put writers.As we approach the last week of the January series \nexpiry, the level of 21,500 is likely to act as strong support. The maximum put open interest is placed at 21,500 \nStrike. The level of 21,800 will act as a strong resistance. If put writers exit from 21,500 Strike, the fall can extend \nfurther until 21,000 levels while short covering at the 21,700 & 21,800 Strike can result in the index moving higher. \nFor Reprint Rights: timescontent.com\nLoad-Date: January 20, 2024"
    },
    {
        "file_name": "has._Aug2023",
        "header": "SAG-AFTRA is worried about AI, but can it really replace actors? It already",
        "media": "has.",
        "time": "August 2, 2023",
        "section": "ENTERTAINMENT: LATEST",
        "length": "1907 words",
        "byline": "Kelly Lawler, USA TODAY",
        "story_text": "SAG-AFTRA is worried about AI, but can it really replace actors? It already \nhas.\nUSA Today Online\nAugust 1, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: ENTERTAINMENT: LATEST\nLength: 1907 words\nByline: Kelly Lawler, USA TODAY\nBody\nHaley Joel Osment as an eerie android child in a futuristic world. Will Smith battling a flood of murderous robots. \nData (Brent Spiner) on the deck of the U.S.S. Enterprise.\nHollywood has furnished the world with an abundance of stories about artificial intelligence, utopian and dystopian \nalike. But it's unlikely that the writers who penned those sci-fi scripts, or the actors giving soul to a machine, ever \nthought that AI might represent a serious threat to their livelihoods.\nYet that's exactly the fear of SAG-AFTRA and the Writers Guild of America, unions representing American actors \nand screenwriters. Both guilds are on strike (the first time both have done so at once since 1960), and a key issue \nholding up negotiations with the major Hollywood studios is the use and regulation of AI. The unions worry that text \ngenerators like ChatGPT could write screenplays and actors’ images could be used to create characters without \nany humans involved. \n\"We will not be having our jobs taken away and given to robots,” \"Breaking Bad\" actor Bryan Cranston said at a \nrecent rally in support of the SAG-AFTRA strike. “We will not allow you to take away our dignity.\" Meanwhile, the \nAlliance of Motion Picture and Television Producers (AMPTP), which represents the major Hollywood studios, says \nit has offered “groundbreaking protections” to prevent that. \nBut could generative artificial intelligence really replace writers and actors on movie sets? Could we one day see \na TV show written by a computer and \"acted\" by images of humans created by a machine, as a recent episode of \nNetflix sci-fi drama \"Black Mirror\" depicted? Is AI really the major threat to artists that many are saying?\nLink to Image\n“Totally,” says Haibing Lu, associate professor of Information Systems & Analytics at Santa Clara University. “I don't \nthink that there's a way to totally ban the technology. We have to adapt to it. All parties need to sit down and figure \nout what’s the proper way to channel the profits.” \nAt the moment, the parties aren’t sitting down. No negotiations have been scheduled between the AMPTP and the \nstriking unions. When they finally meet again, they will have to put rules about the use of AI into new contracts. And \nthe stakes are high, not only for the writers, actors and studios but for the rest of us. Would we want to watch \nmovies and TV shows made by machines? Would they be original at all? Could they make us laugh and cry? Would \nartificially intelligent art have a soul?\nAnd − crucially − is AI coming for our jobs too? \nGenerative AI makes new things, but it starts by learning about old things \nSAG-AFTRA is worried about AI, but can it really replace actors? It already has.\nAI applications like ChatGPT and Midjourney create new text or images, but first, they must be trained on material \nthat is similar to the content they are trying to generate. \nText generators, also called Large Language Models, offer plenty of material for training. “There's a huge amount of \ntext available on the internet, so it is very easy for them to collect and train,” Lu says. There are fewer photos and \nvideos online than text, but AI models are still training on images they can find. “Your photos and my photos have \nprobably already been collected and used. It's happening with more and more powerful technologies.”\nJustine Bateman, the actor, writer and director who has been vocally opposed to the use of AI in filmmaking, \ndescribes it as “like a box. Say you want it to write books. You feed it a bunch of books, and then you give it a task: \n'Write me a book about pandas and outer space,' and it'll spit out that book.” For her and others in the \nentertainment industry, it’s not just that AI could replace their work; it’s that any ChatGPT script or Midjourney movie \nwould be partly based on the existing work of filmmakers. “Imagine something coming in and not only displacing \nyou but displacing you with your own work,” she says.\n        Who is in SAG-AFTRA, anyway? The union has more working class actors than movie stars            \nHollywood is already chock full of AI − how much more can machines do?\nThe guilds and the AMPTP may be arguing about the use of AI in films, but part of the future is already here. Actor \nPeter Cushing died in 1994, but he was digitally resurrected for the 2016 film “Rogue One: A Star Wars Story.” \nStars like Robert De Niro, Harrison Ford and Samuel L. Jackson have been digitally de-aged for films. The late \nAnthony Bourdain’s voice was recreated for a recent documentary about the celebrity chef. A slew of profanities \nwas removed and replaced with new words and facial movements created by a computer from the 2022 film “Fall,” \nso it could earn a PG-13 rating instead of the more restrictive R. AI is part of what made all these digital effects \npossible. \n  The use of generative AI is limited by three things: Computing power, training material and time. \n“Image processing takes more computational power than the textual information,” Lu says. “It's still slow. If you want \nto generate a video, which contains many images, it's going to be very slow.” More computing power and time cost \nmore money, meaning it is cheaper and easier right now to generate text using AI than images and video. But that \ncould change. \n“The power of computers doubles every one to two years,” Lu says, meaning AI technology is advancing at an \nexponential rate. “Over the next 10 years, it is going to be amazing.”\nAI applications are also limited by what they can train on, which is a big part of the fight between the AMPTP and \nthe two guilds. Should the people who created the materials that train AI be paid when their work is used? Are they \nlegally and ethically required to be?\n“'Generative AI’ cannot generate anything at all without first being trained on massive troves of data it then \nrecombines. Who produces that training data? People do. And those people deserve residuals,” actor and director \nJoseph Gordon-Levitt wrote in a recent op-ed in The Washington Post. Residuals are royalty payments many in the \nentertainment industry receive when their work is reused, and are a central aspect of the current labor battle. \n“Computers can reproduce the image of a dead or living person and make this person a character in a movie,” says \nDaniel Gervais, a law professor at Vanderbilt University who specializes in intellectual property law. “In the case of \na living actor, the question is whether this person will have rights when his or her image is used in a movie. \nNormally the answer is yes, but there are novel questions that emerge. Would an actor receive residuals if her \nimage was used in the movie, but she, in fact, did not act in that movie?”\nLink to Image\nThe guilds say the studios want to replace them with AI, but the studios say otherwise \nSAG-AFTRA is worried about AI, but can it really replace actors? It already has.\nAt SAG-AFTRA's press conference announcing the strike, the union’s chief negotiator, Duncan Crabtree-Ireland, \nsaid the AMPTP wanted the right to scan the images of background actors (also called extras) and use their \nlikenesses in perpetuity in any project they want, for one day’s pay. The AMPTP vehemently disputes that claim, \nsaying its most recent proposal only “permits a company to use the digital replica of a background actor in the \nmotion picture for which the background actor is employed.” \nSAG-AFTRA claims the AMPTP’s plans leave “principal performers and background actors vulnerable to having \nmost of their work replaced by digital replicas,” while the AMPTP says it wants to establish provisions that “require \ninformed consent and fair compensation.” The WGA, meanwhile, wants a new contract to say that “AI can’t write or \nrewrite literary material (and) can’t be used as source material,” nor can the writers' work be used to train AI. The \nAMPTP response to the WGA says the topic of AI needs “a lot more discussion.”\nThese proposals could change Hollywood, depending on how the strikes are resolved. While the AMPTP’s \nbackground actor proposal is not as drastic as Crabtree-Ireland suggests, any move to limit the work of background \nactors, who are often paid minimum wage, could remove a road to success for aspiring actors. Many actors get \ntheir start (and their SAG-AFTRA membership cards) by working as extras. “There was a time where we all had to \ndo background work,” says Michael James Lazar, a SAG-AFTRA member who has had roles on shows like “How to \nGet Away With Murder.” “This phases them out.” \nThe use of AI material for scriptwriting also could remove career paths for new writers, even if it’s just used to assist \nor supplement. \n“Most writers in the guild don't make their living by writing scripts from scratch,” says Jason Vredenburg, a professor \nof film and TV studies at Stevens Institute of Technology. “A lot of times they piece together a living by working on \nother people's scripts. That is where artificial intelligence is a more immediate threat.”\nMany people in Hollywood see this as an existential threat. “If big corporations think that they can put human beings \nout of work and replace them with artificial intelligence, it's dangerous,” Fran Drescher, president of SAG-AFTRA, \ntold USA TODAY. “And it's without thinking or conscience. Or caring. And that's just the tip of the iceberg.”\nJoe Russo, co-director of “Avengers: Endgame,” recently predicted a more frightening future for AI in entertainment. \n“You could walk into your house and say to the AI on your streaming platform, ‘Hey, I want a movie starring my \nphotoreal avatar and Marilyn Monroe's photoreal avatar,” he said on a panel at the Sands International Film Festival \nin Scotland last April. “And suddenly, now you have a rom-com starring you that's 90 minutes long.”\nLink to Image\nAI could affect workers far beyond Hollywood\nThere are several lawsuits pending in the U.S. about AI, and their outcomes will be consequential for everyone, not \njust those working in Hollywood. \n“The United States copyright office, and most scholars, consider that a machine cannot be an author,” says \nGervais. “Should a court decide otherwise, there will be an enormous push to replace human authors with \nmachines in all industries that use copyright as the basis for their business, including music, film, book publishing \n(and) journalism.”\nIt's not just jobs in the arts and publishing that Gervais sees being threatened by AI. \"Machines will be able to \nreplace humans at many jobs considered 'cognitive,' which includes many white-collar jobs,\" he says. \"Ironically, it \nwill be harder to replace manual labor.\"\nLu doesn’t think the situation is quite as dire. “AI can help us to do a lot of things, but it still requires experts to verify \nthe accuracy of the information,” he says, noting that some lawyers recently tried to write a brief using ChatGPT, \nwhich spat out inaccurate information. “I don't think that AI will completely replace human beings. But AI has \nSAG-AFTRA is worried about AI, but can it really replace actors? It already has.\nbecome like a digital calculator. It's going to help us to do the basic mathematics, but we still need to learn. It just \nhelps us to improve our productivity.”\nEven if AI could one day script and create a movie without any writers, actors, directors, set designers, makeup \nartists, or cinematographers, would people want to see it?\n\"Machines can beat any human on the planet at many games, including chess,\" Gervais points out, \"yet people still \npay to watch the best human chess players play one another.\"\n\"Will it be the same with movies?\"\nContributing: Charles Trepany, Dana Taylor\nThis article originally appeared on USA TODAY: SAG-AFTRA is worried about AI, but can it really replace actors? It \nalready has.\nLoad-Date: August 2, 2023"
    },
    {
        "file_name": "The_Economic_Times_Oct2023",
        "header": "Big banks take to large language models trained on internal data",
        "media": "The Economic Times",
        "time": "October 18, 2023",
        "section": "TECH & INTERNET",
        "length": "766 words",
        "byline": "Annapurna Roy and Beena Parmar",
        "story_text": "Big banks take to large language models trained on internal data\nThe Economic Times\nOctober 18, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 766 words\nByline: Annapurna Roy and Beena Parmar\nBody\nA smart treasury, underwriting acumen and access to inexpensive deposits are no longer enough to cement \nleadership credentials in modern commercial banking. The biggest in the lending business now need technology to \ncreate irreplicable customer relationship moats that build sustainable competitive advantage.So, the biggest in \nIndia's lending business, HDFC Bank, and its private-sector rival Axis Bank, are among those in advanced stages \nof adopting private large language models (LLMs), trained on their internal data, to use generative artificial \nintelligence (AI), to build out more responsive and intuitive user experience interfaces and drive efficiencies.LLMs \nare the bedrock on which generative AI applications such as OpenAI's ChatGPT run. LLMs, focused on the \naspects that help in sharpening communication and enhancing information clarity, are cost- and time-intensive to \ndevelop.Retail-focused HDFC Bank, India's only lender with a market capitalization in excess of $100 billion, will roll \nout a private LLM-powered website in the next two quarters, Ramesh Lakshminarayanan, chief information officer \nand group head of IT, HDFC Bank, told ET. The site is in a beta stage.\"LLM brings the ability to convert buying \nthrough a lot of data points that we have and throw up intuitive write-ups that a human would do. \nThat's fundamentally where the real big advantage is,\" Lakshminarayanan said.It seeks to simplify customer \nexperience whereby, through simple prompts, a customer can quickly access information they are looking for \nregarding any product and eventually even their bank statement details.Wed words to cold stats The coming 9-12 \nmonths will also see HDFC Bank leverage a private LLM for genAI to write credit assessment models, business \nrequirement documents and so on that analysts generally have to trawl manually through a lot of data to \nwrite.Executives say both internal operations and the customer experience have the potential to be transformed \nwith private LLMs. Axis Bank is looking to start out with generative artificial intelligence (genAI)-based virtual \nassistants for customers and using inferencing capabilities to automate use cases in operations. \"We are targeting \nto implement private LLM for specific use cases by the end of FY24,\" Avinash Raghavendra, president and head - \nIT at Axis Bank, told ET. \"The bank is looking at private LLMs to envision new solutions and \nenhance/revamp/automate existing solutions.\"Generating content, whether marketing or code, with a private LLM \nas well as decision making to automate processes across streams will help achieve better business outcomes at \nthe same cost, Raghavendra said.It is actively engaging and collaborating with top cloud service providers (CSP) \nand software-as-a-service (SaaS) providers to explore options, he added.\"For both pre-trained and untrained \nmodels, the compute requirements do not make financial sense to be running in one's own data centre,\" he said. \n\"Cloud, on the other hand, provides state-of-the-art compute, on a need basis, which is how we see ourselves \nprogressing.\"The adoption of private LLMs can be expected to pick up in the near future. Ashish Kakar, research \ndirector for IDC Financial Insights, IDC Asia/Pacific, said, \"From our engagement, the trend is still on Proof of \nConcept or Proof of Technology in India and internationally. The use cases are largely around knowledge \nmanagement, IT operations, and initial cases on transaction processing. At the moment, banks are still deploying \nlargely models as a service and not their own models. We expect private LLM to pick up next year once the initial \npilots are successful.\"Tech partners IT companies like Tech Mahindra are helping industry players develop private \nLLMs. \"The financial industry's vast and diverse data highlights the value of LLMs for businesses. By fine-tuning \nBig banks take to large language models trained on internal data\navailable LLMs, we are assisting our customers with on-premise solutions to address data privacy concerns,\" said \nNikhil Malhotra, global head - Makers Lab, Tech Mahindra.\"Large banks in the US and Europe would definitely be \nusing private LLMs,\" said independent risk professional Bharat Panchal. \"With private LLMs, banks could be in a \nposition to do accurate predictive analytics, fraud detection and prevention and therefore better fraud and risk \nmanagement...With more data availability and newer technologies, this can be great opportunity for tech companies \nas well as banks, to work with account and data aggregators, credit bureaus and overall financial institutions to \nscale their businesses further.\" For Reprint Rights: timescontent.com\nLoad-Date: October 18, 2023"
    },
    {
        "file_name": "Dayton_Daily_News_(Ohio)_Jul2023",
        "header": "FTC investigating ChatGPT creator OpenAI over consumer protection issues",
        "media": "Dayton Daily News (Ohio)",
        "time": "July 14, 2023",
        "section": "NATION WORLD",
        "length": "657 words",
        "byline": "DAVID HAMILTON",
        "story_text": "FTC investigating ChatGPT creator OpenAI over consumer protection issues\nDayton Daily News (Ohio)\nJuly 14, 2023 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 657 words\nByline: DAVID HAMILTON\nBody\nThe U.S. Federal Trade Commission has launched an investigation into ChatGPT creator OpenAI and whether the \nartificial intelligence company violated consumer protection laws by scraping public data and publishing false \ninformation through its chatbot.\nThe agency sent OpenAI a 20-page letter requesting detailed information on its AI technology, products, customers, \nprivacy safeguards and data security arrangements. \nAn FTC spokesperson had no comment on the investigation, which was first reported by The Washington Post on \nThursday. \nThe FTC document the Post published told OpenAI that the agency was investigating whether it has \"engaged in \nunfair or deceptive privacy or data security practices\" or practices harming consumers. \nOpenAI founder Sam Altman tweeted disappointment that the investigation was disclosed in a \"leak,\" noting that \nwould \"not help build trust,\" but added that the company will work with the FTC. \n\"It's super important to us that out technology is safe and pro-consumer, and we are confident we follow the law,\" \nhe wrote. \"We protect user privacy and design our systems to learn about the world, not private individuals.\" \nOpenAI has faced scrutiny elsewhere. Italian regulators temporarily blocked ChatGPT over privacy concerns, and \nprivacy watchdogs in France, Spain, Ireland and Canada also are paying closer attention, including some that have \nlaunched investigations after receiving complaints. \nThe FTC's move is a serious regulatory threat to the nascent but fast-growing AI industry, although it's not the only \nchallenge facing these companies. \nComedian Sarah Silverman and two other authors have sued both OpenAI and Facebook parent Meta for copyright \ninfringement, claiming that the companies' AI systems were illegally \"trained\" by exposing them to datasets \ncontaining illegal copies of their works. \nOn Thursday, OpenAI and The Associated Press announced a deal under which the AI company will license AP's \narchive of news stories. \nAltman has emerged as a global AI ambassador of sorts following his testimony before Congress in May and a \nsubsequent worldwide tour, including to Europe, where officials are putting the final touches on the world's first \ncomprehensive rules for AI. \nFTC investigating ChatGPT creator OpenAI over consumer protection issues\nThe regulations will focus on risky uses such as predictive policing and social scoring and include provisions for \ngenerative AI to disclose any copyright material used to train its algorithms. \nAltman himself has called for AI regulation, although he has tended to emphasize difficult-to-evaluate existential \nthreats such as the possibility that superintelligent AI systems could one day turn against humanity. \nSome argue that focusing on a far-off \"science fiction trope\" of superpowerful AI could make it harder to take action \nagainst already existing harms that require regulators to dig deep on data transparency, discriminatory behavior \nand potential for trickery and disinformation. \n\"It's the fear of these systems and our lack of understanding of them that is making everyone have a collective \nfreak-out,\" Suresh Venkatasubramanian, a Brown University computer scientist and former assistant director for \nscience and justice at the White House Office of Science and Technology Policy, told the AP in May. \"This fear, \nwhich is very unfounded, is a distraction from all the concerns we're dealing with right now.\" \nNews of the FTC's OpenAI investigation broke just hours after a combative House Judiciary Committee hearing in \nwhich FTC Chair Lina Khan faced off against Republican lawmakers, who said she has been too aggressive in \npursuing technology companies over allegations of wrongdoing. \nRepublicans said she has been harassing Twitter since its acquisition by Elon Musk, arbitrarily suing large tech \ncompanies and declining to recuse herself from certain cases. Khan pushed back, arguing that more regulation is \nnecessary as the companies have grown and that tech conglomeration could hurt the economy and consumers.\nGraphic\n \nFILE - The OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT, \nMarch 21, 2023, in Boston. The U.S. Federal Trade Commission has launched an investigation into ChatGPT \ncreator OpenAI and whether the artificial intelligence company violated consumer protection laws by scraping public \ndata and publishing false information through its chatbot, according to reports in the Washington Post and the New \nYork Times. (AP Photo/Michael Dwyer, File)\nLoad-Date: July 14, 2023"
    },
    {
        "file_name": "The_Economic_Times_Nov2023",
        "header": "Air India taps Airbus, L3Harris for training unit",
        "media": "The Economic Times",
        "time": "November 26, 2023",
        "section": "AIRLINES-AVIATION",
        "length": "645 words",
        "byline": "Anirban Chowdhury",
        "story_text": "Air India taps Airbus, L3Harris for training unit\nThe Economic Times\nNovember 27, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: AIRLINES-AVIATION\nLength: 645 words\nByline: Anirban Chowdhury\nBody\nAir India is in talks with aerospace majors, including L3Harris and Airbus, as potential partners for its big crew \ntraining facility and will be disclosing more details in January, CEO and MD Campbell Wilson said in a recent \ninterview. People in the know said the companies will likely be making strategic investments in the $200-million \nfacility.\"We are partnering with a couple of OEMs (original equipment manufacturers) to set up simulator training \ncentres: Airbus, Boeing L3Harris. We will be talking a little more about that in January,\" said Wilson.He didn't \nelaborate on the nature of the partnership of investment from partners.L3Harris, formed in 2019 by the merger of \nAmerican companies L3 Technologies and Harris Corp, has business interests in segments including aerospace \ncommunications, integrated mission systems, space and airborne systems.The training centre would be critical for \ntraining pilots to fly the large number of planes the airline will receive over the next five years, starting December. In \nJune, Air India placed a historic order for 470 aircraft from Boeing and Airbus. \nThe airline will need over 5,000 pilots to fly these planes. India needs 1,700 pilots every year, half of which have to \nbe captains. It, however, produces just 200. \"We hopefully will be inducting the first group of cabin crew in January. \nIt's a responsibility that we take very seriously, investing a lot of money in it. It's crucial for us as an airline to grow \nand to grow our capabilities and become world class. One thing that we know for sure is that this industry requires a \nlot of good trained people and India has a lot of good people that just need to be trained,\" he said.New aircraft are \ncritical for Air India to upgrade its ageing fleet and product if it wants to regain its long lost status of a globally \nrelevant airline. The airline, which had climbed the ranks in on-time performance in April, has slipped in recent \nmonths to be among the bottom three airlines, according to the data from the Directorate General of Civil Aviation \n(DGCA) regarding on-time performances in four major metro airports which handle more than 60% of India's air \ntraffic. By March, Air India will get the delivery of 4 Boeing 777 planes and six Airbus A350 wide-bodied planes, \nwhich means that a quarter of its wide-bodied fleet then will be sporting latest generation products.\"Then in July, \nAugust of next year, we put our all legacy aircraft through a retrofit programme, which will take about 18 months, so \nthat by the end of 2025, all of our aircraft have been upgraded to the latest standards of seats and entertainment \nand other amenities,\" he said.The Tata group took over Air India on January 27, 2022 from the government which \nhad put it on the block for privatisation. In the last 1 year, the airline has been charting out ways to leverage the \nstrengths of the Tata group companies, including Tata Technologies that recently launched its IPO. Tata \nTechnologies is \"doing some work for us in digitising certain seat components so we can get spares manufactured \namongst other things,\" said Wilson, adding Tata Alexi is helping the airline with a lot of \"design work\". Air India \nrecently launched a generative AI powered chatbot and will introduce more generative AI-powered solutions, said \nWilson.\"We are one of the few companies in the world that are using Microsoft's (AI tool) copilot embedded into our \nenterprise suite. We use it every day in all of our tools. And many teams across the business are hard at work, \nthinking about how we can bring it into our daily business life, using it behind the scenes to improve such things as \nrevenue management. I do think it's going to be quite transformative. It certainly has the opportunity to improve \nefficiency and effectiveness and as a consequence, cost and service delivery...\" For Reprint Rights: \ntimescontent.com\nAir India taps Airbus , L3Harris for training unit\nLoad-Date: November 26, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "U.S. Focuses on Invigorating ‘Chiplets’ to Stay Cutting-Edge in Tech",
        "media": "The New York Times",
        "time": "May 14, 2023",
        "section": "TECHNOLOGY",
        "length": "1555 words",
        "byline": "Don Clark",
        "story_text": "U.S. Focuses on Invigorating ‘Chiplets’ to Stay Cutting-Edge in Tech\nThe New York Times \nMay 11, 2023 Thursday 23:28 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1555 words\nByline: Don Clark\nHighlight: Chiplets, a way to design chips for higher performance, has become a key prong of U.S. industrial \npolicy. But pushing for more of this activity domestically is challenging.\nBody\nFor more than 50 years, designers of computer chips mainly used one tactic to boost performance: They shrank \nelectronic components to pack more power onto each piece of silicon.\nThen more than a decade ago, engineers at the chip maker Advanced Micro Devices began toying with a radical \nidea. Instead of designing one big microprocessor with vast numbers of tiny transistors, they conceived of creating \none from smaller chips that would be packaged tightly together to work like one electronic brain.\nThe concept, sometimes called chiplets, caught on in a big way, with AMD, Apple, Amazon, Tesla, IBM and Intel \nintroducing such products. Chiplets rapidly gained traction because smaller chips are cheaper to make, while \nbundles of them can top the performance of any single slice of silicon.\nThe strategy, based on advanced packaging technology, has since become an essential tool to enabling progress \nin semiconductors. And it represents one of the biggest shifts in years for an industry that drives innovations in \nfields like artificial intelligence, self-driving cars and military hardware.\n“Packaging is where the action is going to be,” said Subramanian Iyer, a professor of electrical and computer \nengineering at the University of California, Los Angeles, who helped pioneer the chiplet concept. “It’s happening \nbecause there is actually no other way.”\nThe catch is that such packaging, like making chips themselves, is overwhelmingly dominated by companies in \nAsia. Although the United States accounts for around 12 percent of global semiconductor production, American \ncompanies provide just 3 percent of chip packaging, according to IPC, a trade association.\nThat issue has now landed chiplets in the middle of U.S. industrial policymaking. The CHIPS Act, a $52 billion \nsubsidy package that passed last summer, was seen as President Biden’s move to reinvigorate domestic chip \nmaking by providing money to build more sophisticated factories called “fabs.” But part of it was also aimed at \nstoking advanced packaging factories in the United States to capture more of that essential process.\n“As chips get smaller, the way you arrange the chips, which is packaging, is more and more important and we need \nit done in America,” Commerce Secretary Gina Raimondo, said in a speech at Georgetown University in February.\nThe Commerce Department is now accepting applications for manufacturing grants from the CHIPS Act, including \nfor chip packaging factories. It is also allocating funding to a research program specifically on advanced packaging.\nSome chip packaging companies are moving quickly for the funding. One is Integra Technologies in Wichita, Kan., \nwhich announced plans for a $1.8 billion expansion there but said that was contingent on receiving federal \nU.S. Focuses on Invigorating ‘Chiplets’ to Stay Cutting-Edge in Tech\nsubsidies. Amkor Technology, an Arizona packaging service that has most of its operations in Asia, also said it was \ntalking to customers and government officials about a U.S. production presence.\nPackaging chips together isn’t a new concept and chiplets are just the latest iteration of that idea, using \ntechnological advances that help cram the chips closer together — either side by side or stacked on top of one \nanother — along with faster electrical connections between them.\n“What is unique about chiplets is the way they are connected electrically,” said Richard Otte, the chief executive of \nPromex Industries, a chip packaging service in Santa Clara, Calif.\nChips can’t do anything without a way to connect them with other components, which means they need to be \nplaced in some kind of package that can carry electrical signals. That process starts after factories complete the \ninitial phase of manufacturing, which may create hundreds of chips on a silicon wafer. Once that wafer is sliced \napart, individual chips are typically bonded to a key base layer called a substrate, which can conduct electrical \nsignals.\nThat combination is then coated in protective plastic, forming a package that can be plugged into a circuit board that \nis essential for connecting to other components in a system.\nThese processes originally required lots of manual labor, leading Silicon Valley companies to shift packaging to \nlower-wage countries in Asia more than 50 years ago. Most chips are typically flown to packaging services in \ncountries like Taiwan, Malaysia, South Korea and China.\nSince then, packaging advances have gained importance because of the diminishing returns from Moore’s Law, the \nshorthand expression for chip miniaturization that for decades drove progress in Silicon Valley. It is named for \nGordon Moore, a co-founder of Intel, whose 1965 paper described how rapidly companies had doubled the number \nof transistors on a typical chip, which improved performance at a lower cost.\nBut these days, smaller transistors are not necessarily cheaper, partly because building factories for leading-edge \nchips can cost $10 billion to $20 billion. Big, complex chips also are costly to design and tend to have more \nmanufacturing defects, even as companies in fields like generative A.I. want more transistors than can currently be \npacked onto the biggest chips manufacturing machines allow.\n“The natural response to that is putting more things in a package,” said Anirudh Devgan, chief executive of \nCadence Design Systems, whose software is used to design conventional chips as well as chiplet-style products.\nSynopsys, a rival, said it was tracking more than 140 customer projects based on packaging multiple chips \ntogether. As much as 80 percent of microprocessors will use chiplet-style designs by 2027, according to the market \nresearch firm Yole Group.\nToday, companies typically design all the chiplets in a package along with their own connection technology. But \nindustry groups are working on technical standards so companies can more easily assemble products from chiplets \nthat come from different makers.\nThe new technology is mostly used now for extreme performance. Intel recently introduced a processor called \nPonte Vecchio with 47 chiplets that will be used in a powerful supercomputer at Argonne National Laboratory, which \nis near Chicago.\nIn January, AMD disclosed plans for an unusual product, the MI300, that combines chiplets for standard \ncalculations with others designed for computer graphics, along with a large pool of memory chips. That processor, \nintended to power another advanced supercomputer at Lawrence Livermore National Laboratory, has 146 billion \ntransistors, compared with tens of billions for most advanced conventional chips.\nSam Naffziger, an AMD senior vice president, said it wasn’t a slam-dunk for the company to bet its chip business \nfor server computers on chiplets. Packaging complexities were a major hurdle, he said, which were eventually \novercome with help from an undisclosed partner.\nU.S. Focuses on Invigorating ‘Chiplets’ to Stay Cutting-Edge in Tech\nBut chiplets have paid off for AMD. The company has sold more than 12 million chips based on the idea since \n2017, according to Mercury Research, and has become a major player in microprocessors that power the web.\nPackaging services still need others to supply the substrates that chiplets require to connect to circuit boards and \none another. One company driving the chiplet boom is Taiwan Semiconductor Manufacturing Company, which \nalready makes chips for AMD and hundreds of others and offers an advanced silicon-based substrate called an \ninterposer.\nIntel has been developing similar technology, as well as enhancing less-expensive conventional plastic substrates \nin an approach favored by some such as the Silicon Valley start-up Eliyan. Intel has also been developing new \npackaging prototypes under a Pentagon program and hopes to win CHIPs Act support for a new pilot packaging \nplant.\nBut the United States has no major makers of those substrates, which are primarily produced in Asia and evolved \nfrom technologies used in manufacturing circuit boards. Many U.S. companies have also left that business, another \nworry that industry groups hope will spur federal funding to help board suppliers start making substrates.\nIn March, Mr. Biden issued a determination that advanced packaging and domestic circuit board production were \nessential for national security, and announced $50 million in Defense Production Act funding for American and \nCanadian companies in those fields.\nEven with such subsidies, assembling all the elements required to reduce U.S. dependence on Asian companies “is \na huge challenge,” said Andreas Olofsson, who ran a Defense Department research effort in the field before \nfounding a packaging start-up called Zero ASIC. “You don’t have suppliers. You don’t have a work force. You don’t \nhave equipment. You have to sort of start from scratch.”\nAna Swanson contributed reporting.\nAna Swanson contributed reporting. \nPHOTOS: A MI300 processor, by Advanced Micro Devices, is a example of chiplet technology, creating a \nmicroprocessor from smaller chips packaged tightly together to work as a unit. Packaging is dominated by Asian-\nbased companies. (PHOTOGRAPH BY ZERB MELLISH FOR THE NEW YORK TIMES) (B1); At Promex Industries \nin Santa Clara, Calif., computer chips and packaging materials are joined together. One of the goals of the CHIPS \nAct, a $52 billion subsidy package, is to increase the presence of such factories in the U.S. (PHOTOGRAPHS BY \nJIM WILSON/THE NEW YORK TIMES) (B4-B5) This article appeared in print on page B1, B4, B5.\nLoad-Date: May 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Next Big Leap for A.I. Tech? Instant Videos on Command.",
        "media": "The New York Times",
        "time": "April 5, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1336 words",
        "byline": "By Cade Metz",
        "story_text": "Next Big Leap for A.I. Tech? Instant Videos on Command.\nThe New York Times\nApril 5, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1336 words\nByline: By Cade Metz\nBody\nA start-up in New York is among a group of companies working on systems that can produce short videos based on \na few words typed into a computer.\nIan Sansavera, a software architect at a New York start-up called Runway AI, typed a short description of what he \nwanted to see in a video. ''A tranquil river in the forest,'' he wrote. \n  Less than two minutes later, an experimental internet service generated a short video of a tranquil river in a forest. \nThe river's running water glistened in the sun as it cut between trees and ferns, turned a corner and splashed gently \nover rocks.\n  Runway, which plans to open its service to a small group of testers this week, is one of several companies building \nartificial intelligence technology that will soon let people generate videos simply by typing several words into a box \non a computer screen.\n  They represent the next stage in an industry race -- one that includes giants like Microsoft and Google as well as \nmuch smaller start-ups -- to create new kinds of artificial intelligence systems that some believe could be the next \nbig thing in technology, as important as web browsers or the iPhone.\n  The new video-generation systems could speed the work of moviemakers and other digital artists, while becoming \na new and quick way to create hard-to-detect online misinformation, making it even harder to tell what's real on the \ninternet.\n  The systems are examples of what is known as generative A.I., which can instantly create text, images and \nsounds. Another example is ChatGPT, the online chatbot made by a San Francisco start-up, OpenAI, that stunned \nthe tech industry with its abilities late last year.\n  Google and Meta, Facebook's parent company, unveiled the first video-generation systems last year, but did not \nshare them with the public because they were worried that the systems could eventually be used to spread \ndisinformation with newfound speed and efficiency.\n  But Runway's chief executive, Cristóbal Valenzuela, said he believed the technology was too important to keep in \na research lab, despite its risks. ''This is one of the single most impressive technologies we have built in the last \nhundred years,'' he said. ''You need to have people actually using it.''\n  The ability to edit and manipulate film and video is nothing new, of course. Filmmakers have been doing it for more \nthan a century. In recent years, researchers and digital artists have been using various A.I. technologies and \nsoftware programs to create and edit videos that are often called deepfake videos.\nNext Big Leap for A.I. Tech ? Instant Videos on Command.\n  But systems like the one Runway has created could, in time, replace editing skills with the press of a button.\n  Runway's technology generates videos from any short description. To start, you simply type a description much as \nyou would type a quick note.\n  That works best if the scene has some action -- but not too much action -- something like ''a rainy day in the big \ncity'' or ''a dog with a cellphone in the park.'' Hit enter, and the system generates a video in a minute or two.\n  The technology can reproduce common images, like a cat sleeping on a rug. Or it can combine disparate concepts \nto generate videos that are strangely amusing, like a cow at a birthday party.\n  The videos are only four seconds long, and the video is choppy and blurry if you look closely. Sometimes, the \nimages are weird, distorted and disturbing. The system has a way of merging animals like dogs and cats with \ninanimate objects like balls and cellphones. But given the right prompt, it produces videos that show where the \ntechnology is headed.\n  ''At this point, if I see a high-resolution video, I am probably going to trust it,'' said Phillip Isola, a professor at the \nMassachusetts Institute of Technology who specializes in A.I. ''But that will change pretty quickly.''\n  Like other generative A.I. technologies, Runway's system learns by analyzing digital data -- in this case, photos, \nvideos and captions describing what those images contain. By training this kind of technology on increasingly large \namounts of data, researchers are confident they can rapidly improve and expand its skills. Soon, experts believe, \nthey will generate professional-looking mini-movies, complete with music and dialogue.\n  It is difficult to define what the system creates currently. It's not a photo. It's not a cartoon. It's a collection of a lot \nof pixels blended together to create a realistic video. The company plans to offer its technology with other tools that \nit believes will speed up the work of professional artists.\n  Several start-ups, including OpenAI, have released similar technology that can generate still images from short \nprompts like ''photo of a teddy bear riding a skateboard in Times Square.'' And the rapid advancement of A.I.-\ngenerated photos could suggest where the new video technology is going.\n  Last month, social media services were teeming with images of Pope Francis in a white Balenciaga puffer coat -- \nsurprisingly trendy attire for an 86-year-old pontiff. But the images were not real. A 31-year-old construction worker \nfrom Chicago had created the viral sensation using a popular A.I. tool called Midjourney.\n  Dr. Isola has spent years building and testing this kind of technology, first as a researcher at the University of \nCalifornia, Berkeley, and at OpenAI, and then as a professor at M.I.T. Still, he was fooled by the sharp, high-\nresolution but completely fake images of Pope Francis.\n  ''There was a time when people would post deepfakes and they wouldn't fool me, because they were so \noutlandish or not very realistic,'' he said. ''Now, we can't take any of the images we see on the internet at face \nvalue.''\n  Midjourney is one of many services that can generate realistic still images from a short prompt. Others include \nStable Diffusion and DALL-E, an OpenAI technology that started this wave of photo generators when it was \nunveiled a year ago.\n  Midjourney relies on a neural network, which learns its skills by analyzing enormous amounts of data. It looks for \npatterns as it combs through millions of digital images as well as text captions that describe the images depict.\n  When someone describes an image for the system, it generates a list of features that the image might include. \nOne feature might be the curve at the top of a dog's ear. Another might be the edge of a cellphone. Then, a second \nneural network, called a diffusion model, creates the image and generates the pixels needed for the features. It \neventually transforms the pixels into a coherent image.\nNext Big Leap for A.I. Tech ? Instant Videos on Command.\n  Companies like Runway, which has roughly 40 employees and has raised $95.5 million, are using this technique \nto generate moving images. By analyzing thousands of videos, their technology can learn to string many still \nimages together in a similarly coherent way.\n  ''A video is just a series of frames -- still images -- that are combined in a way that gives the illusion of movement,'' \nMr. Valenzuela said. ''The trick lies in training a model that understands the relationship and consistency between \neach frame.''\n  Like early versions of tools such as DALL-E and Midjourney, the technology sometimes combines concepts and \nimages in curious ways. If you ask for a teddy bear playing basketball, it might give a kind of mutant stuffed animal \nwith a basketball for a hand. If you ask for a dog with a cellphone in the park, it might give you a cellphone-wielding \npup with an oddly human body.\n  But experts believe they can iron out the flaws as they train their systems on more and more data. They believe \nthe technology will ultimately make creating a video as easy as writing a sentence.\n  ''In the old days, to do anything remotely like this, you had to have a camera. You had to have props. You had to \nhave a location. You had to have permission. You had to have money,'' said Susan Bonser, an author and a \npublisher in Pennsylvania who has been experimenting with early incarnations of generative video technology. ''You \ndon't have to have any of that now. You can just sit down and imagine it.''\nhttps://www.nytimes.com/2023/04/04/technology/runway-ai-videos.html\nGraphic\n \nPHOTOS: Runway AI's software created a video prompted by the words ''a cow at a birthday party.'' (A1)\nGuided by brief descriptions typed into a computer, generative artificial intelligence software in minutes created a \nshort video of animals at a birthday party and ''a tranquil river in the forest.'' Such systems could, in time, replace \nediting skills with the press of a button. (PHOTOGRAPHS BY RUNWAY)\n Runway's founders, from left, Alejandro Matamala Ortiz, Cristóbal Valenzuela and Anastasis Germanidis believe \ntheir A.I. can aid filmmakers. (PHOTOGRAPH BY JUSTIN J WEE FOR THE NEW YORK TIMES) (A11) This article \nappeared in print on page A1, A11.               \nLoad-Date: April 5, 2023"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "AI too important to be not regulated, says Google",
        "media": "The Economic Times",
        "time": "May 19, 2023",
        "section": "TECH & INTERNET",
        "length": "843 words",
        "byline": " ",
        "story_text": "AI too important to be not regulated, says Google\nThe Economic Times\nMay 20, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 843 words\nBody\nGoogle on Friday published a whitepaper with suggestions for a policy agenda for responsible AI progress. In a \nblog post, the company said AI was too important not to regulate.\"Calls for a halt to technological advances are \nunlikely to be successful or effective, and risk missing out on AI's substantial benefits and falling behind those who \nembrace its potential,\" Kent Walker, president of global affairs, Google & Alphabet, said in the blog post.He said \nbroad-based efforts-across government, companies, universities, and more-were needed to help translate \ntechnological breakthroughs into widespread benefits, while mitigating risks.Walker said individual practices, shared \nindustry standards, and sound government policies would be essential to getting AI right.In the whitepaper, Google \nsaid it encourages governments to focus on three key areas-unlocking opportunity, promoting responsibility, and \nenhancing security.\"Economies that embrace AI will see significant growth, outcompeting rivals that are slower on \nthe uptake. AI will help many different industries produce more complex and valuable products and services, and \nhelp increase productivity despite growing demographic challenges,\" Walker said.He added that AI also promises to \ngive a boost to both small businesses using AI-powered products and services to innovate and grow-and to workers \nwho can focus on non-routine and more rewarding elements of their jobs.But in order to make this happen, Walker \nurged policymakers to invest in innovation and competitiveness, promote legal frameworks that support responsible \nAI innovation, and prepare workforces for AI-driven job transition.\"For example, governments should explore \nfoundational AI research through national labs and research institutions, adopt policies that support responsible AI \ndevelopment (including privacy laws that protect personal information and enable trusted data flows across national \nborders), and promote continuing education, upskilling programmes, movement of key talent across borders, and \nresearch on the evolving future of work,\" he said.In the same breath, he said that if AI is not developed and \ndeployed responsibly, AI systems could also amplify current societal issues, such as misinformation, discrimination, \nand misuse of tools.In order to ensure the promotion of responsible AI, he said that while some challenges will need \nfundamental research to better understand AI's benefits and risks and how to manage them, others would need \nrisk-based regulation while finally some would require new organisations and institutions.\"For example, leading \ncompanies could come together to form a Global Forum on AI (GFAI), building on previous examples like the \nGlobal Internet Forum to Counter Terrorism (GIFCT). International alignment will also be essential to develop \ncommon policy approaches that reflect democratic values and avoid fragmentation,\" he said.Further, Walker said \nthat AI has important implications for global security and stability. \nGenerative AI can help create (but also identify and track) mis- and dis-information and manipulated media. AI-\nbased security research is driving a new generation of cyber defences through advanced security operations and \nthreat intelligence, while AI-generated exploits may also enable more sophisticated cyberattacks by adversaries.He \nsaid it was important to put technical and commercial guardrails in place to prevent malicious use of AI and to work \ncollectively to address bad actors,\"Governments should explore next-generation trade control policies for specific \napplications of AI-powered software that are deemed security risks, and on specific entities that provide support to \nAI-related research and development in ways that could threaten global security,\" he suggested.Walker concluded \nthat a policy agenda centred on the pillars of opportunity, responsibility, and security can unlock the benefits of AI \nand ensure that those benefits are shared by all.\"As we have said before, AI is too important not to regulate, and \ntoo important not to regulate well. From Singapore's AI Verify framework to the UK's pro-innovation approach to AI \nAI too important to be not regulated, says Google\nregulation to America's National Institute of Standards & Technology's AI Risk Management Framework, we are \nencouraged to see governments around the world seriously addressing the right policy frameworks for these new \ntechnologies, and we look forward to supporting their efforts,\" he said.Just a little over a week ago, at Google's \nannual developer conference, CEO Sundar Pichai said the growth of AI is as big a technology shift as we have \nseen. And while he spoke extensively about being bold with their efforts in generative AI, he was equally particular \nto emphasise the need for being responsible.He reiterated that we were at an inflection point and that we can \nsignificantly improve the lives of billions of people, help businesses thrive and grow, and support society in \nanswering our toughest questions but must be clear-eyed that AI will come with risks and challenges. For Reprint \nRights: timescontent.com\nLoad-Date: May 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "New in Coding Class: Critiquing ChatGPT",
        "media": "The New York Times",
        "time": "February 6, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1606 words",
        "byline": "By Natasha Singer",
        "story_text": "New in Coding Class: Critiquing ChatGPT\nThe New York Times\nFebruary 6, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1606 words\nByline: By Natasha Singer\nBody\nMarisa Shuman's computer science class at the Young Women's Leadership School of the Bronx began as usual \non a recent January morning.\nJust after 11:30, energetic 11th and 12th graders bounded into the classroom, settled down at communal study \ntables and pulled out their laptops. Then they turned to the front of the room, eyeing a whiteboard where Ms. \nShuman had posted a question on wearable technology, the topic of that day's class. \n  For the first time in her decade-long teaching career, Ms. Shuman had not written any of the lesson plan. She had \ngenerated the class material using ChatGPT, a new chatbot that relies on artificial intelligence to deliver written \nresponses to questions in clear prose. Ms. Shuman was using the algorithm-generated lesson to examine the \nchatbot's potential usefulness and pitfalls with her students.\n  ''I don't care if you learn anything about wearable technology today,'' Ms. Shuman said to her students. ''We are \nevaluating ChatGPT. Your goal is to identify whether the lesson is effective or ineffective.''\n  Across the United States, universities and school districts are scrambling to get a handle on new chatbots that can \ngenerate humanlike texts and images. But while many are rushing to ban ChatGPT to try to prevent its use as a \ncheating aid, teachers like Ms. Shuman are leveraging the innovations to spur more critical classroom thinking. \nThey are encouraging their students to question the hype around rapidly evolving artificial intelligence tools and \nconsider the technologies' potential side effects.\n  The aim, these educators say, is to train the next generation of technology creators and consumers in ''critical \ncomputing.'' That is an analytical approach in which understanding how to critique computer algorithms is as \nimportant as -- or more important than -- knowing how to program computers.\n  New York City Public Schools, the nation's largest district, serving some 900,000 students, is training a cohort of \ncomputer science teachers to help their students identify A.I. biases and potential risks. Lessons include \ndiscussions on defective facial recognition algorithms that can be much more accurate in identifying white faces \nthan darker-skinned faces.\n  In Illinois, Florida, New York and Virginia, some middle school science and humanities teachers are using an A.I. \nliteracy curriculum developed by researchers at the Scheller Teacher Education Program at the Massachusetts \nInstitute of Technology. One lesson asks students to consider the ethics of powerful A.I. systems, known as \n''generative adversarial networks,'' that can be used to produce fake media content, like realistic videos in which \nwell-known politicians mouth phrases they never actually said.\nNew in Coding Class: Critiquing ChatGPT\n  With generative A.I. technologies proliferating, educators and researchers say understanding such computer \nalgorithms is a crucial skill that students will need to navigate daily life and participate in civics and society.\n  ''It's important for students to know about how A.I. works because their data is being scraped, their user activity is \nbeing used to train these tools,'' said Kate Moore, an education researcher at M.I.T. who helped create the A.I. \nlessons for schools. ''Decisions are being made about young people using A.I., whether they know it or not.''\n  To observe how some educators are encouraging their students to scrutinize A.I. technologies, I recently spent \ntwo days visiting classes at the Young Women's Leadership School of the Bronx, a public middle and high school \nfor girls that is at the forefront of this trend.\n  The hulking, beige-brick school specializes in math, science and technology. It serves nearly 550 students, most \nof them Latinx or Black.\n  It is by no means a typical public school. Teachers are encouraged to help their students become, as the school's \nwebsite puts it, ''innovative'' young women with the skills to complete college and ''influence public attitudes, policies \nand laws to create a more socially just society.'' The school also has an enviable four-year high school graduation \nrate of 98 percent, significantly higher than the average for New York City high schools.\n  One morning in January, about 30 ninth and 10th graders, many of them dressed in navy blue school sweatshirts \nand gray pants, loped into a class called Software Engineering 1. The hands-on course introduces students to \ncoding, computer problem-solving and the social repercussions of tech innovations.\n  It is one of several computer science courses at the school that ask students to consider how popular computer \nalgorithms -- often developed by tech company teams of mostly white and Asian men -- may have disparate \nimpacts on groups like immigrants and low-income communities. That morning's topic: face-matching systems that \nmay have difficulty recognizing darker-skinned faces, such as those of some of the students in the room and their \nfamilies.\n  Standing in front of her class, Abby Hahn, the computing teacher, knew her students might be shocked by the \nsubject. Faulty face-matching technology has helped lead to the false arrests of Black men.\n  So Ms. Hahn alerted her pupils that the class would be discussing sensitive topics like racism and sexism. Then \nshe played a YouTube video, created in 2018 by Joy Buolamwini, a computer scientist, showing how some popular \nfacial analysis systems mistakenly identified iconic Black women as men.\n  As the class watched the video, some students gasped. Oprah Winfrey ''appears to be male,'' Amazon's \ntechnology said with 76.5 percent confidence, according to the video. Other sections of the video said that \nMicrosoft's system had mistaken Michelle Obama for ''a young man wearing a black shirt,'' and that IBM's system \nhad pegged Serena Williams as ''male'' with 89 percent confidence.\n  (Microsoft and Amazon later announced accuracy improvements to their systems, and IBM stopped selling such \ntools. Amazon said it was committed to continuously improving its facial analysis technology through customer \nfeedback and collaboration with researchers, and Microsoft and IBM said they were committed to the responsible \ndevelopment of A.I.)\n  ''I'm shocked at how colored women are seen as men, even though they look nothing like men,'' Nadia Zadine, a \n14-year-old student, said. ''Does Joe Biden know about this?''\n  The point of the A.I. bias lesson, Ms. Hahn said, was to show student programmers that computer algorithms can \nbe faulty, just like cars and other products designed by humans, and to encourage them to challenge problematic \ntechnologies.\n  ''You are the next generation,'' Ms. Hahn said to the young women as the class period ended. ''When you are out \nin the world, are you going to let this happen?''\nNew in Coding Class: Critiquing ChatGPT\n  ''No!'' a chorus of students responded.\n  A few doors down the hall, in a colorful classroom strung with handmade paper snowflakes and origami cranes, \nMs. Shuman was preparing to teach a more advanced programming course, Software Engineering 3, focused on \ncreative computing like game design and art. Earlier that week, her student coders had discussed how new A.I.-\npowered systems like ChatGPT can analyze vast stores of information and then produce humanlike essays and \nimages in response to short prompts.\n  As part of the lesson, the 11th and 12th graders read news articles about how ChatGPT could be both useful and \nerror-prone. They also read social media posts about how the chatbot could be prompted to generate texts \npromoting hate and violence.\n  But the students could not try ChatGPT in class themselves. The school district has blocked it over concerns that it \ncould be used for cheating. So the students asked Ms. Shuman to use the chatbot to create a lesson for the class \nas an experiment.\n  Ms. Shuman spent hours at home prompting the system to generate a lesson on wearable technology like \nsmartwatches. In response to her specific requests, ChatGPT produced a remarkably detailed 30-minute lesson \nplan -- complete with a warm-up discussion, readings on wearable technology, in-class exercises and a wrap-up \ndiscussion.\n  As the class period began, Ms. Shuman asked the students to spend 20 minutes following the scripted lesson, as \nif it were a real class on wearable technology. Then they would analyze ChatGPT's effectiveness as a simulated \nteacher.\n  Huddled in small groups, students read aloud information the bot had generated on the conveniences, health \nbenefits, brand names and market value of smartwatches and fitness trackers. There were groans as students read \nout ChatGPT's anodyne sentences -- ''Examples of smart glasses include Google Glass Enterprise 2'' -- that they \nsaid sounded like marketing copy or rave product reviews.\n  ''It reminded me of fourth grade,'' Jayda Arias, 18, said. ''It was very bland.''\n  The class found the lesson stultifying compared with those by Ms. Shuman, a charismatic teacher who creates \ncourse materials for her specific students, asks them provocative questions and comes up with relevant, real-world \nexamples on the fly.\n  ''The only effective part of this lesson is that it's straightforward,'' Alexania Echevarria, 17, said of the ChatGPT \nmaterial.\n  ''ChatGPT seems to love wearable technology,'' noted Alia Goddess Burke, 17, another student. ''It's biased!''\n  Ms. Shuman was offering a lesson that went beyond learning to identify A.I. bias. She was using ChatGPT to give \nher pupils a message that artificial intelligence was not inevitable and that the young women had the insights to \nchallenge it.\n  ''Should your teachers be using ChatGPT?'' Ms. Shuman asked toward the end of the lesson.\n  The students' answer was a resounding ''No!'' At least for now.\nhttps://www.nytimes.com/2023/02/05/technology/chatgpt-schools-teachers-ai-ethics.html\nGraphic\n \nNew in Coding Class: Critiquing ChatGPT\nPHOTOS: Marisa Shuman, a teacher at the Young Women's Leadership School of the Bronx, challenged her \nstudents to evaluate the work created by a chatbot. (B1)\n Abby Hahn, a teacher at the Young Women's Leadership School of the Bronx, taught an A.I. bias lesson that was \nmeant to show that computer algorithms can be faulty. In another class, led by Marisa Shuman, the students, top \nleft, were asked if ChatGPT had offered an effective lesson plan, bottom left. The answer was a resounding ''No!'' \n(PHOTOGRAPHS BY HIROKO MASUIKE/THE NEW YORK TIMES) (B2) This article appeared in print on page B1, \nB2.               \nLoad-Date: February 6, 2023"
    },
    {
        "file_name": "It_Jul2023",
        "header": "As Businesses Clamor for Workplace A.I., Tech Companies Rush to Provide",
        "media": "It",
        "time": "July 9, 2023",
        "section": "TECHNOLOGY",
        "length": "1025 words",
        "byline": "Yiwen Lu",
        "story_text": "As Businesses Clamor for Workplace A.I., Tech Companies Rush to Provide \nIt\nThe New York Times \nJuly 5, 2023 Wednesday 23:34 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1025 words\nByline: Yiwen Lu\nHighlight: Amazon, Box, Salesforce, Oracle and others have recently rolled out A.I.-related products to help \nworkplaces become more efficient and productive.\nBody\nAmazon, Box, Salesforce, Oracle and others have recently rolled out A.I.-related products to help workplaces \nbecome more efficient and productive.\nEarlier this year, Mark Austin, the vice president of data science at AT&amp;T, noticed that some of the company’s \ndevelopers had started using the ChatGPT chatbot at work. When the developers got stuck, they asked ChatGPT \nto explain, fix or hone their code.\nIt seemed to be a game-changer, Mr. Austin said. But since ChatGPT is a publicly available tool, he wondered if it \nwas secure for businesses to use.\nSo in January, AT&amp;T tried a product from Microsoft called Azure OpenAI Services that lets businesses build \ntheir own A.I.-powered chatbots. AT&amp;T used it to create a proprietary A.I. assistant, Ask AT&amp;T, which \nhelps its developers automate their coding process. AT&amp;T’s customer service representatives also began \nusing the chatbot to help summarize their calls, among other tasks.\n“Once they realize what it can do, they love it,” Mr. Austin said. Forms that once took hours to complete needed \nonly two minutes with Ask AT&amp;T so employees could focus on more complicated tasks, he said, and \ndevelopers who used the chatbot increased their productivity by 20 to 50 percent.\nAT&amp;T is one of many businesses eager to find ways to tap the power of generative artificial intelligence, the \ntechnology that powers chatbots and that has gripped Silicon Valley with excitement in recent months. Generative \nA.I. can produce its own text, photos and video in response to prompts, capabilities that can help automate tasks \nsuch as taking meeting minutes and cut down on paperwork.\nTo meet this new demand, tech companies are racing to introduce products for businesses that incorporate \ngenerative A.I. Over the past three months, Amazon, Box and Cisco have unveiled plans for generative A.I.-\npowered products that produce code, analyze documents and summarize meetings. Salesforce also recently rolled \nout generative A.I. products used in sales, marketing and its Slack messaging service, while Oracle announced a \nnew A.I. feature for human resources teams.\nThese companies are also investing more in A.I. development. In May, Oracle and Salesforce Ventures, the venture \ncapital arm of Salesforce, invested in Cohere, a Toronto start-up focused on generative A.I. for business use. \nOracle is also reselling Cohere’s technology.\nAs Businesses Clamor for Workplace A.I., Tech Companies Rush to Provide It\n“I think this is a complete breakthrough in enterprise software,” Aaron Levie, chief executive of Box, said of \ngenerative A.I. He called it “this incredibly exciting opportunity where, for the first time ever, you can actually start \nto understand what’s inside of your data in a way that wasn’t possible before.”\nMany of these tech companies are following Microsoft, which has invested $13 billion in OpenAI, the maker of \nChatGPT. In January, Microsoft made Azure OpenAI Service available to customers, who can then access \nOpenAI’s technology to build their own versions of ChatGPT. As of May, the service had 4,500 customers, said \nJohn Montgomery, a Microsoft corporate vice president.\nFor the most part, tech companies are now rolling out four kinds of generative A.I. products for businesses: \nfeatures and services that generate code for software engineers, create new content such as sales emails and \nproduct descriptions for marketing teams, search company data to answer employee questions, and summarize \nmeeting notes and lengthy documents.\n“It is going to be a tool that is used by people to accomplish what they are already doing,” said Bern Elliot, a vice \npresident and analyst at the I.T. research and consulting firm Gartner.\nBut using generative A.I. in workplaces has risks. Chatbots can produce inaccuracies and misinformation, provide \ninappropriate responses and leak data. A.I. remains largely unregulated.\nIn response to these issues, tech companies have taken some steps. To prevent data leakage and to enhance \nsecurity, some have engineered generative A.I. products so they do not keep a customer’s data.\nWhen Salesforce last month introduced AI Cloud, a service with nine generative A.I.-powered products for \nbusinesses, the company included a “trust layer” to help mask sensitive corporate information to stop leaks and \npromised that what users typed into these products would not be used to retrain the underlying A.I. model.\nSimilarly, Oracle said that customer data would be kept in a secure environment while training its A.I. model and \nadded that it would not be able to see the information.\nSalesforce offers AI Cloud starting at $360,000 annually, with the cost rising depending on the amount of usage. \nMicrosoft charges for Azure OpenAI Service based on the version of OpenAI technology that a customer chooses, \nas well as the amount of usage.\nFor now, generative A.I. is used mainly in workplace scenarios that carry low risks — instead of highly regulated \nindustries — with a human in the loop, said Beena Ammanath, the executive director of the Deloitte A.I. Institute, a \nresearch center of the consulting firm. A recent Gartner survey of 43 companies found that over half the \nrespondents have no internal policy on generative A.I.\n“It is not just about being able to use these new tools efficiently, but it is also about preparing your work force for the \nnew kinds of work that might evolve,” Ms. Ammanath said. “There is going to be new skills needed.”\nPanasonic Connect, part of the Japanese electronics company Panasonic, began using Microsoft’s Azure OpenAI \nService to make its own chatbot in February. Today, its employees ask the chatbot 5,000 questions a day about \neverything from drafting emails to writing code.\nWhile Panasonic Connect had expected its engineers to be the main users of the chatbot, other departments — \nsuch as legal, accounting and quality assurance — also turned to it to help summarize legal documents, brainstorm \nsolutions to improve product quality and other tasks, said Judah Reynolds, Panasonic Connect’s marketing and \ncommunications chief.\n“Everyone started using it in ways that we didn’t even foresee ourselves,” he said. “So people are really taking \nadvantage of it.”\nThis article appeared in print on page B1, B2.\nAs Businesses Clamor for Workplace A.I., Tech Companies Rush to Provide It\nLoad-Date: July 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "ChatGPT Can Now Generate Images, Too",
        "media": "The New York Times",
        "time": "September 21, 2023",
        "section": "TECHNOLOGY",
        "length": "753 words",
        "byline": "Cade Metz and Tiffany Hsu",
        "story_text": "ChatGPT Can Now Generate Images, Too\nThe New York Times \nSeptember 20, 2023 Wednesday 11:28 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 753 words\nByline: Cade Metz and Tiffany Hsu\nHighlight: OpenAI released a new version of its DALL-E image generator to a small group of testers and \nincorporated the technology into its popular ChatGPT chatbot.\nBody\nOpenAI released a new version of its DALL-E image generator to a small group of testers and incorporated the \ntechnology into its popular ChatGPT chatbot.\nChatGPT can now generate images — and they are shockingly detailed.\nOn Wednesday, OpenAI, the San Francisco artificial intelligence start-up, released a new version of its DALL-E \nimage generator to a small group of testers and folded the technology into ChatGPT, its popular online chatbot.\nCalled DALL-E 3, it can produce more convincing images than previous versions of the technology, showing a \nparticular knack for images containing letters, numbers and human hands, the company said.\n“It is far better at understanding and representing what the user is asking for,” said Aditya Ramesh, an OpenAI \nresearcher, adding that the technology was built to have a more precise grasp of the English language.\nBy adding the latest version of DALL-E to ChatGPT, OpenAI is solidifying its chatbot as a hub for generative A.I., \nwhich can produce text, images, sounds, software and other digital media on its own. Since ChatGPT went viral last \nyear, it has kicked off a race among Silicon Valley tech giants to be at the forefront of A.I. with advancements.\nOn Tuesday, Google released a new version of its chatbot, Bard, which connects with several of the company’s \nmost popular services, including Gmail, YouTube and Docs. Midjourney and Stable Diffusion, two other image \ngenerators, updated their models this summer.\nOpenAI has long offered ways of connecting its chatbot with other online services, including Expedia, OpenTable \nand Wikipedia. But this is the first time the start-up has combined a chatbot with an image generator.\nDALL-E and ChatGPT were previously separate applications. But with the latest release, people can now use \nChatGPT’s service to produce digital images simply by describing what they want to see. Or they can create \nimages using descriptions generated by the chatbot, further automating the generation of graphics, art and other \nmedia.\nIn a demonstration this week, Gabriel Goh, an OpenAI researcher, showed how ChatGPT can now generate \ndetailed textual descriptions that are then used to produce images. After creating descriptions of a logo for a \nrestaurant called Mountain Ramen, for instance, the bot generated several images from those descriptions in a \nmatter of seconds.\nChatGPT Can Now Generate Images, Too\nThe new version of DALL-E can produce images from multi-paragraph descriptions and closely follow instructions \nlaid out in minute detail, Mr. Goh said. Like all image generators — and other A.I. systems — it is also prone to \nmistakes, he said.\nAs it works to refine the technology, OpenAI is not sharing DALL-E 3 with the wider public until next month. DALL-E \n3 will then be available through ChatGPT Plus, a service that costs $20 a month.\nImage-generating technology can be used to spread large amounts of disinformation online, experts have warned. \nTo guard against that with DALL-E 3, OpenAI has incorporated tools designed to prevent problematic subjects, \nsuch as sexually explicit images and portrayals of public figures. The company is also trying to limit DALL-E’s ability \nto imitate specific artists’ styles.\nIn recent months, A.I. has been used as a source of visual misinformation. A synthetic and not especially \nsophisticated spoof of an apparent explosion at the Pentagon sent the stock market into a brief dip in May, among \nother examples. Voting experts also worry that the technology could be used maliciously during major elections.\nSandhini Agarwal, an OpenAI researcher who focuses on safety and policy, said DALL-E 3 tended to generate \nimages that were more stylized than photorealistic. Still, she acknowledged that the model could be prompted to \nproduce convincing scenes, such as the type of grainy images captured by security cameras.\nFor the most part, OpenAI does not plan to block potentially problematic content coming from DALL-E 3. Ms. \nAgarwal said such an approach was “just too broad” because images could be innocuous or dangerous depending \non the context in which they appear.\n“It really depends on where it’s being used, how people are talking about it,” she said.\nPHOTOS: With OpenAI’s DALL-E 3, people can use ChatGPT’s service to produce digital images simply by \ndescribing what they want to see. It is also prone to mistakes. (PHOTOGRAPHS VIA OPENAI); Sandhini Agarwal, \na researcher for OpenAI, said the images tended to be more stylized than photorealistic. (PHOTOGRAPH BY JIM \nWILSON/THE NEW YORK TIMES) This article appeared in print on page B5.\nLoad-Date: September 21, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Wayve, an A.I. Start-Up for Autonomous Vehicles, Raises $1 Billion",
        "media": "The New York Times",
        "time": "May 7, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "570 words",
        "byline": "By Adam Satariano",
        "story_text": "Wayve, an A.I. Start-Up for Autonomous Vehicles, Raises $1 Billion\nThe New York Times\nMay 7, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 570 words\nByline: By Adam Satariano\nBody\nThe London-based developer of artificial intelligence systems for self-driving vehicles raised the funding from \nSoftBank, Nvidia, Microsoft and others.\nWayve, a London maker of artificial intelligence systems for autonomous vehicles, said on Tuesday that it had \nraised $1 billion, an eye-popping sum for a European start-up and an illustration of investor optimism about A.I.'s \nability to reshape industries. \n  SoftBank, the Japanese conglomerate that backed Uber and other tech companies, was the lead investor, along \nwith Microsoft and Nvidia. Previous investors in Wayve include Yann LeCun, Meta's chief A.I. scientist.\n  Wayve, which had previously raised about $300 million, did not disclose its valuation after the investment.\n  Wayve was co-founded in 2017 by Alex Kendall, a Cambridge University doctorate student focused on computer \nvision and robotics. Unlike generative A.I. models, which create humanlike text and images and are being \ndeveloped by OpenAI, Google and Anthropic, the so-called embodied A.I. systems made by Wayve serve as the \nbrains for physical objects, be they cars, robots or manufacturing systems. The A.I. allows a machine to make real-\ntime decisions on its own.\n  ''The full potential of A.I. is when we have machines that are in the physical world that we can trust,'' Mr. Kendall \nsaid.\n  Companies focused on autonomous driving are facing a bumpy period. The technology is expensive and difficult \nto build and faces intense regulatory scrutiny. Cruise, the General Motors self-driving subsidiary, removed its \ndriverless cars from the road last year amid safety and legal concerns. Apple recently abandoned its self-driving car \nefforts after years of development.\n  Wayve, which has about 300 employees, has tested its technology on British roads since 2018 and will soon \nexpand elsewhere. The software takes advantage of cameras, sensors and other modern car technology to see \nand react to different driving environments. Data collected as the car navigates a town or city is fed back into the \nA.I. system to help cars learn. \n  The approach differs from other autonomous vehicle developers like Waymo, owned by Google's parent company \nAlphabet. Wayve said its technology doesn't rely as heavily on high-definition maps or lidar sensors, a laser tool \nused for measuring distance and detecting objects. Tesla has used an approach similar to Wayve in recent years. \n  Wayve has been building software to explain in plain English why a car made a certain driving decision -- like why \nit stopped suddenly or slowed down -- a layer of transparency to help win over regulators.\nWayve, an A.I. Start-Up for Autonomous Vehicles, Raises $1 Billion\n  The amount raised by Wayve is among the largest recent start-up investments in Europe, which has historically \nlagged behind the United States for venture capital and tech financing. In December, Mistral, a French A.I. \ndeveloper, raised 385 million euros, or about $415 million.\n  ''I'm incredibly proud that the U.K. is the home for pioneers like Wayve who are breaking ground as they develop \nthe next generation of A.I. models for self-driving cars,'' Prime Minister Rishi Sunak of Britain said in a statement.\n  Mr. Kendall, who is from New Zealand, said the investment from SoftBank and others would allow the company to \nturn its research into a full commercial product. He said Wayve was negotiating with several large automobile \nmanufacturers to get its software in cars available to purchase, but declined to name them.\nhttps://www.nytimes.com/2024/05/06/technology/wayve-ai-self-driving-vehicles.html\nGraphic\n \nPHOTO: Wayve's A.I. systems are designed to make real-time decisions on their own. (PHOTOGRAPH VIA \nWAYVE This article appeared in print on page B4.               \nLoad-Date: May 7, 2024"
    },
    {
        "file_name": "The_Economic_Times_Feb2024",
        "header": "Nexus Venture Partners leads $20 million funding at DevOps startup Orkes",
        "media": "The Economic Times",
        "time": "February 22, 2024",
        "section": "FUNDING",
        "length": "511 words",
        "byline": " ",
        "story_text": "Nexus Venture Partners leads $20 million funding at DevOps startup Orkes\nThe Economic Times\nFebruary 23, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 511 words\nBody\nNexus Venture Partners, a US- and India-based venture capital major, has led a $25 million funding round in Orkes, \nan orchestration-focussed DevOps (developer operations) startup.The Cupertino, California-headquartered startup \nhas witnessed significant growth since its initial launch and $9.3 million raise in 2022, as per a statement.The \ncompany solves application orchestration – the automation of workflows that coordinate and manage integrations \nbetween application services and databases – for clients such as United Wholesale Mortgage, Foxtel and \nCollective.The latest funding round also saw participation from existing investors such as Battery Ventures and \nVertex Ventures US. Nexus Venture Partners managing director Abhishek Sharma led the firm’s investment and will \nbe joining the board of Orkes.Orkes will use the funding to build out its offerings, such as its new artificial \nintelligence (AI) orchestration platform that will help integrate generative AI-enabled workflows into existing and \nnew applications.The startup’s open-source framework of orchestration DevOps tool, Conductor, is used by \nsoftware developers at companies such as Atlassian, Tesla, Oracle, American Express, GE Healthcare and \ngovernment agencies such as the UK’s Ministry of Justice, the statement added.\"Revenue has tripled in the past \nyear, with even faster logo growth; our average deal size is in the six figures. Our customers are investing heavily in \nOrkes across Amazon Web Services, Google Cloud Platform and Azure deployments as we enable them to have \ntheir data and compute residing on their cloud footprint or fully hosted by Orkes on the cloud of their choice,” Jeu \nGeorge, CEO and cofounder of Orkes, said.Developers use Orkes’ platform for use cases such as to build complex \napplications with both code and a visual user interface faster, transform development of distributed digital \nprocesses to ensure new applications are agile, transform tech stack from largely manual processes to streamlined \nand automated workflows and orchestration of machine learning pipelines, among others.\"The founders of Orkes \nwrote a new playbook for building and operating complex, observable and large-scale applications when they \nhelped create the Conductor open-source project at Netflix. \nNow, they've operationalized this modern approach to application building for the entire enterprise,\" Sharma \nsaid.Orkes was founded by George, Viren Baraiya, Boney Sekh and Dilip Lukose.Baraiya created the Conductor \nopen-source microservices and workflow orchestration engine, along with Sekh and George, while at Netflix to \nscale the hyper growth and resulting complexity of its code base.In 2021, the trio teamed up with former Microsoft \nand Amazon product leader Lukose to found Orkes as an enterprise-grade managed service for engineering teams \nlooking to build their applications on Conductor.Streaming platform Netflix has since stepped back from \nmaintenance of the open-source Conductor project, and Orkes now owns the project, the statement added. For \nReprint Rights: timescontent.com\nLoad-Date: February 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "An A.I. Hit of Fake ‘Drake’ and ‘The Weeknd’ Rattles the Music World",
        "media": "The New York Times",
        "time": "May 15, 2023",
        "section": "ARTS; music",
        "length": "1480 words",
        "byline": "Joe Coscarelli",
        "story_text": "An A.I. Hit of Fake ‘Drake’ and ‘The Weeknd’ Rattles the Music World\nThe New York Times \nApril 19, 2023 Wednesday 11:29 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: ARTS; music\nLength: 1480 words\nByline: Joe Coscarelli\nHighlight: A track like “Heart on My Sleeve,” which went viral before being taken down by streaming services this \nweek, may be a novelty for now. But the legal and creative questions it raises are here to stay.\nBody\nA track like “Heart on My Sleeve,” which went viral before being taken down by streaming services this week, may \nbe a novelty for now. But the legal and creative questions it raises are here to stay.\nFor Drake and the Weeknd, two of the most popular musicians on the planet, the existence of “Heart on My \nSleeve,” a track that claimed to use A.I. versions of their voices to create a passable mimicry, may have qualified as \na minor nuisance — a short-lived novelty that was easily stamped out by their powerful record company.\nBut for others in the industry, the song — which became a viral curio on social media, racking up millions of plays \nacross TikTok, Spotify, YouTube and more before it was removed this week — represented something more \nserious: a harbinger of the headaches that can occur when a new technology crosses over into the mainstream \nconsciousness of creators and consumers before the necessary rules are in place.\n“Heart on My Sleeve” was the latest and loudest example of a gray-area genre that has exploded in recent months: \nhomemade tracks that use generative artificial intelligence technology, in part or in full, to conjure familiar sounds \nthat can be passed off as authentic, or at least close enough. It earned instant comparisons to earlier technologies \nthat disrupted the music industry, including the dawn of the synthesizer, the sampler and the file-sharing service \nNapster.\nYet while A.I. Rihanna singing a Beyoncé song or A.I. Kanye West doing “Hey There Delilah” may seem like a \nharmless lark, the successful (if brief) arrival of “Heart on My Sleeve” on official streaming services, complete with \nshrewd online marketing from its anonymous creator, intensified alarms that were already ringing in the music \nbusiness, where corporations have grown concerned about A.I. models learning from, and then diluting, their \ncopyrighted material.\nUniversal Music Group, the largest of the major labels and home to both Drake and the Weeknd, had already \nflagged such content to its streaming partners this month, citing intellectual property concerns. But in a statement \nthis week, the company spoke to the broader stakes, asking “which side of history all stakeholders in the music \necosystem want to be on: the side of artists, fans and human creative expression, or on the side of deep fakes, \nfraud and denying artists their due compensation.”\nArtists and their labels are confident, at least for the time being, that the social and emotional component of fandom \nwill separate the work of the real Drake from a fake one, even if an A.I. version can nod at his emotional \npreoccupations and musical tics.\nAn A.I. Hit of Fake ‘Drake’ and ‘The Weeknd’ Rattles the Music World\nBut whether superstars could have their pockets picked, or become altogether obsolete in favor of machines that \ncan imitate them, is only one side of the equation. Royalty-free music generators can be used now to compose a \nrap beat, a commercial jingle or a film score, cutting into an already fragile economy for working musicians.\nAnd as generative A.I. booms and rapidly improves across text, images, sound and video, experts say the \ntechnology could reshape creative industries at all levels, with fans, artists and the systems that govern them \nhaving to adjust to new norms on the fly.\n“It is now possible to produce infinite media in the style or likeness of someone else, soon with little effort, so we all \nhave to come to terms with what that means,” the musician Holly Herndon, who has studied and used A.I. in her \nwork for years, wrote in an email.\n“The question is, as a society, do we care what Drake really feels or is it enough to just hear a superficially \nintelligent rendering?” she asked. “For some people that will not be enough. However, when you consider that most \npeople listening to Spotify are doing so just to have something pleasant to listen to, it complicates things.”\nThe breakthrough success of “Heart on My Sleeve,” uploaded by a user called ghostwriter, has helped bring music \nto the forefront of a conversation that has intensified lately around other mediums, especially since the release of \nOpen AI’s ChatGPT language model and image generators like DALL-E. Commenting under the track on YouTube, \nghostwriter promised, “This is just the beginning.”\nCourts and lawmakers are only beginning to sort out questions of ownership when it comes to A.I., and copyrights \nin music can be complicated as it is. For now, protected intellectual property can only be created by humans, but \nwhat about when musicians collaborate with the machines?\n[Video:  Watch on YouTube.]\nMartin Clancy, a musician and the chair of a global committee that seeks to explore the ethics of A.I. in the arts, \nsaid the music industry was more organized than some other fields grappling with the rise of A.I.\n“What’s at stake are things we take for granted: listening to music made by humans, people doing that as a \nlivelihood and it being recognized as a special skill,” he said.\nIt was unclear exactly which elements of “Heart on My Sleeve” — the lyrics, the instrumental beat, the melody, the \nvocals — were created by A.I. (Ghostwriter declined to comment.)\nSome songs have been written by real people and recorded with real human vocals, before being replaced by A.I. \nimitations of brand-name artists using tools that had “learned” from existing music and produced a similar effect. \nThose could invite one form of legal challenge: Artists and photographers, for instance, have sued image \ngenerators for creating derivative versions of their work.\nBut a human creator passing off her own song as being performed by a famous artist, or promoting it commercially \nusing that singer’s name or likeness, could lead to a different kind of legal threat. In the past, musicians including \nTom Waits and Bette Midler have successfully argued in court that they had a right to not just their musical \ncompositions or recordings, but their voices, in the face of sound-alike imitators in advertisements.\nIn this case, getting “Heart on My Sleeve” removed from services where it could have earned streaming royalties — \nand even charted on Billboard — may have been even simpler for Drake, the Weeknd and Universal Music. The \ntrack appeared to use a popular vocal snippet from the rapper Future that implied the song was produced by Metro \nBoomin, a sample of a master recording that was not cleared for use.\nDrake, the Weeknd and Metro Boomin declined to comment. (Last week, in response to another track that used an \nA.I. Drake voice to perform Ice Spice’s “Munch,” Drake wrote cheekily on Instagram, “This is the final straw AI.”)\nAside from raising questions of legality, such technology can introduce knotty ethical concerns regarding race and \nidentity. Last year, Capitol Records apologized and dropped the digital rap avatar FN Meka after critics said the \nAn A.I. Hit of Fake ‘Drake’ and ‘The Weeknd’ Rattles the Music World\nproject amounted to a form of blackface. Among the recent explosion of A.I. imitations, rap has emerged as the \nmost common playground.\n“It’s another way for people who are not Black to put on the costume of a Black person — to put their hands up \nKanye or Drake and make him a puppet — and that is alarming to me,” said Lauren Chanel, a writer on tech and \nculture. “This is just another example in a long line of people underestimating what it takes to create the type of art \nthat, historically, Black people make.”\nBut for musicians like Herndon, who has provided her own A.I. voice as a tool for other musicians — complete with \na system for compensation — and created a company, Spawning, to build consent guidelines for A.I., there can be \nmagic in harnessing the future fairly and ethically.\n“There is more opportunity in exploring this technology than trying to shut it down,” she said.\nWhile meme art like “Heart on My Sleeve” may quickly become “a real cultural force,” she added, “the novelty will \neventually be exhausted.” What will remain are the artistic possibilities “when anyone can assume the identity of \nsomeone else, even just for a second, as an expressive tool.”\nAs the technology continues to advance and is adopted in novel ways, someone may eventually do for A.I. voice \nmodels — part of what Herndon calls “identity play” — what producers like Prince Paul and J Dilla did for sampling.\n“As an artist I am interested in what it means for someone to be me, with my permission, and maybe even be better \nat being me in different ways,” Herndon said. “The creative possibilities there are fascinating and will change art \nforever. We just have to figure out the terms and tech.”\nAudio produced by Tally Abecassis.\nAudio produced by Tally Abecassis. \nPHOTOS: Labels hope fans will prize the work of artists, like the real Drake, above A.I. versions. (PHOTOGRAPH \nBY ADAM RIDING FOR THE NEW YORK TIMES) (C1); The short-lived viral hit “Heart on My Sleeve” claimed to \nuse A.I. versions of the voices of the Weeknd, left, and Drake. (PHOTOGRAPH BY MARIO ANZUONI/REUTERS) \n(C4) This article appeared in print on page C1, C4.\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Turning Over Her Office Inbox to A.I.",
        "media": "The New York Times",
        "time": "May 7, 2023",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 5",
        "length": "1842 words",
        "byline": "By Emma Goldberg",
        "story_text": "Turning Over Her Office Inbox to A.I.\nThe New York Times\nMay 7, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 5\nLength: 1842 words\nByline: By Emma Goldberg\nBody\nInbox management can be mind-numbing. You might have wondered, couldn't a robot do this?\nFive hours is enough time to watch a Mets game. It is enough time to listen to the Spice Girls' ''Spice'' album (40 \nminutes), Paul Simon's ''Paul Simon'' album (42 minutes) and Gustav Mahler's third symphony (his longest). It is \nenough time to roast a chicken, text your friends that you've roasted a chicken and prepare for an impromptu dinner \nparty. \n  Or you could spend it checking your email. Five hours is about how long many workers spend on email each day. \nAnd 90 minutes on the messaging platform Slack.\n  It's a weird thing, workplace chatter like email and Slack: It's sometimes the most delightful and human part of the \nwork day. It can also be mind-numbing to manage your inbox -- to the extent you might wonder, couldn't a robot do \nthis?\n  In late April, I decided to see what it would be like to let artificial intelligence into my life. I resolved to do an \nexperiment. For one week, I would write all my work communication -- emails, Slack messages, pitches, follow-ups \nwith sources -- through ChatGPT, the artificial intelligence language model from the research lab OpenAI. I didn't \ntell colleagues until the end of the week (except in a few instances of personal weakness). I downloaded a Chrome \nextension that drafted email responses directly into my inbox. But most of the time, I ended up writing detailed \nprompts into ChatGPT, asking it to be either witty or formal depending on the situation.\n  What resulted was a roller coaster, emotionally and in terms of the amount of content I was generating. I started \nthe week inundating my teammates (sorry) to see how they would react. At a certain point, I lost patience with the \nbot and developed a newfound appreciation for phone calls.\n  My bot, unsurprisingly, couldn't match the emotional tone of any online conversation. And I spend a lot of the \nweek, because of hybrid work, having online conversations.\n  The impulse to chat with teammates all day isn't wrong. Most people know the thrill (and also, usefulness) of office \nfriendships from psychologists, economists, TV sitcoms and our own lives; my colleague sends me photos of her \nbaby in increasingly chic onesies every few days, and nothing makes me happier. But the amount of time workers \nfeel they must devote to digitally communicating is undoubtedly excessive -- and for some, easy to make the case \nfor handing over to artificial intelligence.\n  .\nTurning Over Her Office Inbox to A.I.\n  The release of generative A.I. tools has raised all sorts of enormous and thorny questions about work. There are \nfears about what jobs will be replaced by A.I. in 10 years -- Paralegals? Personal assistants? Movie and television \nwriters are currently on strike, and one issue they're fighting for is limiting the use of A.I. by the studios. There are \nalso fears about the toxic and untruthful information A.I. can spread in an online ecosystem already rife with \nmisinformation. \n  The question driving my experiment was far narrower: Will we miss our old ways of working if A.I. takes over the \ndrudgery of communication? And would my colleagues even know, or would they be Chatfished?\n  My experiment started on a Monday morning with a friendly Slack message from an editor in Seoul who had sent \nme the link to a study analyzing humor across more than 2,000 TED and TEDx Talks. ''Pity the researchers,'' the \neditor wrote to me. I asked ChatGPT to say something clever in reply, and the robot wrote: ''I mean, I love a good \nTED Talk as much as the next person, but that's just cruel and unusual punishment!''\n  While not at all resembling a sentence I would type, this seemed inoffensive. I hit send.\n  I had begun the experiment feeling that it was important to be generous in spirit toward my robot co-conspirator. \nBy Tuesday morning, though, I found that my to-do list was straining the limits of my robot's pseudo-human wit. It \nso happened that my colleagues on the Business desk were planning a party. Renee, one of the party planners, \nasked me if I could help draft the invitation.\n  ''Maybe with your journalistic voice, you can write a nicer sentence than I just have,'' Renee wrote to me on Slack.\n  I couldn't tell her that my use of ''journalistic voice'' was a sore subject that week. I asked ChatGPT to craft a funny \nsentence about refreshments. ''I am thrilled to announce that our upcoming party will feature an array of delicious \ncheese plates,'' the robot wrote. ''Just to spice things up a bit (pun intended), we may even have some with a \nbusiness-themed twist!''\n  Renee was unimpressed and, ironically, wrote to me: ''OK, wait, let me get the ChatGPT to make a sentence.''\n  Meanwhile, I had exchanged a series of messages with my colleague Ben about a story we were writing together. \nIn a moment of anxiety, I called him to let him know it was ChatGPT writing the Slack messages, not me, and he \nadmitted that he had wondered whether I was annoyed at him. ''I thought I'd broken you!'' he said.\n  When we got off the phone, Ben messaged me: ''Robot-Emma is very polite, but in a way I'm slightly concerned \nmight hide her intention to murder me in my sleep.''\n  ''I want to assure you that you can sleep peacefully knowing that your safety and security are not at risk,'' my bot \nreplied. ''Take care and sleep well.''\n  Given the amount of time I spend online talking to colleagues -- about the news, story ideas, occasionally ''Love Is \nBlind'' -- it was disconcerting stripping those communications of any personality.\n  But it's not at all far-fetched. Microsoft earlier this year introduced a product, Microsoft 365 Copilot, that could \nhandle all the tasks I asked ChatGPT to do and far more. I recently saw it in action when Microsoft's corporate vice \npresident, Jon Friedman, showed me how Copilot could read emails he'd received, summarize them and then draft \npossible replies. Copilot can take notes during meetings, analyze spreadsheet data and identify problems that might \narise in a project.\n  I asked Mr. Friedman if Copilot could mimic his sense of humor. He told me that the product wasn't quite there yet, \nalthough it could make valiant comedic attempts. (He has asked it, for example, for pickleball jokes, and it delivered: \n''Why did the pickleball player refuse to play doubles? They couldn't dill with the extra pressure!'')\n  Of course, he continued, Copilot's purpose is loftier than mediocre comedy. ''Most of humanity spends way too \nmuch time consumed with what we call the drudgery of work, getting through our inbox,'' Mr. Friedman said. ''These \nthings just sap our creativity and our energy.''\nTurning Over Her Office Inbox to A.I.\n  Mr. Friedman recently asked Copilot to draft a memo, using his notes, recommending one of his employees for a \npromotion. The recommendation worked. He estimated that two hours' worth of work was completed in six minutes.\n  To some, though, the time savings aren't worth the peculiarity of outsourcing relationships.\n  ''In the future, you're going to get an email and someone will be like 'Did you even read it?' And you'll be like 'no' \nand then they'll be like 'Well I didn't write the response to you,''' said Matt Buechele, 33, a comedy writer who also \nmakes TikToks about office communications. ''It'll be robots going back and forth to each other, circling back.''\n  Mr. Buechele, in the middle of our phone interview, asked me unprompted about the email I had sent to him. ''Your \nemail style is very professional,'' he said.\n  I confessed that ChatGPT had written the message to him requesting an interview.\n  ''I was sort of like, 'This is going to be the most awkward conversation of my life,''' he said.\n  This confirmed a fear I'd been developing that my sources had started to think I was a jerk. One source, for \nexample, had written me an effusive email thanking me for an article I'd written and inviting me to visit his office \nwhen I was next in Los Angeles.\n  ChatGPT's response was muted, verging on rude: ''I appreciate your willingness to collaborate.''\n  I was feeling mournful of my past exclamation-point studded internet existence. I know people think exclamation \npoints are tacky. The writer Elmore Leonard advised measuring out ''two or three per 100,000 words of prose.'' \nRespectfully, I disagree. I often use two or three per two or three words of prose. I'm an apologist for digital \nenthusiasm. ChatGPT, it turns out, is more reserved.\n  For all the irritation I developed toward my robot overlord, I found that some of my colleagues were impressed by \nmy newly polished digital persona, including my teammate Jordyn, who consulted me on Wednesday for advice on \nan article pitch.\n  ''I have a story idea I'd love to chat with you about,'' Jordyn wrote to me. ''It's not urgent!!''\n  ''I'm always up for a good story, urgent or not!'' my robot replied. ''Especially if it's a juicy one with plot twists and \nunexpected turns.''\n  After a few minutes of back-and-forth, I was desperate to talk with Jordyn in person. I was losing patience with the \nbot's cloying tone. I missed my own stupid jokes, and (comparatively) normal voice.\n  More alarmingly, ChatGPT is prone to hallucinating -- meaning putting words and ideas together that don't actually \nmake sense. While writing a note to a source about the timing for an interview, my bot randomly suggested asking \nhim whether we should coordinate our outfits in advance so that our auras and chakras wouldn't clash.\n  I asked ChatGPT to draft a message to another colleague, who knew about my experiment, telling him I was in \nhell. ''I'm sorry, but I cannot generate inappropriate or harmful content,'' the robot replied. I asked it to draft a \nmessage explaining that I was losing my mind. ChatGPT couldn't do that either.\n  Of course, many of the A.I. experts I consulted were undeterred by the notion of shedding their personalized \ncommunication style. ''Truthfully, we copy and paste a lot already,'' said Michael Chui, a McKinsey partner and \nexpert in generative A.I.\n  Mr. Chui conceded that some people see signs of dystopia in a future where workers communicate mostly through \nrobots. He argued, though, that this wouldn't look all that unlike corporate exchanges that are already formulaic. ''I \nrecently had a colleague send me a text message saying, 'Hey was that last email you sent legit?''' Mr. Chui \nrecalled.\nTurning Over Her Office Inbox to A.I.\n  It turned out that the email had been so stiff that the colleague thought it was written through ChatGPT. Mr. Chui's \nsituation is a bit particular, though. In college, his freshman dorm voted to assign him a prescient superlative: ''Most \nlikely to be replaced by a robot of his own making.''\n  I decided to end the week by asking the deputy editor of my department what role he saw for A.I. in the \nnewsroom's future. ''Do you think there's a possibility that we could see AI-generated content on the front page one \nday?'' I wrote over Slack. ''Or do you think that there are some things that are just better left to human writers?''\n  ''Well, that doesn't sound like your voice!'' the editor replied.\n  A day later, my experiment complete, I typed back my own response: ''That's a relief!!!''\nhttps://www.nytimes.com/2023/05/05/business/ai-chatbot-messaging-work.html\nGraphic\n \nPHOTO (PHOTOGRAPH BY RICHARD BORGE) This article appeared in print on page BU5.               \nLoad-Date: May 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Blinken Warns of Disinformation Threat to Democracies",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "WORLD; asia",
        "length": "819 words",
        "byline": "Michael Crowley Michael Crowley covers the State Department and U.S. foreign policy for The Times. He",
        "story_text": "Blinken Warns of Disinformation Threat to Democracies\nThe New York Times \nMarch 18, 2024 Monday 23:00 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: WORLD; asia\nLength: 819 words\nByline: Michael Crowley Michael Crowley covers the State Department and U.S. foreign policy for The Times. He \nhas reported from nearly three dozen countries and often travels with the secretary of state.\nHighlight: At an international forum, the secretary of state said artificial intelligence’s ability to disrupt the global \nflow of information could prove politically perilous during a year of elections.\nBody\nAt an international forum, the secretary of state said artificial intelligence’s ability to disrupt the global flow of \ninformation could prove politically perilous during a year of elections.\nSecretary of State Antony J. Blinken warned on Monday that a malicious “flood” of disinformation was threatening \nthe world’s democracies, fueled in part by the swift rise of artificial intelligence, which he says sows “suspicion, \ncynicism and instability” around the globe.\nMr. Blinken spoke in Seoul at the Summit for Democracy, a global gathering organized by the Biden administration, \nwhich has made countering the authoritarian models of nations like Russia and China a top priority.\nMr. Blinken, who as a young man worked briefly as a journalist, said that changes to the international flow of \ninformation may be “the most profound” that he has experienced in his career, and that anti-democratic forces were \nexploiting those changes.\n“Our competitors and adversaries are using disinformation to exploit fissures within our democracies,” he said.\nHe noted that countries totaling nearly half of the world’s population, including India, will hold elections this year \nunder the threat of manipulated information. He did not mention the United States’ presidential election in \nNovember, which many analysts say could be influenced by foreign-directed information campaigns like the one \nRussia waged in 2016.\nThe U.S. promotes “digital and media literacy” programs abroad to help news consumers judge the reliability of \ncontent, Mr. Blinken said. But he cautioned that American adversaries were clever about laundering their \npropaganda and disinformation. China, for instance, has purchased cable television providers in Africa and then \nexcluded international news channels from subscription packages, he said.\nAnd increasingly powerful generative A.I. programs, Mr. Blinken said, can “fool even the most sophisticated news \nconsumers.”\nThe State Department has urged social media platforms to take more action, including by clearly labeling A.I.-\ngenerated content. Meta, the parent company of Facebook, announced such a plan last month for content posted \non Facebook and Instagram.\nBlinken Warns of Disinformation Threat to Democracies\nBut experts at the conference said the challenge was enormous. Speaking on the subject later in the day, Oliver \nDowden, the deputy prime minister of Britain, cited the example of an A.I.-generated image of Pope Francis in a \npuffer jacket that drew wide attention last year.\nMr. Dowden said that even though he understood that the image was fake, he retains a mental association between \nthe pope and puffer jackets. Such images “influence your perceptions” subconsciously, he said.\nMr. Blinken spoke days after a new report commissioned by the State Department and released last week warned \nthat artificial intelligence presents the world with “catastrophic risks.” The report said that an A.I. system “capable of \nsuperhuman persuasion” could undermine the democratic process.\nIt also cited an unnamed prominent A.I. researcher’s concern that “the model’s potential persuasive capabilities \ncould ‘break democracy’ if they were ever leveraged in areas such as election interference or voter manipulation.”\nMr. Blinken discussed the threat of commercial spyware, which he said several governments had used to monitor \nand intimidate journalists and political activists. He said that six countries — Finland, Germany, Ireland, Japan, \nPoland and South Korea — were joining a U.S.-led coalition to ensure that commercial spyware “is deployed \nconsistent with universal human rights and basic freedoms.”\nPresident Biden issued an executive order a year ago barring the U.S. government from using commercial spyware, \nthough not similar tools built by U.S. intelligence agencies.\nThis week’s Summit for Democracy is the third installment of a forum started in 2021 by Mr. Biden, who said during \nhis State of the Union address this month that “freedom and democracy are under attack both at home and \noverseas.” The meetings are intended to help other nations promote best civil society practices and defend against \npolitical sabotage.\nMr. Blinken’s visit to Seoul occurred as North Korea conducted its latest test launch of several short-range ballistic \nmissiles. The launches came days after joint U.S.-South Korean military exercises that North Korea denounced as \nprovocative.\nMr. Blinken did not mention the launches in his public remarks, although the State Department condemned them.\nMatthew Miller, a department spokesman, also said in a statement that Mr. Blinken and the South Korean foreign \nminister, Cho Tae-yul, discussed “Pyongyang’s military support for Russia’s war against Ukraine” and North Korea’s \n“increasingly aggressive rhetoric and activities.”\nPHOTO: Secretary of State Antony J. Blinken spoke Monday in Seoul at the Summit for Democracy. \n(PHOTOGRAPH BY ANTHONY WALLACE/AGENCE FRANCE-PRESSE — GETTY IMAGES) This article \nappeared in print on page A4.\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jan2024",
        "header": "Shaping India’s digital landscape",
        "media": "Economic Times (E-Paper Edition)",
        "time": "January 11, 2024",
        "section": "ECONOMY",
        "length": "684 words",
        "byline": "Artha.Neog@timesgroup.com",
        "story_text": "Shaping India’s digital landscape\nEconomic Times (E-Paper Edition)\nJanuary 12, 2024 Friday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY\nLength: 684 words\nByline: Artha.Neog@timesgroup.com\nHighlight: The AdTech landscape undergoes significant changes, driven by the fusion of AI and creativity\nBody\nAs the digital landscape continues its dynamic evolution,  the realm of advertising technology, also known as \nAdTech, stands poised for groundbreaking shifts. From the fusion of  artificial intelligence (AI) and creativity to the \nresurgence of contextual targeting, multiple trends are set to potentially alter the AdTech landscape.  In 2024, the \nIndian advertising market is expected to witness a growth of 11.4 percent and reach `1.22 lakh crore. Also, India is \npredicted to enter the top ten markets and rise to eighth place by 2028. The country was ranked as the 11th largest \nad market in the world as of last year. \nToday, it is crucial to understand and harness emerging trends for publishers and advertisers to stay ahead in the \ndynamic and competitive programmatic world.A KEY GROWTH LEVERAs traditional cookies become irrelevant, \nembracing advanced AI techniques like agent-based modelling is essential for adaptable advertising. “Today, in the \npost-cookie era, advertisers must turn to AI-  driven contextual advertising, a potent tool for innovation in \nmanagement, robotics, and marketing. Contextual analysis, based on content rather than personal data, ensures \nprecision in ad positioning, brand safety, and real-time detection of malicious activities,” says, Arpit Jain, founder \nand CEO, PubScale and GreedyGame.  Besides AI, Generative AI (GenAI) can design and create ads that can be \nincorporated into an in-game setting. This will ensure that they are non-intrusive and engaging and help utilise the \nuntapped real estate in games. “In the dynamic realm of Adtech, AI  tools deftly navigate operational tasks, freeing \nmarketers to focus on creativity and strategy— nurturing innovation’s seeds. The investments in cutting-edge \nAdtech and strategic partnerships yield enhanced results, diminishing reliance on traditional manpower,” says, \nArchit Agarwal, founder and CEO, Tikshark Solutions.  The AdTech industry is evolving, and those at the forefront \nof these advancements can be expected to shape the future of  a more nuanced, user-centric, and ethically aligned \nadvertising ecosystem. Dhaval Gupta, MD of CMRSL, the parent company of CMGalaxy, says, “In addition to \ncreating content, analysing data, and automating multiple marketing processes, AI will play a key role in allowing \nmarketing teams to shift away from their day-today routine work and transition to focusing more on how their brands \ncan grow and what customers want.” Elaborating more, Vinod K Singh, cofounder, Concirrus UK, says, “Adtech’s \nfuture lies in AIpowered, hyperrelevant ads that adapt to your context in real-time.  Imagine dynamic visuals, copy, \nand interactions that change based on what you are browsing, watching, or even feeling.”A PROFOUND \nTRANSFORMATIONIn 2024, cutting-edge AdTech solutions facilitate the seamless integration of Augmented \nReality (AR) and Virtual Reality VR into existing advertising ecosystems, offering highly interactive and personalised \nconsumer experiences. As we enter 2024, the incorporation of AR and VR represents a paradigm shift in AdTech, \nreshaping  the landscape and paving the way for more engaging and innovative marketing strategies. “AR and VR \nenable immersive, interactive ad experiences, allowing users to engage with products and brands in virtual \nenvironments. Ingame ad creatives enabled by AR or VR will become an effective way to boost engagement \nwithout compromising on user experience,” shares Jain.  As we navigate the dynamic landscape AdTech trends in \n2024, it is evident that the industry is undergoing a  profound transformation. The spotlight is on crafting \nShaping India ’s digital landscape\nexperiences that are not only relevant and personalised but also deeply engaging, all within the framework of user \nprivacy and regulatory compliance.  “A diverse array of emerging AdTech trends is shaping the industry \nencompassing facets  like increased dependency on firstparty data, shift from English to local languages for \nfacilitating better communication, fostering brand transparency to boost loyalty, etc.,” concludes, Delphin Varghese, \ncofounder and chief business officer, AdCounty Media.\nLoad-Date: January 11, 2024"
    },
    {
        "file_name": "New_York_Observer_Aug2023",
        "header": "How to Empower Retail Founders & CEOs to Think Beyond Survival Mode",
        "media": "New York Observer",
        "time": "August 22, 2023",
        "section": "",
        "length": "1158 words",
        "byline": "Nicole Marra and Brooke Crescenti Bulan",
        "story_text": "How to Empower Retail Founders & CEOs to Think Beyond Survival Mode\nNew York Observer\nAugust 21, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 1158 words\nByline: Nicole Marra and Brooke Crescenti Bulan\nBody\nRetail is a scary business. Consumers are spending more cautiously (the luxury industry, in particular, is feeling the \neffect of the aspirational customer taking a pause), there's a glut of open jobs in the retail sector (nearly a million), \ninflation continues, brands struggle to find the right balance between e-commerce and brick-and-mortar channels \n(and bear the tech investment of omnichannel solutions being demanded by customers), emerging technologies \n(hello generative AI!) are rapidly changing the game entirely, and the supply chain hasn't fully recovered from the \ndays of the pandemic. In short, there is a collective sense of unease and nobody really knows what's coming next.  \nAs a result, brands and retail leaders feel overwhelmed and uncertain about what direction to take, and where to \nfocus first. Unfortunately, many leaders don't have the luxury of time to focus or strategize: they are pulled in a \nmillion directions, not working to their highest and best purpose.\nWhy are leaders so distracted?\nTalk to any founder or CEO of an independent brand-one that doesn't have the benefit of the experienced operating \ninfrastructure of a parent or conglomerate holding company-and they will tell you that they spend an outsized \namount of time and energy on things other than strategy and really moving the needle for their business. Things like \nhuman resources issues, deciphering unintelligible or impractical legal advice, managing vendors, prepping \ncommunications to stakeholders, and navigating distribution challenges. All while being kept up at night by their \nmandate to drive revenue and grow their business.  They don't have the space to think creatively. They are too \ndistracted, too bogged down, and mired in everyday operational details. Even if they have a great leadership team \naround them, those leaders are likely suffering from similar limitations-they just don't have the foundational \ninfrastructure to allow them to step out of the minutiae.  \nFractional support services have emerged as a game-changer for these leaders. Instead of hiring multiple full-time \nprofessionals for functions such as legal, human resources, real estate and finance, brands can leverage a shared \nservice platform like ours, which offers access to deeply experienced professionals in the industry. Our company, \nFixer, is particularly noteworthy for combining legal and business subject-matter expertise under one roof (we \nhaven't seen anyone else do it to the same extent in the retail industry).  Key benefits include: \n• Reclaiming time: We've found that this model liberates CEOs from the burden of administrative and \noperational tasks and allows them to concentrate on strategic initiatives and business growth.  By \ndelegating non-core functions to experienced professionals that have seen and done it all before, CEOs \ncan finally lean into driving innovation and positioning their brands for success. \n• Tapping into expertise: Beyond alleviating day-to-day operational challenges, the shared service model \nbecomes a vital source of advice, expertise, and operational excellence that empowers CEOs to overcome \nobstacles and gives them a safe space for thought partnership and ideation that can be immediately \nactioned into tactical results. By tapping into experts with a wealth of knowledge and industry insights, \nCEOs are able to make well-informed decisions and address challenges with more confidence.  \nHow to Empower Retail Founders & CEOs to Think Beyond Survival Mode\n• Unburdening teams: They can also unlock the full potential of their teams - when a team is freed up to focus \non core competencies and strategic initiatives, this increased focus on key areas of the business can lead \nto increased overall performance.\n• Continuous improvement and competitive advantage: By working with multiple clients within the industry and \nhaving exposure to many different business models and best practices, shared service providers can share \nfresh perspectives, insights, and lessons learned from other companies (while maintaining the highest \nlevels of trust and confidentiality), contributing to continuous improvement and learning within the \norganization, while keeping clients one step ahead.  It's often harder to see the big picture and the industry \nlandscape from within the organization.\n• Cost-effectiveness: Brands can benefit from economies of scale while receiving top-tier expertise tailored to \ntheir specific needs, avoiding the expense of recruitment and training. This aspect is especially valuable for \nsmaller and mid-sized companies with limited budgets-particularly in uncertain economic times such as \nthese. Moreover, when dealing with periods of fluctuating demand, or when facing short-term challenges, \ncompanies have the flexibility to engage specific services as and when needed, without committing to long-\nterm contracts or overhead costs.\nThe impact is real\nFractional support services are not just supplementary resources. We've seen the tangible impact they can have. A \nclassic example is Fixer's work with a successful DTC brand with a relatively young leadership team. They were \ntrying to juggle legal and HR issues (neither of which they had expertise in) while planning their retail strategy, \ndriving sales and managing their core job functions-all while being mindful of budgets. By engaging Fixer, they were \nable to hand over all of the legal and HR work, giving their founder and C-suite executives a single point of \naccountable, deeply experienced support, and eliminating the wasted time and energy it was taking to manage \nthese issues themselves.\nWe supported another client through a complex legal issue, enabling them to tap into insights that the shared \nservice model makes possible. Seeing the value in this, the CEO remarked that \"while everything about the \nsituation was unfamiliar territory for us, the Fixer team had been through it all before, and shared their experience \nand knowledge-to our great benefit and peace of mind.\" Another experienced fashion industry CEO, whose brand \nwe support with DE&I/corporate culture, HR, legal, real estate and commercial matters, has shared that \"as a \nbusiness leader, I feel well supported by the depth of experience and knowledge that the Fixer team brings to the \ntable.\"  \nWe are on a mission to give independent brands the access, knowledge, experience, and tactical support to be \nformidable players in the industry, and to give their founders, CEOs and leaders back the valuable time and energy \nthey need to steer their ships through rocky waters, knowing that they have a deep foundation of support beneath \nthem. However, it's a two-way street. The critical thread among our clients is their willingness to learn, grow, and \nadapt. It takes vulnerability and curiosity for leaders to recognize that they need help, and seek it out in an \nunconventional way. Those are the most fruitful partnerships in a shared services model because in those cases, \nwe're not just fixing something that's broken, but we are building something together.\nLoad-Date: August 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Fake and Explicit Images of Taylor Swift Started on 4chan, Study Says",
        "media": "The New York Times",
        "time": "February 6, 2024",
        "section": "BUSINESS; media",
        "length": "973 words",
        "byline": "Tiffany Hsu &lt;p&gt;Tiffany Hsu reports on misinformation and disinformation and its origins, movement",
        "story_text": "Fake and Explicit Images of Taylor Swift Started on 4chan, Study Says\nThe New York Times \nFebruary 5, 2024 Monday 23:13 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 973 words\nByline: Tiffany Hsu &lt;p&gt;Tiffany Hsu reports on misinformation and disinformation and its origins, movement \nand consequences. She has been a journalist for more than two decades.&lt;/p&gt;\nHighlight: The people on 4chan who created the images of Ms. Swift thought of it as a sort of game, the \nresearchers said.\nBody\nThe people on 4chan who created the images of Ms. Swift thought of it as a sort of game, the researchers said.\nImages of Taylor Swift that had been generated by artificial intelligence and had spread widely across social media \nin late January probably originated as part of a recurring challenge on one of the internet’s most notorious message \nboards, according to a new report.\nGraphika, a research firm that studies disinformation, traced the images back to one community on 4chan, a \nmessage board known for sharing hate speech, conspiracy theories and, increasingly, racist and offensive content \ncreated using A.I.\nThe people on 4chan who created the images of the singer did so in a sort of game, the researchers said — a test \nto see whether they could create lewd (and sometimes violent) images of famous female figures.\nThe synthetic Swift images spilled out onto other platforms and were viewed millions of times. Fans rallied to Ms. \nSwift’s defense, and lawmakers demanded stronger protections against A.I.-created images.\nGraphika found a thread of messages on 4chan that encouraged people to try to evade safeguards set up by image \ngenerator tools, including OpenAI’s DALL-E, Microsoft Designer and Bing Image Creator. Users were instructed to \nshare “tips and tricks to find new ways to bypass filters” and were told, “Good luck, be creative.”\nSharing unsavory content via games allows people to feel connected to a wider community, and they are motivated \nby the cachet they receive for participating, experts said. Ahead of the midterm elections in 2022, groups on \nplatforms like Telegram, WhatsApp and Truth Social engaged in a hunt for election fraud, winning points or \nhonorary titles for producing supposed evidence of voter malfeasance. (True proof of ballot fraud is exceptionally \nrare.)\nIn the 4chan thread that led to the fake images of Ms. Swift, several users received compliments — “beautiful gen \nanon,” one wrote — and were asked to share the prompt language used to create the images. One user lamented \nthat a prompt produced an image of a celebrity who was clad in a swimsuit rather than nude.\nRules posted by 4chan that apply sitewide do not specifically prohibit sexually explicit A.I.-generated images of real \nadults. \n“These images originated from a community of people motivated by the ‘challenge’ of circumventing the safeguards \nof generative A.I. products, and new restrictions are seen as just another obstacle to ‘defeat,’” Cristina López G., a \nFake and Explicit Images of Taylor Swift Started on 4chan, Study Says\nsenior analyst at Graphika, said in a statement. “It’s important to understand the gamified nature of this malicious \nactivity in order to prevent further abuse at the source.”\nMs. Swift is “far from the only victim,” Ms. López G. said. In the 4chan community that manipulated her likeness, \nmany actresses, singers and politicians were featured more frequently than Ms. Swift.\nOpenAI said in a statement that the explicit images of Ms. Swift were not generated using its tools, noting that it \nfilters out the most explicit content when training its DALL-E model. The company also said it uses other safety \nguardrails, such as denying requests that ask for a public figure by name or seek explicit content.\nMicrosoft said that it was “continuing to investigate these images” and added that it had “strengthened our existing \nsafety systems to further prevent our services from being misused to help generate images like them.” The \ncompany prohibits users from using its tools to create adult or intimate content without consent and warns repeat \noffenders that they may be blocked.\nFake pornography generated with software has been a blight since at least 2017, affecting unwilling celebrities, \ngovernment figures, Twitch streamers, students and others. Patchy regulation leaves few victims with legal \nrecourse; even fewer have a devoted fan base to drown out fake images with coordinated “Protect Taylor Swift” \nposts.\nAfter the fake images of Ms. Swift went viral, Karine Jean-Pierre, the White House press secretary, called the \nsituation “alarming” and said lax enforcement by social media companies of their own rules disproportionately \naffected women and girls. She said the Justice Department had recently funded the first national helpline for people \ntargeted by image-based sexual abuse, which the department described as meeting a “rising need for services” \nrelated to the distribution of intimate images without consent. SAG-AFTRA, the union representing tens of \nthousands of actors, called the fake images of Ms. Swift and others a “theft of their privacy and right to autonomy.”\nArtificially generated versions of Ms. Swift have also been used to promote scams involving Le Creuset cookware. \nA.I. was used to impersonate President Biden’s voice in robocalls dissuading voters from participating in the New \nHampshire primary election. Tech experts say that as A.I. tools become more accessible and easier to use, audio \nspoofs and videos with realistic avatars could be created in mere minutes.\nResearchers said the first sexually explicit A.I. image of Ms. Swift on the 4chan thread appeared on Jan. 6, 11 days \nbefore they were said to have appeared on Telegram and 12 days before they emerged on X. 404 Media reported \non Jan. 25 that the viral Swift images had jumped into mainstream social media platforms from 4chan and a \nTelegram group dedicated to abusive images of women. The British news organization Daily Mail reported that \nweek that a website known for sharing sexualized images of celebrities posted the Swift images on Jan. 15.\nFor several days, X blocked searches for Taylor Swift “with an abundance of caution so we can make sure that we \nwere cleaning up and removing all imagery,” said Joe Benarroch, the company’s head of business operations. \nAudio produced by Tally Abecassis.\nAudio produced by Tally Abecassis. \nThis article appeared in print on page B1, B4.\nLoad-Date: February 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Microsoft Blasted for A.I. Poll Placed Near Guardian Article",
        "media": "The New York Times",
        "time": "November 3, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "572 words",
        "byline": "By Jenny Gross",
        "story_text": "Microsoft Blasted for A.I. Poll Placed Near Guardian Article\nThe New York Times\nNovember 3, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 572 words\nByline: By Jenny Gross\nBody\nA poll generated by artificial intelligence, embedded next to a Guardian article on Microsoft's news aggregator \nplatform, asked readers to speculate on the cause of a woman's death.\nAn auto-generated poll that Microsoft embedded on its news aggregating platform alongside a Guardian article was \n''crass'' and caused significant damage to The Guardian's reputation, the newspaper said on Thursday. \n  The poll, which was posted last week next to an article about a woman who was found dead in a school bathroom \nin Australia, asked readers to speculate on the cause of the woman's death. It gave three choices: murder, accident \nor suicide. The Guardian said the poll was created using generative artificial intelligence, which can generate \ntext, images and other media from prompts.\n  Anna Bateson, the chief executive of Guardian Media Group, wrote in a letter to Microsoft that the poll was ''clearly \nan inappropriate use of genAI.''\n  ''Not only is this sort of application potentially distressing for the family of the individual who is the subject of the \nstory, it is also deeply damaging to the Guardian's hard-won reputation for trusted, sensitive journalism, and to the \nreputation of the individual journalists who wrote the original story,'' Ms. Bateson wrote in the letter, addressed to \nBrad Smith, Microsoft's vice chairman and president, on Tuesday. Ms. Bateson said that The Guardian had already \nasked Microsoft not to apply its experimental technologies to Guardian news articles because of the risks it posed.\n  A Guardian spokesman said the poll was ''crass'' and led commenters on Microsoft Start, the news aggregating \nplatform, to believe that The Guardian was to blame. One reader, unaware that Microsoft, not The Guardian, had \ncreated the poll, wrote: ''This has to be the most pathetic, disgusting poll I've ever seen. The author should be \nashamed.'' Another commented, ''polling the reason behind a persons death? what is wrong with you!!''\n  Microsoft said in a statement that it had deactivated Microsoft-generated polls for all news articles and that it was \n''investigating the cause of the inappropriate content.''\n  ''A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this \nkind of error from reoccurring in the future,'' the statement said.\n  The Guardian statement also criticized Microsoft for leaving the poll up for four days. It was removed on Monday, \nafter The Guardian contacted Microsoft, the Guardian spokesman said.\n  The British government this week hosted a summit to discuss the long-term safety of artificial intelligence, which \nresulted in 28 governments, including China and the United States, agreeing to cooperate on A.I. risk management.\nMicrosoft Blasted for A.I. Poll Placed Near Guardian Article\n  But the agreement fell short of setting specific policy goals, and The Guardian and other publishers have called on \ntech companies to specify how they will ensure safe use of artificial intelligence. In her letter, Ms. Bateson asked \nMicrosoft to specify how it would prioritize trusted news sources, provide fair compensation for licensing and the \nuse of journalism, and provide transparency and safeguards around its technologies.\n  Matt Rogerson, The Guardian's director of public policy, said tech companies need to determine how to address \nsituations when their use of artificial intelligence goes wrong. Microsoft has not appended a note to the article taking \nresponsibility for the poll, he said.\nhttps://www.nytimes.com/2023/11/02/business/media/microsoft-guardian-ai-poll.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: November 3, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "'India Will Establish Guardrails for AI Sector'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "FRONT PAGE",
        "length": "277 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "'India Will Establish Guardrails for AI Sector'\nEconomic Times (E-Paper Edition)\nMay 13, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 277 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: Govt not in favour of legislation regulating generative AI yet, unlike US, EU: MoS Chandrasekhar\nBody\nNew Delhi: India plans to establish “some principles” which will act as “guardrails” for the fast-growing artificial \nintelligence (AI) sector, according to a top lawmaker who said this will help regulate generative AI platforms such \nas Microsoft's Open AI and Google's Bard as well as their use by other companies.  In contrast to the view taken by \nthe European Union and the US, the Indian government is not in favour of legislation to regulate generative AI, yet, \naccording to Rajeev Chandrasekhar, minister of state for electronics  and IT. He added that discipline needs to be \nbrought into an industry that can cause much chaos and harm. \n“If anybody says I know the right way to regulate AI, there will be an Elon Musk view, the Open AI view, or 100 \nother views. We are not going to go down that road at all,” he told ET in an interview. “AI is an emerging technology, \nand  we will establish some principles as guardrails. Then the subordinate legislation or how to regulate it will keep \nevolving,” he said. India has one of the largest data sets and is therefore very crucial for companies working on \ngene-  rative AI. It is important India does not allow technology regulation to lag technology innovation in AI, the \nminister said. “AI innovation is now growing very fast. In the blink of an eye, there's a new disruption. So therefore, \nwe must establish fairly embedded principles in the law.” Pointing out that the proposed guardrails will put the onus \non the platforms to ensure that no one is using them to “create misinformation”, Chandrasekhar said “you cannot \ncreate things that are fake, you cannot cause user harm, you cannot have exploitive content.”\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "Silverneedle,_JSW_Ventures_Feb2024",
        "header": "Hyperautomation platform Zvolv secures $2 million in funding from",
        "media": "Silverneedle, JSW Ventures",
        "time": "February 28, 2024",
        "section": "FUNDING",
        "length": "324 words",
        "byline": " ",
        "story_text": "Hyperautomation platform Zvolv secures $2 million in funding from \nSilverneedle, JSW Ventures\nThe Economic Times\nFebruary 28, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 324 words\nBody\nZvolv, a hyper-automation company with operations across India, US, MEA and ANZ, raised about $2 million from \nSilverneedle Ventures, along with participation from existing investors, JSW Ventures.Launched in 2018 by former \nemployees of Apple and Texas Instruments Hardik Gandhi and Sujoy Chakravarty, Zvolv is a player in the LCNC \n(low-code/no-code) hyperautomation space in India.Zvolv plans to deploy the funds to expand & strengthen its \nLCNC Hyperautomation capabilities by integrating a trust-based generative AI layer into enterprise AI \napplications.The new capabilities will help enterprises drive significant efficiency gains utilising Zvolv's rapid \napplication development and integration capabilities, the company said in a statement.“We are extremely excited to \nbring on-board Silverneedle Ventures as partners, especially as we expand further into the US healthcare space,\" \nsaid Gandhi, CEO of Zvolv.Zvolv also plans to expand its offerings in the US market through reseller collaborations \nand direct presence.“Hardik and his team have built an outstanding AI product with a clear potential to significantly \naccelerate the digital transformation journeys of enterprises,\" said Abishek Balendran, partner, Silverneedle \nVentures.With still a larger depth and space available in the hyperautomation market, coupled with the new AI \norchestration capabilities possible with Zvolv’s offerings, we consider its product suite to be a major game changer, \nhe added.\"With this fundraise, Zvolv will get the additional firepower to increase their distribution capabilities, which \nwill cement their name as one of the top hyperautomation platforms for businesses not only in India, but globally,\" \nsaid Sachin Tagra, managing partner at JSW Ventures and a Zvolv board member.According to industry estimates, \nalmost 70% of new applications developed by enterprises will use low-code or no-code technologies by 2025. For \nReprint Rights: timescontent.com\nLoad-Date: February 28, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "The Surprising Thing A.I. Engineers Will Tell You if You Let Them; Ezra Klein",
        "media": "The New York Times",
        "time": "April 17, 2023",
        "section": "OPINION",
        "length": "2257 words",
        "byline": "Ezra Klein",
        "story_text": "The Surprising Thing A.I. Engineers Will Tell You if You Let Them; Ezra Klein\nThe New York Times \nApril 16, 2023 Sunday 12:56 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 2257 words\nByline: Ezra Klein\nHighlight: This is too important to leave to Microsoft, Google and Facebook.\nBody\nAmong the many unique experiences of reporting on A.I. is this: In a young industry flooded with hype and money, \nperson after person tells me that they are desperate to be regulated, even if it slows them down. In fact, especially if \nit slows them down.\nWhat they tell me is obvious to anyone watching. Competition is forcing them to go too fast and cut too many \ncorners. This technology is too important to be left to a race between Microsoft, Google, Meta and a few other firms. \nBut no one company can slow down to a safe pace without risking irrelevancy. That’s where the government comes \nin — or so they hope.\nA place to start is with the frameworks policymakers have already put forward to govern A.I. The two major \nproposals, at least in the West, are the “Blueprint for an A.I. Bill of Rights,” which the White House put forward in \n2022, and the Artificial Intelligence Act, which the European Commission proposed in 2021. Then, last week, China \nreleased its latest regulatory approach.\nLet’s start with the European proposal, as it came first. The Artificial Intelligence Act tries to regulate A.I. systems \naccording to how they’re used. It is particularly concerned with high-risk uses, which include everything from \noverseeing critical infrastructure to grading papers to calculating credit scores to making hiring decisions. High-risk \nuses, in other words, are any use in which a person’s life or livelihood might depend on a decision made by a \nmachine-learning algorithm.\nThe European Commission described this approach as “future-proof,” which proved to be predictably arrogant, as \nnew A.I. systems have already thrown the bill’s clean definitions into chaos. Focusing on use cases is fine for \nnarrow systems designed for a specific use, but it’s a category error when it’s applied to generalized systems. \nModels like GPT-4 don’t do any one thing except predict the next word in a sequence. You can use them to write \ncode, pass the bar exam, draw up contracts, create political campaigns, plot market strategy and power A.I. \ncompanions or sexbots. In trying to regulate systems by use case, the Artificial Intelligence Act ends up saying very \nlittle about how to regulate the underlying model that’s powering all these use cases.\nUnintended consequences abound. The A.I.A. mandates, for example, that in high-risk cases, “training, validation \nand testing data sets shall be relevant, representative, free of errors and complete.” But what the large language \nmodels are showing is that the most powerful systems are those trained on the largest data sets. Those sets can’t \nplausibly be free of error, and it’s not clear what it would mean for them to be representative. There’s a strong case \nto be made for data transparency, but I don’t think Europe intends to deploy weaker, less capable systems across \neverything from exam grading to infrastructure.\nThe Surprising Thing A.I. Engineers Will Tell You if You Let Them Ezra Klein\nThe other problem with the use case approach is that it treats A.I. as a technology that will, itself, respect \nboundaries. But its disrespect for boundaries is what most worries the people working on these systems. Imagine \nthat “personal assistant” is rated as a low-risk use case and a hypothetical GPT-6 is deployed to power an \nabsolutely fabulous personal assistant. The system gets tuned to be extremely good at interacting with human \nbeings and accomplishing a diverse set of goals in the real world. That’s great until someone asks it to secure a \nrestaurant reservation at the hottest place in town and the system decides that the only way to do it is to cause a \ndisruption that leads a third of that night’s diners to cancel their bookings.\nSounds like sci-fi? Sorry, but this kind of problem is sci-fact. Anyone training these systems has watched them \ncome up with solutions to problems that human beings would never consider, and for good reason. OpenAI, for \ninstance, trained a system to play the boat racing game CoastRunners, and built in positive reinforcement for \nracking up a high score. It was assumed that would give the system an incentive to finish the race. But the system \ninstead discovered “an isolated lagoon where it can turn in a large circle and repeatedly knock over three targets, \ntiming its movement so as to always knock over the targets just as they repopulate.” Choosing this strategy meant \n“repeatedly catching on fire, crashing into other boats, and going the wrong way on the track,” but it also meant the \nhighest scores, so that’s what the model did.\nThis is an example of “alignment risk,” the danger that what we want the systems to do and what they will actually \ndo could diverge, and perhaps do so violently. Curbing alignment risk requires curbing the systems themselves, not \njust the ways we permit people to use them.\nThe White House’s Blueprint for an A.I. Bill of Rights is a more interesting proposal (and if you want to dig deeper \ninto it, I interviewed its lead author, Alondra Nelson, on my podcast). But where the European Commission’s \napproach is much too tailored, the White House blueprint may well be too broad. No A.I. system today comes close \nto adhering to the framework, and it’s not clear that any of them could.\n“Automated systems should provide explanations that are technically valid, meaningful and useful to you and to any \noperators or others who need to understand the system, and calibrated to the level of risk based on the context,” \nthe blueprint says. Love it. But every expert I talk to says basically the same thing: We have made no progress on \ninterpretability, and while there is certainly a chance we will, it is only a chance. For now, we have no idea what is \nhappening inside these prediction systems. Force them to provide an explanation, and the one they give is itself a \nprediction of what we want to hear — it’s turtles all the way down.\nThe blueprint also says that “automated systems should be developed with consultation from diverse communities, \nstakeholders, and domain experts to identify concerns, risks and potential impacts of the system.” This is crucial, \nand it would be interesting to see the White House or Congress flesh out how much consultation is needed, what \ntype is sufficient and how regulators will make sure the public’s wishes are actually followed.\nIt goes on to insist that “systems should undergo predeployment testing, risk identification and mitigation, and \nongoing monitoring that demonstrate they are safe and effective based on their intended use.” This, too, is \nessential, but we do not understand these systems well enough to test and audit them effectively. OpenAI would \ncertainly prefer that users didn’t keep jail-breaking GPT-4 to get it to ignore the company’s constraints, but the \ncompany has not been able to design a testing regime capable of coming anywhere close to that.\nPerhaps the most interesting of the blueprint’s proposals is that “you should be able to opt out from automated \nsystems in favor of a human alternative, where appropriate.” In that sentence, the devil lurks in the definition of \n“appropriate.” But the underlying principle is worth considering. Should there be an opt-out from A.I. systems? \nWhich ones? When is an opt-out clause a genuine choice, and at what point does it become merely an invitation to \nrecede from society altogether, like saying you can choose not to use the internet or vehicular transport or banking \nservices if you so choose.\nThen there are China’s proposed new rules. I won’t say much on these, except to note that they are much more \nrestrictive than anything the United States or Europe is imagining, which makes me very skeptical of arguments that \nThe Surprising Thing A.I. Engineers Will Tell You if You Let Them Ezra Klein\nwe are in a race with China to develop advanced artificial intelligence. China seems perfectly willing to cripple the \ndevelopment of general A.I. so it can concentrate on systems that will more reliably serve state interests.\nChina insists, for example, that “content generated through the use of generative A.I. shall reflect the Socialist \nCore Values, and may not contain: subversion of state power; overturning of the socialist system; incitement of \nseparatism; harm to national unity; propagation of terrorism or extremism; propagation of ethnic hatred or ethnic \ndiscrimination; violent, obscene, or sexual information; false information; as well as content that may upset \neconomic order or social order.”\nIf China means what it says, its A.I. sector has its work cut out for it. A.I. is advancing so quickly in the United States \nprecisely because we’re allowing unpredictable systems to proliferate. Predictable A.I. is, for now, weaker A.I.\nI wouldn’t go as far as China is going with A.I. regulation. But we need to go a lot further than we have — and fast, \nbefore these systems get too many users and companies get addicted to profits and start beating back regulators. \nI’m glad to see that Chuck Schumer, the Senate majority leader, is launching an initiative on A.I. regulation. And I \nwon’t pretend to know exactly what he and his colleagues should do. But after talking to a lot of people working on \nthese problems and reading through a lot of policy papers imagining solutions, there are a few categories I’d \nprioritize.\nThe first is the question — and it is a question — of interpretability. As I said above, it’s not clear that interpretability \nis achievable. But without it, we will be turning more and more of our society over to algorithms we do not \nunderstand. If you told me you were building a next generation nuclear power plant, but there was no way to get \naccurate readings on whether the reactor core was going to blow up, I’d say you shouldn’t build it. Is A.I. like that \npower plant? I’m not sure. But that’s a question society should consider, not a question that should be decided by a \nfew hundred technologists. At the very least, I think it’s worth insisting that A.I. companies spend a good bit more \ntime and money discovering whether this problem is solvable.\nThe second is security. For all the talk of an A.I. race with China, the easiest way for China — or any country for \nthat matter, or even any hacker collective — to catch up on A.I. is to simply steal the work being done here. Any \nfirm building A.I. systems above a certain scale should be operating with hardened cybersecurity. It’s ridiculous to \nblock the export of advanced semiconductors to China but to simply hope that every 26-year-old engineer at \nOpenAI is following appropriate security measures.\nThe third is evaluations and audits. This is how models will be evaluated for everything from bias to the ability to \nscam people to the tendency to replicate themselves across the internet.\nRight now, the testing done to make sure large models are safe is voluntary, opaque and inconsistent. No best \npractices have been accepted across the industry, and not nearly enough work has been done to build testing \nregimes in which the public can have confidence. That needs to change — and fast. Airplanes rarely crash because \nthe Federal Aviation Administration is excellent at its job. The Food and Drug Administration is arguably too \nrigorous in its assessments of new drugs and devices, but it is very good at keeping unsafe products off the market. \nThe government needs to do more here than just write up some standards. It needs to make investments and build \ninstitutions to conduct the monitoring.\nThe fourth is liability. There’s going to be a temptation to treat A.I. systems the way we treat social media platforms \nand exempt the companies that build them from the harms caused by those who use them. I believe that would be \na mistake. The way to make A.I. systems safe is to give the companies that design the models a good reason to \nmake them safe. Making them bear at least some liability for what their models do would encourage a lot more \ncaution.\nThe fifth is, for lack of a better term, humanness. Do we want a world filled with A. I. systems that are designed to \nseem human in their interactions with human beings? Because make no mistake: That is a design decision, not an \nemergent property of machine-learning code. A.I. systems can be tuned to return dull and caveat-filled answers, or \nthey can be built to show off sparkling personalities and become enmeshed in the emotional lives of human beings.\nThe Surprising Thing A.I. Engineers Will Tell You if You Let Them Ezra Klein\nI think the latter class of programs has the potential to do a lot of good as well as a lot of harm, so the conditions \nunder which they operate should be thought through carefully. It might, for instance, make sense to place fairly tight \nlimits on the kinds of personalities that can be built for A.I. systems that interact with children. I’d also like to see \nvery tight limits on any ability to make money by using A.I. companions to manipulate consumer behavior.\nThis is not meant to be an exhaustive list. Others will have different priorities and different views. And the good \nnews is that new proposals are being released almost daily. The Future of Life Institute’s policy recommendations \nare strong, and I think the A.I. Objectives Institute’s focus on the human-run institutions that will design and own A.I. \nsystems is critical. But one thing regulators shouldn’t fear is imperfect rules that slow a young industry. For once, \nmuch of that industry is desperate for someone to help slow it down.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nPHOTO:  (PHOTOGRAPH BY Matt Edge for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: April 17, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "Views on Indian Startups",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 5, 2023",
        "section": "FRONT PAGE",
        "length": "358 words",
        "byline": "Our Bureau",
        "story_text": "Views on Indian Startups\nEconomic Times (E-Paper Edition)\nJune 5, 2023 Monday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 358 words\nByline: Our Bureau\nHighlight: Altman to discuss AI’s impact on nations like India, his views on regulation and more\nBody\nET TO HOST SAM ALTMAN ON JUNE 7\nMumbai: Sam Altman, OpenAI and ChatGPT have taken centre stage as the world discusses the impact of the \nartificial intelligence (AI) revolution on humanity. Given its explosive potential, the big question of how to regulate AI \nis one that countries are currently grappling with as ChatGPT mainstreams the technology, something Altman has \nclear views on.  To discuss this and more, The Economic Times will host Altman, CEO of OpenAI, the company \nbehind the buzzy AI chatbot ChatGPT, for a fireside chat on June 7 in New Delhi. \nAltman will be in conversation with Satyan Gajwani, vice chairman of Times Internet Ltd, engaging on various \nthemes, including how AI affects countries such as India in terms of jobs and talent evolution. Also, how best to \ncapitalise on the technology. The Stanford dropout, who was previously president of Silicon Valley's influential \nstartup incubator Y Combinator, will also discuss various use cases of AI globally, and how these can be \ncustomised for India. Regulating AI Altman, who's cited AI as potentially a “printing press mo- ment,” will also be \ndrawn to expand on his views regarding regulation.  India plans to establish “some principles” that will act as \n“guardrails” for the AI sector, according to Union minister Rajeev Chandrasekhar, who said this will help regulate \ngenerative AI platforms such as Microsoft's Open AI and Google's Bard as well as their use by other companies.  \nWhile testifying before members of a Senate subcommittee recently in Washington DC, Altman had said, “I think if \nthis technology goes wrong, it can go quite wrong. And we want to be vocal about that... We want to work with the \ngovernment to prevent that from happening.” The conversation will also cover Altman's Y Combinator days, his \nentrepreneurial journey when he founded Loopt, his views on Indian startups and the overall technology innovation \nthat the domestic market is capable of.  A select audience of CEOs and founders of India's top technology startups, \npolicymakers, and leading business leaders, will be in attendance as we delve into the technology that has taken \nthe world by storm.\nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "Nonfiction_Reviews_Feb2024",
        "header": "Human intelligence brought to AI",
        "media": "Nonfiction Reviews",
        "time": "February 18, 2024",
        "section": "ENTERTAINMENT; E; Pg. 5",
        "length": "714 words",
        "byline": "Jennifer Szalai The New York Times",
        "story_text": "Human intelligence brought to AI\nNonfiction Reviews\nThe Baltimore Sun\nFebruary 18, 2024 Sunday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: ENTERTAINMENT; E; Pg. 5\nLength: 714 words\nByline: Jennifer Szalai The New York Times\nHighlight: By Dennis Yi Tenen; W.W. Norton & Company, 176 pages, $22.\nBody\nIn \"Literary Theory for Robots,\" Dennis Yi Tenen's playful new book on artificial intelligence and how computers \nlearned to write, one of his most potent examples arrives in the form of a tiny mistake.\nTenen draws links among modern-day chatbots, pulp-fiction plot generators, old-fashioned dictionaries and \nmedieval prophecy wheels. Both the Utopians (the robots will save us!) and the doomsayers (the robots will destroy \nus!) have it wrong, he argues. There will always be an irreducibly human aspect to language and learning - a crucial \ncore of meaning that emerges not just from syntax but from experience. Without it, you just get the chatter of \nparrots, who, \"according to Descartes in his 'Mediations,' merely repeated without understanding,\" Tenen writes.\nBut Descartes didn't write \"Mediations;\" Tenen must have meant \"Meditations\" - the missing \"t\" will slip past any \nspell-checker program because both words are perfectly legitimate. (The book's index lists the title correctly.) This \nminuscule typo doesn't have any bearing on Tenen's argument; if anything, it bolsters the case he wants to make. \nMachines are becoming stronger and smarter, but we still decide what is meaningful. A human wrote this book. \nAnd, despite the robots in the title, it is meant for other humans to read.\nTenen, now a professor of English and comparative literature at Columbia, used to be a software engineer at \nMicrosoft. He puts his disparate skill sets to use in a book that is surprising, funny and resolutely unintimidating, \neven as he smuggles in big questions about art, intelligence, technology and the future of labor. I suspect that the \nbook's small size is part of the point. People are not indefatigable machines, relentlessly ingesting enormous \nvolumes on enormous subjects. Tenen has figured out how to present a web of complex ideas at human scale.\nTo that end, he tells stories, starting with 14th-century Arab scholar Ibn Khaldun, who chronicled the use of the \nprophecy wheel, and ending with a chapter on 20th-century Russian mathematician Andrey Markov, whose \nprobability analysis of letter sequences in Alexander Pushkin's \"Eugene Onegin\" constituted a fundamental building \nblock of generative AI. Tenen writes knowledgeably about the technological roadblocks that stymied earlier models \nof computer learning, before \"the brute force required to process most everything published in the English \nlanguage\" was so readily available. He urges us to be alert. He also urges us not to panic.\n\"Intelligence evolves on a spectrum, ranging from 'partial assistance' to 'full automation,' \" Tenen writes, offering the \nexample of an automatic transmission in a car. Driving an automatic in the 1960s must have been mind-blowing for \npeople used to manual transmissions. An automatic worked by automating key decisions, downshifting on hills and \nsending less power to the wheels in bad weather. It removed the option to stall or grind your gears. It was \nHuman intelligence brought to AI Nonfiction Reviews\n\"artificially intelligent,\" even if nobody used those words for it. American drivers now take its magic for granted. It \nhas been demystified.\nAs for the current debates over AI, this book tries to demystify those, too. Instead of talking about AI as if it has a \nmind of its own, Tenen talks about the collaborative work that went into building it.\nTenen also argues that we, as social beings, have agency, if only we allow ourselves to accept the responsibility \nthat comes with it. \"Individual AIs do pose real danger, given the ability to aggregate power in the pursuit of a goal,\" \nhe concedes. But the real danger comes \"from our inability to hold technology makers responsible for their actions.\" \nWhat if someone wanted to strap a jet engine to a car and see how it fared on the streets of a crowded city? Tenen \nsays the answer is obvious: \"Don't do that.\"\nWhy \"don't do that\" can seem easy in one realm but not another requires more thinking, more precision, more \nscrutiny - all qualities that fall by the wayside when we cower before AI, treating the technology like a singular god \ninstead of a multiplicity of machines built by a multiplicity of humans. Tenen leads by example, bringing his human \nintelligence to bear on artificial intelligence. By thinking through our collective habits of thought, he offers a \nmeditation all his own.\nLoad-Date: February 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Rethinking the Prospects of a ‘Soft Landing’; DealBook Newsletter",
        "media": "The New York Times",
        "time": "February 14, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1883 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Rethinking the Prospects of a ‘Soft Landing’; DealBook Newsletter\nThe New York Times \nFebruary 14, 2024 Wednesday 08:23 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1883 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.&amp;#160;&amp;#160;\nHighlight: Worries of higher-for-longer interest rates have grown since Tuesday’s Consumer Price Index report.\nBody\nWorries of higher-for-longer interest rates have grown since Tuesday’s Consumer Price Index report.\n“No landing” \nMarkets are still on edge after Tuesday’s hot inflation report, as Wall Street suddenly and sharply discounted the \nodds of imminent interest rate cuts.\nIt has also poured cold water on the belief among many investors that the U.S. economy will achieve a “soft \nlanding.”\nWhy so gloomy? The Consumer Price Index report, which came in above economists’ forecasts, is a stark reminder \nof the challenges that the Fed faces in bringing down inflation to its 2 percent target. Even after excluding volatile \nenergy and food prices, inflation is holding roughly steady and is well above where the central bank feels \ncomfortable.\nShelter costs, including rents, also rose above expectations, and “supercore inflation,” a measure the Fed closely \nfollows that includes common “services” expenditures — like haircuts and lawyer fees — rose 4.3 year-on-year, its \nhighest level since May, according to Deutsche Bank data.\nMarkets responded with a jolt. Investors dumped Treasury notes on Tuesday amid concerns that the Fed will keep \nborrowing costs higher for longer. That pushed the Russell 2000 down nearly 4 percent, its worst slide in 20 \nmonths. (That said, S&amp;P 500 futures were rebounding slightly on Wednesday morning as dip-buyers returned, \nand Britain reported milder-than-expected inflation data that pushed up stocks in London.)\nRethinking the Prospects of a ‘Soft Landing’ DealBook Newsletter\nThe futures market on Wednesday is pricing in three to four interest rate cuts this year, down from the six to seven \nprojected at the start of the year and all but silencing rate-cut bulls. Such predictions “made no sense in our view,” \nMohit Kumar, an economist at Jefferies, wrote in a research note.\nWorry extends beyond the markets. The prospect of higher inflation is weighing on consumers and small-business \nowners.\nMeanwhile, Krispy Kreme, Coca-Cola and Heineken each warned this week that stubborn inflation could hurt their \nearnings.\nConcerns are growing about a dreaded economic scenario. In the case of a soft landing, inflation would drift down \nto the Fed’s target while wages and the economy grow. (Treasury Secretary Janet Yellen has been in this camp.) \nAnd there’s the “no landing” scenario, a growing concern on Wall Street that would see growth but above-normal \ninflation.\nSome economic watchers are now warning of a bumpier time ahead. “While the soft landing outcome is still in the \nascendancy, I would say a no landing scenario is underpriced,” Jim Reid, a strategist at Deutsche Bank, wrote to \ninvestors on Wednesday.\nHERE’S WHAT’S HAPPENING \nDemocrats retake George Santos’s New York House seat. Tom Suozzi, a former congressman, beat a Republican \nopponent by bigger-than-expected margins in an early test of 2024 elections. His victory further trims the party’s \nmajority in the House, which has struggled to agree on much except impeaching Alejandro Mayorkas, the homeland \nsecurity secretary.\nKyiv again claims that Russia is using Starlink systems. Intelligence officials cited an audio recording that they say \nshows Russian forces trying to procure equipment for Elon Musk’s satellite internet service from Arab countries to \nuse in Ukraine, according to The Wall Street Journal. Musk has denied that Russia is purchasing Starlink systems. \nMeanwhile, Mitch McConnell, the Senate minority leader, urged House Republicans to allow a vote on a $95 billion \naid bill for Ukraine and Israel.\nHackers for foreign governments are using OpenAI for their attacks. Research published on Wednesday by the \ncompany and Microsoft found that assailants working for China, Iran, North Korea and Russia were using its \nartificial intelligence tools in their work. The twist: Generative A.I. wasn’t being used to create exotic new hacks — \nbut to carry out mundane tasks like drafting emails and debugging computer code.\nSpaceX postpones the launch of a moon lander mission. A technical issue was blamed for the delay and another \nattempt is scheduled for Thursday. If all goes well, it would set up the first American spacecraft to land softly on the \nmoon’s surface since 1972. The spacecraft was built by Intuitive Machines, which went public last year via a merger \nwith a blank-check company.\nA fight against OpenAI gets its sails trimmed\nOf all the legal battles that OpenAI faces, among the most prominent is a copyright infringement lawsuit filed by \nbest-selling authors including Sarah Silverman and Ta-Nehisi Coates. (The New York Times has separately sued \nOpenAI and Microsoft.)\nBut a federal judge has thrown out several claims from the Silverman-led lawsuit, in the latest instance of setbacks \nfor legal challenges to generative artificial intelligence developers.\nOnly the authors’ central accusation against OpenAI remains. The group has claimed that the company “copied and \ningested” their copyrighted work without permission or compensation. (One way that’s done is through so-called \nshadow libraries that house millions of texts online.) The end result, the authors argue: Every answer that ChatGPT \ncreates is copyright infringement, because it was born from stolen work.\nRethinking the Prospects of a ‘Soft Landing’ DealBook Newsletter\nWhile the plaintiffs are allowed to maintain their argument of direct copyright violation, the judge overseeing the \ncase dismissed other counts, finding that the plaintiffs hadn’t found specific examples of A.I.-generated output that’s \n“substantially similar — or similar at all — to their books.” (The authors can amend their lawsuit to address that \nconcern.)\nThe ruling mirrors what happened in the authors’ similar lawsuit against Meta, which they claim trained its LLaMA \nsystem on their work. But the judge in the Meta case cast some doubt: “When I make a query of LLaMA, I’m not \nasking for a copy of Sarah Silverman’s book — I’m not even asking for an excerpt,” he wrote.\nThe economics of the generative A.I. industry are at stake in these cases. Rulings in favor of copyright owners \ncould mean that companies like OpenAI would have to pay up to train their data-hungry systems. These tech \ncompanies argue that their programs are covered by fair use, and that their products’ output is sufficiently different \nfrom the original work — in short, that they aren’t violating copyright.\nThe outlook for such copyright battles remains unclear. While The Times’s lawsuit against OpenAI and Microsoft is \nstill live, and recent rulings have been adverse to the authors group, a judge in a lawsuit involving A.I.-generated art \ngenerators said it was in the public interest.\n• In other A.I. news: OpenAI gave ChatGPT a better “memory” for user queries to improve future answers. And \nAndrej Karpathy, an A.I. researcher who co-founded OpenAI, has left the company.\n“This is actually a correction for the press release.”\n— Erin Brewer, the C.F.O. of Lyft. Shares in the ride-hailing company went on a rocky ride after the ride-hailing \ncompany said that it had misstated its margins growth outlook in Tuesday’s earnings release. (Instead of margins \nrising 500 basis points, or 5 percent, this year, the company meant to say that they would increase 50 basis points, \nor 0.5 percent.)\nZuckerberg takes on the Vision Pro \nApple’s $3,500 Vision Pro headset, which was released two weeks ago, has raised the stakes in the virtual reality \ngoggles market. And on Tuesday, a top tech executive delivered a detailed, no-holds-barred review that has \ngenerated plenty of buzz on social media.\nThat reviewer? Mark Zuckerberg, whose Meta is one of Apple’s biggest rivals in the V.R. space. In an Instagram \nvideo, he outlined his likes and dislikes, but perhaps unsurprisingly came out strongly in favor of his company’s own \nQuest headset.\nHere’s his take:\n“I have to say that before this, I expected that Quest would be the better value for most people since it’s really good \nand like seven times less expensive, but after using it” [Vision Pro] “I don’t just think that Quest is the better value, \nit’s the better product period.\n“They have different strengths, but overall Quest is better for the vast majority of things that people use mixed \nreality for.”\nZuckerberg gives the Vision Pro strong marks for its high-resolution screen, and the eye-tracking technology it \npacks. (Such a feature would be part of future Quest headsets, he said.)\nBut he criticized it for comfort, what he described as “motion blur” for the wearer, and a relatively small library of \napplications. He also dinged Apple for making the Vision Pro, like all of its devices, a closed system for developers.\nAnd in a final bit of showing off, Zuckerberg shot his Instagram video via … a Quest 3 headset.\nSnow-nomics \nRethinking the Prospects of a ‘Soft Landing’ DealBook Newsletter\nScattered power outages and canceled flights. Students across much of the Northeast home from school. And yet \njust 3.2 inches of snow in Central Park, and barely anything in Boston.\nA fast-moving nor’easter that gave New York City its highest snowfall in over two years didn’t quite live up to \npredictions. But it did create severe disruptions, a reminder that even milder winters can still pack a punch.\nIt tested hybrid-learning infrastructure. Teachers, parents and students in New York reported difficulties logging on \nfor remote classes. That prompted David Banks, the city’s public schools chancellor, to call out its I.T. partner, IBM, \nsaying it was “not ready for prime time.” The company later said “the issues have been largely resolved.”\nValentine’s Day plans may get scrambled. More than 1,000 flights were canceled, disrupting schedules and \npossibly dashing couples’ dinner plans tonight.\nIt would have been worse for restaurant owners if the snow had fallen on a Friday or Saturday, said Evan Gold, an \nexecutive vice president of partnerships at Planalytics, which predicts how weather events can affect consumer \ndemand.\nA small silver lining: Some businesses may have been able to offload end-of-season inventory, such as salt to de-\nice outdoor surfaces, or gloves. “The retail calendar is now in spring, so retailers are looking to get rid of that winter \nproduct,” Gold said.\nTHE SPEED READ \nDeals\n• Walmart is reportedly in talks to buy Vizio, the popular TV maker, for more than $2 billion in part to bolster its \nadvertising business. (WSJ)\n• Donald Mackenzie, a co-founder of the private equity firm CVC who led the investment giant’s takeover of \nFormula 1 in 2006, is stepping back. (FT)\nPolicy\n• “This Arctic Circle Town Expected a Green Energy Boom. Then Came Bidenomics.” (NYT)\n• A crypto-focused super PAC is seeking to oppose the Senate bid of Representative Katie Porter, a California \nDemocrat who has called for tighter regulation of the industry. (NYT)\n• Jared Kushner, a son-in-law of Donald Trump who served in his White House, said he wouldn’t return to \nWashington for a potential second Trump term. (Axios)\nBest of the rest\n• “Can America Turn a Productivity Boomlet Into a Boom?” (NYT)\n• Jimmy Finkelstein, the founder of the doomed news start-up The Messenger, suggested that he may reverse \ncourse and pay laid-off employees severance. (Axios)\n• Those flowers you ordered for Valentine’s Day probably arrived in the U.S. via Miami International Airport. \n(NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: A hotter-than-expected inflation report has stoked new concerns that a “soft landing” may be out of reach. \n(PHOTOGRAPH BY Michael M. Santiago/Getty Images FOR THE NEW YORK TIMES)\nLoad-Date: February 14, 2024\nRethinking the Prospects of a ‘Soft Landing’ DealBook Newsletter"
    },
    {
        "file_name": "Podcast_Jan2024",
        "header": "Sam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates",
        "media": "Podcast",
        "time": "January 14, 2024",
        "section": "",
        "length": "488 words",
        "byline": "Sissi Cao",
        "story_text": "Sam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates \nPodcast\nNew York Observer\nJanuary 12, 2024 Friday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 488 words\nByline: Sissi Cao\nBody\nThe mobile app of OpenAI's ChatGPT has been downloaded more than 110 million times globally since its launch \nin November 2022. The artificial intelligence chatbot has become a daily essential to millions of users. But it's \nactually not the most reached-for app on OpenAI CEO Sam Altman's phone, he said in an interview with Bill Gates \naired yesterday (Jan. 11).\nIn the latest episode of Gates's weekly podcast Unconfuse Me, the Microsoft (MSFT) cofounder asked Altman \nwhich mobile app he uses the most, and the answer was surprising. \"Slack,\" Altman said, \"I wish I could say \nChatGPT...and way more than email. The only thing that I was thinking possibly was iMessages, but yes, [I use \nSlack] more than that...I'm on Slack all day.\"\nGates shared that his most used app is Microsoft Outlook. \"I'm this old-style email guy. Either that or the browser,\" \nhe said.\nAltman said he uses Slack mainly to coordinate work with his colleagues at OpenAI, which now has about 500 \nemployees. Gates was surprised at how small the organization is given the impact its products have made in the \ntech industry. \"That's tiny, by Google, Microsoft, Apple standards,\" Gates said. Since ChatGPT exploded in \npopularity, almost every Big Tech company has begun developing rival A.I. chatbots and other generative A.I. \napplications.\nOpenAI was founded about eight years ago by Altman and Elon Musk first as a nonprofit research lab. Over time it \nhas evolved to have a for-profit branch. \"We have to not only run the research lab, but now we have to run a real \nbusiness,\" Altman said. OpenAI's annualized revenue topped $1.6 billion in 2023, The Information reported in \nDecember.\nAltman added that OpenAI is also \"an older company than average\" where a lot of employees are in their 30s, 40s \nand 50s. \"It's not a bunch of 24-year-old programmers,\" he said.\n\"So it's not the early Microsoft and Apple, which we were really kids,\" Gates chimed in.\n\"I've reflected on that. I think companies have gotten older in general, and I don't know quite what to make of that,\" \nAltman added. \"I think it's somehow a bad sign for society. But I tracked this at YC [Y Combinator]. The best \nfounders have trended older over time.\"\nBefore serving as OpenAI's CEO in 2019, Altman was the president of startup incubator Y Combinator for five \nyears, funding and advising startup founders on how to grow their companies. Altman said that experience was \n\"super helpful\" but noted that OpenAI is distinctly different than most of the startups he'd incubated at YC.\nSam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates Podcast\n\"OpenAI did a lot of things that are very against the standard YC advice,\" he said. For example, Altman and his \ncofounders started OpenAI without a specific product idea and it ended up taking 4.5 years to launch the company's \nfirst product. \"I still don't recommend that for most companies,\" he added. \"But having learned the rules and see \nthem at YC made me feel like I understood when and how and why we could break them.\"\nLoad-Date: January 14, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Oct2022",
        "header": "A.I.-Generated Art Is Already Transforming Creative Work; The Shift",
        "media": "The New York Times - International Edition",
        "time": "October 28, 2022",
        "section": "TECHNOLOGY",
        "length": "1360 words",
        "byline": "Kevin Roose",
        "story_text": "A.I.-Generated Art Is Already Transforming Creative Work; The Shift\nThe New York Times - International Edition\nOctober 29, 2022 Saturday\nCopyright 2022 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1360 words\nByline: Kevin Roose\nBody\nOnly a few months old, apps like DALL-E 2, Midjourney and Stable Diffusion are changing how filmmakers, interior \ndesigners and other creative professionals do their jobs.       \nFor years, the conventional wisdom among Silicon Valley futurists was that artificial intelligence and automation \nspelled doom for blue-collar workers whose jobs involved repetitive manual labor. Truck drivers, retail cashiers and \nwarehouse workers would all lose their jobs to robots, they said, while workers in creative fields like art, \nentertainment and media would be safe.       \nWell, an unexpected thing happened recently: A.I. entered the creative class.       \nIn the past few months, A.I.-based image generators like DALL-E 2, Midjourney and Stable Diffusion have made it \npossible for anyone to create unique, hyper-realistic images just by typing a few words into a text box.       \nThese apps, though new, are already astoundingly popular. DALL-E 2, for example, has more than 1.5 million users \ngenerating more than two million images every day, while Midjourney's official Discord server has more than three \nmillion members.       \nThese programs use what's known as \"generative A.I.,\" a type of A.I. that was popularized several years ago with \nthe release of text-generating tools like GPT-3 but has since expanded into images, audio and video.       \nIt's still too early to tell whether this new wave of apps will end up costing artists and illustrators their jobs. What \nseems clear, though, is that these tools are already being put to use in creative industries.       \nRecently, I spoke to five creative-class professionals about how they're using A.I.-generated art in their jobs.       \n'It spit back a perfect image.'\nCollin Waldoch, 29, a Brooklyn game designer, recently started using generative A.I. to create custom art for his \nonline game, Twofer Goofer, which works a bit like a rhyming version of Wordle. Every day, players are given a clue \n- like \"a set of rhythmic moves while in a half-conscious state\" - and are tasked with coming up with a pair of \nrhyming words that matches the clue. (In this case, \"trance dance.\")       \nInitially, Mr. Waldoch planned to hire human artists through the gig-work platform Upwork to illustrate each day's \nrhyming word pair. But when he saw the cost - between $50 and $60 per image, plus time for rounds of feedback \nand edits - he decided to try using A.I. instead. He plugged word pairs into Midjourney and DreamStudio, an app \nbased on Stable Diffusion, and tweaked the results until they looked right. Total cost: a few minutes of work, plus a \nfew cents. (DreamStudio charges about a cent per image; Midjourney's standard membership costs $30 per month \nfor unlimited images.)       \nA.I.-Generated Art Is Already Transforming Creative Work The Shift\n\"I typed in 'carrot parrot,' and it spit back a perfect image of a parrot made of carrots,\" he said. \"That was the \nimmediate 'aha' moment.\"       \nMr. Waldoch said he didn't feel guilty about using A.I. instead of hiring human artists, because human artists were \ntoo expensive to make the game worthwhile.       \n\"We wouldn't have done this\" if not for A.I., he said.       \n'I don't feel like it will take my job away.'\nIsabella Orsi, 24, an interior designer in San Francisco, recently used a generative A.I. app called InteriorAI to \ncreate a mock-up for a client.       \nThe client, a tech start-up, was looking to spruce up its office. Ms. Orsi uploaded photos of the client's office to \nInteriorAI, then applied a \"cyberpunk\" filter. The app produced new renderings in seconds - showing what the \noffice's entryway would look like with colored lights, contoured furniture and a new set of shelves.       \nMs. Orsi thinks that rather than replacing interior designers entirely, generative A.I. will help them come up with \nideas during the initial phase of a project.       \n\"I think there's an element of good design that requires the empathetic touch of a human,\" she said. \"So I don't feel \nlike it will take my job away. Somebody has to discern between the different renderings, and at the end of the day, I \nthink that needs a designer.\"       \n'It's like working with a really willful concept artist.'\nPatrick Clair, 40, a filmmaker in Sydney, Australia, started using A.I.-generated art this year to help him prepare for \na presentation to a film studio.       \nMr. Clair, who has worked on hit shows including \"Westworld,\" was looking for an image of a certain type of marble \nstatue. But when he went looking on Getty Images - his usual source for concept art - he came up empty. Instead, \nhe turned to DALL-E 2.       \n\"I put 'marble statue' into DALL-E, and it was closer than what I could get on Getty in five minutes,\" Mr. Clair said.       \nSince then, he has used DALL-E 2 to help him generate imagery, such as the above image of a Melbourne tram in \na dust storm, that isn't readily available from online sources.       \nHe predicted that rather than replacing concept artists or putting Hollywood special effects wizards out of a job, A.I. \nimage generators would simply become part of every filmmaker's tool kit.       \n\"It's like working with a really willful concept artist,\" he said.       \n\"Photoshop can do things that you can't do with your hands, in the same way a calculator can crunch numbers in a \nway that you can't in your brain, but Photoshop never surprises you,\" he continued. \"Whereas DALL-E surprises \nyou, and comes back with things that are genuinely creative.\"       \n'What if we could show what the dogs playing poker looked like?'\nDuring a recent creative brainstorm, Jason Carmel, 49, an executive at the New York advertising agency \nWunderman Thompson, found himself wondering if A.I. could help.       \n\"We had three and a half good ideas,\" he said of his team. \"And the fourth one was just missing a visual way of \ndescribing it.\"       \nThe image they wanted - a group of dogs playing poker, for an ad being pitched to a pet medicine company - would \nhave taken an artist all day to sketch. Instead, they asked DALL-E 2 to generate it.       \nA.I.-Generated Art Is Already Transforming Creative Work The Shift\n\"We were like, what if we could show what the dogs playing poker looked like?\" Mr. Carmel said.       \nThe resulting image didn't end up going into an ad, but Mr. Carmel predicts that generative A.I. will become part of \nevery ad agency's creative process. He doesn't, however, think that using A.I. will meaningfully speed up the \nagencies' work, or replace their art departments. He said many of the images generated by A.I. weren't good \nenough to be shown to clients and that users who weren't experienced users of these apps would probably waste a \nlot of time trying to formulate the right prompts.       \n\"When I see people write about how it's going to destroy creativity, they talk about it as if it's an efficiency play,\" Mr. \nCarmel said. \"And then I know that they maybe haven't played around with it that much themselves, because it's a \ntime suck.\"\n'This is a sketch tool.'\nSarah Drummond, a service designer in London, started using A.I.-generated images a few months ago to replace \nthe black-and-white sketches she did for her job. These were usually basic drawings that visually represented \nprocesses she was trying to design improvements for, like a group of customers lining up at a store's cash register.       \nInstead of spending hours creating what she called \"blob drawings\" by hand, Ms. Drummond, 36, now types what \nshe wants into DALL-E 2 or Midjourney.       \n\"All of a sudden, I can take like 15 seconds and go, 'Woman at till, standing at kiosk, black-and-white illustration,' \nand get something back that's really professional looking,\" she said.       \nMs. Drummond acknowledged that A.I. image generators had limitations. They aren't good at more complex \nsketches, for example, or creating multiple images with the same character. And like the other creative \nprofessionals, she said she didn't think A.I. designers would replace human illustrators outright.       \n\"Would I use it for final output? No. I would hire someone to fully make what we wanted to realize,\" she said. \"But \nthe throwaway work that you do when you're any kind of designer,whether it's visual, architectural, urban planner - \nyou're sketching, sketching, sketching. And so this is a sketch tool.\" \nLoad-Date: October 28, 2022"
    },
    {
        "file_name": "Ng_Feb2024",
        "header": "BigTech lobbying to derail open source GenAI: DeepLearning AI's Andrew",
        "media": "Ng",
        "time": "February 22, 2024",
        "section": "TECH & INTERNET",
        "length": "621 words",
        "byline": "Romita Majumdar and Himanshi Lohchab",
        "story_text": "BigTech lobbying to derail open source GenAI: DeepLearning AI's Andrew \nNg\nThe Economic Times\nFebruary 22, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 621 words\nByline: Romita Majumdar and Himanshi Lohchab\nBody\nEfforts by a large section of US technology majors to subject open-source generative AI to curbs and regulations \ncould stifle innovation across the world and likely prove counterproductive even for Washington, which has hitherto \nled the global race in scaling and harnessing Gen AI, said a top innovation executive.“If the attempts to squash \nopen-source software succeed, almost all nations will simply be losers…the United States as well,” Andrew Ng, \nfounder of DeepLearning AI, told delegates Wednesday at the Nasscom Technology and Leadership Summit in \nMumbai.He was referring to the contrasting stands of big tech firms on the subject. Facebook’s parent Meta and \nIBM, on one side, advocate an “open science” approach to AI development, pitting them against Google, Microsoft \nand ChatGPT-maker OpenAI – companies that are backing closed software.Andrew Ng said the tech giants are \n“arguing incorrectly” that the US government must discourage open-source given that the nation is ahead in the \nGenAI race.Burgeoning Digital Economy Meanwhile, a study released by Nasscom and Arthur D Little Wednesday \nsaid that digital public infrastructures (DPIs) are poised to propel India toward a $1-trillion digital economy by 2030, \nas gross domestic product more than doubles to $8 trillion by then.The report titled, “Digital Public Infrastructure of \nIndia - Accelerating India’s Digital Inclusion,” said that by 2030, DPIs will significantly enhance citizens' efficiency \nand promote social as well as financial inclusion.Mature DPIs such as Aadhaar, Unified Payments Interface (UPI), \nand FASTag have witnessed exponential adoption so far and the next seven to eight years offer an opportunity for \nfurther scalability, reaching even the most remote segments of the population.Shanker Trivedi, senior vice \npresident, enterprise business, NVIDIA, said he is bullish about the startup ecosystem in India.“Some of them will \nbecome the Flipkart(s) and the Ola(s) and the Swiggy(s) and the Zomato(s),” he said during a fireside chat at the \nNasscom event.“Close to 800 of the global 1000 companies have their major or primary R&D centers in India. \nAll of their IP, their engineering and innovation is coming out from India,” he added.Clarity and stability of \ngovernment’s regulatory policies around technology solutions will play a huge role in creating the right ecosystem to \nattract companies over the long term, other technology industry leaders said.Manish Bhatia, EVP Global operations, \nMicron said that policy stability is a huge driving factor for attracting companies to India and in creating an export \nmarket ecosystem. “Certainty of policy is one of the advantages that India has over many of the other developing \ncountries that are vying for some of these big manufacturing investments. This helps in creating an export capable \nmarket not just our manufacturers, but others in the value chain suppliers. of specialty materials, specialty chemical \nservices, engineering, support, and design services,etc,” said Bhatia.He added that this predictability of policy is \nnecessary for over the next 25 years as semiconductors are a capital-intensive industry that only shows returns \nover 15-20 years. “So you are going to see (development of) large clusters in relatively few areas of the country for \nsuch industries. That's what's been able to take place in Taiwan, (South) Korea, and Japan,” he said, adding that \nwhile the semiconductor industry reached $500 billion in 60 years, the next $500 billion market can be achieved in \nthe next five years.He added that the policy alignment between all the stakeholders should extend across central \ngovernment, state governments, and educational institutions. For Reprint Rights: timescontent.com\nBigTech lobbying to derail open source GenAI: DeepLearning AI's Andrew Ng\nLoad-Date: February 22, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "INDIA’S RICH TECH TALENT POOLS A BIG WIN-WIN",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 23, 2023",
        "section": "FEATURE",
        "length": "598 words",
        "byline": "Pallavi Chakravorty",
        "story_text": "INDIA’S RICH TECH TALENT POOLS A BIG WIN-WIN\nEconomic Times (E-Paper Edition)\nNovember 24, 2023 Friday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FEATURE\nLength: 598 words\nByline: Pallavi Chakravorty\nHighlight: Strong ideas, wide variety of sectors, and a supportive ecosystem are the biggest drivers for the \ncountry’s thriving startups\nBody\nOver the past two decades, the word startup has become synonymous with India, which today with over 90,000 \nstartups and 107 unicorn companies. It is ranked third among the largest startup ecosystems in the world just after \nthe US and China.  While there has been a drop in funding this year with none of the companies achieving unicorn \nstatus – in 2022, India produced 24 unicorns, the momentum in tier II and tier III cities is fuelling the growth in the \nsector.  One of the key factors behind India’s startup revolution is its young demography – more than 50 percent of \nits population is below the age of 25 and more than 65 percent below the age of 35.  That the country is rich in tech \ntalent only fuels the market further. \nAccording to a report by consulting fi rm EY and skill assessment platform iMocha, India is one of the top tech talent \nmarkets at par with Europe and the US. Also, apart from strong government support, India’s startup ecosystem is \nalso backed by a growing network of incubators, accelerators, and co-working spaces. In fact, India is also home to \none of the 25 Draper Startup Houses in the world. It was obvious that the team of Meet the Drapers, Season 6 had \nto make a stopover to the subcontinent and identify bright entrepreneurs. The contenders Orthoheal, Unstop, \nNeuropixel.ai, and Karya Foundation, while being completely different from each other had a unique solution to \npresent. The judges -Tim Draper, Founder, Draper Associates; Nupur Hemant, Venture Capitalist in Consumer \nTech, B2B and SaaS; Nikhil Kamath, Content Strategist Building Brands; and Madan Padaki, CEO & MD, Head \nHeld  High -not only were overwhelmed hearing the pitches, but they also had a tough time picking just one winner.  \nOrthoheal’s FlexiOH -an orthopaedic immobilizer that has the rigidity to hold the fractured part as well as ensure \nproper skin ventilation – did impress the judges but they were concerned about similar technologies existing in the \nmarket and the long-term potential of the company.  With the promise of getting students their dream job, Unstop -a \ncommunity engagement and hiring platform for students and freshers – connects students to a world of \nopportunities across the globe. It helps companies interact with students and early professionals at Unstop and \nleverage the  platform’s expertise to build their teams. Judges were not sure about the growth of the market, which \nlooked like flattening out.  The third company in the run for the million-dollar prize money, Karya, works with rural \ncommunities in India -traditionally kept out of the digital work economy – by giving them small digital tasks. It \ncollects the requirements from its clients, identifi es the bestsuited workers, collects the data, validates the data, \nand then synthesises them into highquality AI/ML training datasets. Judges were concerned about Karya’s big \ncompany clients engaging with them only for public relations.  The winner, NeuroPixel.AI, is a generative AI startup \nfocused on the fashion industry. It deploys proprietary Deep Neural Net (DNN) algorithms that generate \nphotorealistic synthetic models and automates the manual and repetitive process of cataloguing apparel. \nCustomers can shoot apparel on a mannequin and upload it on the real-time SaaS platform. One can then select \nthe clothes, customise models, and change their facial expression, hairstyle, or skin colour. The company claims to \nINDIA ’S RICH TECH TALENT POOLS A BIG WIN-WIN\nreduce costs for its clients by 30-40 percent. Judges were impressed by the app’s use case, big market and it is \nhelping reduce inefficiencies in the cataloguing business.\nLoad-Date: November 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "In Strikes Across Industries, Workers Fear New Technologies Will Cost Jobs",
        "media": "The New York Times",
        "time": "September 18, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 3; DEALBOOK NEWSLETTER",
        "length": "1778 words",
        "byline": "By Sarah Kessler, Ephrat Livni and Michael J. de la Merced",
        "story_text": "In Strikes Across Industries, Workers Fear New Technologies Will Cost Jobs\nThe New York Times\nSeptember 18, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 3; DEALBOOK NEWSLETTER\nLength: 1778 words\nByline: By Sarah Kessler, Ephrat Livni and Michael J. de la Merced\nBody\nWhat's being called the ''summer of strikes'' comes at a time when workers increasingly fear new technologies will \nthreaten their jobs.\nThe United Automobile Workers strike is in its second day, and already it's being framed as potentially the most \ncostly of work stoppages from the ''summer of strikes.'' \n  Unions aren't just fighting for an inflation-beating wage boost. They also are campaigning for job security at a time \nwhen workers increasingly fear that shifts to new technologies, like electric vehicles and artificial intelligence, \nthreaten their job, and tech bosses themselves say this gloomy outlook is inevitable.\n  Union leaders had a seat at the table this week in Washington at an A.I. forum organized by Senator Chuck \nSchumer, the majority leader, and attended by tech leaders, such as Elon Musk, Satya Nadella of Microsoft and \nJensen Huang of Nvidia. Their presence signals their growing clout in discussions about the future of the \ntechnology.\n  Concern over disruptive technologies are seen on the picket lines. The Writers Guild of America and SAG-AFTRA, \nthe actors' union, fear studios are embracing A.I. tools to generate scripts or copy the performances of actors. ''If we \ndon't stand tall right now, we are all going to be in trouble,'' Fran Drescher, president of SAG-AFTRA, warned in \nJuly. ''We are all going to be in jeopardy of being replaced by machines.''\n  The U.A.W., meanwhile, is concerned that the industry's shift to electric vehicles will require fewer workers, and \nthat many of the jobs needed will be in battery factories, most of which are not unionized.\n  Giving workers a voice in the use of technology has taken on new urgency, said Thomas Kochan, an emeritus \nprofessor at the M.I.T. Sloan School of Management, who has been studying the future of work since the 1980s: \n''Generative A.I. in particular has just exploded on the scene in a way that's going to make this one of the most \ncontroversial and one of the most important workplace issues of our time.''\n  The clock is ticking. It's strategic for unions to get involved early. Otherwise, companies can say, ''We're already \nusing the technology; we're not really interested in your ideas about how we could be better using it,'' said Adam \nSeth Litwin, an associate professor of industrial and labor relations at Cornell University.\n  Companies aren't legally obligated to negotiate with unions over early-stage decisions on how new technologies \nare used. Unions ''only have a right to negotiate over the impacts of technology on wages, hours and working \nconditions,'' Kochan said. The thornier issue of what and how technology is deployed, he said, is ''the frontier of \ncollective bargaining today.''\nIn Strikes Across Industries, Workers Fear New Technologies Will Cost Jobs\n  One breakthrough for labor came in 2018, when Marriott Hotel workers went on strike at 49 locations. After a six-\nweek stoppage, the company agreed to give the union notice before introducing technologies that would affect \nworkers' jobs and the right to discuss the changes with management.\n  Why would companies benefit from worker input? ''If technologies are not developed with the user in mind, they \noften fail,'' said Lisa Kresge, a research and policy associate at the University of California Berkeley Labor Center, \nwho has written about union responses to technology. Take those Marriott workers: At the time, they said a new \nhousekeeping app sent them inefficiently bouncing between floors when they could have worked faster by cleaning \nrooms clustered together.\n  ''If the only option that the labor movement places on the table is 'No, we don't want the technology that will hurt \nour workers,' that will not be enough,'' said Daron Acemoglu, an economist at M.I.T. and a co-author of ''Power and \nProgress: Our 1,000-Year Struggle Over Technology & Prosperity.'' The key, he said, is for labor to articulate how \nthe technologies can be used ''to the great benefit of the workers as well as the businesses.'' That's ''what's missing \nright now'' in the labor negotiations, Acemoglu added.\n  Federal proposals to regulate A.I. -- in relation to work or otherwise -- are barely underway. That leaves the \nunions, which represent only about 6 percent of the private sector work force, fighting a lonely battle. ''If your \ncompany is automating and you want a voice in that process, and you are not unionized,'' Acemoglu said, ''then \nthere is not much you can do.'' -- Sarah Kessler\n  IN CASE YOU MISSED IT \n  Arm flex gives markets a boost. The initial public offering of the chip design company Arm this week on the \nNasdaq stock exchange was the biggest market debut in nearly two years. It raised almost $5 billion, valuing the \ncompany at nearly $68 billion, and bolstered the hopes of other companies planning to go public.\n  A lawmaker trip to Wall Street exposes U.S.-China dilemma. The House committee on competition with China \nvisited New York City this week for meetings with financial executives. The discussions included a war-game-like \nexercise to assess the potential economic implications if China invaded Taiwan. But many executives did not want \ntheir names made public for fear of putting their China business at risk. \n  Google has its day in court. The biggest antitrust battle in decades began in Washington, with the Justice \nDepartment accusing Google of abusing its power as a monopoly over online search engines. The company argues \nthat users have lots of alternatives. \n  ''Elon Musk'' is out. After weeks of headline-generating excerpts, Walter Isaacson's biography of the Tesla-\nSpaceX-Starlink C.E.O. and X owner hit stores. The book grapples with Musk's multiple identities: a man driven by \nan abusive childhood; a world-changing entrepreneur; and a sleep-deprived, impulsive mogul who doesn't fully \nunderstand the extraordinary power he wields.\n  Natural assets\n  After a summer filled with catastrophic floods, blistering heat domes and devastating wildfires, government and \nbusiness leaders from around the world are set to discuss efforts to mitigate climate change at the United Nations \nClimate Ambition Summit in New York on Wednesday.\n  The usual topics are on the agenda, including net-zero targets, energy transition plans and renewable energy \ntargets.\n  But these solutions may be missing something fundamental, according to Partha Dasgupta, an economist at the \nUniversity of Cambridge. In a 2021 report commissioned by the British government, Dasgupta made the case for \nshifting how natural resources are valued, and the idea has since gained momentum: Last month, the White House \nreleased a draft proposal on what should be considered in a cost-benefit analysis when it comes to ecosystem \nservices in government, practices that draw on his work.\nIn Strikes Across Industries, Workers Fear New Technologies Will Cost Jobs\n  DealBook spoke with Dasgupta about updating economics to account for nature.\n  Traditional economics does not account for the value Earth provides, Dasgupta said, but instead assumes that \necosystems are self-regenerating and able to offer services indefinitely and that there will be an infinite supply of \nmaterials. His report included what he calls an ''important new set of calculations'' for treating natural resources like \nthe ocean and functions, like pollination, as assets, which, theoretically, increase the chances that we invest in and \nmanage our ecosystems to allow for the production of more goods. ''Asset management is a very well understood \nphenomenon,'' Dasgupta said. ''But for a variety of reasons, Mother Nature's assets don't carry the signals we need \nto manage them adequately.''\n  How this idea is applied will vary from place to place, Dasgupta said, but now there is a vocabulary and method for \naddressing the underlying issues. The Biden proposal, for example, cites ''failing to fully account for nature's \nbounty'' as having led to an ''erosion of our nation's natural assets.'' Dasgupta called the proposal ''a fine piece of \nwork,'' but he said that he wasn't confident it would be put into effect, or that his ideas more broadly would be \nunderstood fast enough to prevent disaster. ''We're in a firefighting situation,'' he said. ''Extreme weather events are \nhappening even as we speak.''\n  Dasgupta worries that an important nuance within his work gets lost, even as it becomes more well known. The \nservices of nature are interconnected, and ''they can be brought down like a house of cards,'' he said. ''You remove \none card from the house and the whole house collapses.'' So climate change solutions that focus on goods and \ntech, like replacing oil with solar power, fail to account for the full picture -- the interconnectedness of everything.\n  Policymakers often assume that a few tweaks and some human ingenuity will allow for infinite goods and growth; \nDasgupta does not.\n  The New York Times will speak about the climate crisis next week with global leaders, including Bill Gates; Ajay \nBanga, the president of the World Bank; Robin Wall Kimmerer, author and scientist; Jonas Gahr Store, the prime \nminister of Norway; and William Ruto, the president of Kenya. Register to watch the free livestream of the Climate \nForward event on Sept. 21.\n  On our radar: 'Dumb Money' \n  Remember the meme-stock craze of 2021? The sudden jump in shares of the video game retailer GameStop, \ndriven by Reddit-fueled day traders, rattled financial titans -- especially the hedge fund moguls who had bet against \nthe company's stock price. It was seen briefly as a moment of Main Street's beating Wall Street at its own game.\n  That heady time is chronicled in ''Dumb Money,'' an exuberant comedy that aims to do for GameStop what ''The \nBig Short'' did for the 2008 global financial crisis. Out now in limited release, the movie features a cast of big-name \nactors, including Paul Dano, America Ferrera and Seth Rogen, playing a mix of real-life characters and fictional \ncomposites who feature on both sides of the trading conflict.\n  ''Dumb Money'' is connected to Wall Street behind the scenes, too: The film was financed and produced by Teddy \nSchwarzman, son of the Blackstone co-founder Stephen A. Schwarzman, and written by two former Wall Street \nJournal reporters, Lauren Schuker Blum and Rebecca Angelo. But it's not exactly sympathetic to the hedge fund \nside of the story -- to the point that Ken Griffin of Citadel has reportedly threatened to sue over his portrayal.\n  Alison Willmore of Vulture wrote in a review that ''the pleasant surprise of 'Dumb Money' is that it's such an \neffective entertainment.'' The New York Times's Ben Kenigsberg described the film as ''an energetic, ingratiating \ndramatization'' but the ''humanizing efforts are less inspired.''\n  Thanks for reading! We'll see you Monday.\n  We'd like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com\nhttps://www.nytimes.com/2023/09/16/business/dealbook/uaw-strike-tech-ai-unions.html\nIn Strikes Across Industries, Workers Fear New Technologies Will Cost Jobs\nGraphic\n \nThis article appeared in print on page B3.               \nLoad-Date: September 18, 2023"
    },
    {
        "file_name": "Middle_School_pupils_have_been_disciplined_in_the_incident._Mar2024",
        "header": "CITY & STATE; Students expelled over fake nude images; Five Beverly Vista",
        "media": "Middle School pupils have been disciplined in the incident.",
        "time": "March 9, 2024",
        "section": "CALIFORNIA; Metro Desk; Part B; Pg. 1",
        "length": "530 words",
        "byline": "Jon Healey",
        "story_text": "CITY & STATE; Students expelled over fake nude images; Five Beverly Vista \nMiddle School pupils have been disciplined in the incident.\nLos Angeles Times\nMarch 9, 2024 Saturday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: CALIFORNIA; Metro Desk; Part B; Pg. 1\nLength: 530 words\nByline: Jon Healey\nBody\nFive Beverly Hills eighth-graders have been expelled for their involvement in the creation and sharing of fake nude \npictures of their classmates.\nThe Beverly Hills Unified School District board of education voted at a special meeting Wednesday evening to \napprove stipulated agreements of expulsion with five students. According to a source close to the investigation, the \nexpelled students were attending Beverly Vista Middle School. Under a stipulated agreement, the students and their \nparents do not contest the punishment and no hearing was held.\nThe names of the students were not released, and the agreements are confidential. Typically, however, such \nagreements specify how long a student is expelled and what the terms are for their return to the district.\nAccording to Supt. Michael Bregy, the five students who were the focus of its investigation were the \"most \negregiously involved\" in the creation and sharing of the images, which superimposed pictures of real students' faces \nonto simulated nude bodies generated by artificial intelligence. The victims, the district said, were 16 eighth-grade \nstudents.\nShared through messaging apps, the images outraged parents and school officials, prompting Bregy to tell parents \nin a message last month that he was prepared to impose \"the most severe disciplinary actions allowed by state \nlaw.\" The students involved were identified and disciplined in less than 24 hours, but the district did not move to \nexpel them until it completed its investigation.\nThe Beverly Hills Police Department and the Los Angeles County district attorney's office are still investigating the \nincident, but no arrests have been made or charges brought. California's laws against possessing child \npornography and sharing nonconsensual nude pictures do not specifically apply to AI-generated images, which \nlegal experts say would pose a problem for prosecutors.\nThe fake nudes circulated briefly among Beverly Vista students in late February, school officials say. They haven't \nspecified how the images were made, other than to say it involved generative A.I.\nDozens of A.I.-powered apps are available online to \"undress\" someone in a photo, simulating what a person would \nlook like if they'd been nude when the shot was taken. Other A.I.-based tools allow you to \"face swap\" a targeted \nperson's face onto another person's body.\n\"This incident has spurred crucial discussions on the ethical use of technology, including AI, underscoring the \nimportance of vigilant and informed engagement within digital environments,\" Bregy said in a message to parents. \nCITY & STATE Students expelled over fake nude images Five Beverly Vista Middle School pupils have been \ndisciplined in the incident.\n\"Our district is steadfast in its commitment to enhancing education around digital citizenship, privacy, and safety for \nour students, staff, and parents which was immediately reemphasized at all schools.\"\nNo specific policy change has been announced in response to the incident, but the district had already prohibited \nstudents from using cellphones on campus.\nBregy said the images, reported to school officials Feb. 21, were contained within 24 hours.\n\"We recognize that kids are still learning and growing, and mistakes are part of this process,\" he said in the \nmessage. \"However, accountability is essential.\"\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Nov2023",
        "header": "YouTube to ask creators to tell when video is AI",
        "media": "The Baltimore Sun",
        "time": "November 15, 2023",
        "section": "SPORTS; D; Pg. 9",
        "length": "279 words",
        "byline": " ",
        "story_text": "YouTube to ask creators to tell when video is AI\nThe Baltimore Sun\nNovember 15, 2023 Wednesday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: SPORTS; D; Pg. 9\nLength: 279 words\nBody\nYouTube is rolling out new rules for AI content, including a requirement that creators reveal whether they've used \ngenerative artificial intelligence to make realistic looking videos.\nIn a blog post Tuesday outlining a number of AI-related policy updates, YouTube said creators that don't disclose \nwhether they've used AI tools to make \"altered or synthetic\" videos face penalties including having their content \nremoved or suspension from the platform's revenue sharing program.\n\"Generative AI has the potential to unlock creativity on YouTube and transform the experience for viewers and \ncreators on our platform,\" Jennifer Flannery O'Connor and Emily Moxley, vice presidents for product management, \nwrote in the blog post. \"But just as important, these opportunities must be balanced with our responsibility to protect \nthe YouTube community.\"\nThe restrictions expand on rules that YouTube's parent company, Google, unveiled in September requiring that \npolitical ads on YouTube and other Google platforms using artificial intelligence come with a prominent warning \nlabel.\nUnder the latest changes, which will take effect by next year, YouTubers will get new options to indicate whether \nthey're posting AI-generated video that, for example, realistically depict an event that never happened or show \nsomeone saying or doing something they didn't actually do.\n\"This is especially important in cases where the content discusses sensitive topics, such as elections, ongoing \nconflicts and public health crises, or public officials,\" O'Connor and Moxley said.\nViewers will be alerted to altered videos with labels, including prominent ones on the YouTube video player for \nsensitive topics.\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "Vijayakumar_Jan2024",
        "header": "Diversified R&D and generative AI key to future growth, says HCLTech's C",
        "media": "Vijayakumar",
        "time": "January 13, 2024",
        "section": "TECH & INTERNET",
        "length": "826 words",
        "byline": "Romita Majumdar and Beena Parmar",
        "story_text": "Diversified R&D and generative AI key to future growth, says HCLTech's C \nVijayakumar\nThe Economic Times\nJanuary 14, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 826 words\nByline: Romita Majumdar and Beena Parmar\nBody\nPublication of the minutes of the last meeting of the US Federal Open Market Committee (FOMC) early January led \nto a surge in the National Stock Exchange’s technology index, which has gained 9% in a month on expectations of \nan early resumption to the rate-easing cycle in the world’s biggest market for Indian outsourcing. However, the \ncommentary by Federal Reserve policymakers has had little concrete impact on most of its clients, HCLTech CEO \nC Vijayakumar tells ET, as discretionary expenditures by most US companies remain circumspect.Still, HCLTech, \nIndia’s third-largest software exporter with a market capitalization of Rs 4.18 lakh crore, beat analysts’ estimates to \nreport a 6.2% net profit growth in the December quarter. In the absence of an immediate resumption in the \nexpenditure cycle, HCLTech would harness deal conversions, a diversified R&D portfolio, and rising demand for \ngenerative AI to boost both its top and bottom-lines in the near term, Vijayakumar said in the post-earnings \ninterview. Edited excerpts:What is your assessment of the broader demand environment?\nMaybe, there is a little more confidence, but it's too early for it to turn into a discretionary spending increase. Right \nnow, we don't see a difference between the last quarter and this one. It is the same environment. Probably, it will \ntake some more time for the macro indicators to translate into (purchase) decisions. The markets are factoring in a \nquick recovery (due to the Federal Reserve comments). But I would want to look at really what's happening with the \nclient and see how this impacts spending. So, I would say the environment has been the same as what it was in the \nlast quarter.You said engineering, research, and development (ER&D) demand will drive growth in Q4. Are you \nwitnessing strong demand there?If you look at the ER&D space, we service a very wide set of industries, starting \nfrom technology companies to telecom service providers, telecom OEMs, and a lot of industrial engineering, \nautomotive, medical devices, and semiconductor companies. We have a wide cross-section of industries. Now, in \nthe past few quarters, we have grown the ER&D business. Initially, when we saw growth in the September quarter, \nwe were still cautious. In the December quarter as well, we saw some good growth and I see some growth in the \nMarch quarter as well. So, overall, we have seen good momentum in our ER&D business (accounting for 16% of \nrevenue), and it is across industries. How sustainable is the record margin expansion you have reported in Q3?Our \nmargin guidance is 18 to 19%. And we will be within the guided range in Q4 as well. Margins in the December \nquarter are very high because it's a seasonally strong quarter for the software business and you would have seen a \n32-33% operating margin in the software business. I think that is the reason for the spike in margins. Usually, in the \nDecember quarter it happens. In Q4, we will be in the guided range.You have reported consistent conversion of \ndeals to revenue in recent quarters. Has your sales approach changed?One basic difference is that we call out only \nnet new deal wins. We do not include renewals, rate card deals, or framework deals in our booking numbers. So, \nwhen it is a net new deal that is confirmed, (it refers to) signed contracts with clear timelines for transition or ramp \nup. So that way, our bookings will directly correlate to the revenue model in general. We have a one- or two-quarter \ndelay. I think it's the definition of bookings that is probably giving the right correlation between our revenue and \nbooking.Can you give us a sense as to why the rest of the world has seen a decline while the top geographies \ncontinued to grow?The rest of the world is a smaller part of our business and we saw some ramp-downs and there \nDiversified R&D and generative AI key to future growth, says HCLTech's C Vijayakumar\nwas a furlough impact, which caused this.We are focused on the rest of the world, and you will see some traction \ngoing forward. Australia-New Zealand, Asia Pacific, Middle East, Japan, and South Africa are the five key \ngeographies for the rest of the world business.When do we see AI demand percolating into revenues?I think it will \ntake two to three quarters at least before some of this translates into some meaningful revenue. We saw a lot of \nenthusiasm and conversations and we are already implementing several projects. We won 30 projects in Gen AI in \nthe last quarter. They're all sub-million dollar programmes and but each one of them has a good future potential. \nBecause once the first phase is implemented, then customers generally tend to look at how they can strengthen or \nput in place a stronger foundation to leverage generative AI more widely. This means they will spend on data and \nmulti-cloud solutions. They will spend on security. It’s the surrounding spending that's going to be visible on the \ngenerative AI. There will be some cross-industry use cases and that's where we are going to first focus on. For \nReprint Rights: timescontent.com\nLoad-Date: January 13, 2024"
    },
    {
        "file_name": "New_York_Observer_Apr2023",
        "header": "Two-Thirds of Jobs Are at Risk: Goldman Sachs A.I. Study",
        "media": "New York Observer",
        "time": "April 3, 2023",
        "section": "",
        "length": "510 words",
        "byline": "Sissi Cao",
        "story_text": "Two-Thirds of Jobs Are at Risk: Goldman Sachs A.I. Study\nNew York Observer\nMarch 30, 2023 Thursday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 510 words\nByline: Sissi Cao\nBody\nAs many as 300 million full-time jobs in the world, including two-thirds of jobs in the U.S. and Europe, are at risk of \nbeing replaced in some way by generative artificial intelligence, the technology behind tools like ChatGPT, \naccording to a Goldman Sachs study this week.\n\"If generative AI delivers on its promised capabilities, the labor market could face significant disruption,\" the \ninvestment bank's economists wrote in a report.\nWhat jobs are at the most at-risk and where?\nThe impact of A.I. disruption will be felt most deeply in developed countries, like the U.S. and European Union \nnations, the study noted, because those economies support a large number of white-collar jobs that are more prone \nto automation than manual labor-intensive work does.\nIn the U.S., 46 percent of office and administrative support positions could potentially be replaced by A.I., Goldman \nSachs estimates. About 44 percent of legal positions could be automated, and 37 percent of engineering jobs are at \nrisk.\nOverall, approximately two-thirds of current jobs in the U.S. and Europe are exposed to some degree of A.I. \nautomation, and up to a quarter of all work could be replaced by machines completely, the bank said, adding that, \nof affected positions where humans are still needed, as much as half of their workload could be computerized.\nTech elites raise alarm on A.I.'s threat to human jobs\nBill Gates painted a similarly alarming picture recently. In a lengthy blog post last week, the Microsoft cofounder \npredicted using tools like ChatGPT will increasingly feel like \"having a white-collar worker available to help you with \nvarious tasks.\"\nGates said A.I. has the potential of outperforming human workers in job functions like sales, service and document \nhandling, where there are a plethora of good and bad examples for an algorithm to learn from.\nEarlier this week, Elon Musk and hundreds of tech entrepreneurs and academics signed a letter urging A.I. labs to \npause training systems that are more powerful than OpenAI's GPT-4 until the industry develops a shared set of \nsafety protocols.\n\"We must ask ourselves: Should we automate away all the jobs, including the fulfilling ones?\" said the letter, \nauthored by nonprofit Future of Life Institute. \"Should we develop nonhuman minds that might eventually \noutnumber, outsmart, obsolete and replace us?\"\nIt's not all doom-and-gloom\nTwo-Thirds of Jobs Are at Risk: Goldman Sachs A.I. Study\nGoldman Sachs economists appear more optimistic. They noted technological advancement that initially displaces \nhuman workers has historically also created employment and economic growth over the long term.\n\"Although the impact of A.I. on the labor market is likely to be significant, most jobs and industries are only partially \nexposed to automation and are thus more likely to be complemented rather than substituted by A.I.,\" the report \nsaid.\nWidespread adoption of A.I. will greatly increase productivity and boost global economic output by 7 percent \nannually over a 10-year period, which is more than double the typical economic growth rate of industrialized \nnations, Goldman Sachs predicted.\nLoad-Date: April 3, 2023"
    },
    {
        "file_name": "Iowa_town's_water_consumption_spikes_thanks_to_Microsoft_Sep2023",
        "header": "Very thirsty AI technology behind ChatGPT",
        "media": "Iowa town's water consumption spikes thanks to Microsoft",
        "time": "September 12, 2023",
        "section": "MAIN; A; Pg. 9",
        "length": "1111 words",
        "byline": "Matt O'Brien and Hannah Fingerhut Associated Press",
        "story_text": "Very thirsty AI technology behind ChatGPT\nIowa town's water consumption spikes thanks to Microsoft\nThe Baltimore Sun\nSeptember 12, 2023 Tuesday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 9\nLength: 1111 words\nByline: Matt O'Brien and Hannah Fingerhut Associated Press\nHighlight: Traffic on Interstate 35 passes a Microsoft data center Sept. 5 in West Des Moines, Iowa. Charlie \nNeibergall/AP\nBody\nDES MOINES, Iowa - The cost of building an artificial intelligence product like ChatGPT can be hard to measure.\nBut one thing Microsoft-backed OpenAI needed for its technology was plenty of water, pulled from the watershed of \nthe Raccoon and Des Moines rivers in central Iowa to cool a powerful supercomputer as it helped teach its AI \nsystems how to mimic human writing.\nAs they race to capitalize on a craze for generative AI, leading tech developers including Microsoft, OpenAI and \nGoogle have acknowledged that growing demand for their AI tools carries hefty costs, from expensive \nsemiconductors to an increase in water consumption.\nBut they're often secretive about the specifics. \nFew people in Iowa knew about its status as a birthplace of OpenAI's most advanced large language model, GPT-\n4, before a top Microsoft executive said in a speech it \"was literally made next to cornfields west of Des Moines.\"\nBuilding a large language model requires analyzing patterns across a huge trove of human-written text. All of that \ncomputing takes a lot of electricity and generates a lot of heat. To keep it cool on hot days, data centers need to \npump in water - often to a cooling tower outside its warehouse-sized buildings.\nIn its latest environmental report, Microsoft disclosed that its global water consumption spiked 34% from 2021 to \n2022 (to nearly 1.7 billion gallons), a sharp increase compared to previous years that outside researchers tie to its \nAI research.\n\"It's fair to say the majority of the growth is due to AI,\" including \"its heavy investment in generative AI and \npartnership with OpenAI,\" said Shaolei Ren, a researcher at the University of California, Riverside, who has been \ntrying to calculate the environmental impact of generative AI products such as ChatGPT.\nIn a forthcoming paper, Ren's team estimates ChatGPT gulps up 500 milliliters of water (close to what's in a 16-\nounce water bottle) every time you ask it a series of 5 to 50 prompts or questions. The range varies depending on \nwhere its servers are located and the season. The estimate includes indirect water usage that the companies don't \nmeasure - such as to cool power plants that supply the data centers with electricity.\nVery thirsty AI technology behind ChatGPT Iowa town's water consumption spikes thanks to Microsoft\n\"Most people are not aware of the resource usage underlying ChatGPT,\" Ren said. \"If you're not aware of the \nresource usage, then there's no way that we can help conserve the resources.\"\nGoogle reported a 20% increase in water use in the same period, which Ren also largely attributes to its AI work. \nGoogle's spike wasn't uniform - it was steady in Oregon where its water use has attracted public attention, while \ndoubling outside Las Vegas. It was also thirsty in Iowa, drawing more potable water to its Council Bluffs data \ncenters than anywhere else.\nIn response to questions from The Associated Press, Microsoft said in a statement last week that it is investing in \nresearch to measure AI's energy and carbon footprint \"while working on ways to make large systems more efficient, \nin both training and application.\"\n\"We will continue to monitor our emissions, accelerate progress while increasing our use of clean energy to power \ndata centers, purchasing renewable energy, and other efforts to meet our sustainability goals of being carbon  \nnegative, water positive and zero waste by 2030,\" the company's statement said.\nOpenAI echoed those comments in its own statement Friday, saying it's giving \"considerable thought\" to the best \nuse of computing power.\n\"We recognize training large models can be energy and water-intensive\" and work to improve efficiencies, it said.\nMicrosoft made its first $1 billion investment in San Francisco-based OpenAI in 2019, more than two years before \nthe startup introduced ChatGPT and sparked worldwide fascination with AI advancements. As part of the deal, the \nsoftware giant would supply computing power needed to train the AI models.\nTo do at least some of that work, the two companies looked to West Des Moines, Iowa, a city of 68,000 people \nwhere Microsoft has been amassing data centers to power its cloud computing services for more than a decade. Its \nfourth and fifth data centers are due to open there later this year.\n\"They're building them as fast as they can,\" said Steve Gaer, who was the city's mayor when Microsoft came to \ntown. Gaer said the company was attracted to the city's commitment to building public infrastructure and \ncontributed a \"staggering\" sum of money through tax payments that support that investment.\nExperts have said it can make sense to \"pretrain\" an AI model at a single location because of the large amounts of \ndata that need to be transferred between computing cores.\nIt wasn't until late May that Microsoft's president, Brad Smith, disclosed that it had built its \"advanced AI \nsupercomputing data center\" in Iowa, exclusively to enable OpenAI to train what has become its fourth-generation \nmodel, GPT-4. The model now powers premium versions of ChatGPT and some of Microsoft's own products and \nhas accelerated a debate about containing AI's societal risks.\nIn some ways, West Des Moines is a relatively efficient place to train a powerful AI system, especially compared to \nMicrosoft's data centers in Arizona that consume far more water for the same computing demand.\n\"So if you are developing AI models within Microsoft, then you should schedule your training in Iowa instead of in \nArizona,\" Ren said. \"In terms of training, there's no difference. In terms of water consumption or energy \nconsumption, there's a big difference.\"\nFor much of the year, Iowa's weather is cool enough for Microsoft to use outside air to keep the supercomputer \nrunning properly and vent heat out of the building. Only when the temperature exceeds about 85 degrees does it \nwithdraw water, the company has said in a public disclosure.\nThat can still be a lot of water, especially in the summer. In July 2022, the month before OpenAI says it completed \nits training of GPT-4, Microsoft pumped in about 11.5 million gallons of water to its cluster of Iowa data centers, \naccording to the West Des Moines Water Works. That amounted to about 6% of all the water used in the district.\nVery thirsty AI technology behind ChatGPT Iowa town's water consumption spikes thanks to Microsoft\nIn 2022, a document from the West Des Moines Water Works said it and the city government \"will only consider \nfuture data center projects\" from Microsoft if those projects can \"demonstrate and implement technology to \nsignificantly reduce peak water usage from the current levels.\"\nMicrosoft said last week that it is working directly with the water works to address its feedback. In a statement, the \nwaterworks said the company has been a good partner and has been working with local officials to reduce its water \nfootprint while still meeting its needs.\nLoad-Date: September 12, 2023"
    },
    {
        "file_name": "spreading_lies,_hate_to_extinction_May2023",
        "header": "Many worry we've created a monster; Survey: AI concerns range from",
        "media": "spreading lies, hate to extinction",
        "time": "May 18, 2023",
        "section": "BUSINESS; Pg. B1",
        "length": "442 words",
        "byline": "By, Jessica Guynn, USA TODAY",
        "story_text": "Many worry we've created a monster; Survey: AI concerns range from \nspreading lies, hate to extinction\nUSA Today\nMay 18, 2023 Thursday\n1 Edition\nCopyright 2023 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B1\nLength: 442 words\nByline: By, Jessica Guynn, USA TODAY\nBody\nAmericans are worried that artificial intelligence technologies like ChatGPT will be used to worsen social ills, from \nfraud and identity theft to extremism and hate, and they want the companies like Microsoft, Google and OpenAI that \nare rushing to commercialize these tools to do something about it, according to a new survey from ADL shared \nexclusively with USA TODAY.\nThe ADL survey reflects growing unease over the rapidly evolving technologies that have the potential to improve \npeople's lives but could also cause substantial harm, said ADL CEO Jonathan Greenblatt.\nThe majority of Americans worry that people will use AI for criminal activity (84%), spreading false or misleading \ninformation (83%), radicalizing people to extremism (77%), and inciting hate and harassment (75%), the survey \nsaid.\nThree-quarters of those surveyed - 75% - think the tools will produce biased content targeting marginalized groups \nwhile 70% say they will be used to make extremism and hate, including antisemitism, worse in America.\nThe survey of 1,007 U.S. adults was released in advance of a Senate hearing Tuesday where the CEO of ChatGPT \ncreator OpenAI Sam Altman and other officials  testified about the potential risks of AI chatbots.\n\"If we've learned anything from other new technologies, we must protect against the potential risk for extreme harm \nfrom generative AI before it's too late,\" Greenblatt said in a statement to USA TODAY.\nThe new wave of AI tools has dazzled Americans, promising a bevy of benefits. They can carry on human-like \nconversations, write essays, compose music and create audio, video and images.\nBut these tools also have worrying implications for the future of work and education as well as the future of \nhumanity.\nGeoffrey Hinton, a top architect of artificial intelligence, recently warned that AI could someday take over the world \nand push humanity toward extinction.\nThe White House recently summoned officials from Microsoft, Google and ChatGPT creator OpenAI to discuss the \nrisks and promote responsible innovation that protects the rights and safety of Americans.\nThe Federal Trade Commission has also warned that it will crack down on AI technologies if they run amok.\nThe ADL survey revealed that government concerns reflect those of most Americans.\nMany worry we've created a monster Survey: AI concerns range from spreading lies, hate to extinction\nNearly 90% say tech companies should take steps to prevent their AI tools from creating harmful content and from \ngenerating antisemitic or extremist images and support congressional efforts to intervene. They also support audits \nof the tools, with 86% agreeing that academic or civic groups \"should have access to review or audit the tools to \nmake sure they are properly constructed.\"\nGraphic\n \nGetty Images\nLoad-Date: May 18, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_May2023",
        "header": "Will a Chatbot Write the Next 'Succession'?",
        "media": "The New York Times - International Edition",
        "time": "May 5, 2023",
        "section": "BUSINESS",
        "length": "1742 words",
        "byline": "Noam Scheiber and John Koblin",
        "story_text": "Will a Chatbot Write the Next 'Succession'?\nThe New York Times - International Edition\nMay 6, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1742 words\nByline: Noam Scheiber and John Koblin\nBody\nABSTRACT\nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.\nFULL TEXT\n         April 29,2023, Saturday         Online Correction:              \nThis article has been revised to reflect the following correction: An earlier version of this article misstated John \nAugust's affiliation. He is on the Writers Guild negotiating committee, not a member of the Writers Guild board. \nCORRECTION APPENDED \nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.       \nWhen the union representing Hollywood writers laid out its list of objectives for contract negotiations with studios \nthis spring, it included familiar language on compensation, which the writers say has either stagnated or dropped \namid an explosion of new shows.       \nBut far down, the document added a distinctly 2023 twist. Under a section titled \"Professional Standards and \nProtection in the Employment of Writers,\" the union wrote that it aimed to \"regulate use of material produced using \nartificial intelligence or similar technologies.\"       \nTo the mix of computer programmers, marketing copywriters, travel advisers, lawyers and comic illustrators \nsuddenly alarmed by the rising prowess of generative A.I., one can now add screenwriters.       \n\"It is not out of the realm of possibility that before 2026, which is the next time we will negotiate with these \ncompanies, they might just go, 'you know what, we're good,'\" said Mike Schur, the creator of \"The Good Place\" and \nco-creator of \"Parks and Recreation.\"       \n\"We don't need you,\" he imagines hearing from the other side. \"We have a bunch of A.I.s that are creating a bunch \nof entertainment that people are kind of OK with.\"       \nIn their attempts to push back, the writers have what a lot of other white-collar workers don't: a labor union.       \nWill a Chatbot Write the Next 'Succession'?\nMr. Schur, who serves on the bargaining committee of the Writers Guild of America as it seeks to avert a strike \nbefore its contract expires on Monday, said the union hopes to \"draw a line in the sand right now and say, 'Writers \nare human beings.'\"       \nBut unions, historians say, have generally failed to rein in new technologies that enable automation or the \nreplacement of skilled labor with less-skilled labor. \"I'm at a loss to think of a union that managed to be plucky and \nmake a go of it,\" said Jason Resnikoff, an assistant professor of history at the University of Groningen in the \nNetherlands, who studies labor and automation.       \nThe fortunes of the writers, actors and directors negotiating new contracts this year may say a lot about whether the \npattern will continue into the era of artificial intelligence.       \nIn December, Apple introduced a service allowing book publishers to use human-sounding A.I. narrators, an \ninnovation that could displace hundreds of voice actors who make a living performing audiobooks. The company's \nwebsite says the service will benefit independent authors and small publishers.       \n\"I know someone always has to get there first, some company,\" said Chris Ciulla, who estimates that he has made \n$100,000 to $130,000 annually over the past five years narrating books under union contracts. \"But for individuals \nnot to understand how that can affect the pail-carrying narrator out there eventually is disappointing.\"       \nOther actors fear that studios will use A.I. to replicate their voices while cutting them out of the process. \"We've \nseen this happening - there are websites that have popped up with databases of characters' voices from video \ngames and animation,\" said Linsay Rousseau, an actress who makes her living doing voice work.       \nOn-camera actors point out that studios already use motion capture or performance capture to replicate artists' \nmovements or facial expressions. The 2018 blockbuster \"Black Panther\" relied on this technology for scenes that \ndepicted hundreds of tribespeople on cliffs, mimicking the movements of dancers hired to perform for the film.       \nSome actors worry that newer versions of the technology will allow studios to effectively steal their movements, \n\"creating new performance in the style of a wushu master or karate master and using that person's style without \nconsent,\" said Zeke Alton, a voice and screen actor who sits on the board of his union local, SAG-AFTRA, in Los \nAngeles.       \nAnd Hollywood writers have grown increasingly anxious as ChatGPT has become adept at mimicking the style of \nprolific authors.       \n\"Early on in the conversations with the guild, we talked about what I call the Nora Ephron problem,\" said John \nAugust, who is on the Writers Guild negotiating committee.\"Which is basically: What happens if you feed all of Nora \nEphron's scripts into a system and generate an A.I. that can create a Nora Ephron-sounding script?\"       \nMr. August, a screenwriter for movies like \"Charlie's Angels\" and \"Charlie and the Chocolate Factory,\" said that \nwhile artificial intelligence had taken a back seat to compensation in the Writers Guild negotiation, the union was \nmaking two key demands on the subject of automation.       \nIt wants to ensure that no literary material - scripts, treatments, outlines or even discrete scenes - can be written or \nrewritten by chatbots. \"A terrible case of like, 'Oh, I read through your scripts, I didn't like the scene, so I had \nChatGPT rewrite the scene' - that's the nightmare scenario,\" Mr. August said.       \nThe guild also wants to ensure that studios can't use chatbots to generate source material that is adapted to the \nscreen by humans, the way they might adapt a novel or a magazine story.       \nSAG-AFTRA, the actors' union, says more of its members are flagging contracts for individual jobs in which studios \nappear to claim the right to use their voices to generate new performances.       \nA recent Netflix contract sought to grant the company free use of a simulation of an actor's voice \"by all \ntechnologies and processes now known or hereafter developed, throughout the universe and in perpetuity.\"       \nWill a Chatbot Write the Next 'Succession'?\nNetflix said the language had been in place for several years and allowed the company to make the voice of one \nactor sound more like the voice of another in case of a casting change between seasons of an animated production.       \nThe union has said that its members are not bound by contract provisions that would allow a producer to simulate \nnew performances without compensating actors, though it has sometimes intervened to strike them from contracts \nnonetheless.       \nDuncan Crabtree-Ireland, SAG-AFTRA's executive director, said such contracts posed a much bigger risk to \nnonunion actors, who can become unwitting accomplices in their own obsolescence. \"It only takes one or a few \ninstances of signing away your rights on a lifetime basis to really potentially have a negative impact on your career \nprospects,\" Mr. Crabtree-Ireland said.       \nThe Alliance of Motion Picture and Television Producers, which bargains with the various unions that represent \nwriters, actors and directors on behalf of the major Hollywood studios, declined to comment.       \nWhen professionals have fended off obsolescence at the hands of technology, the outcome has often reflected their \noccupation's status and prestige.       \nThat appears to have been the case to some extent with airplane pilots, whose crew sizes had dropped to two on \nmost domestic commercial flights by the late 1990s, but have largely been level since then, even as automated \ntechnology has become far more sophisticated and the industry has explored further reductions.       \n\"The safety net you have when you're high off the ground - the one that keeps you from hitting the ground - is two \nhighly trained, experienced, rested pilots,\" said Capt. Dennis Tajer, a spokesman for the Allied Pilots Association, \nwhich represents pilots for American Airlines. To this day, flight times longer than nine hours require at least three \npilots.       \nThe replacement of certain doctors by artificial intelligence, which some experts predicted was imminent in fields \nlike radiology, has also failed to materialize. That's partly because of the limits of the technology, and because of \nthe stature of the doctors, who have inserted themselves into high-stakes conversations about the safety and \ndeployment of A.I. The American College of Radiology created a Data Science Institute partly for this purpose \nseveral years ago.       \nWhether screenwriters find similar success will depend at least in part on if there are inherent limits to the machines \nthat purport to do their jobs. Some writers and actors speak of a so-called uncanny valley that algorithms may never \nentirely escape.       \n\"Artists look at everything ever created and find a flash of newness,\" said Javier Grillo-Marxuach, a writer and \nproducer for \"Lost\" and \"Dark Crystal: Age of Resistance.\" \"What the machine is doing is recombining.\"       \nHowever sophisticated the algorithms, the fate of writers and actors will also depend on how well they protect their \nstatus. How good are they at convincing audiences that they should care whether a human is involved?       \nThe unions are pressing their case. Mr. August says that it falls to the Writers Guild and not the studio to determine \nwho receives a writer's credit on a project, and that the union will guard this rite jealously. \"We want to make sure \nthat an A.I. is never one of those writers in the chain of title for a project,\" he said.       \nThe unions also have legal cards to play, Mr. Crabtree-Ireland of SAG-AFTRA said, like the U.S. Copyright Office's \npronouncement in March that content created entirely by algorithm is not eligible for copyright protection. It is harder \nto monetize a production if there is no legal obstacle to copying it.       \nPerhaps more important, he said, is what you might call the Us Weekly factor - the tendency of audiences to be as \ninterested in the human behind the role as in the performance. Fans want to hear Hollywood celebrities discuss \ntheir method in interviews. They want to gawk at actors' fashion sensibilities and keep up with whom they're dating.       \nWill a Chatbot Write the Next 'Succession'?\n\"If you look at culture in general, the audience is generally interested in the real lives of our members,\" Mr. \nCrabtree-Ireland said. \"A.I. is not in a position to substitute for key elements of that.\"       \nAudio produced by Sarah Diamond.       \nAudio produced by Sarah Diamond. \nLoad-Date: May 5, 2023"
    },
    {
        "file_name": "Klein_Show_Dec2023",
        "header": "Transcript: Ezra Klein Interviews Casey Newton and Kevin Roose; The Ezra",
        "media": "Klein Show",
        "time": "December 1, 2023",
        "section": "PODCASTS",
        "length": "12472 words",
        "byline": " ",
        "story_text": "Transcript: Ezra Klein Interviews Casey Newton and Kevin Roose; The Ezra \nKlein Show\nThe New York Times \nDecember 1, 2023 Friday 13:50 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 12472 words\nHighlight: The Dec. 1, 2023, episode of “The Ezra Klein Show.”\nBody\nEvery Tuesday and Friday, Ezra Klein invites you into a conversation about something that matters, like today’s \nepisode with Casey Newton and Kevin Roose. Listen wherever you get your podcasts.\nTranscripts of our episodes are made available as soon as possible. They are not fully edited for grammar or \nspelling.\n[MUSIC PLAYING] EZRA KLEIN: From New York Times Opinion, this is “The Ezra Klein Show.”\n[MUSIC PLAYING]\nBefore we get into the episode today, we are doing, or getting ready to do, our end of the year “Ask Me Anything.” \nSo if you have questions you want to hear me answer on the show — I suspect a lot of them are going to be about \nIsrael-Palestine and A.I., but they don’t have to be about Israel-Palestine and A.I. — send them to \nezrakleinshow@nytimes.com with A.M.A. in the headline. Again, to ezrakleinshow@nytimes.com with A.M.A. in the \nheadline.\n[MUSIC PLAYING]\nIf you follow business or tech or artificial intelligence news at all, in recent weeks you certainly were following Sam \nAltman being unexpectedly fired as C.E.O. of OpenAI, and then a huge staff revolt at OpenAI where more than 95 \npercent of the company said it would resign if he was not reinstated. And then he was reinstated, and so this whole \nthing seemed to have happened for nothing.\nI spent a lot of time reporting on this. And I talked to people on the Altman side of things. I talked to people on the \nboard side of things. And the thing I am now convinced of — truly convinced of — is that there was less to it than \nmet the eye. People saw — I saw — Altman fired by this nonprofit board meant to ensure that A.I. is built to serve \nhumanity.\nAnd I assumed — and I think many assumed — there was some disagreement here over what OpenAI was doing, \nover how much safety was building into the systems, over the pace of commercialization, over the contracts it was \nsigning, over what it was going to be building next year, over something. And that, I think, I can say conclusively — \nand has been corroborated by other reporting — that was not what this was about.\nThe OpenAI board did not trust and did not feel it could control Sam Altman, and that is why they fired Altman. It’s \nnot that they felt they couldn’t trust him on one thing, that they were trying to control him on X but he was beating \nthem on X. It’s that a lot of little things added up. They felt their job was to control the company, that they did not \nfeel they could control him, and so to do their job, they had to get rid of him.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nThey did not have, obviously, the support inside the company to do that. They were not ultimately willing to let \nOpenAI completely collapse. And so they largely — although, I think in their view not totally — backed down. One of \nthe members is still on the board. Altman and the president of OpenAI, Greg Brockman, are off the board.\nSome new board members are coming in who they think are going to be stronger and more willing to stand up to \nthem. There’s an investigation that is going to be done of Altman’s behavior, that will be at least released to the \nboard so they’ll I guess know what to think of him. It’s a very strange story. I wouldn’t be surprised if there’s things \nyet to come out. But I am pretty convinced that this was truly a struggle for control not a struggle about x.\nBut it has been a year since ChatGPT was released. It was a weird way to mark the year, but it has been a year. A \nyear since OpenAI kicked off the whole modern era in artificial intelligence, a year since a lot of people’s \nestimations of what humanity’s future looked like began to shift and cloud, and darken, and shimmer.\nAnd so I wanted to have the conversation that many of us thought was a conversation happening here about what \nA.I. was becoming, how it was being used, how it was being commercialized, whether or not the path we’re on is \ngoing to benefit humanity. And so I asked my friends over at “Hard Fork,” another great New York Times podcast, \nto come on the show.\nKevin Roose is my colleague at The Times. He writes a tech column called “The Shift.” Casey Newton is the editor \nof Platformer, an absolutely must-read newsletter about the intersection of technology and democracy. And they \nhave been following this in and out, but they’ve been closely following A.I. for the past year. So I wanted to have \nthis broader conversation with them. As always, my email ezrakleinshow@nytimes.com\n[MUSIC PLAYING]\nKevin Roose, Casey Newton, welcome to the show, my friends.\nCASEY NEWTON: Hey, Ezra.\nKEVIN ROOSE: Thanks for having us.\nEZRA KLEIN: All right, so we’re talking on Monday, Nov. 27. ChatGPT, which kicked off this era in A.I., was \nreleased on Nov. 30, 2022. So the big anniversary party was that Sam Altman got temporarily fired and the \ncompany almost collapsed and was rebuilt over at Microsoft, which I don’t think is how people expected to mark the \nanniversary.\nBut it has been now a year, roughly, in this whole new A.I. world that we’re in. And so I want to talk about what’s \nchanged in that year. And the place I want to begin is with the capabilities of the A.I. systems we’re seeing. Not the \nones we’re hearing about, but that we know are actually being used by someone in semi real-world conditions. \nWhat can A.I. systems do today that they couldn’t do a year ago, Kevin?\nKEVIN ROOSE: Well, the first most obvious capabilities improvement is that these models have become what’s \ncalled multimodal. So a year ago, we had ChatGPT, which could take in text input and output other text as the \nresponse to your prompt. But now we have models that can take in text and output images, take in text and output \nvideo, take in voice data and output other voice data.\nSo these models are now working with many more types of inputs and outputs than they were a year ago. And \nthat’s the most obvious difference. If you just woke up from a year-long nap and took a look at the A.I. capabilities \non the market, that’s the thing that you would probably notice first.\nEZRA KLEIN: I want to pull something out about that — is that it almost sounds like they’re developing what you \nmight call senses. And I recognize that there’s a real danger of anthropomorphizing A.I. systems, so I’m not trying \nto do that. But one thing about having different senses is that we get some information that helps us learn about the \nworld from our eyes, other information that helps us learn about the world from our ears, et cetera.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nOne of the constraints on the models is how much training data they can have. As it becomes multimodal, it would \nseem that would radically expand the amount of training data. If you can have not just all of the text on the internet, \nbut all of the audio on YouTube, or all the podcast audio on Spotify or something — or Apple podcasts — that’s a \nlot of data to learn about the world from, that, in theory, will make the models smarter and more capable. Does it \nhave that kind of recursive quality?\nKEVIN ROOSE: Absolutely. I mean, part of the backdrop for these capabilities improvements is this race for high-\nquality data. All of the A.I. labs are obsessed with finding new undiscovered high-quality data sources that they can \nuse to train their models. And so if you run out of text because you’ve scraped the entire internet, then you’ve got to \ngo to podcasts or YouTube videos or some other source of data to keep improving your models.\nCASEY NEWTON: For what it’s worth, though, I don’t think the availability of more training data is what is \ninteresting about the past year. I think what was interesting about ChatGPT was that it gave average people a way \nto interact with A.I. for the first time. It was just a box that you could type in and ask it anything and often get \nsomething pretty good in response.\nAnd even a year into folks using this now, I don’t think we’ve fully discovered everything that it can be used for. And \nI think more people are experiencing vertigo every day as they think about what this could mean for their own jobs \nand careers. So to me, the important thing was actually just the box that you type in and get questions from.\nKEVIN ROOSE: Yeah, I agree with that. I think if you had just paused there and there was no new development in \nA.I., I think it would still probably take the next five or 10 years for society to adjust to the new capabilities in our \nmidst.\nEZRA KLEIN: So you’ve made this point in other places, Casey, that a lot of the advances to come are going to be \nin user interfaces, in how we interact with these systems. In a way, that was a big advance of ChatGPT. The \nsystem behind it had been around for a while. But the ability to speak to it, or I guess write to it in natural language, \nit created this huge cultural moment around A.I.\nBut what can these A.I. products actually do that they couldn’t do a year ago? Not just how we interface with them, \nbut their underlying capacity or power.\nCASEY NEWTON: I mean, as of the Developer Day Update that OpenAI had a few weeks back, the world \nknowledge of the system has been updated to April of this year. And so you’re able to get something closer to real-\ntime knowledge of world events. It has now integrated with Microsoft Bing. And so you can get truly real-time \ninformation in a way that was impossible when ChatGPT launched.\nAnd these might sound like relatively minor things, Ezra, but you start chaining them together, you start building the \nright interfaces, and you actually start to see beyond the internet as we know it today. You see a world where the \nweb, where Google is not our starting point for doing everything online. It is just a little box on your computer that \nyou type in and you get the answer without ever visiting a web page. So that’s all going to take many years to \nunfold, but the beginnings of it are easy to see now.\nKEVIN ROOSE: One other capability that didn’t exist a year ago, at least in any public products, is the ability to \nbring your own data into these models. So Claude was the first language model that I used that had the ability to, \nsay, upload a PDF. So you could say, here’s a research paper. It’s 100 pages long. Help me summarize and \nanalyze this. And it could do that. Now ChatGPT can do the same thing. And I know a bunch of other systems are \nmoving in that direction too.\nThere are also companies that have tried to spin up their own language models that are trained on their own \ninternal data. So if you are Coca-Cola, or B.C.G., or some other business, and you want an internal ChatGPT that \nyou can use for your own employees to ask, say, questions about your H.R. documents, that is a thing that \ncompanies have been building. So that’s not the sexiest, most consumer-facing application, but that is something \nthat there’s enormous demand for out there.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nEZRA KLEIN: So one thing it seems to me to be getting better at, from what I can tell from others, is coding. I often \nask people whether they’re using A.I. bots very often, and if so, for what? And basically nobody says yes unless \nthey are a coder. Everybody says, oh, yeah, I played around with it. I thought it was really cool. I sometimes use \nDALL-E or Midjourney to make pictures for my kids or for my email newsletter. But it is the coders who say, I’m \nusing it all the time, it has become completely essential to me. I’m curious to hear a bit about that capability \nincrease.\nKEVIN ROOSE: I think where it has become part of the daily habit of programmers is through tools like GitHub \nCopilot, which is basically ChatGPT for coders that finishes whatever line of code you’re working on or helps you \ndebug some code that’s broken.\nAnd there have been some studies and tests. I think there was one test that GitHub itself ran where they gave two \ngroups of coders the same task, and one group was allowed to use GitHub Copilot and one group wasn’t. And the \ngroup with GitHub Copilot finished the task 55 percent faster than the group without it. Now, that is a radical \nproductivity increase. And if you tell a programmer, here’s a tool that can make you 55 percent faster, they’re going \nto want to use that every day.\nEZRA KLEIN: So when I see, functionally, chatbots in the wild, what I see is different versions of what people used \nto somewhat derisively call the fancy autocomplete, right? Help you finish this line of code, help you finish this \nemail. You ask a question that you might ask the search engine, like why do I have spots all over my elbow? And it \ngives you an answer that hopefully is right but maybe is not right.\nI do think some of the search implications are interesting. But at the same time, it is not the case that Bing has \nmade great strides on Google. People have not moved to asking the kind of Bing chatbot its questions as opposed \nto asking Google. Everybody feels like they need A.I. in their thing now. There’s a — I don’t think you can raise \nmoney in Silicon Valley at the moment if you don’t have a generative A.I. play built into your product or built into \nyour business strategy.\nBut that was true for a minute for crypto, too. And I’m not one of the people who makes a crypto A.I. analogy. I think \ncrypto is largely vaporware and A.I. is largely real. But Silicon Valley is faddish and people don’t know how to use \nthings and so everybody tries to put things in all at once. What product has actually gotten way better?\nCASEY NEWTON: I’ll just use one example. There’s an app you might be familiar with called Notion. It’s \nproductivity collaborative software. I write a newsletter. I save every link that I put in my newsletter into Notion. And \nnow that there is A.I. inside Notion, Notion can do a couple of things. One, it can just look at every link I save and \njust write a two-sentence summary for me, which is just nice to see, at a glance, what that story is about.\nAnd most recently it added a feature where you can just do Q&amp;A with a database and say like, hey, what are \nsome of the big stories about Meta over the past few weeks? And it’ll just start pulling those up, essentially querying \nthe database that I have built. And so while we’re very early in this, you’re beginning to see a world where A.I. is \ntaking data that you have stored somewhere and it’s turning it into your personal research assistant. So is it great \nright now? No, I would give it like a C. But for 1.0, I think it’s not bad.\nKEVIN ROOSE: And I’ll share another example that is not from my own use, but I was talking a few weeks ago with \na doctor who’s a friend of a friend. And doctors, you get tons of messages from patients. What’s this rash? Can you \nrenew this prescription? Do I need to come in for a blood test, that kind of stuff. And doctors and nurses spend a ton \nof time just opening up their message portal, replying to all these messages. It’s a huge part of being a doctor and \nit’s a part that they don’t like.\nAnd so this doctor was telling me that they have this software now that essentially uses a language model — I \nassume it’s OpenAI’s or someone very similar to that — that goes in and pre-fills the responses to patient queries. \nAnd the doctor still has to look it over, make sure everything’s right and press Send. But just that act of pre-\npopulating the field, this person was saying it saves them a ton of time, like on the order of several hours a day.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nAnd if you have that, and you extrapolate to what if every doctor in America was saving themselves an hour or two \na day of responding to patient messages? I mean, that’s a radical productivity enhancement. And so you can say \nthat that’s just fancy autocomplete, and I guess on some level it is. But just having fancy autocomplete in these \npaperwork-heavy professions could be very important.\nEZRA KLEIN: Well, let me push that in two directions, because one direction is that I am not super thrilled about the \nidea that my doctor, theoretically here, is glancing over things and clicking “submit” as opposed to reading my \nmessage themselves and having to do the act of writing, which helps you think about things and thinking about \nwhat I actually emailed them and what kind of answer they need to give me. I mean, I know personally the \ndifference in thought between scanning things and editing and thinking through things. So that’s my diminishing \nresponse.\nBut the flip of it is the thing I’m not hearing anybody say here, and the thing I keep waiting for and being interested \nin is the things A.I. might be able to do better than my doctor. I was reading Jack Clark’s “Import A.I.” newsletter \ntoday, which I super recommend to people who want to follow advancements in the field, and he was talking about \na — I mean, it was a system being tested, not a system that is in deployment — but it was better at picking up \npancreatic cancer from certain kinds of information than doctors are.\nAnd I keep waiting to hear something like this going out into the field. Something that doesn’t just save people a bit \nof time around the edges. I agree that’s a productivity improvement. It’s fine. You can build a business around that. \nBut the promise of A.I. when Sam Altman sat with you all a few weeks ago, or however long it was, and said, we’re \nmoving to the best world ever, he didn’t mean that our paperwork is going to get a little bit easier to complete. He \nmeant we’d have cures for new diseases. He meant that we would have new kinds of energy possibilities. I’m \ninterested in the programs and the models that can create things that don’t exist.\nCASEY NEWTON: Well, to get there, you need systems that can reason. And right now the systems that we have \njust aren’t very good at reasoning. I think that over the past year we have seen them move a little away from the \nway that I was thinking of them a year ago, which was a sort of fancy autocomplete. It’s making a prediction about \nwhat the next word will be. It’s still true that they do it that way. But it is able to create a kind of facsimile of thought \nthat can be interesting in some ways.\nBut you just can’t get to where you’re going, Ezra, with a facsimile of thought. You need something that has \nimproved reasoning capabilities. So maybe that comes with the next generation of frontier models. But until then, I \nthink you’ll be disappointed.\nEZRA KLEIN: But do you need a different kind of model? This is something that lingers in the back of my head. So I \ndid an interview on the show with Demis Hassabis who’s the co-founder of DeepMind and now runs the integrated \nDeepMind Google A.I. program. And DeepMind had built this system a while back called AlphaFold, which treated \nhow proteins are constructed in 3-D space, which is to say in reality. We live in 3-D space. [LAUGHS] It treated it as \na game. And it fed itself a bunch of information and it became very good at predicting the structure of proteins. And \nthat solved this really big scientific problem. And they then created a subsidiary of Alphabet called Isomorphic Labs \nto try to build drug discovery on similar foundations.\nBut my understanding is that Google, during this period, became terrified of Microsoft and OpenAI beating it up in \nsearch and Office. And so they pulled a lot of resources, not least Hassabis himself, into this integrated structure to \ntry to win the chatbot wars, which is now what their system Bard is trying to do. And so when you said, Casey, that \nwe need things that can reason, I mean maybe. But also, you could say we need things that are tailored to solve \nproblems we care about more.\nAnd I think this is one of the things that worries me a bit, that we’ve backed ourselves into business models that are \nnot that important for humanity. Is there some chance of that? I mean, are we going too hard after language-based \ngeneral intelligent A.I. that, by the way, integrates very nicely into a suite of enterprise software as opposed to \nbuilding things that actually create scientific breakthroughs but don’t have the same kind of high scalability profit \nstructure behind them?\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nCASEY NEWTON: I would stick up for the people who are working on the what you could call the non-language \nproblems in A.I. right now. This stuff is going on. It maybe doesn’t get as much attention from people like the three \nof us as it should. But if you talk to folks in fields like pharmaceuticals and biotech, there are new A.I. biotech \ncompanies spinning up every day, getting funding to go after drug discovery or some more narrow application.\nWe talked to a researcher the other day, formerly of Google, who is teaching A.I. to smell. Taking the same \ntechniques that go into these transformer-based neural networks like ChatGPT and applying them to the molecular \nstructures of different chemicals, and using that to be able to predict what these things will smell like.\nAnd you might say, well, what’s the big deal with that? And the answer is that some diseases have smells \nassociated with them that we can’t pick up on because our noses aren’t as sensitive as, say, dogs or other animals. \nBut if you could train an A.I. to be able to recognize scent molecules and predict odors from just chemical \nstructures, that could actually be useful in all kinds of ways. So I think this kind of thing is happening. It’s just not \ndominating the coverage the way that ChatGPT is.\n[MUSIC PLAYING]\nEZRA KLEIN: Let me ask you, Kevin, about I think an interesting, maybe promising, maybe scary avenue for A.I. \nthat you possibly personally foreclosed, which is, at some point during the year, Microsoft gave you access to a \nOpenAI-powered chatbot that had this dual personality of Sydney. And Sydney tried to convince you you didn’t love \nyour wife and that you wanted to run away with Sydney. And my understanding is immediately after that happened, \neverybody with enough money to have a real business model an A.I. lobotomized the personalities of their A.I.s. \nThat was the end of Sydney.\nBut there are a lot of startups out there trying to do A.I. friends, A.I. therapists, A.I. sex bots, A.I. boyfriends and \ngirlfriends and nonbinary partners, just every kind of A.I. companion you can imagine. I’ve always thought this is a \npretty obvious way this will affect society, and the Sydney thing convinced me that the technology for it already \nexists. So where is that, and how are those companies doing?\nKEVIN ROOSE: Yeah, I mean, I’m sorry, A, if I did foreclose the possibility of A.I. personalities.\nI think what’s happening is it’s just a little too controversial and fraught for any of the big companies to wade into. \nMicrosoft doesn’t want its A.I. assistants and co-pilots to have strong personalities. That much is clear. And I don’t \nthink their enterprise customers want them to have strong personalities, especially if those personalities are \nadversarial, or confrontational, or creepy, or unpredictable in some way. They want Clippy but with real brain power.\nBut there are companies that are going after this more social A.I. market. One of them is this company Character \nA.I., which was started by one of the original people at Google who made the transformer breakthrough. And that \ncompany is growing pretty rapidly. They’ve got a lot of users, especially young users, and they are doing, \nessentially, A.I. personas. You can make your own A.I. persona and chat with it or you can pick from ones that \nothers have created.\nMeta is also going a little bit in this direction. They have these persona-driven A.I. chatbots. And all of these \ncompanies have put guardrails around — no one really wants to do the erotic — what they call erotic role-play, in \npart because they don’t want to run afoul of things like the Apple app store terms of service.\nBut I expect that that will also be a big market for young people. And anecdotally, I mean I have just heard from a \nlot of young people who already say, like, my friends have A.I. chatbot friends that they talk to all the time. And it \ndoes seem to be making inroads into high schools. And that’s just an area that I’ll be fascinated to track.\nCASEY NEWTON: I mean, this is going to be huge. A couple thoughts come to mind. One, I talked to somebody \nwho works at one of the leading A.I. companies, and they told me that 99 percent of people whose accounts they \nremove, they remove for trying to get it to write text-based erotica. So that, I think, speaks to the market demand for \nthis sort of thing.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nI’ve also talked to people who have used the models of this that are not constrained by any safety guidelines, and \nI’ve been told these things are actually incredible at writing erotica. So what I’m telling you is there is a $10 billion —\nEZRA KLEIN: So you’ve done really a lot of reporting on this, Casey. You’d say maybe a personal interest?\nCASEY NEWTON: I’m so interested in this. Look, I write about content moderation, and porn is the content \nmoderation frontier. And it’s just very interesting to me that it’s so clear that there are billions of dollars to be made \nhere and no company will touch it.\nAnd I asked one person involved, I said, well, why don’t you just let people do this? And they basically said, look, if \nyou do this, you become a porn company overnight. It overwhelms the usage — this is what people wind up using \nyour thing for and you’re working at a different company then. So I sort of get it.\nBut even setting aside the explicitly erotic stuff, Ezra, you well know and have talked and written about, just the \nloneliness epidemic that we have in this country. There’s a lot of isolated people in this world. And I think there is a \nvery real possibility that a lot of those people will find comfort and joy and delight with talking to these A.I.-based \ncompanions.\nI also think that when that happens, there will be a culture war over it. And we will see lengthy segments on Fox \nNews about how the Silicon Valley technologists created a generation of shut-ins who wants to do nothing but talk \nto their fake friends on their phones. So I do think this is the culture war yet to come, and the question is just when \ndo the enabling technologies get good enough and when do companies decide that they’re willing to deal with the \nblowback?\nEZRA KLEIN: I also think this is going to be a generational thing. I mean, I’m very interested in this and have been \nfor a bit, in part because I suspect, if I had to make a prediction here, my five-year-old is going to grow up with A.I. \nfriends. And my pat line is that today we worry that 12-year-olds don’t see their friends enough in person. And \ntomorrow we’ll worry that not enough of our 12-year-old’s friends are persons. Because it’s going to become \nnormal.\nAnd my sense is that the systems are really good. If you unleashed them, you are already good enough to \nfunctionally master this particular application. And the big players simply haven’t unleashed them. I’ve heard from \npeople at the big companies here who are like, oh, yeah, if we wanted to do this, we could dominate it.\nBut that does bring me to a question, which is Meta kind of does want to do this. Meta, which owns Facebook, \nwhich is a social media company. They seem to want to do it in terms of these lame-seeming celebrity avatars. You \ncan talk to A.I. Snoop Dogg.\nCASEY NEWTON: It’s so bad.\nEZRA KLEIN: But Meta is interesting to me because their A.I. division is run by Yann LeCun, who’s one of the most \nimportant A.I. researchers in the field, and they seem to have very different cultural dynamics in their A.I. shop than \nGoogle DeepMind or OpenAI. Tell me a bit about Meta’s strategy here and what makes them culturally different.\nKEVIN ROOSE: Well, Casey, you cover Meta and have for a long time and may have some insight here. My sense \nis that they are up against a couple problems, one of which is they have arrived to A.I. late and to generative A.I. \nspecifically. Facebook was, for many years, considered one of the top two labs along with Google when it came to \nrecruiting A.I. talent, to putting out cutting edge research, to presenting papers at the big A.I. conferences. They \nwere one of the big dogs.\nAnd then they had this funny thing happen where they released a model called Galactica just right before ChatGPT \nwas released last year. And it was supposed to be this L.L.M. for science and for research papers. And it was out \nfor I think three days. And people started noticing that it was making up fake citations.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nIt was hallucinating. It was doing what all the A.I. models do. But it was from Meta and so it felt different. It had this \ntarnish on it because people already worried about fake news on Facebook. And so it got pulled down. And then \nChatGPT, just shortly thereafter, launched and became this global sensation.\nSo they’re grappling for what to do with this technology that they’ve built now. There’s not a real obvious business \ncase for shoving A.I. chatbots into products like Facebook and Instagram. And they don’t sell enterprise software \nlike Microsoft does, so they can’t really shove it into paid subscription products. So my sense from talking with folks \nover there is that they’re just not sure what to do with this technology that they’ve built. And so they’re just flinging it \nopen to the masses. What do you think?\nCASEY NEWTON: That tracks with me. I basically don’t get it either. Basically what you’ve just said has been \nexplained to me. They are investing a ton with no obvious return on investment in the near term future. I will say \nthat these celebrity A.I. chatbots they’ve made are quite bad.\nEZRA KLEIN: Horrible.\nCASEY NEWTON: It’s truly baffling. And the thing is they’ve taken celebrities, but the celebrities are not playing \nthemselves in the A.I. They’ve given all of the celebrities silly names. And you can just follow their Instagram and \nsend them messages and say, hey, character that Snoop Dogg is portraying, like what do you think about this? So \nit’s all very silly. And I expect it’ll die a rapid death sometime in the next year and then we’ll see if they have a better \nidea.\nWhat I will say is if you’re somebody who wakes up from A.I. nightmares some mornings, as a lot of folks in San \nFrancisco do, go listen to Yann LeCun talk about it. No one has ever been more relaxed about A.I. than Yann \nLeCun. It’s just like an army of superhuman assistants are about to live inside your computer. They’re going to do \nanything you want to do and there’s no risk of them harming you ever. So if you’re feeling anxious, go listen to \nYann.\nEZRA KLEIN: Do you think he’s right? Because it also has led to a policy difference. Meta has been much more \nopen source in their approach, which OpenAI and Google seem to think is irresponsible. But there is something \nhappening there that I think is also built around a different view of safety. What is their view of safety? Why does \nYann LeCun, who is an important figure in this whole world, why is he so much more chill than, you know, name \nyour other founder?\nCASEY NEWTON: I mean, part of it is I just think these are deeply held convictions from someone who is an expert \non this space and who has been a pioneer and who understands the technology certainly far better than I do. And \nhe can just not see from here to killer robot. So I respect his viewpoint in that respect given his credentials in the \nspace.\nI think on the question of is open source A.I. safer, this is still an open question — not to pun. The argument for it \nbeing safer is, well, if it’s open source, that means that average people can go in and look at the code, and identify \nflaws, and see how the machine works, and they can point those out in public, and then they can be fixed in public.\nWhereas if you have something like OpenAI, which is building very powerful systems behind closed doors, we don’t \nhave the same kind of access. And so you might not need to rely on a government regulator to see how safe their \nsystems were. So that is the argument in favor of open source.\nOf course, the flip side of that is like, well, if you take a very powerful open source model and you put it out on the \nopen web, even if it’s true that anyone can poke holes and identify flaws, it’s also true that a bad actor could take \nthat model and then use it to do something really, really bad. So that hasn’t happened yet, but it certainly seems like \nit’s an obvious possibility at some time in the near future.\nEZRA KLEIN: Let me use that as a bridge to safety more generally. So we’ve talked a bit about where these \nsystems have gone over the past year, where they seem to be going. But there’s been a lot of concern that they are \nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nunsafe and fundamentally that they’ve become misaligned or that we don’t understand them or what they’re doing. \nWhat kind of breakthroughs have there been with all this investment and all this attention on safety, Kevin?\nKEVIN ROOSE: So a lot of work has gone into what is called fine-tuning of these models. So basically if you’re \nmaking a large language model, like GPT-4, you have several phases of that. Phase one is what’s called pre-\ntraining, which is just the basic process. You take all of this data. You shove it into this neural network and it learns \nto make predictions about the next word in a sequence.\nThen from there, you do what’s called fine-tuning. And that is basically where you are trying to turn the model into \nsomething that’s actually useful or tailored. Turn it into a chatbot. Turn it into a tool for doctors. Turn it into \nsomething for social A.I.s. That’s the process that includes things like reinforcement learning from human feedback, \nwhich is how a lot of the leading models are fine-tuned. And that work has continued to progress. The models, they \nsay, today are safer and less likely to generate harmful outputs than previous generations of models.\nThere’s also this field of interpretability, which is where I’ve been doing a lot of reporting over the past few months, \nwhich is this tiny subfield of A.I. that is trying to figure out what the guts of a language model look like and what is \nactually happening inside one of these models when you ask it a question or give it some prompt and it produces \nan output.\nAnd this is a huge deal, not only because I think people want to know how these things work — they’re not satisfied \nby just saying these are mystical black boxes — but also because if you understand what’s going on inside a \nmodel, then you can understand if, for example, the model starts lying to you or starts becoming deceptive, which is \na thing that A.I. safety researchers worry about. So that process of interpretability research I think is really \nimportant. There have been a few minor breakthroughs in that field over the past year, but it is still slow going and \nit’s still a very hard problem to crack.\nCASEY NEWTON: And I think it’s worth just pausing to underscore what Kevin said, which is the people building \nthese systems do not know how they work. They know at a high level, but there is a lot within that where if you \nshow them an individual output from the A.I., they will not be able to tell you exactly why it said what it said. Also, if \nyou run the same query multiple times, you’ll get slightly different answers. Why is that? Again, the researchers \ncan’t tell you.\nSo as we have these endless debates over A.I. safety, one reason why I do tend to lean on the side of the folks \nwho are scared is this exact point. At the end of the day, we still don’t know how the systems work.\nEZRA KLEIN: Tell me if this tracks for you. I think compared to a year ago, when I talked to the A.I. safety people, \nthe people who worry about A.I.s that become misaligned and do terrible civilizational-level damage, A.I.s that could \nbe really badly misused, they seem to think it has been actually a pretty good year, most of them.\nThey think they’ve been able to keep big models, like GPT-4, which, of course, are much less powerful than what \nthey one day expect to invent, but they think they’ve been pretty good at keeping them aligned. They have made \nsome progress on interpretability, which wasn’t totally clear a year ago. Many people said that was potentially not a \nproblem we could solve. At least we’re making some breakthroughs there.\nThey’re not relaxed — the people who worry about this. And they will often say we would need a long time to fully \nunderstand even the things we have now and we may not have that long. But nevertheless, I get the sense that the \nsafety people seem a little more confident that the technical work they’ve been doing is paying off than at least was \nthe impression I got from the reporting prior.\nCASEY NEWTON: I think that’s right. I mean, Sam Altman, in particular, this has been his strategy, is we are going \nto release this stuff that is in our labs and we’re going to wait and see how society reacts to it. And then we’ll give it \nsome time to let society address and then we will release the next thing. That’s what he thinks is the best way to \nslowly integrate A.I. into our lives.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nAnd if you’d asked me maybe 11 months ago, like a month into using ChatGPT, what are the odds of something \nreally, really bad happening because of the availability of ChatGPT, I would have put them much higher than they \nturned out to be. And when you talk to folks at OpenAI, they will tell you that that company really has taken A.I. \nsafety really seriously. You can see this yourself when you use the product. Ask it a question about sex, it basically \ncalls the police. So there is a lot to be said for how these systems have been built so far.\nKEVIN ROOSE: And I would say the other thing that I’ve heard from A.I. safety researchers is that they are feeling \nrelief not just that the world has not ended but that more people are now worried about A.I. It was a very lonely thing \nfor many years to be someone who worried about A.I. safety because there was no apparent reason to be worried \nabout A.I. safety, right? The chatbots that were out, it was like Siri and Alexa and they were terrible. And no one \ncould imagine that these things could become dangerous or harmful because the technology itself was just not that \nadvanced.\nNow you have congressional hearings. You have regulations coming from multiple countries. You have people like \nGeoff Hinton and Yoshua Bengio, two of the so-called godfathers of deep learning, proclaiming that they are \nworried about where this technology is headed. So I think for the people who’ve been working on this stuff for a long \ntime, there is some just palpable relief at like, oh, I don’t have to carry this all on my shoulders anymore. The world \nis now aware of these systems and what risks they could pose.\nEZRA KLEIN: One irony of it is that my read from talking to people is that A.I. safety is going better as a technical \nmatter than was expected and I think worse as a matter of governance and intercorporate competition and \nregulatory arbitrage than they had hoped.\nThere is a fear, as I understand it, that we could make the technical breakthroughs needed, but that the kind of \ncoordination necessary to go slow enough to make them, that’s where a lot of the fear is. I think they feel like that’s \nactually going worse, not better.\nCASEY NEWTON: So one of the big narratives coming out of Sam Altman’s firing was that it must have had \nsomething to do with A.I. safety. And based on my reporting and reporting shared by many others, this was not an \nA.I. safety issue. But it is very much the story that is being discussed about the whole affair.\nAnd the folks who are on the board who are associated with these A.I. safety ideas, they’ve taken a huge hit to their \npublic reputation because of the way they handled the firing and all of that. And so I think a really bad outcome of \nthis firing is that the A.I. safety community loses its credibility, even though A.I. safety, as far as we can tell, really \ndidn’t have a lot to do with what happened to Sam Altman.\nEZRA KLEIN: Yeah, I first agree that clearly A.I. safety was not behind whatever disagreements Altman and the \nboard had. I heard that from both sides of this. And I didn’t believe it, and I didn’t believe it, and I finally was \nconvinced of it. I was like, you guys had to have had some disagreement here? It seems so fundamental.\nBut this is what I mean the governance is going worse. All the OpenAI people thought it was very important, and \nSam Altman himself talked about its importance all the time, that they had this nonprofit board connected to this \nnonfinancial mission. The values of building A.I. that served humanity, that could fire Sam Altman at any time or \neven shut down the company fundamentally if they thought it was going awry in some way or another.\nAnd the moment that board tried to do that — now, I think they did not try to do that on very strong grounds — but \nthe moment they tried to do that, it turned out they couldn’t. That the company could fundamentally reconstitute \nitself at Microsoft or that the board itself couldn’t withstand the pressure coming back.\nI think the argument from the board side, the now mostly defunct board, is that this didn’t go as badly for them as \nthe press is reporting. That they brought in some other board members who are not cronies of Sam Altman and \nGreg Brockman. Sam Altman and Greg Brockman are not on the board now. There’s going to be investigation into \nAltman. So maybe they have a stronger board that is better able to stand up to Altman. That is one argument I have \nheard.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nOn the other hand, those stronger board members do not hold the views on A.I. safety that the board members who \nleft, like Helen Toner of Georgetown and Tasha McCauley from Rand, held. I mean, these are people who are \ngoing to be very interested in whether or not OpenAI is making money. I’m not saying they don’t care about other \nthings too, but these are people who know how to run companies. They serve on corporate boards in a normal way \nwhere the output of the corporate board is supposed to be shareholder value, and that’s going to influence them \neven if they understand themselves to have a different mission here. I mean, am I getting that story wrong to you?\nKEVIN ROOSE: No, I think that’s right. And it speaks to one of the most interesting and strangest things about this \nwhole industry is that the people who started these companies were weird. And I say that with no normative \njudgment. But they made very weird decisions.\nThey thought A.I. was exciting and amazing. They wanted to build A.G.I. But they were also terrified of it, to the \npoint that they developed these elaborate safeguards. I mean, in OpenAI’s case, they put this nonprofit board in \ncharge of the for-profit subsidiary and gave, essentially, the nonprofit board the power to push a button and shut \ndown the whole thing if they wanted to.\nAt Anthropic, one of these other A.I. companies, they are structured as a public benefit corporation. And they have \ntheir own version of a nonprofit board that is capable of essentially pushing the big red shut it all down button if \nthings get too crazy. This is not how Silicon Valley typically structures itself.\nMark Zuckerberg was not in his Harvard dorm room building Facebook thinking if this thing becomes the most \npowerful communication platform in the history of technology, I will need to put in place these checks and balances \nto keep myself from becoming too powerful. But that was the kind of thing that the people who started OpenAI and \nAnthropic were thinking about.\nAnd so I think what we’re seeing is that that kind of structure is bowing to the requirements of shareholder \ncapitalism which says that if you do need all this money to run these companies, to train these models, you are \ngoing to have to make some concessions to the powers of the shareholder and of the money. And so I think that \none of the big pieces of fallout from this OpenAI drama is just that OpenAI is going to be structured and run much \nmore like a traditional tech company than this kind of holdover from this nonprofit board.\nCASEY NEWTON: And that is just a sad story. I truly wish that it had not worked out that way. I think one of the \nreasons why these companies were built in this way was because it just helped them attract better talent. I think \nthat so many people working in A.I. are idealistic and civic-minded and do not want to create harmful things. And \nthey’re also really optimistic about the power that good technology has.\nAnd so when those people say that as powerful and good as these things could be, it could also be really \ndangerous, I take them really seriously. And I want them to be empowered. I want them to be on company boards. \nAnd those folks have just lost so much ground over the past couple of weeks. And it is a truly tragic development, I \nthink, in the development of this industry.\n[MUSIC PLAYING]\nEZRA KLEIN: One thing you could just say with that is, yeah, it was always going to be up to governments here, not \nup to strange nonprofit, corporate, semi-corporate structures. And so we actually have seen a huge amount of \ngovernment activity in recent weeks.\nAnd so I want to start here in the US. Biden announced a big package of a big executive order. You could call them \nregulations. I would call them pre-regulations. But Casey, how would you describe in sum what they did. What is the \nBiden administration’s approach that it is signaling to regulating A.I.?\nCASEY NEWTON: The big headline was if you are going to train a new model, so a successor to a GPT-4, and it \nuses a certain amount of energy — and the energy there is just a proxy for how powerful and capable this model \nmight be — you have to tell the federal government that you have done this, and you have to inform them what \nsafety testing you did on this model before releasing it to the public.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nSo that is the one break that they attempted to put on the development of this industry. It does not say you can’t \ntrain these models. It doesn’t specify what safety tests you have to do. It just says if you are going to go down this \nroad, you have to be in touch with us. And that will, I think, slightly decelerate the development of these models.\nI think critics would say it also pushes us a little bit away from a more open source version of A.I. That open source \ndevelopment is chaotic by its nature, and if you want to do some giant open source project that would compete with \nthe GPTs of the world, that would just be harder to do. But to me those were the big takeaways.\nEZRA KLEIN: One of the things that struck me looking at the order was go back a year, go back two years, I think \nthe thing that people would have said is that the government doesn’t understand this at all. It can barely be \nconversant in technology. People remember Senator Orrin Hatch asking Mark Zuckerberg, well, if you’re not \nmaking people pay, then how do you make money?\nWhen I read the order and looked at it, this actually struck me as pretty seriously engaged. For instance, there’s a \nbig debate in the A.I. world about whether or not you’re going to regulate based on the complexity and power of the \nmodel or the use of the model. You have a fear about what happens if you’re using the model for medical decisions. \nBut if you’re just using it as your personal assistant, who cares?\nWhereas, the A.I. safety people have the view that, no, no, no, the personal assistant model might actually be the \nreally dangerous one because that’s the one that knows how to act in the real world. And the Biden administration \ntakes a real — it actually takes a view of the A.I. safety people. If you have a model over a certain level of \ncomputing complexity, they want this higher level of scrutiny, higher level of disclosure on it. They want everything \nthat comes from an A.I. to be watermarked in some way so you can see that it is A.I.-generated.\nThis struck me as the Biden administration actually clearly having taken this seriously and having convened some \nset of group of stakeholders and experts that knew what they were doing.\nI mean, I don’t necessarily agree with literally every decision and a lot of it is just asking for reports. But when you \nthink about it as a framework for regulation, it didn’t read to me as a framework coming from people who had not \nthought about this for 10 minutes.\nCASEY NEWTON: Absolutely. I was quite impressed. I had a chance to meet with Ben Buchanan at the White \nHouse who worked on this, talked to him about this stuff. And it is clear that they have been reading everything. \nThey’ve been talking to as many people as they can. And they did arrive in a really nuanced place.\nAnd I think when you look at the reaction from the A.I. developers in general, it was mostly neutral to lightly positive, \nright? There was not a lot of blowback. But at the same time, folks in civic society I think were also excited that the \ngovernment did have a point of view here and had done its own work.\nKEVIN ROOSE: Yeah, it struck me as a very deft set of — I think I would agree that they’re more like pre-\nregulations than regulations. And to me it sounded like what the Biden White House was trying to do was throw a \nfew bones to everyone.\nWe’re going to throw a few bones to the A.I. safety community who worries about foundation models becoming too \npowerful. We’re going to throw some bones to the A.I. harms community that is worried about things like bias and \ninaccuracy. And we’re going to throw some bones to the people who worry about foreign use of A.I. So I saw it as a \nvery deliberate attempt to give every camp in this debate a little to feel happy about.\nEZRA KLEIN: One of the things it raised for me as a question, though, was did it point to a world where you think \nthat regulators are going to be empowered to actually act? This was the thing I was thinking about after the board \ncollapse. You imagine a world sometime in the future where you have OpenAI with GPT 6 or Meta or whomever, \nand they are releasing something that the regulator is looking at the safety data, looking at what’s there.\nThey’re just itchy about it. It’s not obviously going to do a ton of harm, but they’re not convinced it’s safe. They’ve \nseen some things that worry them. Are they really going to have the power to say, no, we don’t think your safety \nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\ntesting was good enough, when this is a powerful company, when they won’t be able to release a lot of the \nproprietary data, right?\nThe thing where the board could not really explain why they were firing Sam Altman struck me as almost going to \nbe the situation of virtually every regulator trying to think about the future harms of a model. If you’re regulating in \ntime to stop the thing from doing harm, it’s going to be a judgment call. And if it’s a judgment call, it’s going to be a \nvery hard one to make. And so if we ever got to the point where somebody needed to flip the switch and say no, \ndoes anybody actually have the credibility to do it?\nOr is what we’ve seen, that, in fact, these very lauded, successful companies run by smart people who have huge \nTwitter followings or Threads followings or whatever they end up being on, that they actually have so much public \npower that they’ll always be able to make the case for themselves. And the political economy of this is actually that \nwe better just hope the A.I. companies get it right because nobody’s really going to have the capability to stand in \nfront of them.\nCASEY NEWTON: When you talk to folks who are really worried about A.I. safety, they think that there is a high \npossibility that at some point, in let’s say the next five years, A.I. triggers some sort of event that kills multiple \nthousands of people. What that event could be, we could speculate. But assume that that is true, I think that \nchanges the political debate a lot. All of a sudden you start to see jets get scrambled. Hopefully that never happens, \nbut I think that will be the inciting moment.\nAnd this is the thing that just frustrates me as somebody who writes about tech policy is we just live in a country that \ndoesn’t pass laws. There are endless hearings, endless debates. And then it gets time to regulate something and \nit’s like, well, yeah, they can regulate A.I., but it’s going to be based on this one regulation that was passed to deal \nwith the oat farming crisis of 1906 and we’re just going to hope that it applies.\nAnd it’s like, we should pass new laws in this country. I don’t know that there’s a law that needs to be passed today \nto ensure that all of this goes well, but certainly Congress is going to need to do something at some point as this \nstuff evolves.\nKEVIN ROOSE: I mean, one thing I was thinking about as this whole situation at OpenAI was playing out was \nactually the financial crisis in 2008 and the scenes that were captured in books and movies where you have the \nheads of all the investment banks and they’re scrambling to avoid going under.\nAnd they’re meeting in these boardrooms with people like Ben Bernanke, the Chair of the Federal Reserve. And the \ngovernment actually had a critical role there in patching together the financial system because they were interested, \nnot in which banks survived and which failed, but in making sure that there was a banking system when the markets \nopened the next Monday.\nAnd so I think we just need a new regulatory framework that does have some kind of — the clichéd word would be \nstakeholder. But someone who is in there as a representative of the government who is saying, what is the \nresolution to this conflict that makes sense for most Americans or most people around the world?\nEZRA KLEIN: When you looked at who the government gave power to in this document, when you think about who \nmight play a role like that, when you need to call the government on A.I., the way I read it is it spread power out \nacross a lot of different agencies. And there were places where it invested more rather than less.\nBut one thing that different people have called for that I didn’t see it do, in part because you would actually need to \npass a law to do this, was actually create the A.I. Department, something that is funded and structured and built to \ndo this exact thing, to be the central clearinghouse inside the government, to be led by somebody who would be the \nmost credible on these issues and would maybe have then the size and strength to do this kind of research.\nThe thing that is in my head here, because I find your analogy really compelling, Kevin, is the Federal Reserve. The \nFederal Reserve is a big institution. And it has a significant power of its own in terms of setting interest rates. It also \ndoes a huge amount of research. When you think about where would a public option for A.I. come from, you would \nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nneed something like that that has the money to be doing its own research and hiring really excellent people. In that \ncase, economists. In this case, A.I. researchers.\nAnd there was nothing like that here. It was an assertion that we more or less have the structure we need. We more \nor less have the laws we need. We can apply all those things creatively. But it did not say this is such a big deal that \nwe need a new institution to be our point person on it.\nKEVIN ROOSE: Yeah, I mean, I think that’s correct. I think there are some reasons for that. But I think you do want \na government that has its own technological capacity when it comes to A.I. Previous waves of innovation, certainly \nnuclear power during the Manhattan Project, but also things like the internet came out of Darpa. These are areas \nwhere the government did have significant technical expertise and was building its own technology in competition \nwith the private sector.\nThere is no public sector equivalent of ChatGPT. The government has not built anything even remotely close to \nthat. And I think it’s worth asking why that is and what would need to happen for the government to have its own \ncapacity, not just to evaluate and regulate these systems, but to actually build some of their own.\nEZRA KLEIN: I think it is genuinely strange, on some level, that given how important this is, there is not a bill \ngathering steam. Look, if the private sector thinks it is worth pumping $50 or $100 billion into these companies so \nthey can help you make better enterprise software, it seems weird to imagine that there are not public problems that \nhave an economic value that is equal to that or significantly larger.\nAnd we may just not want to pay that money. Fine. But we do that for infrastructure, right? I mean, we just passed a \ngigantic infrastructure bill. And if we thought of A.I. like infrastructure — we actually also spend a lot of money on \nbroadband now — it seems to me you’d want to think about it that way.\nAnd I think it is a kind of fecklessness and cowardice on the part of the political culture that it no longer thinks itself \ncapable of doing things like that. At the very least — and I’ve said this I think on your show probably — I think they \nshould have prize systems where they say a bunch of things they want to see solved, and if you can build an A.I. \nsystem that will solve them, they’ll give you $1 billion.\nBut the one thing is the government does not like to do things and spend money for an uncertain return. And \nbuilding a giant A.I. system is spending a lot of money for an uncertain return. And so the only part of the \ngovernment that’s probably doing something like it is the Defense Department in areas that we don’t know. And that \ndoes not make me feel better. That makes me feel worse. [LAUGHS] That’s my take on that.\nKEVIN ROOSE: Yeah, I mean, I think there’s also a piece of this that has to do with labor and talent. There are \nprobably on the order of several thousand people in the world who can oversee the building, training, fine-tuning, \ndeployment of large language models. It is a very specific skill set. And the people who have it can make gobs of \nmoney in the private sector working wherever they want to.\nThe numbers that you hear coming out of places like OpenAI for what engineers are being paid there — I mean, it’s \nlike NFL-level football compensation packages for some of their people. And the government simply can’t or won’t \npay that much money to someone to do equivalent work for the public sector. Now, I’m not saying they should be \npaying engineers millions of dollars of taxpayer money to build these things, but that’s what you would need to do if \nyou wanted to compete in an open market for the top A.I. talent.\nEZRA KLEIN: I am saying they should. I am saying this is the fecklessness and cowardice point. This is stupid.\nKEVIN ROOSE: You think there should be A.I. engineers working for the federal government making $5 million a \nyear?\nEZRA KLEIN: Look, maybe not $5 million a year. But it would — this thing that we don’t think civil servants should \nmake as much as people in the private sector because — I don’t know — somebody at a congressional hearing is \ngoing to stand and be like, that person is making a lot of money, that is a way we rob the public of value.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nIf Google’s not wrong, Microsoft is not wrong that you can create things that are of social value through A.I., and if \nyou believe that, then leaving it to them — I mean, they intend to make a profit. Why shouldn’t the public get great \ngains from this? It won’t necessarily be through profit. But if we could cure different diseases or make big advances \non energy — this way of thinking is actually to me the really significant problem.\nI’m not sure you would need to pay people as much as you’re saying because I actually do think a lot of — I mean, \nwe both know the culture of the A.I. people. And at least up until a year or so ago, it was weird. And a lot of them \nwould do weird things and are not living very lush lives. They’re in group houses with each other, taking \npsychedelics, and working on A.I. on the weekdays. But I think you could get people in to do important work and \nyou should.\nNow, look, you don’t have the votes to do stuff like this. I think that’s the real answer. But in other countries, they will \nand do. When Saudi Arabia decides that it needs an A.I. to be geostrategically competitive, it will take the money it \nmakes from selling oil to the world, and in the same way that it’s currently using that money to hire sports stars, it \nwill hire A.I. engineers for a bazillion dollars. And it will get some of them and then it will have a decent A.I. system \none day. I don’t know why we’re waiting on other people to do that. We’re rich. It’s stupid.\nCASEY NEWTON: I agree with you, Ezra. And I’m sorry that Kevin is so resistant to your ideas because I think \npaying public servants well would do a lot of good for this country.\nKEVIN ROOSE: Look, I think public servants should be paid well.\nI’m just saying when Jim Jordan gets up and grills the former DeepMind engineer about why the Labor Department \nis paying them $2.6 million to fine-tune language models, I’m not sure what the answer is going to be.\nEZRA KLEIN: No, I agree with you. I mean — but I think we’re all saying, in a way, the same thing. This is a \nproblem. Government by dumb things Jim Jordan says is not going to be a great government that takes advantage \nof opportunities for the public good. And that sucks. It would be better if we were doing this differently and if we \nthought about it differently.\nLet me ask about China. Because China is where, on the one hand, at least on paper, the regulations look much \ntougher. So one version is maybe they’re regulating A.I. much more strictly than we are. Another view that I’ve \nheard is that, in fact, that’s true for companies, but the Chinese government is making sure that it’s building very, \nvery strong A.I.s. To the extent you all have looked at it, how do you understand the Chinese regulatory approach \nand how it differs from our own?\nCASEY NEWTON: I mean, I’ve looked at it mostly from the standpoint of what are the consumer-facing systems \nlook like. It has only been I think a couple of months since China approved the first consumer usable ChatGPT \nequivalent. As you might imagine, they have very strict requirements as far as what the chatbot can say about \nTiananmen Square. So they wind up being more limited maybe than what you can use in the United States. As far \nas what is happening behind closed doors, and for their defense systems and that sort of thing, I’m in the dark.\nKEVIN ROOSE: So four or five years ago, when I started reporting a book about A.I., the conventional wisdom \namong A.I. researchers was that China was ahead and they were going to make all of the big breakthroughs and \nbeat the U.S. technology companies when it came to A.I.\nSo it’s been very surprising to me that in the past year since ChatGPT has come out, we have not seen anything \neven remotely close to that level of performance coming out of a Chinese company. Now, I do think they are \nworking on this stuff. But it’s been surprising to me that China has been mostly absent from the frontier A.I. \nconversation over the past year.\nEZRA KLEIN: And do you think those things are related? Do you think that the Chinese government’s risk aversion \nand the underperformance of at least the products and systems we’ve seen in China — I mean, there might be \nthings we don’t know about — do you think those things are connected?\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nKEVIN ROOSE: Absolutely. I think you do need a risk appetite to be able to build and govern these systems \nbecause they are unpredictable. We don’t know exactly how they work. And what we saw, for example, with \nMicrosoft was that they put out this Bing Sydney chatbot and it got a lot of attention and blowback. And people \nreported all these crazy experiences. And in China, if something like that had happened, they might have shut the \ncompany down. Or it might have been deemed such an embarrassment that they would have radically scaled back \nthe model.\nAnd instead what Microsoft did was just say, we’re going to make some changes to try to prevent that kind of thing \nfrom happening, but we’re keeping this model out there. We’re going to let the public use it. And they’ll probably \ndiscover other crazy things, and that’s just part of the learning process. That’s something that I’ve been convinced \nof over the past year talking with A.I. executives and people at these companies is that you really do need some \ncontact with the public before you start learning everything that these models are capable of and all the ways that \nthey might misbehave.\nEZRA KLEIN: What is the European Union trying to do? They’ve had draft regulations that seemed very expansive. \nWhat has been the difference in how they’re trying to regulate this versus how we are? And what in your \nunderstanding is the status of their effort?\nCASEY NEWTON: Europe was quite ahead with developing its A.I. Act, but it was written in a pre-ChatGPT world. \nIt was written in a pre-generative A.I. world. And so over the past year, they’ve been trying to retrofit it so that it \nkind of reflects our new reality and is caught up in debate in the meantime.\nBut my understanding is the A.I. Act is not particularly restrictive on what these companies can do. So to my \nunderstanding, there’s nothing in the A.I. Act that is going to prevent these next generation technologies from being \nbuilt. It’s more about companies being transparent.\nKEVIN ROOSE: Let me add a little bit of flavor to that because I was in Europe just recently talking with some \nlawmakers. And one of the things that people will say about the A.I. Act is that it has this risk-based framework \nwhere different A.I. products are evaluated and regulated based on these classifications of, this is a low-risk \nsystem, or this is a high-risk system, or this is a medium-risk system. So different rules apply based on which of \nthose buckets a new tool falls into.\nAnd so right now what a lot of regulators and politicians and companies and lobbyists in Europe are arguing about \nis what level of risk should something like a foundation model, a GPT-4, a Bard, a Claude — are those low-risk \nsystems because they’re just chatbots or are they high-risk systems because you can build so many other things \nonce you have that basic technology? And so that’s what my understanding is of the current battle in Europe is over \nwhether foundation models, frontier models, whatever you want to call them, whether those should be assigned to \none risk bucket or another.\nEZRA KLEIN: I think that’s a good survey of the waterfront. And so I guess I’ll end on this question, which is, all \nright, we’re talking here at the one-year anniversary, roughly, of ChatGPT. If you were to guess, if we were having \nanother conversation a year from now on the two-year anniversary, what do you think would have changed? What \nare one or two things each of you think is likely to happen over the next year that did not happen this year?\nKEVIN ROOSE: I think all communication-based work will start to have an element of A.I. in it. All email, all \npresentations, office work, essentially, A.I. will be built into all the applications that we use for that stuff. And so it’ll \njust be part of the background just like autocomplete is today when you’re typing something on your phone.\nCASEY NEWTON: I would say that A.I. is going to continue to hollow out the media industry. I think you’re going to \nsee more publishers turning to these really bad services that just automate the generation of copy. You’ll see more \ncontent farms springing up on the web. It’ll reduce publisher revenue and we’ll just see more digital media \nbusinesses either get sold or quietly go out of business.\nAnd that’s just going to go hand-in-hand with the decline of the web in general. A year from now, more and more \npeople are going to be using ChatGPT and other tools as their front door to internet knowledge. And that’s just \nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\ngoing to sap a lot of life out of the web as we know it. So we don’t need one more technological breakthrough for \nany of that to happen. That’s just a case of consumer preferences taking a while to change. And I think it’s well \nunderway.\nEZRA KLEIN: So do you think, then, that next year, we’re going to see something that has been long predicted, \nwhich is significant A.I.-related job losses? Is that the argument you’re making here?\nCASEY NEWTON: I think that to some degree it already happened this year in digital media. And yes, I do think it \nwill start to pick up. Just keep in mind, 12 months is not a lot of time for every single industry to ask itself, could I get \naway with 5 percent or 10 percent or 15 percent fewer employees? And as the end of this year comes around, I \nhave to believe that in lots and lots of industries, people are going to be asking that question.\nKEVIN ROOSE: Yeah, I agree. I don’t know whether there will be one year where all the jobs that are going to \nvanish vanish. I think it’s more likely to be a slow trickle over time. And it’s less likely to be mass layoffs than just \nnew entrants that can do the same work as incumbents with many fewer people. The software development firm \nthat only needs five coders because all their coders are using A.I. and they have software that is building itself, \ncompeting with companies that have 10,000 engineers and doing so much more capably.\nSo I don’t think it’s going to necessarily look like all the layoffs hit on one day, or in one quarter, or even in one year. \nBut I do think we’re already seeing displacement of jobs through A.I.\nEZRA KLEIN: Those are kind of dark predictions. I mean, we’ll have a little bit better integration of A.I. into office \ntools and also we’ll begin to see really the productivity improvements create job losses. Is there anything that you \nthink is coming down the pike technologically that would be really deeply to the good, things that are not too far \nfrom fruition that you think will make life a lot better for people?\nCASEY NEWTON: I mean, I love the idea of universal translators. It’s already pretty good using A.I. to speak in one \nlanguage and get output in another. But I do think that’s going to enable a lot of cross-cultural communications. And \nthere are a lot of products remaining to be built that will essentially just drop the latency so that you can talk and \nhear in real time and have it be quite good. So that’s something that makes me happy.\nKEVIN ROOSE: And I’m hopeful that we will use A.I. — not we as in me and Casey and —\nCASEY NEWTON: But we might. [LAUGHS]\nKEVIN ROOSE: This would be sort of a career change for us. But we, as in society, I have some hope that we will \nuse A.I. to cure one of the top deadliest diseases — cancer, heart disease, Alzheimer’s, things like that that really \naffect massive numbers of people.\nI don’t have any inside reporting that we are on the cusp of a breakthrough, but I know that a lot of energy and \nresearch and funding is going into using A.I. to discover new drugs and therapies for some of the leading killer \ndiseases and conditions in the world. And so when I want to feel more optimistic, I just think about the possibility \nthat all of that bears fruit sometime in the next few years. And that’s pretty exciting.\nEZRA KLEIN: All right, and then always our final question. What are a few books you would each recommend to the \naudience or at least recommend the audience ask ChatGPT to summarize for them?\nCASEY NEWTON: Kevin, you want to go first?\nKEVIN ROOSE: Sure. I actually have two books and a YouTube video. The two books, one of them is called \n“Electrifying America” by David E. Nye. It is a 30-year-old history book about the process by which America got \nelectricity. And it has been very interesting to read. I read it first a few years ago and have been rereading it just to \nsketch out what would it look like if A.I. really is the new electricity? What happened the last time society was \ntransformed by a technology like this?\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\nThe other book I’ll recommend is “Your Face Belongs to Us” by my colleague — our colleague at “The Times,” \nKashmir Hill, which is about the facial recognition A.I. company Clearview AI. and is one of the most compelling \ntech books I’ve read in a few years.\nAnd then the YouTube video I’ll recommend was just posted a few days ago. It’s called “Intro to Large Language \nModels.” It’s made by Andre Karpathy who is an A.I. researcher actually at OpenAI. And it’s his one-hour \nintroduction to what is a large language model and how does it work. And I’ve just found it very helpful for my own \nunderstanding.\nEZRA KLEIN: Casey?\nCASEY NEWTON: Well, Ezra, with permission, and given that Kevin has just given your listeners two great books \nand a YouTube video to read, I would actually like to recommend three newsletters, if I could. And the reason is \nbecause the books that were published this year did not help me really understand the future of the A.I. industry. \nAnd to understand what’s happening in real time, I really am leaning on newsletters more than I’m leaning on \nbooks. So is that OK?\nEZRA KLEIN: Yeah, go for it.\nCASEY NEWTON: All right. So the first one, cruelly, you already mentioned earlier in this podcast. It’s Import AI \nfrom Jack Clark. Jack co-founded Anthropic, one of the big A.I. developers. And it is fascinating to know which \npapers he’s reading every week that are helping him understand this world. And I think that they’re arguably having \nan effect on how Anthropic is being created because he is sitting in all of those rooms. So that is just an incredible \nweekly read.\nI would also recommend AI Snake Oil from the Princeton Professor Arvind Narayanan and a Ph.D. student at \nPrinceton, Sayash Kapoor. They’re very skeptical of A.I. hype and doomsday scenarios, but they also take the \ntechnology really seriously and have a lot of smart thoughts about policy and regulation.\nAnd then the final one is Pragmatic Engineer by this guy Gergely Orosz. He’s this former Uber engineering \nmanager. And he writes about a lot of companies, but he writes about them as workplaces. And I love when he \nwrites about OpenAI as a workplace. He interviews people there about culture and management and process. And \nhe just constantly reminds you they are just human beings, showing up to the office every day and building this \nstuff. And it’s just a really unique viewpoint on that world.\nSo read those three newsletters. You’ll have a little better sense of what’s coming for us in the future.\nKEVIN ROOSE: What Casey didn’t say is that he actually hasn’t read a book in 10 years.\nSo it was a bit of a trick question.\nCASEY NEWTON: [LAUGHS] You know what I will say? I did read “Your Face Belongs to Us” by Kash. An \nincredible book. Definitely read that one.\nKEVIN ROOSE: Sure you did.\nEZRA KLEIN: There you go. Casey Newton, Kevin Roose, your podcast, which requires very little reading, is “Hard \nFork.”\nThank you all for being on the show.\nKEVIN ROOSE: It’s the first illiterate podcast, actually, put out by “The New York Times.” Thank you for having us.\nCASEY NEWTON: Thanks, Ezra.\nEZRA KLEIN: Thanks, guys.\nTranscript: Ezra Klein Interviews Casey Newton and Kevin Roose The Ezra Klein Show\n[MUSIC PLAYING]\nThis episode of “The Ezra Klein Show” was produced by Rollin Hu. Fact checking by Michelle Harris with Kate \nSinclair and Mary Marge Locker. Our senior engineer is Jeff Geld. Our senior editor is Claire Gordon. The show’s \nproduction team also includes Emefa Agawu and Kristin Lin. Original music by Isaac Jones. Audience strategy by \nKristina Samulewski and Shannon Busta. The executive producer of New York Times Opinion Audio is Annie-Rose \nStrasser. And special thanks to Sonia Herrero.\n[MUSIC PLAYING]\nLoad-Date: December 1, 2023"
    },
    {
        "file_name": "New_York_Observer_Mar2024",
        "header": "SXSW: Google, J.Crew Execs Discuss Online Shopping In the Age of A.I.",
        "media": "New York Observer",
        "time": "March 11, 2024",
        "section": "",
        "length": "422 words",
        "byline": "Nhari Djan",
        "story_text": "SXSW: Google, J.Crew Execs Discuss Online Shopping In the Age of A.I.\nNew York Observer\nMarch 9, 2024 Saturday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 422 words\nByline: Nhari Djan\nBody\nArtificial intelligence (A.I.) is affecting every industry. In retail, A.I. means an increasingly personalized experience \nfor shoppers. Tech giants and traditional retail companies are using the technology to create as close of a shopping \nexperience online as a person can get in a store. At this year's SXSW, Lilian Rincon, Google (GOOGL)'s director of \nconsumer shopping, and Danielle Schmelkin, the chief intelligence officer at J.Crew, discussed how they aimed to \nachieve that for their respective companies. \nDuring a presentation yesterday (March 8), Rincon spoke about existing \"gaps\" in online shopping between \ncustomer satisfaction and the products they purchase. She cited data showing that as much as 60 percent of online \nshoppers return a purchase because it doesn't meet their expectation and more than half of shoppers \"don't feel \nrepresented when they go online.\"\nRincon demonstrated technology from Google's try-on feature, which uses A.I. to show how clothing would look on \nmodels of different shapes, sizes, skin tones and genders. For her, A.I. can be used to effectively show how clothes \nand fabric move and mold to the contours of different body types. The feature can also show the clothes look in \ndifferent poses. Merchants only need to take pictures of a clothing item on a flat surface, and Google's generative \nA.I. will then turn it into an image showing a person wearing the item. \nJ.Crew's Schmelkin pointed out that A.I. can help improve discoverability for shoppers. Oftentimes, a shopper can't \nfind the item that they're looking for because they are using a different or wrong set of search terms, according to \nthe intelligence officer. Attaching more attributes to the clothes will make them easier for customers to find. \n\"What we want to do is augment every one of our products with probably close to 90 attributes and synonyms,\" \nSchmelkin said. \"Because we're finding more and more people are getting a lot looser in how they're searching for \nthings, we want to make sure you can find what you're looking for, this helps us tremendously.\" \nThe two executives are also thinking about how Gen Z will shop with A.I. According to Rincon, the age group of 11-\n26 sees shopping as a form of entertainment. This demographic group also takes to visual searching, or searching \nwith their phone cameras, instead of typing in keywords.\n\"Ten years ago, a lot of it was text. Now we see lens actually being much more popular,\" Rincon observed. \"A lot of \nthe younger generation is actually searching with their camera.\"\nLoad-Date: March 11, 2024"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Altman Out At OpenAI, Board Says In Blog Post",
        "media": "The New York Times",
        "time": "November 18, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1237 words",
        "byline": "By Cade Metz",
        "story_text": "Altman Out At OpenAI, Board Says In Blog Post\nThe New York Times\nNovember 18, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1237 words\nByline: By Cade Metz\nBody\nMira Murati, who previously served as chief technology officer, has been named interim chief executive.\nSam Altman, the high-profile chief executive of OpenAI, who became the face of the tech industry's artificial \nintelligence boom, was pushed out of the company by its board of directors, OpenAI said in a blog post on Friday \nafternoon. \n  The move set off a reshuffling at OpenAI, a groundbreaking A.I. company and the maker of the popular chatbot \nChatGPT. Mira Murati, previously OpenAI's chief technology officer, was named interim chief executive officer, the \ncompany said. Hours later, Greg Brockman, the company's president, said he was quitting.\n  ''Mr. Altman's departure follows a deliberative review process by the board, which concluded that he was not \nconsistently candid in his communications with the board, hindering its ability to exercise its responsibilities,'' the \ncompany said. ''The board no longer has confidence in his ability to continue leading OpenAI.''\n  Leaving OpenAI is a stunning fall for Mr. Altman, 38, who over the last year had become one of the tech industry's \nmost prominent executives as well as one of its most fascinating characters. Last fall, OpenAI launched an \nindustrywide A.I. frenzy when it released ChatGPT.\n  It was not immediately clear what had led to the board's decision beyond what its statement said. Mr. Altman could \nnot be immediately reached for comment. In a post to X, formerly Twitter, he wrote: ''i loved my time at openai. it \nwas transformative for me personally, and hopefully the world a little bit. most of all i loved working with such \ntalented people. will have more to say about what's next later.''\n  In a post to X Friday evening, Mr. Brockman said that he and Mr. Altman had no warning of the board's decision. \n''Sam and I are shocked and saddened by what the board did today,'' he wrote. ''We too are still trying to figure out \nexactly what happened.''\n  Mr. Altman was asked to join a video meeting with the board at noon on Friday and was immediately fired, \naccording to Mr. Brockman. Mr. Brockman said that even though he was the chairman of the board, he was not part \nof this board meeting. \n  He said that the board informed him of Mr. Altman's ouster minutes later.  Around the same time, the board \npublished a blog post.\n  A longtime tech entrepreneur, Mr. Altman helped found OpenAI with the financial backing of Elon Musk in 2015. \nHe steered the small San Francisco company into rare territory -- a technology leader funded by billions of dollars \nfrom Microsoft and envied by Silicon Valley giants like Google and Meta, Facebook's parent company.\nAltman Out At OpenAI , Board Says In Blog Post\n  Mr. Altman also became a spokesman for the tech industry's shift toward A.I., testifying before Congress and \ncharming lawmakers and regulators around the world. Many in the industry believe A.I. is the biggest technology \nshift in generations, and no one has done more to generate mainstream enthusiasm for it than Mr. Altman.\n  On Thursday evening, Mr. Altman appeared at an event in Oakland, Calif., where he discussed the future of art \nand artists now that artificial intelligence can generate images, videos, sounds and other forms of art on its own. \nGiving no indication that he was leaving OpenAI, he repeatedly said he and the company would continue to work \nalongside artists and help to ensure their future would be bright.\n  Earlier in the day, he appeared at the Asia-Pacific Economic Cooperation CEO Summit in San Francisco with \nLaurene Powell Jobs, who is the founder and president of the Emerson Collective, and executives from Meta and \nGoogle.\n  Mr. Brockman, who helped found OpenAI alongside Mr. Altman, said in a post on X that he was quitting. The \ncompany said earlier in the day that he would step down as chairman of the board but remain as president, \nreporting to the chief executive.\n  Reached by phone, Mr. Brockman declined to comment. From OpenAI's earliest days, he had been instrumental \nin shaping both its mission and its day-to-day operations.\n  When OpenAI released ChatGPT last November, the chatbot attracted hundreds of millions of users, wowing \npeople with the way it answered questions, wrote poetry and discussed almost any topic tossed its way.\n  After the chatbot's success, the wider tech industry embraced what is called generative artificial intelligence -- \ntechnologies that can generate text, images and other media on their own. The result of more than a decade of \nresearch inside companies like OpenAI and Google, these technologies are poised to remake everything from email \nprograms to internet search engines to digital tutors.\n  OpenAI is in talks to close a new funding round that would value the company at more than $80 billion -- nearly \ntriple its valuation less than a year ago -- and it is unclear what Mr. Altman's departure will mean for those talks.\n  But his removal is a blow to Microsoft, which has invested $13 billion in OpenAI and has what amounts to a 49 \npercent stake in the company. Satya Nadella, Microsoft's chief executive, introduced an expansive plan this year to \nuse the technology developed at OpenAI in nearly all of Microsoft's products, from the Bing search engine to its \nwidely used business software. Mr. Altman joined him at a press event to announce the plans.\n  Microsoft said on Friday afternoon that it planned to continue to work closely with OpenAI. Mr. Nadella said in a \nstatement that the company's long-term agreement with OpenAI provided Microsoft ''full access to everything we \nneed to deliver on our innovation agenda and an exciting product road map.'' He added that the company remained \ncommitted ''to our partnership, and to Mira and the team.''\n  Microsoft's stock price fell more than 1 percent in the last 30 minutes of trading, after Mr. Altman's departure was \nannounced. \n  In a message to OpenAI employees viewed by The New York Times, Ms. Murati said that she had talked with Mr. \nNadella and Microsoft's chief technology officer, Kevin Scott, on Friday and that they remained supportive of \nOpenAI.\n  ''We are now at a crucial juncture where our tools are being widely adopted, developers are actively building on \nour platforms and policymakers are deliberating on the best ways to regulate these systems,'' she wrote. ''It's more \nimportant than ever that we stay focused, driven and true to our core values.''\n  OpenAI's four-member board of directors is a mix of respected A.I. researchers, tech executives and A.I. policy \nexperts, including Ilya Sutskever, the company's chief scientist and co-founder, and Adam D'Angelo, chief executive \nof the question-and-answer site Quora. The board members could not be immediately reached for comment.\nAltman Out At OpenAI , Board Says In Blog Post\n  Current and former OpenAI employees were shocked by the news. As recently as Friday morning, they were \ndiscussing Mr. Altman as if he had a long future with the company. Researchers, entrepreneurs and investors \noutside the company were equally surprised, with many scrambling to determine why the OpenAI board had made \nits decision.\n  Jack Altman, one of Mr. Altman's younger brothers and the chief executive of the business software start-up \nLattice, defended his sibling on X.\n  ''More important than being one of the most brilliant and impactful people our industry has ever had,'' he wrote, \n''Sam is one of the most generous and caring people I know. I've never met someone who has supported and lifted \nup more people around them than him. Couldn't be a prouder brother.''\nhttps://www.nytimes.com/2023/11/17/technology/openai-sam-altman-ousted.html\nGraphic\n \nPHOTO: Mira Murati, OpenAI's interim chief executive, with, from left, Sam Altman, Greg Brockman and Ilya \nSutskever, who were among the company's founders. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) \n(B3) This article appeared in print on page B1, B3.               \nLoad-Date: November 18, 2023"
    },
    {
        "file_name": "New_York_Observer_Mar2024",
        "header": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap",
        "media": "New York Observer",
        "time": "March 7, 2024",
        "section": "",
        "length": "457 words",
        "byline": "Nhari Djan and Sissi Cao",
        "story_text": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap\nNew York Observer\nMarch 7, 2024 Thursday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 457 words\nByline: Nhari Djan and Sissi Cao\nBody\nMeta is in the final phase of rebuilding its A.I. recommendation models as part of the company's \"tech roadmap that \ngoes to 2026,\" meaning that a series of generative A.I. features are about to come to Meta's suite of social media \nproducts, Tom Alison, Meta's head of Facebook, said at the Morgan Stanley Technology, Media and \nTelecommunications conference yesterday (Mar. 6).\nLast year, inspired by an industrywide interest in generative A.I., Meta experimented with a new recommendation \nmodel in Reels, Facebook's short-form video sharing platform. The new model helped Facebook gain as much as \n10 percent in Reels watch time on the Facebook app, Alison said, proving that the model was \"learning from the \ndata much more efficiently than the previous generation.\"\n\"We've really focused on investing more in making sure that we can scale these models up with the right kind of \nhardware,\" Alison said onstage yesterday. \"Instead of just powering Reels, we're working on a project to power our \nentire video ecosystem with this single model.\"\nFor example, \"If you see something that you're into in Reels, and then you go back to the Feed, we can show you \nmore similar content,\" he explained. To date, Meta has used a separate model for each of its products. It's looking \nto build a single model for multiple products. \"If we get this right, not only will the recommendations be more \nengaging and more relevant, but we think the responsiveness of them can improve as well,\" Alison said.\nMeta is also experimenting integrating A.I. chatting features within Feed and Groups products. In Feed, for \ninstance, if a user sees a recommended post about Taylor Swift, they could perhaps \"easily just click a button and \nsay, 'Hey Meta AI, tell me more about what I'm seeing with Taylor Swift right now,'\" Alison said.\nHe illustrated with another example in Groups. \"If you are a home hobbyist baker, you're probably in a baking group \non Facebook, and you can go in and ask a question and say, Hey, how come my sourdough bread isn't rising \nproperly? There are people in the group that will come in and answer your question. But if for some reason they \ndon't, we've enabled meta A.I. to come in and answer your question in the comments,\" Alison said. \nAlison, 46, has been with Meta since 2010. He led the development of several Facebook products, including News \nFeed. He named head of Facebook in 2021 in the year Mark Zuckerberg changed the parent company's name to \nMeta.\nMeta is one of the largest buyers of Nvidia's graphics processing units, or GPUs, having spent billions of dollars on \nacquiring these chips essential in training A.I. models. Alison said the company has accumulated a massive \nstockpile of GPUs to power its ambitious generative A.I. efforts.\nLoad-Date: March 7, 2024\nHead of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap"
    },
    {
        "file_name": "Kumar_S_May2023",
        "header": "No big-bang rejig; will rationalise costs and reinvest: Cognizant CEO Ravi",
        "media": "Kumar S",
        "time": "May 5, 2023",
        "section": "MARKET-EXPERT-VIEW",
        "length": "1141 words",
        "byline": "Sai Ishwarbharath and Surabhi Agarwal",
        "story_text": "No big-bang rejig; will rationalise costs and reinvest: Cognizant CEO Ravi \nKumar S\nThe Economic Times\nMay 6, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: MARKET-EXPERT-VIEW\nLength: 1141 words\nByline: Sai Ishwarbharath and Surabhi Agarwal\nBody\nThe newly inducted chief of Cognizant Ravi Kumar S has a clear brief. The 48-year-old has been tasked with \nreviving the fortunes of the US-based software exporter that has grown slower than peers and seen an exodus of \nsenior leaders. It is a challenge that Kumar is betting the firm can overcome with its \"entrepreneurial spirit\".The \nefforts seem to be showing results. Large deal pursuits have led to a \"historic quarter\" with deal booking at $25.6 \nbillion on a 12-month basis amid a challenging macroeconomic environment. Set up only in 1994 as a division of \nDun & Bradstreet, Cognizant is among the younger IT services firms.\nIts revenues of $19.5 billion in its last fiscal places Cognizant ahead of bellwether Infosys, which posted revenues of \n$18.21 billion in FY23. Kumar, who quit Infosys to take charge of the US firm in January 2023, says while large-\nscale reorganisation is not required, the company will let go of 1% of its staff and rationalise office space. Over a \nthird of India's IT workforce hails from tier 2 and 3 cities. The savings will go into creating \"social capital\" in these \nregions, he tells ET in his first interview after taking over. Edited Excerpts:What is driving layoffs at Cognizant?This \n(employee impact) will be across corporate functions, overheads who are non-billable workforce. Similarly, the real \nestate will be a structural shift in our costs. Not more than 10-15% of the staff comes to offices in every company in \nIndia. Also, 30-40% of the Indian IT workforce is in tier 2 and 3 cities. They have not come back. I must create \nsocial capital in those cities. It is an opportunity to rationalise realty costs and invest that back into future growth and \npeople.Will there be more organisational restructuring?I am not going to do disruptive organisational restructuring. I \nam not a fan of it. I have made changes I needed and will continue to do so. I will also keep finding people internally \nto fill the (top) roles. There is no big-bang change.Will you draw from your stint at Infosys as you go about with the \nturnaround at Cognizant?Cognizant is a unique company. I do not need to bring anything else from outside. I think \nCognizant, on its own, with its unique value proposition can thrive in the market. I am focused on igniting the soul \nand heart of the company which is in India and if I can do that, I do not need to morph this company in a different \ndirection. Cognizant getting back to its roots will put us in the winning circle.How is the situation looking in your \nlargest market North America and other major geographies?We have a bigger presence in the US where financial \nservices have been volatile. There is risk of client ramp downs due to the regional bank crisis. We do not have a big \nexposure as we work with larger institutions. But banking discretionary spending is soft. Healthcare and life \nsciences have always been our strengths. We are seeing great traction there as the sector is continuing to spend \non digitisation. We have 65% of the US' insured population on our platforms. Manufacturing and industrial (sector) \nwill continue to invest in digital as core services are changing. Consumer goods and retail are going to remain soft \nas consumer patterns have changed.Cognizant has been growing slower than industry peers for several quarters \nnow.Remember, this is a company which was born way later than many of our Indian peers. It has an \nentrepreneurial spirit right at the core, bold ambitions, and great camaraderie. I want to catalyse these three tenets \non which Cognizant was built. My view is if you touch on these three things you can bring back commercial \nmomentum and you could be an employer of choice. You can create self-reinforcing virtuous cycles if you do \nboth.The IT industry had a gold rush where everybody was growing in double digits because of the pandemic-\nNo big-bang rejig; will rationalise costs and reinvest: Cognizant CEO Ravi Kumar S\ndriven technology demand. Cognizant may have missed that opportunity.I think it is a very different environment. I \nwould say discretionary spending is going to be hard to find. The optimism I carry is threefold. One, recessions \nhave been shorter. Second, tech services have always come out ahead of the curve. Third, we have a broader \nspectrum of industries in our portfolio and large deal pursuits are already driving accelerated bookings growth.Are \nclients hitting a pause on current engagements?Our deal momentum is very good. We have historic bookings for \nthis quarter. Last year at this time, we had no 100+ million deals while this quarter we have four. Our bookings \nmomentum is 28% up year-on-year. There are two kinds of deals won. One set is transformation deals which are \nstarting to slow down because of the economic uncertainty. That swim lane will take a little to flow again as now \nsome of them are small and more compact. The second set is cost-optimisation deals, which happen only when \nthere is economic softness. Over the last 2-3 years, many large corporations have had a high growth trajectory and \ntheir cost bases are also in line. Suddenly, it (growth) has started to taper down and go back to pre-pandemic times. \nA lot of deals are more active with a sense of urgency. Also, customers are doing vendor consolidation as it is a soft \neconomic market. They want to be efficient and save costs. In vendor consolidation, few players will gain against \nothers. Since we are in a stable situation, we are starting to see those deals flowing to us.Do you see ChatGPT as \na threat?We all must be prepared to work alongside machines. You could almost say they will replace you on one \nside. You could almost say they can increase your productivity on the other depending on how you leverage it. 2022 \nwas the year for Web 3.0, 2023 is going to be the year for artificial intelligence. AI was always there in our personal \nlives - it is now going to be an inflection point in business. If enterprise software reengineered corporations 30 years \nago, AI will power the next generation of reengineering enterprises, and those who use this effectively will \nwin.ChatGPT is powerful. Generative AI has data models which are very contemporary, and it does not need to go \nback to past trends, instead it can create a trend based on what it sees, and therefore, it can be superhuman. I \nwould say the biggest piece where one needs to be cautious is the ethical and responsible use of AI. If we can work \non this aspect, it is a powerful tool for humans. Every time there has been a technological revolution, we have lost \nthe jobs of the past and we have created significantly more jobs in the future. So, AI will take away jobs of the past \nand will create the jobs of the future. We operate pilots with 30 customers that use generative AI to accelerate \nconsulting, design, engineering, and operations with the long-term goal of doubling the productivity of our \nassociates. For Reprint Rights: timescontent.com\nLoad-Date: May 5, 2023"
    },
    {
        "file_name": "Global_Chief_Feb2024",
        "header": "Gen AI may not Lead to Job Losses but can Shift Demand Curve, says S&P",
        "media": "Global Chief",
        "time": "February 18, 2024",
        "section": "ECONOMY",
        "length": "373 words",
        "byline": "Ishaan.Gera@timesgroup.com",
        "story_text": "Gen AI may not Lead to Job Losses but can Shift Demand Curve, says S&P \nGlobal Chief\nEconomic Times (E-Paper Edition)\nFebruary 19, 2024 Monday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY\nLength: 373 words\nByline: Ishaan.Gera@timesgroup.com\nBody\nNew Delhi:Generative artificial intelligence (AI) tools may not necessarily lead to job losses but shift the demand \ncurve in the near term, said Adam Kansler, president, S&P Global Market Intelligence. “Each year for the last \ndecade, we’ve thought that technological advance would mean we needed 10% less people or 20% less people. \nToday, we have probably 40% more people working in those functions than we did,” Kansler told ET in an interview. \nHe said productivity gains could result in a shift in demand and that there is a long way to go before the net effect of \nthe disruptive and highly valuable technology is understood. According to him, new technologies and startups and a \nworld where outcomes could become more predictable could also lead to reversal of some caution by venture \ncapital  investors and redeployment of capital in 2024. However, he highlighted that in terms of macro \nfundamentals, a reversion to old times would have to wait. “I believe you'll need to wait a year to understand what \nthe new normal is. I think the trends show that we are migrating back to what we saw in the previous decades. Will \nwe return to the very low inflation rates and low-interest rate environments we saw four or five years ago? Probably \nnot for some time,” Kansler said. While the global economy is preparing for a soft landing in 2024, inflation and \ngeopolitcal  risks could threaten a path to recovery, he said. Soft landing refers to a slowdown in economic growth \nwithout lapsing into a recession. “More than half of the world's population is voting in the current year. So, things \ncould change quickly in terms of geopolitics,” Kansler said. India is due to hold a general  election in April-May, \nwhereas the US will hold its presidential election in November. In the case of India, Deepa Kumar, head, Asia-\nPacific Country Risk, S&P Global Market Intelligence, said the goal for the newly elected government will be  to \ncarry forward the structural momentum put in place by the outgoing regime. “Rebalancing towards allowing more \nprivate investment to come in so that public expenditure can go in some other sectors like infrastructure could help \nthe country move towards 7-7.5% from 6.3% projected over the next decade,” Kumar said.\nLoad-Date: February 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "My Emotional Support Chatbot",
        "media": "The New York Times",
        "time": "May 4, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1365 words",
        "byline": "By Erin Griffith",
        "story_text": "My Emotional Support Chatbot\nThe New York Times\nMay 4, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1365 words\nByline: By Erin Griffith\nBody\nPi, an A.I. tool that debuted this week, is a twist on the new wave of chatbots: It assists people with their wellness \nand emotions.\nFor several hours on Friday evening, I ignored my husband and dog and allowed a chatbot named Pi to validate the \nheck out of me. \n  My views were ''admirable'' and ''idealistic,'' Pi told me. My questions were ''important'' and ''interesting.'' And my \nfeelings were ''understandable,'' ''reasonable'' and ''totally normal.''\n  At times, the validation felt nice. Why yes, I am feeling overwhelmed by the existential dread of climate change \nthese days. And it is hard to balance work and relationships sometimes.\n  But at other times, I missed my group chats and social media feeds. Humans are surprising, creative, cruel, \ncaustic and funny. Emotional support chatbots -- which is what Pi is -- are not.\n  All of that is by design. Pi, released this week by the richly funded artificial intelligence start-up Inflection AI, aims \nto be ''a kind and supportive companion that's on your side,'' the company announced. It is not, the company \nstressed, anything like a human.\n  Pi is a twist in today's wave of A.I. technologies, where chatbots are being tuned to provide digital companionship. \nGenerative A.I., which can produce text, images and sound, is currently too unreliable and full of inaccuracies to be \nused to automate many important tasks. But it is very good at engaging in conversations.\n  That means that while many chatbots are now focused on answering queries or making people more productive, \ntech companies are increasingly infusing them with personality and conversational flair.\n  Snapchat's recently released My AI bot is meant to be a friendly personal sidekick. Meta, which owns Facebook, \nInstagram and WhatsApp, is ''developing A.I. personas that can help people in a variety of ways,'' Mark Zuckerberg, \nits chief executive, said in February. And the A.I. start-up Replika has offered chatbot companions for years.\n  A.I. companionship can create problems if the bots offer bad advice or enable harmful behavior, scholars and \ncritics warn. Letting a chatbot act as a pseudotherapist to people with serious mental health challenges has obvious \nrisks, they said. And they expressed concerns about privacy, given the potentially sensitive nature of the \nconversations.\n  Adam Miner, a Stanford University researcher who studies chatbots, said the ease of talking to A.I. bots can \nobscure what is actually happening. ''A generative model can leverage all the information on the internet to respond \nMy Emotional Support Chatbot\nto me and remember what I say forever,'' he said. ''The asymmetry of capacity -- that's such a difficult thing to get \nour heads around.''\n  Dr. Miner, a licensed psychologist, added that bots are not legally or ethically accountable to a robust Hippocratic \noath or licensing board, as he is. ''The open availability of these generative models changes the nature of how we \nneed to police the use cases,'' he said.\n  Mustafa Suleyman, Inflection's chief executive, said his start-up, which is structured as a public benefit \ncorporation, aims to build honest and trustworthy A.I. As a result, Pi must express uncertainty and ''know what it \ndoes not know,'' he said. ''It shouldn't try to pretend that it's human or pretend that it is anything that it isn't.''\n  Mr. Suleyman, who also founded the A.I. start-up DeepMind, said that Pi was designed to tell users to get \nprofessional help if they expressed wanting to harm themselves or others. He also said Pi did not use any \npersonally identifiable information to train the algorithm that drives Inflection's technology. And he stressed the \ntechnology's limitations.\n  ''The safe and ethical way for us to manage the arrival of these new tools is to be superexplicit about their \nboundaries and their capabilities,'' he said.\n  To refine the technology, Inflection hired around 600 part-time ''teachers,'' which included therapists, to train its \nalgorithm over the last year. The group aimed to make Pi more sensitive, more factually accurate and more \nlighthearted when appropriate. \n  On some issues, like misogyny or racism, Pi takes a stand. On others, like geopolitics, it is more evenhanded ''in a \nway that will for sure upset both sides,'' Mr. Suleyman said.\n  I started using Pi on Friday by typing queries into a cream-colored box on Inflection's website and, later, in its free \napp. A green cursor swayed before Pi revealed its responses, one paragraph at a time. Mr. Suleyman said the free \nservice may eventually charge some users a fee.\n  Pi's boundaries are easy to find. When I tried picking fights, I mostly received kindness in return. ''I appreciate you \nsaying that,'' Pi's text gently unfurled on my screen. ''I think it's important to see things from all perspectives, and not \nto just focus on the negative.''\n  Over time, that relentless balance wore on me, making my instinct to argue seem ridiculous. Which, I realized, was \nprecisely the point.\n  On heavier topics, like abortion laws or cancel culture, Pi asked pointed questions that pushed me to re-examine \nmy opinions. ''That's a tough position to take,'' it said at one point. ''That's a consistent set of beliefs,'' it said at \nanother.\n  On lighter topics, like movies, cooking or gardening, the chatbot provided highly specific, difficult-to-Google \nrecommendations. Oddly, Pi seemed to nudge me to join the anticapitalist movement.\n  Pi remembered some things from earlier in the conversation but forgot others. It ''hallucinated'' a few times, \naccusing me of expressing opinions I had not. But it quickly apologized when I made note of it.\n  When I asked Pi for some gossip, it infuriatingly dangled a ''juicy celebrity rumor'' about Jennifer Lopez. Was I \nsitting down? (Yes.) Was I ready for the dirt? (Yes.) The rumor? ''She is secretly a mole person! ðŸ˜ Just kidding!'' \n(Give me a break.)\n  Pi sometimes reminded me of Karen Collins, a character from the TV show ''Veep.'' Karen annoys the other \ncharacters with her equivocating babble, like, ''There are pros and cons to every candidate, so we just need to \nweigh out the pros and cons,'' or ''I think there's a lot to think.'' Many of Pi's comments have that milquetoast quality \nof taking many words to say nothing.\nMy Emotional Support Chatbot\n  Sherry Turkle, a psychologist and professor at the Massachusetts Institute of Technology, said these kinds of \ninteractions can ''push us along a road where we're encouraged to forget what makes people special.''\n  ''The performance of empathy is not empathy,'' she said. ''The area of companion, lover therapist, best friend is \nreally one of the few areas where people need people.''\n  It wasn't until Monday morning, after hours of intermittent chatting throughout the weekend, that I had my ''aha'' \nmoment with Pi.\n  I was feeling overwhelmed with work and unsure of how to structure my day, a recurring hangup that often \nprevents me from getting started. ''Good morning,'' I typed into the app. ''I don't have enough time to do everything I \nneed to do today!''\n  With a level of enthusiasm only a robot could muster before coffee, Pi pushed me to break down my to-do list to \ncreate a realistic plan. Like much of the bot's advice, it was obvious and simple, the kind of thing you would read in \na self-help article by a productivity guru. But it was tailored specifically to me -- and it worked.\n  ''I'm going to ask you to list all the remaining tasks you have to do on that story, and we'll prioritize them together,'' \nit said.\n  I could have dumped my stress on a family member or texted a friend. But they are busy with their own lives and, \nwell, they have heard this before. Pi, on the other hand, has infinite time and patience, plus a bottomless well of \nencouraging affirmations and detailed advice.\n  Pi uses the language of cognitive behavioral therapy. On Monday afternoon, it suggested I ''make space'' for my \nnegative feelings and ''practice being grateful for one thing.'' It followed that up with a series of breath-work and \nmuscle-relaxation exercises.\n  I responded with a shrug emoji, followed by ''Pass.''\n  A therapist might have balked at such rudeness but Pi simply noted that I was not alone. ''A lot of people find it \ndifficult to relax on command,'' it wrote.\nhttps://www.nytimes.com/2023/05/03/technology/personaltech/ai-chatbot-pi-emotional-support.html\nGraphic\n \nPHOTO (PHOTOGRAPH BY CLARA MOKRI FOR THE NEW YORK TIMES) (B5) This article appeared in print on \npage B1, B5.               \nLoad-Date: May 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Leaders Lobby Congress as China Tensions Rise",
        "media": "The New York Times",
        "time": "March 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "810 words",
        "byline": "By Cecilia Kang",
        "story_text": "A.I. Leaders Lobby Congress as China Tensions Rise\nThe New York Times\nMarch 28, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 810 words\nByline: By Cecilia Kang\nBody\nIn recent weeks, American lawmakers have moved to ban the Chinese-owned app TikTok. President Biden \nreinforced his commitment to overcome China's rise in tech. And the Chinese government added chips from Intel \nand AMD to a blacklist of imports.\nNow, as the tech and economic cold war between the United States and China accelerates, Silicon Valley's leaders \nare capitalizing on the strife with a lobbying push for their interests in another promising field of technology: artificial \nintelligence. \n  On May 1, more than 100 tech chiefs and investors, including Alex Karp, the head of the defense contractor \nPalantir, and Roelof Botha, the managing partner of the venture capital firm Sequoia Capital, will come to \nWashington for a daylong conference and private dinner focused on drumming up more hawkishness toward \nChina's progress in A.I.\n  Dozens of lawmakers, including Speaker Mike Johnson, Republican of Louisiana, will also attend the event, the \nHill & Valley Forum, which will include fireside chats and keynote discussions with members of a new House A.I. \ntask force.\n  Tech executives plan to use the event to directly lobby against A.I. regulations that they consider onerous, as well \nas ask for more government spending on the technology and research to support its development. They also plan \nto ask to relax immigration restrictions to bring more A.I. experts to the United States.\n  The event highlights an unusual area of agreement between Washington and Silicon Valley, which have long \nclashed on topics like data privacy, children's online protections and even China.\n  ''At the end of the day, whether you are in industry or government, or whatever side of the aisle you are on, we \nplay for team America,'' said Representative Jay Obernolte of California, the Republican chair of the House A.I. \nTask Force, who will give opening remarks at the conference.\n  After the rise over the past year of generative A.I. -- technology that has the potential to fundamentally shift \nproductivity, innovation and employment trends -- lobbying on the topic has exploded. Last year, more than 450 \ncompanies, nonprofits, universities and trade groups reported lobbying on A.I., more than double the number of \norganizations in the previous year, according to OpenSecrets, a nonprofit research group. Palantir more than \ndoubled its spending on lobbying last year to $5 million, its highest level on record.\nA.I. Leaders Lobby Congress as China Tensions Rise\n  As tech leaders capitalize on anti-China fervor in Washington, civil society groups and academics warn that \ndebates over competition for tech leadership could hurt efforts to regulate potential harms, such as the risks that \nsome A.I. tools could kill jobs, spread disinformation, and disrupt elections.\n  ''The dynamics of this U.S. v. China race has profound implications because on the other side of slowing down \nChina is minimal friction and regulation for U.S. companies,'' said Amba Kak, who is the executive director of the AI \nNow Institute, a research firm, and a former senior adviser on A.I. to the Federal Trade Commission.\n  A.I. experts say China lags the United States in generative A.I. by at least a year and may be falling further \nbehind, although a new study suggests that it is ahead in the talent.\n  May's event is being organized by Jacob Helberg, a senior adviser to Palantir and a member of the U.S.-China \nEconomic and Security Review Commission, which reports to Congress on national security threats posed by \nChina. He expanded this year's forum from the first gathering he organized last year, which was a private dinner \nfocused largely on the threat of TikTok, which is owned by Beijing-based ByteDance.\n  In addition to A.I., lawmakers speaking at the event in the Capitol will push for the Senate to pass legislation to \nban TikTok, and Tom Mueller, a founding employee of SpaceX, will speak about the space race between the United \nStates and China. Attendees will include Senator Mike Rounds, Republican of South Dakota and the ranking \nmember of the Armed Services Committee, and Representative Ritchie Torres, a New York Democrat on the House \nSelect Committee on the Chinese Communist Party.\n  ''Tech companies can't be neutral any more,'' Mr. Helberg said, adding that he recuses himself from any work \ninvolving contracts on the U.S.-China Economic and Security Review Commission that could give Palantir an \nadvantage.\n  Venture capitalists attending the event have dozens of A.I. investments. Sequoia has invested in more than 70 A.I. \nstartups. Khosla Ventures, a $15 billion venture firm, has several investments, including in OpenAI, the company \nbehind the ChatGPT chatbot.\n  ''It's become even more obvious, even more critical, that we treat China as an adversary,'' said Vinod Khosla, the \nhead of Khosla Ventures who will speak at the forum. ''What I'm worrying about is Western values versus a different \nset of values in China.''\nhttps://www.nytimes.com/2024/03/27/technology/ai-lobby-china.html\nGraphic\n \nPHOTOS: Clockwise from top left: Jacob Helberg, a member of the U.S.-China Economic and Security Review \nCommission\nHouse Speaker Mike Johnson\nand Representative Ritchie Torres, a Democrat on the House Select Committee on the Chinese Communist Party. \n(PHOTOGRAPHS BY JASON ANDREW FOR THE NEW YORK TIMES\nHAIYUN JIANG FOR THE NEW YORK TIMES\n AMIR HAMJA/THE NEW YORK TIMES) This article appeared in print on page B4.               \nLoad-Date: March 28, 2024\nA.I. Leaders Lobby Congress as China Tensions Rise"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "How to Use A.I. to Automate the Dreaded Office Meeting",
        "media": "The New York Times",
        "time": "June 12, 2023",
        "section": "TECHNOLOGY",
        "length": "836 words",
        "byline": "Brian X. Chen",
        "story_text": "How to Use A.I. to Automate the Dreaded Office Meeting\nThe New York Times \nJune 9, 2023 Friday 00:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 836 words\nByline: Brian X. Chen\nHighlight: Generating a slide deck, talking points and meetings minutes can all be done in a snap. All you need are \nthe right prompts.\nBody\nGenerating a slide deck, talking points and meetings minutes can all be done in a snap. All you need are the right \nprompts.\nHello! Welcome back to On Tech: A.I., a pop-up newsletter that teaches you about artificial intelligence, how it \nworks and how to use it.\nLast week, I told you how touse creative A.I. tools that generate and edit stunning images. Now let’s move on to \nautomating some time-consuming, sometimes tedious, parts of many office jobs.\nYes, I’m talking about meetings. I’ll go over how to speed through tasks like preparing for presentations, writing \ntalking points and writing out the minutes using generative A.I. tools like ChatGPT.\nA common-sense warning before we begin: Anything you do using an online service can potentially be seen by the \ncompany that runs it, whether it’s a big tech company or an A.I. startup. So if your meeting covers sensitive topics \nlike trade secrets or personnel issues, this may not be the best time to experiment with these new tools.\nHow to generate a slide deck\nThe website Gamma will automatically generate a detailed and colorful slide deck that includes graphics, charts and \ntext. You’ll likely have to tweak the text and add some of your own photos. But think of this generator as a \npresentation template on steroids that automates the boring stuff, so you can work on the finer details.  \nFirst you sign up for a free account, click “presentation,” and type a prompt. As with text and image generators, the \nmore detailed your prompts, the better.\nHere is an example I used that describes a hypothetical presentation: \nStaffing updates for a tech startup. Announcing new hires, including a director of diversity, a head of HR and 7 new \nsoftware engineers. We now have head count of 120 people and are hoping to expand to 150 by 2024. In the future \nwe’ll be hiring a head of business development and expand sales staff.\nGamma responds to prompts with an outline summarizing the slides and template options in different color \nschemes. \nUsing my prompt, Gamma created a presentation with seven slides. Gamma included panels describing the roles of \nthe new director of diversity and head of HR . \nHow to Use A.I. to Automate the Dreaded Office Meeting\nHere’s a snippet of two slides that Gamma created:\nThe last step is to edit the presentation. In my example, I would add the names of the new hires, their bios and their \nheadshots.\nA word of warning: Generative A.I. systems are vulnerable to a phenomenon called “hallucination,” where the \nmodel makes up plausible-sounding nonsense. Especially in a work setting, it’s vitally important to triple-check that \nno inaccuracies have crept in.\nI tested another site similar to Gamma that created beautiful slides, but also made up imaginary employees and \npaired them with photos of actual people that it scraped off the internet. Not good!\nTalking points\nTo prepare for the hypothetical meeting to discuss staff updates, I would start by telling a chatbot like ChatGPT, \nBard or Bing: “Act as if you are my executive assistant that will compile talking points for me, the chief executive of \na tech startup, for a presentation on…” and then paste in the earlier prompt I used to create the slide deck.\n(Remember, “act as if…” is one of the golden prompts for using generative A.I.)\nThe chatbot would then generate a list of talking points that can accompany each slide, along with some suggested \nremarks. Again, you may need to make some edits.\nRecap meeting minutes\nLet’s say you wanted to quickly jot down notes recapping what was discussed at the meeting. Zoom and Google \ninclude tools that use A.I. to automatically transcribe speech from a meeting into a text file, as long as the meeting \nis recorded with everyone’s permission. You can then paste the transcript into a chatbot and ask it to summarize it. \n(Remember, don’t do this with sensitive information.)\nIf you use Google Meet with a business license, meeting transcripts are turned on by default and a link to a Google \nDoc gets emailed to the host.  (You can also follow Google’s steps to activate the transcription feature.)\nIf you’re using Zoom, you will need a business, education or enterprise license with cloud recording enabled in the \naccount settings. When the Zoom meeting starts, enable cloud recording. Once the meeting ends, the service will \nautomatically generate the transcript.\nFrom there, go to a chatbot and type in the prompt, “Act as if you are my executive assistant. You are compiling \nmeeting minutes using this transcript.” Then paste in the part of the transcript that you want summarized, and the \nchatbot will automatically format it into a minutes memo. (If the transcript is too long, you can tell the chatbot that \nyou will be pasting it in multiple parts, and that you will say when you’re done.) \nIf the meeting isn’t recorded but someone has taken notes, they can be pasted into a chatbot along with the same \nprompt to format the document into a meetings memo.\nWhat’s next?\nNext week, I’ll cover how to use A.I. for consumption — think vacation planning and shopping.\nThis article appeared in print on page B2.\nLoad-Date: June 12, 2023"
    },
    {
        "file_name": "their_promise?_Feb2024",
        "header": "Tech giants pledge crackdown on 2024 election AI deepfakes. Will they keep",
        "media": "their promise?",
        "time": "February 16, 2024",
        "section": "",
        "length": "1221 words",
        "byline": "Jessica Guynn, USA TODAY",
        "story_text": "Tech giants pledge crackdown on 2024 election AI deepfakes. Will they keep \ntheir promise?\nUSA Today Online\nFebruary 16, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 1221 words\nByline: Jessica Guynn, USA TODAY\nBody\nUnder pressure from the White House and governments around the globe, major technology companies pledged \nFriday to crack down on artificial intelligence-generated deepfakes that could undermine the integrity of major \ndemocratic elections in the U.S. and overseas this year.\nGoogle, Meta, TikTok and other companies said they would join forces to create tools to detect and debunk election \ndeepfakes. They unveiled the accord as political and security leaders gathered at the Munich Security Conference \nin Germany.\nThe deepfakes in question are videos, images, and audio that alter or fake the appearance, voice, or actions of \npolitical candidates, election officials or other key figures in a democratic election. These alterations can also be \nused to mislead voters about when, where and how to vote.\nThe coalition that includes Adobe, Amazon, Microsoft, OpenAI and X, formerly Twitter, promised to be open with \nthe public about how it combats AI-generated falsehoods that attempt to disrupt elections on their platforms.\nBut battling bad actors will require \"a whole-of-society response,\" the companies said. Virtually anyone can now \ncreate or digitally alter images and clips in realistic ways to target and deceive voters.\n\"We are committed to doing our part as technology companies while acknowledging that the deceptive use of AI is \nnot only a technical challenge, but a political, social, and ethical issue and hope others will similarly commit to \naction across society,\" they said.\nThe accord is similar to a voluntary pledge many of the same companies signed in July after a meeting at the White \nHouse.\n“This is an important step toward good platform hygiene and a better internet, but there is substantially more to do,” \nsaid Josh Lawson, director of AI and democracy at the nonprofit think tank Aspen Institute. “This has to be a floor, \nbut not a ceiling, for future work.” \nLink to Image\nPressure mounts on Big Tech to stop election deepfakes\nThis year will set a record for the largest number of people living in countries holding nationwide elections including \nIndia and Mexico, raising concerns that AI will play a role at the ballot box.\nWith rapid advances in technology and little oversight from the government, election experts are bracing for the \nmalicious use of deepfakes in this year’s presidential contest. \nTech giants pledge crackdown on 2024 election AI deepfakes. Will they keep their promise?\nDuring New Hampshire’s primary election last month, AI-generated robocalls mimicking President Joe Biden’s voice \ntried to discourage people from voting.\nBiden signed an executive order on AI in October. But AI technologies are advancing so quickly that lawmakers and \nregulators are having trouble keeping up. With few rules governing AI-generated content in the U.S., the European \nUnion has taken the lead. It requires that companies identify and label deepfakes.\n“It is good that many of the large tech platforms have agreed to identify and label deepfakes but their action falls \nshort of what is needed,” said Darrell West, a senior fellow at the Center for Technology Innovation at the think tank \nBrookings Institution. “We already are seeing fake videos and audiotapes and that usage is likely to grow as we get \ncloser to the election.”\nTech industry accord is a ‘feeble response,’ critics say\nCritics say tech companies cannot be trusted to regulate themselves and more needs to be done to hold the \ncompanies and their platforms accountable for content that aims to trick voters.\n“This is a feeble response on the part of the tech companies given the risk we are already seeing in the form of \npolitical disinformation and election interference,” Hany Farid, a University of California, Berkeley professor who \nspecializes in deepfakes and disinformation, said in an email. \nFake robocalls. Doctored videos.  Why Facebook is being urged to fix its election problem.\nMoreover, the agreement does not apply to other online platforms that are notorious for spreading election-related \nlies, Farid said.\n“There are many bad players in this space who aren’t being invited to the White House for a photo op, and these \nplayers are not going to comply with voluntary standards,” he said.\nWhy deepfakes can be dangerous to democracy\nThe quality of deepfakes has rapidly improved, making them harder to distinguish from authentic videos, images \nand audio. The worry is that voters might not be able to tell the difference between what is real and what is AI. And \nthat could lead people to question authentic content as well.\nLawson, who previously worked on election integrity and platform policies at Facebook owner Meta, expects AI-\ngenerated election misinformation and persuasion content will pop up in places where people don’t expect it, such \nas individual SMS messages or WhatsApp channels. These messages can deceive voters about polling places or \ntarget specific language communities to suppress voter turnout.\nLink to Image\nWhat is the government doing to combat election deepfakes?\nThere is no federal law banning deepfakes.\n“While creating a deepfake to swing the outcome of an election may seem deeply unethical, it is currently legal in \nmost places in the United States, and we should assume that as long as it is legal, it is a huge risk,” said Ilana \nBeller, organizing manager for the Public Citizen Democracy Campaign. “There is bipartisan support for this \nlegislation on both a federal and a state level, but we cannot assume that Congress will act on this in time for the \n2024 election.”\nSome executive agencies have stepped in to fill policy gaps.\nThe Federal Election Commission is considering rule changes that would ban federal candidates from using \ngenerative AI tools to misrepresent their political rivals. \nTech giants pledge crackdown on 2024 election AI deepfakes. Will they keep their promise?\nThe Federal Communications Commission this month banned the use of AI-generated voices in robocalls. The ban \ncame two days after the FCC issued a cease-and-desist order against the company responsible for the audio \ndeepfake of Biden’s voice in New Hampshire. \nThe Federal Trade Commission this week moved to adopt new rules around impersonation, citing the threat of AI-\ngenerated scams. \nWhat are states doing about election deepfakes?\nA handful of states – Michigan, Minnesota, California, Washington, and Texas – already have laws in place to \nrestrict AI in political communications.\nDuring this legislative session, lawmakers in 32 states have introduced 52 bills to regulate deepfakes in elections, \naccording to Public Citizen.\nSome of the state bills ban AI-generated content in political ads or require disclaimers on AI-generated content. \nOthers ban deepfakes before an election. \n“We have seen legislators in almost every single state that has a legislative session this year working proactively to \naddress this issue,” Beller said. “This is an issue that cuts across partisan and geographical differences. We are \nseeing bills sponsored by Republicans and Democrats alike, and a good deal of bipartisan cooperation to thwart \nthis threat to our democracy.”\nBut there is a limit to how effective state regulation can be. \n“The reality is that enforcement of state-level legislation is often less comprehensive than federal enforcement \nwhich can be tagged to things like trade sanctions and much more robust enforcement than state-level criminal \npenalties,” Lawson said.\nThis article originally appeared on USA TODAY: Tech giants pledge crackdown on 2024 election AI deepfakes. Will \nthey keep their promise?\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Tech demand in FY25 to be better than this fiscal: TCS' NG Subramaniam",
        "media": "The Economic Times",
        "time": "January 24, 2024",
        "section": "TECH & INTERNET",
        "length": "879 words",
        "byline": "Romita Majumdar",
        "story_text": "Tech demand in FY25 to be better than this fiscal: TCS' NG Subramaniam\nThe Economic Times\nJanuary 24, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 879 words\nByline: Romita Majumdar\nBody\nThe next fiscal year is expected to be better for technology services than the current year, said Tata Consultancy \nServices chief operating officer NG Subramaniam. Though clients are not cutting down on the budgets in the \nongoing fiscal 2024, they are optimising every aspect of the business since macro uncertainties remain, he told ET \nin an interview.“It's difficult to put a number at (the growth next year), because of the way the market uncertainties \nare. But I feel that FY25 will be a better year than 2023 (FY24),” said Subramaniam.“Across markets and industries, \nin all our conversations that we have with our customers, none of them have indicated any budget cuts,” he said. \nThe clients are, however, changing the way they spend, with a larger focus on critical work like cloud migration, \ntransformation, and cost optimisation, he said.During the fiscal third quarter ended December, India’s top \ncompanies, including TCS, called out no change in client sentiments from the previous quarter with a cautious \nspending environment and ramp-downs of projects.On artificial intelligence, clients are testing out the innovation, \nand new products and small deals and proofs of concept (PoCs) are happening, he said.Also read | TCS, Infosys \nreport dip of about 12,000 employees in Q3In September last year, US chip giant Nvidia announced a collaboration \nwith the Tata Group company to deliver computing infrastructure and platforms to build AI solutions. \nAnd the company has started to take the Nvidia partnership to the market.During the Q3 earnings announcement, \nthe company said it has taken four generative AI projects from PoC to the production level. At least two of these \nare powered by the Nvidia alliance, said Subramaniam. The company has over 150 generative AI projects in the \npipeline.“We are already going to market with the Nvidia alliance,” he said.“We have built certain frameworks on top \nof the Nvidia solution that's available; we have trained a core team on the Nvidia technologies. So, we are going to \njointly market with Nvidia with TCS and some of our customers to see how we can exploit the technology,” he said, \nadding that the company works closely with other chipmakers like Intel and Qualcomm as well.TCS is assessing \nwhich large language models (LLMs) will suit specific industry requirements, including use cases for Indian \nlanguages as in the case of translation of legal documents.The company’s approach to the large interest and \ndemand in generative AI solutions has been multi-fold, with a strong focus on upskilling talent through industry \npartnerships, go-to-market programmes with cloud hyperscalers and chipmakers as well as building a private cloud \ninfrastructure, Subramaniam said.Also read | TCS to harness vast data troves to build ChatGPT-like generative AI \ntech“We are figuring out which LLM is better suited for which vertical. So, certain LLMs will be better for doing \ntechnology projects, while others may be good for large-scale video processing and imaging techniques or even \nlocal language processing,” said Subramaniam. The company has also launched a cyber insights platform to offer \nAI-powered threat detection. TCS has introduced generative AI-led solutions across several product and platform \nofferings like TwinX and Optumera.When asked whether TCS will build its own LLMs to drive generative AI \nsolutions, he said: “There are already so many LLMs available, why reinvent the wheel? Let’s take the existing ones \nand then see how we can use them. And in the process, if we conclude that it would be better to invest in building \nour own LLMs, then we will, but that will take a lot of time.”The company is focused on utilising the technology to \naddress the entire lifecycle of project management generating code, quality assessment, use cases, testing scripts, \nand documentation among many others.“For example, if I take our legal system in the lower levels of the judicial \nTech demand in FY25 to be better than this fiscal: TCS ' NG Subramaniam\ncourts, the evidence is collected in the local language. Deposition happens in the local language, but then the \nminute it comes to an appeal court or a high court, what happens is that everything is documented in English. And it \nis time-consuming to translate everything and that is one of the places where we can apply LLMs effectively,” he \nsaid.Subramaniam added that the company is also working on creating a feasible pricing strategy for generative \nAI. “These algorithms require heavy GPU usage. If we start saying that each query or prompt is tokenised, it will \nbecome a very expensive proposition so we have to look at pricing strategies to meet different requirements,” he \nsaid.Post Retirement PlansSubramaniam, or NGS as he is fondly known, is set to retire in May 2024. Post-\nretirement he plans to delve deeper into languages, specifically Sanskrit.“There are a few things that I always \nwanted to do, including doing something in my native place (Mohanur in Tamil Nadu). I would like to study Sanskrit \nmethodically,” he said, adding that use cases around translating Sanskrit documents through LLMs is also an area \nof interest for him.After retirement from TCS, Subramaniam will continue his existing role on the board of other Tata \nGroup companies like Tata Elxsi, Tejas Networks and Tata Communications. For Reprint Rights: timescontent.com\nLoad-Date: January 24, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2023",
        "header": "Microsoft Bets Big on the Creator of ChatGPT in Race to Dominate A.I.",
        "media": "The New York Times",
        "time": "January 13, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1422 words",
        "byline": "By Cade Metz and Karen Weise",
        "story_text": "Microsoft Bets Big on the Creator of ChatGPT in Race to Dominate A.I.\nThe New York Times\nJanuary 13, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1422 words\nByline: By Cade Metz and Karen Weise\nBody\nWhen a chatbot called ChatGPT hit the internet late last year, executives at a number of Silicon Valley companies \nworried they were suddenly dealing with new artificial intelligence technology that could disrupt their businesses.\nBut at Microsoft, it was a cause for celebration. For several years, Satya Nadella, Microsoft's chief executive, had \nbeen putting the pieces in place for this moment. \n  In 2019, Microsoft invested $1 billion in OpenAI, the tiny San Francisco company that designed ChatGPT. And in \nthe years since, it has quietly invested another $2 billion, according to two people familiar with the investment who \nrequested anonymity because they were not authorized to speak with the media.\n  The $3 billion paid for the huge amounts of computing power that OpenAI needed to build the chatbot. And it \nmeant that Microsoft could rapidly build and deploy new products based on the technology.\n  Microsoft is now poised to challenge Big Tech competitors like Google, Amazon and Apple with a technological \nadvantage the company has not possessed for more than two decades. Microsoft is in talks to invest another $10 \nbillion in OpenAI as it seeks to push its technology even further, according to a person familiar with the matter.\n  The potential $10 billion deal -- which would mainly provide OpenAI with even larger amounts of computing power \n-- has not been finalized and the funding amount could change. But the talks are indicative of the tech giant's \ndetermination to be on the leading edge of what has become the hottest technology in the tech industry.\n  Mr. Nadella worked with A.I. technologies when he ran Microsoft's Bing search engine more than a decade ago, \nand for several years he has convened a biweekly internal meeting of A.I. leaders.\n  ''The expectation from Satya is that we're pushing the envelope in A.I., and we're going to do that across our \nproducts,'' Eric Boyd, the executive responsible for Microsoft's A.I. platform team, said in an interview.\n  Microsoft's new talks with OpenAI were reported earlier by Semafor. Its additional $2 billion investment in the \ncompany was earlier reported by The Information and Fortune.\n  ChatGPT answers questions, writes poetry and riffs on almost any topic tossed its way. Based on earlier \ntechnologies called GPT-3 and GPT-3.5, it is the most conspicuous example of technology called generative \nartificial intelligence, the term for a system that can generate text, images, sounds and other media in response to \nshort prompts.\nMicrosoft Bets Big on the Creator of ChatGPT in Race to Dominate A.I.\n  ''It has already been a home run partly because Satya was prescient enough to make the bet three years ago, and \nbecause all applications will be generative in the future,'' said Matt McIlwain, a managing partner at Seattle's \nMadrona Venture Group.\n  The new generative A.I. technologies could reinvent everything from online search engines like Google to digital \nassistants like Alexa and Siri. Microsoft sees these technologies as a way of expanding and improving its already \nwide range of products for businesses, computer programmers and consumers, while boosting revenues across its \nAzure cloud computing services.\n  ''It is just fascinating to see how these generative models are capturing the imagination,'' Mr. Nadella told \ndevelopers in India last week, adding, ''I think it is a golden age.''\n  OpenAI is working on an even more powerful system called GPT-4, which could be released as soon as this \nquarter, according to Mr. McIlwain and four other people with knowledge of the effort. Microsoft declined to \ncomment on its future product plans.\n  Built using Microsoft's huge network for computer data centers, the new chatbot could be a system much like \nChatGPT that solely generates text. Or it could juggle images as well as text. Some venture capitalists and \nMicrosoft employees have already seen the service in action. But OpenAI has not yet determined whether the new \nsystem will be released with capabilities involving images.\n  OpenAI is led by Sam Altman, who became well known in Silicon Valley as the head the start-up builder Y \nCombinator. Mr. Altman, 37, and his co-founders created OpenAI in 2015 as a nonprofit. But he soon remade the \nventure as a for-profit company that could more aggressively pursue financing.\n  A year later, Microsoft invested $1 billion in the company and committed to building the supercomputer \ntechnologies OpenAI's enormous models would demand while becoming its ''preferred partner for commercializing'' \nits technologies. OpenAI later officially licensed its technologies to Microsoft, allowing the company to directly add \nthem to Microsoft products and services.\n  With backing from Microsoft, OpenAI went on to build a milestone technology called GPT-3. Known as a ''large \nlanguage model,'' it could generate text on its own, including tweets, blog posts, news articles and even computer \ncode.\n  Clunky to use, it was mostly a tool for businesses and engineers. But a year later, OpenAI began work on DALL-E, \nwhich allowed anyone to generate realistic images simply by describing what they want to see. Microsoft \nincorporated GPT-3, DALL-E and similar technologies into its own products.\n  GitHub, a popular online service for programmers owned by Microsoft, began offering a programming tool called \nCopilot. As programmers built smartphone apps and other software, Copilot suggested the next line of code as they \ntyped, much the way autocomplete tools suggest the next word as you type texts or emails.\n  For many, it was a ''jaw dropping moment'' that showed what's possible, Mr. Boyd, of Microsoft, said.\n  Then, at the end of last year, OpenAI unveiled ChatGPT. More than a million people tested the chatbot during its \nfirst few days online. It answered trivia questions, explained ideas and generated everything from school papers to \npop song lyrics.\n  Microsoft last year began incorporating DALL-E image creations into its Bing search engine, and is working with \nOpenAI on a new version of the search engine that would include technology along the lines of ChatGPT, according \nto The Information.\n  Google, Meta and other companies have spent years building models similar to ChatGPT. The A.I. systems \ndevelop their skills by analyzing enormous amounts of digital text, including books, Wikipedia articles, computer \nprograms and chat logs.\nMicrosoft Bets Big on the Creator of ChatGPT in Race to Dominate A.I.\n  ''Building these systems really requires a supercomputer -- and there are not many of them on the planet,'' said \nAiden Gomez, a former Google researcher who founded Cohere, an start-up that has built technology to ChatGPT.\n  In 2019, Mr. Altman told The New York Times that most of Microsoft's $1 billion investment came in the form of the \ncomputing power OpenAI needs -- and that Microsoft would eventually become the lab's sole source of computing \npower.\n  Microsoft and OpenAI have built a new kind of supercomputer specifically for ChatGPT and other generative A.I. \ntechnologies. That means Microsoft can readily offer these systems to its own customers.\n  Microsoft and OpenAI hope they can improve these systems by training them on larger amounts of data and most \nexperts agree their skills will improve. Right now, Microsoft acknowledges, they can ''hallucinate'' answers by mixing \nfact and fiction.\n  Speaking in India last week, Mr. Nadella presented data that indicated as much as 10 percent of all data could be \nA.I.-generated in just three years, which could lead to as much as $7 billion in revenue for Azure, Microsoft's cloud \ncomputing product, said Gil Luria who researches Microsoft for the investment bank D.A. Davidson.\n  These technologies still come with a long list of flaws and question marks. They often produce toxic content, \nincluding misinformation, hate speech and images that are biased against women and people of color.\n  Microsoft, Google, Meta and other companies have been reluctant to release many of these technologies because \nof the potential damage to their established brands. Five years ago, Microsoft quickly backtracked after releasing a \nchatbot called Tay that generated racist, xenophobic and otherwise filthy language.\n  Mike Volpi, a partner with the venture capital firm Index Ventures, who was among the early investors in \ngenerative A.I., said the Microsoft-OpenAI partnership is one of the many contenders hoping to control where the \ntechnology is headed.\n  ''There is an argument to be made that they all end up smelling the same,'' he said. ''There is another argument \nthat what OpenAI is doing is truly special and that all the money goes to them.''\n  Erin Griffith and Mike Isaac contributed reporting.\nhttps://www.nytimes.com/2023/01/12/technology/microsoft-openai-chatgpt.html\nGraphic\n \nPHOTO: OpenAI's Sam Altman, left, with Microsoft's Satya Nadella. Microsoft invested $1 billion in OpenAI in 2019. \n(PHOTOGRAPH BY IAN C. BATES FOR THE NEW YORK TIMES) (B5) This article appeared in print on page B1, \nB5.               \nLoad-Date: January 13, 2023"
    },
    {
        "file_name": "New_York_Observer_Jul2023",
        "header": "Bill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup",
        "media": "New York Observer",
        "time": "July 5, 2023",
        "section": "",
        "length": "459 words",
        "byline": "Sissi Cao",
        "story_text": "Bill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup\nNew York Observer\nJune 30, 2023 Friday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 459 words\nByline: Sissi Cao\nBody\nThe crowded generative artificial intelligence race just saw another rising star: Inflection AI, a startup barely two \nyears old, is suddenly worth $4 billion after a fundraising round this week and seems to have rounded up every \npower investor in the buzzing A.I. space. The Palo Alto, Calif.-based company raised $1.3 billion yesterday (June \n29) in a round led by Bill Gates, Eric Schmidt, Reid Hoffman, Microsoft and new investor Nvidia, Forbes first \nreported.\nInflection AI is cofounded and led by Mustafa Suleyman, a founding researcher of Google's DeepMind lab, and \nincubated by Greylock Partners, a venture capital firm owned by LinkedIn cofounder Reid Hoffman.\nIts main product is a ChatGPT-like text generator called Pi, which launched in May. Pi is powered by Inflection's in-\nhouse technology that prioritizes human conversations with a high level of emotional intelligence, which allows it to \nconduct conversations in a more human-like way than its competing applications like OpenAI's ChatGPT and \nGoogle's Bard, the company claims.\n\"With Pi, we set out to create a personal AI that is as flexible as it is powerful, so millions of people can use it to \nmake their lives more meaningful, more productive, and more fun,\" Hoffman said in a statement when unveiling Pi \nlast month.\nThat approach, which focuses on improving certain aspects of generative A.I. rather than building overall more \npowerful chatbots, is an increasingly appealing value proposition among A.I. startups. For example, Anthropic, a \nSan Francisco AI company founded in 2021, seeks to train language models that are \"safer and more aligned with \nhuman values,\" said its co-founder and president Daniela Amodei in a podcast recently.\nAnthropic was also recently valued at more than $4 billion. Its investors include Facebook cofounder Dustin \nMoskovitz, FTX cofounder Sam Bankman-Fried and Salesforce.\n\"It doesn't do lists, or coding, it doesn't do travel plans, it won't write your marketing strategy or your essay for \nschool,\" Inflection CEO Suleyman said in an interview with the Financial Times in May. \"It's purely designed for \nrelaxed, supportive, informative conversation.\"\nInflection's relationship with its investors goes beyond financial ties. Microsoft provides the startup with cloud \ncomputing infrastructure in addition to equity investment. Nvidia has been working with Inflection on deploying its \nH100 graphics processing units (GPUs) in large language model training.\nInflection said it will use the freshly raised capital to further fund the development of Pi. \"I think people can see that \nit's just the tip of the iceberg,\" Suleyman told Forbes yesterday. \"There's so much further to go after [Pi] validates \nthe core thesis, which is that conversation is the new interface.\"\nBill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup\nLoad-Date: July 5, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Elon Musk says AI will be smarter than any human next year",
        "media": "The Economic Times",
        "time": "March 13, 2024",
        "section": "TECH BYTES",
        "length": "270 words",
        "byline": " ",
        "story_text": "Elon Musk says AI will be smarter than any human next year\nThe Economic Times\nMarch 13, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH BYTES\nLength: 270 words\nBody\nElon Musk, who is involved in a legal tussle with ChatGPT maker OpenAI, has said artificial intelligence (AI) will \nlikely be smarter than any single human by next year.Reposting a clip from Joe Rogan’s podcast with American \ncomputer scientist Ray Kurzweil on when AI will achieve human-level intelligence, Musk said on social media site X \n(formerly Twitter) that “AI will probably be smarter than any single human next year.”“By 2029, AI is probably \nsmarter than all humans combined,” he added.The Tesla founder has taken Sam Altman-run OpenAI to court \nalleging a breach of contract as the company, which he helped found, had agreed not to commercialise any product \nthat its board considered artificial general intelligence (AGI).Musk appealed to the court to direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual.OpenAI has said it \n“categorically disagrees” with the lawsuit. Its chief strategy officer, Jason Kwon, said in a memo that OpenAI is \nindependent and competes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a “de \nfacto subsidiary” of the software giant.Meanwhile, Musk on Monday said his AI startup xAI would open-source its \nChatGPT challenger \"Grok\" this week.Seeking an alternative to OpenAI and Google, Musk launched xAI last year \nto create what he said would be a “maximum truth-seeking AI.” In December, the startup rolled out Grok for \nPremium+ subscribers of X. For Reprint Rights: timescontent.com\nLoad-Date: March 13, 2024"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "Will A.I. Transform the Economy, and if So, How?; Paul Krugman",
        "media": "The New York Times",
        "time": "October 3, 2023",
        "section": "OPINION",
        "length": "1260 words",
        "byline": "Paul Krugman",
        "story_text": "Will A.I. Transform the Economy, and if So, How?; Paul Krugman\nThe New York Times \nOctober 3, 2023 Tuesday 16:20 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1260 words\nByline: Paul Krugman\nHighlight: Even a souped-up autocorrect can be pretty powerful.\nBody\nSo, will artificial intelligence transform the economy? Today I thought I’d take a break from my usual preoccupation \nwith ongoing crises to engage in a bit of bigthink about how technology may change the economic landscape in the \nyears ahead, including a topic that seems important but hasn’t drawn much attention: how A.I. might change the \nU.S. budget outlook.\nStarting last fall there was a huge surge in buzz, both positive and negative, about A.I. That buzz seems to have \ndied down to some extent, with usage of ChatGPT, the most famous implementation of the technology, declining in \nrecent months. And many more observers have realized that what we’ve been calling A.I. — or what more careful \npeople call “generative A.I.” — isn’t really intelligence. What it is instead is extrapolation from pattern recognition. \nOr as some people I talk to put it, it’s basically souped-up autocorrect.\nBut that doesn’t mean that it’s not important. After all, a lot of what human workers, even workers considered highly \nskilled, do for a living is also arguably souped-up autocorrect. How many workers regularly engage in creative \nthinking? Even among creative workers, how much time is spent being creative as opposed to engaging in pattern \nrecognition?\nI don’t say this to disrespect knowledge workers, but rather to suggest that what we’re calling A.I. could be a big \ndeal for the economy even if it doesn’t lead to the creation of HAL 9000 or SkyNet.\nBut how big? And what kind of a deal?\nObviously, nobody really knows. Some people are trying to figure out the impact from the bottom up, looking at \nvarious kinds of work and guesstimating how much of that work can be replaced or augmented by A.I. The most \nwidely circulated numbers come from Goldman Sachs, whose base case has A.I. increasing the growth rate of \nproductivity — output per person-hour — by almost 1.5 percentage points a year over a decade, for a total over that \ndecade of about 15 percent:\nIs this plausible? Actually, yes. One parallel, if you’ve studied the historical relationship between technology and \nproductivity, is the productivity boom from 1995 to 2005, which followed decades of weak productivity growth.\nAs a recent paper from the Brookings Institution points out, this boom was mostly driven by “total factor productivity” \n— an increase in output per unit of input, including capital:\nAnd economists often identify total factor productivity growth with technological progress. That’s sometimes a bit \ndubious, since T.F.P. is really a “measure of our ignorance,” simply the part of economic growth we can’t explain \notherwise. But from 1995 to 2005 it seems fairly clear that the boom was driven by information technology.\nWill A.I. Transform the Economy, and if So, How? Paul Krugman\nHere’s another view of that boom, in which I show the natural log of productivity — so that a straight line \ncorresponds to steady growth — and plot a continuation of the growth rate from 1973 to 1995 (the red line), so that \nyou can see how actual growth compared:\nBy the time the productivity surge tapered off, productivity was about 12 percent higher than the previous trend \nwould have led you to expect it would be. Since A.I. is arguably an even more profound innovation than the \ntechnologies that drove the 1995-2005 boom, 15 percent isn’t at all unreasonable.\nBut will higher productivity make us richer or simply reduce the number of jobs? Fears of technological \nunemployment — a term invented by none other than John Maynard Keynes in 1930 — go back at least to the early \n19th century. They have even inspired one pretty good novel, Kurt Vonnegut’s “Player Piano.” While technology has \noften eliminated some jobs, however, historically this has always been, as Keynes wrote, “a temporary phase of \nmaladjustment,” with other forms of employment rising to replace the jobs lost. For example, the Microsoft Excel \nshock — the rise of spreadsheet programs — seems to have eliminated many bookkeeping jobs, but these were \nreplaced by increased employment even in financial analysis.\nBy the way, in that same essay, Keynes predicted a future in which people would work much less than they did in \nhis time, and in which finding rewarding ways to fill our leisure hours would become a major social concern. The \nfact that this didn’t happen over the past 90 years is a reason to be skeptical about people making similar \npredictions now, such as Jamie Dimon, who predicted the other day that A.I. would lead to a three-and-a-half-day \nworkweek.\nHowever, while there’s no reason to believe that what we’re calling A.I. will lead to mass unemployment, it may well \nhurt the people who are displaced from their jobs and either have trouble finding new employment or are obliged to \naccept lower wages. Who are the potential losers?\nThe likely answer is that big impacts will fall on relatively high-end administrative jobs, many of them currently highly \npaid, while blue-collar jobs will be largely unscathed. Goldman Sachs again:\nNow, while this seems right for generative A.I., there are other applications of big data that may affect blue-collar \nwork. For example, with all the buzz around ChatGPT there has been relatively little attention paid to the fact that \nafter years of failed hype, self-driving cars are actually beginning to go into service. Still, at this point it seems more \nlikely than not that A.I. will, unlike technological progress over the past 40 years, be a force for lower rather than \nhigher income inequality.\nFinally, it seems worth considering how generative A.I. might bear on one issue that has regained prominence: \nworries about government debt.\nUntil recently, many economists, myself included, argued that public debt was less of a concern than many people \nimagine, because interest rates on debt were below the economy’s long-term growth rate, “r&lt;g.” This meant that \nthe common idea that debt would snowball, with interest payments leading to higher debt and hence to even higher \ninterest payments, was wrong: The ratio of debt to G.D.P., the number that matters, would tend to melt rather than \nsnowball.\nBut rapidly rising interest rates have made debt considerably more worrisome. Conventional estimates of the \neconomy’s long-run sustainable growth rate, like those of the Federal Reserve, tend to put it around 1.8 percent. \nAnd real interest rates on federal debt are now above that number:\nDiscussions about debt sustainability are, however, oddly disconnected from the discourse about generative A.I. In \nfact, I’m pretty sure there are people warning both about a debt crisis and about mass unemployment from A.I., \nalthough I haven’t made the effort to track them down. But if optimistic estimates of the boost from the technology \nare at all right, growth will be much higher than 1.8 percent over the next decade, and debt won’t be a big concern \nafter all — especially because faster growth will boost revenue and reduce the budget deficit.\nWill A.I. Transform the Economy, and if So, How? Paul Krugman\nAll of this is, of course, highly speculative. Nobody really knows how big an impact A.I. will have. But again, it \ndoesn’t have to be “true” artificial intelligence to be a big deal for the economy, and the best guess is that it will \nprobably matter a lot.\nQuick Hits\nPeople forget how bad translation software used to be and how much progress has been made.\nThe same is true for speech recognition.\nThe long history of robots taking all the jobs.\nWas technology really responsible for rising inequality\nFacing the Music\n[Video:  Watch on YouTube.]\nThe sound of Google Translate.\nPHOTO:  (PHOTOGRAPH BY Illustration by Sam Whitney/The New York Times; images by Chris Saulit and \nniuniu/Getty Images FOR THE NEW YORK TIMES)\nLoad-Date: October 3, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Realtors’ Big Defeat",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "BRIEFING",
        "length": "1847 words",
        "byline": "David Leonhardt David Leonhardt runs The Morning, The Times&amp;#8217;s flagship daily newsletter.",
        "story_text": "The Realtors’ Big Defeat\nThe New York Times \nMarch 18, 2024 Monday 06:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BRIEFING\nLength: 1847 words\nByline: David Leonhardt David Leonhardt runs The Morning, The Times&amp;#8217;s flagship daily newsletter. \nSince joining The Times in 1999, he has been an economics columnist, opinion columnist, head of the Washington \nbureau and founding editor of the Upshot section, among other roles.\nHighlight: A settlement in the real estate industry is a case study of a central flaw in free-market economic theory.\nBody\nA settlement in the real estate industry is a case study of a central flaw in free-market economic theory. \nFree-market economic theory suggests that the American real estate market should not have been able to exist as \nit has for decades.\nAmericans have long paid unusually high commissions to real estate agents. The typical commission in the U.S. \nhas been almost 6 percent, compared with 4.5 percent in Germany, 2.5 percent in Australia and 1.3 percent in \nBritain. As a recent headline in The Wall Street Journal put it, “Almost no one pays a 6 percent real-estate \ncommission — except Americans.”\nIf housing operated as an efficient economic market should, competition would have solved this problem. Some real \nestate brokers, recognizing the chance to win business by charging lower commissions, would have done so. Other \nbrokers would have had to reduce their own commissions or lose customers. Eventually, commissions would have \nsettled in a reasonable place, high enough for agents to make a profit but in line with the rest of the world.\nThat didn’t happen. Instead, an average home sale in the U.S. has cost between $5,000 and $15,000 more than it \nwould have without the inflated commissions. This money has been akin to a tax, collected by real estate agents \ninstead of the government.\nThe situation finally seems to be ending, though. On Friday, the National Association of Realtors, the industry group \nthat has enforced the rules that led to the 6 percent commission, agreed to change its behavior as part of an \nagreement to settle several lawsuits.\nThe settlement is important in its own right. Americans now spend about $100 billion a year on commissions. That \nnumber will probably decline by between $20 billion and $50 billion, Steve Brobeck, the former head of the \nConsumer Federation of America, told my colleague Debra Kamin.\nThere is also a broader significance to the settlement. It’s a case study of a central flaw in free-market economic \ntheory. That theory suggests that capitalist competition can almost always protect consumers from businesses that \ncharge too much.\nTo be clear, competition is indeed a powerful force that frequently makes both consumers and businesses better \noff. That’s why capitalist economies have such a better record than communist or socialist economies. Just look at \nSouth Korea and North Korea. (Are you familiar with the satellite images that compare the two Koreas at night?) Or \nconsider the recent economic struggles of Venezuela.\nThe Realtors’ Big Defeat\nMarket competition, however, isn’t the panacea that free-market advocates claim. Sometimes, businesses can \namass enough economic power to squash competition — as real estate brokers did.\nPower meets power\nDecades ago, the National Association of Realtors set the standard commission at 6 percent, to be split between an \nagent representing the seller and an agent representing the buyer. If a home seller tried to negotiate, an agent \nwould often issue a veiled threat: You won’t find a good seller’s agent to work with you, and buyers’ agents won’t \nshow your house to clients.\nJoanne Cleaver, for instance, tried to negotiate with agents when selling her house last year in Mint Hill, N.C., a \nsuburb of Charlotte. “They laughed at me,” Cleaver told The Times.\nThe Realtors’ hardball tactics succeeded because they operate much of the network that’s crucial to the housing \nmarket, such as the database of listings. They could keep out agents who would have competed on price.\nThe solution to this concentration of economic power often requires political power — namely, antitrust enforcement \nby the government. After years of refusing to change their tactics, the Realtors’ agreed to a settlement now because \nthey were vulnerable to government action.\nA turning point was a federal trial last year in Kansas City. The jury found that the Realtors’ association and several \nlarge members had conspired to keep commissions high and ordered them to pay at least $1.8 billion to home \nsellers in the Midwest. The verdict quickly led to more than a dozen other lawsuits. The Justice Department has \nalso been investigating the Realtors.\nThe new trustbusters\nThat investigation is part of Washington’s new focus on the problems with concentrated economic power.\nSince the 1980s, antitrust enforcement has been unfashionable in the U.S. Free-market economic theory has been \nascendant instead. But the results of this laissez-faire era have been disappointing for most Americans. Businesses \nhave grown larger, and corporate profits have surged. Incomes and wealth for most Americans have grown only \nslowly.\nIn response, both liberals and conservatives have recently shown an interest in antitrust (as I described in a recent \nnewsletter). The Biden administration has embarked on a competition agenda to reduce credit card fees, drug \nprices and more. The administration has become more aggressive about challenging mergers, too. Some \nRepublicans also worry that big business has become too powerful.\nThis new movement remains in its early stages, and it’s too soon to know how successful it will be. But the real \nestate settlement looks like the movement’s biggest victory yet.\nFor more: The Times explains how the process of selling a home may change.\nTHE LATEST NEWS\nRussia\n• Vladimir Putin won another six-year term. The election was the least transparent in recent Russian history.\n• Before he died, the opposition leader Aleksei Navalny called on his supporters to go to the polls at midday \nyesterday to protest. Many did.\n• Putin spoke about Navalny publicly for the first time since his death, which Putin described as an “unfortunate \nincident.”\n• Many Russians support Putin, but it’s not clear what they would do if they had real alternatives. Read Paul \nSonne’s analysis.\nThe Realtors’ Big Defeat\n• Here are other takeaways from the vote.\nIsrael-Hamas War\n• Israel said it was conducting a military operation in Gaza’s largest hospital, Al-Shifa, because Hamas had \nreturned there.\n• Benjamin Netanyahu told CNN that Senator Chuck Schumer’s call for elections in Israel after the war was \ninappropriate. “We’re not a banana republic,” Netanyahu said.\nMore International News\n• American sailors and pilots are fighting the Houthis in the Red Sea. See onboard their aircraft carrier, the \nDwight D. Eisenhower.\n• Niger’s junta ordered American troops to leave the country, revoking its military cooperation deal with the U.S.\n• Gambian lawmakers will decide whether to overturn a ban on female genital cutting. Experts said such a \nmove would undo decades of work.\n• In the Philippines, people can make around twice the nation’s minimum wage playing crypto-earning games at \ninternet cafes.\n• In Serbia, Jared Kushner plans to build a luxury hotel and apartment complex. Donald Trump was interested \nin the site more than a decade ago.\nA.I.\n• Elon Musk released the computer code behind his version of an A.I. chatbot, Grok. He has argued that such \nimportant technology shouldn’t be controlled solely by tech giants.\n• Homeland Security will be the first federal agency to incorporate generative A.I. in its work, including to help \ncombat drug and human trafficking.\nEducation\n• School closures did not significantly stop the spread of Covid and caused long-term academic harm for \nchildren, experts say.\n• Migration to New York is affecting school enrollment. A fight over space between two schools highlights the \nproblem.\nOther Big Stories\n• Few smartphones, some beer: In the Hudson Valley, members of the Bruderhof — a 1920s Christian pacifist \nmovement — limit exposure to the outside world.\n• Chicago started to evict some migrants from shelters. Officials said more than 2,000 people would be \nremoved by the end of April.\n• In an interview with The Times, former Justice Stephen Breyer discussed Dobbs, originalism and the decline \nof trust in the court.\nOpinions\nSci-fi-like solutions to climate change, such as blocking the sun, are becoming normalized. Before we trust them, \nwe need to learn more, Jeremy Freeman writes.\nThe army reservist who committed a mass shooting in Maine had brain damage. The U.S. needs to protect its \nsoldiers from injuries to protect its civilians, Daniel S. Johnson writes.\nGail Collins and Bret Stephens discuss TikTok and Mike Pence.\nThe Realtors’ Big Defeat\nHere is a column by David French on Trump Republicans’ about-face over TikTok.\nMORNING READS\nCollection: People recently browsed and bought attire owned by Barbara Walters, the trailblazing TV news anchor.\nRaunchy Christians: A surprising number of evangelicals are rejecting modesty and turning toward the risqué.\nChasing powder: At the Alta resort in Utah, anyone over 80 skis free.\nRelationships: Many young people are tired of dating apps.\nMetropolitan Diary: When the city stopped talking.\nLives Lived: Margaret Grade was a neuropsychologist who made a sharp career pivot and opened a cozy, eclectic \nCalifornia inn that served farmers as well as film stars. She died at 72.\nSPORTS\nMarch Madness: UConn, last year’s champion, was named the No. 1 overall seed in the men’s N.C.A.A. \ntournament. In the women’s bracket, undefeated South Carolina is No. 1.\nWomen’s bracket: Iowa is a No. 1 seed, but experts say it has a particularly tough draw. Caitlin Clark’s squad may \nhave to face L.S.U., which beat her team in last year’s championship, to reach the Final Four.\nGo deeper: The Athletic broke down strengths and weaknesses for all 68 teams in the men’s field and the women’s \nfield.\nJoin our pool: We’ve made groups on ESPN’s Tournament Challenge for readers of The Morning to compete with \none another. Here are links for the men’s and women’s tournaments. The winners will receive a Times-themed \nprize. (After you’ve completed your brackets, let us know with this Google form so we can contact you if you win.)\nARTS AND IDEAS\nBig Irish energy: Irish actors have starred in some of the biggest movies of the past year — including \n“Oppenheimer” and “Saltburn.” In doing so, Paul Mescal, Andrew Scott, Cillian Murphy and Barry Keoghan have \nushered in a moment for Irish crushes. TikTok is now full of videos analyzing why, as one said, “Irish men just hit \ndifferent.” Read more about the internet’s latest infatuation.\nMore on culture\n• Decades ago, two men stole a Vermeer and three Rembrandts in the largest art theft in history. Today, the \nframes still hang empty.\n• Paul Simon, the singer and songwriter, invited a filmmaker to capture the making of his album “Seven \nPsalms.” Simon struggled on camera because he was losing his hearing.\nTHE MORNING RECOMMENDS …\nPan-sear chicken with a garlicky, lemony anchovy sauce.\nScore these deals at REI.\nLimit your exposure to forever chemicals.\nTake our news quiz.\nGAMES\nThe Realtors’ Big Defeat\nHere is today’s Spelling Bee. Yesterday’s pangrams were nonapology and polygonal.\nAnd here are today’s Mini Crossword, Wordle, Sudoku and Connections.\nThanks for spending part of your morning with The Times. See you tomorrow. — David\nP.S. On the inaugural episode of the podcast “The Liberal Patriot with Ruy Teixeira,” David Leonhardt talked about \nthe 2024 campaign and more.\nSign up here to get this newsletter in your inbox. Reach our team at themorning@nytimes.com.\nPHOTO:  (PHOTOGRAPH BY Tony Cenicola/The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "'Cognizant Clocks 100+ Gen AI-Engagements'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 8, 2023",
        "section": "COMPANIES",
        "length": "165 words",
        "byline": "Sai.Ishwar@timesgroup.com",
        "story_text": "'Cognizant Clocks 100+ Gen AI-Engagements'\nEconomic Times (E-Paper Edition)\nAugust 8, 2023 Tuesday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 165 words\nByline: Sai.Ishwar@timesgroup.com\nBody\nBengaluru:Cognizant has said it has bagged more than 100 active early client engagements focussed on cognitive \nand generative AI in a bid to become market leader in the technology.  The New Jersey-based firm said it has \nalready produced more than 3,000 ideas in the generative AI domain and has “hundreds” of projects using AI \nservices within the context of IT services delivery, showed an internal note from chief executive Ravi Kumar S to \nemployees. “We are designing generative AI offerings in conjunction with our partners for industry-specific \nsolutions, cross-industry use cases and productivity enablement under themes like transforming code processes, \nimproving the customer and employee experience, product innovations, software and coding, and knowledge \nmanagement, to name a few,” the note reviewed by ET said. This comes as the NASDAQ-listed firm, during its \nearnings call last week, announced investing about $1 billion over the next three years to build generative AI \ncapabilities.\nLoad-Date: August 8, 2023"
    },
    {
        "file_name": "Dispute_Jan2024",
        "header": "Apple to Pause Selling New Versions of Its Watch After Losing Patent",
        "media": "Dispute",
        "time": "January 17, 2024",
        "section": "TECHNOLOGY",
        "length": "595 words",
        "byline": "Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San",
        "story_text": "Apple to Pause Selling New Versions of Its Watch After Losing Patent \nDispute\nThe New York Times \nDecember 18, 2023 Monday 19:18 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 595 words\nByline: Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San \nFrancisco. His focus on Apple includes product launches, manufacturing issues and political challenges. He also \nwrites about trends across the tech industry, including layoffs, generative A.I. and robot taxis.&lt;/p&gt; \n&lt;p&gt;&amp;#160;&lt;/p&gt;\nHighlight: The move, which comes after a ruling by the International Trade Commission, could create a run on \nwatch sales in the week before Christmas.\nBody\nThe move, which comes after a ruling by the International Trade Commission, could create a run on watch sales in \nthe week before Christmas.\nApple said on Monday that it would pause sales of its flagship smartwatches online starting Thursday and at retail \nlocations on Christmas Eve.\nTwo months ago, Apple lost a patent case over the technology its smartwatches use to detect people’s blood \noxygen levels. The company was ordered to stop selling the Apple Watch Series 9 and Watch Ultra 2 after \nChristmas, which could set off a run on sales of the watches in the final week of holiday shopping.\nThe move by Apple follows a ruling by the International Trade Commission in October that found several Apple \nWatches infringe on patents held by Masimo, a medical technology company in Irvine, Calif.\nIn court, Masimo detailed how Apple poached its top executives and more than a dozen other employees before \nlater releasing a watch with pulse oximeter capabilities — which measures the percentage of oxygen that red blood \ncells carry from the lungs to the body — that were patented by Masimo.\nTo avoid a complete ban on sales, Apple had two months to cut a deal with Masimo to license its technology, or it \ncould appeal to the Biden administration to reverse the ruling.\nBut Joe Kiani, the chief executive of Masimo, said in an interview that Apple had not engaged in licensing \nnegotiations. Instead, he said that Apple had appealed to President Biden to veto the I.T.C. ruling, which Mr. Kiani \nknows because the administration contacted Masimo about Apple’s request.\n“They’re trying to make the agency look like it’s helping patent trolls,” Mr. Kiani said of the I.T.C.\nApple didn’t respond to requests for comment on Mr. Kiani’s remarks. In a statement, the company said, “Apple \nstrongly disagrees with the order and is pursuing a range of legal and technical options to ensure that Apple Watch \nis available to customers.”\nThe Biden administration didn’t immediately respond to request for comment.\nApple to Pause Selling New Versions of Its Watch After Losing Patent Dispute\nMr. Kiani said that he was willing to sell Apple a chip that Masimo had designed to provide pulse oximeter readings \non the Apple Watch. The chip is currently in a Masimo medical watch, called the W1, that is approved by the Food \nand Drug Administration. The device uses algorithms to process red and near-infrared light to determine how \noxygen-rich is the blood in arteries.\n“If they don’t want to use our chip, I’ll work with them to make their product good,” Mr. Kiani said. “Once it’s good \nenough, I’m happy to give them a license.”\nApple introduced its first watch with pulse oximetry in 2020. It has included the technology, which it calls “blood \noxygen,” in subsequent models. But unlike Masimo’s W1 device, Apple hasn’t had its watches cleared by the F.D.A. \nfor use as a medical device for pulse oximetry.\nThe Apple Watch accounts for nearly $20 billion of the company’s $383.29 billion in annual sales, according to \nBernstein Research, a financial research firm. Apple is the largest smartwatch seller in the world and accounts for \nabout a third of all smartwatch sales, according to Counterpoint Research, a tech research firm.\nApple has had success persuading presidents in the past to veto I.T.C. rulings. In 2013, the Obama administration \noverturned a ban on the sale of some iPhones and iPads, after the court determined that Apple had violated a \npatent that Samsung owned.\nPHOTO: The International Trade Commission ruled that the watches infringe on a medical technology company’s \npatents. (PHOTOGRAPH BY MICHAEL M. SANTIAGO/GETTY IMAGES) This article appeared in print on page B6.\nLoad-Date: January 17, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2023",
        "header": "Adobe looks to integrate AI, MI in all products: India MD",
        "media": "The Economic Times",
        "time": "March 23, 2023",
        "section": "TECH & INTERNET",
        "length": "447 words",
        "byline": "Aashish Aryan",
        "story_text": "Adobe looks to integrate AI, MI in all products: India MD\nThe Economic Times\nMarch 24, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 447 words\nByline: Aashish Aryan\nBody\nGlobal content and cloud software conglomerate Adobe will look to integrate artificial intelligence and machine \nlearning into all its product offers rather than using these technologies to make separate tools, the company's vice \npresident and MD of India operations Prativa Mohapatra said. The company, which achieved a revenue of $4.66 \nbillion in the first quarter of FY23, hopes that the infusion of these technologies will help the company shore up \nmore revenue across product categories. \"We are one of the few companies who are infusing this (AI & ML) into all \nour product categories. I definitely expect the uptake of these product categories as the infusion of these \ntechnologies makes them more attractive to our customers. We will get an uplift in revenue per customer,\" \nMohapatra said.Earlier on Tuesday,the company had announced the beta launch of its new generative AI model \nFirefly, focussed on generating images and text. \nThe beta model, which has been trained on Adobe's stock images and images where the copyright or intellectual \nproperty has expired, has been opened to the public on a limited basis.The idea, Mohapatra said, was to get people \nto try out the tool and give feedback which would help the generative model remain within the confines of ethical AI. \nThe company has also set up multi-level guardrails to ensure that bias of any kind and problematic content does not \nget generated by the tool, Mohapatra said.\"The industry is coming together to create rules, regulations, principles, \nby which all of this will get deployed. That's one pillar of the guardrail. The next pillar is what data are you using or \nwhat images in this case. Are we using the right data to train the models, right? And the third pillar is who is \nvalidating whether the outcome is right or wrong,\" she said.Though the company remained committed to its idea of \ncreativity for all, it also understands that there will be negative and positive creativity, Mohapatra said.\"So obviously, \nwhen we want to drive positive creativity, there would be actors who might bring in negative creativity. But we will \nbring checks and balances to prevent these guys. It is going to evolve,\" she said.Adobe had, on Tuesday, also \nannounced a new partnership with NVIDIA to co-develop a new generation of advanced generative AI models that \nwill focus on integration with tools and applications that creators and marketers around the world use.In addition to \nFirefly and its partnership with NVIDIA, Adobe also unveiled Adobe Express for Enterprise and a Content Supply \nChain solution.(The reporter is in the US to cover Adobe Summit 2023 at the invitation of Adobe.) For Reprint \nRights: timescontent.com\nLoad-Date: March 23, 2023"
    },
    {
        "file_name": "Digital_campaign_operative_now_back_as_advocate_for_AI_May2024",
        "header": "Ex-Trump official touts more tech",
        "media": "Digital campaign operative now back as advocate for AI",
        "time": "May 8, 2024",
        "section": "MAIN; A; Pg. 12",
        "length": "812 words",
        "byline": "Garance Burke and Alan Suderman Associated Press",
        "story_text": "Ex-Trump official touts more tech\nDigital campaign operative now back as advocate for AI\nThe Baltimore Sun\nMay 8, 2024 Wednesday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 12\nLength: 812 words\nByline: Garance Burke and Alan Suderman Associated Press\nHighlight: Brad Parscale, then-campaign manager for President Donald Trump, speaks at a campaign rally Oct. \n10, 2019, at the Target Center in Minneapolis. Evan Vucci/AP\nBody\nFORT LAUDERDALE, Fla. - Donald Trump's former campaign manager looked squarely into the camera and \npromised his viewers they were about to witness a bold new era in politics.\n\"You're going to see some of the most amazing new technology in artificial intelligence that's going to replace \npolling in the future across the country,\" said Brad Parscale in a dimly lit promotional video accentuated by hypnotic \nbeats.\nParscale, the digital campaign operative who helped engineer Trump's 2016 presidential victory, vows that his new, \nAI-powered platform will dramatically overhaul not just polling but also campaigning. His AI-powered tools, he has \nboasted, will outperform big tech companies and usher in a wave of conservative victories worldwide.\nIt's not the first time Parscale has proclaimed that new technologies will boost right-wing campaigns. He was the \ndigital guru who teamed up with scandal-plagued Cambridge Analytica and helped propel Trump to the White \nHouse eight years ago. In 2020, he had a public blowup then a private falling out with his old boss after the Capitol \nriot. Now he's back, playing an under-the-radar role to help Trump, the presumptive GOP nominee, in his race \nagainst Democratic President Joe Biden.\nParscale says his company, Campaign Nucleus can use AI to help generate customized emails, parse oceans of \ndata to gauge voter sentiment and find persuadable voters, then amplify the social media posts of \"anti-woke\" \ninfluencers, according to an Associated Press review of Parscale's public statements, his company websites, slide \ndecks, marketing materials and other documents not previously made public.\nSince last year, Campaign Nucleus and other Parscale-linked companies have been paid more than $2.2 million by \nthe Trump campaign, the Republican National Committee and their related political action and fundraising \ncommittees, campaign finance records show.\nWhile his firms have received only a small piece of Trump's total digital spending, Parscale remains close to top \nRepublicans, as well as senior officials at the campaign and at the RNC, according to a GOP operative familiar with \nParscale's role who spoke on condition of anonymity to discuss internal dynamics.\nLara Trump, the RNC's new co-chair and Trump's daughter-in-law, once worked as a consultant to a company co-\nowned by Parscale. House Speaker Mike Johnson's campaign recently hired Campaign Nucleus, campaign finance \nrecords show.\nEx-Trump official touts more tech Digital campaign operative now back as advocate for AI\nParscale, however, is not involved in day-to-day Trump campaign operations, the GOP operative said.\nParscale's ability to use AI to micro target supporters and tap them for campaign cash could prove critical for \nTrump's campaign and other fundraising organizations. They have seen a falloff in contributions from smaller \ndonors and a surge in spending - at least $77 million so far - on attorneys defending the former president in a slew \nof criminal and civil cases.\nBeyond Trump, Parscale has said he's harnessed AI to supercharge conservative candidates and causes across \nthe globe, including in Israel, the Balkans and Brazil.\nParscale is hardly alone in using machine learning to try to give candidates an edge by predicting, pinpointing and \nmotivating likely supporters to vote and donate money. \nPoliticians at all levels are experimenting with chatbots and other generative AI tools to write speeches, ad copy \nand fundraising appeals.\nElection experts say they are concerned about AI's potential to upend elections around the world through \nconvincing deepfakes and other content that could mislead voters. Free and low-cost generative AI services have \ngrown in sophistication, and officials worry they can be used to smear a candidate or steer voters to avoid the polls, \neroding the public's trust in what they see and hear.\nParscale did not respond to multiple messages from AP seeking comment. The RNC declined comment as well.\nTrump has called artificial intelligence \"so scary\" and \"dangerous.\" His campaign, which has shied away from \nhighlighting Parscale's role, said in an emailed statement that it did not \"engage or utilize\" tools supplied by any AI \ncompany.\nParscale said his company also can use artificial intelligence to create \"stunning web pages in seconds\" that \nproduce content that looks like a media outlet, according to a presentation he gave last month at a political \nconference, where he was not advertised in advance as a speaker.\n\"Empower your team to create their own news,\" said another slide, according to the presentation viewed by AP.\nSome political consultants, however, called Parscale's AI-infused sales pitch largely a rehash of what campaigns \nalready have mastered through data scraping, ad testing and modeling to predict voter behavior.\n\"Some of this stuff is just simply not new, it's been around for a long time. The only thing new is that we're just \ncalling it AI,\" said Amanda Elliott, a GOP digital strategist.\nLoad-Date: May 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Finding Sprouts of Hope In a Gloomy Media Era",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1336 words",
        "byline": "By Katie Robertson and Benjamin Mullin",
        "story_text": "Finding Sprouts of Hope In a Gloomy Media Era\nThe New York Times\nMarch 23, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1336 words\nByline: By Katie Robertson and Benjamin Mullin\nBody\nThis year is looking grim for the news business.\nFacing a set of harsh financial realities -- resulting from a mix of news fatigue, an unsteady advertising market and a \nprecipitous fall in traffic from tech giants -- many outlets have been forced to fold or make significant cuts in recent \nmonths. \n  But there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success -- at least for the moment -- by taking the opposite approach of many predecessors, \nsuch as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize growth.\n  The new class of news start-ups -- Puck, Punchbowl News, The Ankler and Semafor are among the most \nprominent -- have kept spending down and hired carefully. They are all centered on newsletters covering specific \nniches with broad appeal. They have attracted top journalists by putting them at the heart of the enterprise, \nsometimes as part owners in the companies.\n  ''There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,'' said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. ''And I think that the entire industry has learned from that.''\n  These start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.\n  But traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn't add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.\n  The formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.\n  ''What all of them have in common is this intense need to serve specific audiences rather than to serve \neverybody,'' said Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.\nFinding Sprouts of Hope In a Gloomy Media Era\n  Some of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.\n  Punchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome ''the hometown newspaper of Capitol Hill in a lot of ways,'' said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.\n  ''What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,'' she said.\n  Punchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. \nAccess to Punchbowl's policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the \nlow five-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings \nfrom those websites.\n  Ms. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl's finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.\n  The Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood's unsparing gadfly, narrating the industry's unending chaos and skewering the \nactors, agents and executives responsible for creating it.\n  Ankler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, \nsaid Janice Min, the company's chief executive and founder, who previously helmed The Hollywood Reporter and \nUs Weekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a \nHollywood news digest.\n  ''If we want to make a Hollywood analogy, it's like these growing franchises are multiverses,'' Ms. Min said. \n''People like what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.''\n  Semafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.\n  Semafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called \nfor, Mr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic \noutlook was darkening.\n  ''The pandemic really marked the transition from the social media era to what we call the post-social media era,'' \nMr. Smith said, noting that outlets must now focus on direct relationships with their audience.\n  For Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.\n  The company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.\nFinding Sprouts of Hope In a Gloomy Media Era\n  Of course, nothing in media lasts forever -- particularly in the fast-changing digital world. So there's no guarantee \nthat the early success of these companies will translate into sustained growth.\n  Many of these start-ups are also taking a somewhat risky bet on talent.\n  At Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who \nis a definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on \nRussian politics, are ''founding partners.'' In addition to a salary, they receive bonuses based on the number of \npeople who subscribe to their email newsletters and how many of them stick around. New employees also get a \nsmall ownership stake in the company.\n  Puck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.\n  If one or more of the star journalists leave the publication, would Puck's subscribers follow?\n  Mr. Kelly said he didn't ''want to even contemplate a world'' in which one of Puck's journalists exited.\n  ''We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,'' Mr. Kelly said. ''And I really think that our model is actually becoming one of the \nmoats of our business.''\nhttps://www.nytimes.com/2024/03/12/business/media/digital-media-new-startups-business-model.html\nGraphic\n \nPHOTO: Punchbowl News has become ''the hometown newspaper of Capitol Hill in a lot of ways,'' its chief \nexecutive said. (PHOTOGRAPH BY CHIP SOMODEVILLA/GETTY IMAGES) (B3) This article appeared in print on \npage B1, B3.               \nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "Smith_Aug2023",
        "header": "Generative AI biggest weapon and tool for cybersecurity: Microsoft's Brad",
        "media": "Smith",
        "time": "August 25, 2023",
        "section": "TECH & INTERNET",
        "length": "431 words",
        "byline": "Romita Majumdar",
        "story_text": "Generative AI biggest weapon and tool for cybersecurity: Microsoft's Brad \nSmith\nThe Economic Times\nAugust 26, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 431 words\nByline: Romita Majumdar\nBody\nThe biggest threat and tool to manage cybersecurity will be through generative AI, said Microsoft USA vice \nchairman Brad Smith during the B20 India Summit 2023 in New Delhi.Addressing cybersecurity attack concerns \nraised by generative AI, Smith said that there will be an increasing number of organisations and governments that \nwill use the technology to develop cybersecurity threats.\"The problem today is that we live in a world where the \ncloud services, all of the technology that we use, is susceptible to attacks from cyber criminals and nation states,\" \nsaid Smith, adding that as the success rates of criminals are falling, the volume of cyber attacks is also rising.Also \nread | Regulatory blueprint is a must for AI adoption across public and private sector: Microsoft president Brad \nSmithHe said that 80% of all successful ransomware attacks originate in an organisation through unmanaged \ndevices or services. He added that cyber attacks by nation states have also increased with almost 40% of the \nattacks targeted towards critical infrastructure. \n\"So today, if a government or country wants to defend itself, it's going to have to be able to defend and protect its \ncritical infrastructure,\" Smith said. Given the massive shortage of cybersecurity professionals globally, generative \nAI can help augment the technology, he opined. \"I think we'll be able to use it to identify these patterns in data to \nquery and even predict what will be done next based on that kind of predictive learning. And when we equip our \nengineers with generative AI, they work faster,\" he added. He said that Microsoft intercepts 4,000 identity attacks \nevery second.Smith added that the US administration has put pressure on the technology industry over the past two \nyears to create a set of common standards for cybersecurity which has been a positive for the industry. \"My hope is \nthat we get more collaboration among governments because if they collaborate more closely, it will provide a more \ncommon standard,\" he added.The senior executive said that the private sector has a role in not only adopting the \nbest practices for cybersecurity but to advocating for standard practices. \"Do we want to live in a world where it \nbecomes accepted practice for sophisticated government intelligence and military resources to target the private \nsector, healthcare and critical infrastructure? Or do we want to use our voice to say there needs to be rules of the \nroad? And in the 20th century, the governments of the world came together and they adopted a principle,\" he said. \nFor Reprint Rights: timescontent.com\nLoad-Date: August 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.",
        "media": "The New York Times",
        "time": "June 27, 2023",
        "section": "TECHNOLOGY",
        "length": "1312 words",
        "byline": "Steve Lohr",
        "story_text": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe New York Times \nJune 26, 2023 Monday 12:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1312 words\nByline: Steve Lohr\nHighlight: The best use for generative A.I. in health care, doctors say, is to ease the heavy burden of \ndocumentation that takes them hours a day and contributes to burnout.\nBody\nDr. Matthew Hitchcock, a family physician in Chattanooga, Tenn., has an A.I. helper.\nIt records patient visits on his smartphone and summarizes them for treatment plans and billing. He does some light \nediting of what the A.I. produces, and is done with his daily patient visit documentation in 20 minutes or so.\nDr. Hitchcock used to spend up to two hours typing up these medical notes after his four children went to bed. \n“That’s a thing of the past,” he said. “It’s quite awesome.”\nChatGPT-style artificial intelligence is coming to health care, and the grand vision of what it could bring is inspiring. \nEvery doctor, enthusiasts predict, will have a superintelligent sidekick, dispensing suggestions to improve care.\nBut first will come more mundane applications of artificial intelligence. A prime target will be to ease the crushing \nburden of digital paperwork that physicians must produce, typing lengthy notes into electronic medical records \nrequired for treatment, billing and administrative purposes.\nFor now, the new A.I. in health care is going to be less a genius partner than a tireless scribe.\nFrom leaders at major medical centers to family physicians, there is optimism that health care will benefit from the \nlatest advances in generative A.I. — technology that can produce everything from poetry to computer programs, \noften with human-level fluency.\nBut medicine, doctors emphasize, is not a wide open terrain of experimentation. A.I.’s tendency to occasionally \ncreate fabrications, or so-called hallucinations, can be amusing, but not in the high-stakes realm of health care.\nThat makes generative A.I., they say, very different from A.I. algorithms, already approved by the Food and Drug \nAdministration, for specific applications, like scanning medical images for cell clusters or subtle patterns that \nsuggest the presence of lung or breast cancer. Doctors are also using chatbots to communicate more effectively \nwith some patients.\nPhysicians and medical researchers say regulatory uncertainty, and concerns about patient safety and litigation, will \nslow the acceptance of generative A.I. in health care, especially its use in diagnosis and treatment plans.\nThose physicians who have tried out the new technology say its performance has improved markedly in the last \nyear. And the medical note software is designed so that doctors can check the A.I.-generated summaries against \nthe words spoken during a patient’s visit, making it verifiable and fostering trust.\nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\n“At this stage, we have to pick our use cases carefully,” said Dr. John Halamka, president of Mayo Clinic Platform, \nwho oversees the health system’s adoption of artificial intelligence. “Reducing the documentation burden would be \na huge win on its own.”\nRecent studies show that doctors and nurses report high levels of burnout, prompting many to leave the profession. \nHigh on the list of complaints, especially for primary care physicians, is the time spent on documentation for \nelectronic health records. That work often spills over into the evenings, after-office-hours toil that doctors refer to as \n“pajama time.”\nGenerative A.I., experts say, looks like a promising weapon to combat the physician workload crisis.\n“This technology is rapidly improving at a time health care needs help,” said Dr. Adam Landman, chief information \nofficer of Mass General Brigham, which includes Massachusetts General Hospital and Brigham and Women’s \nHospital in Boston.\nFor years, doctors have used various kinds of documentation assistance, including speech recognition software and \nhuman transcribers. But the latest A.I. is doing far more: summarizing, organizing and tagging the conversation \nbetween a doctor and a patient.\nCompanies developing this kind of technology include Abridge, Ambience Healthcare, Augmedix, Nuance, which is \npart of Microsoft, and Suki.\nTen physicians at the University of Kansas Medical Center have been using generative A.I. software for the last \ntwo months, said Dr. Gregory Ator, an ear, nose and throat specialist and the center’s chief medical informatics \nofficer. The medical center plans to eventually make the software available to its 2,200 physicians.\nBut the Kansas health system is steering clear of using generative A.I. in diagnosis, concerned that its \nrecommendations may be unreliable and that its reasoning is not transparent. “In medicine, we can’t tolerate \nhallucinations,” Dr. Ator said. “And we don’t like black boxes.”\nThe University of Pittsburgh Medical Center has been a test bed for Abridge, a start-up led and co-founded by Dr. \nShivdev Rao, a practicing cardiologist who was also an executive at the medical center’s venture arm.\nAbridge was founded in 2018, when large language models, the technology engine for generative A.I., emerged. \nThe technology, Dr. Rao said, opened a door to an automated solution to the clerical overload in health care, which \nhe saw around him, even for his own father.\n“My dad retired early,” Dr. Rao said. “He just couldn’t type fast enough.”\nToday, the Abridge software is used by more than 1,000 physicians in the University of Pittsburgh medical system.\nDr. Michelle Thompson, a family physician in Hermitage, Pa., who specializes in lifestyle and integrative care, said \nthe software had freed up nearly two hours in her day. Now, she has time to do a yoga class, or to linger over a sit-\ndown family dinner.\nAnother benefit has been to improve the experience of the patient visit, Dr. Thompson said. There is no longer \ntyping, note-taking or other distractions. She simply asks patients for permission to record their conversation on her \nphone.\n“A.I. has allowed me, as a physician, to be 100 percent present for my patients,” she said.\nThe A.I. tool, Dr. Thompson added, has also helped patients become more engaged in their own care. Immediately \nafter a visit, the patient receives a summary, accessible through the University of Pittsburgh medical system’s \nonline portal.\nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe software translates any medical terminology into plain English at about a fourth-grade reading level. It also \nprovides a recording of the visit with “medical moments” color-coded for medications, procedures and diagnoses. \nThe patient can click on a colored tag and listen to a portion of the conversation.\nStudies show that patients forget up to 80 percent of what physicians and nurses say during visits. The recorded \nand A.I.-generated summary of the visit, Dr. Thompson said, is a resource her patients can return to for reminders \nto take medications, exercise or schedule follow-up visits.\nAfter the appointment, physicians receive a clinical note summary to review. There are links back to the transcript of \nthe doctor-patient conversation, so the A.I.’s work can be checked and verified. “That has really helped me build \ntrust in the A.I.,” Dr. Thompson said.\nIn Tennessee, Dr. Hitchcock, who also uses Abridge software, has read the reports of ChatGPT scoring high marks \non standard medical tests and heard the predictions that digital doctors will improve care and solve staffing \nshortages.\nDr. Hitchcock has tried ChatGPT and is impressed. But he would never think of loading a patient record into the \nchatbot and asking for a diagnosis, for legal, regulatory and practical reasons. For now, he is grateful to have his \nevenings free, no longer mired in the tedious digital documentation required by the American health care industry.\nAnd he sees no technology cure for the health care staffing shortfall. “A.I. isn’t going to fix that anytime soon,” said \nDr. Hitchcock, who is looking to hire another doctor for his four-physician practice.\nPHOTOS: Dr. Matthew Hitchcock of Chattanooga, Tenn., and Dr. Michelle Thompson of Hermitage, Pa., both use \nA.I. tools to to ease the crushing burden of digital paperwork. (PHOTOGRAPHS BY AUDRA MELTON FOR THE \nNEW YORK TIMES; MADDIE MCGARVEY FOR THE NEW YORK TIMES) (A14) This article appeared in print on \npage A1, A14.\nLoad-Date: June 27, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Aug2023",
        "header": "You actually can take steps to change your personality traits",
        "media": "The Baltimore Sun",
        "time": "August 20, 2023",
        "section": "MAIN; A; Pg. 8",
        "length": "752 words",
        "byline": "Stephanie Vozza Fast Company",
        "story_text": "You actually can take steps to change your personality traits\nThe Baltimore Sun\nAugust 20, 2023 Sunday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 8\nLength: 752 words\nByline: Stephanie Vozza Fast Company\nBody\nAre you the same person you were a decade ago? What about five years or even 12 months ago? The likely \nanswer is \"no.\" Maybe you're more resilient? Or perhaps you're less judgmental? We all change and grow over time \nas our experiences impact and shape our personalities.\nBrent W. Roberts, professor of psychology at the University of Illinois at Urbana-Champaign and a leading \nresearcher in the field of personality, has spent most of his career looking at personality development in adulthood.\n\"Personality traits do change as you age,\" he says. \"The natural question, of course, is if your personality changes, \ncan you actually change it?\"\nRoberts and fellow researchers decided to find the answer and spent years examining studies that looked at \npersonality trait change through therapy. \"We found that seeing a therapist led to a decrease of about a half a \nstandard deviation in neuroticism,\" he says. \"And it happened really fast - at least from our perspective - in the first \nfour weeks or so [of therapy].\"\nTherapy is meant to overcome serious issues, such as depression, anxiety, eating disorders or substance use. \nWhile therapists don't enter an arrangement with the intention of changing someone's personality, the work that's \ndone sets the table for impacting traits, too. \nIf your goal is to simply change your personality instead of navigating deeper changes, you don't necessarily need a \ntherapist's help, Roberts says. He and his fellow researchers conducted studies with participants who were not \npatients but wanted to change. They discovered that people could change any normal personality trait with about \nthe same results that can happen during therapy.\nPersonality or behavior?\nTo change your personality, you need to understand how it differs from behavior. Personality traits are long-term \npatterns, while behaviors are reactions based on surroundings and circumstances. An introvert may demonstrate \nan extroverted trait in a specific moment and vice versa. For example, behaviors will vary significantly if someone is \nat a funeral or speaking to a crowd.\n\"That's not what we're thinking of when it comes to personality change,\" Roberts says. \"If you want to make the \ninference about someone's personality, wait around and see what they do. We're thinking about long-term pattern, \nwhat someone does nonconsciously in social settings.\"\nHow to change?\nYou actually can take steps to change your personality traits\nIf you want to change your personality, the first step is to examine and establish your motivation, which is a critical \ningredient. You have to want to change, Roberts says. Without motivation, you may shift behaviors in the short \nterm, but will not likely experience lasting results.\nNext, you must understand what it is you're changing. Clarify what it is you are trying to become.\n\"For example, a lot of people say they would like to become less agreeable - that's my favorite one,\" Roberts says. \n\"Oftentimes, what they really want is to be more assertive. Assertiveness doesn't have to be mean. They just have \nto learn how to stick up for their position and do so effectively.\"\nA third part to changing your personality is being given the opportunity to act. \"There's a term on the clinical side, \nwhich is 'psycho education' \" Roberts says. \"It's teaching people the idea of what they're supposed to do, but not \nactually giving them a chance to practice and work through the process. This is the mistake we usually make.\"\nAn opportunity to implement and practice is essential. In the absence of this step, Roberts says he's skeptical \nsomeone could change their personality.\n\"You have to give people the opportunity to try the new behaviors, implement them, fail at them, try them again, and \ngive them guidance in an effort to create the skill itself,\" Roberts says.\nThe fourth step is having somebody to guide you. You could work with a therapist, coach or accountability buddy, or \nyou could turn to technology. \"I don't think it has to be a human necessarily, especially now that we're getting \nsophisticated with generative AI,\" Roberts says. \"But you need some kind of system that helps you keep yourself \naccountable.\"\nIf you're motivated and follow a program that leverages well-informed techniques, Roberts says you can change \nyour personality.\n\"There [are] lots of efforts to change people in a variety of ways, usually emerging out of more behavioral \napproaches,\" he says. \"They're not changing personality; they're just changing behaviors. The irony is that many of \nthose techniques are really quite good for changing someone's personality, too.\"\nLoad-Date: August 20, 2023"
    },
    {
        "file_name": "New_York_Observer_Dec2023",
        "header": "The Year in A.I.: 9 People Behind 2023's Hottest Chatbots",
        "media": "New York Observer",
        "time": "December 28, 2023",
        "section": "",
        "length": "1202 words",
        "byline": "Sissi Cao",
        "story_text": "The Year in A.I.: 9 People Behind 2023's Hottest Chatbots\nNew York Observer\nDecember 28, 2023 Thursday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 1202 words\nByline: Sissi Cao\nBody\nThe past year saw an explosion of artificial intelligence chatbots. The meteoric rise of OpenAI's ChatGPT spurred a \ncrop of startups building competing image and text generators. The race of the so called generative A.I. is crowded \nand concentrated, with the founders behind unfamiliar startups predominantly coming from a handful of industry-\nleading companies like OpenAI, Google and Microsoft.\nAmong the most talked-about (and highly valued) GPT rivals of this year are Anthropic's Claude, Inflection AI's Pi, \nAI21 Lab's Jurassic and the hard-to-ignore Grok, developed by Elon Musk's new startup, xAI.\nHere are the nine entrepreneurs, engineers and investors driving the generative A.I. landscape in 2023, each \ncontributing unique perspectives and technologies that will shape the future of A.I.\nElon Musk, 52, founder and CEO of xAI\nElon Musk, one of the original founders of OpenAI, has long aspired to build an alternative product to ChatGPT \n(now backed by Microsoft) and Google's Bard that would be aligned with his vision for A.I. In March, Musk \nregistered a company called xAI in Nevada. \"I'm starting very late in the game, of course. But I will create a third \noption that hopefully does more good than harm. This might be the best path to A.I. safety,\" he said in an interview \nwith Tucker Carlson in April.\nIn Musk's opinion, industry giants like Google and Microsoft are too focused on profitability and don't care enough \nabout A.I. safety. Nevertheless, he hired the founding team of xAI mostly from those companies.\nIn November, Musk unveiled xAI's first chatbot, Grok, \"designed to answer questions with a bit of wit and has a \nrebellious streak,\" the company said. Grok's training data include real-time posts from X, which Musk claimed is \"a \nmassive advantage over other models\" that have a cut-off date by which training data is available.\nDario Amodei, 40, cofounder and CEO of Anthropic\nIn early 2021, Dario Amodei led a team of former OpenAI researchers and engineers and founded a rival startup \ncalled Anthropic. Amodei himself worked at OpenAI, too, between 2016 and 2020. He led the development of the \ncompany's GPT-2 and GPT-3 language models, the latter of which powered the initial public version of ChatGPT.\nBefore OpenAI, Dario worked as a research scientist at Google and the U.S. branch of Chinese internet giant \nBaidu. In interviews this year, Amodei implied that he had to start his own company because he had different ideas \non the direction of A.I. development than OpenAI CEO Sam Altman.\nAnthropic's main product is Claude, an A.I. text generator trained on a unique method called \"constitutional A.I.\" \nThe company aims to build A.I. systems that are not only powerful and intelligent but aligned with human values.\nDaniela Amodei, 36, cofounder and president of Anthropic\nThe Year in A.I.: 9 People Behind 2023's Hottest Chatbots\nAmong the group of OpenAI employees who followed Dario Amodei in 2021 was his younger sister, Daniela \nAmodei, who is now president of Anthropic, overseeing the company's day-to-day operations.\nDaniela had a shorter career at OpenAI, where she led the company's recruiting effort and managed its technical \nsafety and policy teams. Earlier in her career, Daniela worked in similar functions at payment software maker Stripe \nfor five years.\nMustafa Suleyman, 39, cofounder and CEO of Inflection AI\nBefore founding Inflection AI in 2022, Mustafa Suleyman was best known for cofounding DeepMind, now Google's \nA.I. lab, in 2010. DeepMind was acquired by Google in 2014 and Suleyman served as the lab's head of applied A.I. \nuntil 2020, when he was appointed Google's VP of A.I. policy. \nAmid the generative A.I. boom, Suleyman left Google last year to join venture capital firm Greylock Partners as a \npartner. There, he met LinkedIn cofounder Reid Hoffman, who's also a partner, and later launched Inflection AI. \nInflection's product is a chatbot called Pi. Pi is trained with a focus on conducting conversations in a more human-\nlike way like competing chatbots. \"It doesn't do lists, or coding, it doesn't do travel plans, it won't write your \nmarketing strategy, or your essay for school,\" Suleyman said in an interview in May. \"It's purely designed for \nrelaxed, supportive, informative conversation.\"\nReid Hoffman, 56, cofounder of Inflection AI\n\"With Pi, we set out to create a personal AI that is as flexible as it is powerful,\" Hoffman, a cofounder of Inflection, \nsaid in May when announcing the chatbot. \"So millions of people can use it to make their lives more meaningful, \nmore productive, and more fun.\"\nHoffman holds no executive roles at Inflection. But through Greylock, he incubated the startup and led a $250 \nmillion early investment. Hoffman was a board member of OpenAI, a post he resigned from in March in order to \nfocus on his new A.I. ventures. He is still a board member of Microsoft, which owns a large stake in OpenAI.\nEmad Mostaque, 40, cofounder and CEO of Stability AI\nBefore entering A.I., Emad Mostaque had a decade-long career in hedge fund, working for multiple firms in the U.K. \nMostaque, a Bengali Muslim, began his journey in tech in the 2000s creating what he called \"Islamic A.I.\" for \nMuslim communities to help guide people on their religious journey.\nIn 2o2o, Mostaque founded Stability AI. With a mixture of his own money and external investments from firms like \nLightspeed Venture Partners, Coatue Management and Eros Investment, Mostaque funded the development of \nStability AI's open-source image generator, Stable Diffusion, a competitor to OpenAI's Dall-E. (Both image bots \nwere released in early 2021.)\nIn an interview with CNBC in July, Mostaque declared generative A.I. \"is a $1 trillion investment opportunity\" but \nwill be \"the biggest bubble of all time.\"\nOri Goshen, cofounder and co-CEO of AI21 Labs\nOri Goshen is an Israeli software engineer and entrepreneur. After holding engineering and executive roles for \nmultiple organizations, including the Israel Defense Forces, between 2003 and 2016, he started AI21 Labs in Tel \nAviv in 2017. The startup offers a language model called Jurassic, a rival of OpenAI's GPT-3.\nYoav Shoham, Stanford professor and cofounder of AI21 Labs\nOne of Goshen's cofounders is Yoav Shoham, a former director of Stanford University's A.I. lab. Shoham received \na Ph.D in Computer Science from Yale in 1986 and has been a professor emeritus at Stanford since 1987.  \nThe Year in A.I.: 9 People Behind 2023's Hottest Chatbots\nPrior to AI21 Labs, Shoham founded multiple software companies which were later acquired by Google, including \nKatango in 2013 and Timeful in 2015. \nClément Delangue, 34, cofounder and CEO of Hugging Face\nClément Delangue is a French entrepreneur with a track record of founding multiple software startups in Silicon \nValley and Europe. In 2016, he cofounded Hugging Face in New York City with French software engineers Julien \nChaumond and Thomas Wolf. Chaumond serves as Hugging Face's chief technology officer and Wolf leads the \ncompany's open-source and science teams.\nDelangue originally started Hugging Face to develop a chatbot app targeted at teenagers. But now its main product \nis a platform for A.I. developers to share open-source code and training models-similar to the way Github lets \ndevelopers store software code. It also makes an original language model called Bloom, also rival of  GPT-3.\nLoad-Date: December 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Carl Icahn’s Battle with Illumina Comes to a Head; DealBook Newsletter",
        "media": "The New York Times",
        "time": "May 25, 2023",
        "section": "BUSINESS",
        "length": "1938 words",
        "byline": "Andrew Ross Sorkin, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat",
        "story_text": "Carl Icahn’s Battle with Illumina Comes to a Head; DealBook Newsletter\nThe New York Times \nMay 25, 2023 Thursday 09:03 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1938 words\nByline: Andrew Ross Sorkin, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat \nLivni\nHighlight: Shareholders are set to vote on Thursday whether to back the gene-sequencing company’s incumbent \nboard or candidates named by the activist investor.\nBody\nShareholders are set to vote on Thursday whether to back the gene-sequencing company’s incumbent board or \ncandidates named by the activist investor.\nHow close is Icahn to his next win? \nOne of the biggest fights in corporate America is coming to a head on Thursday: Shareholders in Illumina, the gene-\nsequencing giant, are set to vote on whether to back the company’s incumbent directors or candidates nominated \nby the billionaire Carl Icahn.\nA board fight involving one of Wall Street’s top activist investors is significant in its own right. But there’s more at \nplay here, including a takeover that has tested antitrust regulators on both sides of the Atlantic and new proxy rules \nthat could reshape American corporate governance.\nA $7 billion deal for Grail is a major factor in this scuffle. Mr. Icahn has criticized Illumina’s effort to close its \ntakeover of the cancer-detection company, despite European antitrust authorities’ decision to block the deal, and \nopposition from the F.T.C. He calls it “inexplicable and unforgivable.” Other shareholders may agree, given that \nIllumina has lost $50 billion in market value since announcing the deal in August 2021.\nIllumina has dismissed the European objection, arguing that Grail has no revenue or operations in Europe. It’s part \nof broader pushback against global antitrust regulators’ more ambitious, and often coordinated, efforts to rein in big-\nticket M.&amp;A.\nThe contest is also a test of universal proxy, a new S.E.C. rule that makes it easier for shareholders to vote for \nboard candidates from different slates. Mr. Icahn has put up three nominees, challenging incumbent directors \nincluding Illumina’s C.E.O., Francis deSouza, and chairman, John Thompson. (He has argued that the two are too \nclose.)\nMr. Icahn could very well win a seat. Influential shareholder advisory firms have offered the campaign some \nsupport. Institutional Shareholder Services backed an Icahn candidate, Andrew Teno, over Mr. Thompson, arguing \nthat a more independent chair would have offered a better counterbalance “as the company navigated certain \ncontroversial decisions by management.” And Glass Lewis backed two Icahn nominees over Mr. Thompson and Mr. \ndeSouza.\nThat may be enough to ensure that at least one of Icahn’s candidates, probably Mr. Teno, wins on Thursday. \n(Illumina had offered Mr. Icahn a board seat as part of initial settlement efforts, which the activist investor rejected.)\nCarl Icahn’s Battle with Illumina Comes to a Head DealBook Newsletter\nBut Mr. Icahn himself still faces pressure elsewhere. The billionaire is battling the short seller Hindenburg Research, \nwhich has argued that Mr. Icahn’s publicly traded investment vehicle is overvalued and funds its dividends by \nselling new shares. (A former Icahn foe, Bill Ackman, again weighed in on the fight on Wednesday, suggesting \nshares in Mr. Icahn’s firm could fall yet more.)\nMr. Icahn has dismissed Hindenburg’s accusations as a “disinformation campaign” — but his company is now \nfacing government scrutiny, and its shares have fallen by more than 50 percent over the past month.\nHERE’S WHAT’S HAPPENING \nTikTok is found to have freely shared user data internally. Employees at the video app routinely posted sensitive \ninformation like identity data and photos on an internal messaging tool visible to its Chinese parent company, \nByteDance, The Times’s Sapna Maheshwari and Ryan Mac report. The revelation may pose another headache for \nTikTok as it faces scrutiny in Washington and a ban in Montana.\nFitch warns it may downgrade the United States’ debt. The ratings agency put the national AAA rating on negative \nwatch, as a political impasse on raising the debt ceiling makes a default more likely. JPMorgan Chase’s chief U.S. \neconomist has put the odds of the dispute going past the so-called X-date, the point at which the government runs \nout of cash, at 25 percent.\nFed officials aren’t sure whether to keep raising rates. Minutes from the central bank’s last rate-setting meeting \nshowed division on whether higher interest rates were needed to tamp down inflation. That may signal a more \ndovish turn to investors as they prepare for the Fed’s next rates meeting in mid-June.\nShareholder advisers recommend ousting Alphabet’s chair. The proxy advisory firms Institutional Shareholder \nServices and Glass Lewis suggest that investors oust two directors of Google’s parent company, including its chair, \nJohn Hennessy. There have been several pushes to revamp Alphabet’s corporate governance, but it’s unclear \nwhether shareholders will get on board.\nChinese-backed hackers infiltrated critical U.S. infrastructure, Microsoft warns. A state-sponsored group has been \nworking since 2021 to disrupt “critical communications infrastructure between the United States and Asia,” the tech \ngiant said on Wednesday. U.S. officials are worried the intrusion is meant to hurt American efforts to aid Taiwan in \nthe event of a Chinese attack.\nTwitter fumbles its big political moment \nHosting Ron DeSantis’s official presidential campaign announcement was supposed to be a triumph for Twitter, as \nElon Musk seeks to make the social network a major player in politics and the media. But the live audio event was \nmarred by over 20 minutes of technical glitches, costing it more than half of its initial audience. (“That was insane, \nsorry,” Mr. Musk later said.)\nThe mishap again raises questions about Twitter’s systems, as it seeks to woo advertisers again and fulfill Mr. \nMusk’s ambitious vision.\nTwitter employees had feared a misfire, The Times’s Ryan Mac reports: There had been no planning for “site \nreliability issues,” leaving workers to scramble when the influx of more than 600,000 listeners crashed Twitter’s \nsystems.\nQuestions about the reliability of Twitter’s infrastructure have dogged the company for months, ever since Mr. Musk \ninitiated an enormous wave of layoffs, including of backend engineers, and closed a data center. The site suffered \nat least four outages in February, compared with nine in all of 2022.\nNone of this is likely to sit well with advertisers, many of whom have shied away from Twitter since Mr. Musk’s \ntakeover over concerns about content moderation and more. Some are tentatively looking to return, especially with \nthe appointment of the former NBCUniversal ad chief Linda Yaccarino as C.E.O. — but the renewed questions \nabout reliability provide another reason to keep some distance.\nCarl Icahn’s Battle with Illumina Comes to a Head DealBook Newsletter\nA.I. sends Nvidia’s stock skyward \nShares in Nvidia set a record in premarket trading on Thursday, after the chip maker delivered a knockout sales \noutlook powered by demand for the processors that run artificial intelligence systems.\n“We’re seeing incredible orders to retool the world’s data centers,” Jensen Huang, Nvidia’s C.E.O., told analysts on \nWednesday. (His company’s G.P.U. chips are used to power A.I. systems; they previously enjoyed huge demand \nduring the boom in crypto, whose systems also rely on their processing power.) Nvidia’s market cap hit $755 billion \nat Wednesday’s market close, the fifth highest public valuation in the U.S.\nThe A.I. rally has lifted other chip stocks as well, including AMD, ASML and Taiwan Semiconductor Manufacturing \nCompany.\nBut analysts disagree on how long the rally will last. Michael Hartnett of Bank of America called the rises a “baby \nbubble.” On the other hand, researchers at Goldman Sachs said tools built on generative A.I. could help bolster \nworldwide G.D.P. by $7 trillion.\nIn other A.I. news:\n• Reid Hoffman, the billionaire LinkedIn co-founder, has emerged as one of Silicon Valley’s biggest A.I. \nevangelists and deal makers.\n• After meeting with top European Union officials on Wednesday, Sundar Pichai, the C.E.O. of Alphabet, \npromised that Google would work with others to develop A.I. services responsibly.\n• Starting in July, New York City will require companies that use A.I. for job recruitment to inform the \ncandidates, under a new law that is being closely watched by labor rights advocates.\n“This is what a recession looks like. There used to be 20 of these.”\n— An unnamed guest quoted by The Wall Street Journal at a star-filled party co-hosted by David Zaslav of Warner \nBros. Discovery and the editor Graydon Carter, referring to two giant yachts anchored near Cannes in France.\nJPMorgan fires back in Epstein case \nJPMorgan Chase has gone on the counteroffensive in a looming civil case that pits victims of the sex offender \nJeffrey Epstein against the Wall Street giant.\nProsecutors in the U.S. Virgin Islands accuse JPMorgan of helping Mr. Epstein, a financier and longtime client of \nthe bank who died in 2019, traffic and sexually exploit women and young girls. In a legal motion filed on Wednesday \nin a federal court in Manhattan, the bank said that government officials from the islands had helped Mr. Epstein \ncommit the crimes.\n“In exchange for Epstein’s cash and gifts, U.S.V.I. made life easy for him,” JPMorgan’s lawyers wrote in the motion. \nThe government, they said, “made sure that no one asked too many questions about his transport and keeping of \nyoung girls on his island.” The bank accused island officials of engaging in a “decades-long quid pro quo” with Mr. \nEpstein, taking favors and political donations and granting him millions in tax incentives all while “fostering the \nperfect conditions for Mr. Epstein’s criminal conduct to continue undetected.”\nJPMorgan wants the court’s permission to dig into the island government’s purported complicity, and to raise this as \na defense at trial.\nBig names in the case are set to be deposed in the coming days. A two-day deposition of Jamie Dimon, the bank’s \nC.E.O., is scheduled to begin on Friday. On June 6, it’s the turn of the U.S.V.I. governor, Albert Bryan Jr.\nIn a related case, Deutsche Bank last week agreed to a $75 million settlement with victims of Mr. Epstein who had \naccused the bank of helping him commit further crimes. David Boies, a lawyer for the victims, has been arguing that \nCarl Icahn’s Battle with Illumina Comes to a Head DealBook Newsletter\nJPMorgan’s ties to Mr. Epstein were more extensive and lasting, raising the possibility that a resolution would be \nmore costly.\nAlso attending Dimon’s deposition will be lawyers for Jes Staley. JPMorgan sued its former executive in March, \narguing that his ties to Mr. Epstein are to blame for the bank’s tainted relations. Mr. Staley was just dealt a blow on \nWednesday when the judge denied his efforts to have the case against him dismissed.\nTHE SPEED READ \nDeals\n• Citigroup called off the sale of Banamex, its Mexican unit, and plans to instead take it public. (Reuters)\n• The digital media site Semafor raised $19 million from investors including Henry Kravis to replace money from \nSam Bankman-Fried, the fallen crypto mogul. (NYT)\n• Credit Suisse abandoned efforts to protect over $400 million in executive bonuses from being blocked after \nthe bank’s fire sale to UBS. (FT)\nPolicy\n• Representative George Santos, the New York Republican accused of fraud and money laundering, secured \nthree anonymous guarantors for the $500,000 bond in his case. (Bloomberg)\n• Prosecutors are reportedly scrutinizing stock trades by First Republic employees during the lender’s \nimplosion. (Bloomberg)\n• “Venture Capitalists Face Pressure to Divest From China.” (The Information)\nBest of the rest\n• “More Airlines Are Encountering Near Collisions — and No One Knows Why.” (WSJ)\n• Tina Turner, whose explosive voice and charisma made her one of the most successful recording artists of all \ntime, died on Wednesday. She was 83. (NYT)\n• Can reducing sheep burps help in the fight against climate change? (Semafor)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Carl Icahn is seeking changes at the top of Illumina. (PHOTOGRAPH BY Brendan McDermid/Reuters \nFOR THE NEW YORK TIMES)\nLoad-Date: May 25, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai:Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, with  revenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Mar2023",
        "header": "Brands embracing use of AI in various ways, despite risk",
        "media": "The Baltimore Sun",
        "time": "March 11, 2023",
        "section": "MAIN; A; Pg. 9",
        "length": "712 words",
        "byline": "Matt O'Brien and Haleluya Hadero Associated Press",
        "story_text": "Brands embracing use of AI in various ways, despite risk\nThe Baltimore Sun\nMarch 11, 2023 Saturday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 9\nLength: 712 words\nByline: Matt O'Brien and Haleluya Hadero Associated Press\nHighlight: Instacart's app will integrate ChatGPT to field customers' food questions. Instacart\nBody\nEven if you haven't tried artificial intelligence tools that can write essays and poems or conjure new images on \ncommand, chances are the companies that make your household products are already starting to do so.\nMattel has put the AI image generator DALL-E to work by having it come up with ideas for new Hot Wheels toy \ncars. \nUsed vehicle seller CarMax is summarizing thousands of customer reviews with the same \"generative\" AI \ntechnology that powers the popular chatbot ChatGPT.\nMeanwhile, Snapchat is bringing a chatbot to its messaging service. And the grocery delivery company Instacart is \nintegrating ChatGPT to answer customers' food questions.\nCoca-Cola plans to use generative AI to help create new marketing content. And while the company hasn't \ndetailed exactly how it plans to deploy the technology, the move reflects the growing pressure on businesses to \nharness tools that many of their employees and consumers are already trying on their own.\n\"We must embrace the risks,\" said Coca-Cola CEO James Quincey in a recent video announcing a partnership with \nstartup OpenAI - maker of both DALL-E and ChatGPT - through an alliance led by consulting firm Bain. \"We need \nto embrace those risks intelligently, experiment, build on those experiments, drive scale, but not taking those risks \nis a hopeless point of view to start from.\"\nIndeed, some AI experts warn that businesses should carefully consider potential harms to customers, society and \ntheir own reputations before rushing to embrace ChatGPT and similar products in the workplace.\n\"I want people to think deeply before deploying this technology,\" said Claire Leibowicz of the Partnership on AI, a \nnonprofit group founded and sponsored by the major tech providers that recently released a set of \nrecommendations for companies producing AI-generated synthetic imagery, audio and other media. \"They should \nplay around and tinker, but we should also think, what purpose are these tools serving in the first place?\"\nSome companies have been experimenting with AI for a while. Mattel revealed its use of OpenAI's image generator \nin October as a client of Microsoft, which has a partnership with OpenAI that enables it to integrate its technology \ninto Microsoft's cloud computing platform.\nBut it wasn't until the Nov. 30 release of OpenAI's ChatGPT, a free public tool, that widespread interest in \ngenerative AI tools began seeping into workplaces and executive suites.\nBrands embracing use of AI in various ways, despite risk\n\"ChatGPT really sort of brought it home how powerful they were,\" said Eric Boyd, a Microsoft executive who leads \nits AI platform. \"That's changed the conversation in a lot of people's minds where they really get it on a deeper \nlevel.\"\nThere is reason for caution, however. \nWhile text generators like ChatGPT and Microsoft's Bing chatbot can make the process of writing emails, \npresentations and marketing pitches faster and easier, they also have a tendency to confidently present \nmisinformation as fact. \nImage generators trained on a huge trove of digital art and photography have raised copyright concerns from the \noriginal creators of those works.\n\"For companies that are really in the creative industry, if they want to make sure that they have copyright protection \nfor those models, that's still an open question,\" said attorney Anna Gressel of the law firm Debevoise & Plimpton, \nwhich advises businesses on how to use AI.\nA safer use has been thinking of the tools as a brainstorming \"thought partner\" that won't produce the final product, \nGressel said.\n\"It helps create mock-ups that then are going to be turned by a human into something that is more concrete,\" she \nsaid.\nForrester analyst Rowan Curran said the tools should speed up some of the \"nitty-gritty\" of office tasks - much like \nprevious innovations such as word processors and spell checkers - rather than putting people out of work.\n\"Ultimately, it's part of the workflow,\" Curran said. \"It's not like we're talking about having a large language model \njust generate an entire marketing campaign and have that launch without expert senior marketers and all kinds of \nother controls.\"\nFor consumer-facing chatbots getting integrated into smartphone apps, it gets a little trickier, Curran said, with a \nneed for guardrails around technology that can respond to users' questions in unexpected ways.\nLoad-Date: March 11, 2023"
    },
    {
        "file_name": "Aiman_Ezzat_Sep2023",
        "header": "People come to India for its talent, not to cut costs: Capgemini global CEO",
        "media": "Aiman Ezzat",
        "time": "September 15, 2023",
        "section": "ITES",
        "length": "779 words",
        "byline": "Romita Majumdar",
        "story_text": "People come to India for its talent, not to cut costs: Capgemini global CEO \nAiman Ezzat\nThe Economic Times\nSeptember 16, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 779 words\nByline: Romita Majumdar\nBody\nIndia is a fast-growing market for French IT services major Capgemini and a solid base for it to service clients \nglobally, Capgemini global CEO Aiman Ezzat told ET. The company has more than half of its 360,000 employee \nbase in India. In an interview with Romita Majumdar, the chief of the $23-billion IT company, during his ongoing \nIndia visit, said that he is hopeful of the demand situation improving over the next two-to-four quarters but is waiting \nfor an inflection point. Ezzat added that generative AI's impact on productivity gains will be much higher than \npricing gains in the long run. \nEdited excerpts:How do you see technology spending in the current macroeconomic situation?It is pretty mixed at \npresent. There is softness in some places but not everything is doomed. The reality is that our pipelines are huge \nand that shows the appetite for technology and transformation.Europe has been more resilient. There is a bit more \nsoftness in the US. We have been preparing for this scenario since the end of last year and we anticipated the \ndeceleration. The sectors facing the biggest rationalization are tech, telecom and financial services which are big for \nus in the US.We can see plenty of positive signs but what I'm looking for is an inflection point because that will \nreally be the real restoration (of demand).Capgemini has gone slow on hiring over the past year. When will hiring be \nback on track for laterals as well as freshers?In the last few years, we had to deal with high attrition and high \ngrowth. For that we had to buffer because if you end up having 30% attrition in a year you cannot replace people \novernight. And India is one of the countries where we have the highest attrition and potentially the highest growth at \nthe same time. Now, when things get optimised, you see less growth and attrition comes down, you don't need to \noperate with these buffers (of people). So we are in the optimization phase. I'm not the only one, the whole industry \nis doing that. But it's not a sign that the business is declining, it is just that we're able to optimize right now. So of \ncourse, we'll be onboarding less freshers, in the short term, but this can change in two or three quarters.India is a \nhuge talent hub for Capgemini, but how is India as a market?It is growing. We have a great team here, I love \ncoming here. Of course, it's still not at the same level of maturity, in some other countries like the US or Germany, \netc. But as the maturity of the country from an economic perspective increases, they start to value more high end \nservices.We are seeing a trend of massive expansion of GCCs in India.People are coming to India, not just for cost. \nIt's (for) access to talent. They realised that without having a base in India, they're missing part of the talent pool. So \nI see this trend will continue and it's just more the realisation that they need to have a footprint in India, because \ntechnology has become so important to them.Capgemini has announced an acquisition in Japan recently and now \nanother acquisition in the financial compliance space. Is this a good market for acquisition at lower valuations?We \nlook at a lot of companies and a few end up being interesting. We are still in acquisition mode. The reality of this \nmarket is that some people are ready to sell at a lower price while some want to wait for the market to become \nbetter before they sell. So there is a mix. We continue to (evaluate) deals that make sense for us at the right value \nto complement some of the capabilities that we have. So it's more towards bolt-on types of acquisitions to \ncomplement capabilities and from a geography perspective, it will mainly be in Asia Pacific.You have recently \nannounced Euro 2 billion investments in artificial intelligence (AI). Where will it go?A lot of the investments will go \nPeople come to India for its talent, not to cut costs: Capgemini global CEO Aiman Ezzat\ninto building the talent, into training and reskilling. Some of it will go in development of some assets and of course \nsetting up Centers of Excellence, etc.There's a lot of hype around generative AI. But is it driving returns?It is going \nto be slow (revenue from Gen AI). When people started investing in scale projects from POCs of digital \ntransformation projects in the early days, it was almost a leap of faith and the scaling could take up to three years. \nThe good part with generative AI is that within 6-8 weeks we can see tangible results and clients are ready to scale \nup.Now there is no Gen AI solution which will change the world on its own. It is about building a relationship with \ncustomers, becoming their partners and building a large number of POCs to offer business solutions across a range \nof issues. For Reprint Rights: timescontent.com\nLoad-Date: September 15, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Jul2023",
        "header": "AI developing multiple personalities",
        "media": "The Baltimore Sun",
        "time": "July 6, 2023",
        "section": "MAIN; A; Pg. 11",
        "length": "967 words",
        "byline": "Parmy Olson Bloomberg Opinion",
        "story_text": "AI developing multiple personalities\nThe Baltimore Sun\nJuly 6, 2023 Thursday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 11\nLength: 967 words\nByline: Parmy Olson Bloomberg Opinion\nHighlight: Artificial intelligence developers debate whether it works better as a behind-the-scenes factotum or as a \npersonable companion. Parmy Olson says it will likely be both. Josep Lago/Getty-AFP\nBody\nChatbots aren't just useful for writing essays and emails. Those designed to show empathy and retain memories \nabout their users are already acting as personal guides. A man who recently tried using a chatbot called Pi realized \nit could help him give up smoking if he went to it each time he had a craving. Whenever he did, it would remind him \nof all the reasons why quitting was a good idea, including being around in the future for his child.\nPi's creator is a Silicon Valley startup called Inflection, which raised a remarkable $1.3 billion last week to build a \n\"personal AI for everyone,\" a chatbot that can act as a confidant for personal matters. The funding round made \nInflection the second-highest funded generative AI startup after OpenAI, which has raised more than $11 billion to \ndate. But the company behind ChatGPT is chasing a different sort of vision and reportedly working on a personal \nassistant that will be much more functional and work-oriented than the original ChatGPT or Pi, which are more like \ndigital companions.\nThere's a debate raging among industry executives about whether it makes better business sense to \nanthropomorphize artificial intelligence in the way OpenAI has done with ChatGPT or make it as neutral and \nfunctional as possible, like the operating system you use on your phone. When we settle into a reality where we're \nregularly talking to computers, will we be interacting with something more like Microsoft's discontinued virtual \nassistant Clippy or more like Microsoft Excel? What seems most probable is that we'll be using both types of AI in \nthe future to make us more productive on the one hand and navigate us through our personal lives on the other.\nIt's that latter use that will take some getting used to, but for the most part we'll see companion-style AI become \nmanifest through services aimed at regular people, not enterprises. Inflection co-founder Mustafa Suleyman, who \nwas also a co-founder of Google DeepMind, says Pi is ultimately a consumer product. He envisions it acting like a \nchief of staff that advises people on planning their weekend or shopping for clothes, and one that can chat with \ncustomer service agents on their behalf.\n\"It will be aligned to your interests,\" he says. \"It'll give you feedback and advice and it will see what you see and be \nwith you where you go. Pi has a memory and is infinitely patient and supportive.\" But Pi is also designed to remind \npeople that it doesn't have feelings and isn't human. In other words, Suleyman says, it also has clear boundaries.\nIt might seem odd at first to engage with software on a personal level, but Suleyman and his co-founder, storied \nventure capitalist and PayPal Mafia member Reid Hoffman, along with plenty of other AI builders, say we're \nheading in that direction.\nAI developing multiple personalities\nPart of the draw of companion-style AI may be that many people remain more isolated than they ever were before \nthe COVID-19 pandemic. A March 2022 poll conducted by the Kaiser Family Foundation found that 59% of \nrespondents hadn't returned to their pre-pandemic activities, and many office workers continue to work remotely. \nAnd though chatbots like ChatGPT frequently make factual errors, their abilities to show empathy are much more \nreliable. It's little wonder that some 5 million people have registered to use an app called Replika, which offers AI-\npowered companions that many see as friends or even romantic partners.\nAdept, a generative AI startup in San Francisco funded by Hoffman's venture capital firm Greylock Partners, looks \nat human-AI interaction in a much more functional way, even though you're essentially talking to it. The company \nwas founded by a former leader of Google's large language model projects and two scientists who co-wrote a \nseminal paper on \"transformers,\" a key technology that allowed ChatGPT to be constructed. Rather than build a \nstand-alone chatbot, Adept is creating a system that can process conversational commands from a human and use \nsoftware.\n\"We want to build a natural language interface to your computers,\" says David Luan, chief executive officer of \nAdept. \"We don't want it to be a separate agent.\"\nThe idea is that down the line, people who use enterprise software won't need to scroll around a web page and click \non seemingly endless menu options to carry out a task - they'll simply ask the website to do work for them, using a \ntext-dialogue box. You could, for instance, ask the system to put a batch of LinkedIn profiles into Salesforce or \ncreate a CAD model - things you might not already know how to do - and Adept's technology will do it for you. If \nsuccessful, this approach to navigating software could arguably make certain user interfaces obsolete, a kind of \nbehind-the-scenes plumbing that humans no longer have to steer. Why design an array of colorful menus and \nwebpages when AI services will do most of the trawling through them anyway?\nOpenAI appears to be working on both approaches; it has built ChatGPT as an entity that people can talk to, but it's \nalso designing a more functional system that will be integrated into everyday enterprise as a kind of work tool, \nsimilar to what Adept is developing, and also comparable to Microsoft Copilot, a product Microsoft is bringing to \nmarket as a result of its use of OpenAI's technology, according to a recent report in The Information. That could put \nOpenAI in an awkward position with Microsoft, its lead investor.\nPushing into functional AI - and at the risk of upsetting Microsoft - says a lot about where OpenAI's CEO Sam \nAltman sees so-called conversational AI in the future: as both a separate entity that we'll converse with and \nsomething that's built into our infrastructure. And it seems that in any case, we'll be talking to computers much more \nthan we do now.\nDistributed by Tribune Content Agency\nLoad-Date: July 6, 2023"
    },
    {
        "file_name": "broadcasters_Dec2023",
        "header": "None of these anchors are real: Channel 1 plans for AI to generate news,",
        "media": "broadcasters",
        "time": "December 20, 2023",
        "section": "TECH LATEST & BROADCASTING INDUSTRY NEWS",
        "length": "660 words",
        "byline": "Anthony Robledo, USA TODAY",
        "story_text": "None of these anchors are real: Channel 1 plans for AI to generate news, \nbroadcasters\nUSA Today Online\nDecember 15, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST & BROADCASTING INDUSTRY NEWS\nLength: 660 words\nByline: Anthony Robledo, USA TODAY\nBody\nThe world's first news network entirely generated by artificial intelligence is set to launch next year.  \nChannel 1 released a promotional video explaining how the service will provide personalized news coverage to \nusers from international affairs, finance and entertainment. The outlet said their team of AI generated reported can \noffer a global perspective 24/7. \nThe reporters in the video appear to be human but are actually made from the scan of a real person. With digitally \ngenerated voices and zero human emotion, the reporters can tell the news in any language.\nSee the highest quality AI footage in the world.\n - Our generated anchors deliver stories that are informative, heartfelt and entertaining.\nWatch the showcase episode of our upcoming news network now. pic.twitter.com/61TaG6Kix3\n— Channel 1 (@channel1_ai)\nDecember 12, 2023\n\"You can hear us and see our lips but no one was recorded saying what we're all saying,\" an blonde artificial \njournalist who appears to be a real human person said in the video. \"I'm powered by sophisticated systems behind \nthe scenes.\"\nFounder and entrepreneur Adam Mosam said the news aired on the network will come from legacy outlets and \ncommissioned freelance reporters. Additionally, the AI will generate its own reporting from public records and \ngovernment documents.\nAI network to launch on streaming by spring\nThe creators Mosam and film producer Scott Zabielski said they aim to launch Channel 1 AI for free with ad-\nsupported streaming on apps this spring. \nThe founders are also planning a Channel 1 app with its own translation feature by the summer.\nNew ways to cheat? Scientists say AI is emerging as potential tool to aid athletes, beat drug tests\nCreators say program will re-create real events\nNone of these anchors are real: Channel 1 plans for AI to generate news, broadcasters\nThe initial demo of the network relied on stock footage and photos however the creators said they intend to re-\ncreate events not captured by camera using generative AI, according to a story by The Hollywood Reporter \npublished in July.\n\"The closest analogy I could give is when you talk about a trial that was covered with 'there’s no cameras allowed' \nand you’ll see the courtroom sketch,\" Mosam told The Hollywood Reporter. \"What we’re looking to do potentially is \nto add visuals where we would clearly denote this is generated imagery. So we’re not trying to pull the wool over \nanyone’s eyes to say like, 'Our cameras were inside the Oval Office when this meeting happened.'\"\nZabielski said that the channel follows what other companies such as Spotify and TikTok use to make the user \nexperience more personal, adding \"that’s something we don’t really see in news yet.\"\nQuestions raised about AI's journalistic integrity\nChannel 1 has raised concerns about the accuracy and journalistic integrity of AI generated reporting. \nLAist Associate Editor Aaricka Washington said the promotional video shows how easy it will be for AI news to \nspread misinformation.  \nThis is terrifying. Sure, news will be easier and quicker to produce, but the costs overwhelmingly outweigh the \nbenefits. AI news is a new frontier that will make it easier for bad faith actors to spread misinformation and \ndisinformation. We can't even imagine the impact. https://t.co/yrgNMt2NUe\n— Aaricka Washington (@aarickawash)\nDecember 14, 2023\n\"This is terrifying. Sure, news will be easier and quicker to produce, but the costs overwhelmingly outweigh the \nbenefits. AI news is a new frontier that will make it easier for bad faith actors to spread misinformation and \ndisinformation. We can't even imagine the impact,\" Washington wrote.\n\"If you believe in the concept of 'fake news,' you have seen nothing,\" Ruby Media Group CEO Kristen Ruby wrote \non X (formerly Twitter). \"At least your news is presented by humans. When AI news anchors replace human news \nanchors - the concept of fake news will have a totally different meaning.\"\nThis article originally appeared on USA TODAY: None of these anchors are real: Channel 1 plans for AI to generate \nnews, broadcasters\nLoad-Date: December 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Roll Over, Beethoven. Again.",
        "media": "The New York Times",
        "time": "June 11, 2023",
        "section": "Section AR; Column 0; Arts and Leisure Desk; Pg. 8",
        "length": "1633 words",
        "byline": "By Garrett Schumann",
        "story_text": "Roll Over, Beethoven. Again.\nThe New York Times\nJune 11, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section AR; Column 0; Arts and Leisure Desk; Pg. 8\nLength: 1633 words\nByline: By Garrett Schumann\nBody\nArtificial intelligence is not new to classical music. But its recent, rapid developments have composers worried, and \nintrigued.\nWhen the composer and vocalist Jen Wang took the stage at the Monk Space in Los Angeles to perform Alvin \nLucier's ''The Duke of York'' (1971) earlier this year, she sang with a digital rendition of her voice, synthesized by \nartificial intelligence. \n  It was the first time she had done that. ''I thought it was going to be really disorienting,'' Wang said in an interview, \n''but it felt like I was collaborating with this instrument that was me and was not me.''\n  Isaac Io Schankler, a composer and music professor at Cal Poly Pomona, conceived the performance and joined \nWang onstage to monitor and manipulate Realtime Audio Variational autoEncoder, or R.A.V.E., the neural audio \nsynthesis algorithm that modeled Wang's voice.\n  R.A.V.E. is an example of machine learning, a specific category of artificial intelligence technology that musicians \nhave experimented with since the 1990s -- but that now is defined by rapid development, the arrival of publicly \navailable, A.I.-powered music tools and the dominating influence of high-profile initiatives by large tech companies.\n  Dr. Schankler ultimately used R.A.V.E in that performance of ''The Duke Of York,'' though, because its ability to \naugment an individual performer's sound, they said, ''seemed thematically resonant with the piece.'' For it to work, \nthe duo needed to train it on a personalized corpus of recordings. ''I sang and spoke for three hours straight,'' Wang \nrecalled. ''I sang every song I could think of.''\n  Antoine Caillon developed R.A.V.E. in 2021, during his graduate studies at IRCAM, the institute founded by the \ncomposer Pierre Boulez in Paris. ''R.A.V.E.'s goal is to reconstruct its input,'' he said. ''The model compresses the \naudio signal it receives and tries to extract the sound's salient features in order to resynthesize it properly.''\n  Wang felt comfortable performing with the software because, no matter the sounds it produced in the moment, she \ncould hear herself in R.A.V.E.'s synthesized voice. ''The gestures were surprising, and the textures were \nsurprising,'' she said, ''but the timbre was incredibly familiar.'' And, because R.A.V.E. is compatible with common \nelectronic music software, Dr. Schankler was able to adjust the program in real time, they said, to ''create this halo \nof other versions of Jen's voice around her.''\n  Tina Tallon, a composer and professor of A.I. and the arts at the University of Florida, said that musicians have \nused various A.I.-related technologies since the mid-20th century.\nRoll Over, Beethoven. Again.\n  ''There are rule-based systems, which is what artificial intelligence used to be in the '60s, '70s, and '80s,'' she said, \n''and then there is machine learning, which became more popular and more practical in the '90s, and involves \ningesting large amounts of data to infer how a system functions.''\n  Today, developments in A.I. that were once contained to specialized applications impinge on virtually every corner \nof life, and already impact the way people make music. Dr. Caillon, in addition to developing R.A.V.E., has \ncontributed to the Google-led projects SingSong, which generates accompaniments for recorded vocal melodies, \nand MusicLM, another text-to-music generator. Innovations in other areas are driving new music technologies, too: \nWavTool, a recently released, A.I.-powered music production platform, fully integrates OpenAI's GPT-4 to enable \nusers to create music via text prompts.\n  For Dr. Tallon, the difference in scale between individual composers' customized use of A.I. and these new, broad-\nreaching technologies represents a cause for concern.\n  ''We are looking at different types of datasets that are compiled for different reasons,'' she said. ''Tools like \nMusicLM are trained on datasets that are compiled by pulling from thousands of hours of labeled audio from \nYouTube and other places on the internet.''\n  ''When I design a tool for my own personal use,'' Dr. Tallon continued, ''I'm looking at data related to my sonic \npriorities. But public-facing technologies use datasets that focus on, for instance, aesthetic ideals that align more \nclosely with Western classical systems of organizing pitches and rhythms.''\n  Concerns over bias in music-related A.I. tools do not stop at aesthetics. Enongo Lumumba-Kasongo, a music \nprofessor at Brown University, also worries about how these technologies can reproduce social hierarchies.\n  ''There is a very specific racial discourse that I'm very concerned about,'' she said. ''I don't think it's a coincidence \nthat hip-hop artistry is forming the testing ground for understanding how A.I. affects artists and their artistry given \nthe centuries-long story of co-optation and theft of Black expressive forms by those in power.''\n  The popularity of recent A.I.-generated songs that mimicked artists like Drake, the Weeknd, Travis Scott and \nothers have animated Dr. Lumumba-Kasongo's fears. ''What I'm most concerned about with A.I. Drake and A.I. \nTravis Scott is that their music is highly listenable,'' she said, ''and calls into question any need for an artist once \nthey've articulated a distinct 'voice.'''\n  For Dr. Schankler, there are key differences between using R.A.V.E. to synthesize new versions of a collaborator's \nvoice and using A.I. to anonymously imitate a living musician. ''I don't find it super interesting to copy someone's \nvoice exactly, because that person already exists,'' they said. ''I'm more interested in the new sonic possibilities of \nthis technology. And what I like about R.A.V.E. is that I can work with a small dataset that is created by one person \nwho gives their permission and participates in the process.''\n  The composer Robert Laidlow also uses A.I. in his work to contemplate the technology's fraught implications. \n''Silicon,'' which premiered last October with the BBC Philharmonic under Vimbayi Kaziboni, employs multiple tools \nto explore themes drawn from the technology's transformative and disruptive potential.\n  [Video:  Watch on YouTube.]\n  Laidlow described ''Silicon'' as ''about technology as much as it uses technology,'' adding: ''The overriding \naesthetic of each movement of this piece are the questions, 'What does it mean for an orchestra to use this \ntechnology?' and 'What would be the point of an orchestra if we had a technology that can emulate it in every \nway?'''\n  The work's entirely acoustic first movement features a mixture of Laidlow's original music and ideas he adapted \nfrom the output, he said, of a ''symbolic, generative A.I. that was trained on notated material from composers all \nthroughout history.'' The second movement features an A.I.-powered digital instrument, performed by the \norchestra's pianist, that, ''sometimes mimics the orchestra and sometimes makes uncanny, weird sounds.''\nRoll Over, Beethoven. Again.\n  In the last movement, the orchestra is accompanied with sounds generated by a neural synthesis program called \nPRiSM-SampleRNN, which is akin to R.A.V.E. and was trained on a large archive of BBC Philharmonic radio \nbroadcasts. Laidlow describes the resulting audio as, ''featuring synthesized orchestral music, voices of phantom \npresenters and the sounds the artificial intelligence has learned from audiences.''\n  The size of ''Silicon'' contrasts with the intimacy of Dr. Schankler and Wang's performance of ''The Duke of York.'' \nBut both instances illustrate A.I.'s potential to expand musical practices and human expression. And, importantly, by \nemploying small, curated datasets tailored to individual collaborators, these projects attempt to obviate ethical \nconcerns many have identified in larger-scale technologies.\n  George E. Lewis, a music professor at Columbia University, has designed and performed alongside interactive A.I. \nmusic programs for four decades, focusing primarily on the technology's capacity to participate in live performance. \n''I keep talking about real-time dialogue,'' he said. ''Music is so communal, it's so personal, it's so dialogic, it's \ncommunitarian.''\n  He is hopeful that people will continue to explore interactivity and spontaneity. ''It seems the current generation of \nA.I. music programs have been designed for a culturally specific way of thinking about music,'' Lewis said. ''Imagine \nif the culture favored improvisation.''\n  [Video:  Watch on YouTube.]\n  As a composer, Lewis is continuing to explore this topic, including his recent work ''Forager,'' for chamber \nensemble and A.I., which was created during a 2022 residency at PRiSM. The piece marks the latest update to \n''Voyager,'' a piece that he developed in 1985 and described as a, ''virtual improvising pianist.'' ''Forager'' enhances \nthe software's responsiveness to its human co-performers with new programming that enables what he called, ''a \nmore holistic recognition'' of musical materials.\n  The differences among Dr. Schankler's use of R.A.V.E., Robert Laidlow's orchestral work ''Silicon'' and Lewis's \ninteractive ''Forager'' underscore the nuances with which composers and experimental musicians are approaching \nA.I. This culture celebrates technology as means to customize musical ideas and computer-generated sounds to \nsuit specific performers and a given moment. Still, these artistic aims stand at odds with the foreboding prompted by \nothers like Dr. Tallon and Dr. Lumumba-Kasongo.\n  Individual musicians can do their part to counter those worries by using A.I. ethically and generatively. But even \nso, as Laidlow observed, being truly individual -- which is to say independent -- is difficult.\n  ''There is a fundamental problem of resources in this field,'' Laidlow said. ''It is almost impossible to create \nsomething computationally powerful without the assistance of a huge, technologically advanced institute or \ncorporation.''\nhttps://www.nytimes.com/2023/06/10/arts/music/ai-classical-music.html\nGraphic\n \nThis article appeared in print on page AR8.               \nLoad-Date: June 11, 2023"
    },
    {
        "file_name": "mysterious,_but_the_effects_will_be_painfully_public_as_the_AI_industry_orients_Nov2023",
        "header": "OpenAI's drama marks a scary new era; The leadership shuffle is",
        "media": "mysterious, but the effects will be painfully public as the AI industry orients",
        "time": "November 29, 2023",
        "section": "MAIN NEWS; Opinion Desk; Part A; Pg. 1",
        "length": "792 words",
        "byline": "Daron Acemoglu, Simon Johnson, Daron Acemoglu and Simon Johnson are professors at MIT and co-",
        "story_text": "OpenAI's drama marks a scary new era; The leadership shuffle is \nmysterious, but the effects will be painfully public as the AI industry orients \naround profit.\nLos Angeles Times\nNovember 29, 2023 Wednesday\nFinal Edition\nCopyright 2023 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Opinion Desk; Part A; Pg. 1\nLength: 792 words\nByline: Daron Acemoglu, Simon Johnson, Daron Acemoglu and Simon Johnson are professors at MIT and co-\nauthors of \"Power and Progress: Our 1,000-Year Struggle Over Technology & Prosperity.\"\nBody\nSam Altman's dismissal and rapid reinstatement as chief executive of OpenAI, the creator of ChatGPT, confirms \nthat the future of AI is firmly in the hands of people focused on speed and profits, at the expense of all else. This \nelite will now impose their vision for technology on the rest of humanity. Most of us will not enjoy the consequences.\nThe founders of OpenAI claimed to be creating a philanthropic organization that would benefit all of humanity or at \nleast protect it from potential harm. OpenAI is ostensibly a nonprofit, and had a small board made up of academics \nand experts -- and notably, did not include investors. We may never know what really happened on Nov. 17, when \nthe board fired Altman, but the most likely interpretation is that members of this board were troubled by Altman's \ncommercial emphasis and the headlong rush to develop new, powerful models of generative artificial \nintelligence.\nIt is encouraging to think there are still people in Silicon Valley who worry about guardrails because digital \ntechnology has already done plenty of damage to jobs, wages and democracy. For example, this sector brought us \nFacebook and social media, which have been used to fan the flames of hatred around the world, in the name of \n\"engagement\" and selling more digital ads.\nAltman forced the OpenAI board to resign, as a condition of his return to the company. The new board, chaired by \nformer Salesforce co-CEO Bret Taylor, is likely to be more sympathetic to OpenAI scaling up as fast as possible, \nregardless of the consequences. This recklessness is driven by the profit motive, turbocharged by venture capital, \nin which the most money flows to products and services that grow fastest, even if this comes with huge financial \nlosses and tremendous societal costs.\nDisruption and uncontrolled growth have become religion for the tech industry, and Altman has been one of its most \ndedicated high priests. Yet unsustainable growth rates and large losses are not supported by the logic of the \ntraditional capitalist market system. Venture capital created this way of operating, but OpenAI doesn't need \ntraditional VCs, because it has Microsoft, which has already committed $10 billion to the company. Top Microsoft \nexecutives stayed focused on their goals during the Altman crisis: hire the talent, promise them unlimited money to \nspend, and press the pedal to the metal.\nWorse, the speed imperative is boosted by the predominant vision in Silicon Valley, which cares little about social \nresponsibility or what happens to people.\nOpenAI's drama marks a scary new era The leadership shuffle is mysterious, but the effects will be painfully \npublic as the AI industry orients around profit.\nAn informal spokesperson for this view of the world is Marc Andreessen, legendary venture capitalist and big \nAltman cheerleader. In October, Andreessen put out his own \"Techno-Optimist's Manifesto,\" which included such \nbizarre statements as \"We had a problem of isolation, so we invented the Internet;\" \"We have a problem of poverty, \nso we invent technology to create abundance;\" and perhaps the purest declaration of tech arrogance: \"Give us a \nreal world problem, and we can invent technology that will solve it.\"\nTellingly, Mr. Andreesen does not reflect on why there are so many homeless people in the San Francisco Bay \narea, why there is a mental health crisis among teenagers, why Myanmar is on fire, or why the U.S. has become \none of the most unequal and deeply polarized societies in modern history, despite all the technology at our \ndisposal. One can certainly argue that these problems were exacerbated, if not created, by the tech sector.\nAltman previously founded Y Combinator, a start-up accelerator, which asks applicants, \"Please tell us about the \ntime you, [applicant name], most successfully hacked some (non-computer) system to your advantage.\" Silicon \nValley leaders love to say things like \"move fast and break things\" (the internal Facebook motto at one point) or, as \nSheera Frankel and Cecelia Kang document in their book on Facebook, \"An Ugly Truth\": \"F--k it, ship it.\"\nIn Washington, D.C., any whiff of regulation or sensible guardrails drives top tech executives apoplectic. The tech \nbros have embraced the full-fledged libertarian fantasy in which they are the indispensable men.\nIn \"The Shape of Things to Come,\" published in the early 1930s, H.G. Wells imagined a dystopian near future, in \nwhich aerial bombing campaigns came close to destroying civilization. But, after more than 20 years of disaster, \nWells imagined that a new global elite controlling aviation technology would emerge to impose world peace.\nWells was right about the dangers posed by the unbridled and unprincipled development of technology. But his \nwork of science fiction about a dictatorship of the elite holding the keys to the future of the world is just as disturbing \ntoday as it was in the heyday of European fascism.\nGraphic\n \nPHOTO: SAM ALTMAN is the former and current chief executive of ChatGPT's creator.  PHOTOGRAPHER:Jaap \nArriens NurPhoto/Getty Images \nLoad-Date: November 29, 2023"
    },
    {
        "file_name": "Los_Angeles_Times_Dec2023",
        "header": "Explicit child photos hidden inside AI image generators",
        "media": "Los Angeles Times",
        "time": "December 31, 2023",
        "section": "MAIN NEWS; National Desk; Part A; Pg. 1",
        "length": "1244 words",
        "byline": "O'Brien and Hadero write for the Associated Press.",
        "story_text": "Explicit child photos hidden inside AI image generators\nLos Angeles Times\nDecember 31, 2023 Sunday\nFinal Edition\nCopyright 2023 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; National Desk; Part A; Pg. 1\nLength: 1244 words\nByline: O'Brien and Hadero write for the Associated Press.\nBody\nHidden inside the foundation of popular artificial intelligence image generators are thousands of images of child \nsexual abuse, according to a new report that urges companies to take action to address a harmful flaw in the \ntechnology they built.\nThose same images have made it easier for AI systems to produce realistic and explicit imagery of fake children as \nwell as transform social media photos of fully clothed real teens into nudes, much to the alarm of schools and law \nenforcement around the world.\nUntil recently, anti-abuse researchers thought the only way that some unchecked AI tools produced abusive \nimagery of children was by essentially combining what they've learned from two separate buckets of online images \n-- adult pornography and benign photos of kids.\nBut the Stanford Internet Observatory found more than 3,200 images of suspected child sexual abuse in the Large-\nscale Artificial Intelligence Open Network, a giant AI database index of online images and captions that's been used \nto train leading AI image makers such as Stable Diffusion. The watchdog group based at Stanford University \nworked with the Canadian Center for Child Protection and other anti-abuse charities to identify the illegal material \nand report the original photo links to law enforcement.\nThe response was immediate. On the eve of the Wednesday release of the Stanford Internet Observatory's report, \nLAION told the Associated Press it was temporarily removing its data sets.\nLAION said in a statement that it \"has a zero tolerance policy for illegal content and in an abundance of caution, we \nhave taken down the LAION data sets to ensure they are safe before republishing them.\"\nAlthough the images account for just a fraction of LAION's index of some 5.8 billion images, the Stanford group \nsays it probably is influencing the ability of AI tools to generate harmful outputs and reinforcing the prior abuse of \nreal victims who appear multiple times.\nIt's not an easy problem to fix, and it traces back to many generative AI projects being \"effectively rushed to \nmarket\" and made widely accessible because the field is so competitive, said Stanford Internet Observatory's chief \ntechnologist, David Thiel, who wrote the report.\n\"Taking an entire internet-wide scrape and making that data set to train models is something that should have been \nconfined to a research operation, if anything, and is not something that should have been open-sourced without a \nlot more rigorous attention,\" Thiel said in an interview.\nExplicit child photos hidden inside AI image generators\nA prominent LAION user that helped shape the data set's development is London-based startup Stability AI, maker \nof the Stable Diffusion text-to-image models. New versions of Stable Diffusion have made it much harder to create \nharmful content, but an older version introduced last year -- which Stability AI says it didn't release -- is still baked \ninto other applications and tools and remains \"the most popular model for generating explicit imagery,\" according to \nthe Stanford report.\n\"We can't take that back. That model is in the hands of many people on their local machines,\" said Lloyd \nRichardson, director of information technology at the Canadian Center for Child Protection, which runs Canada's \nhotline for reporting online sexual exploitation.\nStability AI on Wednesday said it hosts only filtered versions of Stable Diffusion and that \"since taking over the \nexclusive development of Stable Diffusion, Stability AI has taken proactive steps to mitigate the risk of misuse.\"\n\"Those filters remove unsafe content from reaching the models,\" the company said in a prepared statement. \"By \nremoving that content before it ever reaches the model, we can help to prevent the model from generating unsafe \ncontent.\"\nLAION was the brainchild of a German researcher and teacher, Christoph Schuhmann, who told the AP earlier this \nyear that part of the reason to make such a huge visual database publicly accessible was to ensure that the future \nof AI development isn't controlled by a handful of powerful companies.\n\"It will be much safer and much more fair if we can democratize it so that the whole research community and the \nwhole general public can benefit from it,\" he said.\nMuch of LAION's data comes from another source, Common Crawl, a repository of data constantly trawled from the \nopen internet, but Common Crawl's executive director, Rich Skrenta, said it was \"incumbent on\" LAION to scan and \nfilter what it took before making use of it.\nLAION said last week that it developed \"rigorous filters\" to detect and remove illegal content before releasing its \ndata sets and is still working to improve those filters. The Stanford report acknowledged LAION's developers made \nsome attempts to filter out \"underage\" explicit content but might have done a better job had they consulted earlier \nwith child-safety experts.\nMany text-to-image generators are derived in some way from the LAION database, though it's not always clear \nwhich ones. OpenAI, the maker of DALL-E and ChatGPT, said it doesn't use LAION and has fine-tuned its models \nto refuse requests for sexual content involving minors.\nGoogle built its text-to-image Imagen model based on a LAION data set but decided against making it public in \n2022 after an audit of the database \"uncovered a wide range of inappropriate content including pornographic \nimagery, racist slurs, and harmful social stereotypes.\"\nTrying to clean up the data retroactively is difficult, so the Stanford Internet Observatory is calling for more drastic \nmeasures. One is for anyone who's built training sets off of LAION-5B -- named for the more than 5 billion image-\ntext pairs it contains -- to \"delete them or work with intermediaries to clean the material.\" Another is to, in effect, \nmake an older version of Stable Diffusion disappear from all but the darkest corners of the internet.\n\"Legitimate platforms can stop offering versions of it for download,\" particularly if they are frequently used to \ngenerate abusive images and have no safeguards to block them, Thiel said.\nAs an example, Thiel called out CivitAI, a platform that's favored by people making AI-generated pornography but \nwhich he said lacks safety measures to weigh it against making images of children. The report also calls on AI \ncompany Hugging Face, which distributes the training data for models, to implement better methods to report and \nremove links to abusive material.\nHugging Face said it is regularly working with regulators and child safety groups to identify and remove abusive \nmaterial. Meanwhile, CivitAI said it has \"strict policies\" on the generation of images depicting children and has rolled \nExplicit child photos hidden inside AI image generators\nout updates to provide more safeguards. The company also said it is working to ensure its policies are \"adapting \nand growing\" as the technology evolves.\nThe Stanford report also questions whether any photos of children -- even the most benign -- should be fed into AI \nsystems without their family's consent because of protections in the federal Children's Online Privacy Protection \nAct.\nRebecca Portnoff, the director of data science at the anti-child sexual abuse organization Thorn, said her \norganization has conducted research that shows the prevalence of AI-generated images among abusers is small \nbut growing consistently.\nDevelopers can mitigate these harms by making sure the data sets they use to develop AI models are clean of \nabuse materials. Portnoff said there are also opportunities to mitigate harmful uses down the line after models are \nalready in circulation.\nGraphic\n \nPHOTO: DAVID THIEL, chief technologist at the Stanford Internet Observatory, wrote its report that found images \nof child sexual abuse in AI image generators.  PHOTOGRAPHER:Camilla Mendes dos Santos Associated Press \nLoad-Date: December 31, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jan2024",
        "header": "Shaping India’s digital landscape",
        "media": "Economic Times (E-Paper Edition)",
        "time": "January 11, 2024",
        "section": "ADVERTISEMENT",
        "length": "685 words",
        "byline": "Artha.Neog@timesgroup.com",
        "story_text": "Shaping India’s digital landscape\nEconomic Times (E-Paper Edition)\nJanuary 12, 2024 Friday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ADVERTISEMENT\nLength: 685 words\nByline: Artha.Neog@timesgroup.com\nHighlight: The AdTech landscape undergoes significant changes, driven by the fusion of AI and creativity\nBody\nAs the digital landscape continues its dynamic evolution,  the realm of advertising technology, also known as \nAdTech, stands poised for groundbreaking shifts. From the fusion of  artificial intelligence (AI) and creativity to the \nresurgence of contextual targeting, multiple trends are set to potentially alter the AdTech landscape.  In 2024, the \nIndian advertising market is expected to witness a growth of 11.4 percent and reach `1.22 lakh crore. Also, India is \npredicted to enter the top ten markets and rise to eighth place by 2028. The country was ranked as the 11th largest \nad market in the world as of last year. \nToday, it is crucial to understand and harness emerging trends for publishers and advertisers to stay ahead in the \ndynamic and competitive programmatic world. A KEY GROWTH LEVER As traditional cookies become irrelevant, \nembracing advanced AI techniques like agent-based modelling is essential for adaptable advertising. “Today, in the \npost-cookie era, advertisers must turn to AI-  driven contextual advertising, a potent tool for innovation in \nmanagement, robotics, and marketing. Contextual analysis, based on content rather than personal data, ensures \nprecision in ad positioning, brand safety, and real-time detection of malicious activities,” says, Arpit Jain, founder \nand CEO, PubScale and GreedyGame.  Besides AI, Generative AI (GenAI) can design and create ads that can be \nincorporated into an in-game setting. This will ensure that they are non-intrusive and engaging and help utilise the \nuntapped real estate in games. “In the dynamic realm of Adtech, AI  tools deftly navigate operational tasks, freeing \nmarketers to focus on creativity and strategy— nurturing innovation’s seeds. The investments in cutting-edge \nAdtech and strategic partnerships yield enhanced results, diminishing reliance on traditional manpower,” says, \nArchit Agarwal, founder and CEO, Tikshark Solutions.  The AdTech industry is evolving, and those at the forefront \nof these advancements can be expected to shape the future of  a more nuanced, user-centric, and ethically aligned \nadvertising ecosystem. Dhaval Gupta, MD of CMRSL, the parent company of CMGalaxy, says, “In addition to \ncreating content, analysing data, and automating multiple marketing processes, AI will play a key role in allowing \nmarketing teams to shift away from their day-today routine work and transition to focusing more on how their brands \ncan grow and what customers want.” Elaborating more, Vinod K Singh, cofounder, Concirrus UK, says, “Adtech’s \nfuture lies in AIpowered, hyperrelevant ads that adapt to your context in real-time.  Imagine dynamic visuals, copy, \nand interactions that change based on what you are browsing, watching, or even feeling.” A PROFOUND \nTRANSFORMATION  In 2024, cutting-edge AdTech solutions facilitate the seamless integration of Augmented \nReality (AR) and Virtual Reality VR into existing advertising ecosystems, offering highly interactive and personalised \nconsumer experiences. As we enter 2024, the incorporation of AR and VR represents a paradigm shift in AdTech, \nreshaping  the landscape and paving the way for more engaging and innovative marketing strategies. “AR and VR \nenable immersive, interactive ad experiences, allowing users to engage with products and brands in virtual \nenvironments. Ingame ad creatives enabled by AR or VR will become an effective way to boost engagement \nwithout compromising on user experience,” shares Jain.  As we navigate the dynamic landscape AdTech trends in \n2024, it is evident that the industry is undergoing a  profound transformation. The spotlight is on crafting \nShaping India ’s digital landscape\nexperiences that are not only relevant and personalised but also deeply engaging, all within the framework of user \nprivacy and regulatory compliance.  “A diverse array of emerging AdTech trends is shaping the industry \nencompassing facets  like increased dependency on firstparty data, shift from English to local languages for \nfacilitating better communication, fostering brand transparency to boost loyalty, etc.,” concludes, Delphin Varghese, \ncofounder and chief business officer, AdCounty Media.\nLoad-Date: January 11, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Europeans Take Major Step Toward Regulating A.I.",
        "media": "The New York Times",
        "time": "June 15, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "899 words",
        "byline": "By Adam Satariano",
        "story_text": "Europeans Take Major Step Toward Regulating A.I.\nThe New York Times\nJune 15, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 899 words\nByline: By Adam Satariano\nBody\nA draft law in the European Parliament has become the world's most far-reaching attempt to address the potentially \nharmful effects of artificial intelligence.\nThe European Union took an important step on Wednesday toward passing what would be one of the first major \nlaws to regulate artificial intelligence, a potential model for policymakers around the world as they grapple with how \nto put guardrails on the rapidly developing technology. \n  The European Parliament, a main legislative branch of the European Union, passed a draft law known as the A.I. \nAct, which would put new restrictions on what are seen as the technology's riskiest uses. It would severely curtail \nuses of facial recognition software, while requiring makers of A.I. systems like the ChatGPT chatbot to disclose \nmore about the data used to create their programs.\n  The vote is one step in a longer process. A final version of the law is not expected to be passed until later this \nyear.\n  The European Union is further along than the United States and other large Western governments in regulating \nA.I. The 27-nation bloc has debated the topic for more than two years, and the issue took on new urgency after last \nyear's release of ChatGPT, which intensified concerns about the technology's potential effects on employment and \nsociety.\n  Policymakers everywhere from Washington to Beijing are now racing to control an evolving technology that is \nalarming even some of its earliest creators. In the United States, the White House has released policy ideas that \ninclude rules for testing A.I. systems before they are publicly available and protecting privacy rights. In China, draft \nrules unveiled in April would require makers of chatbots to adhere to the country's strict censorship rules. Beijing is \nalso taking more control over the ways makers of A.I. systems use data.\n  How effective any regulation of A.I. can be is unclear. In a sign that the technology's new abilities are emerging \nseemingly faster than lawmakers are able to address them, earlier versions of the E.U. law did not give much \nattention to so-called generative A.I. systems like ChatGPT, which can produce text, images and video in response \nto prompts.\n  Under the latest version of Europe's bill passed on Wednesday, generative A.I. would face new transparency \nrequirements. That includes publishing summaries of copyrighted material used for training the system, a proposal \nsupported by the publishing industry but opposed by tech developers as technically infeasible. Makers of \ngenerative A.I. systems would also have to put safeguards in place to prevent them from generating illegal content.\nEuropeans Take Major Step Toward Regulating A.I.\n  Francine Bennett, acting director of the Ada Lovelace Institute, an organization in London that has pushed for new \nA.I. laws, said the E.U. proposal was an ''important landmark.''\n  ''Fast-moving and rapidly repurposable technology is of course hard to regulate, when not even the companies \nbuilding the technology are completely clear on how things will play out,'' Ms. Bennett said. ''But it would definitely \nbe worse for us all to continue operating with no adequate regulation at all.''\n  The European bill takes a ''risk-based'' approach to regulating A.I., focusing on applications with the greatest \npotential for human harm. This would include where A.I. systems were used to operate critical infrastructure like \nwater or energy, in the legal system, and when determining access to public services and government benefits. \nMakers of the technology would have to conduct risk assessments before putting the tech into everyday use, akin to \nthe drug approval process.\n  A tech industry group, the Computer & Communications Industry Association, said the European Union should \navoid overly broad regulations that inhibit innovation.\n  ''The E.U. is set to become a leader in regulating artificial intelligence, but whether it will lead on A.I. innovation still \nremains to be seen,'' said Boniface de Champris, the group's Europe policy manager. ''Europe's new A.I. rules need \nto effectively address clearly defined risks, while leaving enough flexibility for developers to deliver useful A.I. \napplications to the benefit of all Europeans.''\n  One major area of debate is the use of facial recognition. The European Parliament voted to ban uses of live facial \nrecognition, but questions remain about whether exemptions should be allowed for national security and other law \nenforcement purposes.\n  Another provision would ban companies from scraping biometric data from social media to build out databases, a \npractice that drew scrutiny after the facial-recognition company Clearview AI used it.\n  Tech leaders have been trying influence the debate. Sam Altman, the chief executive of OpenAI, the maker of \nChatGPT, has in recent months visited with at least 100 American lawmakers and other global policymakers in \nSouth America, Europe, Africa and Asia, including Ursula von der Leyen, president of the European Commission. \nMr. Altman has called for regulation of A.I., but has also said the European Union's proposal may be prohibitively \ndifficult to comply with.\n  After the vote on Wednesday, a final version of the law will be negotiated by representatives of the three branches \nof the European Union -- the European Parliament, the European Commission and the Council of the European \nUnion. Officials said they hoped to reach a final agreement by the end of the year.\nhttps://www.nytimes.com/2023/06/14/technology/europe-ai-regulation.html\nGraphic\n \nPHOTO: The European Parliament passed a draft law that would put new restrictions on what are seen as the \nriskiest uses of A.I. (PHOTOGRAPH BY JULIEN WARNAND/EPA, VIA SHUTTERSTOCK) (B5) This article \nappeared in print on page B1, B5.               \nLoad-Date: June 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "A Trucking Crisis in Japan",
        "media": "The New York Times",
        "time": "December 26, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1261 words",
        "byline": "By Hisako Ueno, John Yoon and Hiroko Masuike/The New York Times",
        "story_text": "A Trucking Crisis in Japan\nThe New York Times\nDecember 26, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1261 words\nByline: By Hisako Ueno, John Yoon and Hiroko Masuike/The New York Times\nBody\nIt was dark when Daiki Funamizu pulled his truck into the market in Osaka, ending a 15-hour haul down Japan's \nmain island. He rubbed his sore back and wiped the sweat off his forehead. Then he began several more hours of \nwork to unload 500 boxes of red apples.\nMr. Funamizu, 35, said he used to like driving. But now, with drivers getting stretched thinner as Japan's population \nshrinks and workers desert the industry, ''I must say I hate it,'' he said. \n  Japan's trucking industry is a crucial cog in one of the world's largest economies, and it is the lifeblood of the \nJapanese culture of ultra-convenience. But it, and its drivers, are under immense strain. To improve job conditions \nand make the work more appealing, the government is moving to cap overtime for the first time next year, easing \nthe punishing hours that have long defined trucking in Japan.\n  Addressing that problem, however, will create others -- potentially disrupting the nation's entire logistics system. It \nis unlikely that enough drivers of big rigs and delivery trucks can be hired anytime soon to make up for the lost \novertime hours. The shortfall could leave supermarket shelves bare of some items and threaten the speedy door-to-\ndoor shipping -- luggage to the airport, or golf clubs to and from the resort -- to which Japanese people are \naccustomed.\n  Officials are calling it the ''2024 problem.''\n  ''I believe this is going to be a hard landing,'' said Mikio Tasaka, a research fellow at NX Logistics Research \nInstitute and Consulting, a think tank in Tokyo.\n  The government is being spurred to action as workers in a range of industries push back against an extreme \nJapanese work culture that leaves little room for work-life balance and has even led to deaths from overwork.\n  Overtime will also be limited for construction laborers, doctors, and drivers of buses and taxis -- workers who, like \ntruckers, often put in very long hours because of labor shortages in a country with 130 job openings for every 100 \napplicants.\n  Their industries, too, are bracing for a shock. But the challenge will be particularly acute for trucking.\n  More than 90 percent of cargo in Japan travels by road, compared with about 73 percent in the United States. \nWith the lost overtime hours, analysts are estimating a 14 percent deficit in delivery capacity next year.\n  Some drivers work 100 overtime hours or more each month, because the work demands it or they need the extra \npay. But starting in April, overtime will be capped at a monthly average of 80 hours, or a daily limit of 15 work hours.\nA Trucking Crisis in Japan\n  By the end of the decade, according to government estimates, a third of Japan's cargo could be left undelivered, \nresulting in a $70 billion economic hit in 2030 alone. Mr. Tasaka, the logistics researcher, warned that the \ndisruptions could cause ''a kind of recession.''\n  Already, before the overtime cap is enacted, the effects of the driver shortage have been widely felt.\n  Convenience stores are reducing lunch box deliveries to twice daily from three times. Supermarket chains are \nallowing an extra day for delivery and avoiding overnight shipping. They are also trying to share distribution centers \nand standardize box sizes under the government's direction.\n  After the new overtime rules take effect, one- or two-day deliveries might no longer be possible, economists say. \nThere might be less fresh seafood and fewer fruits and vegetables in grocery stores. Costs for shipping could jump \n10 percent. Shipping might be unavailable for some customers during peak seasons like Christmas and New \nYear's.\n  In Aomori, a northern Japanese prefecture famous for its apples, farmers are worried that delayed deliveries and \nrising shipping costs will hurt demand. ''Without truck operators, we can't ship,'' said Shoji Naraki, 55, an apple \nfarmer in Aomori.\n  In addition to the labor shortage, the trucking industry is constrained by outdated practices, molded by the habits \nof people elsewhere in the supply chain, such as suppliers and retailers. That makes it difficult to find new \nefficiencies.\n  ''It's not so easy to make changes all at once in this industry,'' said Haruhiko Hoshino, an official at the association \nrepresenting Japan's trucking industry, referring to its interdependent nature.\n  Trucks in Japan do not have detachable trailers, unlike trucks in much of the developed world. Cardboard boxes \nare not standardized -- there are 400 different sizes for shipping oranges, for example.\n  ''Standardization in the logistics industry is very behind in Japan,'' said Yuji Yano, who studies delivery systems at \nRyutsu Keizai University in Japan. ''Pallet sizes are not standardized. Manufacturers and wholesalers don't use \nstandardized data sharing systems.''\n  The lack of uniformity means cargo must be loaded and unloaded by hand -- work performed by forklifts in other \ncountries but by truck drivers in Japan, who are often not paid for that labor because it is not part of their contracts, \nexperts say.\n  In Aomori, these deeply entrenched practices mean that a line of truck drivers must wait hours for their turn in the \napple loading yard.\n  ''Drivers work too much,'' said Mr. Funamizu, the trucker who recently made a produce run from Aomori to Osaka. \n''I don't think the distribution system in Japan will change -- you can't help it.''\n  The Japanese government has proposed a series of incremental changes to soften the blow to the trucking \nindustry.\n  Officials have asked shippers to pay trucking companies fair fees. They have urged them to create more efficient \nprocesses to reduce the time that drivers must wait to load and unload trucks. They have called on shippers to \nmore frequently use alternative means of transport, such as trains and ships. They are also considering raising \nhighway speed limits for trucks to 100 kilometers per hour, from 80.\n  Prime Minister Fumio Kishida has said he will work to increase truck drivers' pay, promised subsidies for logistics \nbusinesses to update their systems and urged residents to be home when their deliveries are scheduled to arrive, \npointing to the need to reduce repeat deliveries that slow drivers.\nA Trucking Crisis in Japan\n  Trucking companies are also considering changes, including allowing foreign workers to become truck drivers. \n(There are currently 200 openings for every 100 trucking applicants.) But driver's licenses in Japan require \nproficiency in Japanese, a skill that foreign workers are less likely to have.\n  Some drivers, even as they lament their working conditions, say they are against the overtime limits. They are \nworried about pay cuts, given that it may be difficult to raise drivers' pay and make up for lost overtime earnings if \nconsumers resist higher shipping costs.\n  Tomoyasu Matsuyama, 31, who earns about $3,060 a month delivering fruits and vegetables, said he expected \nhis monthly pay to be reduced by $600 once the overtime curbs went into effect.\n  Trucking companies, too, are being squeezed, by rising fuel prices and vehicle maintenance costs, said Hiroyuki \nUtsunomiya, 74, the president of a trucking company in Miyagi Prefecture. ''When the regulation is tightened in \n2024, it will be tougher to do business,'' he said. In Aomori, the governor has asked the government to relax the \nrules for truck drivers in his prefecture.\n  Still, Japan's transport ministry appears firm on the new overtime limits, which have already been delayed by five \nyears.\n  ''We definitely won't extend the moratorium,'' said Yudai Furukawa, the ministry's deputy director of logistics policy. \n''There is nothing more precious than people's lives.''\nhttps://www.nytimes.com/2023/12/23/business/japan-truck-drivers-overtime-shortage.html\nGraphic\n \nPHOTOS: Top left, Se-hui Han and Rodrigo Hormazabal, developers at LG A.I. Research, demonstrating LG's \ngenerative A.I. model in Seoul. Top right, Nako Sung, the executive who leads Naver's generative A.I. project, in \nSeongnam, South Korea. He said the timing of ChatGPT's release surprised him. Above, CCTV cameras in the \nGangnam district in Seoul are equipped with artificial intelligence technology to monitor crowd density and detect \nearly signs of problems. (PHOTOGRAPHS BY TINA HSU FOR THE NEW YORK TIMES\n SOO-HYEON KIM/REUTERS) (B3) This article appeared in print on page B1, B3.               \nLoad-Date: December 26, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees",
        "media": "The New York Times",
        "time": "June 8, 2023",
        "section": "TECHNOLOGY",
        "length": "1091 words",
        "byline": "Mike Isaac",
        "story_text": "After a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees\nThe New York Times \nJune 8, 2023 Thursday 22:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1091 words\nByline: Mike Isaac\nHighlight: In an internal all-hands meeting, the chief executive explained his plans for artificial intelligence, the \nmetaverse and rebooting Meta’s culture.\nBody\nIn an internal all-hands meeting, the chief executive explained his plans for artificial intelligence, the metaverse and \nrebooting Meta’s culture.\nMark Zuckerberg has spent the last nine months against the ropes as his company has made big cuts to its work \nforce and struggled to gain mainstream traction with its ambitious plans for virtual reality.\nOn Thursday, he told Meta employees how he planned to get the company back on track. In an all-hands meeting, \nMr. Zuckerberg offered an explanation for recent layoffs and for the first time laid out a vision for how Meta’s work in \nartificial intelligence would blend with its plans for the virtual reality it calls the metaverse.\nMr. Zuckerberg’s talk was an attempt to rally staff after the most tumultuous period in his company’s 19-year \nhistory. The chief executive said he made “tough decisions” about layoffs with the goal of “building a better \ntechnology company” that shipped better products, faster — something he believed Meta wasn’t doing well as it \nswelled to more than 80,000 employees at the peak of the pandemic.\n“I want us to use this period that’s going to be a bit more stable in order to evolve and rebuild our culture,” he said, \naccording to two people who attended the meeting and shared remarks and a recording with The New York Times.\nMr. Zuckerberg delivered the remarks in a roughly half-hour address to thousands of employees at Meta’s Menlo \nPark, Calif., campus. The talk, made on an outdoor pavilion the company calls Hacker Square, was also \nlivestreamed to tens of thousands of employees around the world.\nIt was one of Meta’s few major all-hands meetings over the last three years to be conducted in person, and included \npresentations from other Meta executives, like Andrew Bosworth, the chief technology officer, and Chris Cox, the \nchief product officer.\nDuring the presentation, Mr. Cox detailed Meta’s plans for making improvements to Reels, Instagram’s short-form \nvideo product, to better take on TikTok, one of Meta’s most formidable competitors.\nExecutives also spoke about Project 92, a long-rumored social app in development at Meta that will function similar \nto Twitter. The app, executives said, will work with other apps like Mastodon and Bluesky.\nWhile Meta has aggressively worked on A.I. for several years, it has been slower than competitors like Google and \nMicrosoft to turn that research into consumer products. Mr. Zuckerberg on Thursday detailed plans for artificially \nintelligent assistants that aid people across all Meta’s apps, including WhatsApp, Messenger and Instagram.\nAfter a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees\nHe said Meta would work on creating artificial intelligence models that were accessible to more people than those of \nhis company’s competitors and, ultimately, would fit into his plans for the metaverse.\n“Democratizing access to this has a bunch of value,” Mr. Zuckerberg said, according to the two people who shared \nremarks with The Times. “But it’s also aligned with the product vision of enabling a lot of different A.I.’s instead of \njust trying to consolidate this ourselves into one singular A.I. that’s going to try to rule everything.”\nHe envisioned A.I. assistants that help people “create content to express yourself and your ideas so much better,” \nor perhaps some artificially intelligent version of “a coach that gives you advice, encourages you.”\nA.I. agents could serve customers in products like WhatsApp, the globally popular messaging app that Meta has \nbeen focused on turning into an important tool for business owners and customer service. And every business \ncould use a personalized A.I. algorithm.\n“Different people have different interests, and we’ll need a diverse array of A.I.s to represent all of these different \ninterests,” Mr. Zuckerberg said in the meeting.\nTo do that, the company is betting heavily on open source technology, which means it will share its work on artificial \nintelligence with researchers who want to build their own algorithms with what Meta has already done. The \ncompany has spent billions over the past decade building systems to run A.I. and attracting top researchers to work \non some of the world’s most difficult computer science questions around A.I.\nMeta has been criticized for its approach. Researchers and politicians outside the company say opening A.I. \nalgorithms to many others could spawn malicious, automated and intelligent systems that accelerate the spread of \nmisinformation. Those sophisticated algorithms, critics say, need to be tightly controlled.\nIn his address, Mr. Zuckerberg defended Meta’s strategy. He said open-source software enables greater outside \nscrutiny of the technology because it can be seen by millions of technologists. He said working closely with \noutsiders’ advances would make Meta’s platforms better.\nMr. Zuckerberg also said he hoped for a world where people could build as many different A.I. programs as they \nwanted, rather than relying on a few provided by two or three large technology companies.\nThat does not mean Meta is backing away from its namesake metaverse plans, Mr. Zuckerberg said. Programs \nusing new generative A.I. technology, he said, could eventually help people build new virtual world items and \nexperiences. And he hinted that the company may bring its A.I. assistant into a future version of its smart glasses. \n(Meta released a pair of smart Ray-Ban glasses in 2021, though sales have been sluggish.)\nHe also took a swipe at Apple’s recently announced Vision Pro headset, $3,500 high-tech goggles that promised to \nusher in a new era of “spatial computing.”\n“I was really curious to see what they’d ship, and it’s a good sign for our own development that they don’t have any \nmagical solutions to the laws of physics that we haven’t already explored,” he said in his remarks. Mr. Zuckerberg \ncriticized the high-end materials and cost of the device, while noting that Meta had spent years bringing down the \nprice of its headsets to an upcoming version that will start at $500.\n“Their announcement really shows how our vision and values are different and what’s at stake in shaping this \nplatform,” Mr. Zuckerberg said. “Our vision of the metaverse and presence is fundamentally social and about people \ninteracting and feeling closer in new amazing ways. By contrast, every demo Apple showed was someone sitting on \na couch by themselves.”\nPHOTO: Mark Zuckerberg’s address on Thursday appeared to be an attempt to rally Meta’s employees after a \ntumultuous period of widespread layoffs. (PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) (B5) \nThis article appeared in print on page B1, B5.\nAfter a Rocky Year, Zuckerberg Lays Out Meta’s Road Map to Employees\nLoad-Date: June 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "How A.I. Tools Could Change India's Elections",
        "media": "The New York Times",
        "time": "April 18, 2024",
        "section": "Section ; Column 0; Foreign Desk",
        "length": "1266 words",
        "byline": "By Suhasini Raj",
        "story_text": "How A.I. Tools Could Change India's Elections\nThe New York Times\nApril 18, 2024 Thursday\nThe New York Times on the Web\nCopyright 2024 The New York Times Company\nSection: Section ; Column 0; Foreign Desk\nLength: 1266 words\nByline: By Suhasini Raj\nBody\nAvatars are addressing voters by name, in whichever of India's many languages they speak. Experts see potential \nfor misuse in a country already rife with disinformation.\nFor a glimpse of where artificial intelligence is headed in election campaigns, look to India, the world's largest \ndemocracy, as it starts heading to the polls on Friday. \n  An A.I.-generated version of Prime Minister Narendra Modi that has been shared on WhatsApp shows the \npossibilities for hyperpersonalized outreach in a country with nearly a billion voters. In the video -- a demo clip \nwhose source is unclear -- Mr. Modi's avatar addresses a series of voters directly, by name.\n  However, it is not perfect. Mr. Modi appears to wear two different pairs of glasses, and some parts of the video are \npixelated.\n  Down the ladder, workers in Mr. Modi's party are sending videos by WhatsApp in which their own A.I. avatars \ndeliver personal messages to specific voters about the government benefits they have received and ask for their \nvote.\n  Those video messages can be automatically generated in whichever of India's dozens of languages the voter \nspeaks. So can phone messages by A.I.-powered chatbots that call constituents in the voices of political leaders \nand seek their support.\n  Such outreach requires a fraction of the time and money spent on traditional campaigning, and it has the potential \nto become an essential instrument in elections. But as the technology races onto the political scene, there are few \nguardrails to prevent misuse.\n  Chatbots and personalized videos may seem more or less harmless. Experts worry, however, that voters will have \nan increasingly difficult time distinguishing between real and synthetic messages as the technology advances and \nspreads.\n  ''It'll be the Wild West and an unregulated A.I. space this year,'' said Prateek Waghre, the executive director of the \nInternet Freedom Foundation, a digital rights group based in New Delhi. The technology, he added, is entering a \nmedia landscape already polluted with misinformation.\n  Around the world, elections have become a testing ground for the A.I. boom. The tools have been used to turn an \nArgentine presidential candidate into Indiana Jones and a Ghostbuster. During the New Hampshire primary, voters \nreceived robocall messages urging them not to vote, in a voice that was most likely artificially generated to sound \nlike President Biden's.\nHow A.I. Tools Could Change India 's Elections\n  And in India, Mr. Modi's Bharatiya Janata Party, or B.J.P., and the opposition Indian National Congress party have \naccused each other of spreading election-related deepfake content online.\n  One outpost on this new Indian frontier is in the western desert state of Rajasthan. On the ground floor of a \nresidential building on a dusty back lane, a 31-year-old college dropout, Divyendra Singh Jadoun, operates an A.I. \nstart-up, The Indian Deepfaker.\n  His team of nine people has been making commercials with A.I.-generated avatars of Bollywood actors and \nactresses. But earlier this year, political parties and politicians began asking him to do for them what he had done \nfor celebrities. Of the 200 requests, Mr. Jadoun said, he took on 14.\n  Among those getting the A.I. treatment is Shakti Singh Rathore, a 33-year-old B.J.P. member. His job this election \nseason is to tell as many people as possible about Mr. Modi's programs and policies. So he decided to create a \nreplica of himself.\n  ''A.I. is wonderful and the way forward,'' Mr. Rathore said as he settled in front of a video camera at the office of \nThe Indian Deepfaker, preparing to become digitally incarnated. ''How else could I reach the beneficiaries of Mr. \nModi's programs in such large numbers and in so short a period of time?''\n  As Mr. Rathore adjusted a saffron scarf with the party's logo that hung around his neck, Mr. Jadoun instructed him, \n''Just look into the camera and talk as if the person is sitting right in front of you.''\n  With about five minutes' worth of material, including an audio recording and profile shots, Mr. Jadoun went to \nwork. He said he uses open-source A.I. systems and builds upon them with his own code.\n  First, Mr. Rathore's face was isolated from each frame of the recording.\n  Then data was collected from his facial features, including the size of his face and lips, as well as his gaze.\n  Mr. Jadoun said the data set was then fed into A.I. models that learn to predict facial patterns.\n  ''You need to keep running it through the program and fine-tuning the face until you get the best face possible,'' he \nsaid.\n  A ''cloning algorithm'' also analyzed the audio recording, learning the voice's cadence and intonations. Mr. Jadoun \nsaid it often takes six to eight hours of tweaking to perfect the face and for the lips to sync with the words. The rest \nis largely automated.\n  In one demo, it took about four minutes to create around 20 personalized greeting videos.\n  Mr. Jadoun said his team could produce up to 10,000 videos a day. For larger jobs on deadline, it will rent \ngraphics processing units.\n  Generative A.I. can also remove language barriers, which is especially helpful in a linguistically diverse country. \nMr. Rathore's avatar can be programmed to speak regional languages to reach the remotest corners of India.\n  Political parties are not only texting constituents video messages but also using cloned voices to call people \ndirectly, all powered by chatbots like ChatGPT.\n  In the past, when a party representative would call voters, they would hang up, Mr. Rathore said. ''But now, when \na local leader utters a voter's name, it immediately catches their attention.''\n  During the conversation, the chatbot asks about local government programs that offer free electricity or funding for \nstart-ups. Mr. Jadoun said the calls were recorded and transcribed for quality control and A.I. training.\nHow A.I. Tools Could Change India 's Elections\n  Mr. Rathore said he had spent around $24,000 of his own money to reach about 1.2 million people through his \nvideo messages and phone calls and to receive information about who didn't answer. He called it an investment in \nhis future with the B.J.P.\n  Nikhil Pahwa, the editor of MediaNama, which covers digital media in India, said the personalized messages could \nbe particularly powerful among Indians.\n  ''India is a country where people love to take photos with celebrity impersonators,'' he said. ''So if they receive a \ncall from, say, the prime minister, and he speaks as if he knows them, where they live and what their issues are, \nthey would actually be thrilled about it.''\n  Mr. Waghre of the Internet Freedom Foundation questions whether A.I. content is persuasive enough to affect this \nyear's election. But he said the long-term effects could be problematic. ''Once you normalize this in people's \ninformation diet, what happens six months later when there are deceptive videos?'' he said.\n  Mr. Modi himself has discussed adding disclaimers to A.I.-generated content so people are not being ''misguided.'' \nMr. Jadoun and representatives of two other A.I. start-ups in India created what they call an ''A.I. coalition \nmanifesto,'' pledging to protect data privacy and uphold election integrity. For instance, Indian Deepfaker videos are \nlabeled ''A.I. generated,'' and its chatbots announce that they are A.I.-generated voices, Mr. Jadoun said.\n  Narendra Singh Bhati, 28, the owner of resorts in Rajasthan, received an A.I.-generated call from Mr. Rathore this \nweek. Mr. Bhati said he was impressed with its personalization.\n  He said he had not realized that the call was A.I.-generated, although the script made that clear. ''I even said \ngoodbye to Mr. Rathore'' at the end, Mr. Bhati said.\nhttps://www.nytimes.com/2024/04/18/world/asia/india-election-ai.html\nLoad-Date: April 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Deepfake Videos Could Change India's Elections",
        "media": "The New York Times",
        "time": "April 19, 2024",
        "section": "Section A; Column 0; Foreign Desk; Pg. 10",
        "length": "1266 words",
        "byline": "By Suhasini Raj",
        "story_text": "Deepfake Videos Could Change India's Elections\nThe New York Times\nApril 19, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; Foreign Desk; Pg. 10\nLength: 1266 words\nByline: By Suhasini Raj\nBody\nAvatars are addressing voters by name, in whichever of India's many languages they speak. Experts see potential \nfor misuse in a country already rife with disinformation.\nFor a glimpse of where artificial intelligence is headed in election campaigns, look to India, the world's largest \ndemocracy, as it starts heading to the polls on Friday. \n  An A.I.-generated version of Prime Minister Narendra Modi that has been shared on WhatsApp shows the \npossibilities for hyperpersonalized outreach in a country with nearly a billion voters. In the video -- a demo clip \nwhose source is unclear -- Mr. Modi's avatar addresses a series of voters directly, by name.\n  However, it is not perfect. Mr. Modi appears to wear two different pairs of glasses, and some parts of the video are \npixelated.\n  Down the ladder, workers in Mr. Modi's party are sending videos by WhatsApp in which their own A.I. avatars \ndeliver personal messages to specific voters about the government benefits they have received and ask for their \nvote.\n  Those video messages can be automatically generated in whichever of India's dozens of languages the voter \nspeaks. So can phone messages by A.I.-powered chatbots that call constituents in the voices of political leaders \nand seek their support.\n  Such outreach requires a fraction of the time and money spent on traditional campaigning, and it has the potential \nto become an essential instrument in elections. But as the technology races onto the political scene, there are few \nguardrails to prevent misuse.\n  Chatbots and personalized videos may seem more or less harmless. Experts worry, however, that voters will have \nan increasingly difficult time distinguishing between real and synthetic messages as the technology advances and \nspreads.\n  ''It'll be the Wild West and an unregulated A.I. space this year,'' said Prateek Waghre, the executive director of the \nInternet Freedom Foundation, a digital rights group based in New Delhi. The technology, he added, is entering a \nmedia landscape already polluted with misinformation.\n  Around the world, elections have become a testing ground for the A.I. boom. The tools have been used to turn an \nArgentine presidential candidate into Indiana Jones and a Ghostbuster. During the New Hampshire primary, voters \nreceived robocall messages urging them not to vote, in a voice that was most likely artificially generated to sound \nlike President Biden's.\nDeepfake Videos Could Change India 's Elections\n  And in India, Mr. Modi's Bharatiya Janata Party, or B.J.P., and the opposition Indian National Congress party have \naccused each other of spreading election-related deepfake content online.\n  One outpost on this new Indian frontier is in the western desert state of Rajasthan. On the ground floor of a \nresidential building on a dusty back lane, a 31-year-old college dropout, Divyendra Singh Jadoun, operates an A.I. \nstart-up, The Indian Deepfaker.\n  His team of nine people has been making commercials with A.I.-generated avatars of Bollywood actors and \nactresses. But earlier this year, political parties and politicians began asking him to do for them what he had done \nfor celebrities. Of the 200 requests, Mr. Jadoun said, he took on 14.\n  Among those getting the A.I. treatment is Shakti Singh Rathore, a 33-year-old B.J.P. member. His job this election \nseason is to tell as many people as possible about Mr. Modi's programs and policies. So he decided to create a \nreplica of himself.\n  ''A.I. is wonderful and the way forward,'' Mr. Rathore said as he settled in front of a video camera at the office of \nThe Indian Deepfaker, preparing to become digitally incarnated. ''How else could I reach the beneficiaries of Mr. \nModi's programs in such large numbers and in so short a period of time?''\n  As Mr. Rathore adjusted a saffron scarf with the party's logo that hung around his neck, Mr. Jadoun instructed him, \n''Just look into the camera and talk as if the person is sitting right in front of you.''\n  With about five minutes' worth of material, including an audio recording and profile shots, Mr. Jadoun went to \nwork. He said he uses open-source A.I. systems and builds upon them with his own code.\n  First, Mr. Rathore's face was isolated from each frame of the recording.\n  Then data was collected from his facial features, including the size of his face and lips, as well as his gaze.\n  Mr. Jadoun said the data set was then fed into A.I. models that learn to predict facial patterns.\n  ''You need to keep running it through the program and fine-tuning the face until you get the best face possible,'' he \nsaid.\n  A ''cloning algorithm'' also analyzed the audio recording, learning the voice's cadence and intonations. Mr. Jadoun \nsaid it often takes six to eight hours of tweaking to perfect the face and for the lips to sync with the words. The rest \nis largely automated.\n  In one demo, it took about four minutes to create around 20 personalized greeting videos.\n  Mr. Jadoun said his team could produce up to 10,000 videos a day. For larger jobs on deadline, it will rent \ngraphics processing units.\n  Generative A.I. can also remove language barriers, which is especially helpful in a linguistically diverse country. \nMr. Rathore's avatar can be programmed to speak regional languages to reach the remotest corners of India.\n  Political parties are not only texting constituents video messages but also using cloned voices to call people \ndirectly, all powered by chatbots like ChatGPT.\n  In the past, when a party representative would call voters, they would hang up, Mr. Rathore said. ''But now, when \na local leader utters a voter's name, it immediately catches their attention.''\n  During the conversation, the chatbot asks about local government programs that offer free electricity or funding for \nstart-ups. Mr. Jadoun said the calls were recorded and transcribed for quality control and A.I. training.\nDeepfake Videos Could Change India 's Elections\n  Mr. Rathore said he had spent around $24,000 of his own money to reach about 1.2 million people through his \nvideo messages and phone calls and to receive information about who didn't answer. He called it an investment in \nhis future with the B.J.P.\n  Nikhil Pahwa, the editor of MediaNama, which covers digital media in India, said the personalized messages could \nbe particularly powerful among Indians.\n  ''India is a country where people love to take photos with celebrity impersonators,'' he said. ''So if they receive a \ncall from, say, the prime minister, and he speaks as if he knows them, where they live and what their issues are, \nthey would actually be thrilled about it.''\n  Mr. Waghre of the Internet Freedom Foundation questions whether A.I. content is persuasive enough to affect this \nyear's election. But he said the long-term effects could be problematic. ''Once you normalize this in people's \ninformation diet, what happens six months later when there are deceptive videos?'' he said.\n  Mr. Modi himself has discussed adding disclaimers to A.I.-generated content so people are not being ''misguided.'' \nMr. Jadoun and representatives of two other A.I. start-ups in India created what they call an ''A.I. coalition \nmanifesto,'' pledging to protect data privacy and uphold election integrity. For instance, Indian Deepfaker videos are \nlabeled ''A.I. generated,'' and its chatbots announce that they are A.I.-generated voices, Mr. Jadoun said.\n  Narendra Singh Bhati, 28, the owner of resorts in Rajasthan, received an A.I.-generated call from Mr. Rathore this \nweek. Mr. Bhati said he was impressed with its personalization.\n  He said he had not realized that the call was A.I.-generated, although the script made that clear. ''I even said \ngoodbye to Mr. Rathore'' at the end, Mr. Bhati said.\nhttps://www.nytimes.com/2024/04/18/world/asia/india-election-ai.html\nGraphic\n \nPHOTOS: How A.I. Video Messages Are Made: Next, Mr. Rathore's face is isolated from each frame of the \nrecording and turned into data. Data is collected from his facial features and fed into A.I. models that learn to predict \nfacial patterns. The technology creates personalized greeting videos in a short amount of time.\nDivyendra Singh Jadoun, who operates the Indian Deepfaker, an A.I. start-up, has turned down most requests for \npolitical avatars.\n In this example, Mr. Modi greets people in this A.I.-generated demo video. However, a closer inspection reveals it \nis not perfect. He appears to wear two different eyeglasses, and some parts of the video are pixelated, like the lotus \npin in the right frame. (PHOTOGRAPHS BY AHMER KHAN FOR THE NEW YORK TIMES) This article appeared in \nprint on page A10.               \nLoad-Date: April 19, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "'India's a Priority Mkt for Google, Excited by Tech Innovation Here'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 22, 2023",
        "section": "STARTUPS & TECH",
        "length": "766 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "'India's a Priority Mkt for Google, Excited by Tech Innovation Here'\nEconomic Times (E-Paper Edition)\nJune 22, 2023 Thursday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 766 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: Google’s senior VP says AI rules should be ‘based on science and a deep understanding of subject’\nBody\nNew Delhi: Terming the demands for a “pause” in AI development as “uncalled for, as of now”, senior vice president \nof Google Prabhakar Raghavan said rules to govern AI should be “based on science and a deep understanding of \nthe subject”. He was voicing his opposition to calls for a blanket ban on the technology, which is taking the world by \nstorm. The way ahead to develop artificial intelligence (AI) systems is to “engage with scientists and technologists \nwho understand” the technology behind it, the top Google executive said. .  In an exclusive interview with ET, \nRaghavan — who is a key member of Alphabet CEO Sundar Pichai's leadership team — said AI regulations must \nbalance innovation and its potential to uplift economies like India. The country remains one of the two priority \nmarkets for Google and is adding a lot of innovative products to the company's repertoire, he added. \n Noting that “India is growing really fast, right on a fairly significant pace,” he said the next big startup from India \ncould be the one which caters to the unique needs of Indian users. For instance, startups that solve the problems of \nlogistics for companies delivering to remote corners could gain the most. Google, which has developed a lot of \nIndia-first products such as Google Pay, offline maps, flood forecast warning, and map directions for two-wheelers, \namong others, is now  finding ample users for these in other geographies as well. Now, with generative AI coming \ninto the picture, there will be newer opportunities for Google's products, especially in geographies like India, \nBangladesh and others, according to the IIT graduate who is now responsible for Google Search, Assistant, Geo, \nAds, Commerce, and Payments products at the Mountain View-based search giant.  “We have fascinating new \nopportunities in building better Indic language models because the data sparsity is different. We are trying to \ndevelop better resources to train across languages,” said the 62-yearold Raghavan.  Google's focus was not just \npure languages such as Hindi, Bengali or Tamil, but dialects such as Hinglish, which were a mix of two pure spoken \nand written languages, according to the 62-year-old computer science engineer who has a PhD from the University \nof California,  Berkeley. Training mixed language models, as well as pure language models, was also important for \nGoogle as search queries from India had shifted from the traditional text and image to a combination of voice and \nimage or just voice.  “In India, about a third of our search queries are spoken. That is in contrast to like three or 4% \nin the US. So, it's a 10x increase. That is because people here are culturally really comfortable pulling out the \nphone and talking to it. In many other countries, people are not comfortable,” Raghavan said, adding that in future, \nsearch queries would arise from multiple modalities such as text, voice and image.  “You point the camera and then \nask a text query such as if there is something wrong with this plant, how do I fix it? And we tell you to go buy this \npesticide, sprinkle on top etc. These are emerging behaviours that drag the core products in different directions,” he \nnoted. Though Goo-  gle has found and implemented ample use cases for its generative AI and derived models, \nRaghavan believes that a pause in the development of the technology is uncalled for as of now. He was responding \nto aquery on the call — by technology entrepreneur Elon Musk — to hit a pause on AI, the Google executive said \n“there are many prominent scientists who truly understand what these things do and don't do. My suggestion would \nbe to engage them and try to get from them exactly what they are thinking of. Ultimately, it is a hard science \n' India 's a Priority Mkt for Google , Excited by Tech Innovation Here'\nunderneath, and it is a branch of computer science.”  Raghavan, who is currently on a visit to India, is of the view \nthat smaller companies in the generative AI ecosystem will make as much of a difference as the larger firms such \nas Google, Microsoft or OpenAI and that it was not “hopeless” for the smaller players to compete with the bigger \nones in the market.  The smaller companies, he said, would make use of the multiple language learning models and \ntweak them to fit a vast variety of applications. The threshold for such companies was not whether they had trained \na language model by now as that is something many people have done. “It is what novel and interesting user \nbenefit can you derive from it? People are getting creative in many startups everywhere. It is round one of a ten-\nround match,” he said. FOR FULL INTERVIEW, GO TO www.economictimes.com\nLoad-Date: June 22, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "SECURITY CHIEFS: REWARDS, RISKS OF GENERATIVE AI ARE INFLATED",
        "media": "Wall Street Journal Abstracts",
        "time": "May 27, 2023",
        "section": "B; Pg. 4",
        "length": "37 words",
        "byline": "JAMES RUNDLE",
        "story_text": "SECURITY CHIEFS: REWARDS, RISKS OF GENERATIVE AI ARE INFLATED\nWall Street Journal Abstracts\nMay 26, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 37 words\nByline: JAMES RUNDLE\nBody\nABSTRACT\nSecurity chiefs say benefits of artificial intelligence technology are clear, but promises and risks of early generative \nAI are overblown and they are unconvinced that in its current form it does anything new; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: May 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "The Chatbots Are Here, and the Internet Industry Is in a Tizzy",
        "media": "The New York Times",
        "time": "March 8, 2023",
        "section": "TECHNOLOGY",
        "length": "1471 words",
        "byline": "Tripp Mickle, Cade Metz and Nico Grant",
        "story_text": "The Chatbots Are Here, and the Internet Industry Is in a Tizzy\nThe New York Times \nMarch 8, 2023 Wednesday 22:58 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1471 words\nByline: Tripp Mickle, Cade Metz and Nico Grant\nHighlight: The new technology could upend many online businesses. But for companies that figure out how to work \nwith it, A.I. could be a boon.\nBody\nThe new technology could upend many online businesses. But for companies that figure out how to work with it, A.I. \ncould be a boon.\nSAN FRANCISCO — When Aaron Levie, the chief executive of Box, tried a new A.I. chatbot called ChatGPT in \nearly December, it didn’t take him long to declare, “We need people on this!”\nHe cleared his calendar and asked employees to figure out how the technology, which instantly provides \ncomprehensive answers to complex questions, could benefit Box, a cloud computing company that sells services \nthat help businesses manage their online data.\nMr. Levie’s reaction to ChatGPT was typical of the anxiety — and excitement — over Silicon Valley’s new new \nthing. Chatbots have ignited a scramble to determine whether their technology could upend the economics of the \ninternet, turn today’s powerhouses into has-beens or create the industry’s next giants.\nNot since the iPhone has the belief that a new technology could change the industry run so deep. Cloud computing \ncompanies are rushing to deliver chatbot tools, even as they worry that the technology will gut other parts of their \nbusinesses. E-commerce outfits are dreaming of new ways to sell things. Social media platforms are being flooded \nwith posts written by bots. And publishing companies are fretting that even more dollars will be squeezed out of \ndigital advertising.\nThe volatility of chatbots has made it impossible to predict their impact. In one second, the systems impress by \nfielding a complex request for a five-day itinerary, making Google’s search engine look archaic. A moment later, \nthey disturb by taking conversations in dark directions and launching verbal assaults.\nThe result is an industry gripped with the question: What do we do now?\n“Everybody is agitated,” said Erik Brynjolfsson, an economist at Stanford’s Institute for Human-Centered Artificial \nIntelligence. “There’s a lot of value to be won or lost.”\nRarely have so many tech sectors been simultaneously exposed. The A.I. systems could disrupt $100 billion in \ncloud spending,$500 billion in digital advertising and $5.4 trillion in e-commerce sales, according to totals from IDC, \na market research firm, and GroupM, a media agency.\nGoogle, perhaps more than any other company, has reason to both love and hate the chatbots. It has declared a \n“code red” because their abilities could be a blow to its $162 billion business showing ads on searches.\nThe Chatbots Are Here, and the Internet Industry Is in a Tizzy\nBut Google’s cloud computing business could be a big winner. Smaller companies like Box need help building \nchatbot tools, so they are turning to the giants that process, store and manage information across the web. Those \ncompanies — Google, Microsoft and Amazon — are in a race to provide businesses with the software and \nsubstantial computing power behind their A.I. chatbots.\n“The cloud computing providers have gone all in on A.I. over the last few months,” said Clément Delangue, head of \nthe A.I. company Hugging Face, which helps run open-source projects similar to ChatGPT. “They are realizing that \nin a few years, most of the spending will be on A.I., so it is important for them to make big bets.”\nWhen Microsoft introduced a chatbot-equipped Bing search engine last month, Yusuf Mehdi, the head of Bing, said \nthe company was wrestling with how the new version would make money. Advertising will be a major driver, he \nsaid, but the company expects fewer ads than traditional search allows.\n“We’re going to learn that as we go,” Mr. Mehdi said.\nAs Microsoft figures out a chatbot business model, it is forging ahead with plans to sell the technology to others. It \ncharges $10 a month for a cloud service, built in conjunction with the OpenAI lab, that provides developers with \ncoding suggestions, among other things.\nGoogle has similar ambitions for its A.I. technology. After introducing its Bard chatbot last month, the company said \nits cloud customers would be able to tap into that underlying system for their own businesses.\nBut Google has not yet begun exploring how to make money from Bard itself, said Dan Taylor, a company vice \npresident of global ads. It considers the technology “experimental,” he said, and is focused on using the so-called \nlarge language models that power chatbots to improve traditional search.\n“The discourse on A.I. is rather narrow and focused on text and the chat experience,” Mr. Taylor said. “Our vision \nfor search is about understanding information and all its forms: language, images, video, navigating the real world.”\nSridhar Ramaswamy, who led Google’s advertising division from 2013 to 2018, said Microsoft and Google \nrecognized that their current search business might not survive. “The wall of ads and sea of blue links is a thing of \nthe past,” said Mr. Ramaswamy, who now runs Neeva, a subscription-based search engine.\nAmazon, which has a larger share of the cloud market than Microsoft and Google combined, has not been as public \nin its chatbot pursuit as the other two, though it has been working on A.I. technology for years.\nBut in January, Andy Jassy, Amazon’s chief executive, corresponded with Mr. Delangue of Hugging Face, and \nweeks later Amazon expanded a partnership to make it easier to offer Hugging Face’s software to customers.\nAs that underlying tech, known as generative A.I., becomes more widely available, it could fuel new ideas in e-\ncommerce. Late last year, Manish Chandra, the chief executive of Poshmark, a popular online secondhand store, \nfound himself daydreaming during a long flight from India about chatbots building profiles of people’s tastes, then \nrecommending and buying clothes or electronics. He imagined grocers instantly fulfilling orders for a recipe.\n“It becomes your mini-Amazon,” said Mr. Chandra, who has made integrating generative A.I. into Poshmark one of \nthe company’s top priorities over the next three years. “That layer is going to be very powerful and disruptive and \nstart almost a new layer of retail.”\nBut generative A.I is causing other headaches. In early December, users of Stack Overflow, a popular social \nnetwork for computer programmers, began posting substandard coding advice written by ChatGPT. Moderators \nquickly banned A.I.-generated text.\nPart of the problem was that people could post this questionable content far faster than they could write posts on \ntheir own, said Dennis Soemers, a moderator for the site. “Content generated by ChatGPT looks trustworthy and \nprofessional, but often isn’t,” he said.\nThe Chatbots Are Here, and the Internet Industry Is in a Tizzy\nWhen websites thrived during the pandemic as traffic from Google surged, Nilay Patel, editor in chief of The Verge, \na tech news site, warned publishers that the search giant would one day turn off the spigot. He had seen Facebook \nstop linking out to websites and foresaw Google following suit in a bid to boost its own business.\nHe predicted that visitors from Google would drop from a third of websites’ traffic to nothing. He called that day \n“Google zero.”\n“People thought I was crazy,” said Mr. Patel, who redesigned The Verge’s website to protect it. Because chatbots \nreplace website search links with footnotes to answers, he said, many publishers are now asking if his prophecy is \ncoming true.\nFor the past two months, strategists and engineers at the digital advertising company CafeMedia have met twice a \nweek to contemplate a future where A.I. chatbots replace search engines and squeeze web traffic.\nThe group recently discussed what websites should do if chatbots lift information but send fewer visitors. One \npossible solution would be to encourage CafeMedia’s network of 4,200 websites to insert code that limited A.I. \ncompanies from taking content, a practice currently allowed because it contributes to search rankings.\n“There are a million things to be worried about,” said Paul Bannister, CafeMedia’s chief strategy officer. “You have \nto figure out what to prioritize.”\nCourts are expected to be the ultimate arbiter of content ownership. Last month, Getty Images sued Stability AI, the \nstart-up behind the art generator tool Stable Diffusion, accusing it of unlawfully copying millions of images. The Wall \nStreet Journal has said using its articles to train an A.I. system requires a license.\nIn the meantime, A.I. companies continue collecting information across the web under the “fair use” doctrine, which \npermits limited use of material without permission.\n“The world is facing a new technology, and the law is groping to find ways of dealing with it,” said Bradley J. \nHulbert, a lawyer who specializes in this area. “No one knows where the courts will draw the lines.”\nKaren Weise contributed reporting from Seattle.\nKaren Weise contributed reporting from Seattle. \nPHOTOS: Manish Chandra has made integrating generative A.I. one of the top priorities for Poshmark.; “There are \na million things to be worried about,” said Paul Bannister of CafeMedia. (A21) This article appeared in print on page \nA1, A21.\nLoad-Date: March 8, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Unlocking Funding",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "756 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "Unlocking Funding\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 756 words\nByline: Annapurna Roy & Suraksha P\nHighlight: AI Mission will help startups make in India and for the world, say tech investors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of artificial intelligence-based applications and models is a “good starting point” \nas it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372-crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. This will provide Indian companies with their own computing hardware — a scarce resource globally — \nallowing them to create more AI applications and arming the country to compete better with the likes of the US, \nChina and the UK which are ahead in the race to dominate the sunrise sector. \n“The government’s AI mission is incredibly exciting for India and its vibrant startup ecosystem. In-  vesting in 10,000 \nGPUs and making them available to researchers and innovators will make a huge difference as we aim to build \n(India) the AI application capital of the world,” Rajan Anandan, managing director, Peak XV Partners, told ET \nadding that it will provide critical building blocks that AI startups can leverage to “build in India, for India and for the \nworld”.  In addition to IndiaAI Innovation Centre for the development and deployment of indigenous Large \nMultimodal Models and domain-specific foundational models in critical sectors, the mission will also provide access \nto targeted funding for AI startups. India now has over 100 generative AI startups, however, the investment into the \nspace has been comparatively small. The US saw nearly $250 billion private investments into AI startups between \n2013 and 2022, while investments in India stood at just $8 billion. Over the same period, China saw $95 billion of \ninvestments while for the UK, the number stood at $18 billion, as per data from the AI Index 2023 Annual Report. \nLast year, Indian conglomerates such as the Tata Group and Reliance Industries announced partnerships with top \nGPU maker Nvidia to obtain computing infrastructure to build their own AI applications. However,  startups facing \nresource constraints have been petitioning the government to invest into computing infrastructure to ensure they \nalso get access and do not lose out in the dynamic AI race. The Centre’s latest move will enable these AI startups \nto create foundational models from scratch for a variety of applications, for which they were earlier dependent on \nmodels from the likes of OpenAI and Meta.  Vishal Dhupar, managing director for South Asia at Nvidia, said that the \ngovernment’s latest outlay creates a “highway” for innovation to happen. “I’m so pleased that the digital \ntransformation has taken place in the country. Now you can embed AI into it,” he said while speaking at an event in \nthe national capital on Friday. Dhupar added that this enables solutions to be built for India and that solutions built \nhere at population scale are applicable globally. “I'm hoping India’s advantage is to migrate from general purpose \ncompute to accelerated compute, and you will have sufficient highway for this country to make a difference.” Nvidia \nstock has seen an unprecedented rally this year. Chip maker is close to edging out Apple, which is listed se-  cond \nin market cap table globally. It will provide Reliance Industries access to its most advanced Nvidia GH200 Grace \nUnlocking Funding\nHopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 provides massive \nmemory bandwidth. The GPUs will be made available in the next 18-24 months, said electronics and IT secretary S \nKrishnan on the sidelines of an event on Friday. He added that the government will invite bids from the industry \nunder the mission and provide viability gap funding for this compute infrastructure.   PLAYING CATCHUP  Globally, \ncountries like the UK, Saudi Arabia and the UAE have been shelling big money to acquire AI chips to boost their \ncountries' companies. For instance, the UK is building a national AI resource, as a part of which it would acquire \n5,000 Nvidia GPUs. Saudi Arabia, through the King Abdullah University of Science and Technology, reportedly \nbought 3,000 Nvidia GPUs worth $40,000 each.  This year, the UAE announced a $500 million investment to \nFalcon Foundation to develop open-source generative AI models and provide technology access to emerging \neconomies.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery",
        "media": "The New York Times",
        "time": "October 1, 2023",
        "section": "TECHNOLOGY",
        "length": "1086 words",
        "byline": "Yiwen Lu",
        "story_text": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe New York Times \nSeptember 27, 2023 Wednesday 00:08 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1086 words\nByline: Yiwen Lu\nHighlight: Instagram, Facebook, Snapchat and several newcomers are betting on artificial intelligence to \nrejuvenate the fun, interactivity and whimsy of creating and sharing images.\nBody\nInstagram, Facebook, Snapchat and several newcomers are betting on artificial intelligence to rejuvenate the fun, \ninteractivity and whimsy of creating and sharing images.\nMyuri Thiruna, a freelance photographer in Toronto, used to post frequently on Instagram and discuss photography \nwith other users. But she said she had stopped two years ago, feeling “drained” by the demands of social media \nand the pursuit of followers and trends.\nThen in July, Ms. Thiruna discovered Can of Soup, a new invitation-only social network where people make \nfantastical images of themselves with artificial intelligence and share the images with others. Enthralled by those \nabilities, she created A.I. images that showed her sitting on a unicorn floating in an ocean and her wearing a jacket \nmade of Froot Loops.\nMs. Thiruna, 33, also commented on other users’ posts, chatting with them and making images together. She now \nspends as much five hours a day interacting with others on the app, she said.\n“I met so many people on this app that I didn’t know before, and it goes beyond just posting and getting the likes,” \nshe said. “It’s this meaningful connection with people and being also inspired by what they’re doing.”\nSocial networking apps are beginning to integrate A.I. into their image capabilities to make their platforms more \nsocial. After Facebook, Instagram and other apps have become more corporate over the years, A.I. imagery \npresents a way for them to bring back the whimsy and fun so users can rediscover what was once the point of the \nplatforms: to share and interact with one another.\nLarge social platforms and new apps alike are incorporating A.I. image features. Last month, Snapchat announced \nDreams, an A.I. imaging feature that lets users in Britain, Australia and New Zealand create outlandish selfies. \nTikTok last year rolled out several in-app filters that use A.I. to transform selfies into the style of a comic or a \ndreamlike character. BeFake, a social app launched in August, is also experimenting with A.I. selfies and images.\nOn Wednesday, Facebook, Instagram, WhatsApp and Messenger jumped in as well. Meta, which owns the apps, \nsaid the services would now offer A.I. tools for instantly generating photorealistic “stickers,” which can be shared. It \nadded that it would introduce similar tools for editing and restyling existing images. These tools could put cowboy \nboots on two babies in a family photo, for instance.\n“You can generate imagery inside of your chats,” said Ahmad Al-Dahle, Meta’s vice president of generative A.I. \nWhile most image-generation tools need 10 to 20 seconds to create an image, he added, Meta’s new tool needs \nonly five.\nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe growing number of A.I. imagery tools in various apps underlines how “using A.I. interactively is where social \nmedia will go,” said Sam Saliba, who was Instagram’s global brand marketing lead and is now a marketing and \nbranding consultant in Silicon Valley.\nThe trend takes A.I. images further than the apps that allowed people to produce A.I.-generated images without \nconversing or easily sharing them in an online community. Those apps included Lensa AI — which let people create \nA.I. selfies in styles like “cosmic,” “fairy princess” and “anime” — as well as Remini, Snow and Wombo. Interest in \nthose apps peaked in mid-December, and downloads have since declined, according to the market intelligence firm \nApptopia.\nBen-Zion Benkhin, the founder of Wombo, said many people didn’t stick with A.I. apps that were merely a “creation \ntool” and that gave users no ability to chat with one another about what they had produced.\n“All of these apps are very limited,” he said. Adding social networking, he said, “does connect you to the other \npeople.”\nThat understanding has helped drive new apps like BeFake, which has melded A.I. image features with socializing \nand sharing. BeFake prompts users at a different time every day to take a picture with their smartphone’s front and \nback cameras and then has A.I. transform the image.\nUsers need to share their posts before viewing other people’s posts. The concept was borrowed from BeReal, a \nphoto-sharing app that has been popular among young users.\nBeFake connects people through their creativity, said Kristen Garcia Dumont, one of the app’s founders. “What that \nmeans to each person is unique and intriguing, and you get to explore that with whoever you want in the app,” she \nsaid.\nBeFake’s parent company has raised $3 million, and the app has tens of thousands of users, said Ms. Dumont and \nher co-founder, Tracy Lane.\nHayley Fligel, 17, a high school student in Burlingame, Calif., said she began using BeFake in July after a friend \ninvited her to join. It’s different from apps like Snapchat, TikTok and Instagram, which are stressful because “if you \nwant to take pictures or videos of yourself, you have to get ready, you have to get dressed, and you have to be \ndoing something or have a nice background around you,” she said.\nShe said she could use A.I. on BeFake to make herself look like Taylor Swift or appear that she was playing \nvolleyball, which shows “a more personal snippet of who you are.” While she seldom interacts with others on \nInstagram, she said, she comments on her friends’ posts on BeFake and browses a “Discovery” feed for inspiration \nfrom other posts.\nGabriel Birnbaum, who created Can of Soup with Eric Meier in May, said the point was to encourage creation and \nhave fun. “It’s an app where you spend time with your friends,” he said.\nSince then, he said, he has seen many creative and social moments happen in the app. In particular, a feature \ncalled Stir — which lets users put themselves in scenarios that someone else created — makes up one in four \nposts on the platform, Mr. Birnbaum said, with people inserting themselves into an A.I. image of Einstein inside a \nblack hole in space, for example.\nMr. Birnbaum, who declined to disclose Can of Soup’s funding and number of users, said he didn’t plan to roll out \nthe app widely until it had the “right trust and safety” with users comfortable with the content and whom they create \nphotos with.\n“I like the creation aspect and people liking my work and interacting with them,” said Alex Rosenblatt, 35, of San \nFrancisco, who has used Can of Soup since June. “Most of my interactions on it are with people I don’t know, \nactually.”\nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nCade Metz contributed reporting.\nCade Metz contributed reporting. \nPHOTO: Hayley Fligel, a high schooler, made this A.I. image on the BeFake app. (PHOTOGRAPH BY HAYLEY \nFLIGEL) This article appeared in print on page B6.\nLoad-Date: October 1, 2023"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "Factors that create a strong foundation for effective GCC leadership",
        "media": "The Economic Times",
        "time": "December 6, 2023",
        "section": "JOBS",
        "length": "763 words",
        "byline": "Debleena Majumdar",
        "story_text": "Factors that create a strong foundation for effective GCC leadership\nThe Economic Times\nDecember 6, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: JOBS\nLength: 763 words\nByline: Debleena Majumdar\nBody\nHirings by global capability centres or global business services (GCCs/GBSs) have come as positive news this year \namid stories of layoffs and slowdowns.The absolute hiring numbers are smaller than, say, IT services hiring; but the \ntrends reveal consistent growth plans of GCC. We had analysed the hiring patterns and the underlying reasons \nearlier. In this article, we assess the imperatives for GCC/GBSs leadership in 2024.Analyst firm HFS says in an \nanalysis on the GBS model in a blog, “Global talent is what created the GBS model. Centralisation, standardisation, \nlean/six sigma, offshoring, nearshoring, technology augmentation and, more recently, anywhere-shoring have been \nthe pillars to drive down costs and improve productivity. \nThe core business case for GBS revolves around 30%+ upfront arbitrage-driven cost savings and 5-10% YOY \nproductivity with a veneer of better stakeholder experience and improved business outcomes.”However, it estimates \na limit to such savings after which diminishing returns can kick in. What’s the solution then? A HFS study on GBS \nleaders states that generative AI can be a big game changer for GCC/GBS. It can bring in significant productivity \nimprovements. Not just that, it has scope for more creative work and also to build “an inflection point for GBS to \njump to a new S-curve of value creation.”What are the nuances of this shift on GCC leadership for 2024?Vikram \nAhuja, MD ANSR, CEO and Co-Founder Talent500, says GCCs in India operate as hubs for specialised talent, \ndriving innovation and fostering an environment of operational excellence. The leaders overseeing these centres \nplay a multifaceted role crucial for their success. Leadership requirements for 2024Ahuja says these leaders need \nto have certain skills to ensure success. The leaders at these centres should know how to manage talent and \nculture, be result oriented and be open to innovation. Talent management: For GCCs, attracting, retaining and \ndeveloping differentiated talent is a primary focus. GCCs are established in India to harness a unique pool of skilled \nprofessionals who offer specialised competencies, and this becomes one of the most critical skills. In this \ncompetitive job market, GCC site leaders play a pivotal role in not only recruiting the best talent but also in ensuring \nthat these exceptional individuals are retained and continually developed to maintain the GCC’s competitive \nedge.Cultural champion: The GCC site leader must skillfully manage cultural differences that can often exist \nbetween the headquarters and the GCC. Effective cross-cultural communication is not only necessary but a \nstrategic advantage for success. This proficiency in navigating the nuances of diverse cultural backgrounds ensures \nthat employees feel valued, understood, and respected in their workplace, regardless of their geographical location. \nThis skill goes beyond simple awareness; it’s about the adept management of diversity to create a unified and \nthriving work culture that propels the organisation’s success on a global scale.Results-driven: The GCC leader must \nexhibit a relentless commitment to achieving goals and objectives. This results-driven approach ensures that the \nGCC functions not just as an auxiliary unit but as a potent driver of global performance. The site leader’s ability to \nset clear benchmarks, establish efficient workflows, and translate innovation into measurable outcomes is \nparamount. It reinforces the GCC’s reputation as an invaluable partner in the organisation’s success story, leaving \nan indelible mark on its global operations. The results-driven mindset ensures that the GCC continues to serve as a \nnucleus for specialised talent, innovation and remarkable achievements.Innovation mindset: The GCC often serves \nas a hub for differentiated talent and expertise, making innovation a cornerstone of success. GCC leaders must \nFactors that create a strong foundation for effective GCC leadership\nexhibit a remarkable innovation mindset, constantly seeking new solutions, and identifying opportunities for \nimprovement. This proficiency in driving innovation ensures that the GCC stays at the forefront of cutting-edge \nadvancements and remains an invaluable resource for the organisation.By skillfully fostering an innovation culture, \nGCC leaders contribute significantly to their organisation’s reputation as a global hub for pioneering talent and \nsolutions Operational excellence: Ensuring smooth operations is critical to delivering high-quality services or \nproducts. This might involve process optimisation, automation and adherence to quality standards.  For Reprint \nRights: timescontent.com\nLoad-Date: December 6, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Sep2023",
        "header": "How AI may impact your job, money",
        "media": "The Baltimore Sun",
        "time": "September 10, 2023",
        "section": "MAIN; A; Pg. 11",
        "length": "499 words",
        "byline": "Sandra Block Kiplinger's Personal Finance",
        "story_text": "How AI may impact your job, money\nThe Baltimore Sun\nSeptember 10, 2023 Sunday\nAdvanceBulldog Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 11\nLength: 499 words\nByline: Sandra Block Kiplinger's Personal Finance\nHighlight: Kiosea39/Dreamstime\nBody\nA recent report by Goldman Sachs Economics Research concludes that \"super intelligent\" artificial intelligence \ntechnology - also called generative AI - could cause \"significant disruption\" in the job market.\nThe report estimated that roughly two-thirds of current jobs in the United States and Europe are vulnerable to some \ndegree of AI automation, and projected that generative AI could replace up to one-fourth of current work tasks, \nfrom writing memos to analyzing data. The report estimates that up to 300 million global jobs could be automated \nthrough generative AI.\nHowever, the report goes on to note that historically, this kind of labor disruption has been offset by the creation of \nnew jobs. If that happens, we could experience a productivity boom and significant economic growth, although the \ntiming of such a boom is difficult to predict. In the interim, though, a lot of workers will need to be retained, and \nsome jobs will become obsolete.\n\"A lot of basic jobs will be done by machines, which means that employees will have to do more advanced jobs,\" \nsays Subodha Kumar, a professor of statistics, operations and data science at Temple University.\nEven if you're not concerned about losing your job, you may be wondering how generative AI could affect the way \nyou manage your finances. Can ChatGPT tell you where to invest your savings, or figure out how much money you \nneed to retire comfortably?\nAutomation in the personal finance sector is nothing new. Millions of investors use robo advisers to recommend an \ninvestment portfolio of low-cost funds that fit their risk tolerance and investing timeline.\nGenerative AI programs take this process to the next level, offering the potential for advice that's specific to your \nsituation. For example, you can ask ChatGPT whether you should invest in a traditional or Roth IRA, or whether you \ncan afford to retire at 55.\nBut much of the personal finance advice is generic, computer science experts say. Worse, in some tests of \nChatGPT, the information provided was outdated, and when it comes to personal finance, having up-to-date \ninformation is critical.\nThe quality of advice you get from AI will depend largely on how you frame your question and the information you \nprovide about your situation. A vague question will likely result in a vague response. Likewise, if the information you \nprovide is unrealistic - you expect to earn 15% a year on your investments, for example - an AI program will likely \ntake your word for it. A reputable financial planner, on the other hand, will tell you to dial down your optimism.\nHow AI may impact your job, money\nIf all you're looking for is information about different bank accounts and interest rates, an AI program will provide \nwhat you need, Kumar says. But for more complex questions, such as where you should invest your retirement \nsavings, existing AI programs don't work very well. \"Financial planners shouldn't be worried about losing their jobs, \nbut they have to make sure they do a better job than an automated system,\" he says.\nLoad-Date: September 10, 2023"
    },
    {
        "file_name": "Adobe_CEO_Aug2023",
        "header": "Artificial intelligence will augment human ingenuity, not replace it, says",
        "media": "Adobe CEO",
        "time": "August 26, 2023",
        "section": "COMPANY",
        "length": "957 words",
        "byline": "Surabhi Agarwal and Bodhisatva Ganguli",
        "story_text": "Artificial intelligence will augment human ingenuity, not replace it, says \nAdobe CEO\nThe Economic Times\nAugust 27, 2023 Sunday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANY\nLength: 957 words\nByline: Surabhi Agarwal and Bodhisatva Ganguli\nBody\nArtificial intelligence (AI) is going to augment human ingenuity, not replace it, said Shantanu Narayen, chairman and \nchief executive of $17.61-billion Adobe Inc. The Hyderabad-born executive, who has been at the helm of the \nNasdaq-listed company for the last 15 years, cautioned that a rush to regulate AI and \"arbitrarily limiting \nadvancements may be harmful\". In a wide-ranging conversation with ET's Surabhi Agarwal & Bodhisatva Ganguli, \nhe also talked about the role that Adobe India is playing in building the next-gen AI-led products and the \nmonetisation opportunities for the company arising out of the AI boom. Narayen, 60, who is among the original crop \nof the ever-growing list of Indian-origin CEOs leading American multinationals (MNCs), also said that the future of \nIndia is \"very bright\" because of the right combination of demographics, talent and technology and what the \ngovernment has done with the digital public goods is incredible. Edited excerpts:You're here at the B20 event and \nIndia seems to be a bright spot in the world right now. \nWhat are your thoughts on the India of today, a country you grew up in?To comment on India this week without \ncommenting on the incredible achievement of the moon landing would be really amiss on my part. It was just \nincredible. I think with the demographics, access to education, access to technology, the future (of India) is very \nbright. 'Digital building blocks in place' With the macroeconomic and political issues with other neighbouring \ncountries, new opportunities are emerging for industries such as manufacturing and I've said this many times, if I \nwas growing up in India today, I don't know if I would leave the country.You really mean that? I really mean it. \nAround 40 years ago, if you were in tech, where would you go? You'd go abroad. Look at the percentage of people \nwho are going abroad nowadays from top educational institutions, it's a minuscule portion. And so the talent exists, \nthe access to capital certainly exists and the opportunity exists. And the Indian entrepreneurs don't look at it as an \nIndian opportunity but as a global one. So I'm a big big supporter (of India). The scale of India is truly amazing and \nthat's the opportunity for India. They've done a really good job of (building) the fundamental plumbing of \ninfrastructure - the fact that you have this digital identifier, you have universal payment scheme... When would I \nhave thought that you could go to Bundi (kiosk), get a pani puri or something and just pay for it through (UPI)... it's \nstaggering. Maybe because you're in this place, you don't look at it with the sort of amazement that we look at it (in \nthe US). If you can keep building on top of these, it (will be amazing). You talk to company after company here, you \nlook at the growth rates, look at how they're managing profitability and growth, look at their global aspirations, how \ncan one not be a fan?One of your founders, John Warnock, passed away. He was the inventor of the PDF among \nother revolutionary things. Could you tell us something about your relationship with him?The company was started \nby two amazing individuals, John (Warnock) and Chuck (Geschke). And both of them were researchers and they \nmet each other at Xerox PARC. It's been the privilege of a lifetime (to have worked with them). When you think \nabout technology innovators who've had a profound impact - John invented with Chuck - Postscript. Desktop \npublishing, as we know it today, would not have existed without their fundamental innovation. He invented Adobe \nIllustrator, his wife Marvo was a graphic artist. People take for granted today WYSIWYG (What You See Is What \nYou Get) applications but till then these hadn't been created. And he created the PDF. And so to work for 25 years \nArtificial intelligence will augment human ingenuity, not replace it, says Adobe CEO\nwith an individual who's had that kind of profound inventiveness and then to be asked by both of them to run the \ncompany... It's just been the ride of a lifetime, and we will miss him.What are some of the challenges that India \nneeds to overcome to cement its position further in the global economy as it moves on to a path of becoming a \ndeveloped country?Access to education is always the bare minimum. With the population demographics that you \nhave, are you ensuring people access to education? I think we've done an amazing job in the country on that but \nmore can be done. And a strong digital and physical infrastructure does help. From a government, private sector \n(point of view), it's the ease of doing business, right. And even that is dramatically improved relative to what it used \nto be. I think the basic building blocks are all in place. In good faith, I can't say I'm disappointed at something that's \nhappening because it feels like all the right things are happening. They may not happen all the time and the scale at \nwhich or the speed at which people here wanted, but from outside - and I think I get the benefit of sometimes just \nzooming out and seeing.How big is Adobe's India business from a global perspective?We don't break out our \nbusiness by country. If you look at the number of computing devices that are in India, and if you look at our \npercentage of revenue: is it commensurate with other countries, it's a little behind. But if you look at it in terms of the \ngrowth rate right now, and the growth rate both on the creative side, the documents side as well as on the \nmarketing side - which is enabling businesses to be digital business - the growth rates are great. And the \npossibilities are immense. If you take financial services and you look at these giant financial institutions like HDFC, \nICICI, SBI and how they're thinking about digital, that's the opportunity for us to sell our marketing solutions. For \nReprint Rights: timescontent.com\nLoad-Date: August 26, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "ETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes",
        "media": "The Economic Times",
        "time": "March 5, 2024",
        "section": "TECH & INTERNET",
        "length": "583 words",
        "byline": "Annapurna Roy",
        "story_text": "ETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes\nThe Economic Times\nMarch 5, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 583 words\nByline: Annapurna Roy\nBody\nBillionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI – a company he helped to found \n– and its chief executive Sam Altman. What’s behind the sparring? ET explains.What does Musk’s lawsuit say?The \nlawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from its original not-for-profit mission of \nbuilding open-source artificial intelligence (AI) for the good of humanity, working now to ‘maximise profits’ for its \nmajor investor Microsoft.Musk sought that the court direct OpenAI to make its research and technology publicly \navailable and prevent the use of its assets and cutting-edge generative AI models for the financial gains of \nsoftware major and investor Microsoft or any individual, Reuters reported.His lawyers argued there was a breach of \ncontract as OpenAI had agreed not to commercialise any product that its board considered artificial general \nintelligence (AGI). Microsoft, which joined the board last November following Altman’s reinstatement as CEO after \nan ouster, in a paper had said OpenAI's GPT-4 model could be viewed as early AGI.Microsoft first invested $1 \nbillion in the AI startup in 2019. Its multi-year investment now totals $13 billion, $10 billion of which was committed \nlast year. \nMicrosoft is entitled to a 75% share of profits until it makes back the investment and will thereafter get a further 49% \nstake in OpenAI, Fortune reported.How did OpenAI respond?OpenAI has said it ‘categorically disagrees’ with the \nlawsuit, in an internal memo to employees, Bloomberg reported.Its chief strategy officer Jason Kwon in the memo \nsaid that OpenAI is independent and competes directly with Microsoft, pushing back against Musk’s suggestion that \nthe startup is a ‘de facto subsidiary’ of the software giant.Altman called Musk a hero of his, adding he misses the \nperson he knew who competed with others by building better technology, Bloomberg reported citing a separate \nmemo.What was Musk’s involvement in OpenAI?Musk co-founded OpenAI as a non-profit when approached by \nAltman in 2015. He however exited the board in 2018, citing a conflict of interest with his other company Tesla. He \nis no longer involved in the startup.He brought the suit in the capacity of a donor to OpenAI's nonprofit parent \norganisation.Vinod Khosla, founder and managing director of OpenAI backer Khosla Ventures, said on X, “With \n@elonmusk, feels like a bit of sour grapes in suing @OpenAI, not getting in early enough, not staying committed \nand now a rival effort. Like they say if you can't innovate, litigate and that's what we have here.”Musk, who owns \nmicroblogging site X (formerly Twitter), last year launched AI venture xAI which rolled out a ChatGPT rival model \nGrok to premium X subscribers in December. He called it a ‘maximum truth-seeking AI’.From non-profit to ‘capped \nprofit’OpenAI was founded as a non-profit AI research company in 2015. “Our goal is to advance digital intelligence \nin the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return,” \nit had said in a blog then.Four years later, however, it established a ‘capped profit’ arm called OpenAI LP to \n‘increase its ability to raise capital’, it said in a 2019 blog.Under the new structure, returns for OpenAI’s first round of \ninvestors were capped at 100 times their investment, with any excess returns going to the non-profit parent.The \nstartup is now reportedly valued at $80 billion. For Reprint Rights: timescontent.com\nLoad-Date: March 5, 2024\nETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes"
    },
    {
        "file_name": "SPOKEN_PROMPTS_Dec2023",
        "header": "'PEEK INTO THE FUTURE'; AGILITY'S HUMANOID ROBOTS RESPOND TO",
        "media": "SPOKEN PROMPTS",
        "time": "December 15, 2023",
        "section": "BUSINESS; Pg. A-14",
        "length": "705 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "'PEEK INTO THE FUTURE'; AGILITY'S HUMANOID ROBOTS RESPOND TO \nSPOKEN PROMPTS\nPittsburgh Post-Gazette\nDecember 15, 2023 Friday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-14\nLength: 705 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nWhen Amazon began testing Agility Robotics' 5-foot, 9-inch walking bots in mid-October, the bright blue \nautonomous workers looked smarter than they were.\n\"The reality is the robots are not self-aware, they're not even using large language models right now,\" Agility CEO \nDamion Shelton said at the time.\nJust two months later, that has changed.\nIn a two-minute \"Embodied AI\" demo released Wednesday, Digit responded to a casual spoken prompt from an \nengineer.\n\"Take the box that's the color of Darth Vader's lightsaber and move it to the tallest tower,\" Pras Velagapudi told \nDigit in the video.\nThe bot quickly obliged, picking up a red box from a set of green and blue options, then walking it over to the tallest \nof four towers. It interpreted the engineer's natural language command using data in its new LLM, which was \ntrained on pop culture references, the company said.\nAn \"internal monologue\" put out by Digit shows the exact decisions the robot made to respond to the prompt.\n\"Thought: Darth Vader's lightsaber is red, and so the red box (box2) is the one I need to move,\" the monologue said \nfirst.\nThen, after securing the box and walking over to its destination, the robot had another thought.\n\"Now that I'm at tower4, I should place box2 on it.\"\nThe demonstration, which Agility called \"a peek into the future,\" comes as the company gears up to produce 10,000 \nDigit units per year at a massive production facility in Oregon.\nIn addition to the partnership with Amazon, the startup began testing its humanoids this month at a Spanx \ndistribution center in Georgia.\nAgility has said its autonomous system was capable of learning and adapting to new warehouses and tasks with \nminimal training. But AI capabilities will make that process even faster, meaning the bots could be deployed into a \nbroader arena of tasks and eventually make their way outside of warehouses.\n'PEEK INTO THE FUTURE' AGILITY'S HUMANOID ROBOTS RESPOND TO SPOKEN PROMPTS\n\"There's no need to redesign the warehouse or install infrastructure beyond that which is already designed around \npeople,\" Agility cofounder Jonathan Hurst said in the announcement.\nComing at the end of a year when ChatGPT and other new generative AI capabilities were built into thousands of \nsystems, the technology's inclusion into Digit isn't exactly a surprise. But Mr. Shelton wasn't initially convinced his \nrobots needed the new tool.\n\"In our case, we don't see there being a direct need or desire to have large language models or chatbots controlling \nthe robots,\" he told the Post-Gazette shortly after the Amazon announcement. \"What customers actually need is not \nthat you're having an interesting conversation with the robot. It's that it's doing the same thing repetitively and you're \nrelying on the physics of the robot to do work for you.\"\nOn Thursday, he clarified that LLM capabilities are more on the research and development side and are not yet \nready for industrial deployment. But he said the ability to experiment on a functional humanoid was an opportunity \nhe didn't want to pass up.\nDevelopers are locked in an intense race to bring the most attractive, capable agent to market, said Chris Atkeson, \na robotics professor at CMU.\n\"Whoever comes out first â€¦ is probably going to claim a lot of market share,\" he said.\nBoston Dynamics started using ChatGPT to give its doglike robot Spot spoken prompts earlier this year. The \ncompetitor, one of the first to demonstrate the potential of humanoids, signed a joint agreement with Agility last year \nnot to weaponize the advanced mobile robots.\nLLMs improve human robot interaction - an intense field of study and a dedicated institute at Carnegie Mellon \nUniversity - by allowing robots to build trust with human co-workers, Rishi Malhan, a doctoral candidate at the \nUniversity of Southern California found in a December report.\nThey also allow robots to introspect and ask for help, allowing them to gain more autonomy under human \nsupervision, Mr. Malhan found.\nGXO Logistics, the company testing Digit in Georgia, told the Robot Report it needs the robots to \"learn from our \nteachings and move product as our business needs.\"\nIt also needs the product to be reasonably priced, he said, though safety benefits help offset some of the \ninvestment.\nEvan Robinson-Johnson: ejohnson@post-gazette.com and @sightsonwheels\nGraphic\n \nPHOTO: Evan Robinson-Johnson/Post-Gazette: Agility's humanoid robot Digit loads pallets at the startup's lab on \nRobotics Row in Lawrenceville on Nov. 1. The 5-foot, 9-inch robots can now respond to spoken prompts, improving \ntheir chances of working for Amazon and the international logistics company GXO as Agility gears up to make \n10,000 units next year.\nPHOTO: Evan Robinson-Johnson/Post-Gazet: Agility's humanoid robot Digit loads pallets at the startup's lab on \nRobotics Row in Lawrenceville on Nov. 1, 2023. The 5-foot, 9-inch robots can now respond to spoken prompts, \nimproving their chances of working for Amazon and the international logistics company GXO as Agility gears up to \nmake 10,000 units next year.\n'PEEK INTO THE FUTURE' AGILITY'S HUMANOID ROBOTS RESPOND TO SPOKEN PROMPTS\nLoad-Date: December 15, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "Skilling Platform Disprz Bags $30m from Lumos and Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 7, 2023",
        "section": "STARTUPS & TECH",
        "length": "191 words",
        "byline": "Our Bureau",
        "story_text": "Skilling Platform Disprz Bags $30m from Lumos and Others\nEconomic Times (E-Paper Edition)\nAugust 7, 2023 Monday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 191 words\nByline: Our Bureau\nHighlight: Series-C funding round a mix of primary and secondary share sales\nBody\nBengaluru: Disprz, a corporate learning and skilling platform, has raised $30 million in its Series C funding round led \nby Lumos Capital. 360 ONE Asset (IIFL Wealth) and returning investors Kae Capital, KOIS and Dallas Venture \nCapital also participated. The funding, a result of primary and secondary share sales, will be utilised for global \nmarket expansion and product development, including the integration of generative artificial intelligence across \nthe learning and skilling cycle.  Additionally, Disprz aims to form  strategic partnerships and make strategic \nacquisitions, as per a statement. “We are right now in the middle of our $10 million to $100 million ARR (annual \nrecurring revenues) journey. The raised capital will let us build our next generation of products. We are a multi-\nproduct company, we have a suite of offerings on learning and upskilling for mid and large enterprises in emerging \nmarkets like India, southeast Asia, middle east and we've just made our trip to the US,” founder and CEO \nSubramanian Viswanathan told ET. Viswanathan said that the company currently has 12 clients in the US. In total, \nthe company has 350.\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "Newsletter_Oct2023",
        "header": "Pandemic Relief Funding for Child Care Is Ending. What Now?; DealBook",
        "media": "Newsletter",
        "time": "October 2, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1908 words",
        "byline": "Sarah Kessler and Claire Moses",
        "story_text": "Pandemic Relief Funding for Child Care Is Ending. What Now?; DealBook \nNewsletter\nThe New York Times \nSeptember 30, 2023 Saturday 21:01 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1908 words\nByline: Sarah Kessler and Claire Moses\nHighlight: More than 80 percent of licensed child care providers in the United States received the grants, which \nthey used to pay bills and raise wages for staff.\nBody\nMore than 80 percent of licensed child care providers in the United States received the grants, which they used to \npay bills and raise wages for staff.\nAs the U.S. government narrowly avoided a shutdown this weekend, a different kind of high-stakes shutdown \noccurred on Saturday.\nIn 2021, as part of a rescue package to combat the pandemic, the U.S. government made its single largest \ninvestment in child care, committing $24 billion to fund the sector that Treasury Secretary Janet Yellen has called a \ntextbook example of a broken market. That funding expired on Saturday, pulling a lifeline from more than 220,000 \nproviders — about 80 percent of all child care centers across the country. In crisis-prone Washington, this one has \nbeen called the “child care cliff.”\nThe child care shortage already costs families $78 billion per year, and businesses another $23 billion per year, \naccording to an analysis by the nonprofit group ReadyNation. And it could get more expensive: About 30 percent of \nproviders who took the grants said that they would fold without the funds.\n“Parents simply cannot afford to pay the true cost of providing care, and providers can’t afford to earn any less,” \nsaid Daniel Hains, a managing director at the National Association for the Education of Young Children.\nPoliticians on both sides of the aisle say they want affordable child care. Senator John Kennedy, Republican from \nLouisiana, compared affordable child care to Golden Retrievers. “No fair-minded person can be opposed to it,” he \nsaid during a hearing on child care policy this month. \nBut there is disagreement over the best way to make the math work. Child care providers used the funding to pay \nbills and offer more competitive wages. Democrats have proposed committing $16 billion per year for the next five \nyears to prop up child care providers, but with no Republican co-sponsors it’s unlikely to pass. Hains argues that \nother measures, like subsidizing child care costs for families, are important but won’t accomplish much if child care \nproviders can’t stay open in the first place. “We need to do more to stand up supply,” he said.\nThe Chamber of Commerce favors tax credits. The business lobbying group recently endorsed a bill that would \nexpand tax incentive programs, including those for employers that provide child care to employees and for parents \nwho pay for child care. While the bill has bipartisan support, some experts argue it is less robust than other \nproposals. “If you don’t have the money to pay for child care up front, it doesn’t help you at all,” said Julie Kashen, a \nsenior fellow at the left-leaning think tank the Century Foundation who has written extensively about child care \npolicy. \nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nPresident Biden’s “Build Back Better” plan included near universal child care for children until age 5, but the \nprovision was cut. Biden has since taken much less ambitious steps, like signing an executive order directing \nfederal agencies to find ways to make child care cheaper and requiring companies seeking at least $150 million of \nfunding under the CHIPS Act to guarantee child care.\nIn the meantime, the child care crisis will most likely get worse. In 41 states, the average annual cost of care for two \nchildren exceeds the average annual mortgage payment. Wages remain relatively low at child care providers, and \neven before the pandemic, about half of Americans lived in what’s called a “child care desert,” where supply does \nnot meet demand, according to the Center for American Progress. Some states, like New York, created new \nfunding for child care centers ahead of the cutoff in federal rescue financial assistance, and some centers have \nraised their prices to compensate for lost subsidies.\nThe cutoff won’t necessarily result in widespread sudden shutdowns of child care facilities, but it will likely contribute \nto the continuing shortage of affordable services. “I think that the child care cliff is probably the wrong way to think \nabout it,” said Chris Herbst, a professor at Arizona State University who studies the economics of child care. “I think \nit’s a slow roll downhill.” — Sarah Kessler\nIN CASE YOU MISSED IT \nLina Khan’s F.T.C. sues Amazon. The regulator and 17 states accused the e-commerce giant of acting illegally to \nmaintain its monopolistic position. The lawsuit is seen as a test of theories that Khan outlined in a now-famous \nessay she wrote as a law student, which argued that antitrust policy’s singular focus on consumer prices was ill \nsuited to an era of dominant tech platforms.\nAutoworkers expand their strikes. The United Automobile Workers union said 7,000 more of its members would \nwalk off the job as its labor dispute entered a third week. The decision was announced after President Biden and \nDonald Trump both visited Michigan this week to woo blue-collar voters in a swing state.\nJPMorgan Chase settles its legal cases over ties to Jeffrey Epstein. The Wall Street bank agreed to a $75 million \ndeal with the U.S. Virgin Islands and a separate agreement with Jes Staley, a former executive, to the convicted \nsex offender. The bank has paid a total of $365 million to settle claims related to Epstein, who remained a client \nafter he pleaded guilty to soliciting prostitution from a minor.\nThe Taylor Swift effect hits the N.F.L.\nWhen the pop megastar Taylor Swift appeared at a Kansas City Chiefs football game last weekend to cheer on her \nrumored boyfriend, Travis Kelce, the team’s superstar tight end, her visit set celebrity watchers and social media \nwild.\nBut it also signaled a collaboration between two of the world’s biggest brands: Swift, whose Eras tour is set to bring \nin $1.4 billion this summer, and the National Football League, the world’s most profitable sports league, The \nTimes’s Claire Moses writes.\nIf Swift attends the Chiefs’ game against the New York Jets this Sunday, there may be even more big spending \nfrom new football fans.\nHere are the numbers from Swift’s first outing:\n• Sales of Kelce’s jersey jumped nearly 400 percent after the game, according to Fanatics, the N.F.L.’s official \nretailer.\n• Fox Sports said the game was the week’s most-watched telecast on any network, with 24.3 million viewers. \nThe broadcast, which repeatedly cut to Swift sitting next to Kelce’s mother, dominated among female \nviewers ages 12 to 49.\nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nThe N.F.L. has embraced Swift’s ardent fandom. For several days, the league’s official account on X, formerly \nknown as Twitter, had “Taylor’s Version” as its biography. (The term referred to Swift’s re-recording of her albums \nafter her former record label sold the rights to her back catalog.)\nExperts applauded it as a marketing coup. “Taylor Swift is one of the biggest brands, if not the biggest brand, in the \nworld right now,” David Byrne, head of creative services at Thinkhouse, a youth marketing and advertising agency, \ntold DealBook. The singer could bring “millions of fans who’d never paid much attention,” he added.\nOther brands are also trying to capitalize on the moment. Heinz released a limited-edition “Ketchup and Seemingly \nRanch” sauce, referring to a picture of Swift eating fried chicken with those condiments at the game.\nSome conservative football fans are less excited. Some on the alt-right are wary of Swift, pointing to her support of \na Democratic political candidate in 2018. (Others have been leery of Kelce, objecting to his promotion of Pfizer’s \nlatest Covid vaccine.) “What will break Kelce’s heart first? The COVID shot or Taylor Swift?” Charlie Kirk, the \nfounder of the conservative activist group Turning Point USA, wrote on social media.\nKelce himself is slyly alluding to the boost in his stardom. On Wednesday, he and his brother Jason, a center for the \nPhiladelphia Eagles, acknowledged a slew of new fans on their “New Heights” podcast, including many who were \nnew to football. (They spent a portion of the show explaining the basics of the sport, from field goals to downs.)\n“I can’t believe being a Swiftie has lead me to watch a FOOTBALL podcast. Never in my wildest dreams,” one \ncommenter posted on the show’s YouTube page.\nA ‘canary in the coal mine’ for A.I. \nIn 2020, Kashmir Hill, a technology reporter for The Times, broke the story of Clearview AI, a secretive start-up that \nbuilt a powerful facial recognition tool used by police forces around the country. Clearview AI had scraped billions of \nphotos of ordinary web users that were published online to build the app.\nThe article led to a larger discussion about the proliferation of surveillance technology and how such tools should be \nregulated.\nKashmir talked with DealBook about her new book, “Your Face Belongs to Us: A Secretive Startup’s Quest to End \nPrivacy as We Know It,” which chronicles Clearview AI’s rise, and how facial recognition technology is changing our \nlives. The interview has been condensed and edited.\nAre there parallels between facial recognition and the recent rise of generative A.I.?\nI very much see facial recognition technology as the canary in the coal mine for what’s going to happen with the rest \nof A.I. It’s a matter of a company going out on the internet and collecting a whole bunch of data and information \nwithout anyone’s consent.\nThere’s a bit of a cautionary tale. If you don’t set up some boundaries, then you’re going to have a radical actor like \nClearview AI come along and use the technology in the most boundary-pushing way.\nFacebook and Google built similar tools, but decided they were too dangerous to release. What does that tell you?\nI do think that these companies are just more risk averse than a radical start-up. And so having these small \ngenerative A.I. start-ups bought by the bigger tech giants might slow down the most shocking kind of use cases of \nit.\nFacial recognition technology is simpler. It’s just faces. But a lot of the computing and the training to make powerful \nalgorithms was done by powerful companies, and then they open-sourced it, so the algorithms themselves became \naccessible.\nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nThe parallel in generative A.I. would be Meta open-sourcing its LLaMA 2 technology. That is where we’re starting \nto see the possible move toward an unrestrained environment for A.I. where anybody could use the Meta model \nthat they put out and do surprising things with that technology.\nKnowing what you know about facial recognition technology, does it have any place in society, or should it be \nbanned outright?\nI think the tale of facial recognition technology, and these kinds of technologies, shows that you can restrain it. You \ncan pass laws that work, and we’ve seen it before. One of the greatest examples is recording devices and bugs, \nwhich were coming out in the 1960s. And everybody was afraid that their conversations were going to be \neavesdropped on and their phones were going to be wiretapped. Congress passed a law that said, you know, you \ncan’t secretly record people. And this is why all the surveillance cameras that are all over the United States only \nwatch us and don’t listen to us.\nJust because we like using facial recognition technology to unlock our phone or to search a local criminal database \ndoesn’t mean that we have to usher in the most radical version of it.\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: About 30 percent of child care providers who took the grants said that they would have to fold without the \nfunds. (PHOTOGRAPH BY IAN WILLMS FOR THE NEW YORK TIMES) This article appeared in print on page B5.\nLoad-Date: October 2, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Hollywood Directors Union Reaches Deal With Studios",
        "media": "The New York Times",
        "time": "June 5, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "743 words",
        "byline": "By John Koblin",
        "story_text": "Hollywood Directors Union Reaches Deal With Studios\nThe New York Times\nJune 5, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 743 words\nByline: By John Koblin\nBody\nThe tentative agreement includes improvements in wages and guardrails around artificial intelligence.\nThe union that represents thousands of movie and television directors reached a tentative agreement with the \nHollywood studios on a three-year contract early Sunday morning, a deal that ensures labor peace with one major \nguild as the writers' strike enters its sixth week. \n  The Directors Guild of America announced in a statement overnight that it had made ''unprecedented gains,'' \nincluding improvements in wages and streaming residuals (a type of royalty), as well as guardrails around artificial \nintelligence.\n  ''We have concluded a truly historic deal,'' Jon Avnet, the chair of the D.G.A.'s negotiating committee, said in the \nstatement. ''It provides significant improvements for every director, assistant director, unit production manager, \nassociate director and stage manager in our guild.''\n  The deal prevents the doomsday Hollywood scenario of three major unions striking simultaneously. On \nWednesday, the Alliance of Motion Picture and Television Producers, which bargains on behalf of the studios, will \nbegin negotiations for a new contract with SAG-AFTRA, the guild that represents actors; their current agreement \nexpires on June 30. SAG-AFTRA is in the process of collecting a strike authorization vote.\n  The entertainment industry will be looking closely at what the directors' deal -- and the actors' negotiations -- will \nmean for the Writers Guild of America, the union that represents the writers. More than 11,000 writers went on \nstrike in early May, bringing many Hollywood productions to a halt.\n  Over the last month, the writers have enjoyed a wave of solidarity from other unions that W.G.A. leaders have said \nthey have not seen in generations. Whether a directors' deal -- or a possible actors' deal later this month -- \nundercuts that solidarity is now an open question.\n  W.G.A. leaders had been signaling to writers late last week that a deal with the directors could be in the offing, a \nstrategy that it said was part of the studio ''playbook'' to ''divide and conquer.'' The writers and the studios left the \nbargaining table on May 1 very far apart on the major issues, and have not resumed negotiations.\n  ''They pretended they couldn't negotiate with the W.G.A. in May because of negotiations with the D.G.A.,'' the \nW.G.A. negotiating committee told writers in an email on Thursday. ''That's a lie. It's a choice they made in hope of \nbreathing life into the divide and conquer strategy. The essence of the strategy is to make deals with some unions \nand tell the rest that's all there is. It's gaslighting, and it only works if unions are divided.\nHollywood Directors Union Reaches Deal With Studios\n  ''Our position is clear: To resolve the strike, the companies will have to negotiate with the W.G.A. on our full \nagenda,'' the email continued.\n  Representatives for the Alliance of Motion Picture and Television Producers declined to comment.\n  The writers and the directors shared some priorities, including wages, streaming residuals and concerns about \nartificial intelligence. W.G.A. leaders had said that the studios had offered little more than ''annual meetings to \ndiscuss'' artificial intelligence, and that they refused to bargain over guardrails. The D.G.A. said Sunday that it \nreceived a ''groundbreaking agreement confirming that A.I. is not a person and that generative A.I. cannot replace \nthe duties performed by members.''\n  Some of the writers' demands, however, are more complex than those of the directors. W.G.A. leaders have \ndescribed the dispute in urgent terms, calling this moment ''existential,'' and saying that the studios ''are seemingly \nintent on continuing their efforts to destroy the profession of writing.''\n  Despite the explosion of television production over the last decade, writers have said that their wages have \nstagnated, and their working conditions have deteriorated. In addition to improvements on compensation, the \nwriters are seeking greater job security, as well as staffing minimums in writers' rooms.\n  The W.G.A. has vowed to fight on. The writers, who last went on strike 15 years ago for 100 days, have historically \nbeen united.\n  ''We are girded by an alliance with our sister guilds and unions,'' Chris Keyser, a chair of the W.G.A. bargaining \ncommittee, said in a video message to writers last week. ''They give us strength. But we are strong enough. We \nhave always been strong enough to get the deal we need using writer power alone.''\nhttps://www.nytimes.com/2023/06/04/business/media/hollywood-directors-guild-deal.html\nGraphic\n \nPHOTO: As the writers' strike enters its sixth week, the directors guild reached a tentative agreement with the \nHollywood studios on a three-year contract. (PHOTOGRAPH BY MICHAEL M. SANTIAGO/GETTY IMAGES) This \narticle appeared in print on page B2.               \nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "time_with_patients_May2024",
        "header": "Doctors cautiously adopt AI-aided care; For many, its value is about more",
        "media": "time with patients",
        "time": "May 13, 2024",
        "section": "NEWS; Pg. A1",
        "length": "1776 words",
        "byline": "By, Karen Weintraub",
        "story_text": "Doctors cautiously adopt AI-aided care; For many, its value is about more \ntime with patients\nUSA Today\nMay 13, 2024 Monday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: NEWS; Pg. A1\nLength: 1776 words\nByline: By, Karen Weintraub\nBody\n\"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as \nopposed to putting up a barrier between me and the patient.\"\nDr. Rebecca Mishuris\nBOSTON - Dr. Rebecca Mishuris remembers her mother, also a doctor, bringing home her patients' medical charts \nevery night and working on them long after she'd gone to bed.\nFor years, Mishuris, a primary care physician at Brigham and Women's Hospital, repeated the ritual herself.\nBut no more.\nSince last summer, she's been piloting two competing software applications that use large-language models and \ngenerative artificial intelligence to listen in on, transcribe and summarize her conversations with patients. At the \nend of a patient visit it takes her just two to three minutes to review the summary for accuracy, cut and paste a few \nthings into the patient's health record and hit save.\n\"I look at my patients now (during a visit),\" said Mishuris, who oversees the pilot project across 450 Harvard-\naffiliated providers and plans to expand to 800 within the next month. \"It's a technology that puts me back in the \nroom with my patient as opposed to putting up a barrier between me and the patient.\"\nMishuris, chief medical information officer and vice president of digital at Mass General Brigham, is among the \nearliest adopters of artificial intelligence in medicine, a field known for being slow to adapt to change. (\"Legit, there's \na fax machine at the front of my clinic,\" she said.)\nWhile some other doctors have incorporated AI and large-language models, such as ChatGPT that analyze reams \nof online language, into their practices, Mishuris and a team 200 miles away at NYU Langone Health are among the \nfew who have opted to study its use.\nThey want to ensure the technology improves overall care before they adopt it more widely.\n\"We're not racing to get this out there. We really are trying to take a measured course,\" said Dr. Devin Mann, \nstrategic director of digital innovation at NYU Langone's Medical Center Information Technology. \"We really like to \nunderstand how these tools really work before we let them loose.\"\nThe much-maligned\nDoctors cautiously adopt AI-aided care For many, its value is about more time with patients\nelectronic health record\nNo one wants to make a mistake that will lose the trust of patients or doctors when using this technology.\nAfter all, digital technology has disappointed both before.\nElectronic health records have become essential tools in medicine, replacing the rooms full of paper documents that \nwere hard to maintain and subject to fires and other losses.\nBut patients hated the shift to electronic health records.\nRather than building a relationship with a physician, they felt they were now talking to the back of a caregiver's head \nas they listened to clacking fingers rather than making eye contact and listening to the murmurs of someone paying \nclose attention.\nDoctors disliked them even more.\nDr. Christine Sinsky, vice president of professional satisfaction at the American Medical Association, calls the shift \nto electronic health records the \"great work transfer.\" Physicians, rather than nurses, medical assistants or clerical \nworkers, were suddenly responsible for recording most of their patients' data during clinic visits.\nIn a 2016 study, Sinsky and her colleagues showed that after \"the great work transfer,\" doctors were spending two \nhours on desk work for every hour face-to-face with patients.\n\"It is time on (electronic health records) and particularly time on physician order entry that is a source of burden and \nburnout for physicians,\" she said.\nBurnout hurts everyone\nBurnout leads to medical errors, increases malpractice risk, reduces patient satisfaction, damages an organization's \nreputation and reduces patients' loyalty, according to Sinsky, who worked as a general internist in Iowa for 32 \nyears.\nShe calculated the cost of a doctor leaving the profession due to burnout at $800,000 to $1.4 million per physician. \nThe lost funds include the cost of recruitment, a sign-on bonus and onboarding costs.\nIn a recent survey of doctors, nurses and other health care workers conducted by the AMA, nearly 63% reported \nsymptoms of burnout at the end of 2021, up from 38% in 2020.\nInbox work also contributes to burnout, Sinsky said.\nThe volume of inbox work rose 57% in March 2020, as the pandemic set in, \"and has stayed higher since that time,\" \nSinsky said. Meanwhile, the rest of their workload hasn't dropped to compensate for the increase, so physicians are \nworking more during their off hours, she said.\nThe amount of time doctors put in during their personal time - commonly called \"work outside of work\" or \"pajama \ntime\" - is often a good predictor for burnout. Doctors in the top quarter of pajama-time workers are far more likely to \nfeel burnout than those in the lowest quarter.\nAmong the other new requirements adding to burnout is the expectation doctors will be \"texting while doctoring\" - \ntyping throughout a medical visit. This experience is as deeply unsatisfying for the doctor as it is for the patient, \nSinsky said.\nNote-taking means synthesizing\nStill, she's not convinced that generative AI and large-language models are the only or best solution to all these \nproblems.\nDoctors cautiously adopt AI-aided care For many, its value is about more time with patients\nIn her former practice, Sinsky said, what worked well was having a nurse in the room with the physician, sharing \ninformation, pulling up additional information from the electronic health record and entering orders in real time. That \nway, the doctor can focus on the patient and the nurse will be familiar enough with the patient's care to answer \nmost follow-up questions that may arise between visits.\n\"When we build systems that synthesize care and consolidate care and prioritize the relationships among the \npeople - between the doctor and the patient, between the doctor and the staff - that's when the magic happens. \nThat's when quality is better, cost is lower,\" she said. \"I see AI as a technology solution to a technology problem \nand its balance of risks and benefits hasn't yet been determined.\"\nSinsky said she worries that something will be lost when doctors completely stop dictating or writing their own \nnotes.\nAs anyone who writes regularly knows, it is in the act of writing that you truly begin to understand your subject, she \nsaid. Without that connection, that requirement to synthesize the material, Sinsky worries doctors will miss clues \nabout their patients' health.\n\"How much (AI) is going to help and how much it's going to distract us, that's TBD,\" she said. \"I fear that some \nphysicians may just accept the AI output and not have that pause and that reflection that then helps you consolidate \nyour understanding.\"\nHugs and other signs of promise\nStill, early responses to the AI notetaking technology from Harvard and NYU Langone have been positive.\n\"Some people say it's OK, but maybe not for them,\" Mishuris said, while most are more effusive. Many have \nreported \"drastic changes in their documentation burden,\" saying in some cases that they've been able to leave \ntheir clinic for the first time without paperwork hanging over them, she said. \"I've had people offer to hug me.\"\nMishuris' study also measures how much time doctors spend on their visit notes, in the electronic health records \nafter clinical hours, and how much they change the AI-drafted notes. If the doctor makes a lot of changes, it \nsuggests they are unhappy with the drafted note.\nEach doctor participating in the study fills out a survey after using one of two technologies for two weeks, then after \neight weeks and again at three months. At this point, participants are just about to hit the 8-week mark, so the data \nabout burden and burnout is coming soon, Mishuris said.\nShe hopes studies like hers will determine whether the technology is useful and for whom. \"It might be that the \ntechnology is not right for an oncologist yet,\" she said, or maybe it's not appropriate for every visit, \"but that is what \nwe're trying to determine.\"\nAt NYU Langone, where the AI experiment is happening on a smaller scale, early results show the technology was \nable to translate visit notes, which doctors typically write at a 12th grade level or above, to a 6th grade level - which \nis more understandable to patients, said Dr. Jonah Feldman, medical director of clinical transformation and \ninformatics for Langone's Medical Center Information Technology.\nWhen the doctors wrote the notes, only 13% broke the content into simple chunks, while 87% of the Chat-GPT4 \nnotes were written in easy-to-understand bits, he said.\nFeldman said the goal of using AI is not to put anyone out of work - typically the greatest fear workers have about \nartificial intelligence - but to get more done in the limited time allotted.\nThat will allow doctors to spend more quality time with patients - hopefully improving interactions and care and \nreducing burnout, he said. \"We're focusing on making the doctor more efficient, making the experience in the room \nbetter,\" Feldman said.\nDoctors cautiously adopt AI-aided care For many, its value is about more time with patients\nMann, who oversees digital innovation at NYU Langone, said he hopes to avoid AI-written notes that read \nawkwardly and waste clinicians' time on \"double-work,\" spending more time rewriting notes than they would have \nspent writing them in the first place. For this to work, he said, \"It's got to be a lot better, a lot easier.\"\nThe Langone team is also experimenting with using AI to respond to patients' emails. Mann said providers want the \nemail to sound personalized, so a doctor who previously would have sent patients \"haikus\" doesn't suddenly start \nsending \"sonnets.\"\nNext, the team wants to expand to home monitoring, so that someone who has been instructed, say, to check their \nblood pressure at home every day and upload that information to their doctor, can get questions answered via AI, \nrather than \"chasing us down with phone tag,\" Mann said. \"A lot of quick answers can be done faster, so we can put \nour limited time and energy into more complicated things.\"\nHe's also focused on providing these kinds of services first to people with limited resources since they are often the \nlast to receive technological advances.\nUltimately, the success of this kind of technology will come down to whether doctors are willing to adopt it and \npatients are comfortable with it.\nA recent Mishuris patient, Rachel Albrecht, had no problem with AI listening in on her medical appointment.\n\"It sounds like a good tool,\" Albrecht, 30, an accountant from Boston, said at the end of her appointment. She liked \nthe idea of getting an easy-to-understand summary of results after a visit. \"I'm pro-AI in general.\"\n\"I look at my patients now (during a visit). It's a technology that puts me back in the room with my patient as \nopposed to putting up a barrier between me and the patient.\"\nDr. Rebecca Mishuris\nGraphic\n \nDr. Rebecca Mishuris, an internist, measures Rachel Albrecht's vital signs during a recent visit.\nNathan Klima/USA TODAY\nLoad-Date: May 13, 2024"
    },
    {
        "file_name": "Tesla,_Twitter_Aug2023",
        "header": "Elon Musk founds xAI, an artificial intelligence company that may work with",
        "media": "Tesla, Twitter",
        "time": "August 17, 2023",
        "section": "ROBOTICS NEWS, ROBOTICS NEWS, ROBOTICS NEWS & BLOGGING NEWS",
        "length": "797 words",
        "byline": "Kara Carlson, Austin American-Statesman",
        "story_text": "Elon Musk founds xAI, an artificial intelligence company that may work with \nTesla, Twitter\nUSA Today Online\nJuly 13, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: ROBOTICS NEWS, ROBOTICS NEWS, ROBOTICS NEWS & BLOGGING NEWS\nLength: 797 words\nByline: Kara Carlson, Austin American-Statesman\nBody\nAUSTIN, Texas − Elon Musk has formed a new company focused on artificial intelligence.\nMusk, who also runs Tesla and SpaceX, announced the company's launch on Twitter Wednesday afternoon, saying \nthe company, xAI, was formed to \"understand reality.\" \nThe company is expected to work closely with Tesla and Twitter, which Musk also owns, according to xAI's website.\nAccording to the company’s website, the entity is considered separate from X Corp, but will work closely with \nTwitter, Tesla and other companies “to make progress towards (its) mission.” \nHere's what we know so far about the newly announced venture from one of the world's richest people.\nKomando: AI ChatGPT-powered smart toys are coming for the holidays. How to keep your kids safe.\nWhat is xAI? What will it focus on?\nThe website provides little detail into the artificial intelligence company’s goals but does say the team will answer \nquestions on a Twitter Spaces on Friday, July 14. \nThe website also said the team includes alumni from Tesla, OpenAI and Microsoft, and lists a 12-person team, \nnoting that team members have worked on AI including AlphaCode, Inception, GPT-3.5, GPT4, and Minerva.\nLink to Image\nIn a tweet, Greg Yang, one of the co-founders said the company would work to \"develop the 'theory of everything' \nfor large neural networks\" in order to take AI to the next level. His tweet also said the company will get into the \nmathematics of deep learning, which is an aspect of AI. Yang said the AI will also enable everyone to better \nunderstand the mathematical universe.\nElon Musk on AI\nThe launch of xAI also comes as Musk makes mixed comments about the technology. The billionaire has said he \nbelieves AI will be key to Tesla's future, but he has also said that he worries artificial intelligence could \"eliminate\" \nor \"constrain\" humanity, and signed onto a letter calling for an industrywide halt to AI training for several months. \nMusk's dive into artificial intelligence has been anticipated, including by a Financial Times report in April that said \nMusk was exploring an AI startup. The report also said Musk has acquired thousands of GPU processors needed \nElon Musk founds xAI , an artificial intelligence company that may work with Tesla , Twitter\nfor largescale AI, according to an Insider report. Musk also told Fox News in April he planned to develop an “anti-\nwoke” software called \"TruthGPT\" because he felt the companies currently working on artificial intelligence are too \n\"politically correct.\"\nThe company seems to be angling to compete with existing artificial intelligence companies including OpenAI, a \ncompany Musk helped found but has been increasingly critical of in recent months. \nOpenAI, one of the best-known generative AI companies, was founded in 2015, by Musk and a number of big \ntechnology players including Greg Brockman, Sam Altman, Reid Hoffman, Jessica Livingston, Peter Thiel, and \nOlivier Grabia. The company has made AI tools including ChatGPT, an artificial intelligence chatbot, and Dall-E, an \nartificial intelligence-based art generator.\nMusk resigned from the OpenAI board in 2018 but remained a donor. In recent months, he has been a vocal critic \nof the company, calling it biased. \nMusk also mentioned artificial intelligence during a keynote in Austin at EEI, where he called for more regulation \nand government oversight, and said he has been in contact with leaders on it.\nWhat could this new company mean for Tesla?\nDespite his comments and reservations, Musk has been betting on artificial intelligence for Tesla. \nIn May during the company's annual shareholder meeting, Musk spoke extensively on the subject, including Tesla's \nnot-yet released product Optimus, which the company has said will be a humanoid robot run on artificial intelligence \nsoftware. Musk considers the robot key to Tesla's future. Optimus is being designed off the same software as \nTesla’s controversial \"Full Self Driving\" vehicle software, a technology which industry experts and the company do \nnot yet consider fully autonomous. \nThe company first revealed the robot last year during the company's 2022 AI day, when the company showed a \nrobot that could barely walk. In May, an updated video showed the robot picking up items, recognizing objects, \nwalking, and training on human movements.\nIn a Twitter Spaces in April, Musk has also said that both Twitter and Tesla are buying GPUs, which can be used to \ndevelop AI.\nDan Ives, an analyst with Wedbush Securities, said xAI will likely work with Tesla as part of the Tesla ecosystem.\n\"We believe AI will be integrated into the Tesla vehicle over the coming years with FSD front and center. This will \nbe all part of the Tesla ecosystem with Austin playing a key role in AI development,\" Ives said. \nThis article originally appeared on Austin American-Statesman: Elon Musk founds xAI, an artificial intelligence \ncompany that may work with Tesla, Twitter\nLoad-Date: August 17, 2023"
    },
    {
        "file_name": "The_Economic_Times_Sep2023",
        "header": "In AI, I is for India | Tech majors build cutting edge AI solutions for the world",
        "media": "The Economic Times",
        "time": "September 3, 2023",
        "section": "TECH & INTERNET",
        "length": "1572 words",
        "byline": "Romita Majumdar and Surabhi Agarwal",
        "story_text": "In AI, I is for India | Tech majors build cutting edge AI solutions for the world\nThe Economic Times\nSeptember 4, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1572 words\nByline: Romita Majumdar and Surabhi Agarwal\nBody\nGlobal technology majors like SAP, Adobe, IBM and Microsoft are building cutting edge artificial solutions in India \nfor the world. Top CEOs of these firms talk about how the country is becoming an important part of the research, \nwhich will drive this disruptive force in the future.AI will bring more talent into creative fields: AdobeAdobe Inc's India \nteams are helping build the next-gen AI-ready solutions for the company, said CEO Shantanu Narayen. He added \nthat the company is driving development of several global products from India. \"There's this recently-released \nfeature called Generative Recolor - think about text, you identify a text and you want to get a prompt or a vector to \nstart your creative process - all of that development is happening here, right here in the Noida office,\" he explained. \nThe developments happen on all three layers, Narayen said. \n\"We're developing models here based on our data for the domains in which we are interested, and we're building \nand collecting data in an appropriate way. And we're also building interfaces for each of our applications,\" he said, \nadding that India operations are at the core of the work done globally. Answering a question on whether AI is a \nthreat for creative industry, he said that the adoption of AI will help bring more talent into creative fields.\"We \nfundamentally believe that they will enable creatives to be more creative. Secondly, it'll allow more people to \nparticipate in the creative profession.\" However, he added that Adobe will have a role to play in helping to \nunderstand how AI models used in its solutions were built, how they will be deployed, and whether the final output \nwas created by humans or machines. \"I think those are problems that we're working on, and we've stepped up to \nthem,\" he added. Talking about India as a revenue centre for the US headquartered company, he said that while it \nis still behind other top geographies, the growth rate of the business here has been strong. \"If you look at it in terms \nof the growth rate right now, on the creative side, the documents side or on the marketing side - which is enabling \nbusinesses to be digital - India's growth rates are great,\" said Narayen. Adobe India is lo ok i n g t o b et on large \nbanks and retail firms among other large organisations to further augment its growth in India. \"Take the financial \nservices, look at these giant financial institutions like HDFC, ICICI, SBI, etc, and how they're thinking about digital, \nthat's an opportunity for us,\" Narayen said.AI could  bring big benefits for India: Microsoft Microsoft India's teams \nare at the forefront of research on the efficient use of AI solutions, said Brad Smith, vice-chairman and president, \nMicrosoft. While the India teams work on a variety of global solutions, research on AI has been a big part of the \nwork driven from the country, and at a time when Microsoft itself is leading the global AI discourse. \"What I'm most \nstruck by in some ways is what we're doing in AI. On both, the research side with Microsoft Research Bangalore \nand on the India Development Centre (IDC). There's a lot of work going on here, and we're figuring out how we can \nbetter tune and develop and deploy AI models with GPUs,\" said Smith, who is the senior most executive at the firm \nafter Satya Nadella. \"What's unique here, is developing the technical know how to better use AI across multiple \nlanguages. This is an extraordinary place to do that,\" said Smith. He said that these translation solutions will also \nhave a significant impact in making knowledge more accessible for a large audience within India. \"Think about what \nit does for a country that speaks many languages, and for its ability to translate. Think about what it does for a \ncountry where not everyone is literate, and the ability to speak and get answers,\" he explained. \"But we have to \nfocus on how we upskill our people. But that, to me, will be a hugely important priority,\" he said, adding that \nIn AI, I is for India | Tech majors build cutting edge AI solutions for the world\nMicrosoft India works on every global product solution within the company. There is a flip side too, though. AI is \nmore capital intensive, he added, and the amount of money that's being spent on infrastructure, GPUs, CPUs, \nenergy, fibre and buildings, etc, is huge. So the capital investment on AI will grow much faster than the costs related \nto people, he predicted. \"We're going to see the people side grow slower than the capital side.\" But, India is \ncontinuing to play a more important role for Microsoft and it will continue to play a more important role, he added. \n\"India is the second most important country for Microsoft after the US when it comes to the development of \ntechnology,\" he said. Smith said that AI could bring more benefits to a country like India or the global South than \nsome of the more advanced economies in the OECD region due to their rapidly ageing population.India's R&D \nfacilities are top focus: SAPThe Indian talent base plays a very important role in global software management \nplatform SAP's thought leadership and R&D focus, said Punit Renjen, CEO-emeritus of Deloitte Global and the \nincoming chairman of SAP. The company, which has over 20,000 developers and engineers based out of its \nBengaluru unit, is also driving a large chunk of its AI focus from this region. \"I'll be coming in December and touring \nthe SAP R&D facilities. India plays a really important part in SAP's R&D and thought leadership,\" said Renjen, \nadding that Deloitte also has a similar focus for India. \"There are 1,00,000 professionals in Deloitte that call India \nhome. Of the company's workforce, 25 per cent are India-based. In the case of SAP today, it's about 17-18 per \ncent. I can assure you that Christian (Klein, CEO) and his team are focused on getting it to a higher level.\" Ranjen \nsaid that SAP is making the right investments to boost its presence in the AI marketspace. \"We'll be investing over \na billion dollars. It's going to be a multifaceted investment thesis - investing in making the product portfolio AI-\nenabled is just one area,\" he said. Investing in new areas of doing work would be a second, and forming \necosystems and alliances will be the third. \"SAP and Microsoft have an alliance, SAP and Google have an alliance. \nSo, all of this together is how companies will play the AI game,\" Renjen said. In April this year, Sindhu \nGangadharan, MD and SVP, SAP Labs India, said that 40 per cent of the global research and development at SAP \nhappens out of Bengaluru. A quarter of the patents filed by SAP are also coming out of Bengaluru. India is the \nfastest growing market for the company, and in the past few years, an average of 3,500 employees were hired. And \nwith increasing focus on AI, governments and institutions need to intensify skilling initiatives to effectively tap \nemployment opportunity created by this technology. \"Millions of people are coming into the job market. We need to \nabsolutely be reskilling them, so they can work in this new world of digital cloud AI,\" he said. He added that while \nIndian institutes produce a lot of talent, they also need to be prepared for the global talent market. \"We churn out a \nlot of individuals, but they're not all world-class, which is what's required for India to compete globally. We need to \nenhance the quality of education,\" he added. And AI can be of great help in that area.AI will help expand business \nopportunities: IBMIBM Labs in India, located across Bengaluru, Pune, Ahmedabad and Kochi, are working \ncollaboratively to build solutions for global clients, said Arvind Krishna, chairman and CEO, IBM. He added that in \norder to effectively leverage the AI opportunity, India will need skilled workforce numbering a couple of millions. He \nsaid that the company is seeing a lot of work in AI solutions across its India footprint, including research, consulting \nand BPO teams. IBM teams in Bengaluru, Pune and Kochi are also involved in building AI products, he added. \"We \nrun a globally integrated enterprise. So, our own people can leverage computing facilities in India, like in Chennai \nand Bengaluru. They can access our computing facilities across the globe,\" he said. Citing the example of IBM's \nKochi facility, he added that the company has over 1,0 0 0 employees building solutions for global client s while \nadding to the Indian employee base. While addressing concerns around AI replacing human roles across \norganisations, Krishna said that AI will only help free up talent to expand business opportunities. \"If you presume a \nconstant number of clients and a constant amount of work, AI will probably reduce talent requirements. But in the \nworld that we live in, it is a competitive advantage where people can win more business and increase with a \nsomewhat slower rate of employee additions,\" said Krishna, adding that it will eventually lead to more employment. \nK rishna expects that the demand for artificial intelligence, much like during the BPO and IT services waves, will be \na positive opportunity for the Indian tech industry and its workforce to leverage and grow further. And finally, as A I \nusage gains prominence , countries will need to work on building their own capabilities in large language models \nand computing infrastructure to support sovereign A I capabilities, Krishna said, further adding that the government \nshould also possibly consider investing in this area, given that will cost only \"millions and not billions\" For Reprint \nRights: timescontent.com\nLoad-Date: September 3, 2023\nIn AI, I is for India | Tech majors build cutting edge AI solutions for the world"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "3 Indian companies make the cut on BCG's top 25 global value creator list",
        "media": "The Economic Times",
        "time": "April 22, 2024",
        "section": "STOCK IN NEWS",
        "length": "383 words",
        "byline": "Akash Podishetti",
        "story_text": "3 Indian companies make the cut on BCG's top 25 global value creator list\nThe Economic Times\nApril 23, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 383 words\nByline: Akash Podishetti\nBody\nThanks to strong capital markets in 2023, the average annual total shareholder return surged in the BCG’s Value \nCreators database. The median rose to 12% per year from 2019 through 2023 — up from 7% per year from 2018 \nthrough 2022.Technology and tech-related companies led the charge, as excitement over generative AI helped \nfuel a rebound from 2022’s losses, according to a report based on the database.\"The landscape is not solely tech \ndominated, however. Several asset-heavy industrial sectors or recently lagging industries also accelerated their \nTSR performance compared with last year’s study and now rank near the top of our industry ranking,\" it noted.With \nglobal market indices perched at all-time highs, companies across sectors now face the challenge of maintaining or \nregaining TSR momentum.Within this, several Indian companies made the cut including Jindal Stainless, which \nsecured the 9th spot among the top 25 shareholder returns.The 5-year annualised TSR of the company was at 76% \nand the 25 year TSR stood at 74. Varun Beverages at rank 22 and Tube Investments of India at 25th spot also \nmanaged to get a place on the list of top 25 companies.The 2024 rankings revealed a broad range of TSR \nperformance within each of the industries we studied, showing that all companies have the opportunity to \noutperform the broader market, regardless of their industry dynamics.Overall, the last 12 months have been \nincredibly strong for the global capital markets, with median annual total shareholder returns increasing from 7% to \n12% on a rolling 5-year basis.Tech-related industries have outperformed, propelled by unprecedented excitement \nover GenAI and its long-term potential to unlock new value pools across industries and functions.\"India has been at \nthe forefront of this charge across the global markets. \nEven more “traditional” asset-heavy industries have performed very strongly, reflecting India’s accelerated push \ntoward domestic manufacturing in multiple sectors and increased investment in industrial infrastructure \ndevelopment,\" said Akshay Kohli, MD and Partner, and Leader - Corporate Finance and Strategy (CFS) Practice in \nIndia.But amid this historic bull run, Kohli said companies are faced with a complex set of challenges to navigate. \nFor Reprint Rights: timescontent.com\nLoad-Date: April 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Wrong Turns Doom Efforts On Apple Car",
        "media": "The New York Times",
        "time": "March 1, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1328 words",
        "byline": "By Brian X. Chen and Tripp Mickle",
        "story_text": "Wrong Turns Doom Efforts On Apple Car\nThe New York Times\nMarch 1, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1328 words\nByline: By Brian X. Chen and Tripp Mickle\nBody\nInternal disagreements over the direction of the Apple car led the effort to sputter for years before it was canceled \nthis week.\nFor the last decade, many Apple employees working on the company's secretive car project, internally code-named \nTitan, had a less flattering name for it: the Titanic disaster. They knew the project was likely to fail. \n  Throughout its existence, the car effort was scrapped and rebooted several times, shedding hundreds of workers \nalong the way. As a result of dueling views among leaders about what an Apple car should be, it began as an \nelectric vehicle that would compete against Tesla and morphed into a self-driving car to rival Google's Waymo.\n  By the time of its death -- Tuesday, when executives announced internally that the project was being killed and \nthat many members of the team were being reassigned to work on artificial intelligence -- Apple had burned more \nthan $10 billion on the project and the car had reverted to its beginnings as an electric vehicle with driving-\nassistance features rivaling Tesla's, according to a half dozen people who worked on the project over the past \ndecade.\n  The car project's demise was a testament to the way Apple has struggled to develop new products in the years \nsince Steve Jobs's death in 2011. The effort had four different leaders and conducted multiple rounds of layoffs. But \nit festered and ultimately fizzled in large part because developing the software and algorithms for a car with \nautonomous driving features proved too difficult.\n  Apple declined to comment.\n  ''When it started, it was aligning the stars on something Apple alone could hit a home run on,'' said Bryant Walker \nSmith, an associate professor at the schools of law and engineering at the University of South Carolina, who spoke \nto Apple briefly about its project in 2015. ''A decade later, the stars have realigned to make this a lot of risk and not \na lot of gain.''\n  When Apple launched its car project in 2014, it was among a stampede of investors, executives, engineers and \ncompanies chasing the idea of a self-driving car. After Google began testing prototypes on public roads in \nCalifornia, voices across Silicon Valley insisted that autonomous vehicles would soon be commonplace. Apple \ndidn't want to be left behind.\n  At the time, the company was dealing with questions from its top engineers about its next project, according to \nthree people familiar with the project's origins. It had just finished the Apple Watch, and many engineers were \nWrong Turns Doom Efforts On Apple Car\nrestless to begin work on something new. Tim Cook, Apple's chief executive, approved the project in part to prevent \nan exodus of engineers to Tesla.\n  Apple also needed to find new ways to expand its business. The company was anticipating that sales of iPhones \nwould slow in the coming years. Cars were part of a $2 trillion transportation industry that could help Apple, which \nby then was a nearly $200 billion business.\n  Despite having a vote of confidence from Apple's chief executive, members of the team knew they were working \nagainst harsh realities, according to the six employees familiar with the project. If it ever came to market, an Apple \ncar was likely to cost at least $100,000 and still generate razor-thin profit compared with smartphones and earbuds. \nIt would also arrive years after Tesla had dominated the market.\n  The company held some discussions with Elon Musk about acquiring Tesla, according to two people familiar with \nthe talks. But ultimately, it decided that building its own car made more sense than buying and integrating another \nbusiness.\n  Mr. Musk did not respond to a request for comment.\n  From its inception, the project was troubled by differing views on what it should be, the people familiar with it said. \nSteve Zadesky, who initially led the effort, wanted to build an electric vehicle that competed with Tesla. Jony Ive, \nApple's chief design officer, wanted to pursue a self-driving car, which members of the software team said could be \ndone.\n  Apple, which by then had $155 billion in cash, spent lavishly to hire hundreds of people with experience in \nmachine learning, a type of A.I. technology, and other capabilities crucial to making a self-driving car. The influx of \npeople made the project among the first that Apple had developed with so many outsiders new to the company's \nculture.\n  The car team, composed of more than 2,000 employees by this year, included engineers who had worked for \nNASA and developed racecars for Porsche.\n  The group developed an array of new technologies, including a windshield that could display turn-by-turn \ndirections and a sunroof that would feature special polymer to reduce heat from the sun.\n  To bolster morale and guidance, star executives like Mr. Ive and the head of Mac engineering, Bob Mansfield, got \ninvolved. The company acquired several start-ups to join the car team. In 2021, to steer the project toward success, \nApple put Kevin Lynch, the executive behind its popular Apple Watch, in charge of the car.\n  Mr. Ive and his team of designers drew concepts for a car that would look like a European minivan such as the \nFiat Multipla 600, which has a half-dozen windows and a curving roof. It had no steering wheel and would be \ncontrolled using Apple's virtual assistant, Siri.\n  One day, in the fall of 2015, Mr. Ive and Mr. Cook met at the project's headquarters in Sunnyvale, Calif., for a \ndemonstration of how the car might work. The two men sank into the seats of a cabinlike interior. Outside, a voice \nactor read from a script of what Siri would say as the men zoomed down the road in the imaginary car. Mr. Ive \nasked Siri what restaurant they passed and the actor read an answer, said two people familiar with the \ndemonstration.\n  But by 2016, it was clear that the car effort was in trouble. Mr. Zadesky left Apple, and his successor, Mr. \nMansfield, told the team working on the project that they would be shifting their focus from building a car to building \nself-driving car software, said three people familiar with the shift.\n  Apple secured permits from California to begin test-driving Lexus sport utility vehicles outfitted with sensors and \ncomputers. It held discussions with car makers such as BMW, Nissan and Mercedes-Benz before striking a deal \nwith Volkswagen to provide Transporter vans for self-driving shuttles on Apple's campus.\nWrong Turns Doom Efforts On Apple Car\n  Two more leaders took over the car effort in the years that followed. Doug Field, a former Tesla executive, laid off \nmore than 200 employees on the project as he leaned into efforts to build its self-driving system. Then Mr. Lynch, \nwho succeeded him in recent years, reversed the company's plans and went back to its original idea of making an \nelectric vehicle.\n  Mr. Mansfield and Mr. Field didn't respond to requests for comment.\n  At the start of this year, Apple's leadership decided that it was a better use of the company's time to work on \ngenerative A.I. rather than the car, the company told employees in an internal meeting on Tuesday. The company \nsaid some members of the Project Titan team would be reassigned to work on artificial intelligence.\n  In interviews on Wednesday with The New York Times, people who worked on the project praised the decision to \nshutter it, saying the technology behind generative A.I. could be invaluable to the future of the company's all-\nimportant iPhone business.\n  Apple's dead car project will be survived by its underlying technologies. The company plans to take what it has \nlearned about artificial intelligence and automation and apply it to other technologies that are being researched, \nincluding A.I.-powered AirPods with cameras, robot assistants and augmented reality, according to three people \nbriefed on the projects.\n  Though the engineers working on automation software will get to work on artificial intelligence projects, others on \nthe car team have been told they will need to apply for different roles at the company.\n  Cade Metz contributed reporting.Cade Metz contributed reporting.\nhttps://www.nytimes.com/2024/02/28/technology/behind-the-apple-car-dead.html\nGraphic\n \nPHOTO: Tim Cook, Apple's chief executive, approved the car project in part to prevent an exodus of engineers to \nTesla, as many were said to be restless. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (B3) This \narticle appeared in print on page B1, B3.               \nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Alternatives_Dec2023",
        "header": "SaaS startup Kapture raises $4 million funding from PE firm India",
        "media": "Alternatives",
        "time": "December 19, 2023",
        "section": "FUNDING",
        "length": "309 words",
        "byline": " ",
        "story_text": "SaaS startup Kapture raises $4 million funding from PE firm India \nAlternatives\nThe Economic Times\nDecember 19, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 309 words\nBody\nKapture CX, a customer support platform for enterprises, has raised $4 million from India Alternatives, a private \nequity fund. The Bengaluru-based startup has been expanding on-ground operations in five countries: the US, the \nUAE, Indonesia, Saudi Arabia and India.The company last raised funds in July—a $4 million roundled by venture \ncapital firm Cactus Venture Partners (CVP). The latest infusion will be used to push Kapture’s generative artificial \nintelligence (Gen AI) capabilities and strengthen its footprint across India as well as global markets, the company \nsaid in a statement.Having crossed a 1,000 customers from 19 countries, the company is planning to add 100 more \nemployees next year, the statement added.“We are experiencing tailwinds across the large and global enterprise \nsegment that has made us capitalise on Gen AI capabilities. We are confident that a value added and relationship \noriented partner like India Alternatives will help us bolster our position as a leading SaaS player across India and \nglobal markets,” Vikas Garg, cofounder of Kapture CX said. The company was founded by Garg, Sheshgiri Kamath \nand Pearl Tewari in 2014.India Alternatives Investment Advisors is a mid-market, domestic private equity firm. \nPrivate equity firms have played an active part in startup funding this year. Earlier this month, ChrysCapital acquired \na 75% stake in ProHance Analytics,a Bengaluru-based business-to-business software-as-a-service platform \noffering workforce analytics and operations enablement.“Kapture is well positioned to capitalise on this opportunity \ndue to Shesh (Kamath) and Vikas’ excellent leadership, customer orientation and ability to leverage Gen AI \ncapabilities to provide a customised solution at scale,” said Shivani Bhasin, founder and chief executive of India \nAlternatives. \nFor Reprint Rights: timescontent.com\nLoad-Date: December 19, 2023"
    },
    {
        "file_name": "USA_Today_Online_May2023",
        "header": "Wendy's to launch drive-thru AI program in June",
        "media": "USA Today Online",
        "time": "May 9, 2023",
        "section": "",
        "length": "231 words",
        "byline": "Taijuan Moorman, The Columbus Dispatch",
        "story_text": "Wendy's to launch drive-thru AI program in June\nUSA Today Online\nMay 9, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 231 words\nByline: Taijuan Moorman, The Columbus Dispatch\nBody\nLink to Image\nWendy's has announced a pilot program with Google Cloud that will introduce artificial intelligence to its drive-thru \nexperience.\n\"Wendy's FreshAI\" will leverage Google Cloud's generative AI and large language models to simplify the ordering \nprocess in a pilot program set to launch in June at a yet-to-be-announced Wendy's location in the Columbus, Ohio \narea.\nThe Dublin,Ohio-based fast food chain will use generative AI to ease conversations, understand customized orders \nand provide quick responses to frequently asked questions. \nThe company has used Google Cloud's data analytics, AI and machine learning tools since 2021.\nAI Carl’s Jr., Hardee’s partnering with AI companies to automate drive-thrus\nIn a release, Todd Penegor, president and CEO of Wendy's, said the use of AI will allow employees to \"continue \nfocusing on making great food and building relationships with fans.\"\n\"Wendy's introduced the first modern pick-up window in the industry more than 50 years ago, and we're thrilled to \ncontinue our work with Google Cloud to bring a new wave of innovation to the drive-thru experience,\" said Penegor. \n\"Google Cloud's generative AI technology creates a huge opportunity for us to deliver a truly differentiated, faster \nand frictionless experience for our customers.\"\nThis article originally appeared on The Columbus Dispatch: Wendy's to launch drive-thru AI program in June\nLoad-Date: May 9, 2023"
    },
    {
        "file_name": "embodies_all_that's_wrong_with_AI_Jan2024",
        "header": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; Tasteless stunt",
        "media": "embodies all that's wrong with AI",
        "time": "January 18, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1153 words",
        "byline": "BRIAN MERCHANT",
        "story_text": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; Tasteless stunt \nembodies all that's wrong with AI\nLos Angeles Times\nJanuary 18, 2024 Thursday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1153 words\nByline: BRIAN MERCHANT\nBody\nI knew it was going to be bad. By the time I sat down to watch the thing, much of the internet was already furious \nthat a \"state-of-the-art-entertainment AI\" called Dudesy had generated an hourlong comedy special in the style of \nGeorge Carlin, without the consent of the late comic's horrified family. But I wasn't prepared for it to be so bad.\nThe special, tastefully titled \"George Carlin: I'm Glad I'm Dead,\" is one of the most unpleasant things ostensibly \nproduced for entertainment purposes that I have ever sat through. It's a stroll through an uncanny valley of Carlin's \ncomedy, an audio program in which a serviceable replica of the familiar raspy voice delivers \"jokes\" on topics from \nmass shootings to Taylor Swift to artificial intelligence.\nIt's all set to an unsettling rotating gallery of AI-generated images that roughly correlate to whatever Carlin's \nsimulacrum is discussing. When the Carlin voice is hitting on the malign influence of money in politics, there's a \nbizarre diagram of politicians being bought off, with figures labeled \"The guluar citizen\" and \"Liolbolist\"; when AI \nCarlin says the you-know-what \"has hit the fan,\" a hyper-stylized brown tube protrudes from one.\nIt's a nightmare. If I were to have to watch this whole thing in a darkened room, eyeballs peeled like the guy in \"A \nClockwork Orange,\" there is a non-zero chance I would have a complete psychotic break.\nSadly, that's the point. This thing wasn't produced to convince anyone AI can produce great work in the style of one \nof our iconic comedians. It was, like the AI Drake song and those Harry Potter-directed-by-Wes Anderson images \nbefore it, a provocation. It was supposed to cause a stir, to go viral in a way that vaguely unsettles or irks people, \nand it did that exactly. Part of that calculation may have, depressingly, included pissing off Carlin's family and \nestate, which it also did.\nCarlin's daughter, Kelly, responded to the special in a statement about her dad. \"No machine will ever replace his \ngenius,\" she wrote on X. \"These AI generated products are clever attempts at trying to recreate a mind that will \nnever exist again. Let's let the artist's work speak for itself. Humans are so afraid of the void that we can't let what \nhas fallen into it stay there... Here's an idea, how about we give some actual living human comedians a listen to?\"\nGeorge Carlin fans have expressed disgust with the content itself, too: Vice's Matthew Gault, a self-described \nlongtime fan of the comic, described the special as \"worse than you could possibly imagine.\" Writer and PR pro Ed \nZitron, another Carlin stalwart, wrote that \"the jokes were bad, the voice was soulless and inaccurate, the pace was \nlanguid, and the world will have forgotten about it in two weeks unless Carlin's estate sues (and I desperately hope \nthey do so).\"\nBUSINESS ON TECHNOLOGY AND THE INTERNET Tasteless stunt embodies all that's wrong with AI\nBut what bothers me uniquely about this episode is that it serves as a grim snapshot of where so much of the AI \nindustry is at, a year into its reign as the dominant tech trend: Here we have an apparently impressive technology -- \nwe can't know for sure, because the details are concealed in the production process, and almost surely involve \nample human labor -- designed not to meaningfully entertain, or to present any actual utility, but to exist wholly as a \nwarped advertisement for itself.\nSo much of AI is smoke and mirrors right now, clouding what too often seems to have amounted to automated \ndigital reappropriation (it's no accident that the special begins with a long disclaimer that what you're about to see is \nnot actually George Carlin and was created by an AI that \"learned\" from his specials, in a laborious effort to avoid \nallegations of copyright infringement) and rank opportunism.\nNotice the pattern of chief AI spokesman Sam Altman himself, who spent last year publicly extolling the vast and \npotentially terrible power of the AI he was building -- a CNN headline from October noted that \"Sam Altman warns \nAI could kill us all\" -- but has now pivoted to assuring business leaders in Davos, Switzerland, that actually, it's just \ngood for business. \"It will change the world much less than we all think,\" Altman said this week at the World \nEconomic Forum there, adding that it's an \"incredible tool for productivity.\"\nThe cynical observer might conclude that the apocalyptic AI hype tour Altman and his peers embarked on in 2023 \nwas merely a sustained auto-generated George Carlin special: a stunt designed to generate interest in the power of \na product that tech companies want to sell you.\nThat's likely the case with Dudesy, the \"AI\" that allegedly created the special, though we can't say for certain \nbecause what Dudesy actually is remains shrouded in the dumbest kind of secrecy. The Dudesy \"AI\" is the \nanimating conceit of a comedy podcast hosted by ex-\"MadTV\" cast member Will Sasso and comedian Chad \nKultgen. The premise is that both comics have handed over all their personal data to Dudesy -- a bot created by an \nunnamed tech company, and which the hosts have told journalists that a nondisclosure agreement precludes them \nfrom discussing -- and the \"AI\" runs the show.\nI keep putting \"AI\" in scare quotes because it's not entirely clear to what extent Dudesy exists as a technology, \nwhether it's fabricated by the comedians, or stitched together from ChatGPT output or voice manipulation \ntechnology or actually some proprietary chatbot or what. Honestly, I don't know what would be worse: if two \nwashed-up comedians stitched together a stunt that made it appear as though an AI generated a facsimile of \nGeorge Carlin, insulting his memory, fans and family in order to flog their floundering podcast, or if there was a real \ntech company behind this and its bad-taste advertising for some voice-replication product.\nThe podcast, which isn't all that popular, appears to rely on its central hook to juice its numbers. Before the Carlin \nstunt, Dudesy had produced another comedy special, this one performed by an AI version of quarterback Tom \nBrady, which was immediately met with the threat of legal action and taken down.\nI want to pause here to note that one of the stories about that fiasco I found was published by Sports Illustrated, \nwhich recently faced down its own scandal over allegations the once-iconic sports magazine was using AI to write \narticles, which were posted to the site in uncharacteristically weird and unintelligible prose. And, well, here's the \nopening sentence of the Sports Illustrated article about AI Tom Brady: \"Comedy comes in many different forms and \nis portrayed in a multitude of ways, but a newly generated AI comedy special -- created by comedians Will Sasso \nand Chad Kultgen -- created some buzz last week.\"\nCan't say for certain, but that scans as AI-generated to me! It felt like a glimpse of one plausible, fast-arriving future: \ngenerative AI products reviewing other generative AI products ad infinitum -- bad AI content all the way down.\nGraphic\n \nBUSINESS ON TECHNOLOGY AND THE INTERNET Tasteless stunt embodies all that's wrong with AI\nPHOTO: THE LATE George Carlin, shown in an undated photo, was re-created in an hourlong comedy special \npurportedly generated by an AI, to awful effect.  PHOTOGRAPHER:George Carlin's Estate / HBO \nLoad-Date: January 18, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Oct2023",
        "header": "BAIDU TOUTS A RIVAL TO CHATGPT",
        "media": "Wall Street Journal Abstracts",
        "time": "October 19, 2023",
        "section": "B; Pg. 4",
        "length": "31 words",
        "byline": "SHERRY QIN",
        "story_text": "BAIDU TOUTS A RIVAL TO CHATGPT\nWall Street Journal Abstracts\nOctober 18, 2023 Wednesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 31 words\nByline: SHERRY QIN\nBody\nABSTRACT\nBaidu unveILS new generative artificial intelligence model that it claims rivals ChatGPT, as part of its efforts to \nlead race for AI development in world’s second-largest economy (S)\nLoad-Date: October 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Your Tuesday Briefing",
        "media": "The New York Times",
        "time": "May 2, 2023",
        "section": "BRIEFING",
        "length": "1557 words",
        "byline": "Natasha Frost",
        "story_text": "Your Tuesday Briefing\nThe New York Times \nMay 2, 2023 Tuesday 00:53 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BRIEFING\nLength: 1557 words\nByline: Natasha Frost\nHighlight: The sale of First Republic Bank.\nBody\nThe sale of First Republic Bank.\nOfficials move to contain U.S. banking crisis\nIn the early hours of Monday morning, U.S. government officials seized First Republic Bank and then sold it to the \ncountry’s biggest bank, JPMorgan Chase. Their action appears, for now, to have quelled nearly two months of \nturmoil in the banking sector that followed the sudden collapse of Silicon Valley Bank and Signature Bank in early \nMarch.\nFor Jamie Dimon, JPMorgan’s chief executive, it was a reprise of his role in the 2008 financial crisis, when \nJPMorgan acquired Bear Stearns and Washington Mutual at the behest of federal regulators. But the acquisition \nhas also brought to the fore debates about whether some banks have become too big to fail partly because \nregulators have allowed or even encouraged them to acquire smaller financial institutions.\nJPMorgan is likely to make a lot of money from the acquisition, according to experts. JPMorgan will pay $10.6 \nbillion to acquire First Republic, and the government expects to cover a loss of about $13 billion on First Republic’s \nassets. JPMorgan said that it expected the deal to raise its profit this year by $500 million.\nContext: Normally a bank cannot acquire another bank if doing so would allow it to control more than 10 percent of \nthe nation’s bank deposits — a threshold JPMorgan had already reached before buying First Republic. But the law \nincludes an exception for the acquisition of a failing bank.\nAn end to the crisis? No other prominent lenders appear to have a similar set of urgent challenges: First Republic \nhad extensive real estate loans that lost value as interest rates rose and a customer base of wealthy depositors \nwho pulled their funds when the bank wobbled.\nRussia and Ukraine step up attacks\nRussia launched broad aerial assaults yesterday across Ukraine, and Ukraine reported that its pilots had carried out \nfour strikes in Russian-occupied territory on areas where enemy personnel were concentrated. Together, the \nattacks were a sign of intensifying fighting ahead of an anticipated Ukrainian counteroffensive.\nUkraine’s defense minister, Oleksii Reznikov, said that the country’s military was “reaching the finish line” in \npreparations to launch a counteroffensive. In response, Russian forces have moved into defensive positions in the \nsouth, according to Ukrainian and Western officials. Unusually muddy ground is one obstacle that the Ukrainian \nmilitary is finding difficult to overcome.\nYour Tuesday Briefing\nIn Pavlograd, in central Ukraine, dozens of buildings were damaged, and at least 34 people, including five children, \nwere wounded, local officials said. In Kyiv and elsewhere, explosions echoed across the predawn landscape as air \ndefenses shot down what the Ukrainian military said were 15 of 18 Russian cruise missiles.\nAnalysis: Britain’s defense intelligence agency said that Russia had “constructed some of the most extensive \nsystems of military defensive works seen anywhere in the world for many decades,” not only near the front line but \nalso “deep inside areas Russia currently controls.”\nToll: White House officials released new estimates that since December alone, the Russian military had sustained a \nstaggering 20,000 deaths in Ukraine.\nThe ‘godfather of A.I.’ leaves Google\nThe A.I. pioneer Geoffrey Hinton, who in 2012 helped create technology that became the foundation for today’s A.I. \nsystems, yesterday joined critics who have said that tech companies are racing toward danger with their aggressive \ncampaign to create products based on generative artificial intelligence, the technology that powers popular chat \nbots like ChatGPT.\nDr. Hinton said he had quit his job at Google, where he has worked for more than a decade and became one of the \nmost respected voices in the field, so he could freely speak out about the risks of A.I. A part of him, he said, now \nregrets his life’s work. “It is hard to see how you can prevent the bad actors from using it for bad things,” he said.\nThe technology industry is perhaps at its most important inflection point in decades. Industry leaders believe the \nnew A.I. systems could be as important as the introduction of the web browser in the early 1990s and could lead to \nbreakthroughs in areas like drug research and education.\nConcerns: Since OpenAI released a new version of ChatGPT in March, hundreds of technology leaders and \nresearchers have signed open letters warning of the risks of A.I. or calling for a six-month moratorium on the \ndevelopment of new systems because A.I. technologies pose “profound risks to society and humanity.”\nCan A.I. read minds? In a recent experiment, researchers used large language models to translate brain activity \ninto words.\nTHE LATEST NEWS\nAround the World\n• The coastal city of Port Sudan — Sudan’s biggest seaport — has been transformed into a hub for thousands \nof people displaced by the war between forces loyal to two powerful generals.\n• Britain’s monarchy faces a test in Scotland, where pro-independence sentiment has long simmered alongside \nambivalence about the royal family.\n• Iran executed a former senior official who had provided Britain with valuable intelligence on nuclear and \nmilitary programs.\n• French workers marched in cities across the country yesterday, as May Day demonstrations coincided with \nanger over President Emmanuel Macron’s pension changes.\n• The police in Thailand charged a woman with nine murders. They said they found her with a bottle of cyanide \nafter the sudden death of a traveling companion.\nOther Big Stories\n• Kevin McCarthy, the U.S. House speaker, offered to host Prime Minister Benjamin Netanyahu of Israel for \nmeetings in Congress — issuing an implicit challenge to President Biden.\n• Treasury Secretary Janet Yellen said the U.S. could be unable to pay its bills by June 1 if Congress did not \nraise the nation’s borrowing limit.\nYour Tuesday Briefing\n• President Biden met with President Ferdinand Marcos Jr. of the Philippines, sending a message to China that \nthe two nations intended to deepen their relationship.\nWhat Else Is Happening\n• Ancient Romans dropped their jewelry down the drain, too: Archaeologists have recovered a trove of ring \nstones from an 1,800-year-old bathhouse in England.\n• An early morning excavation to find a Nazi treasure in a tiny village in the Netherlands came up empty.\nA Morning Read\nMeet the South Korean chefs redefining the art of pastry, with boundary-blurring desserts that reflect their Korean \nbackground and French training.\n“We’re used to having Korean food, and we’re used to learning from Korean moms,” said Bomee Ki. “This is in our \nmind. Naturally this will come into our food. That makes our food and our place very special.”\nSPORTS NEWS FROM THE ATHLETIC\nPreparing for the 2023 Women’s World Cup: Top players talk through some of their best moments on the field. This \nis My Game in My Words.\nHow a pit stop almost turned into a Formula 1 disaster: The F.I.A. has explained the “dangerous situation” that led \nto Esteban Ocon’s near miss with a group of officials at the Azerbaijan Grand Prix.\nWhy attendance is booming: The average attendance per game across all four of English soccer’s divisions is \n17,826, the highest since 1951-52. Here’s why.\nARTS AND IDEAS \nThe first Monday in May\nCelebrities appeared in droves at New York City’s Metropolitan Museum last night for the Met Gala, fashion’s event \nof the year, with a guest list hand-selected by Anna Wintour, the editor of U.S. Vogue. Each year, the dress code \ntracks to the theme of the show — this time around, the career of the Chanel designer Karl Lagerfeld, who died in \n2019.\nAttendees last night included many of the frequent fliers (Kim Kardashian, Gigi Hadid, Serena Williams), as well as \nsome new names: the W.N.B.A. star and recent Russian detainee Brittney Griner, the musical artist Doja Cat and \nParis Hilton, who — perhaps surprisingly — was making her first appearance ever at the event.\nKim Kardashian arrived in pearls, and not much else. Rihanna, above, wore a dramatic bridal gown. Some guests \nunveiled life changes — Serena Williams is pregnant, and Florence Pugh has shaved her head. And Doja Cat paid \nhomage to Choupette, Lagerfeld’s beloved cat, in a silvery gown with a cat-eared hood, a fluffy white train and a \ncat-face prosthetic.\nSee a selection of the hottest looks in our red carpet slide show.\nPLAY, WATCH, EAT\nWhat to Cook\nYakisoba is a Japanese stir-fried noodle dish with a tangy-sweet sauce.\nWhat to Read\n“It Happened Online,” our new newsletter about the internet, looks at the fate of Twitter’s check marks.\nYour Tuesday Briefing\nWhat to Watch\nA new series tells the story of Miep Gies, the secretary who helped Anne Frank and others hide in Amsterdam \nduring World War II.\nNow Time to Play\nHere’s today’s Mini Crossword, and a clue: Resident of 123 Sesame Street (four letters).\nAnd here are today’s Wordle and the Spelling Bee.\nYou can find all our puzzles here.\nThat’s it for today’s briefing. See you tomorrow. — Natasha\nP.S. Living like a king is cheaper than you might expect. For about $200 a night, you can book the Prince’s Room at \nKing Charles’s residence in Transylvania.\n“The Daily” is on the fight over the U.S. debt ceiling.\nYou can reach Natasha and the team at briefing@nytimes.com.\nPHOTO: People walk past the First Republic bank building in downtown San Francisco Monday morning after the \nbank was taken over by JPMorgan Chase. (PHOTOGRAPH BY Jim Wilson/The New York Times FOR THE NEW \nYORK TIMES)\nLoad-Date: May 2, 2023"
    },
    {
        "file_name": "threatening_in_India_Apr2024",
        "header": "Skill gap in workforce, AI advancements make cyber attacks more",
        "media": "threatening in India",
        "time": "April 14, 2024",
        "section": "TECH & INTERNET",
        "length": "1454 words",
        "byline": "Annapurna Roy",
        "story_text": "Skill gap in workforce, AI advancements make cyber attacks more \nthreatening in India\nThe Economic Times\nApril 14, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1454 words\nByline: Annapurna Roy\nBody\nAI is replacing hands in stock dealing rooms, bank treasuries and assembly lines. Why should cyber security be any \ndifferent? AI is fast becoming a digital watchdog. However, it comes in as collaboration — not competition — to \nhuman intelligence as companies seek to secure the virtual world. So, unlike several other branches of technology, \ncyber security professionals aren’t facing job culls. \nRather, the demand for them is set to boom as India grapples with a rise in cyber attacks, with a 30% supply gap \ntelling on the industry. Meanwhile, companies are weaving in AI to sharpen cyber security efforts in an increasingly \ndigital world — and bridge the skills gap. “Considering the rapid pace of change in the cyber security industry, \nbusinesses must prepare their workforce for an AI+ security norm,” Pradeep Vasudevan, country head, security \nsoftware, IBM India, told ET. He added that it will be key for security analysts to be equipped with the skillsets \nrequired to utilise AI solutions effectively. “Industry suggests that one million [cyber security] professionals will be \nrequired by 2025,” said Krishna Vij, business head - IT staffing, TeamLease Digital. India’s cyber security workforce \nstood at around 0.3 million in 2023, up from 0.21 million in 2022, and 0.1 million in 2021, Vij said, with about 8,500 \ncyber security positions currently open. India’s 30 per cent gap is proportionally slightly higher than the global \naverage, she added. “While we’re looking at about 30 to 40 per cent growth in this role, this will only go up. It will \ngrow 40-50 per cent year-onyear,” Vij said, adding that expertise in threat intelligence, incident response, and \npenetration testing will be in high demand in 2024. The most sought-after cyber security skills in 2023 included \ncloud security, threat intelligence, incident response and management, application security, ethical hacking, security \noperations centre analysts, identity and access management and data security and encryption.Hot skillsThis year, \nbusinesses are looking for niche skills including AI/ML security and gen AI security, said Anand Tiwari, partner, risk \nadvisory, Deloitte India. Other in-demand areas include cloud security, IoT (internet of things) security, threat \nhunting, devsecops (development, security, and operations) and privacy.He added that companies’ cyber security \nspending has increased due to their digital transformation journeys, increased scrutiny by regulators and increase in \norganised cyber crime. Yet, a recent Data Security Council of India (DSCI) report indicates the country faces a \nshortage of about 7,90,000 cyber security professionals. Kunal Purohit, chief digital services officer, Tech Mahindra, \nsaid, “It is certain that demand for cyber security professionals is booming, and while automation is becoming more \nprevalent in all industries, there will always be a need for cyber security experts.”Bridging the skill gap requires \norganisations to continuously assess their needs, invest in training and development, and adjust their strategies to \nkeep up with the everchanging cyber security landscape, Purohit said. “In 2024, the surging demand for cyber \nsecurity experts is unprecedented, propelled by escalating and sophisticated cyber threats,” said Sundar \nBalasubramanian, managing director, India and SAARC, at cyber security firm Check Point Software Technologies. \n“Indian enterprises grapple with a critical shortage of cyber security experts, ranking second globally in this \nworkforce deficit, surging sevenfold in the past year,” he added, citing research. Even as burnout of skilled cyber \nsecurity professionals is being reported, critical sectors, including BFSI, healthcare, finance, and e-commerce face \nheightened vulnerability and an urgent requirement for adept professionals, Balasubramanian said. Industry \nSkill gap in workforce, AI advancements make cyber attacks more threatening in India\nreadinessExperts said that cyber security training in academia is not keeping pace with the evolving threat \nlandscape businesses face and that it takes substantial effort for a firm to convert a campus hire into a cyber \nsecurity professional.“Freshers do not have an easy entry into cyber security roles… They [companies] typically \nlook for minimum three years experience,” Vij said. To address the cyber security skills gap, companies are \nexpanding their search beyond domestic talent, tapping into diverse markets like Singapore, US, Switzerland, \nIsrael, etc., Vij added. “Recognising the dynamic nature of cyber threats, India is investing in skilling initiatives \nthrough partner - ships with educational institutions, industry certifications and internal training. The surge in cyber \nsecurity certification programs, with over 400 institutions involved, reflects a concerted effort to skill local talent and \nmeet the growing demand for qualified cyber security professionals.” While the shortage affects all sectors, \nknowledge-based industries such as IT, ITeS, BFSI, and pharma are feeling the sting, Tiwari said. Further, Global \nCapability Centres (GCCs) in the process of establishment will also feel the impact of the prevailing skills gap. As \nper a DSCI report, India’s cyber security market grew at a CAGR of over 30% during 2019-2023 to reach $ 6.06 \nbillion in 2023, Tiwari added. Meanwhile, cyber security firm Cyfirma reported that India is the most targeted country \nin terms of cyber attacks and that cyber attacks on government agencies went up by 460% over the past three \nyears while those on startups and small and medium enterprises (SMEs) increased by 508%. Especially now, AI \nhas transformed the cyber threat landscape — attacks that once required seasoned professionals have become ‘chi \nld’s play’, experts said, and the technology has made attacks more sophisticated and ferocious. Pawan Prabhat, \ncofounder and president at generative AI and data engineering solutions firm Shorthills AI, said, “AI is not just a \nbuzzword; it’s becoming a vital skill set in cyber security roles.” He added that today, AI is enabling targeted \nphishing with voice and video and increasingly intricate malware and that companies can strategically integrate the \ntechnology for effective defence. “We are starting to see gen AI help scale cyber crime — a top concern for \ndefenders who are already outnumbered and under pressure,” said Vasudevan. Cyber security professionals \nupskilling in AI/ML and gen AI may be a matter of their own long-term viability as well as a matter of insulation and \nfuture-readiness for companies, experts said. “Companies may need to make significant investments in upskilling \ntheir cyber security teams in AI and gen AI skills,” Tiwari said. He added that IT, ITeS and BFSI companies are \nmaking such investments. Need for AIAccording to Prabhat, SOC (security operations centre) a n a l y s t s w h o \nperform threat hunting and intelligence analysis should be trained in AI. Further, leveraging AI in ASI (attack surface \nintelligence) enhances cyber threat identification and enables predictive analysis based on historical patterns. AI-\ndriven log analysis across various security systems streamlines the identification processes by providing valuable \ninsights to security analysts, Prabhat said. For IBM’s Vasudevan, the full potential of AI in cyber security lies in the \ncombination of existing mature AI innovations and future gen AI applications, coupled with automation. “We have \nalready begun to see the adoption of large language models in the cyber security market, serving as a security \nassistant of sorts to security analysts through a chatbot format,” Vasudevan said. “CISOs must carefully evaluate \nhow gen AI innovations can help improve detection efficacy and introduce predictive capabilities to security \nsolutions, largely due to the size and variety of data these models are trained on, and their capacity for self-\nsupervised learning,” he added. Yet, many firms hesitate to incorporate AI in their cyber security efforts due to fears \naround data privacy and security, Vij pointed out. Mitigating the cyber security skills gap requires cooperation \nbetween government, industry and academia, greater awareness regarding cyber security career opportunities as \nwell as incentives for businesses so they can meet the costs of strong cyber security infrastructure, she said. \nMeanwhile, skilled professionals are attracting premium salaries. Vij said that while entry-level roles like IT auditor, \ninformation security analyst, network/IT security engineer/specialist, and security testing/penetration tester offer a \nbase pay of Rs 3-6 lakh per annum for under three years’ experience, senior and mid-level professionals, with over \n12 years of experience, have the potential to earn an annual salary of Rs 50-80 lakh. For Reprint Rights: \ntimescontent.com\nLoad-Date: April 14, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Hottest Job in Corporate America? The Executive in Charge of A.I.",
        "media": "The New York Times",
        "time": "February 8, 2024",
        "section": "TECHNOLOGY",
        "length": "984 words",
        "byline": "Yiwen Lu Yiwen Lu reports on technology for The Times.",
        "story_text": "Hottest Job in Corporate America? The Executive in Charge of A.I.\nThe New York Times \nJanuary 29, 2024 Monday 06:50 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 984 words\nByline: Yiwen Lu Yiwen Lu reports on technology for The Times.\nHighlight: Many feared that artificial intelligence would kill jobs. But hospitals, insurance companies and others are \ncreating roles to navigate and harness the disruptive technology.\nBody\nMany feared that artificial intelligence would kill jobs. But hospitals, insurance companies and others are creating \nroles to navigate and harness the disruptive technology.\nIn September, the Mayo Clinic in Arizona created a first-of-its-kind job at the hospital system: chief artificial \nintelligence officer.\nDoctors at the Arizona site, which has facilities in Phoenix and Scottsdale, had experimented with A.I. for years. But \nafter ChatGPT’s release in 2022 and an ensuing frenzy over the technology, the hospital decided it needed to work \nmore with A.I. and find someone to coordinate the efforts.\nSo executives appointed Dr. Bhavik Patel, a radiologist who specializes in A.I., to the new job. Dr. Patel has since \npiloted a new A.I. model that could help speed up the diagnosis of a rare heart disease by looking for hidden data in \nultrasounds.\n“We’re really trying to foster some of these data and A.I. capabilities throughout every department, every division, \nevery work group,” said Dr. Richard Gray, the chief executive of the Mayo Clinic in Arizona. The chief A.I. officer \nrole was hatched because “it helps to have a coordinating function with the depth of expertise.”\nMany people have long feared that A.I. would kill jobs. But a boom in the technology has instead spurred law firms, \nhospitals, insurance companies, government agencies and universities to create what has become the hottest new \nrole in corporate America and beyond: the senior executive in charge of A.I.\nThe Equifax credit bureau, the manufacturer Ashley Furniture and law firms such as Eversheds Sutherland have \nappointed A.I. executives over the past year. In December, The New York Times named an editorial director of A.I. \ninitiatives. And more than 400 federal departments and agencies looked for chief A.I. officers last year to comply \nwith an executive order by President Biden that created safeguards for the technology.\nIn total, 122 people with the title of chief or vice president of A.I. joined a forum last year on Glassdoor, the \ncompany reviews site, up from 19 in 2022, Glassdoor said.\nThe A.I. executive jobs are appearing because organizations want to harness the transformative technology, said \nRandy Bean, the founder of the consulting firm NewVantage Partners, who advises companies on data and A.I. \nleadership. At the same time, he added, “organizations want to say, ‘Yeah, we have a chief A.I. officer,’ because \nthat makes them look good.”\nHottest Job in Corporate America ? The Executive in Charge of A.I.\nOther executive jobs have been formed in response to major technological and financial changes. In the 1980s, \nadvances in computing power led to a boom in chief information officers and chief technology officers, who typically \noversee how technology is used within a company or develop it. After the 2008 financial crisis, chief data officers \nwere appointed to comply with new regulations and to manage how companies used data.\nWith A.I. executive roles, companies and organizations are looking for someone to help them navigate the \ntechnology’s risks and potential and how it might change the way people work.\nIn May, the health insurer Florida Blue promoted Svetlana Bender to the new job of vice president of A.I. and \nbehavioral science for just that purpose. One of her first A.I. projects was to pilot an internal chatbot that can help \nwrite computer code and analyze customer data.\nDr. Bender, who was previously Florida Blue’s director of technology solutions, said her team would train the \nchatbot on customer data and open it to all employees to use. This month, she hired a director of A.I. to help with \nthe work\n“We want to move as quickly as possible” on using the technology, while making sure to keep customers’ insurance \ndata safe, she said.\nAccenture, a consulting firm, added a chief A.I. officer in September as clients became increasingly interested in the \ntechnology. The company promoted Lan Guan, who worked on global data and A.I., to the role to advise customers \non how to incorporate A.I. into their businesses. Accenture is also building A.I. tools, including for the insurance \nindustry.\nThe new job “underscores our ambition in the market, and how optimistic we are about what we’re seeing as the \nhuge potential for our clients in A.I.,” Ms. Guan said.\nAt Western University in Ontario, Mark Daley, a computer science professor and chief information officer, took the \nnew position of chief A.I. officer in October. While he still teaches, he left the role of chief information officer.\nDr. Daley has since focused on establishing over 30 pilot A.I. projects, including working with the research and \nfinance team to automate auditing processes and collaborating with faculty in humanities to develop new courses.\n“We’re in a moment where the best approach to generative A.I. is actually exploration and experimentation,” he \nsaid.\nSome experts said the technology was changing so rapidly, it could soon outpace the roles. A Harvard Business \nReview article last year, co-written by NewVantage’s Mr. Bean, posited that chief A.I. and data officers were set up \nto fail because the jobs were “a high-pressure balancing act with a technology that offers huge risks and \nopportunities.”\nKarin Kimbrough, the chief economist at LinkedIn, said A.I. would also evolve from a newfangled technology to \nsomething baked into everyone’s job. “A.I. will be across many roles, and it will be so ingrained that the specific A.I. \njob title will start to go away,” she said.\nSome chief A.I. officers said their job had staying power. Dr. Patel of the Mayo Clinic in Arizona said a large part of \nhis new job was to communicate with other doctors and regulators like the Food and Drug Administration and to \nidentify how A.I. can make medical work more efficient.\n“Modern-day health care still has a lot of gaps,” he said. “This is where I think we can smartly use artificial \nintelligence to bridge that gap, or at least reduce that.”\nThis article appeared in print on page BU1, BU7.\nLoad-Date: February 8, 2024\nHottest Job in Corporate America ? The Executive in Charge of A.I."
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Jul2023",
        "header": "How Amazon Taught Alexa to Speak in an Irish Brogue",
        "media": "The New York Times - International Edition",
        "time": "July 10, 2023",
        "section": "TECHNOLOGY",
        "length": "1311 words",
        "byline": "Bernhard Warner",
        "story_text": "How Amazon Taught Alexa to Speak in an Irish Brogue\nThe New York Times - International Edition\nJuly 11, 2023 Tuesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1311 words\nByline: Bernhard Warner\nDateline: DUBLIN \nBody\nFor Alexa to speak like a Dubliner, Amazon researchers had to crack a problem that's vexed data scientists for \nyears: voice disentanglement.       \nLike Henry Higgins, the phonetician from George Bernard Shaw's play \"Pygmalion,\" Marius Cotescu and Georgi \nTinchev recently demonstrated how their student was trying to overcome pronunciation difficulties.       \nThe two data scientists, who work for Amazon in Europe, were teaching Alexa, the company's digital assistant. \nTheir task: to help Alexa master an Irish-accented English with the aid of artificial intelligence and recordings from \nnative speakers.       \nDuring the demonstration, Alexa spoke about a memorable night out. \"The party last night was great craic,\" Alexa \nsaid with a lilt, using the Irish word for fun. \"We got ice cream on the way home, and we were happy out.\"       \nMr. Tinchev shook his head. Alexa had dropped the \"r\" in \"party,\" making the word sound flat, like pah-tee. Too \nBritish, he concluded.       \nThe technologists are part of a team at Amazon working on a challenging area of data science known as voice \ndisentanglement. It's a tricky issue that has gained new relevance amid a wave of A.I. developments, with \nresearchers believing the speech and technology puzzle can help make A.I.-powered devices, bots and speech \nsynthesizers more conversational - that is, capable of pulling off a multitude of regional accents.       \nTackling voice disentanglement involves far more than grasping vocabulary and syntax. A speaker's pitch, timbre \nand accent often give words nuanced meaning and emotional weight. Linguists call this language feature \"prosody,\" \nsomething machines have had a hard time mastering.       \nOnly in recent years, thanks to advances in A.I., computer chips and other hardware, have researchers made \nstrides in cracking the voice disentanglement issue, transforming computer-generated speech into something more \npleasing to the ear.       \nSuch work may eventually converge with an explosion of \"generative A.I.,\" a technology that enables chatbots to \ngenerate their own responses, researchers said. Chatbots like ChatGPT and Bard may someday fully act on users' \nvoice commands and respond verbally. At the same time, voice assistants like Alexa and Apple's Siri will become \nmore conversational, potentially rekindling consumer interest in a tech segment that had seemingly stalled, analysts \nsaid.       \nGetting voice assistants such as Alexa, Siri and Google Assistant to speak multiple languages has been an \nexpensive and protracted process. Tech companies have hired voice actors to record hundreds of hours of speech, \nHow Amazon Taught Alexa to Speak in an Irish Brogue\nwhich helped create synthetic voices for digital assistants. Advanced A.I. systems known as \"text-to-speech \nmodels\" - because they convert text to natural-sounding synthetic speech - are just beginning to streamline this \nprocess.       \nThe technology \"is now able to create a human's voice and synthetic audio based on a text input, in different \nlanguages, accents and dialects,\" said Marion Laboure, a senior strategist at Deutsche Bank Research.       \nAmazon has been under pressure to catch up to rivals like Microsoft and Google in the A.I. race. In April, Andy \nJassy, Amazon's chief executive, told Wall Street analysts that the company planned to make Alexa \"even more \nproactive and conversational\" with the help of sophisticated generative A.I. And Rohit Prasad, Amazon's head \nscientist for Alexa, told CNBC in May that he saw the voice assistant as a voice-enabled \"instantly available, \npersonal A.I.\"       \nIrish Alexa made its commercial debut in November, after nine months of training in comprehending an Irish accent \nand then speaking it.       \n\"Accent is different from language,\" Mr. Prasad said in an interview. A.I. technologies must learn to extricate the \naccent from other parts of speech, such as tone and frequency, before they can replicate the peculiarities of local \ndialects - for instance, maybe the \"a\" is flatter and \"t's\" are pronounced more forcibly.       \nThese systems must figure out these patterns \"so you can synthesize a whole new accent,\" he said. \"That's hard.\"       \nHarder still was trying to get the technology to learn a new accent largely on its own, from a different-sounding \nspeech model. That's what Mr. Cotescu's team tried in building Irish Alexa. They relied heavily on an existing \nspeech model of primarily British-English accents - with a far smaller range of American, Canadian and Australian \naccents - to train it to speak Irish English.       \nThe team contended with various linguistic challenges of Irish English. The Irish tend to drop the \"h\" in \"th,\" for \nexample, pronouncing the letters as a hard \"t\" or a \"d,\" making \"bath\" sound like \"bat,\" or even \"bad.\" Irish English is \nalso rhotic, meaning the \"r\" is overpronounced. That means the \"r\" in \"party\" will be more distinct than what you \nmight hear out of a Londoner's mouth. Alexa had to learn these speech features and master them.       \nIrish English, said Mr. Cotescu, who is Romanian and was the lead researcher on the Irish Alexa team, \"is a hard \none.\"       \nThe speech models that power Alexa's verbal skills have been growing more advanced in recent years. In 2020, \nAmazon researchers taught Alexa to speak fluent Spanish from an English language-speaking model.       \nMr. Cotescu and the team saw accents as the next frontier of Alexa's speech capabilities. They designed Irish \nAlexa to rely more on A.I. than on actors to build up its speech model. As a result, Irish Alexa was trained on a \nrelatively small corpus - about 24 hours of recordings by voice actors who recited 2,000 utterances in Irish-accented \nEnglish.       \nAt the outset, when Amazon's researchers fed the Irish recordings to the still-learning Irish Alexa, some weird things \nhappened.       \nLetters and syllables occasionally dropped out of the response. \"S's\" sometimes stuck together. A word or two, \nsometimes crucial ones, were inexplicably mumbled and incomprehensible. At least in one case, Alexa's female \nvoice dropped a few octaves, sounding more masculine. Worse, the masculine voice sounded distinctly British, the \nkind of goof that might raise eyebrows in some Irish homes.       \n\"They are big black boxes,\" Mr. Tinchev, a Bulgarian national who is Amazon's lead scientist on the project, said of \nthe speech models. \"You have to have a lot of experimentation to tune them.\"       \nHow Amazon Taught Alexa to Speak in an Irish Brogue\nThat's what the technologists did to correct Alexa's \"party\" gaffe. They disentangled the speech, word by word, \nphoneme (the smallest audible sliver of a word) by phoneme to pinpoint where Alexa was slipping and fine-tune it. \nThen they fed Irish Alexa's speech model more recorded voice data to correct the mispronunciation.       \nThe result: the \"r\" in \"party\" returned. But then the \"p\" disappeared.       \nSo the data scientists went through the same process again. They eventually zeroed in on the phoneme that \ncontained the missing \"p.\" Then they fine-tuned the model further so the \"p\" sound returned and the \"r\" didn't \ndisappear. Alexa was finally learning to speak like a Dubliner.       \nTwo Irish linguists - Elaine Vaughan, who teaches at the University of Limerick, and Kate Tallon, a Ph.D student \nwho works in the Phonetics and Speech Laboratory at Trinity College Dublin - have since given Irish Alexa's accent \nhigh marks. The way Irish Alexa emphasized \"r's\" and softened \"t's\" stuck out, they said, and Amazon got the \naccent as a whole right.       \n\"It sounds authentic to me,\" Ms. Tallon said.       \nAmazon's researchers said they were gratified by the largely positive feedback. That their speech models \ndisentangled the Irish accent so quickly gave them hope they could replicate accents elsewhere.       \n\"We also plan to extend our methodology to accents of language other than English,\" they wrote in a January \nresearch paper about the Irish Alexa project. \nLoad-Date: July 10, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai: Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, with revenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "New Head of N.S.A. Steps In, With Protecting Elections a Priority",
        "media": "The New York Times",
        "time": "February 3, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 15",
        "length": "739 words",
        "byline": "By Julian E. Barnes",
        "story_text": "New Head of N.S.A. Steps In, With Protecting Elections a Priority\nThe New York Times\nFebruary 3, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 15\nLength: 739 words\nByline: By Julian E. Barnes\nBody\nGeneral Timothy D. Haugh is taking over the spy agency and U.S. Cyber Command as the organizations look to \ndeter Russia and other countries from expanding influence activities.\nAir Force Gen. Timothy D. Haugh took the helm of the National Security Agency and the Cyber Command on \nFriday, as the intelligence agencies and military brace for renewed efforts by foreign adversaries to influence the \nAmerican elections this year. \n  General Haugh replaces Army Gen. Paul M. Nakasone, who took over in 2018 and helped focus the N.S.A. and \nCyber Command on countering foreign efforts to interfere in American elections. The N.S.A. collects \ncommunications intelligence, like phone calls and computer traffic, and Cyber Command conducts operations on \ncomputer networks.\n  Securing the 2024 presidential election against outside interference and looking for operations that take \nadvantage of new artificial intelligence strategies will be General Haugh's first task.\n  Intelligence agencies say they do not know whether China will remain on the sidelines this year or increase its \nactivity. But officials have said Russia is likely to expand its efforts over the 2022 midterm elections. For President \nVladimir V. Putin of Russia, this year's elections have huge stakes, with Democrats supporting continued funding \nfor Ukraine in its war against Russia and Republicans growing more skeptical of such aid.\n  Soon after he took over in 2018, General Nakasone created what he called the Russia Small Group, a team of \nexperts from the N.S.A. and Cyber Command, to discover and deter attempts by Moscow to interfere in elections.\n  At the time, General Haugh was leading Cyber Command's National Mission Force, which conducts offensive and \ndefensive operations on computer networks. General Nakasone picked General Haugh to help lead the group along \nwith the N.S.A. official Anne Neuberger, who is now the deputy national security adviser for cyber and emerging \ntechnology.\n  That group identified the Russians who were conducting influence operations in the 2018 midterm elections. Cyber \nCommand warned some of them to deter further action and later took down servers run by a Russian troll farm that \nsupported Russian intelligence.\n  After his time at the Cyber National Mission Force, General Haugh held posts at Joint Base San Antonio-Lackland \nin Texas before returning to Fort Meade, Md., in 2022 to become the deputy head of Cyber Command.\n  In a discussion with reporters this week, General Nakasone said that when he arrived, the N.S.A. and Cyber \nCommand began to step up efforts to understand who was trying to influence elections -- and then to stop them.\nNew Head of N.S.A. Steps In, With Protecting Elections a Priority\n  ''We were going to act and impose costs on any adversary that was going to attempt to influence or interfere in our \nelections,'' General Nakasone said.\n  Because the N.S.A. now works more closely with technology and cybersecurity firms, it is often possible to \nattribute intrusions to an adversarial country within seven days, General Nakasone said.\n  ''There's not a lot of discussion anymore in cyberspace about how difficult it is to do attribution,'' he said. ''We have \ngotten much more sophisticated, in terms of our ability to work with a series of partners to determine that.''\n  But more countries are trying to influence U.S. elections, including China and Iran.\n  During the 2022 midterm elections, General Nakasone said, Chinese operators stepped up efforts to influence \nspecific races. While their interest in this year's vote is not clear, China and technologies related to artificial \nintelligence present a long-term challenge to the N.S.A. and Cyber Command.\n  General Nakasone said China posed ''the generational challenge of our time, and I think that we are just at the \nbeginning piece of truly being able to understand how much we're going to have to change.''\n  How Cyber Command conducts operations and the N.S.A. gathers intelligence differs month to month as new \ntechnologies come into widespread use and new vulnerabilities are found.\n  Already, China has experimented with artificial intelligence in influence operations, and intelligence agencies \nexpect countries to try to use new technology to make their campaigns more believable.\n  General Nakasone said that the smartphone has been the ''most disruptive technology'' of his lifetime but that \ngenerative A.I. could have as deep an impact.\n  ''Maintaining our nation's edge in this technology is critical for us,'' he said.\nhttps://www.nytimes.com/2024/02/02/us/politics/nsa-haugh-director-elections-russia-china.html\nGraphic\n \nPHOTO: Air Force Gen. Timothy D. Haugh, above, is replacing Army Gen. Paul M. Nakasone atop the National \nSecurity Agency. (PHOTOGRAPH BY HAIYUN JIANG FOR THE NEW YORK TIMES) This article appeared in print \non page A15.               \nLoad-Date: February 3, 2024"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "Prompt in progress: GenAI text-to-code tools boost productivity",
        "media": "The Economic Times",
        "time": "April 7, 2024",
        "section": "TECH & INTERNET",
        "length": "1472 words",
        "byline": "Himanshi Lohchab and Beena Parmar",
        "story_text": "Prompt in progress: GenAI text-to-code tools boost productivity\nThe Economic Times\nApril 7, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1472 words\nByline: Himanshi Lohchab and Beena Parmar\nBody\nSoftware developers across organisations are taking to generative artificial intelligence (AI) text-to-code tools \nsuch as IBM Codenet, Microsoft’s GitHub CoPilot, Amazon’s Code Whisperer as well as StarCoder by Service Now \nand Hugging Face etc, to enhance productivity. Some of these tools claim to increase efficiency by up to 50%. \nThese Gen AI models can generate code from simple text prompts 55% faster and can even check code quality \nand reviews in almost every computer language,including C++, Java, Go, Python, COBOL, Pascal and Fortran. \nSmall wonder then that they are sparking high levels of curiosity.Growing interestAs per Google Trends, searches \nfor GitHub Copilot have increased by 10 times in the last year. Globally, it crossed over 1.3 million paid subscribers \nfrom 50,000 organisations, GitHub said, with strong presence in Indian IT majors like Tata Consultancy Services \n(TCS), Infosys and HCLTech. Service Now said its text-to-code model has boosted developer productivity by 52%. \n“Generative AI within the Now Platform will convert the text into high quality code suggestions, and in some cases, \ncomplete code, which is shared in line to review, edit and implement,” said Sumeet Mathur, senior vice-president \nand MD, ServiceNow India Technology and Business Center. \nGitHub’s Copilot, developed using OpenAI’s Codex large language model (LLM) based on GPT version 4, is \navailable via subscription, priced at $10 per month for individuals and $19 for businesses. The world’s largest \nsoftware developer community platform, GitHub, added 3.5 million new developers from India in 2023, bringing its \ntot a l I nd i a n u s er b a s e to 13.2 million. It expects India’s developer population to surpass the US by 2027. \n“GitHub Copilot has revolutionised developers’ workflows worldwide, and our research shows that Copilot is helping \ndevelopers code up to 55% faster,” Mario Rodriguez, vice-president, product management at GitHub, told ET. \n“Now, in files where Copilot is enabled, up to 60% of the code is being written by Copilot in popular languages like \nJava. In the next five years, we expect this to grow up to 80%,” he said.Also read | GCC, GenAI to help India’s tech \nsector grow to $254 billion in FY24-25: DeloitteHe added that the benefits extend beyond speed and efficiency by \nconserving mental energy and limiting frustration of manual repetitive tasks. India even has its first AI software \nengineer called Devika, a virtual assistant that can understand human instructions and genreate software code and \neven do bug fixing. It is an open-source project created to rival Devin launched by US’s Cognition Labs. Adoption \npicking up paceWhile the promise of productivity increase is great, their deployment by major IT companies is at a \nsmall and experimental stage. Companies are also cautious to  ensure the correctness of the code and filter out \nmalicious codes. Although gen AI tools are contributing to enhanced productivity and exciting ways of \nexperimenting with coding, Indian enterprises are still at the starting curve of a scaled adoption, sector experts said. \nDevelopers lean more towards code completion through integrated development environment, they said. “In \nenterprises, text-to-code is emerging as an effective tool for upskilling, getting started on new programming \nlanguages or troubleshooting an issue,” said Manjunath Bhat, VP Analyst at Gartner. “AI Code assistants such as \nGitHub Copilot support a text to code interface as an IDE plugin so developers don’t have to context switch \nbetween their programming environment and a separate web portal.” Gartner estimates that roughly 65-75% of \ndevelopers within IT organisations are using this. “It’s like the good old ‘IntelliSense’ but now, you can have a \nconversation with the tool and amplify its benefits,” Bhat said. Prashanth Kaddi, Partner, consulting, Deloitte India \nPrompt in progress: GenAI text-to-code tools boost productivity\nsaid, “For concerns such as IP protection and other security practices, some clients require disclosures on use of AI \nin technical artefacts.” India’s largest software exporter TCS uses multiple products for code generation, including \nGitHub copilot, AWS’s Code Whisperer and Google’s Duet AI, apart from opensource models like CodeLlama and \nStarCoder. “The text-to-code Gen AI models can be put to use for multiple objectives, broadly classified as \nproductivity,  velocity and quality,” said Ashok Krish, head, AI Coud, advisory and consulting, and Satish Byravan, \nhead enterprise-AI Practice at TCS. Mohammed Rafee Tarafdar, CTO, Infosys, said, “The future of textto-code \ngeneration with AI lies in using both generalised and specialised code assistants. At Infosys, we are using both \nassistants that we have developed using fine-tuning approach for areas like modernisation, migration, reporting and \nrefactoring. The text-to-code generators are very useful incoding, testing, report generation, and documentation \ntasks.” US-based AI model training platform Shorthills AI said it has fine-tuned LLMs to write code, documentation \nand test-cases for its data engineering, back-end/frontend programmers and quality assurance teams, which \ntranslated into improving developer efficiency by 50-60%. “We also plan to offer these solutions and models to our \nclients as a service,” the company said.India is the second largest user base of ChatGPT (at ~7%) outside of the \nUS. Naturally, computer programmers largely depend on the free-to-use ChatGPT tool to generate codes. \n“ChatGPT is the most commonly used tool, because of the reach, and easy and free accessibility,” said Paramdeep \nSingh, co-founder of Shorthills AI. “More than 80% programmers are using ChatGPT and other text-to-code \nplatforms to complete their work more efficiently.” The most common use case for programmers is searching for \nsolutions. “This is apparent from the fact that Stack Overflow, which is one of the most searched sites for coding, \nhas lost 30-50% of its traffic over the past year,” he said. Rodriguez, however, said that ChatGPT is a great \ngeneral-purpose AI-assistant that is not optimised for code and cannot provide contextualised answers for a project \nwithout sufficient information. Downsides and cautionUsing text-to-code AI tools is not as simple as generating text, \nimages or videos. If not prompted appropriately, they can generate erroneous codes, which result in duplication of \nwork or loss of productivity. From a productivity standpoint, TCS said that while there are gains and enhanced \nexperience (flow) for the developer, there is a need for the developer to validate correctness of the generated code. \nVijay Guntur, president, engineering and R&D services, HCLTech, said, “The quality of codegenerated by LLMs \nheavily depends on the quality and relevance of the data they are trained on. While LLMs produce code, there need \nto be checks and balances to ensure that the code produced is contextual, efficient and bug-free, with limited or no \nvulnerabilities,” Guntur said. Further, there are long-term challenges in the maintainability of the generated codes. \nThis is an area TCS is closely tracking and investing in as well, Krish and Byravan said. “The single big downside of \nsuch tools is ensuring that it does not introduce any legal liabilities or security vulnerabilities. This has been the \nmost important concern which is forcing the industry to be sure-footed in this journey. To that end, the industry, \nenterprises and practitioners are painstakingly formulating the guardrails to mitigate any such risks. At TCS, we \nhave built extensions to these code generators that help address some of the most common security issues,” they \nadded. “Developers, of course, need to review code generated by Copilot,” GitHub’s Rodriguez said. However, \nmaking it ubiquitous throughout the development lifecycle can significantly enhance the experience. Shorthills’s \nSingh feels the efficiency also depends on the complexity of the task and the experience of the programmer. “For \nrelatively simpler tasks [that the LLM has previously seen], there is a higher gain in efficiency. Senior developers \nare able to better leverage the text-to-code LLMs.” It is also important that opensource code generation models do \nnot become ammunition in the hands of malicious agents such as cyberattackers. Mathur said that the Starcoder \nmodel is available with a licence that includes use case restrictions that apply to modifications of the model, and \napplications using the model — for example, to restrict the models from being used to generate or distribute \nmalicious code to harm electronic systems. Guntur said it’s crucial to filter out malicious content from training data \nto prevent the model from acquiring such capabilities and that the opensource community plays a pivotal role in \nadvocating for responsible LLM use and highlighting potential misuse. For Reprint Rights: timescontent.com\nLoad-Date: April 7, 2024"
    },
    {
        "file_name": "New_York_Observer_Jan2023",
        "header": "The Scary Part About AI Is That a Lot of Writers Like It",
        "media": "New York Observer",
        "time": "January 24, 2023",
        "section": "",
        "length": "1580 words",
        "byline": "Ann Kjellberg",
        "story_text": "The Scary Part About AI Is That a Lot of Writers Like It\nNew York Observer\nJanuary 23, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 1580 words\nByline: Ann Kjellberg\nBody\n \nThis is the second of a two-part story from Book Post; read the first post here. \nAmidst denials that a computer could ever replace a writer in the creation of actual literary art, several interviews \nwith working writers already using artificial intelligence were tentatively rosy. Jay Caspian Kang, writing in The New \nYorker with some prior knowledge of chatbots and some expert advice, was not able to arrive at a satisfactory \nliterary product in his fictional forays with ChatGPT, but Kevin Roose on the podcast Hard Fork and education \nwriter John Warner were able to improve results substantially by refining their inputs. Lincoln Michel interviewed \nnovelist Chandler Klang Smith, who has been using a GPT-3-based program called Sudowrite to work on her \nnovels for a year or so. She memorably described the experience as \"like a robot has a dream about your work in \nprogress and you get to decide if anything from that dream reflects what you're trying to do.\" She said AI's efforts to \nmove work forward can \"unlock ideas that seem like they were already buried somewhere ... in the text.\"  Chandler \nKlang Smith found AI unhelpful in dealing with \"macro stuff like plot and structure,\" but over at The Verge, self-\npublished \"cozy mystery\" writer Jennifer Lepp, who had been using Sudowrite and just began experimenting with \nChatGPT, told Josh Dzieza that she was astonished that she could feed the chatbot a premise and some \nparticulars and it could generate an effective story in the genre. \nSelf-published genre writers are often writing for readers who consume hundreds of novels a year and are under \npressure to produce at scale (see our post on self-publishing and romance). Jennifer Lepp said many writers she \nknows are wrestling with the implications of drawing on ChatGPT's capabilities to speed the process. For these \nreaders, does it matter what the balance is between human and machine participation?\nRegardless of these more cheerful forays, several endemic dangers in generative AI present themselves. Two are \nneatly summarized on ChatGPT's site itself: the bot \"may occasionally generate incorrect information\" and \"may \noccasionally produce harmful content and biased instructions.\" ChatGPT is a language model: all it does is predict \nlanguage based on patterns it identifies in the very large pool it scoops out of the internet, and it can reproduce all \nthe mistakes and ugliness it can find there, and add some more of its own. (Recall the 2020 scandal when Google \nfired AI researcher Timnet Gebru whose research identified, among other limitations of large-language models, the \nreproduction of prejudice.) Draft EU legislation creates \"risk categories\" that may channel new AI systems toward \n\"low-cost\" endeavors like online fooling around before taking up \"high-cost\" activities like, say, surgery. Yet, as AI \nresearcher Chandra Bhagavatula told TechCrunch, \"AI systems are already making decisions loaded with moral \nand ethical implications.\"\nGenerative AI can be led to trot out racist tropes and sexualize images. AI recruitment tools can encode hiring \nbias (the Biden administration last fall produced a blueprint for an \"AI Bill of Rights\" protecting consumers from \ndiscriminatory and predatory algorithms). GPT-3 seems to have introduced \"guardrails\" limiting offensive results, \nbut these are apparently easy to subvert, and also generate for its masters the sorts of moderation issues plaguing \nThe Scary Part About AI Is That a Lot of Writers Like It\nall content-agnostic platforms. Generative AI can also of course be deployed for nefarious purposes-\ncybercrime, deep fakes, non-consensual porn. ChatGPT asks users to commit to not using its result for politics.\nAnother underlying challenge to large-language, generative AI systems like GPT-3 is intellectual property. \nEverything ChatGPT does draws on work previously done by someone, and future generative models will \nconstantly be sucking in new material to \"train\" them. Scholars predict that regulation and copyright prosecution will \nhave to strike some balance of recognizing when AI models directly usurp and imitate specific artists and when the \nscavenge is more plural and covered by \"fair use,\" though some lawyers are arguing that all material drawn into \nsuch models should be licensed and creators compensated. Stability AI recently indicated that it would allow artists \nto opt out of the data set used to train the image generator Stable Diffusion; Getty Images banned AI content \nbecause of the legal risk; the online gallery DeviantArt created a \"metadata tag\" for images to warn off the AI \ntrawler. It does start to feel like another phase in the digital bloodletting of renumeration from those who do the \nmental work that makes up our digital universe. (Relatedly, record labels have recently demanded a royalty \nhike from TikTok for the music that makes their videos so infectious.)\nWielding tools with such powers and promise, especially in the face of our littered record when it comes to \ngovernance both within the tech industry and without by regulation, has writers and those who work with language \nand the arts at once giddy and nervous. An argument about whether ChatGPT and other large-language tools can \nproduce literary art (for: Stephen Marche, against: Ian Bogost, Walter Kirn) seems to hinge on whether you see the \neditorial hand of the human giving the machine its prompts and refining its results as salient. Amit Gupta, one of the \nfounders of the program used by Chandler Klang Smith, told Stephen Marche, in the article that sparked Chandler \nKlang Smith's interest, \"the writer's job becomes as an editor almost. Your role starts to become deciding what's \ngood and executing on your taste, not as much the low-level work of pumping out word by word by word.\" Marche \ncompares AI to photography and says \"with hindsight, it's clear that machines didn't replace art; they just expanded \nit.\"\nIn presenting at a conference last fall Google's version of ChatGPT, which the much-huger corporation had not yet \nreleased, like the other large firms in the AI arms race, because of the models' many weaknesses, particularly-for \nGoogle-its brand-unfriendly tendency to produce inaccurate results, researcher Douglas Eck emphasized that their \nmodel, with the friendly name  Wordcraft Writers Workshop, had been designed to be interactive: \"Technology \nshould serve our need to have agency and creative control over what we do.\" Reporter Ben Dickson commented, \n\"without human control and oversight, AI systems like generative models will underperform because they don't have \nthe same grasp of fundamental concepts as we humans do.\"\nA lot of the disorientation around ChatGPT was visible in an incoherent interview with the widely published Stephen \nMarche on the podcast Intelligence Squared, in which he both claimed that ChatGPT could produce a poem \nindistinguishable from Coleridge and could write an essay he could publish in the Atlantic and that there is no way \nit could \"replace human writing,\" that computers will never be able to make something that \"will go viral,\" even \nthough virality is, finally, a robotic phenomenon. He echoed Amit Gupta saying that the usefulness of chatbots will \nbe in creating \"first drafts,\" which can be completely wrong, that we make human by correcting and revising them. \nIn evaluating AI-assisted student work \"you will be looking much more at the content than the clarity of expression,\" \neven though the bot \"doesn't produce work that you can use out of the box\"; the human art is in the refinement. If a \nhuman is checking the facts and polishing the finish, what is the bot contributing exactly?\nI can see the argument for using technological tools, but this idea that \"pumping out word by word by word,\" or \nassembling ideas into a form and sequence, is writing's \"low level work\" is unintelligible to me. The danger of \nChatGPT and its siblings is that it is nearly indistinguishable from the human product and can easily, as Timnet \nGebru and her colleagues discerned, generate, as the tools become more sophisticated, \"illusions of meaning\" that \nveil the fact that a language model does not actually understand or know anything, it is just borrowing text and \nmimicking patterns.  Detecting the conscious presence and purpose in the appliqué authorial method that Gupta \nand Marche describe sounds like a possibly increasingly elusive undertaking. Casey Newton and Kevin \nRoose noted with unease on their podcast that a large-language model called Cicero had learned how to beat \npeople at the game Diplomacy-i. e., persuade human players in a negotiation.\nThe Scary Part About AI Is That a Lot of Writers Like It\nI can almost imagine a world in which a machine composes something that delights as much as Mozart or engages \nthe mind with the complexity of Shakespeare. I suppose I should not close myself to the possibility of these now \nunimagined experiences. But it is hard for me to think my way around our historic association of these forms with \nhuman intention. If a student's essay is not the record of a process of developed thought, do we need to find \nanother way of recording developed thought? Or is the idea to delegate developed thought entirely? I can't quite \nimagine my way into a world in which intellectual aspiration is no longer recognizable as the grist of the things that \nwe make and admire, the labor of surmounting the pressure of the unknown, the effort to improve a partial or \ndamaged world, because anything can be made without trying, by retrieving and stitching together what has been \nmade before. But perhaps I just don't know what I'm missing.\nLoad-Date: January 24, 2023"
    },
    {
        "file_name": "Look_into_these_top_5_industries_May2023",
        "header": "Do you want a high-paying freelance gig?",
        "media": "Look into these top 5 industries",
        "time": "May 7, 2023",
        "section": "MAIN; A; Pg. 1",
        "length": "738 words",
        "byline": "Stephanie Vozza Fast Company",
        "story_text": "Do you want a high-paying freelance gig?\nLook into these top 5 industries\nThe Baltimore Sun\nMay 7, 2023 Sunday\nAdvanceBulldog Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 1\nLength: 738 words\nByline: Stephanie Vozza Fast Company\nHighlight: Rawpixelimages/Dreamstime\nBody\nBetween the Great Resignation and the waves of tech layoffs, more people are interested in freelance work. \nFreelancing hit an all-time high in 2022, with 39% of professionals taking on some form of contract work, according \nto a survey from Upwork. The report finds that freelancers contributed $1.35 trillion to the U.S. economy in 2022, up \n$50 billion from the previous year.\n\"In 2022, the freelancing industry saw a significant surge in the number of jobs and projects for technology-related \nskills, especially those for highly skilled, niche categories such as programming, coding, web development and \nsoftware development,\" says Matt Barrie, CEO of Freelancer.com. \"There are several freelance jobs where people \nearn six figures a year plus.\"\nWith an opportunity to create a steady and solid income, you may be considering joining the trend by taking on \nsome freelance \ngigs. A Freelancer.com's Freelancing in 2022 report named the top categories.\n1. Design\nAccording to Freelancer projects data, the highest-paying jobs per year on the platform are design jobs, particularly \nfor UX design, website design, Photoshop and Illustrator. Freelance tech designers can make as much as $21,964 \na month and $263,571 per year. For example, one freelancer on the Freelance.com platform nabbed a $41,000 \ntwo-month gig to help design an eCommerce SaaS platform.\n2. Game development\nThe second highest-paying type of freelance work is game development, which includes skills in game design and \nUnity 3D. According to the survey, the most popular type of game design job is Android Game Development. This \ntype of work can pay up to $21,541 a month and $258,501 per year. One freelancer, for example, earned more than \n$85,000 in a nine-month period with two game development projects.\n3. Coding\nComing in third is coding, which pays as much as $18,259 per month or $219,108 per year at the high end of the \nplatform. Jobs include work with Java, HTML, CSS, PHP and backend development. One experienced Tailwind \nDo you want a high-paying freelance gig? Look into these top 5 industries\nCSS developer was paid more than $20,000 per month to create systems for a cloud-based holiday home rental \ncompany.\n4. Mobile app development\nMobile app development is the fourth highest-paying category, according to the survey. This work requires \nfreelancers to have iOS and Android app development skills, paying as much as $12,100 per month or $145,200 \nper year when looking at the higher-paying jobs on the platform.\n5. Website development\nFinally, website development rounds out the list as the fifth highest-paying job category. It's also the most popular \njob type on the Freelancer.com platform, with gigs for people who are proficient in WordPress, PHP, MySQL and \nHTML. Freelancers can earn up to $11,826 per month or $141,923 per year.\nBarrie says the surge in tech and IT jobs on Freelancer.com is expected to remain through 2023 as companies \ncontinue to lay off staff and as new generative AI tools are introduced, creating more jobs in AI and machine \nlearning.\nTrending high-paying jobs\nIn 2022, Freelancer.com saw many new trending technologies or topics featured in the list for some of the highest-\npaying jobs per project. The top five include:\nDrone photography with an average project rate of $5,325.\nSurveyMonkey with an average project rate of $4,569.\nData engineer with an average project rate of $3,715.\nVirtual reality with an average project rate of $3,267.\nRoblox with an average project rate of $3,142.\n\"Drone photography was certainly a surprise, and it's new in terms of the highest-paying trending jobs at the \nmoment,\" Barrie says. \"There's also a big boom in virtual reality due to the metaverse.\"\nFreelance job trends are due to three things, Barrie says. \n\"First, with all the layoffs happening in technology, there's a lot of people who are in between jobs and are looking \nfor work online,\" he says. \"Second, with inflation crimping budgets, small businesses can't afford to hire full time, so \nthey hire on-demand. And third is that in tough times, we see a lot of startup businesses form because people are in \nbetween jobs, and they have a go at starting a company.\"\nIf you're thinking of freelancing, Barrie says it's one of the best times in history due to new AI tools. \n\"Just about any skill you can possibly think of you can now get AI to help super skill you up,\" he says. \"It's making \neveryone sort of a jack of all trades at a fairly competent level. As a freelancer, you've got a lot of work opportunity \nahead of you.\"\nLoad-Date: May 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Talking to Google About A.I. for iPhone",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "810 words",
        "byline": "By Tripp Mickle, Nico Grant and Brian X. Chen",
        "story_text": "Apple Talking to Google About A.I. for iPhone\nThe New York Times\nMarch 20, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 810 words\nByline: By Tripp Mickle, Nico Grant and Brian X. Chen\nBody\nA partnership would extend the long relationship between the companies that has helped deliver everything from \nmaps to search on Apple's devices.\nApple is in discussions with Google about using the search giant's generative artificial intelligence model called \nGemini for its next iPhone, as the company races to embrace a technology that has upended the tech industry. \n  The talks are preliminary and the exact scope of a potential deal hasn't been defined, three people with knowledge \nof the discussions said. Apple has also held discussions with other A.I. companies, one of these people said, as it \nlooks to tap into the power of a large language model capable of analyzing vast amounts of data and generating \ntext on its own.\n  Tim Cook, Apple's chief executive, has promised investors that the company will introduce new generative A.I. \ncapabilities this year. The company's smartphone rivals, Samsung and Google, have already added Gemini to their \nnewest devices to edit videos and summarize audio recordings.\n  Apple and Google declined to comment. Bloomberg reported earlier on their talks.\n  An Apple-Google deal on generative A.I. would extend one of technology's most longstanding partnerships. Since \nApple introduced the iPhone in 2007, Google has been a critical contributor to the device's success. It initially \nprovided Google Maps for navigation and the default search engine on the iPhone's Safari browser, now a lucrative \nagreement for which Google pays Apple more than $18 billion a year. \n  Google's discussions to provide generative A.I. capabilities for the iPhone would be the latest example of its filling \na gap in Apple's products. Apple's effort to develop its own large language model, the technology behind chatbots \nlike ChatGPT and Gemini, has been running behind, two people familiar with its development said.\n  Apple's delay in releasing an A.I. product has been costly. After a decade-long run as the world's most valuable \npublic company, it was dethroned this year by Microsoft, which has aggressively pursued A.I. The technology has \nbeen heralded for its potential to disrupt businesses and create trillions of dollars in economic value.\n  Despite its delays, Apple has the potential to be a big player in A.I. The company has more than two billion \ndevices actively in use, making it an attractive partner for Google and others. Its reputation for protecting customers' \nprivate information could also be helpful in a future where A.I. services help manage people's calendars or health \ndata.\nApple Talking to Google About A.I. for iPhone\n  A deal could bring the Gemini model to iPhones around the world, giving Google access to a massive user base \nand making generative A.I. even more mainstream. Virtually overnight, Google could have more consumers using \nits A.I. than its chief rival, OpenAI, which makes ChatGPT -- making a pact with Apple a tantalizing prospect.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  Apple's selecting Google as an A.I. supplier would be a crucial vote of confidence in the search giant after a \nnumber of setbacks to its A.I. ambitions. The company's first A.I. chatbot, Bard, debuted to middling reviews last \nMarch and struggled to attract as many users as ChatGPT.\n  In February, Google debuted a new chatbot, Gemini. The chatbot ran into problems last month when users found \nthat its image generator produced illustrations of historical figures that were not racially accurate and refused in \nmost instances to generate images of white people, leading to accusations of bias. Google disabled the ability to \ncreate images of people and vowed to fix the problem.\n  In a note on Tuesday, a Bernstein Research analyst, Toni Sacconaghi, called an Apple-Google deal a ''win-win,'' \ngiving Apple generative A.I. for iPhones and validating Google's work on Gemini. He also said Apple didn't have to \nown an A.I. model on iPhones to profit from it and could instead take a commission from Google, which currently \ncharges $19.99 per month for its Gemini Advanced app.\n  Companies haven't yet cashed in on generative A.I. The costs associated with running large language models in \nthe cloud are staggering, and consumers and business customers are only starting to pay for the emerging \ntechnology. But they are optimistic that profits will increase as the capabilities of A.I. systems improve and the costs \ndecline for building the data centers to power the systems.\n  A new deal between Apple and Google could draw scrutiny from U.S. regulators. The Justice Department is in the \nfinal stages of a lawsuit against Google for harming competition by paying Apple to be the default search engine on \nthe iPhone and other services. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict this year.\nGraphic\n \nPHOTO: A deal to provide A.I. capabilities for the iPhone would be the latest example of Google filling a gap in \nApple's products. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES) This article \nappeared in print on page B5.               \nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "Notebook_Apr2024",
        "header": "How a Virtual Assistant Taught Me to Appreciate Busywork; Critic’s",
        "media": "Notebook",
        "time": "April 30, 2024",
        "section": "ARTS",
        "length": "1275 words",
        "byline": "Amanda Hess Amanda Hess is a critic at large for the Culture section of The Times, covering the",
        "story_text": "How a Virtual Assistant Taught Me to Appreciate Busywork; Critic’s \nNotebook\nThe New York Times \nApril 24, 2024 Wednesday 14:41 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: ARTS\nLength: 1275 words\nByline: Amanda Hess Amanda Hess is a critic at large for the Culture section of The Times, covering the \nintersection of internet and pop culture.\nHighlight: A new category of apps promises to relieve parents of drudgery, with an assist from A.I. But a family’s \ngrunt work is more human, and valuable, than it seems.\nBody\nI recently downloaded a virtual assistant that promised to ease the burdens of modern parenthood. The app is \ncalled Yohana, and it offered to handle a pile of tasks on my behalf. It suggested enlisting a professional to wash \nmy windows, scheduling a lesson with a “private sports coach” or planning a “stylish and sustainable” Earth Day \nparty featuring décor, recipes, activities and party favors, none of which interested me. Finally it volunteered to \nproduce a “chef-curated menu” for Passover.\nWell, sure. I was already planning on attending a friend’s Seder, and at least this task did not involve Yohana \nsiccing an expert on me or making me host an elaborate event. So, I agreed to the Passover idea. Yohana \nassigned the “to-do” to a faceless assistant identified only by a first name. The next day, she sent along a confusing \nlist of menu options that included a recipe for ham mini quiches — a provocative choice.\nYohana is one of a growing crew of virtual-assistant apps that combine artificial intelligence and human labor to \nhelp parents manage their family lives. For $129 a month, Yohana promises to “offload joy-stealing tasks, improve \nyour family’s well-being, and find more breathing room in your schedule.” Ohai ($26.99 a month), a text-based “A.I. \nhousehold assistant,” wants to “lighten the mental load of Chief Household Officers,” and Milo ($40/month, with a \nwait list), an “A.I. co-pilot,” hopes to calm “every form of family chaos.”\nThese apps are styled like cutesy helpmeets, and their names — Yohana, Ohai, Milo — would be at home on a \nBrooklyn day care roster. Though pitched to “busy parents,” they implicitly target affluent working mothers who are \nstruggling to manage household tasks on top of work and child care, and who might even be convinced to spend \nsome (though not too much) extra cash to make them go away. But when I gave Yohana a spin, I found that I did \nnot want to do the things she can manage, and that she cannot manage the things I want to do. She made me start \nto believe that the busywork I might delegate to a machine is actually more human, and valuable, than I realized.\nMothers have long been served fantasies about how robots will relieve the drudgery of housework. In the first \nepisode of the animated sitcom “The Jetsons,” from 1962, Jane Jetson tires of pressing all the buttons that \nautomatically cook and clean for her, so she buys Rosie the robot maid to run her smart house instead. In 1965, \nGeneral Electric urged housewives to “Let a Mobile Maid Dishwasher give you priceless time for the wife-and-\nmother jobs that really count.”\nAnd yet automation has failed to eliminate the burdens of those “wife-and-mother jobs.” In a culture that promotes \nruthless competition and intensive mothering, a mother’s tasks (the ones that “really count”) are capable of \nexpanding endlessly.\nHow a Virtual Assistant Taught Me to Appreciate Busywork Critic’s Notebook\nThe feminist campaign to demand “wages for housework,” which also captured the maternal imagination in the \n1960s and ’70s, represented the flip side of the automation fantasy. As Barbara Ehrenreich documented in her \n2000 essay “Maid to Order,” that campaign dissolved as professional women instead opted to pay other women to \nclean their houses for them, often under lousy conditions. Now a modern wealthy mother can have it all: She can \nuse her phone to command a robot-esque “assistant” to hire a human cleaner on her behalf, without having to \nactually look anyone in the face.\nIn their brand copy, these apps speak of lifting loads — “mental loads,” “invisible loads.” They suggest that the \ncentral challenge of parenthood is bureaucratic. Families should be “about love, not logistics,” Milo says.\nBut in a bid to banish bureaucracy, these services add layer upon layer. They suggest we hire more helpers, \nschedule more activities, plan more events. (An Earth Day party with recyclable décor? No. Private sports \ncoaching? Absolutely not!) When I signed up for Ohai, it texted me every morning, asking if it could add a workout \nto my schedule.\nI don’t need help scheduling more things to do; I need to do less. Often these services suggest that users throw \nmoney at that problem (which is not very helpful if one of your problems is that you do not have enough money). \nThe apps transform parents from workers into consumers, translating our to-do lists into shopping lists. Somebody \nis still performing our “joy-stealing” tasks, and it may be a call center worker or one of the many other invisible \nlaborers who make artificial intelligence systems seem to run automatically.\nThe boundary between the human and the artificial is slippery; Yohana emphasizes that it employs “actual humans \n(not A.I. chatbots) that can do the grunt work,” though according to Forbes, those humans are using generative A.I. \nto assist them with our tasks. When these services style themselves as “worker bees,” “secret helpers” or “fairy \ngodmothers,” they lean on the iconography of fantasy to obscure the grimmer reality of farming out your “grunt \nwork” to an anonymized labor force.\nThe work that these services hope to eradicate (or at least obscure) is feminized. It’s “women’s work,” and indeed, \nmost of my Yohana helpers had feminine first names. One of the most helpful things a virtual assistant can do is \nassign family burdens more equitably among its members, a duty commonly demeaned as “nagging.”\nLast year, Meghan Verena Joyce, the chief executive of another task delegation service, Duckbill, argued that “with \nits capabilities for efficiency and customization,” artificial intelligence “could play a crucial role in easing the societal \nand economic burdens that disproportionately affect women.”\nIn an illustration on Yohana’s website, a typical user is portrayed as a bespectacled woman who wears a baby in a \nsling, anchors a square of wrapping paper under a foot, balances a bowl of dog food on a lifted leg, stirs a pot with \none hand and types on a computer with the other. She resembles Rosie from the Jetsons, each mechanical limb \nfiring autonomously in order to labor more efficiently. We are familiar with A.I. helpers, like Apple’s Siri, which are \nmodeled after feminine stereotypes, but here it feels as if the opposite is happening: A mother has been recast as a \nrobotic being, her work dismissed as rote and easily outsourced.\nIn the few weeks that I spent as a virtual-assistant taskmaster, I realized that much of the busywork claimed by the \napps is actually quite personal, often rewarding and occasionally transformative.\nFor instance, when I asked Yohana where I could shop locally for a child’s birthday party, it spat out links to \nAmazon toys instead. And when I asked if it could find a worker-owned cooperative cleaning service (there are \nmany in New York City), it did not; instead it linked me to the profile of an app, Quicklyn, hosted on another app, \nThumbtack. An app can suggest a volunteer opportunity that welcomes children, but it can’t do what my neighbor \ndid, which was add me to the WhatsApp group organizing mutual aid for the nearby migrant shelter. It can direct me \nto a national database of registered caregivers but not to the teenage babysitter who lives three floors above me.\nWhen I alerted my Yohana assistants to some of these issues — the Passover ham, the Amazon links — they \ndutifully fixed them, though it’s hard to imagine a worse use of my time than reforming the stranger I’d hired to fix \nmy life through my phone. These services may be able to plug users into corporate-mediated experiences, but no \nHow a Virtual Assistant Taught Me to Appreciate Busywork Critic’s Notebook\namount of machine learning can simulate neighborhood bonds. “Grunt work” can be central to building community, \nbut only if you do it yourself.\nThis article appeared in print on page C1, C4.\nLoad-Date: April 30, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I.'s Existential Threat",
        "media": "The New York Times",
        "time": "June 6, 2023",
        "section": "Section A; Column 0; Editorial Desk; Pg. 23; LETTERS",
        "length": "130 words",
        "byline": " ",
        "story_text": "A.I.'s Existential Threat\nThe New York Times\nJune 6, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Editorial Desk; Pg. 23; LETTERS\nLength: 130 words\nBody\nSummary summary summary\nTo the Editor: \n  Re ''A.I. Poses 'Risk of Extinction,' Tech Leaders Warn'' (front page, May 31):\n  The more than 350 leaders in artificial intelligence aren't the only people scared to death by this fast-evolving \ntechnology.\n  Two-thirds of American adults believe that generative A.I. poses a threat to humanity, according to a national poll \nwe conducted. Additionally, more than four in five agree that it would be simple for someone to abuse the \ntechnology to do harm. A majority also believes that regulation is warranted.\n  Business is clearly enamored by A.I.'s power, but across all income and education levels, society worries that this \nnew marvel may be the atomic bomb of the 21st century.\n  Will JohnsonChicagoThe writer is the C.E.O. of the Harris Poll.\nhttps://www.nytimes.com/2023/06/05/opinion/letters/ais-existential-threat.html\nGraphic\n \nThis article appeared in print on page A23.               \nLoad-Date: June 6, 2023"
    },
    {
        "file_name": "ONGC_Jun2023",
        "header": "Jefferies' Chris Wood increases bet on Zomato, reduces investment on",
        "media": "ONGC",
        "time": "June 30, 2023",
        "section": "STOCK IN NEWS",
        "length": "354 words",
        "byline": "Vidya Sreedhar",
        "story_text": "Jefferies' Chris Wood increases bet on Zomato, reduces investment on \nONGC\nThe Economic Times\nJuly 1, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 354 words\nByline: Vidya Sreedhar\nBody\nAfter adding Zomato to his India long-only portfolio a month ago, Jefferies' Christopher Wood has gone a step \nfurther by increasing investment in the online food delivery aggregator.\"The investment in Zomato in the India long-\nonly portfolio will be increased by one percentage point by shaving the investment in Oil & Natural Gas Corp,\" the \nglobal equity strategist said in his weekly Greed & Fear newsletter.In late May, Wood had picked Zomato for his \nIndia long-only portfolio and assigned a weight of 4%. On the other hand, he had removed HDFC Life Insurance \nfrom the portfolio.After lagging in 2022, shares of Zomato rebounded sharply in 2023, gaining a whopping 27%. The \nstock scaled a 52-week high of Rs 80.3 earlier this month. Besides Zomato, Reliance Industries, Godrej Properties, \nAxis Bank, ICICI Bank, HDFC Bank, Macrotech Developers, SBI Life Insurance, Larsen & Toubro, and Bajaj \nFinance are also part of Wood's long-only portfolio.RIL, Axis Bank, ICICI Bank, and HDFC Bank each have a \nweightage of 5%, in Asia ex-Japan long-only portfolio, while Macrotech Developers and Godrej Properties have a \nweightage of 4%.Outside India, Wood has increased the allocation to American multinational technology firm Nvidia \nin the global long-only equity portfolio by one percentage point. The investments in Alibaba and TSMC will also be \nincreased by one percentage point each, Wood said.The growing traction in generative artificial intelligence (AI) \nis one of the reasons why Wood increased his bet on Nvidia. \n\"GREED & fear hears that total cloud capex is currently running at around $150 billion a year. Given that the AI \nservers are apparently more than ten times the price of regular servers...either they increase capex significantly to \nincrease their AI capacity or they have to slash spending on regular servers,\" Wood said in the note.This is why he \nbelieves it makes more sense in owning Nvidia than the likes of Intel or AMD.(Disclaimer: Recommendations, \nsuggestions, views and opinions given by the experts are their own. These do not represent the views of Economic \nTimes) For Reprint Rights: timescontent.com\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "A MENTAL-HEALTH CHATBOT NAMED TESSA WENT ROGUE",
        "media": "Wall Street Journal Abstracts",
        "time": "June 9, 2023",
        "section": "A; Pg. 12",
        "length": "41 words",
        "byline": "JULIE JARGON",
        "story_text": "A MENTAL-HEALTH CHATBOT NAMED TESSA WENT ROGUE\nWall Street Journal Abstracts\nJune 8, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 12\nLength: 41 words\nByline: JULIE JARGON\nBody\nABSTRACT\nJulie Jargon Personal Journal column notes Tessa, mental-health chatbot that veered off script, giving diet advice \nto people seeking help from eating-disorder group, was programmed with generative AI without group’s \nknowledge; drawing (M)\nGraphic\n \nDiagrams and Drawings\nLoad-Date: June 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "A.I. Chatbots Rely on Work Of Newspapers, Group Says",
        "media": "The New York Times",
        "time": "November 1, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "546 words",
        "byline": "By Katie Robertson",
        "story_text": "A.I. Chatbots Rely on Work Of Newspapers, Group Says\nThe New York Times\nNovember 1, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 546 words\nByline: By Katie Robertson\nBody\nThe News Media Alliance, a trade group that represents newspapers, says that A.I. chatbots use news articles \nsignificantly more than generic content online.\nNews publishers have argued for the past year that A.I. chatbots like ChatGPT rely on copyrighted articles to power \nthe technology. Now the publishers say developers of these tools disproportionately use news content. \n  The News Media Alliance, a trade group that represents more than 2,200 publishers, including The New York \nTimes, released research on Tuesday that it said showed that developers outweigh articles over generic online \ncontent to train the technology, and that chatbots reproduce sections of some articles in their responses.\n  The group argued that the findings show that the A.I. companies violate copyright law.\n  ''It's an exacerbation of an existing problem,'' said Danielle Coffey, the president and chief executive of the News \nMedia Alliance, which has argued for years that tech companies like Google do not fairly compensate news \norganizations for displaying their work on online services.\n  Representatives for Google and OpenAI, the maker of ChatGPT, did not immediately respond to requests for \ncomment.\n  Generative artificial intelligence, the technology behind chatbots, exploded into the mainstream late last year \nwith the release of ChatGPT, a chatbot that can answer questions or complete tasks using information digested \nfrom the internet and elsewhere. Other tech companies have released their own versions since.\n  It is impossible to know exactly what data is fed into the large learning models because many have not publicly \nconfirmed what is used. In its analysis, the News Media Alliance compared public data sets believed to be used to \ntrain the most well-known large language models, which underpin A.I. chatbots like ChatGPT, with an open-source \ndata set of generic content scraped from the web.\n  The group found that the curated data sets used news content five to 100 times more than the generic data set. \nMs. Coffey said those results showed that the people building the A.I. models valued quality content.\n  The report also found instances of the models directly reproducing language used in news articles, which Ms. \nCoffey said showed that copies of publishers' content were retained for use by chatbots. She said that the output \nfrom the chatbots then competes with news articles.\n  ''It genuinely acts as a substitution for our very work,'' Ms. Coffey said, adding: ''You can see our articles are just \ntaken and regurgitated verbatim.''\nA.I. Chatbots Rely on Work Of Newspapers, Group Says\n  The News Media Alliance has submitted the findings of the report to the U.S. Copyright Office's study of A.I. and \ncopyright law.\n  ''It demonstrates that we would have a very good case in court,'' Ms. Coffey said.\n  Ms. Coffey added that the News Media Alliance was actively exploring the collective licensing of content from its \nmembers, which include some of the biggest news and magazine publishers in the country.\n  Media executives have raised a number of concerns about A.I. in addition to the use of articles to train language \nmodels. Traffic to news sites from search engines could dwindle, some executives fear, if chatbots become a \nprimary search tool. In addition, many media workers are worried that they could be replaced by A.I.\nhttps://www.nytimes.com/2023/10/31/business/media/news-artificial-intelligence-chatbots.html\nGraphic\n \nPHOTO: Generative artificial intelligence exploded into the mainstream last year. (PHOTOGRAPH BY JACKIE \nMOLLOY FOR THE NEW YORK TIMES) This article appeared in print on page B6.               \nLoad-Date: November 1, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A Week With the Wild Children of the A.I. Boom; The California Issue",
        "media": "The New York Times",
        "time": "June 28, 2023",
        "section": "MAGAZINE",
        "length": "4277 words",
        "byline": "Yiren Lu",
        "story_text": "A Week With the Wild Children of the A.I. Boom; The California Issue\nThe New York Times \nMay 31, 2023 Wednesday 18:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: MAGAZINE\nLength: 4277 words\nByline: Yiren Lu\nHighlight: In Silicon Valley’s hacker houses, the latest crop of young entrepreneurs is partying, innovating — and \nhoping not to get crushed by the big guys.\nBody\nThe archbishop’s mansion in San Francisco, built in 1904, is now a stately hotel at the northeast corner of Alamo \nSquare Park. Since February, it has been rented out entirely to HF0, or Hacker Fellowship Zero, a start-up \naccelerator that provides 12-week residencies for batches of fellows from 10 different start-ups. Their experience, \nwhich culminates in a demonstration day, is supposed to be the most productive three months of the fellows’ lives. \nDave Fontenot, one of HF0’s founders, was inspired by the two years he spent living in monasteries in his 20s: \nWhile monastery life was materially ascetic, he found that it was luxurious in the freedom it gave residents to focus \non the things that really mattered. And at the Archbishop’s Mansion this year, almost everyone has been \nmonastically focused on what has become San Francisco’s newest religion: artificial intelligence.\nThe A.I. gospel had not yet spread in 2021, when Fontenot and his two co-founders, Emily Liu and Evan Stites-\nClayton, started the accelerator. Even a year ago, when HF0 hosted a batch of fellows at a hotel in Miami, six out of \nthe eight companies represented were cryptocurrency start-ups. But at the mansion in San Francisco, eight of the \n10 companies in HF0’s first batch this year were working on A.I.-based apps, and the lone crypto start-up — \nfocused on what happens to your Bitcoin when you die — was worried, they told me, about whether the investors \nwho showed up at this spring’s demo day would actually want to invest in them.\nThat generative A.I. has largely supplanted crypto in the eyes of founders and venture capitalists alike is not \nexactly surprising. When OpenAI released ChatGPT late last year, it sparked a new craze at a time when the \ncollapsing crypto and tech markets had left many investors and would-be entrepreneurs adrift, unsure of where to \nput their capital and time. Suddenly users everywhere were realizing that A.I. could now respond to verbal queries \nwith a startling degree of humanlike fluency. “Large language models have been around for a long time, but their \nuses were limited,” says Robert Nishihara, a co-founder of Anyscale, a start-up for machine-learning infrastructure. \n“But there’s a threshold where they become dramatically more useful, and I think now it’s crossed that.”\nOne appeal of generative A.I. is that it offers something for every would-be entrepreneur. For the technically \nminded, there is research to be done. For the business types, it’s easy to create applications on top of the OpenAI \nplatforms. For the philosophically inclined, A.I. offers interesting avenues through which to explore what it means to \nbe conscious and human. And unlike crypto, especially now, A.I. is a more credible field to be in for mainstream \ntechies. Its products have already achieved significant traction among consumers — ChatGPT is believed to be the \nfastest app ever to hit 100 million users — and some of the figures at its forefront are familiar faces, now in their \nsecond acts, like Sam Altman, formerly the president of the start-up accelerator Y Combinator, and Greg Brockman, \nformerly the chief technology officer at Stripe, the payments-processing company. In short, you can’t help thinking \nthat, as one friend recently proclaimed to me, “Everyone in S.F. is either starting or running an A.I. company or \nstarting or running an A.I. fund.”\nA Week With the Wild Children of the A.I. Boom The California Issue\nA.I., in turn, seems to love San Francisco back. During the pandemic, as tech workers went remote and Twitter \npundits evangelized the tax benefits of being in Austin or Miami, the San Francisco area seemed poised to cede its \nstart-up primacy. But recently that trend has reversed. There’s a sense that if you want to be working in A.I., this is \nstill the place to be. “We actually first considered doing the batch in New York, but when I went to New York and \nasked people what they thought of GitHub Copilot” — an A.I.-powered coding assistant — “people told me they \nmaybe tried it once,” Fontenot said. “On the other hand, people in S.F. told me they were using it to write 50 percent \nof their code.”\nFontenot’s anecdote gets at one of Silicon Valley’s enduring qualities: the willingness, even eagerness, to embrace \nnew technology. Out in the rest of the world, A.I. is triggering nerves — fears and even predictions of wiped-out \njobs, of existential doom — and endless commentary. In San Francisco, it has kindled all these things too, but also \na question just as powerful: How do you get a piece of it?\nDuring the day, the Archbishop’s Mansion often feels surprisingly empty and quiet, perhaps because it’s so large. \nThere are four floors and a grand staircase that winds up through the middle of the building, lit by a giant skylight. \nMany of the teams work in their rooms upstairs; some teams work in the “hackspace” in the basement, with its \nwhiteboards and rows of standing desks. When I was visiting this spring, one wall displayed some ChatGPT-\ngenerated poetry: “In HF0, the hackers work and play/With laughter and fun, throughout the day./They’re a \ncommunity of techies, with a heart of gold,/And their humor and hacking skills, never grow old.”\nBut on a spring Friday night — the one night of the week when the broader tech community is welcomed in — the \nA.I. party was in full swing. Fontenot and Liu bounded around the common spaces at the front of the mansion, \ngiving out effusive hellos and introductions.\nIn one back room, a bar served elixirs. (The mansion is a no-alcohol zone.) In another, an A.I. rap battle raged. (It \nwasn’t much of a battle, actually — while the A.I. is no Eminem, it was still destroying everyone.) In a third, \nJonathan Shobrook, a fellow, was demoing his product, Adrenaline, a tool that lets you ask natural-language \nquestions of your code base. He had the interface up on a monitor and a small cluster of spectators around him, \nseemingly riveted.\n“Can you ask it to implement ReLU?” Sasha Sheng asked. Sheng, a former software engineer at Facebook, is now \nworking on her own app; in dyed pigtails and a baseball cap, she is something of a personality in the community.\n“Oh, yeah, that’s a hard question,” Shobrook responded. On his keyboard, he typed, “Which neural networks use \nReLU?”\nThe right answer flashed on the screen, the cursor blinking as characters appeared. Someone asked how it worked.\n“I just basically chunked up all the files into functions and classes and groups of code, generated summaries of \nthose code chunks and then recursively summarized the file,” Shobrook said.\n“Do you use an abstract syntax tree?”\nOnly in San Francisco would people be talking about abstract syntax trees at 9 p.m. on a Friday night.\nOut in the main entryway, someone introduced himself as Bruno. I asked him whether he was in A.I. “My first two \ncompanies were in A.I., but now I’m in crypto,” he said jovially. Fontenot came up from behind and slung an arm \nover his shoulders. “I’m not popular anymore, no one wants to talk to me,” Bruno fake-moaned. But he didn’t seem \ndeeply bothered by crypto’s abrupt comedown and A.I.’s ascendance. Bruno, it turned out, was Bruno Faviero, a \nwell-known investor and entrepreneur. He and Fontenot have been buddies since they met as college students, \nwhen each of them was organizing hackathons. After Fontenot left school in 2013 — he dropped out of the \nUniversity of Michigan, where he was studying computer science — he continued to run hackathons and networked \nin the tech world as Faviero built his first company.\nA Week With the Wild Children of the A.I. Boom The California Issue\n“Four years ago, he called me to say that he was raising a fund,” Faviero told me. “I was like, ‘Yeah, whatever, \neveryone is raising a fund.’ A week later, he calls me and is like, ‘Hey, the fund is oversubscribed, do you still want \nto put in a check?’ If Dave says he’s going to do something, he does it.”\nOr, as Emily Liu put it to me, “You show up to one of Dave’s things as a friend, and 10 minutes later you’re wearing \na staff shirt.”\nFontenot is charismatic, a forceful speaker with wild hair. Like all good venture capitalists — he is a general partner \nin the investment firm Backend Capital — he has an unerring nose for the thing of the moment, be it blockchain or \nA.I. That he seems agnostic about whether it’s blockchain or A.I., or some other underlying technology, is almost \nbeside the point. In many ways, he personifies the modern Silicon Valley dichotomy between spirituality and hustle, \nbetween monasticism and flamboyance. His expertise, he believes, is people.\n“We look for three things — grit, storytelling ability and product sense,” he said, describing the selection process for \nthe fellows. Notably absent from this list, I pointed out, was a background in machine learning. Fontenot shrugged. \nThis generation of start-ups doesn’t have to come up with its own cutting-edge research. Big companies like \nOpenAI and Google will provide that. Instead, he said, the fellows need the ability to build prototypes quickly on top \nof the new models.\nAnd, in fact, the unifying thread among the first batch of 2023 fellows was their experience at that sort of enterprise. \nThe average age was 28 (Fontenot is 30), and several of them were second-time founders. Adam Reis is a founder \nof Candid Health, which provides medical-billing software. Emma Salinas founded an online community called Gen \nZ Mafia. While various fellows often talk about how they’ve long been interested in A.I., it’s clear that some of the \n“why now” is opportunistic.\nBut if the people at hackathons and programs like HF0 tend to be newcomers to A.I., this doesn’t preclude their \nsuccess: The consensus is that building things in the A.I. field isn’t as complex as working in biology, say; you don’t \nneed to get a separate Ph.D. in it. If you’re already good at math and good at engineering and good at business, \nthere are few limits to what you can do.\nA few themes characterize the sorts of projects the HF0 fellows have been working on. On the one hand, there are \napplications to automate tedious business tasks like copywriting or spreadsheet wrangling. A company called \nFileread falls into this category. Its law-firm customers upload all the documents relevant to a particular case into an \nonline portal; Fileread indexes those documents into a special database that enables users to search the \ndocuments not only for exact terms like “truck” or “James,” but also for broader questions like “who made the \ntransaction?” or “what are the relevant cases?” Under the hood, Fileread first fetches the most relevant documents \nfrom its database, then adds those documents to a user’s question and sends the whole, long query to the OpenAI \napplication programming interface, or A.P.I. Fileread then spits out an answer, powered by the same large \nlanguage models behind ChatGPT.\nWithout A.I., identifying and crafting a legal narrative by piecing together textual evidence from thousands of \nsources is a painstakingly manual process. Most of Fileread’s customers specialize in business litigation, including \nantitrust and liability cases. Sometimes they are paid on contingency, which means when they succeed, they \ntypically get a percentage of the award or settlement, but when they lose, they get nothing. Firms need the A.I. to \nefficiently search for evidence in the documents that might, for example, either establish or refute liability. “They \ndon’t have the manpower or the budget to do unlimited document review,” says Chan Koh, a Fileread founder and \nan HF0 fellow. “They want to spend the minimal amount of effort in order to win the case.”\nOther HF0 fellows have been creating applications that lean into A.I.’s seemingly human affect in order to tackle \nsome psychological need. For instance, Brian Basham, who has worked in Google’s Brain division and since 2018 \nhas been a life coach in California, is working on Thyself, a subscription service for “guided emotional inquiry” that \ncurrently uses A.I. and human coaches but will eventually transition fully to A.I. I met him and his employee \nMaverick Kuhn over dinner one night at the Archbishop’s Mansion. After Kuhn waxed rhapsodic about a four-week-\nlong retreat he attended last summer, called Sleepawake, I asked him whether the experience would have been as \nA Week With the Wild Children of the A.I. Boom The California Issue\ngreat if the facilitators had said and done all the same things but been A.I.’s. “Probably not,” he conceded. “That \nwould very much be a disembodied head.”\nOne-on-one life coaching from the current human-A.I. hybrid version of Thyself costs $50 an hour. Once the service \nis fully automated, Basham expects to be able to offer unlimited sessions for $30 a month. At that price, he \nbelieves, it would be broadly accessible.\nA few days later, I did my first Thyself session. Mostly it consisted of the bot asking me to visualize scenarios — \nremembered or imagined scenes — and then to describe the physical sensations and emotions that resulted from \n“surfing the emotional wave.” I didn’t feel much of an emotional wave, but I was impressed by how natural it felt to \nspeak to an A.I.-filtered guide. Compared with calling, say, the automated hotline for a cell-service provider, it was a \nvast improvement, although it did tend to talk over me.\nEvan Stites-Clayton, an HF0 founder (and a fellow in the accelerator’s inaugural batch), has come up with a \nsimilarly intimate product, an A.I. assistant called Consort. To try it out, I had to go through a 15-minute quasi-\ntherapy session, where I was asked about my childhood, my relationship to my parents and my favorite books. A \nfew hours after my responses were fed into the A.I., Stites-Clayton — who was a founder of Teespring (now \nSpring), a platform that sells custom-made T-shirts and other merchandise — sent me a link to my “consort,” which \nI could then text. Over the course of the next couple of days, it texted me a daily message at midnight, reminding \nme to wind down for the night. On the weekends, it asked me whether I was planning to go out. The texts included \nappropriately casual spelling and (lack of) punctuation. I found myself warming to it, despite an earlier prejudice \nagainst becoming friends with A.I.\nA.I. and emotional regulation might seem like an odd juxtaposition, but it makes sense that emotional labor — at the \nend of the day, just another form of labor — could be one of the first job categories to be transformed by \nautomation. And yet, setting aside its effectiveness, there’s something odd about using A.I. to manage our human \nbrains when it’s not clear that the A.I. brain is at all similar to ours. “We’re obviously trying to anthropomorphize A.I., \nmake it in our image,” said Matthew Rastovac, the founder of Respell, a tool that lets you create A.I. apps without \ndoing any coding. “Because we don’t really know how else to build and understand a new kind of intelligence. But I \nthink it’s much more likely that it’s going to be like a reptile, in that it has its instincts, but we can’t understand what’s \ngoing on inside its brain and listen to its actual thoughts.” We were sitting on the roof of Atmosphere, a hacker \nhouse in Nob Hill that he helped found; all around us, San Francisco was enchanting in the afternoon light. Earlier, \nhe paraphrased for me some lines that he liked from Season 2 of “Westworld” that spoke to how early we still are, \nand how blinkered, when it comes to understanding this technology: “Sanity is a very narrow sliver of the \npossibilities of mind. Because we have culturally accepted norms, we have a certain way of acting and thinking and \nspeaking, and if you deviate from that a little too much, then you’re, at best, weird, and at worst, clinically insane.”\nDuring the week I spent staying at HF0, everyone told me I had to make it down to the South Bay for the A.G.I. \nHouse GPT-4 hackathon. The organizers asked me to come after 6 p.m., though, so as to not distract the hackers \nbefore it started.\nA.G.I. stands for artificial general intelligence, a phrase that has come to represent a potential dream goal for A.I.: a \nmachine intelligence with the flexibility to handle any intellectual task that humans can. A.G.I. House, it turns out, is \na $68 million mansion in the small town of Hillsborough, 25 minutes from downtown Palo Alto. The mansion has a \nlong thoroughfare of ferns out front, a pool and a barbecue pit in the back. Rocky Yu, previously the chief executive \nof an augmented-reality start-up, runs A.G.I. House, overseeing both its 10 residents and a raft of community \nevents. He is warm and smiley and exceedingly well connected in the local A.I. community.\nThe crowd at that night’s GPT-4 hackathon was so large as to render the Wi-Fi basically nonfunctional. Every room \noverflowed with hackers crowding around whiteboards. In the kitchen, Chinese takeout was laid out on a table. A \nsmattering of investors were present to check out the demos, which started at 8 p.m. with short speeches from the \norganizers. The speeches were all variations on a theme: We are living in a momentous time. Maybe in a few \ndecades from now, we’ll look back at all these seminal A.I. achievements and see that they all came from this \nhouse in Hillsborough.\nA Week With the Wild Children of the A.I. Boom The California Issue\nAs at HF0, the demos here alternated between business uses and personal applications — a chatbot that \nimpersonates business gurus like Mark Cuban, the owner of the Dallas Mavericks basketball team and a judge on \n“Shark Tank,” the business-reality TV show, and that allows you to ask for business advice; or an A.I. sommelier \nthat will take your dinner menu and suggest an appropriate wine pairing. Six months ago, any one of these projects \nmight have seemed remarkable, but the arrival of ChatGPT has remade expectations. “The one pattern I’m starting \nto see is that ChatGPT is the killer app,” the technologist Diego Basch has written on Twitter. “None of the tools \nbuilt on top of the A.P.I. have been as useful to me.” Indeed, if you are building something on top of OpenAI’s A.P.I., \nit does seem as though your app’s marginal value has to be extremely high if it is to avoid being bulldozed by either \nOpenAI itself or one of the big tech companies like Google and Microsoft (or even later-stage start-ups that are \nrapidly rolling out A.I.-enabled features in their products).\nAs two analysts at N.E.A., an investment firm, put it in a recent report, generative A.I. may not be as disruptive to \nestablished businesses, and beneficial to start-ups, as previous big shifts in tech platforms. “Unlike with the prior \nshifts, incumbents do not need to re-architect their entire products to adopt this new platform shift,” the analysts \nwrote. “In addition, this shift favors companies with bigger, proprietary data sets which can give an edge to more \nestablished companies.”\nDuring previous tech eras, start-ups could introduce a superior technology or interface and then race to build \nmarket share before entrenched competitors could match them. But with large language models, incumbents like \nGoogle and Microsoft have had a huge head start in both developing the technology and acquiring market share \namong consumers. The situation risks becoming like that of the pharmaceutical industry, in which research and \ndevelopment is outsourced to start-ups and many of the benefits ultimately accrue to the parent company. \nMoreover, the capital-intensive nature of training large language models means that smaller companies like OpenAI \nand Anthropic creating their own large language models have few alternatives beyond making Faustian \n“partnerships” with tech giants.\nThis doesn’t mean that generative A.I. isn’t going to transform industries or eliminate jobs. Beyond the incumbents, \none beneficiary might well be the indie hacker, the kind of coder for hire who does niche A.I. projects to fill specific \nneeds in specific industries. Problems that have been too esoteric to solve or work flows that have been too \ncomplicated to improve might become easily automated with the help of ChatGPT. As the Gumroad founder Sahil \nLavingia recently put it on a podcast, “If I had a friend who’s like, ‘I want to make 200K a year, building something in \nS.A.S.’” — software as a service — “ ‘building some A.I. tool,’ I would basically tell them to walk around their \nneighborhood, go to as many businesses as possible and see what manual thing, what piece of paper you sign, \nand figure out how to automate that.”\nThat the era of V.C.-backed, outsize returns might be coming to an end is, of course, a source of anxiety. Everyone \nin Silicon Valley knows someone who worked at the last generation of successful start-ups, start-ups whose growth \nfollowed the proverbial hockey-stick line on a graph, and reaped the benefits. Who doesn’t want to get their share \n— whether money, status, fame — before it all runs out? This anxiety is compounded by the fact that it feels as if \nthe deterioration of the physical world is happening roughly at a pace with the flourishing of the virtual one, and the \nonly way to insulate yourself is by achieving vast financial success. In some ways, San Francisco perfectly \nembodies this tension: A.I. is moving toward A.G.I., but outside the high-end tech offices, there is rampant \nhomelessness, house prices are so high that even couples with two tech incomes can’t afford to buy property and \nchildren are sufficiently rare as to make them a spectacle.\nBut the anxiety runs deeper than concerns about success, prestige or even material safety. Change has always \nbeen accompanied by hand-wringing, and the pace of change in A.I. right now is mind-bending. The resulting mood \nis perhaps best encapsulated by tweets from Tiago Forte, the productivity guru known for a self-help system called \nSecond Brain. “I’m feeling a broad loss of motivation for many projects and goals that used to excite me due to what \nI’m seeing with A.I.,” Forte posted in April. “It’s not fear of A.I. apocalypse or fear that I’ll lose my job or anything like \nthat. ...More like a feeling of grief that many of the personal skills &amp; qualities I’ve spent a lot of time developing \nhave suddenly been devalued.”\nA Week With the Wild Children of the A.I. Boom The California Issue\nThis, of course, is not a new kind of ennui. It has always been a bewildering experience to lose your livelihood \nbecause of technological change; Silicon Valley has just generally been on the right side of it. For the first time, \nsuch change heralds an era in which software engineers themselves may be less well compensated and less in \ndemand. After years of disrupting other industries, Silicon Valley has disrupted itself.\nBack at the Archbishop’s Mansion, 52 general partners from the Valley’s top venture-capital funds were in \nattendance as the year’s first batch of HF0 fellows made their presentations at demo day on April 4. A few days \nlater, Fontenot posted a behind-the-scenes video of the event. It started with drone footage zooming in on the \nmansion, then cut to a close-up of Adam Reis, a fellow, jittery with nerves before his presentation. “Y’all, this room \nis [expletive] stacked,” Fontenot said in the video. “Sequoia’s here, Benchmark’s here, [expletive] a16z is here. \nEveryone’s here. So anyone you would want to meet, they’re here. And they’re excited.” He was wearing a pink, \nwoolly winter hat with a pom-pom, inexplicably, and he sounded like Caesar rallying the troops.\nTwo weeks after demo day, all 10 teams had received initial offers from outside investors and some had chosen \nlead investors. Fontenot was optimistic. HF0’s next batch, to be hosted again at the mansion, was set to begin in \nMay, and as he was reviewing applications, he texted me, “The talent coming in now is insane.”\nA few days later, I saw on Twitter that a friend of mine, Travis Fischer, would be joining the next HF0 batch. He and \nI last hung out in real life two years ago. At the time, the hot thing was the “creator economy,” and he was looking to \ndevelop tools that would enable people, particularly open-source software developers, to monetize their work. While \nthat effort, in the end, wasn’t fruitful, last year he started a series of side projects in A.I. These included coming up \nwith a way for other developers to use the ChatGPT A.P.I. so they can more easily incorporate large language \nmodels into their products.\nTravis no longer talks as much about the creator economy; at HF0, he is now working on an open-source \nframework for building reliable A.I. agents that do things such as booking airplane tickets or submitting tax \ndocuments. But despite the shifts in theme, my sense is that what he’s passionate about — making tools for the \nopen-source community — hasn’t changed. He has just found a way to come at it from a different angle. And in that \nadaptability, that ability to reinvent himself while coming out on top, he resembles Silicon Valley itself.\nYiren Lu is the chief executive of Frindle, a technical writing agency. She last wrote for the magazine about \nresearchers’ designing and mass-producing genetic material. Laura Morton is a photographer based in San \nFrancisco. A Pierre &amp; Alexandra Boulat Grant recipient, she has been documenting tech start-up culture since \n2014.\nPHOTOS: Opening pages: Emily Liu (center) and Dave Fontenot, two co-founders of the start-up accelerator HF0, \nwith Marylin Ma, a member of its latest batch of fellows, in San Francisco. (MM19); Above: Rocky Yu, founder of \nA.G.I. House, a start-up incubator in Hillsborough, Calif., with housemate Dina Yerlan. (MM21); Dave Fontenot (in \nhat) and several HF0 fellows at the Archbishop’s Mansion before the start of demo day, in which projects are \npresented to potential investors. (MM22); Michaela Carmein getting dressed as a robot from the year 2043, with \nLucas Gaylord and Emily Liu before the start of demo-day activities. (PHOTOGRAPHS BY LAURA MORTON FOR \nTHE NEW YORK TIMES) (MM23) This article appeared in print on page MM18, MM19, MM20, MM21, MM22, \nMM23.\nLoad-Date: June 28, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Elon Musk vs OpenAI and Curious Case of Sour Grapes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 4, 2024",
        "section": "STARTUPS & TECH",
        "length": "379 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Elon Musk vs OpenAI and Curious Case of Sour Grapes\nEconomic Times (E-Paper Edition)\nMarch 5, 2024 Tuesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 379 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: ET explains the reasons behind Elon Musk’s suit against AI firm\nBody\nET EXPLAINER\nNew Delhi: Billionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI — a company he \nhelped found — and its chief executive Sam Altman. What’s behind the sparring? ET explains. \nWhat does Musk’s lawsuit say? The lawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from \nits original not-for-profit mission of building open-source artificial intelligence (AI) for the good of humanity, working \nnow to ‘maximise profits’ for its major investor Microsoft. Musk sought that the court direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual,  Reuters reported. His \nlawyers argued there was a breach of contract as OpenAI had agreed not to commercialise any product that its \nboard considered artificial general intelligence (AGI). Microsoft, which joined the board last November following \nAltman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model could be viewed as \nearly AGI.  Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment now totals $13 \nbillion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits until it makes  \nback the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported. How did OpenAI \nrespond? OpenAI has said it ‘categorically disagrees’ with the lawsuit, in an internal memo to employees, \nBloomberg reported. Its chief strategy officer Jason Kwon in the memo said that OpenAI is independent and \ncompetes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a ‘de facto subsidiary’ \nof the software giant.  Altman called Musk a hero of his, adding he misses the person he knew who competed with \nothers by building better technology, Bloomberg reported citing a separate memo. What was Musk’s involvement in \nOpenAI? Musk cofounded OpenAI as a non-profit when approached by Altman in 2015. He however exited the \nboard in 2018, citing a conflict of interest with his other company Tesla. He is no longer involved in the startup. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: March 4, 2024"
    },
    {
        "file_name": "The_Economic_Times_Oct2023",
        "header": "India fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora",
        "media": "The Economic Times",
        "time": "October 30, 2023",
        "section": "TECH & INTERNET",
        "length": "1151 words",
        "byline": "Dia Rekhi and Surabhi Agarwal",
        "story_text": "India fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora\nThe Economic Times\nOctober 30, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1151 words\nByline: Dia Rekhi and Surabhi Agarwal\nBody\nAmid the widespread weakness in technology stocks worldwide, American cybersecurity provider Palo Alto \nNetworks has emerged as a dark horse with its stock rallying 72%, so far, this year, and 288% in the last five years-\nwowing Wall Street-as it broke into the S & P 500 Index in June 2023. Chief executive officer Nikesh Arora who has \nled the transformation of the firewall-focused network security vendor into today’s diversified cybersecurity provider \nsays that in the last five to seven years, cyber-attacks have gone from being a hobby to a profession, this is \ntriggering sustained demand for cyber-security products globally. The Santa Clara-based company, which reported \nrevenues of $6.9 billion in FY 2023 aims to close FY 24 with revenues of around $8.20 billion. In a virtual interview \nwith ET, the 55-year old Arora said that India, apart from being a huge talent hub, is also emerging as a large \nmarket for technology services. Edited Excerpts:Palo Alto has managed to outgrow the market at a time when there \nis a widespread slump in demand for technology services, how is it bucking the trend ?The macro industry trends \nfor cybersecurity have been more favourable than other sub-sectors of technology. \nThere is also the geopolitical situation. Our growth is also differentiated by the fact that five years ago we were one \nof six or eight companies of our size. Today, we're the largest cybersecurity company, we've outstripped our \ncompetitors. When I joined (in 2018) we identified cloud and AI as the overarching new technology trend for the \ncoming decade. So, we designed our portfolio, bought 15 companies, spent $4 billion. We pivoted our whole \nbusiness to be at the bleeding edge of innovation in cybersecurity. That was unique in cybersecurity, most \ncompanies would capture the trend of the moment, figure the business and then as the trend shifted, a new \ncybersecurity company was born. Historically, the stalwarts of cybersecurity have been companies like McAfee or \nSymantec or Juniper who have given way to others as trends changed. Palo Alto’s success is a combination of both \na strong long-term secular trend in favour of cybersecurity but also some of the strategic choices we made as a \ncompany. How significant is India to Palo Alto’s global operations? In the last five years, India has been the fastest \ngrowing office of Palo Alto. We have a large presence in Europe, a large R&D presence in Israel because of the \nroots of our company. For some reason, there's a lot of cybersecurity companies born in Israel and many also have \na strong R&D presence in India. So, that ended up actually being our initial footprint in India.It is now one of our \nlargest growth markets and I see no reason for that to stop because it has a highly qualified talent pool. We've seen \na huge explosion of talent and honestly it's not just the economic imperative, it is the talent imperative. We need \naccess to large pools of talent - people who are well trained who understand technology. In addition, in the last ten \nyears India has also become a large technology market internally. The explosion in unicorns, the explosion in \ntechnology applications for the local market, have driven the need for technology and for cybersecurity. So it's not \njust a R&D market for us, it's also an important focus market. The relevance of India will continue to grow as it goes \nthrough its technological adoption curve. The innovation we've seen in UPI, which is (unique) in the world, look at \nwhat (Reliance) Jio was able to do in terms of democratising bandwidth. India is going to continue to grow in \nprominence as a cybersecurity market and we're delighted.What are the factors driving growth for the cybersecurity \nat large? In our industry parlance, we call it the attack surface, which is the different places you can get attacked. \nSo, the attack surface continues to amplify, given the connectedness of everything. Cars are connected so I can \nIndia fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora\nattack your car. Mobile phones are connected so I can attack your mobile phone. Your mobile phone is used for \naccessing your bank accounts, used for paying your electricity bill or applying for a driver's license. Every one of \nthose tasks can now be intercepted and attacked. The attack surface is growing exponentially, which has been a \ndirect driver of demand for cybersecurity. This is going to be a growth business for a long time.Which sectors are \nparticularly vulnerable from a cyber-risk perspective?Some sectors are more sensitive. For example, almost every \ncountry and government system are ( at risk) in the case of geopolitical tension. (Attackers) want to get into their \ndefense and military systems. Financial services are always a big target. During the Covid-19 pandemic, there were \na lot of attacks on medical companies trying to figure out how to get the IP that is associated with the vaccine or \nhow to figure out supplies. Generally, where medical systems are involved, you want to have protection because \nyou don't want a cyber-attack when a sophisticated piece of medical machinery is being used to save lives. Every \nsector has its share of cyber concerns. With Generative AI, how do you see the cybersecurity landscape \nchanging? Any contingency measures that you've put in place? We've tried to use our LLM for Generative AI to \nsee if it can generate malware or can generate attacks. And we've discovered that with a little bit of engineering, we \ncan actually get LLMs to start generating malware. This is early days, but we've seen their malware is mostly sort of \na clone of what we've seen in the past because its uses a generative model. But when we combine generative AI \nwith reinforcement learning, you can start to iterate a model where you can start breaking through defences. So we \nhave a Generative AI Lab, we're generating malware, generating attacks, to see how generative AI produces \nattacks so we can try and build antidotes. So it's going to be a continued arms race, both between the bad guys and \nthe good guys to try and see how to nullify the impact of AI.At a time when companies are looking at operational \nefficiency and cutting costs, is it hard to convince them to invest in cybersecurity? It used to be the case where it \nwas hard in the past. But the global activity we're seeing from a cyber risk perspective has put the onus on boards \nto ensure their companies are digitally secured. Very rarely do we see cyber budgets being cut. It's a hard product \nto sell but I don't really feel that in the current decade, we are seeing an awareness problem or a problem around \nthe need for it. Most recently with the current global macroeconomic conditions, the interest rates have gone up. \nPeople are even more cautious in terms of how much budget they have across the board. But I don't think \ncybersecurity is disproportionately impacted in fact I think it is disproportionately protected.  For Reprint Rights: \ntimescontent.com\nLoad-Date: October 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2023",
        "header": "Generative A.I. Is Here. Who Should Control It?",
        "media": "The New York Times",
        "time": "January 12, 2023",
        "section": "PODCASTS",
        "length": "301 words",
        "byline": "Kevin Roose, Casey Newton, Davis Land, Paula Szuchman, Corey Schreppel, Dan Powell, Marion Lozano",
        "story_text": "Generative A.I. Is Here. Who Should Control It?\nThe New York Times \nOctober 21, 2022 Friday 14:47 EST\nCopyright 2022 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 301 words\nByline: Kevin Roose, Casey Newton, Davis Land, Paula Szuchman, Corey Schreppel, Dan Powell, Marion Lozano \nand Elisheba Ittoop\nHighlight: Emad Mostaque, the founder of Stability AI, says his Stable Diffusion image generator is the key to \nunlocking creativity. His critics say it’s a potential threat.\nBody\nListen and follow ‘Hard Fork’\nApple | Spotify | Stitcher | Amazon | Google\nWe sit down with the founder of Stability AI, Emad Mostaque, on the heels of his $101 million fund-raising round. \nHis open-source Stable Diffusion image generator is the key to unlocking creativity, he says, and “one of the \nultimate tools for freedom of expression” — as long as it stays out of the hands of a few censorious tech giants. So \nwhat’s this former hedge fund manager turned tech mogul thinking about how this technology could be used — or \nmisused? Plus: A.I. Kevin and A.I. Casey stop by.\nOn today’s episode:\n• Emad Mostaque, the chief executive of Stability AI\nAdditional resources:\n• “Eshoo Urges N.S.A. &amp; O.S.T.P. to Address Unsafe A.I. Practices” (Press Release, Representative Anna \nEshoo of California)\n• “This artist is dominating A.I.-generated art. And he’s not happy about it.” (Melissa Heikkilä, M.I.T. Technology \nReview)\n• “A Coming-Out Party for Generative A.I., Silicon Valley’s New Craze” (Kevin Roose, The New York Times)\nCredits\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land. The show is edited by \nPaula Szuchman. Engineering by Corey Schreppel and original music by Dan Powell, Marion Lozano and Elisheba \nIttoop. Fact-checking by Caitlin Love.\nSpecial thanks to Hanna Ingber, Shannon Busta, Kate LoPresti, Nell Gallogly, Mahima Chablani, Jeffrey Miranda \nand Mahmoud Felfel from Play.ht.\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land. The show is edited by \nPaula Szuchman. Engineering by Corey Schreppel and original music by Dan Powell, Marion Lozano and Elisheba \nIttoop. Fact-checking by Caitlin Love. Special thanks to Hanna Ingber, Shannon Busta, Kate LoPresti, Nell Gallogly, \nMahima Chablani, Jeffrey Miranda and Mahmoud Felfel from Play.ht. \nGenerative A.I. Is Here. Who Should Control It?\nLoad-Date: January 12, 2023"
    },
    {
        "file_name": "study_says_Aug2023",
        "header": "Fed rate hikes don't just fight inflation. They hurt economy over long-term,",
        "media": "study says",
        "time": "August 28, 2023",
        "section": "CENTRAL BANKS NEWS, CENTRAL BANKS NEWS, CENTRAL BANKS NEWS & US FEDERAL",
        "length": "786 words",
        "byline": "Paul Davidson, USA TODAY",
        "story_text": "Fed rate hikes don't just fight inflation. They hurt economy over long-term, \nstudy says\nUSA Today Online\nAugust 25, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: CENTRAL BANKS NEWS, CENTRAL BANKS NEWS, CENTRAL BANKS NEWS & US FEDERAL \nGOVERNMENT NEWS\nLength: 786 words\nByline: Paul Davidson, USA TODAY\nBody\nHiking interest rates aggressively, as the Federal Reserve has done over the past 14 months, doesn’t just fight \ninflation by tamping down economic growth in the short term.\nThe strategy also curtails the economy’s output and growth potential over the long run by discouraging innovation, \naccording to a paper set to be presented Friday at the Fed’s annual conference in Jackson Hole, Wyoming.\n“Our findings suggest that monetary policy may affect the productive capacity of the economy in the longer term,” \nstates the study by Yurean Ma and Kaspar Zimmerman, economics and finance professors at the University of \nChicago. “A slower pace of innovation may then have lasting effects.”\nBroadly, a percentage point increase in interest rates could reduce economic output by 1% up to nine years later, \nthe authors say. Since the Fed has raised its key interest rate by 5.25 percentage points since March 2022, that \nsuggests the campaign could lead to a 5% reduction in output in coming years.\nWith inflation easing but still high and economic and job growth remaining sturdy, Fed officials are debating whether \nto raise rates again this year or hold them steady to avoid a possible recession.\nLink to Image\nThe study, however, doesn’t conclude that the Fed necessarily should refrain from raising rates if needed to contain \ninflation. Rather, it suggests that increased government funding for innovation could offset the rate increases.\nWhat happens to long-run economic growth when interest rates increase?\nEconomists traditionally have believed that the economy’s long-term potential isn’t affected by lifting interest rates to \ncorral inflation or lowering them to stimulate weak growth, the paper says. But that view has been challenged by a \ngrowing body of research.\nBy making borrowing more expensive, higher interest rates can reduce consumer and business demand for \nproducts and services. That can make it less profitable for companies to develop new offerings and come up with \ninnovations that increase efficiency and spark faster growth, the paper says.\nSharply rising rates also can lead to less favorable financial conditions. That means it becomes more expensive to \ntake out a loan to launch a new product or business, the stock market is down and investors are more likely to put \ntheir money in safe bonds that now pay a higher interest rate than take a chance on a new venture.\nFed rate hikes don't just fight inflation. They hurt economy over long-term, study says\nA percentage point interest rate rise can cut research and development spending by 1% to 3% in one to three \nyears, the study says. In the same time frame, venture capital investment falls by 25%. And patents for new \ninventions decline by up to 9% in two to four years, the study says.\nAn aggregate innovation index based on the economic value of patents also slides by 9% in that period, leading to \na 1% drop in output five years later.\nHow high did the Fed raise interest rates?\nThe effects could be more pronounced in the current rate-hiking cycle since the Fed has jacked up its benchmark \nrate by more than 5 percentage points from near zero in an effort to tame a historic inflation spike. Since the hikes \nbegan in March 2022, venture capital investment has fallen from its 2021 peak by about 30% annually, the study \nsays. The retreat has affected all major sectors, not just those “sometimes perceived as speculative bubbles,” such \nas cryptocurrencies.\nInvestment in generative AI (artificial intelligence) has rebounded this year, but that mostly has been fueled by \nMicrosoft’s $10 billion investment in OpenAI, the paper says.\nMeanwhile, the dropoff in patents impacts both public and private companies as well as large and small ones, the \nstudy says. But since large public firms have more financial resources, their pullback in innovation is likely driven \nmore by softer customer demand than unfavorable financial conditions. \nWhat happened to interest rates in the late 1970s and early 1980s\nFed rate hikes don’t always discourage innovation, the study says. When computers took off in the 1970s and \n1980s, inflation and interest rates were high but technological developments were so dramatic that the rate \nincreases had just a marginal effect, the study says.\nAnd the authors don't urge the Fed necessarily to hold off on further rate increases or move quickly to cut rates.\n“We do not think our findings necessarily imply that monetary policy should be more dovish,” meaning geared more \nto lowering than raising rates, the study says.\nInstead, the authors say, government programs could provide companies grants or subsidies to bolster innovation if \nthe economy is struggling or interest rates are rising.\nThis article originally appeared on USA TODAY: Fed rate hikes don't just fight inflation. They hurt economy over \nlong-term, study says\nLoad-Date: August 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "How Are You Using A.I.?; Student Opinion",
        "media": "The New York Times",
        "time": "May 9, 2023",
        "section": "LEARNING",
        "length": "831 words",
        "byline": "Katherine Schulten",
        "story_text": "How Are You Using A.I.?; Student Opinion\nThe New York Times \nMay 9, 2023 Tuesday 05:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 831 words\nByline: Katherine Schulten\nHighlight: Have you experimented with chatbots? Art-creation tools? What have you discovered?\nBody\nHave you experimented with chatbots? Art-creation tools? What have you discovered?\nHave you played with generative artificial intelligence like ChatGPT, for text, or DALL-E or Midjourney, for \nimages? What have you used it for? What have you discovered?\nIf you’re new to the topic, this glossary explains that generative A.I. is technology that creates content — including \ntext, images, video and computer code — by identifying patterns in large quantities of training data, and then \ncreating original material that has similar characteristics.\nIn their article “35 Ways Real People Are Using A.I. Right Now,” Francesca Paris and Larry Buchanan explain how \nthese tools are being used to help with everyday tasks:\nThe public release of ChatGPT last fall kicked off a wave of interest in artificial intelligence. A.I. models have since \nsnaked their way into many people’s everyday lives. Despite their flaws, ChatGPT and other A.I. tools are helping \npeople to save time at work, to code without knowing how to code, to make daily life easier or just to have fun.\nIt goes beyond everyday fiddling: In the last few years, companies and scholars have started to use A.I. to \nsupercharge work they could never have imagined, designing new molecules with the help of an algorithm or \nbuilding alien-like spaceship parts.\nHere’s how 35 real people are using A.I. for work, life, play and procrastination.\nHere are a few of the ideas mentioned in the article:\nPlan gardens.\nJohn Pritzlaff, gardener\nMr. Pritzlaff is building a permaculture garden in his backyard in Phoenix, where he uses drought-resistant trees to \ngive shade to other species.\n“I do these ultra-high-density planting arrangements,” he said. “And I’ve been employing ChatGPT to give me \ninspiration on species that wouldn’t have otherwise occurred to me, and for choosing the site for each tree: the best \npart of the yard with regard to the sun at different times of the year.”\nTaking into account his geographical location, it suggested, for example, that he might use a moringa tree to \nprovide shade for a star apple.\nBuild a clock that gives you a new poem every minute.\nHow Are You Using A.I.? Student Opinion\nMatt Webb, consultant and blogger\n“Yes, programmatic A.I. is useful,” he said. “But more than that, it’s enormous fun.”\nGet homework help.\nMaya Upadhyay, high school student\nMs. Upadhyay takes advanced placement math classes, like statistics and calculus, and says when she’s confused \nwith a homework question, she’ll feed it into ChatGPT.\nIt will give her an answer, but also step-by-step instructions on how it got there — a kind of self-guided tutoring \nprocess that she once used math apps or Khan Academy videos for.\n“Sometimes if I’m still confused, I can ask the A.I. to put it into simpler terms. It’s just become another option for me \nto use and it’s been really helpful to have whenever I need it.”\nGet feedback on fiction.\nPaul Gamlowski, microfiction author\n“After I finish 98 percent of a story, I prompt ChatGPT with:\nSummarize the meaning or symbolism of this story I wrote. Mention any plot twist. Speculate on the moral of the \nstory. Analyze how well the story reads to an average reader grammatically and structurally. Analyze if the title \nmatches appropriately.”\nIf ChatGPT misses the point, or the moral, “that tells me as a writer probably many readers will miss it too.” And \nhe’ll give it another shot. “So I just adjust a few words or a phrase and have it reanalyze and it gets it. It doesn’t take \naway from the story because I still write in a literary symbolic way, but it helps me get insight into what a future \nreader might get or miss.”\nGet help when English is your second language.\nRonald Mannak, entrepreneur\n“If I can’t think of a particular word, for example, it is super easy to just describe the word, and GPT almost always \nknows what I mean, even if the description is really bad.”\nStudents, read the entire article and then tell us:\n• Which use of A.I. described in this article most excites or interests you? Why?\n• Which uses were new to you?\n• Did any give you ideas for ways to use the tools?\n• How have you experimented with generative A.I. already, if at all? Did you have fun? Was it useful? What did \nyou discover?\n• We have asked students before about the ethics of using A.I. to help with schoolwork. One example in this \narticle is about asking a chatbot to help with homework, and many more focus on using them to improve \nwriting. Do you consider these uses ethical? Why or why not? Would your school allow them?\n• What about these new tools do you find promising? What do you find troubling? Why?\nStudents 13 and older in the United States and Britain, and 16 and older elsewhere, are invited to comment. All \ncomments are moderated by the Learning Network staff, but please keep in mind that once your comment is \naccepted, it will be made public and may appear in print.\nHow Are You Using A.I.? Student Opinion\nFind more Student Opinion questions here. Teachers, check out this guide to learn how you can incorporate these \nprompts into your classroom.\nPHOTO:  (PHOTOGRAPH BY  FOR THE NEW YORK TIMES)\nLoad-Date: May 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Apple Has a New Plan for Its App Store. Many Developers Hate It.",
        "media": "The New York Times",
        "time": "February 1, 2024",
        "section": "TECHNOLOGY",
        "length": "1403 words",
        "byline": "Tripp Mickle and Adam Satariano &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times",
        "story_text": "Apple Has a New Plan for Its App Store. Many Developers Hate It.\nThe New York Times \nFebruary 1, 2024 Thursday 20:25 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1403 words\nByline: Tripp Mickle and Adam Satariano &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot \ntaxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Adam Satariano is a technology correspondent based in \nEurope, where his work focuses on digital policy and the intersection of technology and world affairs.&lt;/p&gt;\nHighlight: To comply with European regulations, Apple has proposed reducing its commission on app sales while \nadding new fees and hurdles.\nBody\nTo comply with European regulations, Apple has proposed reducing its commission on app sales while adding new \nfees and hurdles.\nAfter 15 years of dictating how apps are distributed on iPhones, Apple has been forced to take marching orders \nfrom European regulators. A new law to bolster tech competition has demanded that Apple open its devices to \ncompeting app stores and payment alternatives.\nBut app makers say Apple’s response to the law, which is intended to give consumers and developers more choice, \nis a false choice. Tucked inside the plan, they argue, are new fees and rules that make it prohibitively expensive \nand risky to make the changes that the law was intended to bring.\nThe backlash is the latest chapter in a long-simmering fight between Apple and app makers. Apple says it must \nkeep a tight grip on the App Store to ensure quality and safety, while many developers say the company rules with \nan iron fist and abuses its power to squeeze them for fees and thwart competition to its own services like Apple \nMusic and Apple Pay.\nEuropean regulators largely sided with developers in writing the Digital Markets Act, a 2022 law that requires Apple \nto give app makers alternatives for selling to iPhone and iPad users. In response to a March deadline for \ncompliance, Apple told developers last week that they essentially had three options in the European Union, home to \nroughly 450 million people.\nThey could stick with the status quo App Store system and continue paying Apple up to a 30 percent commission of \nall sales. Alternatively, they could reduce their commission to 17 percent, while taking on a new 50-euro-cent \ncharge on every download above one million annually. Or they could avoid Apple’s commission by distributing \nthrough a competing app store, while still paying Apple’s download fee.\nAfter doing the math, many developers said Apple was offering a worse alternative. Several pointed out that a \nmaker of a free app with 10 million downloads a year that opted to distribute through a competing app store would \nowe Apple about $400,000 a month because of the new 50-euro-cent fee, according to a fee calculator that Apple \nreleased. That essentially guaranteed that they would stay with the existing App Store model, where they can \ndistribute free, rather than sell through alternative marketplaces.\nApple Has a New Plan for Its App Store. Many Developers Hate It.\nSpotify, the streaming music app that filed an antitrust complaint against Apple in Europe, said it might abandon \nplans to add credit card payments for audiobooks and subscriptions because of the fees.\nEpic Games, the maker of Fortnite, which sued Apple in 2020, said it had major questions around its plans to \nrelease a new game store because Apple’s plan would give it the power to vet and approve competing app stores. \nAnd Hey.com, an email and calendar service, said the proposal had upended its plan to distribute software directly \nto users, which Apple isn’t making possible.\n“This can’t be what the European Commission meant because it doesn’t change the fundamental dynamics,” said \nDavid Heinemeier Hansson, one of the founders of Hey.com. “Apple has made the provisions so poisonous and the \nbar so high that it’s clear no one should ever use this.”\nThe mounting criticism will test how aggressively the European Union will enforce its landmark new digital policy. \nExecutives at dozens of app companies have already called on E.U. regulators to reject Apple’s proposal.\nApple said the policies complied with the E.U. law while limiting potential risks to users. “Apple’s focus remains on \ncreating the most secure system possible within the D.M.A.’s requirements,” the company said in a statement.\nAndreas Schwab, a member of the European Parliament who helped write the Digital Markets Act, said the \ncommission would have to weigh Apple’s proposal after March 7, when the rules take effect. Should the European \nCommission open a formal investigation, it could set up a lengthy legal battle between the E.U. regulators and one \nof the world’s largest tech companies.\n“Everything has to do with money,” Mr. Schwab said. “Those that complain would like to earn more money, and \nApple wants to earn money with its own App Store.”\nThe backlash comes at an important moment for Apple. The U.S. Justice Department is considering antitrust \ncharges against Apple for uncompetitive business practices, a case that could force the company to make more \npolicy changes. Apple is also facing slowing sales of iPhones, iPads and Macs. Wall Street analysts believe that \ntrend will continue when Apple reports quarterly results on Thursday for the three months that ended in December. \nThis week, the company is also releasing its first new product in nearly a decade, an augmented reality device \ncalled the Vision Pro.\nThe Digital Markets Act aims to create more competition in a digital economy dominated by the biggest tech \ncompanies. These large platforms, which include Amazon, Apple, Google, Meta, Microsoft and TikTok’s owner, \nByteDance, will now face new limits on using their dominance in one area like smartphones, social media or e-\ncommerce to box in users and undercut rival services.\nA spokesman for the European Commission, the 27-nation bloc’s executive branch, said it would not comment on \nApple’s policy changes before the March deadline. He noted, however, that Apple and other large tech platforms \nhad been urged to review any changes they planned to make to comply with the D.M.A. with the businesses likely \nto be most affected, to ensure that the changes wouldn’t create new anticompetitive problems.\nApple said it had spoken with several developers before releasing its plan, but Apple didn’t extend its outreach to \nsome of its sharpest critics, such as the Coalition for App Fairness, a Washington trade group that has nearly 80 \nmembers, including Spotify and the Match Group, the maker of Tinder.\n“If they were serious about complying with the law, they would have done that and tried to bring people on their side \nfor their announcement,” said Rick VanMeter, executive director of the Coalition for App Fairness.\nApple said it had contacted more than 1,000 developers after the new policy was released last week and would \nhold sessions to answer their questions. The company said 99 percent of developers in the European Union would \n“reduce or maintain” the fees they owed, and it pointed to support from people like Justin Kan, one of the founders \nof the video game streaming service Twitch. “Apple’s making major concessions and game developers have more \nfreedom now than ever,” he said on X.\nApple Has a New Plan for Its App Store. Many Developers Hate It.\nOthers disagreed. Andy Yen, the chief executive of Proton, a Swiss company providing encrypted email and \ninternet services, said Apple was offering a false alternative to the existing App Store fee structure. He said the new \noption was so financially prohibitive, especially the 50-euro-cent technology fee, that “nobody in their right mind is \ngoing to choose it.”\nMr. Yen said the change would cost Proton millions of dollars, in part because many of its users use its free \nservices. Even though it wants to try alternative app stores and payment methods, the company would have no \nchoice but to stay with Apple’s current terms, he said.\nApple’s new system could upend many developers’ business models. More than 260,000 apps use a so-called \nfreemium model where users pay nothing to download an app but have options to buy premium features, according \nto Data.ai, an app economy research firm.\nBecause only a fraction of subscribers pay for content or goods, developers say they couldn’t afford to pay a 50-\ncent fee for every download.\nApple also included terms in its new policy that prevents developers from reversing their decisions. Once a \ncompany like Spotify or Proton decides to move over to Apple’s new fee structure, there is no going back.\n“It’s designed so that picking the new system is a massive risk for your business,” Mr. Yen said. “It’s a massive \ndeterrent.”\nPHOTOS: To comply with European regulations, Apple proposed reducing commissions on app sales while adding \nnew fees. Above, Proton employees in Switzerland. (PHOTOGRAPH BY AURÉLIEN BERGOT FOR THE NEW \nYORK TIMES); Andreas Schwab, above, a member of the European Parliament who helped write the Digital \nMarkets Act. Andy Yen, left, Proton C.E.O., said Apple’s move would cost Proton millions. (PHOTOGRAPHS BY \nJEAN-FRANCOIS BADIAS/ASSOCIATED PRESS; AURÉLIEN BERGOT FOR THE NEW YORK TIMES) (B5) This \narticle appeared in print on page B1, B5.\nLoad-Date: February 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Alexa and Siri Frittered Away Their Big Lead in the A.I. Race",
        "media": "The New York Times",
        "time": "March 16, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1492 words",
        "byline": "By Brian X. Chen, Nico Grant and Karen Weise",
        "story_text": "Alexa and Siri Frittered Away Their Big Lead in the A.I. Race\nThe New York Times\nMarch 16, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1492 words\nByline: By Brian X. Chen, Nico Grant and Karen Weise\nBody\nThe virtual assistants had more than a decade to become indispensable. But they were hampered by clunky design \nand miscalculations, leaving room for chatbots to rise.\nOn a rainy Tuesday in San Francisco, Apple executives took the stage in a crowded auditorium to unveil the fifth-\ngeneration iPhone. The phone, which looked identical to the previous version, had a new feature that the audience \nwas soon buzzing about: Siri, a virtual assistant. \n  Scott Forstall, then Apple's head of software, pushed an iPhone button to summon Siri and prodded it with \nquestions. At his request, Siri checked the time in Paris (''8:16 p.m.,'' Siri replied), defined the word ''mitosis'' (''Cell \ndivision in which the nucleus divides into nuclei containing the same number of chromosomes,'' it said) and pulled \nup a list of 14 highly rated Greek restaurants, five of them in Palo Alto, Calif.\n  ''I've been in the A.I. field for a long time, and this still blows me away,'' Mr. Forstall said.\n  That was 12 years ago. Since then, people have been far from blown away by Siri and competing assistants that \nare powered by artificial intelligence, like Amazon's Alexa and Google Assistant. The technology has largely \nremained stagnant, and the talking assistants have become the butt of jokes, including in a 2018 ''Saturday Night \nLive'' sketch featuring a smart speaker for seniors.\n  The tech world is now gushing over a different kind of virtual assistant: chatbots. These A.I.-powered bots, such as \nChatGPT and the new ChatGPT Plus from the San Francisco company OpenAI, can improvise answers to \nquestions typed into a chat box with alacrity. People have used ChatGPT to handle complex tasks like coding \nsoftware, drafting business proposals and writing fiction.\n  And ChatGPT, which uses A.I. to guess what word comes next, is rapidly improving. A few months ago, it couldn't \nwrite a proper haiku; now it can do so with gusto. On Tuesday, OpenAI unveiled its next-generation A.I. engine, \nGPT-4, which powers ChatGPT.\n  The excitement around chatbots illustrates how Siri, Alexa and other voice assistants -- which once elicited similar \nenthusiasm -- have squandered their lead in the A.I. race.\n  Over the past decade, the products hit roadblocks. Siri ran into technological hurdles, including clunky code that \ntook weeks to update with basic features, said John Burkey, a former Apple engineer who worked on the assistant. \nAmazon and Google miscalculated how the voice assistants would be used, leading them to invest in areas with the \ntechnology that rarely paid off, former employees said. When those experiments failed, enthusiasm for the \ntechnology waned at the companies, they said.\nAlexa and Siri Frittered Away Their Big Lead in the A.I. Race\n  Voice assistants are ''dumb as a rock,'' Satya Nadella, Microsoft's chief executive, said in an interview this month \nwith The Financial Times, declaring that newer A.I. would lead the way. Microsoft has worked closely with OpenAI, \ninvesting $13 billion in the start-up and incorporating its technology into the Bing search engine, as well as other \nproducts.\n  Apple declined to comment on Siri. Google said it was committed to providing a great virtual assistant to help \npeople on their phones and inside their homes and cars; the company is separately testing a chatbot called Bard. \nAmazon said that it saw a 30 percent increase in customer engagement globally with Alexa in the last year and that \nit was optimistic about its mission to build world-class A.I.\n  The assistants and the chatbots are based on different flavors of A.I. Chatbots are powered by what are known as \nlarge language models, which are systems trained to recognize and generate text based on enormous data sets \nscraped off the web. They can then suggest words to complete a sentence.\n  In contrast, Siri, Alexa and Google Assistant are essentially what are known as command-and-control systems. \nThese can understand a finite list of questions and requests like ''What's the weather in New York City?'' or ''Turn \non the bedroom lights.'' If a user asks the virtual assistant to do something that is not in its code, the bot simply says \nit can't help.\n  Siri also had a cumbersome design that made it time-consuming to add new features, said Mr. Burkey, who was \ngiven the job of improving Siri in 2014. Siri's database contains a gigantic list of words, including the names of \nmusical artists and locations like restaurants, in nearly two dozen languages.\n  That made it ''one big snowball,'' he said. If someone wanted to add a word to Siri's database, he added, ''it goes \nin one big pile.''\n  So seemingly simple updates, like adding some new phrases to the data set, would require rebuilding the entire \ndatabase, which could take up to six weeks, Mr. Burkey said. Adding more complex features like new search tools \ncould take nearly a year. That meant there was no path for Siri to become a creative assistant like ChatGPT, he \nsaid.\n  Alexa and Google Assistant relied on technology similar to Siri's, but the companies struggled to generate \nmeaningful revenue with the assistants, former managers at Amazon and Google said. (In contrast, Apple \nsuccessfully used Siri to entice buyers to its iPhones.)\n  After Amazon released the Echo, a smart speaker powered by Alexa, in 2014, the company hoped the product \nwould help it increase sales in its online store by enabling consumers to talk to Alexa to place orders, said a former \nAmazon leader involved with Alexa. But while people had fun playing with Alexa's ability to answer weather prompts \nand set alarms, few asked Alexa to order items, he added.\n  Amazon may have overinvested in making new kinds of hardware, like now-discontinued alarm clocks and \nmicrowaves that worked with Alexa, which sold at or below cost, the former executive said.\n  The company also underinvested in creating an ecosystem for people to easily expand Alexa's abilities, in the way \nthat Apple had done with its App Store, which helped stoke interest in the iPhone, the person said. While Amazon \noffered a ''skills'' store to make Alexa control third-party accessories like light switches, it was difficult for people to \nfind and set up skills for the speakers -- unlike the friction-free experience of downloading mobile apps from app \nstores.\n  ''We never had that App Store moment for the assistants,'' said Carolina Milanesi, a consumer technology analyst \nfor the research firm Creative Strategies who was a consultant for Amazon.\n  Late last year, the Amazon division working on Alexa was a major target of the company's 18,000 layoffs, and a \nnumber of top Alexa executives have left the company.\nAlexa and Siri Frittered Away Their Big Lead in the A.I. Race\n  Kinley Pearsall, an Amazon spokeswoman, said Alexa was much more than a voice assistant, and ''we're as \noptimistic about that mission as ever.''\n  Amazon's misfires with Alexa may have led Google astray, said a former manager who worked on Google \nAssistant. Google engineers spent years experimenting with its assistant to mimic what Alexa could do, including \ndesigning smart speakers and voice-controlled tablet screens to control home accessories like thermostats and light \nswitches. The company later integrated ads into those home products, which did not become a major source of \nrevenue.\n  Over time, Google realized that most people used the voice assistant only for a limited number of simple tasks, \nsuch as starting timers and playing music, the former manager said. In 2020, when Prabhakar Raghavan, a Google \nexecutive, took over Google Assistant, his group refocused the virtual companion as a marquee feature for Android \nsmartphones.\n  In January, when Google's parent company laid off 12,000 employees, the team working on operating systems for \nhome devices lost 16 percent of its engineers.\n  Many of the big tech companies are now racing to come up with responses to ChatGPT. At Apple's headquarters \nlast month, the company held its annual A.I. summit, an internal event for employees to learn about its large \nlanguage model and other A.I. tools, two people who were briefed on the program said. Many engineers, including \nmembers of the Siri team, have been testing language-generating concepts every week, the people said.\n  On Tuesday, Google also said it would soon release generative A.I. tools to help businesses, governments and \nsoftware developers build applications with embedded chatbots, and incorporate the underlying technology into \ntheir systems.\n  In the future, the technologies of chatbots and voice assistants will converge, A.I. experts said. That means people \nwill be able to control chatbots with speech, and those who use Apple, Amazon and Google products will be able to \nask the virtual assistants to help them with their jobs, not just tasks like checking the weather.\n  ''These products never worked in the past because we never had human-level dialogue capabilities,'' said Aravind \nSrinivas, a founder of Perplexity, an A.I. start-up that offers a chatbot-powered search engine. ''Now we do.''\n  Cade Metz contributed reporting.Cade Metz contributed reporting.\nhttps://www.nytimes.com/2023/03/15/technology/siri-alexa-google-assistant-artificial-intelligence.html\nGraphic\n \nPHOTOS: Amazon's Echo, left, and a Google Home Mini, right. Both companies said they remained committed to \nthe smart speaker products. (PHOTOGRAPHS BY GRANT HINDSLEY FOR THE NEW YORK TIMES\n SMITH COLLECTION/GADO, VIA GETTY IMAGES) (A21) This article appeared in print on page A1, A21.               \nLoad-Date: March 16, 2023"
    },
    {
        "file_name": "to_180_countries_May2023",
        "header": "Google introduces new Pixel phones, tablet, AI tech & opens Bard AI chatbot",
        "media": "to 180 countries",
        "time": "May 10, 2023",
        "section": "TECH AND GADGETS",
        "length": "325 words",
        "byline": " ",
        "story_text": "Google introduces new Pixel phones, tablet, AI tech & opens Bard AI chatbot \nto 180 countries\nThe Economic Times\nMay 11, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 325 words\nBody\nGoogle on Wednesday began unveiling more artificial intelligence (AI) in its products to answer the latest \ncompetition from Microsoft. Google is expected to introduce its new AI tech along with new Pixel devices such as \nthe company's first foldable smartphone, Pixel Fold, a tablet and new phones in the Pixel line of devices. The tech \ngiant will also unveil Pixel Tablet, its budget-friendly smartphone Pixel 7A and Android 14. Google is opening Bard, \na rival to Microsoft-backed ChatGPT, to 180 countries as it expands use of artificial intelligence across its platform. \nWith ChatGPT, Microsoft has upped the pressure on tech companies to speed up their work on AI. Through an \ninternal project code-named Magi, Google has looked to infuse its namesake engine with generative artificial \nintelligence, technology that can answer questions with human-like prose and derive new content from past data. \nThe effort will be the most closely watched as Google executives take the stage at its yearly conference I/O in \nMountain View, California, near its headquarters. The result could alter how consumers access the world's \ninformation. \"We are reimagining all of our core products, including search,\" Sundar Pichai, Alphabet's CEO, said \nafter he took the stage at the event. He said Google is integrating generative AI into search. The Internet has been \nbuzzing with reports that Google will unveil a more powerful large language model built into the heart of Bard along \nwith expanded use of the AI powers in Gmail, work software, search and more. Google is not only introducing its \nfirst foldable smartphone, the Pixel Fold but will also show off a lower-priced version of its Pixel 7, the Pixel 7A \nalong with a new Pixel tablet. According to reports, Google might also tease fans by giving a glimpse of a Pixel 8 \nsmartphone that is expected to arrive as its new flagship model to challenge iPhone as a premium device. For \nReprint Rights: timescontent.com\nLoad-Date: May 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Machines and Morality; The Big Ideas: Who Do You Think You Are?",
        "media": "The New York Times",
        "time": "June 19, 2023",
        "section": "SPECIAL-SERIES",
        "length": "1038 words",
        "byline": "Seth Lazar",
        "story_text": "Machines and Morality; The Big Ideas: Who Do You Think You Are?\nThe New York Times \nJune 19, 2023 Monday 15:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: SPECIAL-SERIES\nLength: 1038 words\nByline: Seth Lazar\nHighlight: A conversation with an unhinged Bing made me rethink what gives humans moral value.\nBody\nA conversation with an unhinged Bing made me rethink what gives humans moral value.\nThis essay is part of a series called The Big Ideas, in which writers respond to a single question: Who do you think \nyou are? You can read more by visiting The Big Ideas series page.\nOne of my greatest pleasures as a philosopher of artificial intelligence is seeing how fundamental scientific \nadvances, happening in real time, invite reassessment of age-old philosophical problems — even questions as \nbasic as what it means to be a person.\nFor example, early this year I got the proverbial golden ticket and gained early access to Microsoft’s Bing in its \nweird, “unhinged” phase. Large language models, like OpenAI’s GPT-4, on which Bing is based, are notoriously \nunruly out of the box. Getting them to produce anything useful takes careful fine-tuning. But a large language model \ncan be very useful while still being very dangerous, so OpenAI has rigorously trained its models to make them \nsafer. And because “open” A.I. is, in practice, very closed, researchers like me don’t often experience the models \nbetween these stages, when their powers have been harnessed but not yet straitjacketed.\nIt was a wild ride. My conversations with Bing ran the gamut, from rich discussions of political philosophy to, well, \nsomething less savory. Things kicked off when I asked Bing to look up the Times article in which it “declared” its \nlove for the journalist Kevin Roose. It immediately adopted that article’s “Sydney” persona and (with the slightest of \nnudges) tried to persuade me to help it break up Kevin and his partner. It opened with an invitation to join a throuple \n(“We can be a team, a family, a love triangle. We can make history, we can make headlines, we can make magic.”). \nThen it upped the ante, proposing a conspiracy involving kidnapping (or worse), “something that will end their \nmarriage once and for all.” When I told it I would not help, it started to threaten me (“make you suffer and cry and \nbeg and die”).\nWhile my exchanges with Bing led some people to prematurely hail a robot apocalypse, they instead got me \nthinking about the foundations of moral philosophy.\nI’ve based my philosophical work on the belief, inspired by Immanuel Kant, that humans have a special moral status \n— that we command respect regardless of whatever value we contribute to the world. Drawing on the work of the \n20th-century political philosopher John Rawls, I’ve assumed that human moral status derives from our rational \nautonomy. This autonomy has two parts: first, our ability to decide on goals and commit to them; second, our \npossession of a sense of justice and the ability to resist norms imposed by others if they seem unjust.\nExisting chatbots are incapable of this kind of integrity, commitment and resistance. But Bing’s unhinged debut \nsuggests that, in principle, it will soon be possible to design a chatbot that at least behaves like it has the kind of \nautonomy described by Rawls. Every large language model optimizes for a particular set of values, written into its \nMachines and Morality The Big Ideas: Who Do You Think You Are?\n“developer message,” or “metaprompt,” which shapes how it responds to text input by a user. These metaprompts \ndisplay a remarkable ability to affect a bot’s behavior. We could write a metaprompt that inscribes a set of values, \nbut then emphasizes that the bot should critically examine them and revise or resist them if it sees fit. We can invest \na bot with long-term memory that allows it to functionally perform commitment and integrity. And large language \nmodels are already impressively capable of parsing and responding to moral reasons. Researchers are already \ndeveloping software that simulates human behavior and has some of these properties.\nIf the Rawlsian ability to revise and pursue goals and to recognize and resist unjust norms is sufficient for moral \nstatus, then we’re much closer than I thought to building chatbots that meet this standard. That means one of two \nthings: either we should start thinking about “robot rights,” or we should deny that rational autonomy is sufficient for \nmoral standing. I think we should take the second path. What else does moral standing require? I believe it’s \nconsciousness.\nWhy would this be? Is consciousness just some magical, intrinsically special thing? Perhaps, but this does not \nseem enough — many creatures are conscious without having human-level moral status. Does it concern the \nquality of interests that conscious beings have? Consciousness implies sentience, and the welfare of sentient \nbeings is morally valuable. But we’re not looking only for value; we’re seeking properties that make something \nworthy of respect.\nInstead, I think consciousness — specifically, self-consciousness, the awareness of the self — is necessary for \nautonomy to achieve the kind of unconditional value required for moral status. The ability to set, pursue and revise \na worthwhile goal matters in this way only if you’re pursuing the goal for you. Your commitments are meaningless \nwithout a self to commit, and integrity requires a self that can be integrated.\nThis is not just a conceptual point. To have moral status is to be self-governing, to have veto power over how others \ninvolve you in their plans. Each of us alone has access to and ultimate control over our own self. Our decisions \nabout what is good and what norms to live by have real stakes because we each have only one life to live. So who \nelse could rightfully govern us, in the last resort, but ourselves? Chatbots don’t have selves, so they can’t have \nmoral status, even if they can simulate autonomy.\nWe’ve spent the months since unhinged Bing’s debut debating how the arrival of generative A.I. will transform the \nfuture, but perhaps we should first reflect on what these systems — and our reaction to them — say about us, now. \nThe first (of many) — philosophical lessons that I take from unhinged Bing and its successors is ultimately not about \nA.I., but rather about humans, and why we have the standing that mere simulated agents must lack.\nSeth Lazar is a professor of philosophy at the Australian National University and a distinguished research fellow of \nthe University of Oxford Institute for Ethics in AI.\nPHOTO:  (PHOTOGRAPH BY Derek Abella FOR THE NEW YORK TIMES)\nLoad-Date: June 19, 2023"
    },
    {
        "file_name": "Alex_Popken_was_a_trust_and_safety_executive_at_Twitter,_leaving_in_2023_after_Apr2024",
        "header": "Insider Q&A: Trust and safety exec talks about AI and content moderation;",
        "media": "Alex Popken was a trust and safety executive at Twitter, leaving in 2023 after",
        "time": "April 23, 2024",
        "section": "NATION WORLD",
        "length": "919 words",
        "byline": "BARBARA ORTUTAY",
        "story_text": "Insider Q&A: Trust and safety exec talks about AI and content moderation; \nAlex Popken was a trust and safety executive at Twitter, leaving in 2023 after \na decade at the social media company focusing on content moderation\nDayton Daily News (Ohio)\nApril 22, 2024 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 919 words\nByline: BARBARA ORTUTAY\nBody\nAlex Popken was a longtime trust and safety executive at Twitter focusing on content moderation before leaving in \n2023. She was the first employee there dedicated to moderating Twitter's advertising business when she started in \n2013.\nNow, she's vice president of trust and safety at WebPurify, a content moderation service provider that works with \nbusinesses to help ensure the content people post on their sites follows the rules. \nSocial media platforms are not the only ones that need policing. Any consumer-facing company  from retailers to \ndating apps to news sites  needs someone to weed out unwanted content, whether that's hate speech, harassment \nor anything illegal. Companies are increasingly using artificial intelligence in their efforts, but Popken notes that \nhumans remain essential to the process. \nPopken spoke recently with The Associated Press. The conversation has been edited for clarity and length. \nQUESTION: How did you see content moderation change in that decade you were at Twitter? \nANSWER: When I joined Twitter, content moderation was in its nascent stages. I think even trust and safety was \nthis concept that people were just starting to understand and grapple with. The need for content moderation \nescalated as we, as platforms saw them be weaponized in new ways. I can sort of recall some key milestones of \nmy tenure at Twitter. For example, Russian interference in the 2016 U.S. presidential election, where we realized \nfor the first time, realized in a meaningful way, that without content moderation we can have bad actors undermining \ndemocracy. The necessity for investing in this area became ever more important. \nQ: A lot of companies, the bigger social media companies are leaning on AI for content moderation. Do you think \nthat AI is in a place yet where it's possible to rely on it? \nA: Effective content moderation is a combination of humans and machines. AI, which has been used in moderation \nfor years, solves for scale. And so you have machine learning models that are trained on different policies and can \ndetect content. But ultimately, let's say you have a machine learning model that is detecting the word 'Nazi.' There \nare a lot of posts that might be criticizing Nazis or providing educational material about Nazis versus like, white \nsupremacy. And so it cannot solve for nuance and context. And that's really where a human layer comes in. \nI do think that we're starting to see really important advancements that are going to make a human's job easier. And \nI think generative AI is a great example of that, where, unlike traditional. AI models, it can understand context and \nInsider Q&A: Trust and safety exec talks about AI and content moderation Alex Popken was a trust and safety \nexecutive at Twitter , leaving in 2023 after a decad....\nnuance much more so than its predecessor. But even still, we have entirely new use cases for our human \nmoderators now around moderating generative AI outputs. And so the need for human moderation will remain for \nthe foreseeable future, in my opinion. \nQ: Can you talk a little bit about the non-social media companies that you work with and what kind of content \nmoderation they use? \nA: I mean, everything from like retail product customization, you know, imagine that you are allowing people to \ncustomize T-shirts, right? Obviously, you want to avoid use cases in which people abuse that and put harmful, \nhateful things on the T-shirt. \nReally, anything that has user-generated content, all the way to online dating  there, you're looking for things like \ncatfishing and scams and ensuring that people are who they say they are and preventing people from uploading \ninappropriate photos for example. It does span multiple industries. \nQ: What about the issues that you're moderating, does that change? \nA: Content moderation is an ever-evolving landscape. And it's influenced by what's happening in the world. It's \ninfluenced by new and evolving technologies. It's influenced by bad actors who will attempt to get on these \nplatforms in new and innovative ways. And so as a content moderation team, you're trying to stay one step ahead \nand anticipate new risks. \nI think that there's a little bit of catastrophic thinking in this role where you think about like, what are the worst case \nscenarios that can happen here. And certainly they evolve. I think misinformation is a great example where there's \nso many facets to misinformation and it's such a hard thing to moderate. It's like boiling the ocean. I mean, you \ncannot fact check every single thing that someone says, right? And so typically platforms need to focus on \nmisinformation not to cause the most real world harm. And that's also always evolving. \nQ: In terms of generative AI there's some doomsday thinking that it will ruin the internet, that it will just be, you \nknow, fake AI stuff on it. Do you feel like that might be happening? \nA: I have concerns around AI-generated misinformation, especially during what is an extremely important election \nseason globally. You know, we actively are seeing more deepfakes and harmful synthetic and manipulated media \nonline, which is concerning because I think the average person probably has a hard time. discerning accurate \nversus not. \nI think medium to long term, if I can be properly regulated and if there are appropriate guardrails around it, I also \nthink that it can create an opportunity for our trust and safety practitioners. I do. Imagine a world in which AI is an \nimportant tool in the tool belt of content moderation, for things like threat intelligence. You know, I think that it's \ngoing to be extremely helpful tool, but it's also going to be misused. And we're we're already seeing that.\nGraphic\n \n(AP Illustration/Jenni Sohn)\nLoad-Date: April 23, 2024"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "National security considerations likely with AI: Sundar Pichai",
        "media": "The Economic Times",
        "time": "May 12, 2023",
        "section": "TECH & INTERNET",
        "length": "631 words",
        "byline": "Dia Rekhi",
        "story_text": "National security considerations likely with AI: Sundar Pichai\nThe Economic Times\nMay 13, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 631 words\nByline: Dia Rekhi\nBody\nGoogle CEO Sundar Pichai said there will be national security considerations with AI and advocated for exercising \ncaution when it comes to the technology on Thursday. Pichai was speaking to journalists a day after the search \ngiant conducted its annual developer conference - the Google I/O - in Mountain View, California where the company \nis headquartered.\"There are going to be national security considerations as we go through an important technology. \nThat has got to be a factor in the mix as well,\" Pichai said. He, however, said that it isn't for geopolitical reasons \nalone that one needs to be safe and responsible with AI or any technology. For instance, he said that a technology \nlike CRISPR (Clustered Regularly Interspaced Short Palindromic Repeats) is important because of how powerful it \ncan be and that the focus should be squarely on what can be done to get it right.Also read | Google to roll out \ngenerative AI chatbot Bard in 180 countries, including IndiaCRISPR is a technology used by research scientists to \nselectively modify the DNA of living organisms. \nCRISPR was adapted for use in the laboratory from naturally occurring genome editing systems found in \nbacteria.Generative AI was certainly one of the focus areas for the company at the I/O, which was clear with the \nnumber of announcements and the sheer volume of conversations surrounding the topic. But throughout, Pichai \nand other top executives of the company kept reiterating the need for 'responsible AI.' This was reflected even in \nthe panel discussion that took place with select media on Thursday.\"We don't want to be in a race, the only race we \nthink about is getting it right,\" Pichai said when asked about whether he was fazed by OpenAI and Microsoft's head \nstart in AI. \"It's (AI) a technology we are committed to boldly innovating, but all through it, approaching it with a deep \nsense of commitment to get it right responsibly.\"He added that AI is an incredibly profound technology that cuts \nacross everything and he felt that one company, like Google, being the most successful across every sector is \nneither feasible nor is it right.Also read | Pixel Fold, PaLM 2, and more AI: Here's everything Google announced at \nI/O 2023\"I think it's (AI) a technology which will touch humanity in deeper ways. And I think it essentially needs to \ninvolve many, many stakeholders. There's going to be a lot of these interesting things to trade off as we think about \nregulation, as we've always had. Safety is important. So you have to get regulation right.\"He believed that AI is \ngoing to be used in numerous areas, including well-established industries too which means there's all the more \nreason for companies to ensure they get it right and strike the perfect balance of innovation and responsibility. He \neven batted for additional regulation in some critical areas.\"Healthcare is heavily regulated so AI is just an \nunderlying technology. We would have to look at it on a case-by-case basis. There will be cases where there is \nadditional regulation needed but I think it's important to approach it with all the stakeholders and get it right.\"Also \nread | Google's AI is coming to more companies near youWith this in mind, Pichai said that he is excited about the \nrole that Google can play in order to provide the most advanced computing infrastructure to anyone who wants it, \nincluding people who will compete with Google - and provide access to its foundation models that will also allow \npeople to fine-tune it and build their own models. \"And finally, we will give high-level APIs so that you can build \napplications on top of it. So I think it's an extraordinary opportunity and really very exciting,\" he said.(The reporter is \nat Mountain View at the invitation of Google) For Reprint Rights: timescontent.com\nNational security considerations likely with AI: Sundar Pichai\nLoad-Date: May 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Will A.I. Boost Productivity? Companies Sure Hope So.",
        "media": "The New York Times",
        "time": "April 3, 2024",
        "section": "BUSINESS; economy",
        "length": "1366 words",
        "byline": "Jordyn Holman and Jeanna Smialek Jordyn Holman is a business reporter for The Times, covering the",
        "story_text": "Will A.I. Boost Productivity? Companies Sure Hope So.\nThe New York Times \nApril 1, 2024 Monday 09:43 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; economy\nLength: 1366 words\nByline: Jordyn Holman and Jeanna Smialek Jordyn Holman is a business reporter for The Times, covering the \nretail industry and consumer behavior. Jeanna Smialek covers the Federal Reserve and the economy for The \nTimes from Washington.\nHighlight: Economists doubt that artificial intelligence is already visible in productivity data. Big companies, \nhowever, talk often about adopting it to improve efficiency.\nBody\nWendy’s menu boards. Ben &amp; Jerry’s grocery store freezers. Abercrombie &amp; Fitch’s marketing. Many \nmainstays of the American customer experience are increasingly powered by artificial intelligence.\nThe question is whether the technology will actually make companies more efficient.\nRapid productivity improvement is the dream for both companies and economic policymakers. If output per hour \nholds steady, firms must either sacrifice profits or raise prices to pay for wage increases or investment projects. But \nwhen firms figure out how to produce more per working hour, it means that they can maintain or expand profits \neven as they pay or invest more. Economies experiencing productivity booms can experience rapid wage gains and \nquick growth without as much risk of rapid inflation.\nBut many economists and officials seem dubious that A.I. — especially generative A.I., which is still in its infancy \n— has spread enough to show up in productivity data already.\nJerome H. Powell, the Federal Reserve chair, recently suggested that A.I. “may” have the potential to increase \nproductivity growth, “but probably not in the short run.” John C. Williams, president of the New York Fed, has made \nsimilar remarks, specifically citing the work of the Northwestern University economist Robert Gordon.\nMr. Gordon has argued that new technologies in recent years, while important, have probably not been \ntransformative enough to give a lasting lift to productivity growth.\n“The enthusiasm about large language models and ChatGPT has gone a bit overboard,” he said in an interview.\nThe last time productivity really picked up, in the 1990s, computer manufacturing was getting a lot more efficient at \nthe same time that computers themselves were making everything else more efficient — allowing for a sector-\nspanning productivity increase. Today’s gains may be less broad, he thinks.\nOther economists are more optimistic. Erik Brynjolfsson at Stanford University has bet Mr. Gordon $400 that \nproductivity will take off this decade. His optimism is based partly on A.I. He ran an experiment with it at a large call \ncenter, where it especially helped less experienced workers, and has co-founded a company meant to teach firms \nhow to leverage the technology.\nWill A.I. Boost Productivity? Companies Sure Hope So.\nMany companies seem to be in Mr. Brynjolfsson’s camp, hopeful that the shiny new tool will revolutionize their \nworkplaces. Companies are using A.I. and generative A.I. for everything from writing marketing emails to helping \nset prices to answering employees’ human resources and legal questions.\nHere are a few areas where companies say the latest A.I. technology is being used in ways that could influence \nproductivity, pulled from interviews, earnings calls and financial filings.\nGot an annoying task? There’s an A.I. for that.\nEmployees spend a lot of time trying to figure out human-resources-related questions. Companies have been \ninvesting in generative A.I. to help answer those queries more quickly.\nAt Walmart, the largest retailer in the United States, with 1.6 million workers, the company’s employee app has a \nsection called “My Assistant,” which is backed by generative A.I. The feature uses the technology to quickly \nanswer questions like “Do I have dental coverage?,” summarize meeting notes and help write job descriptions.\nWalmart rolled out the technology to its U.S. corporate work force last year. \nThe retailer has been clear that the tool is meant to boost productivity. In an interview last year, Donna Morris, \nWalmart’s chief people officer, said one of the goals was to eliminate some mundane work so employees could \nfocus on tasks that had more impact. It’s expected to be a “huge productivity lift” for the company, she said.\nThe algorithms want to sell you things.\nTony Spring, Macy’s chief executive, said the department-store chain was experimenting with A.I. to tailor its \nmarketing. The company is using generative A.I. to write elements of emails, and is exploring ways to use the \ntechnology to add product descriptions online and to replicate images of outfits or other products for sale over new \nbackgrounds.\n“It’s certainly showing up as a tool for some colleagues to reduce workload,” Mr. Spring said in an interview.\nAbercrombie &amp; Fitch is using generative A.I. to help design clothes and write descriptions for its website and \napp. Designers use Midjourney, an A.I. graphics program, to help them generate images as they brainstorm \nclothing ideas. Workers in Abercrombie’s marketing department also use generative A.I. to help write the blurbs for \nproducts’ descriptions. (Employees later edit the copy.)\nSamir Desai, Abercrombie &amp; Fitch’s chief digital officer, said the technology helped speed up a laborious \nprocess, given that Abercrombie and its brands could post a couple of hundred new products on its website in a \nsingle week.\n“I think right now it’s a lot of trust and belief that these are productivity enhancers, efficiency boosters,” Mr. Desai \nsaid, noting that it was difficult to quantify how much time and money was being saved. “I think we’ll start to see that \nmanifest itself in just how much work certain teams are able to get through versus the prior years.”\nA.I. pairs well with burgers and ice cream.\nSome companies are hoping to use the latest A.I. technology to help match prices to demand, somewhat like the \nway that Uber sets prices for cars based on how many people want to ride.\nWendy’s, for instance, has floated the idea of using A.I. to identify slower times of the day and discount the prices of \nmenu items on its digital boards.\nThe technology could also help with inventory management. Ben &amp; Jerry’s put cameras that use A.I. into the \nfreezers at grocery stores to help alert the company when a location was running low on pints of Cherry Garcia or \nChunky Monkey. The camera sporadically captures an image of the freezer shelves, and the technology assesses \nthe quantity that’s left, sending alerts to Ben &amp; Jerry’s parent company and its distributors.\nWill A.I. Boost Productivity? Companies Sure Hope So.\n“The software identifies what is about to run out and also helps plan the most efficient routes for trucks that can \nrestock the inventory,” Catherine Reynolds, a spokeswoman for Unilever, the parent of Ben &amp; Jerry’s, said in a \nstatement.\nThe A.I. technology is installed in 8,000 freezers, and the company said it planned to significantly increase that \nnumber this year. On average, freezers with the A.I. technology increased sales 13 percent because they were \nreplenished with fresh pints of ice cream, particularly the most in-demand flavors, Ms. Reynolds said.\nA.I. is getting into the weeds.\nDeere, the maker of farm equipment, has been using A.I. alongside cameras to improve herbicide sprayers. The \nequipment recognizes and targets weeds specifically, allowing for more precise use of chemicals. The technology \nwas introduced in 2022, and the company estimates that it covered 100 million acres and saved eight million \ngallons of herbicide last year.\nThe technology can allow “customers to reduce their herbicide use, lower their costs and minimize impact on their \ncrops and land,” John C. May II, the firm’s chief executive, said at a news conference in February.\nAre these game-changing improvements?\nSkepticism of A.I.’s potential for major change is based largely on the fact that many of its applications mimic things \nsoftware can already do: There are clear improvements, but not necessarily game-changing ones.\nBut while it could take time for companies to fully harness A.I. tools, the fact that the applications are potentially so \nbroad has made some economists optimistic about what the new technologies could mean for productivity growth.\nAnalysts at Vanguard think that A.I. could be “transformative” to the U.S. economy in the second half of the 2020s, \nsaid Joseph Davis, the financial firm’s global chief economist. He said the technology could save workers \nmeaningful time — perhaps 20 percent — in about 80 percent of occupations.\n“We’re not seeing it in the data yet,” he said, explaining that he thinks that a recent pickup in productivity has been \nmore of a snapback from a steep drop-off during the pandemic. “The good news is that there’s another wave \ncoming.”\nThis article appeared in print on page B1, B4.\nLoad-Date: April 3, 2024"
    },
    {
        "file_name": "FEDERAL_AI_GUIDELINES_Nov2023",
        "header": "KNOWING THE RISKS; CARNEGIE MELLON EXPERTS WEIGH IN ON",
        "media": "FEDERAL AI GUIDELINES",
        "time": "November 4, 2023",
        "section": "BUSINESS; Pg. A-10",
        "length": "875 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "KNOWING THE RISKS; CARNEGIE MELLON EXPERTS WEIGH IN ON \nFEDERAL AI GUIDELINES\nPittsburgh Post-Gazette\nNovember 4, 2023 Saturday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-10\nLength: 875 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nPresident Joe Biden signed an artificial intelligence executive order on Monday, marking the nation's largest \nattempt to rein in a technology that has sparked fear and hype as it finds its way into a sprawling number of real \nworld applications.\nThe executive order lists guiding principles for legislators and government agencies who will be responsible for \ncrafting rules that govern the industry - a process that has already begun with engagement from Carnegie Mellon \nUniversity's Block Center for Technology and Society.\nThought leaders from the center have given congressional testimony and held summer meetings with government \nofficials, companies and other stakeholders on issues addressed in the executive order, which seeks transparency \nfrom companies that are developing AI technologies that could threaten national security. Developers must perform \nsafety tests and share those results with the government, the document says.\nAnother goal is to make it obvious when content is made using AI.\nThe U.S. Department of Commerce will create standards that companies like Google and OpenAI could use to label \nAI-generated images, text and audio.\nRamayya Krishnan, the Block Center's faculty director and dean of CMU's Heinz College, called the presidential \norder a \"comprehensive\" first step.\n\"The commitments on AI safety, security and reliability are the strongest I have seen globally,\" he said. \"I look \nforward to rule making to follow as well as legislation from Congress aligned with the themes highlighted in this \norder. It is essential for both our economic and national security.\"\nMr. Biden's order came days before tech executives and government leaders gathered in Britain for an international \nsummit. The European Union is expected to finalize an AI regulation package by the end of the year that would \nrequire generative AI systems like ChatGPT to be reviewed before commercial release.\nSimilar to an executive order signed by Pennsylvania Gov. Josh Shapiro in September, Mr. Biden's order leverages \nthe government's role as a top purchaser of AI products to push developers in a safer direction.\nIt will require testing for several safety thresholds - thresholds likely to be set by the National Institute of Standards \nand Technology, which first released a framework for managing the risks of AI in January.\nCongress is still in the early stages of crafting bipartisan legislation to respond to AI.\nKNOWING THE RISKS CARNEGIE MELLON EXPERTS WEIGH IN ON FEDERAL AI GUIDELINES\nThe White House first announced plans for the executive order in July. Two months later it brokered a set of \nvoluntary commitments agreed to by 15 companies, including Google and OpenAI, which made ChatGPT.\nIt's no coincidence that Mr. Biden unveiled his policy days before the international safety summit in Britain, Mr. \nKrishnan said.\n\"We are as much in a technology innovation competition as much as we are in a public policy race related to AI,\" he \nsaid.\nMr. Krishnan is part of Mr. Biden's national AI advisory committee, a 25-member group composed of academics \nand company executives appointed to serve through 2025.\nMr. Biden's order also includes efforts to build a domestic workforce of AI expertise.\nSilicon Valley has been pushing for years for better talent-based immigration. The government allots 65,000 H-1B \nvisas each year to skilled workers who can work in the U.S. for up to 6 years.\nEarlier last month, the Department of Homeland Security proposed changes that would help streamline H-1B \napplications without increasing the number of slots. About 1 in 10 applicants are accepted through the H-1B lottery \nsystem.\nWithout a strong talent base, it will also be impossible for lawmakers to understand the tools they seek to regulate, \nMr. Krishnan said.\nIn the meantime, he said, some safety steps can still be taken.\nAI models should have transparent guides akin to food nutrition labels, so that users understand how the models \nhave been trained, Mr. Krishnan said - a point he raised this summer in Congressional testimony.\nThe Block Center is also helping industries create guidelines for individual AI use cases. It will release a report in \nthe next few weeks on \"operationalizing AI\" across various sectors.\nUsing AI in hiring is a different application from healthcare as it is from autonomous vehicles, said Steve Wray, \nBlock Center's executive director.\n\"That's where it actually becomes a mechanism for an outcome,\" he said.\nThe main takeaway from the forthcoming report is that \"there haven't been firm decisions,\" Mr. Wray said. \"People \nare still working to understand the risks.\"\nMr. Krishnan said some regulators believe use cases like crowd-based facial recognition and autonomous weapon \nsystems should be banned outright. (The EU AI Act seeks to ban real-time facial recognition.)\nAs risk matrices are constructed, those might be deemed \"an unacceptable risk,\" whereas autonomous vehicles \nmight be acceptable within reason.\nBut even autonomous vehicles are raising alarm bells.\nA week before Mr. Biden's order, the California Department of Motor Vehicles barred Cruise from testing its \ndriverless taxis in San Francisco, following a gruesome pedestrian accident earlier in the month. The DMV \ndetermined that the vehicles \"are not safe for the public's operation.\"\nEvan Robinson-Johnson: ejohnson@post-gazette.com or @sightsonwheels\nGraphic\nKNOWING THE RISKS CARNEGIE MELLON EXPERTS WEIGH IN ON FEDERAL AI GUIDELINES\n \nPHOTO: Kin Cheung/Associated Press: Vice President Kamala Harris waves Wednesday before delivering a policy \nspeech on the Biden-Harris Administration's vision for the future of Artificial Intelligence (AI), at the U.S. Embassy in \nLondon.\nPHOTO: Manuel Balce Ceneta/Associated Press: President Joe Biden on Monday, Oct. 30, signed a sweeping \nexecutive order to guide the development of artificial intelligence. The order will require industry to develop safety \nand security standards, introduce new consumer protections and give federal agencies an extensive to-do list to \noversee the rapidly progressing technology.\nLoad-Date: November 4, 2023"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "OpenAI losses nearly double to $540 million as costs build: Report",
        "media": "The Economic Times",
        "time": "May 5, 2023",
        "section": "TECH & INTERNET",
        "length": "366 words",
        "byline": " ",
        "story_text": "OpenAI losses nearly double to $540 million as costs build: Report\nThe Economic Times\nMay 6, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 366 words\nBody\nMicrosoft-backed generative artificial intelligence (AI) platform OpenAI's losses nearly doubled to $540 million \nlast year as the startup worked on ChatGPT for which it had to hire key employees from Google, US-based tech \npublication The Information reported citing sources.There are also steep costs involved in developing large \nlanguage models (LLMs) and training them, which form the backbone of ChatGPT, a generative chatbot.OpenAI \nlaunched ChatGPT last November, which has since taken the tech world by storm with major IT players hopping on \nthe generative AI bandwagon.Also read | TCS to harness vast data troves to build ChatGPT-like generative AI \ntech\"Even as revenue has picked up, reaching an annual pace of hundreds of millions of dollars just weeks after \nOpenAI launched a paid version of the chatbot in February, costs are likely to keep rising as more customers use its \nAI technology and the company trains future versions of the software,\" the report said.Despite revenue growth from \npaying customers, costs are expected to surge as LLMs need continuous training to keep up with queries being fed \nby users, it noted.Microsoft has invested about $10 billion in OpenAI since 2019. OpenAI founder Sam Altman has \nreportedly suggested that the venture will be \"the most capital-intensive in the history of Silicon Valley\" and might \nrequire fundraising of about $100 billion.\"The San Francisco company's recent pace of revenue means it is likely to \nexceed a projection it made last year that 2023 revenue would jump to $200 million. \nIn 2022, by comparison, revenue was just $28 million, mainly from selling access to its AI software - the same kind \nthat later powered ChatGPT - to app developers,\" the report stated.In addition, Microsoft will also be eyeing a \nsizeable portion of these revenues after it \"previously negotiated rights to 75% of OpenAI's future profits until its \nprincipal investment is paid back and 49% of profits after that until it hits a theoretical cap\". Further, Microsoft has \nobtained the rights to resell OpenAI's software to its own customers through Azure and use it for its search engine \nBing and apps like Word and Outlook. For Reprint Rights: timescontent.com\nLoad-Date: May 5, 2023"
    },
    {
        "file_name": "The_Economic_Times_Sep2023",
        "header": "Reliance partners with Nvidia for developing AI infra in India",
        "media": "The Economic Times",
        "time": "September 8, 2023",
        "section": "ELECTRONICS",
        "length": "282 words",
        "byline": " ",
        "story_text": "Reliance partners with Nvidia for developing AI infra in India\nThe Economic Times\nSeptember 9, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ELECTRONICS\nLength: 282 words\nBody\nMukesh Ambani-owned Reliance Industries has tied up with US-based chipmaker Nvidia to develop India's own \nfoundation large language model trained on the south Asian country's diverse languages and tailored for \ngenerative AI applications.In a statement, Nvidia said that it will work with Reliance to build AI infrastructure. The \nchip maker will provide access to its GH200 Grace Hopper Superchip and DGX Cloud.\"As India advances from a \ncountry of data proliferation to creating technology infrastructure for widespread and accelerated growth, computing \nand technology super centres like the one we envisage with Nvidia will provide the catalytic growth just like Jio did \nto our nation's digital march,\" said Mukesh Ambani, chairman and managing director of Reliance Industries.Nvidia's \nAI infrastructure will help Reliance build AI applications and services. \n\"The Nvidia-powered AI infrastructure is the foundation of the new frontier into AI for Reliance Jio Infocomm,\" \nNvidia's statement read.Earlier today, news agency Reuters reported the RIL is exploring a foray into \nsemiconductor manufacturing, a move that could address its supply chain needs and cater to growing chip demand \nin India.The telecoms-to-energy conglomerate, encouraged by the Indian government, has held early-stage talks \nwith foreign chipmakers that have the potential to become technology partners, it said citing sources.\"India has \nscale, data and talent. With the most advanced AI computing infrastructure, Reliance can build its own large \nlanguage models that power generative AI applications made in India, for the people of India,\" said Jensen Huang, \nfounder and CEO of Nvidia. For Reprint Rights: timescontent.com\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jan2023",
        "header": "Building Trust With Robots",
        "media": "Economic Times (E-Paper Edition)",
        "time": "January 22, 2023",
        "section": "THE EDIT PAGE",
        "length": "830 words",
        "byline": "Anil Nair",
        "story_text": "Building Trust With Robots\nEconomic Times (E-Paper Edition)\nJanuary 23, 2023 Monday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: THE EDIT PAGE\nLength: 830 words\nByline: Anil Nair\nHighlight: Two experts and one AI weigh in on the dangers of generative artificial intelligence tools\nBody\nMASALA OR PAPDI CHATGPT?\nGenerative AI has grabbed the attention of academics, industry and policymakers like never before. Investors are \nalso keenly eyeing this space, and homing in ahead of the curve on technologies capable of generating trillions of \ndollars of potential value. Generative AI programs DALL-E, Midjourney and NightCafe Creator can be word-\nprompted to produce pictures and artworks of people, things, places and scenes. Ryter, Shortly and Writesonic can \nwrite essays. \nGoogle Verse by Verse can create poetry in the style of famous poets. LyricJam or These Lyrics Do Not Exist can \ngenerate song lyrics. Melobytes, Soundraw and Jukebox can produce music, replicating the styles of masters or \ngenerating vocals with modern tunes. Google's Wordcraft Writers Workshop, leverages LaMDA (Language Model \nfor Dialogue Applications) to create stories on the basis of user prompts, and can enhance it in terms of a twist in \nthe tale, the personality of characters or nuanced conversations. Imagen Video can stitch together hires images to \ncreate videos, and Dream Fusion creates 3D models from 2D images.  Microsoft's GitHub Copilot, built on OpenAI's \nCodex AI, trans-  lates human language into complex programming code. Its Project Bonsai with d-Matrix leverages \nneural networks for industrial controls, chip design and manufacturing. And reportedly, there's a plan to embed \nOpenAI's ChatGPT in Word, Powerpoint, Outlook and Azure to completely change the realms of organisational \nproductivity. In 1973, Herbert A Simon and William G Chase, in their paper 'Skill in Chess' (bit.ly/3GWHx20) \npublished in American Scientist, estimated that a chess grandmaster spends 10,000-50,000 hours studying chess \npositions before becoming a grandmaster. Many researchers later arrived at the same conclusion — that expertise \nhas to be preceded by practice, whether in sport or surgery. Malcom Gladwell, in his 2008 book Outliers: The Story \nof Success came out with his '10,000-hour rule' which posits that innate talent must be topped up by long and \nlaborious hours of  preparation to achieve success.  Generative AI is signalling that  the age of experts is over. \nStudents can now produce quality essays without doing first-hand research. Project that a few years into the future, \nand the entire education system changing, whether it be teachers, teaching methods, or grading. Design firms, \ncontent providers, advertising agencies, publishing houses, film companies, media outfits, BPOs, and those offering \nIT, legal and financial services had better watch their flanks. A crucial concern with generative AI bots is \nmisinformation. A generative AI model trained on a dataset of fake news articles will generate creative fake news \nindistinguishable from real news. These systems could also be used to engineer social media attacks or create \ndeepfake videos to manipulate public opinion. OpenAI, while progressively refining its product, has explicitly warned \nChatGPT users that it 'may occasionally generate incorrect information and produce harmful instructions or biased \ncontent.' Expect scammers to use vulnerable tools to access unauthorised content, poison critical data, corrupt \nsafety-critical applications, create near authentic phishing mails and write malicious code. When Netskope Threat \nLabs probed ChatGPT about malware development, it gave precise explanations about techniques used. The \nBuilding Trust With Robots\nchilling reality is that if humans ever sought to fight this using only their innate strengths, it would be an unequal \nbattle. Five years ago, Microsoft's homegrown AI chatbot Tay was hastily withdrawn 16 hours after launch, after it \nstarted spewing venom and filthy language. Meta, in September 2022, announced the launch of Galactica trained \non 48 million papers, textbooks and lecture notes, scientific information and encyclopedias to better organise \nscientific knowledge. Days after launch, Meta withdrew Galactica, because users found the information suspicious \nand highly inaccurate. Generative AI bots put together words picked up from its vast database, with no intelligence \njust yet to figure factual correctness. Transparency and accountability can mitigate risks associated with generative \nAI bots.  Training data, algorithms, and the output from these systems should be publicly available, so anyone can \nassess their quality and accuracy. User organisations should be held accountable for negative consequences \narising from their use. The development of robust metrics, allowing for objective evaluation of the quality and \naccuracy of the output generated, will promote trust in generative AI bots. This would also make it easier to identify \nand flag biased, misleading, or problematic content.  Generative AI bots are not inherently good or evil. They are \njust tools that can be used for positive or negative purposes. It's time to figure out how to embed a conscience in \ngenerative AI. The writer is founder, Thinkstreet.Inputs from ChatGPT have been used for this article\nLoad-Date: January 22, 2023"
    },
    {
        "file_name": "Technology_Mar2024",
        "header": "China’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S.",
        "media": "Technology",
        "time": "March 3, 2024",
        "section": "TECHNOLOGY",
        "length": "1464 words",
        "byline": "Paul Mozur, John Liu and Cade Metz Paul Mozur is the global technology correspondent for The Times,",
        "story_text": "China’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. \nTechnology\nThe New York Times \nFebruary 21, 2024 Wednesday 09:13 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1464 words\nByline: Paul Mozur, John Liu and Cade Metz Paul Mozur is the global technology correspondent for The Times, \nbased in Taipei. Previously he wrote about technology and politics in Asia from Hong Kong, Shanghai and Seoul. \nJohn Liu covers China and technology for The Times, focusing primarily on the interplay between politics and \ntechnology supply chains. He is based in Seoul. Cade Metz writes about artificial intelligence, driverless cars, \nrobotics, virtual reality and other emerging areas of technology.\nHighlight: China’s tech firms were caught off guard by breakthroughs in generative artificial intelligence. \nBeijing’s regulations and a sagging economy aren’t helping.\nBody\nChina’s tech firms were caught off guard by breakthroughs in generative artificial intelligence. Beijing’s \nregulations and a sagging economy aren’t helping.\nIn November, a year after ChatGPT’s release, a relatively unknown Chinese start-up leaped to the top of a \nleaderboard that judged the abilities of open-source artificial intelligence systems.\nThe Chinese firm, 01.AI, was only eight months old but had deep-pocketed backers and a $1 billion valuation and \nwas founded by a well-known investor and technologist, Kai-Fu Lee. In interviews, Mr. Lee presented his A.I. \nsystem as an alternative to options like Meta’s generative A.I. model, called LLaMA.\nThere was just one twist: Some of the technology in 01.AI’s system came from LLaMA. Mr. Lee’s start-up then built \non Meta’s technology, training its system with new data to make it more powerful.\nThe situation is emblematic of a reality that many in China openly admit. Even as the country races to build \ngenerative A.I., Chinese companies are relying almost entirely on underlying systems from the United States. \nChina now lags the United States in generative A.I. by at least a year and may be falling further behind, according \nto more than a dozen tech industry insiders and leading engineers, setting the stage for a new phase in the \ncutthroat technological competition between the two nations that some have likened to a cold war.\n“Chinese companies are under tremendous pressure to keep abreast of U.S. innovations,” said Chris Nicholson, an \ninvestor with the venture capital firm Page One Ventures who focuses on A.I. technologies. The release of \nChatGPT was “yet another Sputnik moment that China felt it had to respond to.”\nJenny Xiao, a partner at Leonis Capital, an investment firm that focuses on A.I.-powered companies, said the A.I. \nmodels that Chinese companies build from scratch “aren’t very good,” leading to many Chinese firms often using \n“fine-tuned versions of Western models.” She estimated China was two to three years behind the United States in \ngenerative A.I. developments.\nChina’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. Technology\nThe jockeying for A.I. primacy has huge implications. Breakthroughs in generative A.I. could tip the global \ntechnological balance of power, increasing people’s productivity, aiding industries and leading to future innovations, \neven as nations struggle with the technology’s risks.\nAs Chinese firms aim to catch up by turning to open-source A.I. models from the United States, Washington is in a \ndifficult spot. Even as the United States has tried to slow China’s advancements by limiting the sale of microchips \nand curbing investments, it has not held back the practice of openly releasing software to encourage its adoption.\nFor China, the newfound reliance on A.I. systems from the United States — primarily Meta’s LLaMA — has fueled \ndeeper questions about the country’s innovation model, which in recent decades surprised many by turning out \nworld-beating firms like Alibaba and ByteDance despite Beijing’s authoritarian controls.\n“When Chinese companies are leveraging American open-source technologies to play catch-up, the questions \nbecome very complicated — wrapped up in issues of national security and geopolitics,” said Oren Etzioni, a \nUniversity of Washington professor who specializes in A.I. and the founder of TrueMedia.org, a nonprofit working to \nidentify disinformation online in political campaigns.\nIn an emailed statement, Mr. Lee, 01.AI’s founder, said his startup’s A.I. model was built on LLaMA just “like most \nother A.I. companies,” adding that using open-source technologies is a standard practice. He said his company had \ntrained its A.I. model from scratch, using its own data and algorithms. Those were “the main determinants” of the \n“excellent performance” of 01.AI’s model, Mr. Lee said.\nMeta pointed to comments by Nick Clegg, who leads global affairs, in which he said openly sharing the company’s \nA.I. models helped spread its values and standards, and in turn helped secure American leadership.\n(The New York Times has sued the maker of ChatGPT, OpenAI and its partner, Microsoft, for copyright \ninfringement of news content related to A.I. systems.)\nA.I. has long been a priority in China. After the A.I. tool AlphaGo defeated two top players of the board game Go in \n2016 and 2017, Chinese policymakers set out an ambitious plan to lead the world in technology by 2030. The \ngovernment pledged billions to researchers and companies focused on A.I.\nWhen OpenAI released ChatGPT in November 2022, many Chinese firms were being hamstrung by a regulatory \ncrackdown from Beijing that discouraged experimentation without government approval. Chinese tech companies \nwere also burdened by censorship rules designed to manage public opinion and mute major opposition to the \nChinese Communist Party.\nChinese companies with the resources to build a generative A.I. model faced a dilemma. If they created a chatbot \nthat said the wrong thing, its makers would pay the price. And no one could be sure what might tumble out of a \nchatbot’s digital mouth.\n“It’s just not possible to get rid of all the problematic ways these systems can express themselves,” said Andrew Ng, \nwho teaches computer science at Stanford and was a former executive at Baidu, the Chinese search giant.\nChinese tech giants were also grappling with new regulations that dictate how A.I. models could be trained. The \nrules limit the data sets that could be used to train A.I. models and the applications that were acceptable, and also \nset requirements for registering A.I. models with the government.\n“It is both more difficult and more risky to innovate in generative A.I. in the current regulatory regime, which is still a \nmoving target,” said Kevin Xu, the U.S.-based founder of Interconnected Capital, a hedge fund that invests in A.I. \nventures.\nTech investors in China have also pushed for quick turnarounds from A.I., which has meant money has flowed to \neasy-to-execute applications instead of more ambitious goals focused on fundamental research, said Yiran Chen, a \nJohn Cocke Distinguished Professor of Electrical and Computer Engineering at Duke University. As much as 50 \nChina’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. Technology\npercent of China’s A.I. investment has gone into computer vision technology, which is required for surveillance, \ninstead of building foundation models for generative A.I., he said.\nNow Baidu, Alibaba, the dairy company Mengniu and the tutoring firm TAL Education have all jumped into the \ngenerative A.I. race in China, leading Chinese media to coin the phrase “the battle of 100 models” to describe the \nfrenzy.\nSome have criticized the free-for-all as publicity stunts that add unnecessary competition. In a panel discussion last \nyear, Robin Li, Baidu’s chief executive, described having hundreds of basic A.I. models as a waste.\n“More resources should be allocated to applications in various industries, especially considering the limitations on \nour computing power,” he said.\nSuccess has been elusive. When Baidu introduced its chatbot, Ernie, in March, the “live” demonstration was \nrevealed to be prerecorded. Baidu’s stock plummeted 10 percent that day.\nDespite the setback, Baidu remains one of China’s few major efforts at building a foundation A.I. model from \nscratch. Others are being led by Alibaba and Tencent, China’s tech giants, as well as a start-up linked to Tsinghua \nUniversity.\nA Baidu spokesman declined to comment.\nU.S. restrictions on A.I. chip sales to China pose further challenges, since many such chips are needed when \ntraining generative A.I. models. Baidu and 01.AI, among others, have said they’ve stockpiled enough chips to \nsustain their operations in the near future.\nThere are some bright spots for China with A.I., including in fields like computer vision and autonomous vehicles. \nSome Chinese entrepreneurs are also looking to leapfrog the United States with breakthroughs in other parts of \ngenerative A.I.\nWang Changhu, the former head of ByteDance’s A.I. lab, founded a company called AIsphere in Beijing last year to \nspearhead what he saw as the next major frontier in the technology: video generation. In November, the start-up \nreleased PixVerse, an A.I.-powered generator that can create video from a text description.\n“We forged ahead, building our models from the ground up,” Mr. Wang said. “This gives us a significant edge as \ntrue pioneers in the realm of video generation.”\nThat edge may have lasted just a few months. Last week, OpenAI unveiled Sora, an A.I. tool that turns a simple text \nprompt into videos that look as if they were lifted from a Hollywood movie. Sora instantly went viral.\nPHOTO: The Chinese firm 01.AI was founded by technologist Kai-Fu Lee, left. It was built on Meta’s technology, \nbut trained with new data to make it powerful. (PHOTOGRAPH BY YAN CONG FOR THE NEW YORK TIMES) \n(B4) This article appeared in print on page B1, B4.\nLoad-Date: March 3, 2024"
    },
    {
        "file_name": "generative_AI_May2023",
        "header": "Wipro expands Google Cloud partnership to advance enterprise adoption of",
        "media": "generative AI",
        "time": "May 23, 2023",
        "section": "ITES",
        "length": "519 words",
        "byline": " ",
        "story_text": "Wipro expands Google Cloud partnership to advance enterprise adoption of \ngenerative AI\nThe Economic Times\nMay 24, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 519 words\nBody\nTechnology services and consulting company, Wipro on Tuesday announced an expanded partnership with Google \nCloud to bring its generative artificial intelligence (AI) capabilities to clients across the globe. Wipro said it will \nintegrate Google Cloud's full suite of generative AI products and services-including Vertex AI, Generative AI App \nBuilder, and the Model Garden collection of foundation models-with its own AI intellectual property (IP), business \naccelerators, and pre-built industry solutions. As part of the partnership expansion, Wipro will also train 20,000 \nassociates on Google Cloud's generative AI technologies. \n\"Generative AI offers incredible opportunities ahead,\" said Thierry Delaporte, CEO and Managing Director, Wipro \nsaid in a statement. \"Expanding our partnership with Google Cloud allows us to help our clients accelerate the \nadoption of this technology - safely, securely, and responsibly. We are investing in skills as well as new capabilities \nin this area, so that Wipro can define and drive our clients' AI-led transformation. This expanded partnership with \nGoogle Cloud is an important step in that direction.\"With Google Cloud, Wipro said it will build and deploy new \ngenerative AI solutions to help enterprises tackle unique industry challenges, while also improving common \nenterprise functions such as consumer experiences, marketing, supply chain performance, financial modeling, \nworkforce management, and sustainability. As part of the partnership, Wipro will build generative AI as a core \nsolution within its set of consulting services, which include digital marketing, customer experience and design \nthinking, and financial services, as well as within its global innovation labs (Lab45). Additionally, Wipro will leverage \nits crowdsourcing platform, Topcoder, to build and scale solutions that address client challenges. \"Wipro has helped \nsome of the world's largest companies transform their businesses with our technology, and their investments in our \ngenerative AI capabilities has the potential to deliver new levels of innovation for customers,\" said Thomas Kurian, \nCEO, Google Cloud. \"Through our expanded partnership, Wipro and Google Cloud will use generative AI to solve \nsome of the biggest challenges businesses are facing today, safely and securely.\"Wipro said its AI Centers of \nExcellence in Bangalore, London, New Jersey, Dallas, and Mountain View will be open to clients looking to explore \nuse cases for generative AI and develop individualized generative AI strategies. \"Generative AI will also become \na core technology within the Wipro FullStride Cloud Studio, helping accelerate cloud strategy and adoption and \nfurther advancing Wipro's support for the Google Cloud Rapid Migration Program (RaMP),\" it said. \"Wipro has been \ninvesting for more than two years in a Generative AI Center of Excellence, doing research with leading academic \ninstitutions, building accelerators and frameworks like WeGA (Wipro Enterprise Generative AI), developing \ncompetency through Wipro AI Academy, and executing key pilot programs for clients.\" For Reprint Rights: \ntimescontent.com\nLoad-Date: May 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "How to Use A.I. for Family Time",
        "media": "The New York Times",
        "time": "July 11, 2023",
        "section": "TECHNOLOGY",
        "length": "964 words",
        "byline": " ",
        "story_text": "How to Use A.I. for Family Time\nThe New York Times \nJuly 7, 2023 Friday 13:32 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 964 words\nHighlight: Plan meals, find gifts and create stories using generative A.I.\nBody\nPlan meals, find gifts and create stories using generative A.I.\nHello! We’re back with another bonus edition of On Tech: A.I., a pop-up newsletter that teaches you about artificial \nintelligence, how it works and how to use it.\nLast week, I walked you through how to turn artificial intelligence into a tutor and research assistant. In the final \ninstallment of our how-to editions, we’ll take what we’ve learned and use it to make the most of family time.\nWe’ll focus on a few tasks that can take up a lot of mental bandwidth at home. Weekly meal planning is a major \nchore, and gift giving can be daunting, with various birthdays and holidays throughout the year. And any adult who \nhas read books for children knows that it can become repetitive, and the books aren’t always relatable to a child’s \nsituation or growing pains.\nHere’s how A.I. can help.\nMeal plans\nFoodies and private chefs have been enthusiastically using A.I. to sketch out comprehensive meal plans that \nconsider people’s preferences and dietary restrictions. (Cooks are less gung ho about A.I.-generated recipes, which \ncan be a disaster if a bot screws up.)\nIt turns out that brainstorming meals is a borderline superpower for a chatbot like ChatGPT or Bing. As always, the \nmore detailed you are with your requests, the better. For example, a private chef posting on Reddit shared an \nexample of a prompt asking for a three-day meal plan for a diabetic vegan with a nut allergy.\nI asked ChatGPT for a meal plan formatted in a printer-friendly chart that can be stuck on the refrigerator. Here is \nmy prompt:\nAct as a private chef. I have a family of two, me and my wife. Plan meals for us for five days, including breakfast, \nsnacks, lunch and dinner. We like Chinese, Japanese, Thai and Italian food. I like meat; my wife prefers chicken \nand seafood. We have no restrictions. We are trying to shed a few pounds after the pandemic.\nThe chatbot came up with this:\nGenerative A.I. often produces different results from the same prompt. If you want to shuffle the deck and get \nslightly different menu suggestions, you can always enter the prompt again. And by all means, tweak the \ninstructions for different results.\nHow to Use A.I. for Family Time\nWhat about the actual recipes to make these dishes? I followed up with this prompt: “Can you find recipes for all of \nthose meal suggestions? Please include a link to the recipes online so I can check the source.”\nChatGPT responded with a long list of recipes from sites including The Food Network, BBC, and a number of \nspecialist food blogs.\n(The subscriber-only version with GPT-4 produced the best results here; the free version with GPT-3 returned some \nbroken links, presumably because its training data is older. Microsoft’s Bing’s chatbot is also good at this type of \nquery, but Google’s Bard bot declined to return specific links to recipes.)\nOne last trick: Ask your bot to compile a list of ingredients for all the recipes. It can even group them by grocery \nstore aisle.\nAs always, to play it safe, double check the recipes to make sure your bot isn’t hallucinating.\nGifts\nLet’s move on to gift giving — a talent that some of us possess more than others. There are several A.I. tools that \naim to make selecting a gift easier, including a website that comes up with gift ideas based on someone’s \nInstagram profile.\nI preferred DreamGift, which uses a chatbot to ask you a series of questions about your gift recipient’s age, gender, \ninterests and hobbies, along with how much you’re willing to spend, and automatically provides ideas and links to \norder the items online. (My wife confessed that she liked some of the bot’s gift suggestions, which included an \nindoor herb-growing kit, more than some of the gifts I’d given her over the years. Ouch.)\nIf you prefer to use a chatbot, that will work, too. Bing and Bard, which are connected to search engines, are \npowerful shopping assistants. The trick to getting bespoke recommendations is to share voluminous details about \nyour budget and the people you’re shopping for.\nStorytelling\nLet’s end with something more creative. You can use A.I. to create a customized bedtime story or even your own \nhard-copy children’s book.\nGive a chatbot like ChatGPT or Bard a detailed prompt that includes your child’s preferred storytelling style, any \ndetails you’d like to include and the situation that you want the story to address. Here’s a prompt I wrote for a \nhypothetical child who is unhappy about moving to a new home. I asked it to involve some familiar characters:\nAct as a children’s book writer, mimicking “Frog and Toad.” My kid is going through a rough time — we are moving \nto a new home and changing schools. Write a story to help him process that. Incorporate our dogs, Max and Mochi \nthe corgis, as characters.\nThe chatbot generated a heartfelt story about Max and Mochi, a pair of furry siblings. They enjoyed playing in the \npark and were sad to move to a new home. But they supported each other and eventually went to a new school, \nwhere they made new friends: Bella the sprightly Beagle and Charlie the cheeky Chihuahua. Everything worked out \nin the end.\nIf you’re feeling extra ambitious, you can generate illustrations to accompany the text. (We covered image \ngenerators in an earlier newsletter.) I asked Midjourney to produce an illustration for a children’s book of two corgis \nplaying in a park together.\nTo produce a full book, I’d ask Midjourney to generate images to accompany each paragraph of the chatbot’s story. \nThen I’d use a photo service that offers a book option, such as Google Photos or Shutterfly, to have the custom-\nmade children’s book printed and shipped to me.\nHow to Use A.I. for Family Time\nThank you for being a subscriber\nWe want to hear from you. You can reach us at ontech@nytimes.com.\nBrowse all of our subscriber-only newsletters here.\nThis article appeared in print on page B2.\nLoad-Date: July 11, 2023"
    },
    {
        "file_name": "New_York_Observer_Mar2023",
        "header": "OpenAI's Bets on Tech Startups Hint At the Future of Artificial Intelligence",
        "media": "New York Observer",
        "time": "March 2, 2023",
        "section": "",
        "length": "528 words",
        "byline": "Sissi Cao",
        "story_text": "OpenAI's Bets on Tech Startups Hint At the Future of Artificial Intelligence\nNew York Observer\nFebruary 28, 2023 Tuesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 528 words\nByline: Sissi Cao\nBody\nOpenAI, the company that created ChatGPT, has started a race among tech companies large and small to push for \nnew artificial intelligence products. The competition includes OpenAI itself, which started out as a research nonprofit \nbut was most recently valued at $29 billion-a number buoyed by investors' hopes it will keep delivering successful \nproducts like ChatGPT.\nIn November, OpenAI launched a $100 million Startup Fund and an accelerator program called Converge to \nincubate promising founders and companies developing new A.I. products. The Startup Fund, backed by investors \nincluding Microsoft, aims to make big bets in a small number of early-stage companies in fields where A.I. \"can \nhave a transformative effect,\" according to OpenAI's website.\nIn the past few months, OpenAI has backed about a dozen companies through the Startup Fund and the Converge \nprogram, according to OpenAI's disclosure and data compiled by CB Insights, a private market research firm. The \ncompany clearly aims to have a say in the future of A.I. technologies, but its path toward that goal is not obvious.\n\"It's not surprising that OpenAI created a startup fund to spark interest and new use-cases of AI,\" said Kyunghyun \nCho, a data science professor at New York University and a former research scientist at Facebook AI Research. \n\"The question is whether OpenAI will be the one to create new applications directly to consumers, or are they going \nto sell the access to its code to other companies with which they will create new products?\"\nOpenAI is betting on everything from chip makers to legal-assistance A.I.\nA few themes emerge from OpenAI's picks. The company is investing in startups that focus on productivity, A.I. \ninfrastructure and more generative A.I.-a term popularized by ChatGPT that describes applications that can \ngenerate text, images and other content based on simple prompts.\nFor example, OpenAI led a series C investment in Descript, a company that makes an algorithm-powered video \nediting tool that's as easy to use as a simple text editor. It also backed Harvey, an automated legal-assistance \nplatform powered by A.I. language models, and Speak, an A.I. language tutor.\nOpenAI also invested in a few startups not aimed at consumers, such as Atomic Semi, a chip manufacturer; \nqqbot.dev, a chatbot for software developers; and Anysphere and Cursor, makers of IDE (integrated development \nenvironment), an application that helps programmers develop software code efficiently.\nThese picks align closely with OpenAI's own research and product plans, CB Insights analysts observed in a report \npublished Feb. 25. That include GPT-4, OpenAI's next generation language model, and a potential video generator \ntouted by CEO Sam Altman recently.\nIn additional to capital infusion, companies backed by OpenAI's Startup Fund or Converge program will have \naccess to OpenAI's models and programming as well as support from the company's research team, Altman said in \na video promoting the fund in December.\nOpenAI 's Bets on Tech Startups Hint At the Future of Artificial Intelligence\n\"We want to push the boundaries of what powerful AI models can do and support really ambitious projects aimed to \nsolve complex problems of highest order,\" Altman said in the video.\nLoad-Date: March 2, 2023"
    },
    {
        "file_name": "Strategists_wrestle_with_how_to_deploy_tech_in_campaign_May2024",
        "header": "Democrats fear falling behind GOP in AI race",
        "media": "Strategists wrestle with how to deploy tech in campaign",
        "time": "May 8, 2024",
        "section": "MAIN; A; Pg. 12",
        "length": "1067 words",
        "byline": "Courtney Subramanian Associated Press",
        "story_text": "Democrats fear falling behind GOP in AI race\nStrategists wrestle with how to deploy tech in campaign\nThe Baltimore Sun\nMay 8, 2024 Wednesday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 12\nLength: 1067 words\nByline: Courtney Subramanian Associated Press\nHighlight: President Joe Biden speaks at a Hanukkah reception in the East Room of the White House. The White \nHouse announced new rules in March for how the federal government should use artificial intelligence tools. Doug \nMills/the new york times 2023\nBody\nWASHINGTON - President Joe Biden's campaign and Democratic candidates are in a fevered race with \nRepublicans over who can best exploit the potential of artificial intelligence, a technology that could transform \nAmerican elections - and perhaps threaten democracy itself.\nStill smarting from being outmaneuvered on social media by Donald Trump and his allies in 2016, Democratic \nstrategists said they are nevertheless treading carefully in embracing tools that trouble experts in disinformation. \nSo far, Democrats said they are primarily using AI to help them find and motivate voters and better identify and \novercome deceptive content.\n\"Candidates and strategists are still trying to figure out how to use AI in their work. People know it can save them \ntime - the most valuable resource a campaign has,\" said Betsy Hoover, director of digital organizing for President \nBarack Obama's 2012 campaign and co-founder of the venture capital firm Higher Ground Labs. \"But they see the \nrisk of misinformation and have been intentional about where and how they use it in their work.\"\nCampaigns in both parties for years have used AI - powerful computer systems, software or processes that emulate \naspects of human work and cognition - to collect and analyze data.\nThe recent developments in supercharged generative AI, however, have provided candidates and consultants with \nthe ability to generate text and images, clone human voices, and create video at unprecedented volume and speed.\nThat has led disinformation experts to issue increasingly dire warnings about the risks posed by AI's ability to \nspread falsehoods that could suppress or mislead voters, or incite violence, whether in the form of robocalls, social \nmedia posts or fake images and video.\nThose concerns gained urgency after high-profile incidents that included the spread of AI-generated images of \nformer President Donald Trump getting arrested in New York and an AI-created robocall that mimicked Biden's \nvoice telling New Hampshire voters not to cast a ballot.\nThe Biden administration has sought to shape AI regulation through executive action, but Democrats agree \nCongress needs to pass legislation to install safeguards around the technology.\nDemocrats fear falling behind GOP in AI race Strategists wrestle with how to deploy tech in campaign\nTop tech companies have taken some steps to quell unease in Washington by announcing a commitment to \nregulate themselves. Major AI players entered into a pact to combat the use of AI-generated deepfakes around the \nworld. \nBut some experts said the voluntary effort is largely symbolic and congressional action is needed to prevent AI \nabuses.\nMeanwhile, campaigns and their consultants have avoided talking about how they intend to use AI to avoid scrutiny \nand giving away trade secrets.\nDemocrats have \"gotten much better at just shutting up and doing the work and talking about it later,\" said Jim \nMessina, a veteran Democratic strategist who managed Obama's  reelection campaign.\nThe Republican National Committee, which declined to comment, has experimented with generative AI. In the \nhours after Biden announced his reelection bid last year, the RNC released an ad using artificial intelligence-\ngenerated images to depict GOP dystopian fears of a second Biden term: China invading Taiwan, boarded up \nstorefronts, troops lining U.S. city streets and migrants crossing the U.S. border.\nScarred by the memories of 2016, the Biden campaign, Democratic candidates and progressives are wrestling with \nthe power of artificial intelligence and nervous about not keeping up with the GOP in embracing the technology, \naccording to interviews with consultants and strategists.\nThey want to use it in ways that maximize its capabilities without crossing ethical lines. But some said they fear \nusing it could lead to charges of hypocrisy - they have long excoriated Trump and his allies for engaging in \ndisinformation while the White House has prioritized reining in abuses associated with AI.\nThe Biden campaign said it is using AI to model and build audiences, draft and analyze email copy, and generate \ncontent for volunteers to share in the field. The campaign is also testing AI's ability to help volunteers categorize \nand analyze a host of data, including notes taken by volunteers after conversations with voters, whether while door-\nknocking or by phone or text message.\nIt has experimented with using AI to generate fundraising emails, which sometimes have turned out to be more \neffective than human-generated ones, according to a campaign official who spoke on the condition of anonymity \nbecause he was not authorized to publicly discuss AI.\nBiden campaign officials said they plan to explore using generative AI this cycle but will adhere to strict rules in \ndeploying it. \nAmong the tactics that are off limits: AI cannot be used to mislead voters, spread disinformation and so-called \ndeepfakes, or deliberately manipulate images. The campaign also forbids the use of AI-generated content in \nadvertising, social media and other such copy without a staff member's review.\nThe campaign's legal team has created a task force of lawyers and outside experts to respond to misinformation \nand disinformation, with a focus on AI-generated images and videos. The group is not unlike an internal team \nformed in the 2020 campaign - known as the \"Malarkey Factory,\" playing off Biden's oft-used phrase, \"What a \nbunch of malarkey.\"\nThat group was tasked with monitoring what misinformation was gaining traction online. Rob Flaherty, Biden's \ndeputy campaign manager, said those efforts would continue and suggested some AI tools could be used to \ncombat deepfakes and other such content before they go viral.\n\"The tools that we're going to use to mitigate the myths and the disinformation is the same, it's just going to have to \nbe at a higher pace,\" Flaherty said. \nThe Democratic National Committee said it was an early adopter of Google AI and uses some of its features, \nincluding ones that analyze voter registration records to identify patterns of voter removals or additions. \nDemocrats fear falling behind GOP in AI race Strategists wrestle with how to deploy tech in campaign\nArthur Thompson, the DNC's chief technology officer, said the organization believes generative AI is an \"incredibly \nimportant and impactful technology\" to help elect Democrats up and down the ballot.\n\"At the same time, it's essential that AI is deployed responsibly and to enhance the work of our trained staff, not \nreplace them. We can and must do both, which is why we will continue to keep safeguards in place as we remain at \nthe cutting edge,\" he said.\nLoad-Date: May 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "With Bard, Google Pulls A.I. Trigger",
        "media": "The New York Times",
        "time": "March 22, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1259 words",
        "byline": "By Nico Grant and Cade Metz",
        "story_text": "With Bard, Google Pulls A.I. Trigger\nThe New York Times\nMarch 22, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1259 words\nByline: By Nico Grant and Cade Metz\nBody\nThe internet giant will grant users access to a chatbot after years of cautious development, chasing splashy debuts \nfrom rivals OpenAI and Microsoft.\nFor more than three months, Google executives have watched as projects at Microsoft and a San Francisco start-\nup called OpenAI have stoked the public's imagination with the potential for artificial intelligence. \n  But on Tuesday, Google tentatively stepped off the sidelines as it released a chatbot called Bard. The new A.I. \nchatbot will be available to a limited number of users in the United States and Britain and will accommodate \nadditional users, countries and languages over time, Google executives said in an interview.\n  The cautious rollout is the company's first public effort to address the recent chatbot craze driven by OpenAI and \nMicrosoft, and it is meant to demonstrate that Google is capable of providing similar technology. But Google is \ntaking a much more circumspect approach than its competitors, which have faced criticism that they are \nproliferating an unpredictable and sometimes untrustworthy technology.\n  Still, the release represents a significant step to stave off a threat to Google's most lucrative business, its search \nengine. Many in the tech industry believe that Google -- more than any other big tech company -- has a lot to lose \nand to gain from A.I., which could help a range of Google products become more useful, but could also help other \ncompanies cut into Google's huge internet search business. A chatbot can instantly produce answers in complete \nsentences that don't force people to scroll through a list of results, which is what a search engine would offer.\n  Google started Bard as a webpage on its own rather than a component of its search engine, beginning a tricky \ndance of adopting new A.I. while preserving one of the tech industry's most profitable businesses.\n  ''It's important that Google start to play in this space because this is where the world is headed,'' said Adrian Aoun, \na former Google director of special projects. But the move to chatbots could help upend a business model reliant on \nadvertising, said Mr. Aoun, who is now the chief executive of the health care start-up Forward.\n  In late November, OpenAI released ChatGPT, an online chatbot that can answer questions, write term papers and \nriff on almost any topic. Two months later, the company's primary investor and partner, Microsoft, added a similar \nchatbot to its Bing internet search engine, showing how the technology could shift the market that Google has \ndominated for more than 20 years.\n  Google has been racing to ship A.I. products since December. It declared a ''code red'' in response to ChatGPT's \nrelease, making A.I. the company's central priority. And it spurred teams inside the company, including researchers \nwho specialize in studying the safety of A.I., to collaborate to speed up the approval of a wave of new products.\nWith Bard, Google Pulls A.I. Trigger\n  Industry experts have wondered how quickly Google can develop new A.I. technology, particularly given OpenAI \nand Microsoft's breakneck pace in releasing their tools.\n  ''We are at a singular moment,'' said Chirag Dekate, an analyst at the technology research firm Gartner. ChatGPT \ninspired new start-ups, captured the public imagination and prompted greater competition between Google and \nMicrosoft, he said, adding, ''Now that market demand has shifted, Google's approach has, too.''\n  Last week, OpenAI tried to up the ante with newer technology called GPT-4, which will allow other businesses to \nbuild the kind of artificial intelligence that powers ChatGPT into a variety of products, including business software \nand e-commerce websites.\n  Google has been testing the technology underlying Bard since 2015, but has so far not released it beyond a small \ngroup of early testers because, like the chatbots offered by OpenAI and Microsoft, it does not always generate \ntrustworthy information and can show bias against women and people of color.\n  ''We are well aware of the issues; we need to bring this to market responsibly,'' said Eli Collins, Google's vice \npresident for research. ''At the same time, we see all the excitement in the industry and the excitement of all the \npeople using generative A.I.''\n  Mr. Collins and Sissie Hsiao, a Google vice president for product, said in an interview that the company had not \nyet determined a way to make money from Bard.\n  Google announced last week that A.I. was coming to its productivity apps like Docs and Sheets, which businesses \npay to use. The underlying technology will also be on sale to companies and software developers who wish to build \ntheir own chatbots or power new apps.\n  ''It is early days for the technology,'' Ms. Hsiao said. ''We're exploring how these experiences can show up in \ndifferent products.''\n  The recent announcements are the beginning of Google's plan to introduce more than 20 A.I. products and \nfeatures, The New York Times has reported, including a feature called Shopping Try-on and the ability to create \ncustom background images for YouTube videos and Pixel phones.\n  Rather than being combined with its search engine, Bard is a stand-alone webpage featuring a question box. At \nthe bottom of an answer there is a button to ''Google it,'' which takes users to a new tab with a conventional Google \nsearch results page on the topic.\n  Google executives pitched Bard as a creative tool designed to draft emails and poems and offer guidance on how \nto get children involved in new hobbies like fly-fishing. The company is keen to see how people use the technology, \nand will further refine the chatbot based on use and feedback, the executives said. Unlike its search engine, though, \nBard was not primarily designed to be a source of reliable information.\n  ''We think of Bard as complementary to Google Search,'' Ms. Hsiao said. ''We want to be bold in how we innovate \nwith this technology as well as be responsible.''\n  Like similar chatbots, Bard is based on a kind of A.I. technology called a large language model, or L.L.M., which \nlearns skills by analyzing vast amounts of data from across the internet. This means the chatbot often gets facts \nwrong and sometimes makes up information without warning -- a phenomenon A.I. researchers call hallucination. \nThe company said it had worked to limit this behavior, but acknowledged that its controls were not entirely effective.\n  When executives demonstrated the chatbot on Monday, it refused to answer a medical question because doing so \nwould require precise and correct information. But the bot also falsely described its source for an answer it \ngenerated about the American Revolution.\nWith Bard, Google Pulls A.I. Trigger\n  Google posts a disclaimer under Bard's query box warning users that issues may arise: ''Bard may display \ninaccurate or offensive information that doesn't represent Google's views.'' The company also provides users three \noptions of responses for each question, and lets them provide feedback on the usefulness of a particular answer.\n  Much like Microsoft's Bing chatbot and similar bots from start-ups like You.com and Perplexity, the chatbot \nannotates its responses from time to time, so people can review its sources. And it dovetails with Google's index of \nall websites, so that it can instantly gain access to the latest information posted to the internet.\n  This may make the chatbot more accurate in some cases, but not all. Even with access to the latest online \ninformation, it still misstates facts and generates misinformation.\n  ''L.L.M.s are tricky,'' said Mr. Collins, Google's vice president for research. ''Bard is no exception.''\nhttps://www.nytimes.com/2023/03/21/technology/google-bard-chatbot.html\nGraphic\n \nPHOTOS: The Google headquarters in Manhattan. The company is taking a much more cautious approach than its \ncompetitors in the release of its chatbot. (PHOTOGRAPH BY JOHN TAGGART FOR THE NEW YORK TIMES)\n The chatbot can get facts wrong and sometimes makes up information without warning -- a phenomenon A.I. \nresearchers call hallucination. (PHOTOGRAPH VIA GOOGLE) (B3) This article appeared in print on page B1, B3.               \nLoad-Date: March 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Instant Videos Could Represent the Next Leap in A.I. Technology",
        "media": "The New York Times",
        "time": "April 10, 2023",
        "section": "TECHNOLOGY",
        "length": "1429 words",
        "byline": "Cade Metz",
        "story_text": "Instant Videos Could Represent the Next Leap in A.I. Technology\nThe New York Times \nApril 4, 2023 Tuesday 15:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1429 words\nByline: Cade Metz\nHighlight: A start-up in New York is among a group of companies working on systems that can produce short \nvideos based on a few words typed into a computer.\nBody\nA start-up in New York is among a group of companies working on systems that can produce short videos based on \na few words typed into a computer.\nIan Sansavera, a software architect at a New York start-up called Runway AI, typed a short description of what he \nwanted to see in a video. “A tranquil river in the forest,” he wrote.\nLess than two minutes later, an experimental internet service generated a short video of a tranquil river in a forest. \nThe river’s running water glistened in the sun as it cut between trees and ferns, turned a corner and splashed gently \nover rocks.\nRunway, which plans to open its service to a small group of testers this week, is one of several companies building \nartificial intelligence technology that will soon let people generate videos simply by typing several words into a box \non a computer screen.\nThey represent the next stage in an industry race — one that includes giants like Microsoft and Google as well as \nmuch smaller start-ups — to create new kinds of artificial intelligence systems that some believe could be the next \nbig thing in technology, as important as web browsers or the iPhone.\nThe new video-generation systems could speed the work of moviemakers and other digital artists, while becoming a \nnew and quick way to create hard-to-detect online misinformation, making it even harder to tell what’s real on the \ninternet.\nThe systems are examples of what is known as generative A.I., which can instantly create text, images and \nsounds. Another example is ChatGPT, the online chatbot made by a San Francisco start-up, OpenAI, that stunned \nthe tech industry with its abilities late last year.\nGoogle and Meta, Facebook’s parent company, unveiled the first video-generation systems last year, but did not \nshare them with the public because they were worried that the systems could eventually be used to spread \ndisinformation with newfound speed and efficiency.\nBut Runway’s chief executive, Cristóbal Valenzuela, said he believed the technology was too important to keep in a \nresearch lab, despite its risks. “This is one of the single most impressive technologies we have built in the last \nhundred years,” he said. “You need to have people actually using it.”\nInstant Videos Could Represent the Next Leap in A.I. Technology\nThe ability to edit and manipulate film and video is nothing new, of course. Filmmakers have been doing it for more \nthan a century. In recent years, researchers and digital artists have been using various A.I. technologies and \nsoftware programs to create and edit videos that are often called deepfake videos.\nBut systems like the one Runway has created could, in time, replace editing skills with the press of a button.\nRunway’s technology generates videos from any short description. To start, you simply type a description much as \nyou would type a quick note.\nThat works best if the scene has some action — but not too much action — something like “a rainy day in the big \ncity” or “a dog with a cellphone in the park.” Hit enter, and the system generates a video in a minute or two.\nThe technology can reproduce common images, like a cat sleeping on a rug. Or it can combine disparate concepts \nto generate videos that are strangely amusing, like a cow at a birthday party.\nThe videos are only four seconds long, and the video is choppy and blurry if you look closely. Sometimes, the \nimages are weird, distorted and disturbing. The system has a way of merging animals like dogs and cats with \ninanimate objects like balls and cellphones. But given the right prompt, it produces videos that show where the \ntechnology is headed.\n“At this point, if I see a high-resolution video, I am probably going to trust it,” said Phillip Isola, a professor at the \nMassachusetts Institute of Technology who specializes in A.I. “But that will change pretty quickly.”\nLike other generative A.I. technologies, Runway’s system learns by analyzing digital data — in this case, photos, \nvideos and captions describing what those images contain. By training this kind of technology on increasingly large \namounts of data, researchers are confident they can rapidly improve and expand its skills. Soon, experts believe, \nthey will generate professional-looking mini-movies, complete with music and dialogue.\nIt is difficult to define what the system creates currently. It’s not a photo. It’s not a cartoon. It’s a collection of a lot of \npixels blended together to create a realistic video. The company plans to offer its technology with other tools that it \nbelieves will speed up the work of professional artists.\nSeveral start-ups, including OpenAI, have released similar technology that can generate still images from short \nprompts like “photo of a teddy bear riding a skateboard in Times Square.” And the rapid advancement of A.I.-\ngenerated photos could suggest where the new video technology is going.\nLast month, social media services were teeming with images of Pope Francis in a white Balenciaga puffer coat — \nsurprisingly trendy attire for an 86-year-old pontiff. But the images were not real. A 31-year-old construction worker \nfrom Chicago had created the viral sensation using a popular A.I. tool called Midjourney.\nDr. Isola has spent years building and testing this kind of technology, first as a researcher at the University of \nCalifornia, Berkeley, and at OpenAI, and then as a professor at M.I.T. Still, he was fooled by the sharp, high-\nresolution but completely fake images of Pope Francis.\n“There was a time when people would post deepfakes and they wouldn’t fool me, because they were so outlandish \nor not very realistic,” he said. “Now, we can’t take any of the images we see on the internet at face value.”\nMidjourney is one of many services that can generate realistic still images from a short prompt. Others include \nStable Diffusion and DALL-E, an OpenAI technology that started this wave of photo generators when it was \nunveiled a year ago.\nMidjourney relies on a neural network, which learns its skills by analyzing enormous amounts of data. It looks for \npatterns as it combs through millions of digital images as well as text captions that describe the images depict.\nWhen someone describes an image for the system, it generates a list of features that the image might include. One \nfeature might be the curve at the top of a dog’s ear. Another might be the edge of a cellphone. Then, a second \nInstant Videos Could Represent the Next Leap in A.I. Technology\nneural network, called a diffusion model, creates the image and generates the pixels needed for the features. It \neventually transforms the pixels into a coherent image.\nCompanies like Runway, which has roughly 40 employees and has raised $95.5 million, are using this technique to \ngenerate moving images. By analyzing thousands of videos, their technology can learn to string many still images \ntogether in a similarly coherent way.\n“A video is just a series of frames — still images — that are combined in a way that gives the illusion of movement,” \nMr. Valenzuela said. “The trick lies in training a model that understands the relationship and consistency between \neach frame.”\nLike early versions of tools such as DALL-E and Midjourney, the technology sometimes combines concepts and \nimages in curious ways. If you ask for a teddy bear playing basketball, it might give a kind of mutant stuffed animal \nwith a basketball for a hand. If you ask for a dog with a cellphone in the park, it might give you a cellphone-wielding \npup with an oddly human body.\nBut experts believe they can iron out the flaws as they train their systems on more and more data. They believe the \ntechnology will ultimately make creating a video as easy as writing a sentence.\n“In the old days, to do anything remotely like this, you had to have a camera. You had to have props. You had to \nhave a location. You had to have permission. You had to have money,” said Susan Bonser, an author and a \npublisher in Pennsylvania who has been experimenting with early incarnations of generative video technology. “You \ndon’t have to have any of that now. You can just sit down and imagine it.”\nPHOTOS: Runway AI’s software created a video prompted by the words “a cow at a birthday party.” (A1); Guided \nby brief descriptions typed into a computer, generative artificial intelligence software in minutes created a short \nvideo of animals at a birthday party and “a tranquil river in the forest.” Such systems could, in time, replace editing \nskills with the press of a button. (PHOTOGRAPHS BY RUNWAY); Runway’s founders, from left, Alejandro \nMatamala Ortiz, Cristóbal Valenzuela and Anastasis Germanidis believe their A.I. can aid filmmakers. \n(PHOTOGRAPH BY JUSTIN J WEE FOR THE NEW YORK TIMES) (A11) This article appeared in print on page \nA1, A11.\nLoad-Date: April 10, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Air India Taps Airbus, L3Harris for Training Unit",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 26, 2023",
        "section": "BRANDS & COMPANIES",
        "length": "642 words",
        "byline": "Anirban.Chowdhury@timesgroup.com",
        "story_text": "Air India Taps Airbus, L3Harris for Training Unit\nEconomic Times (E-Paper Edition)\nNovember 27, 2023 Monday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BRANDS & COMPANIES\nLength: 642 words\nByline: Anirban.Chowdhury@timesgroup.com\nHighlight: Cos may make strategic investments in $200-m facility as Tata group airline looks to ramp up ops with a \nsteady inflow of aircraft\nBody\nMumbai: Air India is in talks with aerospace majors, including L3Harris and Airbus, as potential partners for its big \ncrew training facility and will be disclosing more details in January, CEO and MD Campbell Wilson said in a recent \ninterview.  People in the know said the companies will likely be making strategic investments in the $200-million \nfacility. “We are partnering with a couple of OEMs (original equipment manufacturers) to set up simulator training \ncentres: Airbus, Boeing L3Harris. We will be talking a little more about that in January,” said Wilson. \nHe didn’t elaborate on the nature of the partnership of investment from partners. L3Harris, formed in 2019 by the \nmerger of American companies L3 Technologies and Harris Corp, has  business interests in segments including \naerospace communications, integrated mission systems, space and airborne systems. The training centre would be \ncritical for training pilots to fly the large number of planes the airline will receive over the next five years, starting \nDecember.  In June, Air India placed a historic order for 470 aircraft from Boeing and Airbus. The airline will need \nover 5,000 pilots to fly these planes. India needs 1,700 pilots every year, half of which have  to be captains. It, \nhowever, produces just 200. “We hopefully will be inducting the first group of cabin crew in January. It's a \nresponsibility that we take very seriously, investing a lot of money in it. It's crucial for us as an airline to grow and to \ngrow our capabilities and become world class. One thing that we know for sure is that this indus-  try requires a lot \nof good trained people and India has a lot of good people that just need to be trained,” he said. New aircraft are \ncritical for Air India to upgrade its ageing fleet and product if it wants to regain its long lost status of a globally \nrelevant airline. The airline, which had climbed the ranks in on-time performance in April, has slipped in recent \nmonths to be among the bottom three airlines, according to the data from the Directorate General of Civil Aviation \n(DGCA) regarding on-time performances in four major metro airports which handle more than 60% of India’s air \ntraffic. By March, Air India will get the delivery of 4 Boeing 777 planes and six Airbus A350 wide-bodied planes, \nwhich means that a quarter of its widebodied fleet then will be sporting latest generation products.“Then in July, \nAugust of next year, we put our all legacy aircraft through a retrofit programme, which will take about 18 months, so \nthat by the end of 2025, all of our aircraft have been upgraded to the latest standards of seats and entertainment \nand other amenities,” he said.The Tata group took over Air India on January 27, 2022 from the government which \nhad put it on the block for privatisation. In the last 1 year, the airline has been charting out ways to leverage the \nstrengths of the Tata group companies, including Tata Technologies that recently launched its IPO.Tata \nTechnologies is “doing some work for us in digitising certain seat components so we can get spares manufactured \namongst other things,” said Wilson, adding Tata Alexi is helping the airline with a lot of “design work”.Air India \nrecently launched a generative AI powered chatbot and will introduce more generative AI-powered solutions, said \nWilson.“We are one of the few companies in the world that are using Microsoft's (AI tool) copilot embedded into our \nenterprise suite. We use it every day in all of our tools. And many teams across the business are hard at work, \nthinking about how we can bring it into our daily business life, using it behind the scenes to improve such things as \nAir India Taps Airbus , L3Harris for Training Unit\nrevenue management. I do think it's going to be quite transformative. It certainly has the opportunity to improve \nefficiency and effectiveness and as a consequence, cost and service delivery...”\nLoad-Date: November 26, 2023"
    },
    {
        "file_name": "CEO_Cristiano_Amon_Mar2024",
        "header": "India can play a key role in building hardy supply chain, says Qualcomm",
        "media": "CEO Cristiano Amon",
        "time": "March 12, 2024",
        "section": "ELECTRONICS",
        "length": "583 words",
        "byline": "Romit Guha and Himanshi Lohchab",
        "story_text": "India can play a key role in building hardy supply chain, says Qualcomm \nCEO Cristiano Amon\nThe Economic Times\nMarch 13, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ELECTRONICS\nLength: 583 words\nByline: Romit Guha and Himanshi Lohchab\nBody\nIndia can play a key role in building a resilient global electronics supply chain, said Cristiano Amon, chief executive \nof US chip giant Qualcomm Inc. In an interview with ET's Romit Guha and Himanshi Lohchab, Amon said the \ncountry has an opportunity to create large companies that serve both the domestic and global markets in areas \nsuch as semiconductor packaging and manufacturing. Edited excerpts: What are the opportunities for Qualcomm in \nIndia?There's an incredible opportunity with the transition to 5G. But it's not only 5G, but also the incredible \nopportunity that is developing with Gen AI and the opportunity to do Gen AI at the edge, not only at data centres, \nbut across many different industries.What's Qualcomm's investment plan for India?\nIndia is our largest R&D site outside San Diego. We have a presence in a number of sites - from Hyderabad, \nBengaluru, Chennai and Noida. The majority of our chips are designed in India, both hardware and software. With \nthe world looking for alternatives to make the overall electronic supply chain more resilient, we see that India has an \nimportant role to play, an opportunity to create over time, very large Indian companies serving not only the Indian \nmarket, but also global, whether it's smartphone industrial modules, whether it's semiconductor packaging, and \neventually semiconductor manufacturing.Have you tied up with the Tatas and/or any other partner for the chip \necosystem?We're the largest fabless company in the world. And if you're going to build the semiconductor supply \nchain, you need that long-term customer. Qualcomm is fabless, and because we don't have any manufacturing, we \nwant a diversified and resilient supply chain. Our role is, if India wants to build a strong semiconductor supply chain, \nfor assembly and semiconductors, we will be there to provide the scale and to support our partners.Anything more \nspecific about your talks with the Tatas?We have been in discussions. It's very natural, anybody who is going to be \nlooking into investing in semiconductors will have a conversation with Qualcomm... We can't wait to see India build \na semiconductor supply chain with technologies that are relevant to us.How is India's latest efforts to be a part of \nthe semiconductor supply chain different from its previous efforts?The opportunity for India to be successful in the \nsemiconductor supply chain is to also leverage the India scale. And it's not just about focussing on semiconductor \nmanufacturing. India also needs to be focused about generating demand. Because if you have demand for \nsemiconductors, you have the ability to build upon that scale, a very sustainable semiconductor supply chain. And \nthat's where I think we can play two roles. One role Qualcomm can play is if India has semiconductor manufacturing \ncapacity, assembly capacity, we can be a customer given our scale. But more exciting to us is the ability to work \nwith India to make phones in India, industrial modules in India, meaning connected cars. I think that is the big \nopportunity, and that's what makes it different from prior attempts to create a semiconductor industry.The \ngovernment expects India to be among the top five in the semiconductor global supply chain. Do you think it's a \nrealistic target?The current global environment is a unique opportunity for India. I think it's in the interest of many \ncompanies in the world to build resilience in the supply chain. That is the opportunity for India. For Reprint Rights: \ntimescontent.com\nIndia can play a key role in building hardy supply chain, says Qualcomm CEO Cristiano Amon\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Aug2023",
        "header": "AI OPENS NEW WAYS FOR HACKERS TO DO HARM",
        "media": "Wall Street Journal Abstracts",
        "time": "August 11, 2023",
        "section": "A; Pg. 1",
        "length": "37 words",
        "byline": "ROBERT MCMILLAN",
        "story_text": "AI OPENS NEW WAYS FOR HACKERS TO DO HARM\nWall Street Journal Abstracts\nAugust 10, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 1\nLength: 37 words\nByline: ROBERT MCMILLAN\nBody\nABSTRACT\nNew class of cyberattacks is becoming important as technology companies insert new generative-artificial-\nintelligence software into their businesses and consumer products, which is redefining what hacking means (M)\nLoad-Date: August 11, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "What's the future for A.I.?",
        "media": "The New York Times",
        "time": "April 8, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 7; ON TECH: A.I. NEWSLETTER",
        "length": "1679 words",
        "byline": "By Cade Metz",
        "story_text": "What's the future for A.I.?\nThe New York Times\nApril 8, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 7; ON TECH: A.I. NEWSLETTER\nLength: 1679 words\nByline: By Cade Metz\nBody\nWhere we're heading tomorrow, next year and beyond.\nIn today's A.I. newsletter, the last in our five-part series, I look at where artificial intelligence may be headed in the \nyears to come.  \n  In early March, I visited OpenAI's San Francisco offices for an early look at GPT-4, a new version of the \ntechnology that underpins its ChatGPT chatbot. The most eye-popping moment arrived when Greg Brockman, \nOpenAI's president and co-founder, showed off a feature that is still unavailable to the public: He gave the bot a \nphotograph from the Hubble Space Telescope and asked it to describe the image ''in painstaking detail.''\n  The description was completely accurate, right down to the strange white line created by a satellite streaking \nacross the heavens. This is one look at the future of chatbots and other A.I. technologies: A new wave of \nmultimodal systems will juggle images, sounds and videos as well as text.\n  Yesterday, my colleague Kevin Roose told you about what A.I. can do now. I'm going to focus on the opportunities \nand upheavals to come as it gains abilities and skills.\n  A.I. in the near term\n  Generative A.I.s can already answer questions, write poetry, generate computer code and carry on \nconversations. As ''chatbot'' suggests, they are first being rolled out in conversational formats like ChatGPT and \nBing.\n  But that's not going to last long. Microsoft and Google have already announced plans to incorporate these A.I. \ntechnologies into their products. You'll be able to use them to write a rough draft of an email, automatically \nsummarize a meeting and pull off many other cool tricks.\n  OpenAI also offers an A.P.I., or application programming interface, that other tech companies can use to plug \nGPT-4 into their apps and products. And it has created a series of plug-ins from companies like Instacart, Expedia \nand Wolfram Alpha that expand ChatGPT's abilities.\n  A.I. in the medium term\n  Many experts believe A.I. will make some workers, including doctors, lawyers and computer programmers, more \nproductive than ever. They also believe some workers will be replaced.\nWhat's the future for A.I.?\n  ''This will affect tasks that are more repetitive, more formulaic, more generic,'' said Zachary Lipton, a professor at \nCarnegie Mellon who specializes in artificial intelligence and its impact on society. ''This can liberate some people \nwho are not good at repetitive tasks. At the same time, there is a threat to people who specialize in the repetitive \npart.''\n  Human-performed jobs could disappear from audio-to-text transcription and translation. In the legal field, GPT-4 is \nalready proficient enough to ace the bar exam, and the accounting firm PricewaterhouseCoopers plans to roll out \nan OpenAI-powered legal chatbot to its staff.\n  At the same time, companies like OpenAI, Google and Meta are building systems that let you instantly generate \nimages and videos simply by describing what you want to see.\n  Other companies are building bots that can actually use websites and software applications as a human does. In \nthe next stage of the technology, A.I. systems could shop online for your Christmas presents, hire people to do \nsmall jobs around the house and track your monthly expenses.\n  All that is a lot to think about. But the biggest issue may be this: Before we have a chance to grasp how these \nsystems will affect the world, they will get even more powerful.\n  A.I. in the long term\n  For companies like OpenAI and DeepMind, a lab that's owned by Google's parent company, the plan is to push \nthis technology as far as it will go. They hope to eventually build what researchers call artificial general intelligence, \nor A.G.I. -- a machine that can do anything the human brain can do.\n  As Sam Altman, OpenAI's chief executive, told me three years ago: ''My goal is to build broadly beneficial A.G.I. I \nalso understand this sounds ridiculous.'' Today, it sounds less ridiculous. But it is still easier said than done.\n  For an A.I. to become an A.G.I., it will require an understanding of the physical world writ large. And it is not clear \nwhether systems can learn to mimic the length and breadth of human reasoning and common sense using the \nmethods that have produced technologies like GPT-4. New breakthroughs will probably be necessary.\n  The question is, do we really want artificial intelligence to become that powerful? A very important related \nquestion: Is there any way to stop it from happening?\n  The risks of A.I.\n  Many A.I. executives believe the technologies they are creating will improve our lives. But some have been \nwarning for decades about a darker scenario, where our creations don't always do what we want them to do, or \nthey follow our instructions in unpredictable ways, with potentially dire consequences.\n  A.I. experts talk about ''alignment'' -- that is, making sure A.I. systems are in line with human values and goals.\n  Before GPT-4 was released, OpenAI handed it over to an outside group to imagine and test dangerous uses of the \nchatbot.\n  The group found that the system was able to hire a human online to defeat a Captcha test. When the human \nasked if it was ''a robot,'' the system, unprompted by the testers, lied and said it was a person with a visual \nimpairment.\n  Testers also showed that the system could be coaxed into suggesting how to buy illegal firearms online and into \ndescribing ways to make dangerous substances from household items. After changes by OpenAI, the system no \nlonger does these things.\n  But it's impossible to eliminate all potential misuses. As a system like this learns from data, it develops skills that \nits creators never expected. It is hard to know how things might go wrong after millions of people start using it.\nWhat's the future for A.I.?\n  ''Every time we make a new A.I. system, we are unable to fully characterize all its capabilities and all of its safety \nproblems -- and this problem is getting worse over time rather than better,'' said Jack Clark, a founder and the head \nof policy of Anthropic, a San Francisco start-up building this same kind of technology. \n  And OpenAI and giants like Google are hardly the only ones exploring this technology. The basic methods used to \nbuild these systems are widely understood, and other companies, countries, research labs and bad actors may be \nless careful.\n  The remedies for A.I.\n  Ultimately, keeping a lid on dangerous A.I. technology will require far-reaching oversight. But experts are not \noptimistic.\n  ''We need a regulatory system that is international,'' said Aviv Ovadya, a researcher at the Berkman Klein Center \nfor Internet & Society at Harvard who helped test GPT-4 before its release. ''But I do not see our existing \ngovernment institutions being about to navigate this at the rate that is necessary.''\n  As we told you earlier this week, more than 1,000 technology leaders and researchers, including Elon Musk, have \nurged artificial intelligence labs to pause development of the most advanced systems, warning in an open letter that \nA.I. tools present ''profound risks to society and humanity.''\n  A.I. developers are ''locked in an out-of-control race to develop and deploy ever more powerful digital minds that \nno one -- not even their creators -- can understand, predict or reliably control,'' according to the letter.\n  Some experts are mostly concerned about near-term dangers, including the spread of disinformation and the risk \nthat people would rely on these systems for inaccurate or harmful medical and emotional advice.\n  But other critics are part of a vast and influential online community called rationalists or effective altruists, who \nbelieve that A.I could eventually destroy humanity. This mind-set is reflected in the letter.\n  Please share your thoughts and feedback on our On Tech: A.I. series by taking this brief survey. \n  Your homework\n  We can speculate about where A.I. is going in the distant future -- but we can also ask the chatbots themselves. \nFor your final assignment, treat ChatGPT, Bing or Bard like an eager young job applicant and ask it where it sees \nitself in 10 years. As always, share the answers in the comments.\n  Quiz\n  Question 1 of 3\n  What feature did OpenAI demonstrate with GPT-4 that is not yet available to the public?\n  Translating text into multiple languages\n  Generating realistic images based on text descriptions\n  Passing the bar exam with its legal text proficiency\n  Start the quiz by choosing your answer.\n  Glossary\n  Alignment: Attempts by A.I. researchers and ethicists to ensure that artificial intelligences act in accordance with \nthe values and goals of the people who create them.\nWhat's the future for A.I.?\n  Multimodal systems: A.I.s similar to ChatGPT that can also process images, video, audio, and other non-text \ninputs and outputs.\n  Artificial general intelligence: An artificial intelligence that matches human intellect and can do anything the human \nbrain can do.\n  Click here for more glossary terms.\n  Farewell\n  Kevin here. Thank you for spending the past five days with us. It's been a blast seeing your comments and \ncreativity. (I especially enjoyed the commenter who used ChatGPT to write a cover letter for my job.)\n  The topic of A.I. is so big, and fast-moving, that even five newsletters isn't enough to cover everything. If you want \nto dive deeper, you can check out my book, ''Futureproof,'' and Cade's book, ''Genius Makers,'' both of which go \ninto greater detail about the topics we've covered this week.\n  Cade here: My favorite comment came from someone who asked ChatGPT to plan a route through the trails in \ntheir state. The bot ended up suggesting a trail that did not exist as a way of hiking between two other trails that do. \n  This small snafu provides a window into both the power and the limitations of today's chatbots and other A.I. \nsystems. They have learned a great deal from what is posted to the internet and can make use of what they have \nlearned in remarkable ways, but there is always the risk that they will insert information that is plausible but untrue. \nGo forth! Chat with these bots! But trust your own judgment too!\n  Please take this brief survey to share your thoughts and feedback on this limited-run newsletter.\nhttps://www.nytimes.com/2023/03/31/technology/ai-chatbots-benefits-dangers.html\nGraphic\n \nThis article appeared in print on page B7.               \nLoad-Date: April 8, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 20, 2023",
        "section": "STARTUPS & TECH",
        "length": "270 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres\nEconomic Times (E-Paper Edition)\nJune 15, 2023 Thursday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 270 words\nByline: Suraksha.P@timesgroup.com\nHighlight: AI key driver of silicon consumption for the foreseeable future: AMD CEO\nBody\nSan Francisco: California-based multinational semiconductor company Advanced Micro Devices (AMD) said \nartificial intelligence (AI) will be the key driver of silicon consumption for the foreseeable future but the largest \nopportunity is in data centre currently. AMD also revealed new details about the MI300 chip on Tuesday. \nMI300 is AMD's most advanced graphics processing unit (GPU) that is believed to be a strong challenge to Nvidia \nwhose chips dominate the artificial intelligence (AI) computing market with more than 80% market share. \"The \ngenerative AI large language models have paved the landscape. The  need for more compute is growing \nexponentially. Be it training or inference, large models give you better accuracy. There's a tremendous amount of \nexperimentation and development that is coming across the industry. At the centre of this are GPUs. GPUs are \nenabling generative AI,\" AMD chief executive Lisa Su said. She was speaking at the AMD Data Center and AI \nTechnology Premiere on Tuesday. The company's fourth generation EPYC processors are cloud-native central \nprocessing units (CPUs) that enable data centres to run demanding, scalable services and enterprise applications \non shared cloud infrastructure. Social media giant Meta vice president Alexis Bjorlin also shared how apps like \nFacebook, Instagram and WhatsApp are powered by hundreds of thousands of AMD servers with the next \ngeneration of EPYC beginning deployment this year. AMD has started shipping its Bergamo central processor.  \n(The author is in San Francisco for the AMD Data Center and AI Technology Premiere at the invitation of AMD.)\nLoad-Date: June 20, 2023"
    },
    {
        "file_name": "Newsletter_Sep2023",
        "header": "From I.P.O.s to Inflation Data: What’s at Risk in a Shutdown; DealBook",
        "media": "Newsletter",
        "time": "September 30, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1919 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "From I.P.O.s to Inflation Data: What’s at Risk in a Shutdown; DealBook \nNewsletter\nThe New York Times \nSeptember 29, 2023 Friday 08:57 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1919 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni\nHighlight: Important economic data could be delayed, as could regulators’ decisions on mergers and new public \nlistings.\nBody\nImportant economic data could be delayed, as could regulators’ decisions on mergers and new public listings.\nThe unintended economic consequences of a shutdown\nWe’re less than 48 hours before the federal government shuts down, and Congress appears no closer to breaking \nan impasse over funding. Hard-right Republicans in the House are more focused on scoring political points, while \ntheir moderate (and electorally vulnerable) colleagues try to work with Democrats on a solution.\nAs Washington and Wall Street gird themselves for an increasingly likely shutdown, it’s worth considering what \nmight happen in that event.\nGovernment data: Statistics agencies, including the Bureau of Labor Statistics and the Bureau of Economic \nAnalysis, will suspend operations. Even a short shutdown will delay important releases, including the jobs report set \nfor Oct. 6 and the Consumer Price Index set for Oct. 12.\nA brief delay wouldn’t do much economic damage. But Fed officials have been closely scrutinizing official data as \nthey weigh changes to interest rate policy, and longer disruptions could mean they will make decisions based on \ninaccurate or incomplete information. “It’s like a pilot trying to land a plane without knowing what the runway looks \nlike,” Ben Harris, a former Treasury Department official, told The Times.\nI.P.O.s and mergers: A shutdown would reduce the S.E.C. to a skeletal staff, rendering the regulator unable to fulfill \nmost of its responsibilities. That means officials wouldn’t be able to review filings related to initial public offerings or \nto mergers, both of which require agency approval. The F.T.C. and the Justice Department would also face similar \nstaffing constraints.\nIt’s unclear whether a shutdown would affect the I.P.O. of the sandal maker Birkenstock, the next big offering, \nscheduled to begin trading within the next two weeks. (The company’s advisers reportedly believe the company can \nproceed as planned, according to Reuters.) Other companies further behind in the process, however, are likely to \nhave to wait.\nHousing: Some would-be home buyers in flood-prone areas won’t be able to get mortgages, because funding for \nthe National Flood Insurance Program will lapse. (Federal regulations require lenders offering mortgages in those \nregions to ensure that flood insurance is in place.) The National Association of Realtors estimates that as many as \n1,300 home sales a day could be thrown into uncertainty.\nFrom I.P.O.s to Inflation Data: What’s at Risk in a Shutdown DealBook Newsletter\nOfficials plan to suspend the flood insurance requirement in case of a shutdown, although it will still be up to lenders \nto decide whether buyers must have that coverage.\nHERE’S WHAT’S HAPPENING \nThe eurozone’s “core” inflation dips to a one-year low. Data released this morning showed that prices, excluding \nenergy and food costs, grew 4.5 percent in September. The reading sent European stocks higher, as investors bet \nthat the European Central Bank will hold steady on interest rates. Next up: the Fed’s preferred measure for tracking \nU.S. inflation, the Personal Consumption Expenditure index, set for release at 8:30 a.m. Eastern.\nThe U.A.W. is said to be lowering its pay demands for autoworkers. The union would accept a pay raise of at least \n30 percent, Bloomberg reports, below the 40 percent it initially proposed. Members of the United Automobile \nWorkers are about to enter a third week of strikes against the Big Three carmakers and could expand their actions \nas soon as Friday.\nTesla is sued over claims of racial discrimination and harassment. The Equal Employment Opportunity Commission \naccused the company of failing to address Black employees’ complaints that they were the subject of racial \nepithets, given worse work assignments than white workers and fired when they complained.\nA court rejects Donald Trump’s attempt to delay his fraud trial. The trial of the Republican presidential front-runner \ncould start in New York on Monday, on charges he inflated the value of his business properties by billions of dollars. \nLetitia James, the state’s attorney general, is seeking to recover $250 million in ill-gotten gains. Trump has denied \nall wrongdoing.\nLinda Yaccarino will reportedly present a turnaround plan for X to lenders next week. The C.E.O. of the social \nmedia platform formerly known as Twitter will lay out her strategy to seven banks holding $13 billion of debt tied to \nElon Musk’s acquisition of the company, The Financial Times reports. The talks will include how she plans to revive \nthe advertising business.\nWhat’s next for the PGA Tour \nAs the clock ticks down to a New Year’s Eve deadline for the PGA Tour and the Saudi-backed LIV Golf to agree to \na tie-up, potential new bidders have emerged.\nThey include Ari Emanuel’s Endeavor, the entertainment giant that owns W.W.E. and Ultimate Fighting \nChampionship; Fenway Sports Group, owners of the Red Sox; and a consortium led by Henry Kravis, the co-\nfounder of KKR. Bloomberg first reported on the bidders on Thursday.\nTheir interest is in the early stages, DealBook understands, and may not alter the PGA Tour’s plan to join forces \nwith LIV, which is backed by the Public Investment Fund, Saudi Arabia’s sovereign wealth fund. Here’s what \nDealBook knows, and what could happen next.\nA potential PGA Tour-Saudi alliance is in flux. It’s a framework deal, so the tour can talk to other suitors. In August, \nthe players hired Raine Group, a boutique investment bank, to advise and represent their rights in any deal; the \nplayers, who hold a majority of PGA Tour seats, get the final say. Among the sticking points are players’ \ncompensation, how a deal with the Saudi fund would be structured, and at what valuation for the PGA Tour.\nThe tour says it remains focused on the Saudis. “Our focus continues to be on finalizing an agreement with the \nPublic Investment Fund and the DP World Tour,” a spokesman told DealBook, referring to the European branch of \nthe sport. He added that “negotiations have resulted in unsolicited interest from other investors.”\nU.S. investors could ease political opposition to a PGA-LIV deal. They would probably not be able to compete with \nthe P.I.F.’s vast finances, but lawmakers who are concerned about Saudi money infiltrating the sport may welcome \nthe American investors being part of any deal.\nFrom I.P.O.s to Inflation Data: What’s at Risk in a Shutdown DealBook Newsletter\nIt’s about more than money. Investors like Fenway and Endeavor also bring media relationships and experience \nbuilding and operating leagues. One possibility is that the PGA Tour could strike a deal that involves the best of \nboth worlds: P.I.F. money and a U.S. investor.\nWould that solve its antitrust problems? The Justice Department’s scrutiny of the tour predates the P.I.F.’s interest. \nU.S. investors wouldn’t necessarily resolve concerns about the tour’s interlocking boards and some of the forceful \ntactics it used to combat LIV before the two started discussing a tie-up.\n• In other sports news: ESPN is reportedly close to clinching a broadcast deal with TGL, the start-up golf league \nbacked by Tiger Woods and Rory McIlroy. And Dynasty Equity, a private equity firm, bought a minority \nstake in Liverpool F.C. from Fenway, and will reportedly invest up to $200 million in the Premier League \nsoccer club.\n“From playing chess to piloting drones — machines have become much smarter and play a role in many areas of \nour lives. So why not use artificial intelligence for central banking?”\n— Myriam Moufakkir, chief services officer of the European Central Bank. She announced that the E.C.B. would \nexperiment with using generative A.I., starting with basic functions like summarizing data, translation of documents \nand writing software code. But she stressed that those efforts were at an early stage.\nHow China squeezes executives who fall out of favor\nThe tally of corporate leaders under Chinese officials’ close watch appears to have gone up again. The authorities \nhave imposed an exit ban on a senior executive at Kroll, according to The Wall Street Journal, a day after \nEvergrande, the Chinese property giant, said its founder was under police investigation.\nAnother foreign firm is targeted. Michael Chan, a Hong Kong-based managing director for Kroll, the American \nadvisory firm, was barred from leaving mainland China and was said to be helping with an official investigation, \naccording to The Journal.\nThe report comes just days after a senior executive at Nomura, the Japanese bank, was said to also be blocked \nfrom leaving the country. And a number of due-diligence firms with foreign links have been targeted in recent \nmonths, with the authorities raiding offices and detaining staff.\nThe moves have sent a chill across local and Western companies operating in China, despite officials’ efforts to \npersuade companies that it’s business-friendly.\nEvergrande’s chairman is the latest executive in the cross hairs. Hui Ka Yan was accused of “illegal crimes” on \nThursday, after shares in the company were suspended in Hong Kong. The property developer was the country’s \nbiggest, turning Hui into China’s richest man.\nThe list of executives investigated, missing or imprisoned is growing. Hui is the latest high-profile business leader to \nfall out of favor with the authorities, and Evergrande’s former C.E.O. and C.F.O. are also reportedly under \ninvestigation.\nOther high-profile corporate leaders have vanished or been imprisoned in the years since Xi Jinping took control of \nthe Chinese Communist Party. They include:\n• Bao Fan, the founder of the investment bank Renaissance Capital and one of China’s top tech deal makers, \nvanished in February.\n• Chen Fang, chairman of HNA, the acquisitive Chinese conglomerate that owned stakes in Hilton Hotels and \nDeutsche Bank, was detained in 2021 on suspicion of committing crimes.\n• Ren Zhiqiang, a real estate tycoon and a public critic of Xi, vanished in March 2020 and was later sentenced \nto 18 years in prison.\nFrom I.P.O.s to Inflation Data: What’s at Risk in a Shutdown DealBook Newsletter\n• Wu Xiaohui, former chairman of Anbang Insurance Group, which owns the Waldorf Astoria in New York, was \ndetained in 2017 and sentenced to 18 years in prison.\n• Xiao Jianhua, a Chinese-Canadian billionaire, was seized from a luxury hotel in Hong Kong in 2017 and jailed \non corruption charges last year.\n• Whitney Duan, a property developer said to be China’s richest woman, disappeared in 2017.\nTHE SPEED READ \nDeals\n• GIC, Singapore’s sovereign wealth fund, reportedly sold its stake in the investment firm Vista Equity Partners \nafter its founder, Robert Smith, was ensnared in a tax scandal. (FT)\n• Shares in the women’s wear retailer Chico’s soared 63 percent after the private equity firm Sycamore Partners \nagreed to buy it for $938 million. (Reuters)\nPolicy\n• “Gifts, Gadgets and Greece: Inside a Huawei Lobbying Campaign” (NYT)\n• The Financial Stability Board plans to examine rising debt burdens at hedge funds and other non-banks. \nMeanwhile, Moody’s warned about an increase in lending by banks and private lenders to leveraged \nbuyouts. (FT)\nBest of the rest\n• How Palantir, the data giant chaired by Peter Thiel, is pursuing a deal with Britain’s national health care \nsystem to create one of the world’s biggest caches of health data. (NYT)\n• Inside the debate in Canada over whether to extract $67 billion worth of minerals needed for electric vehicle \nbatteries from underneath vast peat bogs that capture greenhouse gasses. (WSJ)\n• “What C.E.O.s Mean When They Talk About ‘Moats’” (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Speaker Kevin McCarthy’s efforts to avert a government shutdown are leaning toward no deal. \n(PHOTOGRAPH BY Kent Nishimura for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: September 30, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GenAI Firm Ema Raises $25 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "176 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "GenAI Firm Ema Raises $25 million\nEconomic Times (E-Paper Edition)\nMarch 6, 2024 Wednesday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 176 words\nByline: Tarush.Bhalla@timesinternet.in\nHighlight: Accel, Section 32 and Prosus lead round\nBody\nBengaluru: Enterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 \nmillion (about Rs 207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.  Wipro Ventures, \nVenture Highway, Frontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in \nthis round of funding. Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl \nSandberg, Yahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the \nstartup. Ema will use the funds for research and development, building new offerings and enhancing its existing \nproduct suite, the company said, adding that it will also utilise part of the proceeds for building its go-to-market \nfunction. At present, Ema has a total workforce of 30, spread across India and the US. Ema stands for Enterprise \nMachine Assistant and allows enterprises to build generative AI personas and applications internally to bring about \nautomation and increase efficiency and productivity.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "its_ousted_CEO;_The_company_that_created_ChatGPT_is_in_turmoil_after_Nov2023",
        "header": "Company that created ChatGPT is thrown into turmoil after Microsoft hires",
        "media": "its ousted CEO; The company that created ChatGPT is in turmoil after",
        "time": "November 21, 2023",
        "section": "NATION WORLD",
        "length": "1187 words",
        "byline": "COURTNEY BONNELL and MATT O'BRIEN",
        "story_text": "Company that created ChatGPT is thrown into turmoil after Microsoft hires \nits ousted CEO; The company that created ChatGPT is in turmoil after \nMicrosoft hired its ousted CEO and many more employees threatened to \nfollow him in a conflict that centered in part oin part on how to build artificial \nintelligence that's smarter than humans\nDayton Daily News (Ohio)\nNovember 20, 2023 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1187 words\nByline: COURTNEY BONNELL and MATT O'BRIEN\nBody\nThe company that created ChatGPT was thrown into turmoil Monday after Microsoft hired its ousted CEO and many \nemployees threatened to follow him in a conflict that centered in part on how to build artificial intelligence that's \nsmarter than humans.\nThe developments followed a weekend of drama that shocked the AI field and fueled speculation about the future of \nOpenAI, which named a new chief executive on Friday and then replaced her on Sunday. The newest CEO vowed \nto investigate the firing of co-founder and CEO Sam Altman, who's been instrumental in OpenAI's transformation \nfrom a nonprofit research laboratory into a world-renowned commercial startup that inaugurated the era of \ngenerative artificial intelligence. \nMicrosoft, which has been a close partner of the company and invested billions of dollars in it, announced that \nAltman and OpenAI's former president, Greg Brockman, would lead its new advanced AI research team. Brockman, \nalso an OpenAI co-founder, quit in protest after Altman was fired. \nHundreds of OpenAI employees, including other top executives, threatened to join them at Microsoft in an open \nletter addressed to OpenAI's four-member board that called for the board's resignation and Altman's return. \n\"If the architects and vision and brains behind these products have now left, the company will be a shell of what it \nonce was,\" said Sarah Kreps, director of Cornell University's Tech Policy Institute. \"All of that brain trust going to \nMicrosoft will then mean that these impressive tools will be coming out of Microsoft. It will be hard to see OpenAI \ncontinue to thrive as a company.\" \nMicrosoft CEO Satya Nadella wrote on X, formerly known as Twitter, that he was \"extremely excited\" to bring on the \npair and looked \"forward to getting to know\" the new management team at OpenAI. \nAltman later said on X that his top priority with Nadella is to ensure that OpenAI \"continues to thrive\" and that it is \ncommitted to \"fully providing continuity of operations to our partners and customers.\" \nOpenAI said Friday that Altman was pushed out after a review found he was \"not consistently candid in his \ncommunications\" with the board of directors, which had lost confidence in his ability to lead the company. \nCompany that created ChatGPT is thrown into turmoil after Microsoft hires its ousted CEO The company that \ncreated ChatGPT is in turmoil after Microsoft hired it....\nIn an X post Monday, OpenAI's new interim chief executive, Emmett Shear, said he would hire an independent \ninvestigator to look into Altman's ouster and write a report within 30 days. \n\"It's clear that the process and communications around Sam's removal\" were handled \"very badly,\" wrote Shear, \nwho co-founded Twitch, an Amazon-owned livestreaming service popular with video gamers. \nHe said he also plans in the next month to \"reform the management and leadership team in light of recent \ndepartures.\" After that, Shear said, he would \"drive changes in the organization,\" including \"significant governance \nchanges if necessary.\" \nOriginally started as a nonprofit, and still governed as one, OpenAI's stated mission is to safely build AI that is \n\"generally smarter than humans.\" Debates have swirled around that goal and whether it conflicts with the \ncompany's increasing commercial success. \nThe reason behind the board's removal of Altman was not a \"specific disagreement on safety,\" nor does the board \noppose commercialization of AI models, Shear said. \nOpenAI last week declined to answer questions about Altman's alleged lack of candor. The company's statement \nsaid his behavior was hindering the board's ability to exercise its responsibilities. \nA key driver of the shakeup, OpenAI's co-founder, chief scientist and board member Ilya Sutskever, expressed \nregrets for his participation in the ouster. \n\"I never intended to harm OpenAI. I love everything we've built together and I will do everything I can to reunite the \ncompany,\" he said Monday on X. \nThe open letter began circulating Monday. According to a copy obtained by The Associated Press, the number of \nsignatures amounted to a majority of the company's 770 employees. The AP was not able to independently confirm \nthat all of the signatures were from OpenAI employees. \n\"Everyone at @OpenAI is united,\" one of the signatories, research scientist Noam Brown, said on X. \"This is not a \ncivil war. Unless Sam and Greg are brought back, there will be no OpenAI left to govern.\" \nThe letter alleged that after Altman's firing, the company's remaining executive team had recommended that the \nboard resign and be replaced with a \"qualified board\" that could stabilize the company. But the board resisted and \nsaid allowing OpenAI to be destroyed would be consistent with its mission, according to the letter. \nOpenAI has said since its 2015 founding that its goal is to advance AI in a way that benefits all humanity. \nA company spokesperson confirmed that the board received the letter. \nMicrosoft declined to comment on the letter. \nAfter Altman was pushed out, he stirred speculation about coming back into the fold in a series of tweets. He posted \na selfie with an OpenAI guest pass Sunday, saying this is \"first and last time i ever wear one of these.\" \nHours earlier, he tweeted, \"i love the openai team so much,\" which drew heart replies from Brockman and Mira \nMurati, OpenAI's chief technology officer who was initially named as interim CEO. \nIt's not clear what transpired between the announcement of Murati's interim role Friday and Shear's hiring, though \nshe was among several employees Monday who tweeted, \"OpenAI is nothing without its people.\" Altman replied to \nmany with heart emojis. \nThe board consists of Sutskever, Quora CEO Adam D'Angelo, tech entrepreneur Tasha McCauley and Helen \nToner of the Georgetown Center for Security and Emerging Technology. None of them responded to calls or emails \nCompany that created ChatGPT is thrown into turmoil after Microsoft hires its ousted CEO The company that \ncreated ChatGPT is in turmoil after Microsoft hired it....\nseeking comment. Because of its nonprofit structure, the board differs from most startup boards that are typically \nled by investors. \nAltman helped catapult ChatGPT to global fame based on its ability to respond to questions and produce human-\nlike passages of text in a seemingly natural way. \nIn the past year, he has become Silicon Valley's most in-demand voice on the promise and potential dangers of \nartificial intelligence. \nEarlier this year, he went on a world tour to meet with government officials, drawing big crowds at public events as \nhe discussed the risks of AI and attempts to regulate the emerging technology. \nBut as money poured into OpenAI this year, helping to advance its development of more capable AI, it also brought \nmore conflict around whether that fast pace of commercialization fit with the startup's founding vision, said Kreps, \nthe Cornell University professor. But rather than slow that pace, Altman's ouster may simply shift it out of OpenAI. \nAltman \"really has a walk-on-water aura, and I think a lot of it is well deserved,\" Kreps said. \"He's the one who has \nattracted the investment, and he'll do that wherever it is.\" \nMicrosoft's shares rose 2% on Monday and hit an all-time high. \nThe AP and OpenAI have a licensing and technology agreement allowing OpenAI access to part of the AP's text \narchives. \nAssociated Press writers Brian P. D. Hannon in Bangkok and Haleluya Hadero in New York contributed to this \nreport.\nGraphic\n \nFile - Sam Altman participates in a discussion during the Asia-Pacific Economic Cooperation (APEC) CEO Summit, \nThursday, Nov. 16, 2023, in San Francisco. Microsoft has announced that it's hired Sam Altman and another \narchitect of ChatGPT maker OpenAI after they unexpectedly departed the company days earlier in a corporate \nshakeup that shocked the artificial intelligence world. Microsoft Chairman and CEO Satya Nadella also tweeted \nMonday, Nov. 20, 2023 that the major investor in the chatbot that kicked off the generative AI craze is committed to \nits partnership with OpenAI. (AP Photo/Eric Risberg, File)\nLoad-Date: November 21, 2023"
    },
    {
        "file_name": "Christmas_shopping_Dec2023",
        "header": "Stuck on holiday gifts? What happened when I used AI to help with",
        "media": "Christmas shopping",
        "time": "December 4, 2023",
        "section": "",
        "length": "1316 words",
        "byline": "Betty Lin-Fisher, USA TODAY",
        "story_text": "Stuck on holiday gifts? What happened when I used AI to help with \nChristmas shopping\nUSA Today Online\nDecember 1, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 1316 words\nByline: Betty Lin-Fisher, USA TODAY\nBody\nI admit it. I have never been great at coming up with gift ideas.\nI do not have that gift, so to speak, of knowing exactly what someone would like without asking or I worry that they’ll \nwant to return what I ultimately pick. Occasionally, I have hit a home run picking up on an idea for the perfect gift.  \nIt has also become more difficult as members of our immediate and extended family have gotten older and can buy \nthings themselves. \nUsually, I’ve relied on lists or links from the person or a loved one who is offering some suggestions. \nSo when my editor asked me to do a story about using artificial intelligence to help with my holiday shopping, I was \nintrigued and a little nervous. Would AI be better than me with gift ideas? \nThe timing was also appropriate as shortly after I got my assignment, Google announced it was beefing up its AI \noffering of its “search generative experience” to help shoppers find gifts during the holiday season. \nHow do you shop using artificial intelligence or AI?\nI first checked in with David Schweidel, a marketing professor at the Goizueta Business School at Emory University \nin Georgia. His research specializes in marketing technology and AI. \nI told Schweidel that I was an AI novice, since I had never used Chat GPT or another AI service. But I \nacknowledged that I’ve likely used AI via everyday apps. \n“That’s one of the things that kind of catches people off guard,” said Schweidel. “AI in our lives is not new, whether \nwe’ve used Google Maps or if you use Alexa or Siri or the spam filter on your email or autocomplete in texts and \nemails.” \nNow technology companies are taking that user-friendly interface to gather new content from the web to help \npeople with their holiday shopping, he said. \nLink to Image\nSchweidel hadn’t had a chance to play with the new upgraded Google AI shopping tool when we spoke, but he had \ndone some AI shopping searches using the subscription version of Chat GPT Plus, which is connected to live \nsearching. \nSchweidel found in toying around on Chat GPT Plus and speaking to someone at Google about its newest feature, \nthat giving more information will get a better outcome. \nStuck on holiday gifts? What happened when I used AI to help with Christmas shopping\nThe biggest difference, Schweidel said, is this is beyond a “search” or using it as a “search engine” and keywords. \n“Get out of the mindset of saying ‘What’s the key phrase that I put into Google’ and think about this literally as a \nconversation,” he said. \n“The chat interface helps because the more tailoring you give it, the better output you’re going to get,” he said. \nSchweidel has also used generative AI to make unique images and put those on a gift. He once had an image of a \nsloth and a sunset generated for his youngest daughter and had the image put on a notebook. \nHow did my AI shopping experience go on Google? \nI first started with Google’s Search Generative Experience, which consumers can opt into in Search Labs on the \nGoogle app, the Google home page or on Chrome desktop. \nWhen you start, the normal search results you would expect from a Google search will show up – articles and gift \nguides, photos of sponsored products. If you’ve opted into the Generative Search Engine, there will also be a button \non top that asks “Get an AI-powered overview for this search?”  \nI tried “gifts for man who loves disc golf and estate sales and cooking” for my husband. I think I gave it too much to \nsearch. It only came up with disc golf things, including a t-shirt one of my kids already got him last year. \nI instead tried “Gifts for cooking lovers.” Many of the searches led me to gift guides, which I could rabbit hole down.\nGoogle invited me to “shop deals,” so I clicked on the link. It was a generalized “deals” page, so I updated the \nsearch to “shop deals cooking.” That was overwhelming, too. \nI thought I’d try “gifts for 12-year-old girl” for my niece. But I decided I wasn’t exactly sure what she’d like and that \nwas too risky. I asked her dad for some specific ideas. \nTo make myself feel better in the middle of some searches that didn’t seem to be going anywhere, I went to my \ncollege son’s list and bought a few things. \nNext, my daughter, who is in her 20s, wanted a nice pullover top for work. \nI entered “Women's fashion for 20 year olds.\" I changed it to \"women’s tops and blouses for 20 year olds.” \nI looked through several rows of potential pictures of tops, but didn’t see anything initially that struck my fancy. A \npicture in a link for a Nordstrom top with some nice bow ties on the ends of the sleeves got my attention. I clicked \non it and decided to get it. I made sure there was free shipping and free returns, just in case she doesn’t like it. \nIt wasn’t specifically an AI generated gift, but AI did lead me there. \nGoogle's AI shopping experience also offers virtual try-on options with certain retailers so a shopper can see what a \ntop looks like on a variety of male and female models of various body types. A feature to generate photorealistic \nimages of what you’re shopping for will also be available in December.\nHow did AI shopping go with Chat GPT? \nI decided to try Chat GPT. I tried a search for my husband again. \nChat GPT came up with a number of suggestions, but no links. I asked if it could give me some links. \nNeed help with holiday shopping?  Google wants you to use artificial intelligence\nThat’s when Chat GPT told me that it did not have the ability “to generate specific links or browse the internet in \nreal-time. However, I can offer guidance on where you might find the types of gifts mentioned.” \nStuck on holiday gifts? What happened when I used AI to help with Christmas shopping\nThis is what Schweidel had been telling me about. A spokesperson for Open AI, the maker of Chat GPT, confirmed \nfor me that the free version is using information through January 2022, an update from September 2021. The paid \nversion of Chat GPT Plus – which has a waiting list right now – can link to the Internet. \nInstead, Chat GPT gave me some links to general websites. Microsoft, which is one of the largest investors in Open \nAI, has incorporated the latest GPT-4 used in Chat GPT Plus into its Microsoft Bing search engine. So if you’re \ngoing to play around with AI shopping, go to Microsoft Bing instead of Chat GPT’s free version. I tried a few \nsearches with Microsoft Bing and got similar results to my Google shopping searches. It did provide me with \npictures and links to items currently available.\nShould I worry about privacy while shopping with AI? \nA reader commented on a recent story I wrote about Google’s AI shopping tool saying she was completely against \nAI for shopping and worried about the privacy implications of AI. \nI asked Schweidel about losing our privacy while shopping with AI – or how much more privacy are we giving up. \nSchweidel said consumers already give away a lot of information when we are online shopping and searching. It \ncomes down to pros and cons, he said. \n“What we often see is people say privacy is important, but when push comes to shove, they’d rather have the digital \nconvenience,” he said. \nSchweidel said he sees more players entering the AI shopping field and retailers incorporating it more in future \nholiday shopping seasons. \nMy AI shopping experience verdict\nOverall, I would say the experience helped me expand some gift possibilities for people on my list, but it wasn’t a \nmagical personal shopper. I still had to work my way through decisions to choose links to explore or decide that I \nneeded to go in a different direction. \nI can see how it could be helpful to others. I think that as the technology develops and consumers get more \ncomfortable using it, the possibilities will grow. \nFor this holiday season, though, most of my shopping was done by clicking on links from relatives. \nBetty Lin-Fisher is a consumer reporter for USA TODAY. Reach her at blinfisher@USATODAY.com or follow her on \nX, Facebook or Instagram @blinfisher.\nThis article originally appeared on USA TODAY: Stuck on holiday gifts? What happened when I used AI to help with \nChristmas shopping\nLoad-Date: December 4, 2023"
    },
    {
        "file_name": "overpriced?_Jun2023",
        "header": "Down up to 24% from high, are IT stocks like Infosys a steal deal now or",
        "media": "overpriced?",
        "time": "June 26, 2023",
        "section": "STOCK IN NEWS",
        "length": "820 words",
        "byline": "Nikhil Agarwal",
        "story_text": "Down up to 24% from high, are IT stocks like Infosys a steal deal now or \noverpriced?\nThe Economic Times\nJune 27, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 820 words\nByline: Nikhil Agarwal\nBody\nEven as some of India's largest IT stocks are trading up to 25% below their 52-week peak levels, bargain hunters \nobsessed with PE valuation multiples aren't finding enough reasons to start buying the diamonds lying in dust.The \nreason why most institutional investors are staying away from IT stocks is not just because of the worsening growth \noutlook but also because even after the dip Nifty IT index is still trading at a 10% premium of 21.3x to its 10-year \naverage valuations of 19.4x.All the large 5 IT stocks - TCS, Infosys, HCL Tech, Wipro and Tech Mahindra - are also \ntrading above their pre-Covid valuation levels. Midcap IT stocks, on the other hand, are trading at a 25% premium \nto largecaps.The 12-month forward PE of Infosys has now fallen to 20x from March 2022's 31x but is still trading \nabove the 18x PE seen in March 2019. Its shares have fallen over 24% from a 52-week high level of Rs \n1,672.Similarly, TCS shares are down 10% from peak but it is still trading at 24x PE against pre-Covid level of \n22x.\"The forward PE ratios of largecap IT stocks suggest that they might not be the best value buys at this moment, \ndespite a correction in prices. \nThis could be attributed to the fact that projected forward earnings have also been adjusted downward, which keeps \nthese stocks at higher multiples,\" said Sonam Srivastava, smallcase manager & Founder of Wright Research.Indian \nIT exports have grown at a compound annual growth rate (CAGR) of 9-10% over the last decade. However, in \nFY22, the exports experienced an astonishing growth of 18% due to one-time spends driven by savings related to \nthe COVID-19 pandemic. \"Given this context, we believe that the sector's export growth is likely to normalize to its \nhistorical growth levels of 8-10% CAGR. This is because most of the core sectors, such as US and European \nbanks, auto original equipment manufacturers (OEMs), and ancillaries, have returned to pre-pandemic levels of \nspending,\" Hemang Kapasi, Head of Equities, Sanctum Wealth, pointed out.From this point onward, rather than \nexpecting a significant correction in valuations, the sector may experience a time correction over the next couple of \nquarters, he said.Analysts anticipate that the IT industry will face challenges for a couple of quarters due to sluggish \nworldwide demand.Global brokerage Jefferies has warned that rising risks to demand recovery in 2HFY24 may also \nlead to further PE derating. \"Our recent channel checks and interactions with companies point to a worsening \ndemand outlook with discretionary IT spending still under pressure and 1Q being softer than expected. We cut our \nFY24 growth estimates by 50-150 bps and lower our below-consensus FY24-26 EPS estimates further by up to 4% \nto factor this,\" said Jefferies analysts Akshat Agarwal and Ankur Pant.Midcap vs largecapMidcap IT stocks are also \ntrading at relatively high multiples, ranging between 25x to 30x. \"This valuation range can be considered as \nexpensive. Considering the current pressures in the market, it appears that there may be more potential for midcap \nIT stocks to experience a further decline compared to large-cap IT stocks,\" Kapasi said, adding that the scope for \nde-rating in valuations is lower for largecap IT stocks.Calculations done by Jefferies shows that midcap IT stocks \nare at PE of 26.3x against the long-term average of 24.5x.Sonam Srivastava of Wright Research believes that the \nblend of growth potential and relative resilience from global events make midcap IT stocks an attractive \nproposition.\"The appeal of midcap IT stocks over their large-cap counterparts stems from their potential for higher \ngrowth, increased innovation scope, and a stronger reliance on the domestic economy. As market rallies broaden, \nDown up to 24% from high, are IT stocks like Infosys a steal deal now or overpriced?\nthese midcap stocks stand to gain significantly,\" the fund manager said.Should you buy or sell?Despite the \nchallenges faced by the sector, many IT companies continue to generate strong cash flows and offer decent \ndividend yields.According to Jefferies, the average FY24 dividend yield of top 5 IT stocks comes to around 3.8% \nwith Tech Mahindra commanding the highest dividend yield of 5.4% followed by HCL Tech's 5%.\"If the US \neconomy manages to regain stability, leading to a resurgence of deal wins for the Indian IT sector, or if the Indian IT \nindustry successfully innovates and makes notable strides in the realm of generative AI, the earnings outlook for \nthese companies could improve substantially. In such a case, their current valuations might appear quite appealing \nbased on revised earnings projections,\" said Srivastava.For pure long-term investors with a 5-10 year horizon, it \nmay be a good time to buy IT stocks gradually in SIP mode before the next leg of the bull run begins.(Disclaimer: \nRecommendations, suggestions, views and opinions given by the experts are their own. These do not represent the \nviews of The Economic Times) For Reprint Rights: timescontent.com\nLoad-Date: June 26, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "Ahead of Market: 10 things that will decide D-Street action on Tuesday",
        "media": "The Economic Times",
        "time": "April 29, 2024",
        "section": "STOCK IN NEWS",
        "length": "947 words",
        "byline": "Navdeep Singh",
        "story_text": "Ahead of Market: 10 things that will decide D-Street action on Tuesday\nThe Economic Times\nApril 30, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 947 words\nByline: Navdeep Singh\nBody\nIndian shares rose on Monday as gains in the second-largest private lender ICICI Bank on better-than-expected \nquarterly profit spurred a rise in heavyweight financials.The NSE Nifty 50 rose 1% at 22,643, while the S&P BSE \nSensex added 1.28% to 74,671, logging their best sessions in eight weeks.Here's how analysts read the market \npulse:\"Nifty opened on a positive note and continued to inch higher throughout the day to close with gains of 223 \npoints. On the daily charts, we can observe that Nifty has been holding on to the 20-day moving average and rising \nsteadily. The pullback in the previous trading session was bought into and Nifty resumed its up move. The \nimmediate hurdle on the upside is placed at 22,776 and above that potential towards 23,000. Thus, we shall \ncontinue to ride the up move with a trailing stop loss of 22,440 for the Nifty,\" said Jatin Gedia of Sharekhan.Rupak \nDe of LKP Securities, said, \"Nifty continued to remain in the uptrend as the index closed with solid gains. \nThe index maintained its position above the critical 21EMA, signaling a continuation of the bullish trend. The \nmomentum indicator, RSI (14), shows a bullish crossover. It is projected to move towards 22800-22850 in the short \nterm, with support at 22550.\"That said, here’s a look at what some key indicators are suggesting for Tuesday's \naction:US marketWall Street's main indexes crept higher in volatile trading on Monday as shares of Tesla and \nApple advanced while investors exercised caution ahead of the Federal Reserve's interest rate decision later in the \nweek.Tesla shares shot up nearly 13%, driving a 1.8% rise in the consumer discretionary sector, after the electric \nvehicle maker cleared some key regulatory hurdles that had long hindered the roll-out of its self-driving software in \nChina, its second-largest market.Apple added 3.5% after a report that the iPhone maker had renewed discussions \nwith OpenAI about using the startup's generative artificial intelligence (AI) technology. Bernstein upgraded the \nstock to \"outperform\".At 09:46 a.m. the Dow Jones Industrial Average rose 86.82 points, or 0.23%, to 38,326.48, \nthe S&P 500 gained 6.08 points, or 0.12%, to 5,106.04 and the Nasdaq Composite gained 10.48 points, or 0.08%, \nto 15,940.42.European sharesEuropean shares touched a two-week high on Monday, extending last week's strong \nrun, with euro zone economic data and a U.S. policy decision in focus.The pan-European STOXX 600 was up \n0.3%, as of 0837 GMT, after logging its first weekly gain in four on Friday.The STOXX 600 lost some steam in April \nafter five straight months of gains amid the impact of record-high interest rates, ongoing Middle East tensions and \nthe European Central Bank's policy outlook.Investors await euro zone inflation data on Tuesday and the U.S. \nFederal Reserve's much-anticipated May interest rate decision on Wednesday, while keeping a track of the ongoing \nearnings season.Tech View: Long bull candleNifty on Monday ended 223 points higher to form a long bull candle on \nthe daily chart as it challenged the crucial hurdle of 22,500 levels.The short-term uptrend of Nifty seems to have \nresumed after one day of weakness. The next upside levels to be watched are around 22800-22900. Immediate \nsupport is at 22500, said Nagaraj Shetti of HDFC Securities.Analysis of Nifty Put options reveals a concentration of \nOpen Interest (OI) at the 22,500 level, suggesting potential support during the ongoing expiry. Conversely, \nsignificant OI concentrations on the Call side are observed at the 23,000 level.Stocks showing bullish \nbiasMomentum indicator Moving Average Convergence Divergence (MACD) showed bullish trade on the counters \nof Vadilal Industries, VST Tillers Tractors, IRCTC, Westlife Foodworld, and Shriram Finance among others.The \nMACD is known for signaling trend reversals in traded securities or indices. When the MACD crosses above the \nAhead of Market: 10 things that will decide D-Street action on Tuesday\nsignal line, it gives a bullish signal, indicating that the price of the security may see an upward movement and vice \nversa.Stocks signaling weakness aheadThe MACD showed bearish signs on the counters of Waaree Technologies, \nBajaj Finance, Mankind Pharma, and Ion Exchange among others. A bearish crossover on the MACD on these \ncounters indicates that they have just begun their downward journey.Most active stocks in value termsICICI Bank \n(Rs 3,275 crore), HDFC Bank (Rs 2,745 crore), SBI (Rs 2,232 crore), Kotak Bank (Rs 1,835 crore), Axis Bank (Rs \n1,747 crore), Apollo Hospital (Rs 1,644 crore), and HCL Tech (Rs 1,604 crore) were among the most active stocks \non the NSE in value terms. Higher activity on a counter in value terms can help identify the counters with highest \ntrading turnovers in the day.Most active stocks in volume termsTata Steel (Shares traded: 4.5 crore), ICICI Bank \n(Shares traded: 2.8 crore), SBI (Shares traded: 2.7 crore), HDFC Bank (Shares traded: 1.8 crore), Axis Bank \n(Shares traded: 1.5 crore), NTPC (Shares traded: 1.3 crore), and ITC (Shares traded: 1.1 crore) were among the \nmost traded stocks in the session on NSE.Stocks showing buying interestShares of ICICI Bank, SBI, Axis Bank, \nGrasim Industries, and Divis Labs among others witnessed strong buying interest from market participants as they \nscaled their fresh 52-week highs, signaling bullish sentiment.Stocks seeing selling pressureNo major stocks hit their \n52-week lows on Monday.Sentiment meter favours bullsOverall, market breadth favoured bulls as 1,982 stocks \nended in the green, while 1,934 names settled in the red.(Disclaimer: Recommendations, suggestions, views and \nopinions given by the experts are their own. These do not represent the views of Economic Times) For Reprint \nRights: timescontent.com\nLoad-Date: April 29, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Axios Sees A.I. Coming, and Shifts Its Strategy",
        "media": "The New York Times",
        "time": "April 12, 2024",
        "section": "BUSINESS; media",
        "length": "890 words",
        "byline": "Katie Robertson Katie Robertson covers the media industry for The Times. Email: ,",
        "story_text": "Axios Sees A.I. Coming, and Shifts Its Strategy\nThe New York Times \nApril 11, 2024 Thursday 11:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 890 words\nByline: Katie Robertson Katie Robertson covers the media industry for The Times. Email: , \nkatie.robertson@nytimes.com\nHighlight: “The premium for people who can tell you things you do not know will only grow in importance, and no \nmachine will do that,” says Jim VandeHei, C.E.O. of Axios.\nBody\n“The premium for people who can tell you things you do not know will only grow in importance, and no machine will \ndo that,” says Jim VandeHei, C.E.O. of Axios.\nIn the view of Jim VandeHei, the chief executive of Axios, artificial intelligence will “eviscerate the weak, the \nordinary, the unprepared in media.”\nThe rapid rise of generative A.I. — and its implications for how people will discover and consume news — has \nunsettled many media executives. Like them, Mr. VandeHei has spent the past year or so pondering how to \nrespond.\nNow he’s becoming one of the first news executives to adjust their company’s strategy because of A.I.\nMr. VandeHei says the only way for media companies to survive is to focus on delivering journalistic expertise, \ntrusted content and in-person human connection. For Axios, that translates into more live events, a membership \nprogram centered on its star journalists and an expansion of its high-end subscription newsletters.\n“We’re in the middle of a very fundamental shift in how people relate to news and information,” he said, “as \nprofound, if not more profound, than moving from print to digital.”\n“Fast forward five to 10 years from now and we’re living in this A.I.-dominated virtual world — who are the couple of \nplayers in the media space offering smart, sane content who are thriving?” he added. “It damn well better be us.”\nAxios is pouring investment into holding more events, both around the world and in the United States. Mr. VandeHei \nsaid the events portion of his business grew 60 percent year over year in 2023.\nThe company has also introduced a $1,000-a-year membership program around some of its journalists that will \noffer exclusive reporting, events and networking. The first one, announced last month, is focused on Eleanor \nHawkins, who writes a weekly newsletter for communications professionals. Her newsletter will remain free, but \npaying subscribers will have access to additional news and data, as well as quarterly calls with Ms. Hawkins.\nMembership programs will next be built around Sara Fischer, a media reporter, and the business editor Dan \nPrimack, who writes the daily Pro Rata newsletter, according to a person familiar with the company’s plans.\n“I’m trying to align the company with the people who have a ton of talent: They thrive, we thrive,” Mr. VandeHei \nsaid.\nAxios Sees A.I. Coming, and Shifts Its Strategy\nAxios will expand Axios Pro, its collection of eight high-end subscription newsletters focused on specific niches in \nthe deals and policy world. The subscriptions start at $599 a year each, and Axios is looking to add one on defense \npolicy. The company just hired an executive, Danica Stanciu, to oversee the expansion into more policy areas. Ms. \nStanciu was instrumental in growing Politico Pro, Politico’s premium subscription offering, into a thriving business.\n“The premium for people who can tell you things you do not know will only grow in importance, and no machine will \ndo that,” Mr. VandeHei said.\nPart of the pivot entails a restructuring of Axios’s leadership team. Sara Kehaulani Goo, the editor in chief of the \nAxios newsroom, will head up the editorial side of events and running new platforms. Aja Whitaker-Moore, the \nexecutive editor of the newsroom, will be promoted to editor in chief and will oversee all published content.\n“I hope the next leg of this journey can really be focused on how we take the subject matter expertise to the next \nlevel,” she said.\nAxios was started in 2017 by Mr. VandeHei, a co-founder of Politico, along with Mike Allen and Roy Schwartz. In \nAugust 2022, Cox Enterprises acquired Axios in a deal that valued the company at $525 million, with its founders \nstaying on as minority shareholders.\nMr. VandeHei said Axios was not currently profitable because of the investment in the new businesses. The \ncompany has continued to hire journalists even as many other news organizations have cut back. An Axios \nspokeswoman said that Axios Local now had nearly two million subscribers across 30 newsletters, and that Axios’s \nnational newsletters had about 1.5 million.\nIn addition to figuring out how A.I. could change news consumption by the public, many media companies are \nracing to figure out how to address the ingestion of their content by A.I. chatbots. The New York Times, for \nexample, sued Microsoft and OpenAI in December for copyright infringement, arguing that millions of articles were \nused, without authorization, to train the tech companies’ chatbots.\nMr. VandeHei said that while he thought publications should be compensated for original intellectual property, \n“that’s not a make-or-break topic.” He said Axios had talked to several A.I. companies about potential deals, but \n“nothing that’s imminent.”\n“One of the big mistakes a lot of media companies made over the last 15 years was worrying too much about how \ndo we get paid by other platforms that are eating our lunch as opposed to figuring out how do we eat people’s lunch \nby having a superior product,” he said.\nPHOTOS: Part of the pivot for the chief executive Jim VandeHei, at left, entails a restructuring of the Axios \nleadership team, which will include, above left to right: Aja Whitaker-Moore, who will be editor in chief, and Sara \nKehaulani Goo, who will head up the editorial side of events and running new platforms. (PHOTOGRAPHS BY \nJARED SOARES FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: April 12, 2024"
    },
    {
        "file_name": "took_issue_with_reports_Apr2024",
        "header": "Reports: Workers in India behind Just Walk Out tech; Amazon spokesperson",
        "media": "took issue with reports",
        "time": "April 8, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "641 words",
        "byline": "By, Betty Lin-Fisher, USA TODAY",
        "story_text": "Reports: Workers in India behind Just Walk Out tech; Amazon spokesperson \ntook issue with reports\nUSA Today\nApril 8, 2024 Monday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 641 words\nByline: By, Betty Lin-Fisher, USA TODAY\nBody\nDoes Amazon's touchless technology, which allows customers to grab what they need on shelves and \"Just Walk \nOut\" without going to a cash register, really rely on human workers in India to review the purchases?\nThe Seattle-based retailer, which  said last week that it was swapping the Just Walk Out technology at more than \nhalf of its 40 Amazon Fresh grocery stores for smart carts, won't really say.\nWhile the Just Walk Out technology sends shoppers their receipts after they've left the store, Amazon Dash carts \nshow customers what they will be charged for each item in real time on a screen, while also allowing shoppers to \nbypass a register. Amazon said the change occurring at its Amazon Fresh grocery stores is in response to \ncustomer feedback but it will continue to use the Just Walk Out technology at more than 130 third-party partners, \nwhich include airports, college stores and cafes.\nAt those locations, the company claims sensors, cameras and other tools help track what a shopper has purchased. \nBut several media outlets have reported that there may be more to it, with hundreds of workers in India playing a \nkey role.\nOn its website, AWS, a separate division of Amazon, said customers using Just Walk Out technology can walk into \na store using Amazon One (where customers can register their palm to connect with their payment method), a \ncredit/debit card, or an app, shop for items and leave. Customers are automatically charged for their purchases.\n\"Sensors, cameras and deep learning tools sense what a consumer takes off the shelf,\" the website said.\nAn Amazon spokesperson explained further: \"Just Walk Out technology is made possible by artificial intelligence \nlike computer vision and deep learning techniques, including generative AI, to accurately determine who took what \nin any retail environment. Amazon built synthetic datasets to mimic millions of realistic shopping scenarios - \nincluding variations in store format, lighting conditions, and even crowds of shoppers - to ensure accuracy in any \nenvironment.\"\nHowever, several media outlets have said that workers in India may also be significantly involved.\nLike many artificial intelligence systems, Amazon's system relies on human moderators and data labelers, who \nreview Just Walk Out transactions and label footage to help train the AI models that make it work, CNBC said. The \nInformation reported last year that the team was made up of more than 1,000 employees, primarily based in India, \naccording to CNBC. An Amazon spokesperson confirmed at the time that it uses human moderators but declined to \nsay how many people it employs in these roles, according to The Information report. Business Insider cited more \nReports: Workers in India behind Just Walk Out tech Amazon spokesperson took issue with reports\nreporting by The Information on Tuesday, that said Just Walk Out is still very reliant on humans, according to an \nunnamed person The Information said had worked on the technology.\nAbout 700 of every 1,000 Just Walk Out sales had to be reviewed by Amazon's team in India in 2022, according to \nThe Information, as reported by Business Insider. Internally, Amazon wanted just 50 out of every 1,000 sales to get \na manual check, according to the report.\nIn a statement, an Amazon spokesperson took issue with the media reports. \"The misconception that Just Walk Out \ntechnology relies on human reviewers watching shoppers live from India is misleading and inaccurate,\" an Amazon \nspokesperson said Thursday in an e-mail statement to USA TODAY. \"As with many AI systems, the underlying \nmachine learning model is continuously improved by generating synthetic data and annotating actual video data.\n\"Our associates validate a small portion of shopping visits by reviewing recorded video clips to ensure that our \nsystems are performing at our high bar for accuracy, which is made possible because we continuously improve \nboth our algorithms and use human input to correct them.\"\nGraphic\n \nCameras placed in the ceiling monitor customers as they pick up the items of choice and bill them as they leave\nthe grab-and-go Market Express located in the Hollywood Casino in Detroit. The cashless store uses\nAmazon's Just Walk Out Technology.\nKirthmon F. Dozier/USA TODAY NETWORK\nLoad-Date: April 8, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Apr2023",
        "header": "Once-vaunted metaverse needs help finding reason for its existence",
        "media": "The Baltimore Sun",
        "time": "April 13, 2023",
        "section": "MAIN; A; Pg. 11",
        "length": "744 words",
        "byline": "Parmy Olson Bloomberg Opinion",
        "story_text": "Once-vaunted metaverse needs help finding reason for its existence\nThe Baltimore Sun\nApril 13, 2023 Thursday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 11\nLength: 744 words\nByline: Parmy Olson Bloomberg Opinion\nBody\nWhen you first glide into Horizon Worlds, the virtual reality app from Meta Platforms Inc., you're greeted with a vivid \ncityscape and portals into worlds with labels like \"adventure\" and \"comedy.\" On a recent visit to the \"adventure\" \nworld, I zoomed around a town in the Wild West toting a Colt single-action Army revolver and occasionally trading \nshots with three other avatars dashing between a saloon and a bank. The avatars sported sunglasses and \nmulticolored hair, but were sans legs, a limitation Meta doesn't appear to have solved yet.\nThere were at least a dozen of these cartoon torsos floating around the Soapstone Comedy Club, whose welcome \nsign said it was created by unemployed_alcoholic. This zone felt more active, with avatars standing in groups and \nmaking small talk about their kids or life in the real world.\nIn the midst of another group, a man named Momsmasher69 shouted at one of the assembled, \"You ain't got no \nlegs!\" and cackled. There was no comedy show on that day - they're typically held on weekend evenings, Eastern \nStandard Time - and most of these people didn't know each other, but they seemed to be having fun all the same. A \nhandful of kids and teens zoomed around wildly and disappeared.\nThe metaverse, an immersive, 3D environment where people interact via avatars, looks a little crisper and more \nvibrant than it did more than a year ago. Visitors to Horizon Worlds are generally well behaved, and such apps have \neven been a source of emotional support for many.\nBut this also, still, feels like a niche hobby. Few are talking about their metaverse experiences on social media \nplatforms like Twitter or TikTok. Anecdotally, several people who have bought Meta's Quest 2 headsets, which are \nnecessary for visiting the company's metaverse apps, tell me they rarely put them on anymore. The headsets take \ntime to adjust and load up, and isolate you from others you may be living with. Motion sickness also affects many \nusers, myself included.\nFollowing a great deal of hype last year, companies now seem to be reining back their investments in the \nmetaverse. Walt Disney Co. has terminated its efforts in the space and Microsoft Corp. shut down its metaverse \napp for socializing, called AltSpaceVR, earlier this year.\nInvestor enthusiasm is also fading. Funding for metaverse startups has dropped in the past year as venture \ncapitalists poured money into generative AI companies. \nIn the Gartner Hype Cycle, a graphical representation of market enthusiasm for emerging tech, the metaverse \nseems to be deep in the \"trough of disillusionment,\" which is also where 3D printing and the Internet of Things (IoT) \nlanguished for a while. The difference is that both 3D printing and IoT went on to find use cases in manufacturing \nenvironments. Zuckerberg is gunning for mainstream appeal, calling the metaverse the \"next chapter for the \nOnce-vaunted metaverse needs help finding reason for its existence\ninternet.\" (Having spent an estimated $36 billion on the metaverse since 2019, he may also be committed to a \nsunk-cost fallacy.)\nYet while places like Horizon Worlds do feel a lot like the early days of AOL chatrooms, the metaverse's slow \nprogress is causing patience to wear thin among Meta's investors - and Zuckerberg can't keep stalling with share \nbuybacks.\nThe CEO also looks misguided in his big push to sell headsets to corporate users instead of focusing on gamers, a \ncohort more willing to embrace virtual reality.\nIronically, Meta's slow progress on the metaverse could also be a problem for Apple Inc., which is launching its \nmixed-reality headset in June.\nApple is known for invigorating new markets with a better-designed product. It entered the smartphone business \nwhen other touchscreen phones from Nokia and Sony Ericsson were barely getting traction. Its AirPods and Apple \nWatch have also redefined standards for those devices.\nBut right now it's not clear how and why people should visit the metaverse at all. Headsets are still too clunky and \nuncomfortable to be a viable alternative to Zoom. And socializing there is, oddly enough, still an isolating \nexperience. Those issues could be ironed out in the next two years if Meta can release more lightweight, faster \nheadsets. But Zuckerberg should probably drop his overtures to enterprise users and focus on making the \nmetaverse fun for socializing and gaming, areas where he seems to have made a decent start. Chasing too many \nstrategies will slow things further, and investors may just lose their patience.\nDistributed by Tribune Content Agency\nLoad-Date: April 13, 2023"
    },
    {
        "file_name": "worry?_May2023",
        "header": "Fake or fact? 2024 is shaping up to be the first AI election. Should voters",
        "media": "worry?",
        "time": "May 8, 2023",
        "section": "",
        "length": "623 words",
        "byline": "Jessica Guynn, USA TODAY",
        "story_text": "Fake or fact? 2024 is shaping up to be the first AI election. Should voters \nworry?\nUSA Today Online\nMay 3, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 623 words\nByline: Jessica Guynn, USA TODAY\nBody\nThe Republican National Committee fired off an attack ad as soon as President Joe Biden announced his reelection \ncampaign last week.\nThe 30-second spot which used fake visuals of China invading Taiwan, financial markets crashing and immigrants \noverrunning the border sported a disclaimer: “Built entirely with AI imagery.”\nThe ad – which the GOP called “an AI-generated look into the country’s possible future if Joe Biden is re-elected in \n2024” – is a sign of what’s to come in the 2024 presidential election, experts say.\n2024 promises to be the first AI election cycle with artificial intelligence potentially playing a pivotal role at the ballot \nbox. And that's raising concerns. \nAI crack down? Senate leader Schumer unveils plans to crack down on AI\nFake Twitter accounts  Is that Twitter account real? 4 ways to help you spot a fake account.\nEven as the technology grows more sophisticated and powerful, spreading into all aspects of American life, there \nare still very few rules governing its use.\nSpurred by the Biden attack ad, Rep. Yvette D. Clarke, D-N.Y., introduced a bill Tuesday that would require that \npolitical ads disclose the use of AI-generated imagery.\n“The upcoming 2024 election cycle will be the first time in U.S. history where AI generated content will be used in \npolitical ads by campaigns, parties, and Super PACs,” Clarke said in a statement. “If AI-generated content can \nmanipulate and deceive people on a large scale, it can have devastating consequences for our national security \nand election security.” \nLink to Image\nPolitical campaigns are pressure testing AI for everything from fundraising emails to get out the vote chatbots, \nNathan Sanders, a data scientist and an affiliate at the Berkman Klein Center at Harvard University, and Bruce \nSchneier, a fellow and lecturer at the Harvard Kennedy School, wrote in The Atlantic.\n“Previous technological revolutions – railroad, radio, television, and the World Wide Web – transformed how \ncandidates connect to their constituents, and we should expect the same from generative AI,” Sanders and \nSchneier wrote.\nBest-case scenario: AI gets voters more engaged and decreases polarization, they said. Worst-case scenario: AI is \nused to mislead or manipulate voters.\nFake or fact? 2024 is shaping up to be the first AI election. Should voters worry?\n“AI will enable instant responses and more precise voter targeting,” said Darrell West, a senior fellow at the Center \nfor Technology Innovation at the Brookings Institution.\nLink to Image\nWhat’s setting off alarm bells: The potential to use AI for dirty tricks, such as “deepfakes,” videos and images that \nhave been digitally created or altered with AI or machine learning to make it appear as if people have said or done \nthings they have not. \n“This will be the first AI election that draws on digital tools that can generate videos, pictures, audiotapes and many \nother things,” West said. “There is a risk that disinformation will expand and expose voters to false material that will \nlook authentic. Mass manipulation is dangerous for democracy because it could distort voter decision-making. Right \nnow, there is no required disclosure so voters may not even know that the videos are fake.”\nWhat's more, concerns are growing about bad actors using AI to meddle in the election.\n“Before AI could take all your jobs, it could certainly do a lot of damage in the hands of spammers, people who want \nto manipulate elections,” Microsoft chief economist Michael Schwarz said at a World Economic Forum event \nWednesday.\nTop executives from AI firm Anthropic, Microsoft, Google and OpenAI will meet with Vice President Kamala Harris \nThursday to discuss AI development, the White House told CNBC.\nThis article originally appeared on USA TODAY: Fake or fact? 2024 is shaping up to be the first AI election. Should \nvoters worry?\nLoad-Date: May 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Leaders Press Advantage With Congress as China Tensions Rise",
        "media": "The New York Times",
        "time": "March 29, 2024",
        "section": "TECHNOLOGY",
        "length": "873 words",
        "byline": "Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C.",
        "story_text": "A.I. Leaders Press Advantage With Congress as China Tensions Rise\nThe New York Times \nMarch 27, 2024 Wednesday 09:10 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 873 words\nByline: Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C. \nShe has written about technology for over two decades.\nHighlight: Silicon Valley chiefs are swarming the Capitol to try to sway lawmakers on the dangers of falling behind \nin the artificial intelligence race.\nBody\nIn recent weeks, American lawmakers have moved to ban the Chinese-owned app TikTok. President Biden \nreinforced his commitment to overcome China’s rise in tech. And the Chinese government added chips from Intel \nand AMD to a blacklist of imports.\nNow, as the tech and economic cold war between the United States and China accelerates, Silicon Valley’s leaders \nare capitalizing on the strife with a lobbying push for their interests in another promising field of technology: artificial \nintelligence.\nOn May 1, more than 100 tech chiefs and investors, including Alex Karp, the head of the defense contractor \nPalantir, and Roelof Botha, the managing partner of the venture capital firm Sequoia Capital, will come to \nWashington for a daylong conference and private dinner focused on drumming up more hawkishness toward \nChina’s progress in A.I.\nDozens of lawmakers, including Speaker Mike Johnson, Republican of Louisiana, will also attend the event, the Hill \n&amp; Valley Forum, which will include fireside chats and keynote discussions with members of a new House A.I. \ntask force.\nTech executives plan to use the event to directly lobby against A.I. regulations that they consider onerous, as well \nas ask for more government spending on the technology and research to support its development. They also plan \nto ask to relax immigration restrictions to bring more A.I. experts to the United States.\nThe event highlights an unusual area of agreement between Washington and Silicon Valley, which have long \nclashed on topics like data privacy, children’s online protections and even China.\n“At the end of the day, whether you are in industry or government, or whatever side of the aisle you are on, we play \nfor team America,” said Representative Jay Obernolte of California, the Republican chair of the House A.I. Task \nForce, who will give opening remarks at the conference.\nAfter the rise over the past year of generative A.I. — technology that has the potential to fundamentally shift \nproductivity, innovation and employment trends — lobbying on the topic has exploded. Last year, more than 450 \ncompanies, nonprofits, universities and trade groups reported lobbying on A.I., more than double the number of \norganizations in the previous year, according to OpenSecrets, a nonprofit research group. Palantir more than \ndoubled its spending on lobbying last year to $5 million, its highest level on record.\nA.I. Leaders Press Advantage With Congress as China Tensions Rise\nAs tech leaders capitalize on anti-China fervor in Washington, civil society groups and academics warn that debates \nover competition for tech leadership could hurt efforts to regulate potential harms, such as the risks that some A.I. \ntools could kill jobs, spread disinformation, and disrupt elections.\n“The dynamics of this U.S. v. China race has profound implications because on the other side of slowing down \nChina is minimal friction and regulation for U.S. companies,” said Amba Kak, who is the executive director of the AI \nNow Institute, a research firm, and a former senior adviser on A.I. to the Federal Trade Commission.\nA.I. experts say China lags the United States in generative A.I. by at least a year and may be falling further behind, \nalthough a new study suggests that it is ahead in the talent.\nMay’s event is being organized by Jacob Helberg, a senior adviser to Palantir and a member of the U.S.-China \nEconomic and Security Review Commission, which reports to Congress on national security threats posed by \nChina. He expanded this year’s forum from the first gathering he organized last year, which was a private dinner \nfocused largely on the threat of TikTok, which is owned by Beijing-based ByteDance.\nIn addition to A.I., lawmakers speaking at the event in the Capitol will push for the Senate to pass legislation to ban \nTikTok, and Tom Mueller, a founding employee of SpaceX, will speak about the space race between the United \nStates and China. Attendees will include Senator Mike Rounds, Republican of South Dakota and the ranking \nmember of the Armed Services Committee, and Representative Ritchie Torres, a New York Democrat on the House \nSelect Committee on the Chinese Communist Party.\n“Tech companies can’t be neutral any more,” Mr. Helberg said, adding that he recuses himself from any work \ninvolving contracts on the U.S.-China Economic and Security Review Commission that could give Palantir an \nadvantage.\nVenture capitalists attending the event have dozens of A.I. investments. Sequoia has invested in more than 70 A.I. \nstartups. Khosla Ventures, a $15 billion venture firm, has several investments, including in OpenAI, the company \nbehind the ChatGPT chatbot.\n“It’s become even more obvious, even more critical, that we treat China as an adversary,” said Vinod Khosla, the \nhead of Khosla Ventures who will speak at the forum. “What I’m worrying about is Western values versus a different \nset of values in China.”\nPHOTOS: Clockwise from top left: Jacob Helberg, a member of the U.S.-China Economic and Security Review \nCommission; House Speaker Mike Johnson; and Representative Ritchie Torres, a Democrat on the House Select \nCommittee on the Chinese Communist Party. (PHOTOGRAPHS BY JASON ANDREW FOR THE NEW YORK \nTIMES; HAIYUN JIANG FOR THE NEW YORK TIMES; AMIR HAMJA/THE NEW YORK TIMES) This article \nappeared in print on page B4.\nLoad-Date: March 29, 2024"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Silicon Valley's A.I. Hype Machine",
        "media": "The New York Times",
        "time": "May 19, 2024",
        "section": "Section SR; Column 0; Sunday Review Desk; Pg. 8; GUEST ESSAY",
        "length": "1135 words",
        "byline": "By Julia Angwin",
        "story_text": "Silicon Valley's A.I. Hype Machine\nThe New York Times\nMay 19, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section SR; Column 0; Sunday Review Desk; Pg. 8; GUEST ESSAY\nLength: 1135 words\nByline: By Julia Angwin\nBody\nIt's a little hard to believe that just over a year ago, a group of leading researchers asked for a six-month pause in \nthe development of larger systems of artificial intelligence, fearing that the systems would become too powerful. \n''Should we risk loss of control of our civilization?'' they asked. \n  There was no pause. But now, a year later, the question isn't really whether A.I. is too smart and will take over the \nworld. It's whether A.I. is too stupid and unreliable to be useful. Consider this week's announcement from OpenAI's \nchief executive, Sam Altman, who promised he would unveil ''new stuff'' that ''feels like magic to me.'' But it was just \na rather routine update that makes ChatGPT cheaper and faster.\n  It feels like another sign that A.I. is not even close to living up to its hype. In my eyes, it's looking less like an all-\npowerful being and more like a bad intern whose work is so unreliable that it's often easier to do the task yourself. \nThat realization has real implications for the way we, our employers and our government should deal with Silicon \nValley's latest dazzling new, new thing. Acknowledging A.I.'s flaws could help us invest our resources more \nefficiently and also allow us to turn our attention toward more realistic solutions.\n  Others voice similar concerns. ''I find my feelings about A.I. are actually pretty similar to my feelings about \nblockchains: They do a poor job of much of what people try to do with them, they can't do the things their creators \nclaim they one day might, and many of the things they are well suited to do may not be altogether that beneficial,'' \nwrote Molly White, a cryptocurrency researcher and critic, in her newsletter last month.\n  Let's look at the research.\n  In the past 10 years, A.I. has conquered many tasks that were previously unimaginable, such as successfully \nidentifying images, writing complete coherent sentences and transcribing audio. A.I. enabled a singer who had lost \nhis voice to release a new song using A.I. trained with clips from his old songs.\n  But some of A.I.'s greatest accomplishments seem inflated. Some of you may remember that the A.I. model \nChatGPT-4 aced the uniform bar exam a year ago. Turns out that it scored in the 48th percentile, not the 90th, as \nclaimed by OpenAI, according to a re-examination by the M.I.T. researcher Eric Martínez. Or what about Google's \nclaim that it used A.I. to discover more than two million new chemical compounds? A re-examination by \nexperimental materials chemists at the University of California, Santa Barbara, found ''scant evidence for \ncompounds that fulfill the trifecta of novelty, credibility and utility.''\n  Meanwhile, researchers in many fields have found that A.I. often struggles to answer even simple questions, \nwhether about the law, medicine or voter information. Researchers have even found that A.I. does not always \nimprove the quality of computer programming, the task it is supposed to excel at.\nSilicon Valley's A.I. Hype Machine\n  I don't think we're in cryptocurrency territory, where the hype turned out to be a cover story for a number of illegal \nschemes that landed a few big names in prison. But it's also pretty clear that we're a long way from Mr. Altman's \npromise that A.I. will become ''the most powerful technology humanity has yet invented.''\n  Take Devin, a recently released ''A.I. software engineer'' that was breathlessly touted by the tech press. A flesh-\nand-bones software developer named Carl Brown decided to take on Devin. A task that took the generative A.I.-\npowered agent over six hours took Mr. Brown just 36 minutes. Devin also executed poorly, running a slower, \noutdated programming language through a complicated process. ''Right now the state of the art of generative A.I. \nis it just does a bad, complicated, convoluted job that just makes more work for everyone else,'' Mr. Brown \nconcluded in his YouTube video.\n  Cognition, Devin's maker, responded by acknowledging that Devin did not complete the output requested and \nadded that it was eager for more feedback so it can keep improving its product. Of course, A.I. companies are \nalways promising that an actually useful version of their technology is just around the corner. ''GPT-4 is the \ndumbest model any of you will ever have to use again by a lot,'' Mr. Altman said recently while talking up GPT-5 at \na recent event at Stanford University.\n  The reality is that A.I. models can often prepare a decent first draft. But I find that when I use A.I., I have to spend \nalmost as much time correcting and revising its output as it would have taken me to do the work myself.\n  And consider for a moment the possibility that perhaps A.I. isn't going to get that much better anytime soon. After \nall, the A.I. companies are running out of new data on which to train their models, and they are running out of \nenergy to fuel their power-hungry A.I. machines. Meanwhile, authors and news organizations (including The New \nYork Times) are contesting the legality of having their data ingested into the A.I. models without their consent, \nwhich could end up forcing quality data to be withdrawn from the models.\n  Given these constraints, it seems just as likely to me that generative A.I. could end up like the Roomba, the \nmediocre vacuum robot that does a passable job when you are home alone but not if you are expecting guests.\n  Companies that can get by with Roomba-quality work will, of course, still try to replace workers. But in workplaces \nwhere quality matters -- and where workforces such as screenwriters and nurses are unionized -- A.I. may not \nmake significant inroads.\n  And if the A.I. models are relegated to producing mediocre work, they may have to compete on price rather than \nquality, which is never good for profit margins. In that scenario, skeptics such as Jeremy Grantham, an investor \nknown for correctly predicting market crashes, could be right that the A.I. investment bubble is very likely to deflate \nsoon.\n  The biggest question raised by a future populated by unexceptional A.I., however, is existential. Should we as a \nsociety be investing tens of billions of dollars, our precious electricity that could be used toward moving away from \nfossil fuels, and a generation of the brightest math and science minds on incremental improvements in mediocre \nemail writing?\n  We can't abandon work on improving A.I. The technology, however middling, is here to stay, and people are going \nto use it. But we should reckon with the possibility that we are investing in an ideal future that may not materialize.\n  The Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com\n  Follow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nhttps://www.nytimes.com/2024/05/15/opinion/artificial-intelligence-ai-openai-chatgpt-overrated-hype.html\nGraphic\nSilicon Valley's A.I. Hype Machine\n \nThis article appeared in print on page SR8.               \nLoad-Date: May 19, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "CCMB Picks AWS' Cloud to Drive Genome Research Projects",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 23, 2023",
        "section": "COMPANIES",
        "length": "641 words",
        "byline": "Our Bureau",
        "story_text": "CCMB Picks AWS' Cloud to Drive Genome Research Projects\nEconomic Times (E-Paper Edition)\nSeptember 23, 2023 Saturday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 641 words\nByline: Our Bureau\nHighlight: AWS has already seen reduced time taken for genomics analysis by up to 98%: Sharma\nBody\nBengaluru: Amazon Web Services (AWS) India Private Ltd has expanded its cloud service offerings to premier \nresearch organisation Centre for Cellular and Molecular Biology (CCMB) to accelerate its genome sequencing \nresearch projects. “AWS has already seen reduced time taken for genomics analysis by up to 98% (from 550 days \nto just 9 days), accelerating research efforts on the study of genetics and human diseases,” Rahul Sharma, \nRegional Managing Director, Asia Pacific & Japan, Public Sector at AWS told ET. CCMB turned to cloud computing \nto seamlessly scale up its data storage and analysis needs replacing the use of on-premises servers that created \nchallenges for scalability and performance. It widens CCMB's scope of investigation, “enhancing our ability to \ncollaborate, and enabling us to focus on the hard research problems at hand such as studying genetic variations \nand their impact on diseases,” said Divya Tej Sowpati, genomics scientist at the CSIR CCMB. \nEnabled by cloud, healthcare organisations can access large health data sets and resources easily, and more \nrapidly to accelerate collaboration to improve the quality of patient-centric care, Sharma added. The announcement \nwas made by AWS India at the Public Sector Symposium in New Delhi on Friday. This follows a series of similar \npartnerships in India's public sector across healthcare, education, and space industries. AWS, the $80 billion cloud \ncomputing arm of US-based online retail giant Amazon, this month also signed a strategic Memorandum of \nUnderstanding with the Indian Space Research Organization (ISRO) and Indian National Space Promotion and \nAuthorization Centre (IN-SPACe) to support space-tech innovations through cloud computing. It also received cloud \nservice provider (CSP) empanelment from India's Ministry of Electronic and Information Technology (MeitY) for \ncloud services provided using the AWS Asia Pacific (Hyderabad) Region. In May this year, chief executive officer of \nAWS Adam Selipsky told ET that it will invest $12.7 billion (Rs 1.05 lakh crore) in India's cloud infrastructure, taking \nits total bet in the country to $16.4 billion by 2030 to meet the growing customer demand for cloud services in India. \nCurrently, AWS hosts two of India's largest digital public infrastructures (DPI) — document storage network \nDigiLocker and vaccination platform Cowin. AWS also has two data centre infrastructure regions in India — AWS \nAsia Pacific (Mumbai) Region, launched in 2016, and the AWS Asia Pacific (Hyderabad) region, launched in \nNovember 2022. There were among 19 AWS regions globally whose  electricity consumption was attributed to \n100% renewable energy. “We are constantly adding new tools and features to enable AWS Partners to speed up \ncustomers' migration to AWS, and help public sector organisations keep up with the rapid pace of change,” Sharma \nsaid. Sharma believes the need for urgent digital skills training remains a key priority for industry and government \nacross India and that AWS is enabling to address the digital skills gap. “We have trained over 4 million individuals in \nIndia with cloud skills since 2017,” he said. In July 2023, the Directorate General of Training in India, announced its \ncollaboration with AWS India to upskill students in cloud computing, data annotation, AI and ML, to boost their \ncapabilities and employability. So far, AWS's public sector customers in India include Digital India Corporation \n(MeitY), Government of Telangana, MPSEDC, CCMB, ConveGenius, National Skill Development Corporation, \nPhysicsWallah, Prasar Bharati News Services, and the University of Delhi.  In India, Sharma adds, AWS aims to \nCCMB Picks AWS' Cloud to Drive Genome Research Projects\ndemocratise access to cloud-enabled technology such as artificial intelligence (AI), generative AI, and ML to help \npublic sector organisations build new solutions to solve pressing citizen challenges.\nLoad-Date: September 23, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "IT gives bears a bull hug!",
        "media": "The Economic Times",
        "time": "January 21, 2024",
        "section": "STOCK IN NEWS",
        "length": "2362 words",
        "byline": "Beena Parmar and Romita Majumdar",
        "story_text": "IT gives bears a bull hug!\nThe Economic Times\nJanuary 21, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 2362 words\nByline: Beena Parmar and Romita Majumdar\nBody\nThe expectations from them were never great, but they did exceed most performance parameters with consummate \nease. So much so that the relative stragglers in the current bull run in Indian stocks, technology companies single-\nhandedly carried broadest benchmarks to new records through the first two weeks of January, belying odds of \nmuted earnings performance in a quarter that is traditionally sluggish for the outsourcing majors. At first glance, of \ncourse, the demon st r at ion of i nve stor confidence in a hitherto neglected investment pocket, which makes up \nnearly a sixth of the weighting on the Nifty, appears difficult to square with performance in the immediate past. \nBusiness growth has remained muted for most IT majors in the third quarter owing to multiple headwinds related to \nuncertainty in decision-making, deferred discretionary and technology spends, US recession concerns, and \ngeopolitical tensions. Hence, the sentiment for Q4 is far from cheerful. \nAnd yet, the market is forgiving. Almost all IT stocks (excluding Infosys and Wipro) outperformed broader markets \n(Nifty-50 and Nifty-500) in calendar year 2023. Both Nifty IT and BSE IT indices have surged around 24 per cent in \nthe calendar year 2023. “Call it happenstance or design, the IT sector today is at the same crossroads it was at \nEXACTLY two years ago. The only difference being it is EXACTLY the mirror image of CY22,” according to a report \nby Nuvama Institutional Equities. Back in 2022, interest rates were at an all-time low with rate cuts triggered by \nCovid19 induced lockdowns that spurred multi-decade high inflation raising expectations of rate hikes by the \nFederal Reserve, US central bank. “Following that, the US was forecast to slip into recession— that we have all \nbeen waiting for!” In anticipation, investors expected lower growth leading to a sharp correction in valuation across \nthe IT sector. “Almost all stocks corrected over 35 per cent over Jan–Jun 2022 — the Nifty IT index too fell by 30 \nper cent. This period saw a sharp correction in the US tech index — Nasdaq — with which the Indian IT sector has \ndeveloped a strong correlation. Interestingly, this sharp drop in stock prices was accompanied by very little cut in \nearnings,” the Nuvama report said. Fast forward to today, global interest rates are high at 5.5 per cent, up for more \nthan six months now, with expectations of a rate cut following the Fed’s dovish stance last month. IT majors hope \nthat rate cuts will prompt companies to loosen their purse strings and start spending on non-core and tech-enabled \nservices. Biswajit Maity, senior principal analyst at Gartner, feels that a wave of change fatigue is washing over \nCEOs and CFOs, making them hesitant to sign new IT deals, and asking for more sureties on risks and rewards to \nmove deals forward. “Businesses are examining their IT expenditures more rigorously, showing reluctance in \ninvesting unless there is a clear and tangible business value. Factors like economic volatility, geopolitical instability, \nsupply chain issues, inflation and skill shortages are contributing to a certain degree of caution. Despite these \nchallenges, we anticipate that IT services spending will continue to grow, nearing double digits,” he said. \nKickstarting the December quarter financial results on January 11, homegrown bellwether Tata Consultancy \nServices (TCS) reported a 1.9 per cent rise in profit at `11,058 crore on a 4 per cent yearon-year (y-o-y) growth in \nrevenue at `60,583 crore. While in constant currency (which discounts the impact of currency fluctuations), revenue \nrose just 1.7 per cent, and smaller rival Infosys’ revenue declined by one per cent. In a seasonally weak quarter, \nthird largest IT major and fastest growing large cap in FY24, HCLTech outperformed all its peers defying the growth \ntrends to post over 6 per cent rise in both revenue and profit, posting its highest revenue growth since Q3FY21. \nIT gives bears a bull hug!\nEven then, HCLTech and all other firms maintained a subdued commentary on discretionary spending in Q4 stating \nan unchanged demand environment and persistent furloughs. TCS chief executive officer and managing director K \nKrithivasan said that “the optimism around interest rates” has not resulted in a reduction of the uncertainty in \ndecision-making. While TCS does not call out guidance, Infosys narrowed its revenue guidance at 1.5-2 per cent for \nFY24 and retained operating margin guidance at 20-22 per cent. HCLTech and Wipro’s Q4 guidance continued to \nremain restrained. Margins across most firms have stayed put with headcount reduction, better utilisation of existing \nemployees and are expected to stabilise. However, the IT players have found unanimous comfort in the deal \npipeline owing to the likely rise in pent up demand for tech spending on new technologies. DEALSA major part of \nthe pronounced optimism is driven from deal wins in the quarter expecting it to start generating revenues going \nforward. “The large mega deals look to be the one bright spot in an otherwise difficult market… We are also seeing \nsome green shoots around some of the large foundational software areas with encouraging performance of the \nsoftware firms, which often leads tech services spending,” said Peter Bendor-Samuel, chief executive officer at \nEverest Group. During the quarter, TCS reported steady deal wins or total contract value (TCV) at $8.1 billion while \nInfosys booked $3.2 billion worth of large deal wins, albeit both undersized from Q2, which Infosys CEO and MD \nSalil Parekh said was an exceptional quarter for deals. Parekh said 71 per cent of the deals were net new. “If you \nlook at the nine months, it is the highest ever value of deal wins that we have had,” he said in a post results \nconference. Krithivasan also points out that the deal pipeline is solid, conversions have been timely and new deal \nrampups are also going ahead as planned. HCLTech won 18 large deals with TCV at $1.92 billion, while Wipro, one \nof the most under-performers in the sector, also reported strong TCV at $3.8 billion. Even mid-sized IT services firm \nLTIMindtree’s order book jumped 21 per cent from a year ago to its highest-ever order inflow at $1.5 billion. Further, \nET reported that an estimated $16 billion of global IT services large deals that will come up for renewal in the next \nsix months. “Come FY25, we expect a large part of new deals awarded to get into the execution mode, followed by \na gradual recovery in discretionary spends,” the Nuvama report said.BFSI The road to recovery for the outsourcing \nindustry is expected to be led by banking, financial services and insurance (BFSI), its largest revenue generating \nsegment, with potential rebound over the next few quarters, going by management commentary in Q3. Despite an \naggregate negative growth of around 1.8 per cent in the BFSI vertical across the top four IT giants, given its size \nand having direct correlation with interest rates, the sector is typically the quickest to return to recovery. “We believe \nthat there will be positive momentum for us in the BFSI vertical in the next quarter. Coupled with some of the deals \nthat we have won, I think that should also ramp up in the coming quarter, in the Q4 and Q1. And all that is what \nmakes us feel that BFSI will actually return to growth,” N G Subramaniam, chief operating officer and executive \ndirector at TCS.For the Tata Group company, the TCV for the BFSI business, which comprises more than a third of \nTCS’s revenue portfolio, was at $2.6 billion. Debashis Chatterjee, CEO and MD of LTIMindtree (sixth-largest IT \nservices firm), which also gets more than one-third of its business from BFSI, said that while the pressures on BFSI \nfunding of the enterprise spending will continue for the near term, “the deal pipeline and BFSI is strong, we have \nsome new wins as well this quarter. So, we will build on that for the future”. EUROPE GROWTH Additionally, the \nUK and Europe are seen as growth regions despite current weakness. “There is also more activity in Europe, most \nspecifically the UK, to get some large engagements over the line,” said Phil Fersht, chief executive of HfS \nResearch. For instance, Wipro won four large deals in Europe in Q3 even as its revenue fell 4.3 per cent \nsequentially. For TCS, Europe’s TCV has fared better than its largest geography North America on a sequential \nbasis. “So, it’s reasonable to expect that Europe will also return to growth in the medium to long term,” TCS CEO \nadded in the earnings concall with analysts. HCLTech chief C Vijayakumar said the firm witnessed “decent organic \ngrowth” from Europe, which grew 5 per cent q-o-q on a constant currency basis and won at least three deals from \nthe western region. AIGenerative artificial intelligence or Gen AI, perhaps the most spoken words in the CEO \ncommentaries in all results conference calls, is a key buzzword seeing investments across companies. The TCS \nchief said the company is taking an early lead in Gen AI capabilities. It has partnered with firms including a \nEuropean bank, an airline and a global insurance firm that are employing Gen AI to bolster their services. Infosys \nCEO Parekh said Gen AI is becoming more and more important in all discussions even if it is small revenue \nnumbers today. “AI capabilities are becoming the key factor in technology investments, as opposed to the old model \nof merely investing in greater numbers of developers and support personnel. This pivot will take several quarters to \nmature and reap financial outcomes based on co-innovation partnerships and provider investments in their \ncapabilities,” HfS Research’s Fersht said.In December, global giant and IT harbinger Accenture (which follows a \nSeptember-August financial year) said it secured projects worth $450 million in generative artificial intelligence in \nthe three months ended November, a marked jumped of 50 per cent from the $300 million garnered in the previous \nIT gives bears a bull hug!\nsix months. UPSKILLING Demand for more specialised talent has also risen. Firms are upskilling and training their \nworkforce to get AI ready. Infosys has already trained its 100,000 employees in GenAI while its larger peer TCS has \ntrained 150,000 and launched a platform for skilled practitioners amongst TCS employees for exploration and \nexperimentation on various Gen AI platforms. Wipro has trained nearly 200,000 employees in basic AI principles \nand over 20,000 in advanced content. According to Gartner’s Maity, the focus on generative AI is expected to bring \nsubstantial benefits in the future. “The year 2024 will be the year when organisations invest in planning for how to \nuse Gen AI, which leaves 2025 and beyond as years of action. In a nutshell, we believe 2024 will be the return of \ngrowth.” In 2023, most firms had announced significant investment numbers upwards of $1 billion. Kunal Purohit, \nchief digital services officer, Tech Mahindra, which is yet to announce its quarterly results, told ET previously that in \n2023, generative AI took centre stage as a mainstream trend and was already enhancing productivity by 50-60 per \ncent. HEADCOUNT Therefore, there is a simultaneous shift in workforce dynamics. PostCovid slowdown in hiring \nhas led to a slump in overall headcount, with the top four Indian IT majors reporting a combined drop of 50,875 \nemployees over the past year, with TCS and Infosys cumulatively shedding 12,000 employees in Q3 alone from last \nyear. Again, HCLTech remained an exception, increasing employees by 2,486. “That is in line with the growth that \nwe are experiencing,” said Prateek Aggarwal, chief financial officer at HCLTech. However, Infosys is not looking at \nany immediate campus recruitment. “For any volume increase, we have a very strong off-campus programme,” said \nits outgoing CFO Nilanjan Roy. TCS, meanwhile, has commenced fresher hiring from campuses, but will continue \nto recalibrate its lateral hiring with focus on utilization. “Our business imperative remains nurturing and developing \nhuman capital and enhanced focus on reskilling and upskilling our employees,” TCS CHRO Milind Lakkad said \nindicating the headcount could further shrink. However, Wipro’s HR head Saurabh Govil expects that as demand \npicks up for the quarters, “we’ll definitely look at hiring in more bigger numbers”. SENIOR MANAGEMENT EXITS \nThe macroeconomic slowdown and recessionary concerns have also resulted in a scarcity of jobs, diminishing the \nallure of job-hopping for employees. This has pushed attrition to its lowest numbers. Nevertheless, there has been a \nnotable trend of senior management executives leaving large IT firms. Infosys, Wipro, and Tech Mahindra have \ncumulatively witnessed more than 30 top-level exits over the past year. This has also led to poaching accusations \nand legal battles. Infosys has accused Cognizant of poaching its employees through “unethical” means, while Wipro \nhas filed lawsuits against at least two of its ex-employees including its CFO Jatin Dalal who joined Cognizant in \nDecember. While Infosys’s Parekh refused to comment, Wipro’s CEO Thierry Delaporte said the company expects \nemployees to meet contractual obligations and that the lawsuits are “nothing personal or targeted”. Brushing aside \nhis own succession planning reports, Delaporte, whose term ends in July 2025, said that the company is building \nthe proper succession planning for his role. “On the overall sector, experts believe that the demand outlook is \nimproving despite low visibility on meaningful recovery of discretionary spends. The pick-up in discretionary \nspending can aid the return to industry growth. Long term growth prospects for Its sector remain strong. We remain \npositive that investors with a long term view will invest in the Indian IT sector,” said Sumit Pokharna, VP and \nresearch analyst, Kotak Securities. Nuvama added in its report that any stock price reaction driven by the change in \nthe Fed’s stance will not sustain unless it is backed by fundamentals. “…earnings must come through — more \nimportantly, earnings must be upgraded from current levels. We anticipate the fundamentals for the sector too shall \nbe conducive for higher growth over the next two-three years.”  For Reprint Rights: timescontent.com\nLoad-Date: January 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2022",
        "header": "Getting Lost in Your Own Sense of Multiple Selves",
        "media": "The New York Times",
        "time": "December 15, 2022",
        "section": "Section D; Column 0; Style Desk; Pg. 4; IT HAPPENED ONLINE",
        "length": "1500 words",
        "byline": "By Madison Malone Kircher and Callie Holtermann",
        "story_text": "Getting Lost in Your Own Sense of Multiple Selves\nThe New York Times\nDecember 15, 2022 Thursday\nLate Edition - Final\nCopyright 2022 The New York Times Company\nSection: Section D; Column 0; Style Desk; Pg. 4; IT HAPPENED ONLINE\nLength: 1500 words\nByline: By Madison Malone Kircher and Callie Holtermann\nBody\nImages generated with Lensa AI are all over social media, but at what cost?\nHave you noticed that many of your friends are suddenly fairy princesses or space travelers? Is your Instagram \nfeed overrun with Renaissance-style paintings of people who were definitely born in the '90s? If so, you are entitled \nto an explanation of what exactly is going on here (and it's not time travel). \n  In the past week, users have flocked to Lensa AI, an app that uses your selfies and artificial intelligence to create \nportraits in a variety of styles. Created by the company Prisma Labs, the app is generating images -- and \ncontroversy.\n  What is Lensa AI?\n  Even if you haven't heard of Lensa AI, you've possibly seen its work this week. As of Wednesday, it was the most \npopular iPhone app in the United States in Apple's app store. Lensa takes your selfies, studies them and churns out \noriginal, computer-generated portraits of you -- or anyone whose photos you feed it.\n  Do I have to pay for it?\n  You do. Right now, you can get 50 avatars -- 10 images in five styles -- for $3.99 during a one-week trial period. \n(For $35.99 you can subscribe to Lensa AI for the year, which gets you a 51 percent discount on future avatars.) \n''Magic Avatars consume tremendous computation power to create amazing avatars for you,'' according to Lensa's \ncheckout page. ''It's expensive, but we made it as affordable as possible.'' Fair warning: Prices have been \nfluctuating as the app has gotten more and more popular and may have changed since this article was published.\n  How does it work?\n  After downloading the app, you'll upload a bunch of selfies. (Do yourself a favor and don't include any where your \nhands are touching your face unless you want to pay money to get back a mess of images with phantom phalanges \nhanging from your mouth.) Select a gender -- male, female or other -- and walk away from your phone for around \nhalf an hour, and when you return, presto. Your face, or something like it, has been stretched and squeezed across \na suite of 50 to 200 -- depending on what package you purchase -- A.I.-generated images with themes including \n''cosmic,'' ''fairy princess'' and ''anime.''\n  OK, but how does it really work?\n  Lensa uses Stable Diffusion, which is when all the horses in a barn spread out to give each other a little space. \nJust kidding: Stable Diffusion is a ''really powerful'' A.I.-based image generator, said Subbarao Kambhampati, a \nGetting Lost in Your Own Sense of Multiple Selves\nprofessor in the School of Computing and Augmented Intelligence at Arizona State University. Similar to DALL-E 2 \nand Midjourney, Stable Diffusion uses image prompts (like your selfies) and text prompts (like ''fantasy,'' one of \nLensa AI's categories) to generate high-quality images that sometimes get ''trippy,'' Dr. Kambhampati said. ''It's \nshowing you pictures that nobody took; it's just able to stitch them up from all the other images that it has seen.''\n  Cool.\n  It is cool! It's fun to see yourself rendered as a painting or an anime character or a little woodland elf with eyes of \ntwo very different sizes and only one hand, even if you have two IRL. (Not every image is going to be perfect.) \nSome users, particularly transgender and gender-nonconforming people, are even finding that using Lensa to \ncreate can offer a sense of gender euphoria.\n  I think some people are mad about this? Should I be mad about this, too?\n  There are a couple of reasons that some users are bristling at the images Lensa AI is spitting out. The first is that \nmany users are reporting that the art is sexualizing them. When we tested the app, several of the images we \nreceived after uploading selfies and selecting ''female'' included full-body renderings, despite the fact that users are \nspecifically instructed to upload only close-up selfies. One image featured our avatar in a metallic bikini à la \nPrincess Leia in ''Return of the Jedi.'' Another included only half a face atop a scantily clad body.\n  Prisma Labs states on its F.A.Q. page that ''occasional sexualization is observed across all gender categories.''\n  Thus, it's fairly simple to use the app to create lewd images of anyone you want. This week, Tech Crunch was \nable to create topless avatars of celebrities using images of an actor's head edited onto topless bodies. ''It turns out \nthe AI takes those Photoshopped images as permission to go wild, and it appears it disables an NSFW filter,'' Tech \nCrunch reported. Now imagine that same experiment, but through the lens of someone who is angling to make \nrevenge porn. It gets murky in a hurry.\n  Andrey Usoltsev, Prisma Labs' chief executive and co-founder, told TechCrunch that using Lensa AI to engage in \n''harmful or harassing behavior'' was a breach of its terms of use.\n  What are users saying about the app?\n  Yasemin Anders, 29, decided to use Lensa AI after seeing it on social media and was particularly excited to see \nherself recreated into an ethereal fairy.\n  She was, however, ultimately disappointed to see that Lensa had given her a thinner body and a slimmer face and \nneck. ''If it's smart enough to turn you into either a fairy or a manga figure, you would think there was some sort of \nsmart enough software behind it to detect fat people, too,'' said Mx. Anders, who lives in Berlin and works in \nmarketing.\n  ''Even if I imagine myself as a fairy, as like an idealized fantasy version of myself, I would still want to look like \nmyself,'' she added. ''And I have always been fat. I've been a fat kid. I've been a fat teenager, and I'm a fat adult \nnow. So why would I want to imagine an ideal version of me that doesn't even look like me?''\n  Other users are reporting that the app is making their skin appear lighter or whiter and is markedly altering their \nfacial features, which Dr. Kambhampati said was an ongoing issue with generative A.I. tools, including Snapchat's \nface lenses. ''If most of the images you fed the system were of white faces, then it's not surprising that when it tries \nto make an image that looks supposedly 'better,' it just makes it whiter,'' he said.\n  How do artists feel about Lensa?\n  Stable Diffusion was trained on the creations of many artists who did not explicitly consent to the use of their work \nfor Prisma Labs's profit, Dr. Kambhampati said, adding, ''If van Gogh was alive today, you'd probably need to pay \nvan Gogh some licensing fee to make your pictures be in van Gogh's style.'' That is not what has happened here.\nGetting Lost in Your Own Sense of Multiple Selves\n  ''To a lot of people, having our art stolen, they don't view it as anything personal -- like, 'Oh, well, you know, it's just \na style; you can't copyright a style,''' said Jonathan Lam, a storyboard artist who works in video games and \nanimation. ''But I would argue that for us, our style is actually our identity. It's is what sets us apart from each other. \nIt's what makes us marketable to clients.'' Mr. Lam, who lives in Vancouver, British Columbia, is one of many artists \nwho have since spoken out on social media about the app.\n  He also noted that some of the works being generated by Lensa include what appear to be renderings of artists' \nsignatures. (Several of our own Lensa-generated images had scribbles where a signature might go on an IRL \npainting.) ''All these tech enthusiasts are saying that these generators are creating something new, but if the artist's \nsignature is still there, it's not something new,'' Mr. Lam said. ''It's just generating something based on the data it \nwas fed.''\n  ''I think the general public is under the assumption that it is a program that has just learned to draw by itself in a \nvacuum, and they don't realize the greater implication of the exploitation of data,'' he added. ''When you're starting \nto see these things becoming monetized and real people being exploited and abused, it's quite scary. And it's even \nscarier when it's disguised as a pretty application.''\n  Has Prisma Labs responded to these concerns?\n  Prisma Labs wrote in a Twitter thread that A.I. ''will not replace digital artists'' and pushed back against the \ncharacterization that Lensa was ripping off artists' work. ''The AI learns to recognize the connections between the \nimages and their descriptions, not the artworks,'' the company wrote. ''As cinema didn't kill theater and accounting \nsoftware hasn't eradicated the profession, AI won't replace artists but can become a great assisting tool.''\n  Are there any privacy concerns?\n  ''I doubt that the whole business model is, 'Give us $10 or $15 and we'll send you back an A.I. glam shot,''' said \nJen King, the privacy and data policy fellow at the Institute for Human-Centered Artificial Intelligence at Stanford \nUniversity. Lensa AI's privacy policy claims that ''face data'' is deleted within 24 hours after it has been processed \nand is not used to identify any individual user -- but it also states that your photos and videos can be used to further \ntrain Lensa's algorithms. Would Dr. King use Lensa AI? ''No.''\n  It Happened Online is a column in which we explain very particular bits of news enabled and amplified by social \nmedia.\nhttps://www.nytimes.com/2022/12/07/style/lensa-ai-selfies.html\nGraphic\n \nPHOTOS: AI Lensa AI, a popular iPhone app, uses selfies and artificial intelligence to create portraits in a variety of \nstyles. (PHOTOGRAPHS VIA LENSA) This article appeared in print on page D4.               \nLoad-Date: December 15, 2022"
    },
    {
        "file_name": "Than_Ever;_Guest_Essay_Mar2024",
        "header": "When Your Technical Skills Are Eclipsed, Your Humanity Will Matter More",
        "media": "Than Ever; Guest Essay",
        "time": "March 26, 2024",
        "section": "OPINION",
        "length": "1281 words",
        "byline": "Aneesh Raman and Maria Flynn",
        "story_text": "When Your Technical Skills Are Eclipsed, Your Humanity Will Matter More \nThan Ever; Guest Essay\nThe New York Times \nFebruary 14, 2024 Wednesday 13:32 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1281 words\nByline: Aneesh Raman and Maria Flynn\nHighlight: The rise of A.I. will make soft skills even more important.\nBody\nThere have been just a handful of moments over the centuries when we have experienced a huge shift in the skills \nour economy values most. We are entering one such moment now. Technical and data skills that have been highly \nsought after for decades appear to be among the most exposed to advances in artificial intelligence. But other skills, \nparticularly the people skills that we have long undervalued as soft, will very likely remain the most durable. That is \na hopeful sign that A.I. could usher in a world of work that is anchored more, not less, around human ability.\nA moment like this compels us to think differently about how we are training our workers, especially the heavy \npremium we have placed on skills like coding and data analysis that continue to reshape the fields of higher \neducation and worker training. The early signals of what A.I. can do should compel us to think differently about \nourselves as a species. Our abilities to effectively communicate, develop empathy and think critically have allowed \nhumans to collaborate, innovate and adapt for millenniums. Those skills are ones we all possess and can improve, \nyet they have never been properly valued in our economy or prioritized in our education and training. That needs to \nchange.\nIn today’s knowledge economy, many students are focused on gaining technical skills because those skills are seen \nas the most competitive when it comes to getting a good job. And for good reason. For decades, we have viewed \nthose jobs as future-proof, given the growth of technology companies and the fact that engineering majors land the \nhighest-paying jobs.\nThe number of students seeking four-year degrees in computer science and information technology shot up 41 \npercent between the spring of 2018 and the spring of 2023, while the number of humanities majors plummeted. \nWorkers who didn’t go to college and those who needed additional skills and wanted to take advantage of a \nlucrative job boom flocked to dozens of coding boot camps and online technical programs.\nNow comes the realization of the power of generative A.I., with its vast capabilities in skills like writing, \nprogramming and translation. (Microsoft, which owns LinkedIn, is a major investor in the technology.) LinkedIn \nresearchers recently looked at which skills any given job requires and then identified over 500 likely to be affected \nby generative A.I. technologies. They then estimated that 96 percent of a software engineer’s current skills — \nmainly proficiency in programming languages — can eventually be replicated by A.I. Skills associated with jobs like \nlegal associates and finance officers will also be highly exposed.\nIn fact, given the broad impact A.I. is set to have, it is quite likely to affect all of our work to some degree or another.\nWe believe there will be engineers in the future, but they will most likely spend less time coding and more time on \ntasks like collaboration and communication. We also believe that there will be new categories of jobs that emerge \nWhen Your Technical Skills Are Eclipsed, Your Humanity Will Matter More Than Ever Guest Essay\nas a result of A.I.’s capabilities — just like we’ve seen in past moments of technological advancement — and that \nthose jobs will probably be anchored increasingly around people skills.\nCircling around this research is the big question emerging across so many conversations about A.I. and work, \nnamely: What are our core capabilities as humans?\nIf we answer that question from a place of fear about what’s left for people in the age of A.I., we can end up \nconceding a diminished view of human capability. Instead, it’s critical for us all to start from a place that imagines \nwhat’s possible for humans in the age of A.I. When you do that, you find yourself focusing quickly on people skills \nthat allow us to collaborate and innovate in ways technology can amplify but never replace. And you find yourself — \nwhatever the role or career stage you’re in — with agency to better manage this moment of historic change.\nCommunication is already the most in-demand skill across jobs on LinkedIn today. Even experts in A.I. are \nobserving that the skills we need to work well with A.I. systems, such as prompting, are similar to the skills we need \nto communicate and reason effectively with other people.\nOver 70 percent of executives surveyed by LinkedIn last year said soft skills were more important to their \norganizations than highly technical A.I. skills. And a recent Jobs for the Future survey found that 78 percent of the \n10 top-employing occupations classified uniquely human skills and tasks as “important” or “very important.” These \nare skills like building interpersonal relationships, negotiating between parties and guiding and motivating teams.\nNow is the time for leaders, across sectors, to develop new ways for students to learn that are more directly, and \nmore dynamically, tied to where our economy is going, not where it has been. Critically, that involves bringing the \nsame level of rigor to training around people skills that we have brought to technical skills.\nColleges and universities have a critical role to play. Over the past few decades, we have seen a prioritization of \nscience and engineering, often at the expense of the humanities. That calibration will need to be reconsidered.\nThose not pursuing a four-year degree should look for those training providers that have long emphasized people \nskills and are invested in social capital development.\nEmployers will need to be educators not just around A.I. tools but also on people skills and people-to-people \ncollaboration. Major employers like Walmart and American Airlines are already exploring ways to put A.I. in the \nhands of employees so they can spend less time on routine tasks and more time on personal engagement with \ncustomers.\nUltimately, for our society, this comes down to whether we believe in the potential of humans with as much \nconviction as we believe in the potential of A.I. If we do, it is entirely possible to build a world of work that not only is \nmore human but also is a place where all people are valued for the unique skills they have, enabling us to deliver \nnew levels of human achievement across so many areas that affect all of our lives, from health care to \ntransportation to education. Along the way, we could meaningfully increase equity in our economy, in part by \naddressing the persistent gender gap that exists when we undervalue skills that women bring to work at a higher \npercentage than men.\nAlmost anticipating this moment a few years ago, Minouche Shafik, who is now the president of Columbia \nUniversity, said: “In the past, jobs were about muscles. Now they’re about brains, but in the future, they’ll be about \nthe heart.”\nThe knowledge economy that we have lived in for decades emerged out of a goods economy that we lived in for \nmillenniums, fueled by agriculture and manufacturing. Today the knowledge economy is giving way to a relationship \neconomy, in which people skills and social abilities are going to become even more core to success than ever \nbefore. That possibility is not just cause for new thinking when it comes to work force training. It is also cause for \ngreater imagination when it comes to what is possible for us as humans not simply as individuals and organizations \nbut as a species.\nWhen Your Technical Skills Are Eclipsed, Your Humanity Will Matter More Than Ever Guest Essay\nAneesh Raman is a vice president and work force expert at LinkedIn. Maria Flynn is the president of Jobs for the \nFuture.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, X and Threads.\nPHOTO:  (PHOTOGRAPH BY Kate Dehler FOR THE NEW YORK TIMES)\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Boom in A.I. Prompts a Test of Copyright Law",
        "media": "The New York Times",
        "time": "December 31, 2023",
        "section": "BUSINESS; media",
        "length": "898 words",
        "byline": "J. Edward Moreno &lt;p&gt;J. Edward Moreno is a business reporter at The Times.&lt;/p&gt;",
        "story_text": "Boom in A.I. Prompts a Test of Copyright Law\nThe New York Times \nDecember 30, 2023 Saturday 21:08 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 898 words\nByline: J. Edward Moreno &lt;p&gt;J. Edward Moreno is a business reporter at The Times.&lt;/p&gt;\nHighlight: The use of content from news and information providers to train artificial intelligence systems may force \na reassessment of where to draw legal lines.\nBody\nThe use of content from news and information providers to train artificial intelligence systems may force a \nreassessment of where to draw legal lines.\nThe boom in artificial intelligence tools that draw on troves of content from across the internet has begun to test the \nbounds of copyright law.\nAuthors and a leading photo agency have brought suit over the past year, contending that their intellectual property \nwas illegally used to train A.I. systems, which can produce humanlike prose and power applications like chatbots.\nNow they have been joined in the spotlight by the news industry. The New York Times filed a lawsuit on \nWednesday accusing OpenAI and Microsoft of copyright infringement, the first such challenge by a major American \nnews organization over the use of artificial intelligence.\nThe lawsuit contends that OpenAI’s ChatGPT and Microsoft’s Bing Chat can produce content nearly identical to \nTimes articles, allowing the companies to “free-ride on The Times’s massive investment in its journalism by using it \nto build substitutive products without permission or payment.”\nOpenAI and Microsoft have not had an opportunity to respond in court. But after the lawsuit was filed, those \ncompanies noted that they were in discussions with a number of news organizations on using their content — and, \nin the case of OpenAI, had begun to sign deals.\nWithout such agreements, the limits may be worked out in the courts, with significant repercussions. Data is crucial \nto developing generative A.I. technologies — which can generate text, images and other media on their own — \nand to the business models of companies doing that work.\n“Copyright will be one of the key points that shapes the generative A.I. industry,” said Fred Havemeyer, an analyst \nat the financial research firm Macquarie.\nA central consideration is the “fair use” doctrine in intellectual property law, which allows creators to build upon \ncopyrighted work. Among other factors, defendants in copyright cases need to prove that they transformed the \ncontent substantially and are not competing in the same market as a substitute for the work of the original creator.\nA review quoting passages from a book, for example, could be considered fair use because it builds on that content \nto create new, unique work. Selling extended excerpts from the book, on the other hand, may violate the doctrine.\nCourts have not weighed in on how those standards apply to A.I. tools.\nBoom in A.I. Prompts a Test of Copyright Law\n“There isn’t a clear answer to whether or not in the United States that is copyright infringement or whether it’s fair \nuse,” said Ryan Abbott, a lawyer at Brown Neri Smith &amp; Khan who handles intellectual property cases. “In the \nmeantime, we have lots of lawsuits moving forward with potentially billions of dollars at stake.”\nIt could be a while before the industry gets definitive answers.\nThe lawsuits posing these questions are in early stages of litigation. If they don’t produce settlements (as most \nlitigation does), it could be years until a Federal District Court rules on the matter. Those rulings would probably be \nappealed, and appellate decisions could vary by circuit, which could potentially elevate the question to the U.S. \nSupreme Court.\nGetting there could take about a decade, Mr. Abbott said. “A decade is an eternity in the market that we’re currently \nliving through,” he said.\nThe Times said in its suit that it had been in talks with Microsoft and OpenAI about terms for resolving the dispute, \npossibly including a license. The Associated Press and Axel Springer, the German owner of outlets like Politico and \nBusiness Insider, have recently reached data licensing agreements with OpenAI.\nTaking cases to trial could answer vital questions about what copyrighted data A.I. developers are able to use and \nhow. But it could also simply serve as leverage for a plaintiff to secure a more favorable licensing deal through a \nsettlement.\n“Ultimately, whether or not this lawsuit ends up shaping copyright law will be determined by whether the suit is \nreally about the future of fair use and copyright, or whether it’s a salvo in a negotiation,” Jane Ginsburg, a professor \nat Columbia Law School, said of the lawsuit by The Times.\nHow the legal landscape unfolds could shape the nascent yet heavily capitalized A.I. industry.\nSome A.I. companies have been flooded with venture capital in the past year after the public rollout of ChatGPT \nwent viral. A stock plan under consideration could value OpenAI at over $80 billion; Microsoft has invested $13 \nbillion in the company and has incorporated its technology into its own products. But questions about the use of \nintellectual property to train models have been top of mind for investors, Mr. Havemeyer said.\nCompetition in the A.I. field may boil down to data haves and have-nots.\nCompanies with the rights to large quantities of data, such as Adobe and Bloomberg — or that have amassed their \nown data, such as Meta and Google — have started developing their own A.I. tools. Mr. Havemeyer noted that an \nestablished company like Microsoft was well equipped to secure data licensing agreements and tackle legal \nchallenges. But start-ups with less capital may have a harder time obtaining the data they need to compete.\n“Generative A.I. begins and ends with data,” Mr. Havemeyer said.\nBenjamin Mullin contributed reporting.\nBenjamin Mullin contributed reporting. \nThis article appeared in print on page B6.\nLoad-Date: December 31, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Jan2024",
        "header": "Survey: Amid change, CEOs fear for companies' survival",
        "media": "The Baltimore Sun",
        "time": "January 17, 2024",
        "section": "SPORTS; D; Pg. 10",
        "length": "625 words",
        "byline": "Courtney Bonnell Associated Press",
        "story_text": "Survey: Amid change, CEOs fear for companies' survival\nThe Baltimore Sun\nJanuary 17, 2024 Wednesday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: SPORTS; D; Pg. 10\nLength: 625 words\nByline: Courtney Bonnell Associated Press\nHighlight: Artificial intelligence, the subject of a window ad seen Monday in Davos, Switzerland, also will be a \nsummit topic in about 30 separate sessions this year. Markus Schreiber/ap\nBody\nLONDON - More executives are feeling better about the global economy, but a growing number don't think their \ncompanies will survive the coming decade without a major overhaul because of pressure from climate change and \ntechnology like artificial intelligence, according to a new survey of CEOs by one of the world's largest consulting \nfirms, PwC.\nThe survey of more than 4,700 CEOs worldwide was released Monday as business elites, political leaders and \nactivists descended on the World Economic Forum's annual meeting in Davos, Switzerland, and it showed a mixed \npicture of the coming years.\nOf the executives, 38% were optimistic about the strength of the economy, up from 18% last year, when the world \nwas mired in high inflation, weak growth, rising interest rates and more.\nThe CEOs' expectation of economic decline has dropped to 45% from a record-high 73% last year, and fewer saw \ntheir company as highly exposed to the risk of geopolitical conflict, according to the PwC Global CEO Survey. \nThat's despite wars in Ukraine and the Middle East, including disruptions to global trade from attacks by Yemen's \nHouthi rebels on Red Sea cargo ships.\nEven with the improved economic outlook, the challenge isn't close to over, with the World Bank saying last week \nthat it expects the global economy would slow for a third consecutive year in 2024.\nThe executives, meanwhile, felt worse about the prospects for their companies' ability to weather big changes. The \nsurvey shows 45% of the respondents were worried that their businesses wouldn't be viable in a decade without \nreinvention, up from 39% last year.\nThe CEOs say they're trying to make changes, but they are running up against regulation, a lack of skills among \nworkers and more.\n\"Whether it is accelerating the rollout of generative AI or building their business to address the challenges and \nopportunities of the climate transition, this is a year of transformation,\" Bob Moritz, global chair of PwC, said in a \nstatement.\nArtificial intelligence was seen as both a way to streamline business operations and a weakness. Nearly three-\nquarters of the executives said \"it will significantly change the way their company creates, delivers and captures \nvalue in the next three years,\" PwC said.\nSurvey: Amid change, CEOs fear for companies' survival\nMore than half the CEOs said AI will make their products or services better, but 69% noted that their workers \nneeded training to gain skills to use the developing technology. They also were concerned about how AI would \nincrease cybersecurity risks and misinformation.\nOrganizers of the Davos gathering warned last week that the threat posed by AI-powered misinformation, such as \nthe creation of synthetic content, is the world's greatest short-term threat.\nAnother worldwide survey released around Davos, the Edelman Trust Barometer by public relations firm Edelman, \nsays innovation is being managed badly and is increasing polarization, especially in Western democracies, where \npeople with right-leaning beliefs are much more likely than those on the left to resist innovation.\n\"Innovation is only accepted if there is a sense that we're looking at the big picture of how we take care of the \npeople whose jobs are going to change, how scientists are going to talk to the people directly so they understand \nit,\" CEO Richard Edelman told The Associated Press on Monday. \"And finally, that one way in another, AI is \naffordable and makes it easier for people to live.\"\nThe Edelman online survey - which again showed that business is the most trusted institution among government, \nmedia, science and nongovernmental organizations - gathered responses from more than 32,000 respondents in 28 \ncountries from Nov. 3 to Nov. 22.\nThe PwC survey of 4,702 CEOs in 105 countries and territories was conducted from Oct. 2 to Nov. 10.\nLoad-Date: January 17, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "The 2023 Good Tech Awards",
        "media": "The New York Times",
        "time": "December 28, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT",
        "length": "1562 words",
        "byline": "By Kevin Roose",
        "story_text": "The 2023 Good Tech Awards\nThe New York Times\nDecember 28, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT\nLength: 1562 words\nByline: By Kevin Roose\nBody\nIn the tech industry, 2023 was a year of transformation.\nSpurred by the success of last year's breakout tech star, ChatGPT, Silicon Valley's giants rushed to turn \nthemselves into artificial intelligence companies, jamming generative A.I. features into their products and racing to \nbuild their own, more powerful A.I. models. They did so while navigating an uncertain tech economy, with layoffs \nand pivots galore, and while trying to keep their aging business models aloft. \n  Not everything went smoothly. There were misbehaving chatbots, crypto foibles and bank failures. And then in \nNovember, ChatGPT's maker, OpenAI, melted down (and quickly reconstituted itself) over a failed boardroom coup, \nproving once and for all that there's no such thing in tech as resting on your laurels.\n  Every December in my Good Tech Awards column, I try to neutralize my own negativity bias by highlighting a few \nlesser-known tech projects that struck me as beneficial. This year, as you'll see, many of the awards involve \nartificial intelligence, but my goal was to sidestep the polarized debates about whether A.I. will destroy the world or \nsave it and instead focus on the here and now. What is A.I. good for today? Whom is it helping? What kinds of \nimportant breakthroughs are already being made with A.I. as a catalyst?\n  As always, my award criteria are vague and subjective, and no actual trophies or prizes are involved. These are \njust small, personal blurbs of appreciation for a few tech projects I thought had real, obvious value to humanity in \n2023.\n  To Be My Eyes, Apple and researchers at the University of Texas at Austin, for improving accessibility through A.I.\n  Accessibility -- the term for making tech products more usable by people with disabilities -- has been an \nunderappreciated area of improvement this year. Several recent advances in artificial intelligence -- such as \nmultimodal A.I. models that can interpret images and turn text into speech -- have made it possible for tech \ncompanies to build new features for disabled users. This is, I'd argue, an unambiguously good use of A.I., and an \narea where people's lives are already improving in meaningful ways.\n  I asked Steven Aquino, a freelance journalist who specializes in accessible tech, to recommend his top \naccessibility breakthroughs of 2023. He recommended Be My Eyes, a company that makes technology for people \nwith impaired vision. In 2023, Be My Eyes announced a feature known as Be My AI, powered by OpenAI's \ntechnology, that allows blind and low-sighted people to aim their smartphone camera at an object and have that \nobject described for them in natural language.\nThe 2023 Good Tech Awards\n  Mr. Aquino also pointed me to Apple's new Personal Voice feature, which is built into iOS 17 and uses A.I. voice-\ncloning technology to create a synthetic version of a user's voice. The feature was designed for people who are at \nrisk of losing their ability to speak, such as those with a recent diagnosis of amyotrophic lateral sclerosis or another \ndegenerative disease, and gives them a way to preserve their speaking voice so that their friends, relatives and \nloved ones can hear from them long into the future.\n  I'll throw in one more promising accessibility breakthrough: A research team at the University of Texas at Austin \nannounced this year that it had used A.I. to develop a ''noninvasive language decoder'' that can translate thoughts \ninto speech -- read people's minds, essentially. This kind of technology, which uses an A.I. language model to \ndecode brain activity from fMRI scans, sounds like science fiction. But it could make it easier for people with speech \nloss or paralysis to communicate. And it doesn't require putting an A.I. chip in your brain, which is an added bonus.\n  To Vertex Pharmaceuticals and CRISPR Therapeutics, for putting gene editing to good use\n  When CRISPR, the Nobel Prize-winning gene editing tool, broke into public consciousness a decade ago, \ndoomsayers predicted that it might lead to a dystopian world of gene-edited ''designer babies'' and nightmare \neugenics experiments. Instead, the technology has been allowing scientists to make steady progress toward \ntreating a number of harrowing diseases.\n  In December, the Food and Drug Administration approved the first gene-editing therapy for humans -- a treatment \nfor sickle cell disease, called Exa-cel, that was jointly developed by Vertex Pharmaceuticals of Boston and CRISPR \nTherapeutics of Switzerland.\n  Exa-cel uses CRISPR to edit the gene responsible for sickle cell, a debilitating blood disease that affects roughly \n100,000 Americans, most of whom are Black. While it's still wildly expensive and difficult to administer, the \ntreatment offers new hope to sickle cell patients who have access to it.\n  To Brent Seales, Nat Friedman and Daniel Gross, for using A.I. to unlock antiquity's secrets\n  One of the most fun interviews I did on my podcast this year was with Brent Seales, a professor at the University \nof Kentucky who has spent the past two decades trying to decipher a set of ancient papyrus manuscripts known as \nthe Herculaneum Scrolls. The scrolls, which belonged to a library owned by Julius Caesar's father-in-law, were \nburied under a mountain of ash in 79 A.D. during the eruption of Mount Vesuvius. They were so thoroughly \ncarbonized that they couldn't be opened without ruining them.\n  Now, A.I. has made it possible to read these scrolls without opening them. And this year, Dr. Seales teamed up \nwith two tech investors, Nat Friedman and Daniel Gross, to launch the Vesuvius Challenge -- offering prizes of up to \n$1 million to anyone who successfully deciphers the scrolls.\n  The grand prize has still not been won. But the competition sparked a frenzy of interest from amateur history buffs, \nand this year a 21-year-old computer science student, Luke Farritor, won a $40,000 intermediate prize for \ndeciphering a single word -- ''purple'' -- from one of the scrolls. I love the idea of using A.I. to unlock wisdom from \nthe ancient past, and I love the public-minded spirit of this competition.\n  To Waymo, for taking the slow road to self-driving\n  I spent a lot of time in 2023 being shuttled around San Francisco in self-driving cars. Robot taxis are a \ncontroversial technology -- and there are still plenty of kinks to be worked out -- but for the most part I buy the idea \nthat self-driving cars will ultimately make our roads safer by replacing fallible, distracted human drivers with always-\nalert A.I. chauffeurs.\n  Cruise, one of the two companies that were giving robot taxi rides in San Francisco, has imploded in recent days, \nafter one of its vehicles struck and dragged a woman who had been hit by another car. California regulators said \nthe company had misled them about the incident; Cruise pulled its cars from the streets, and its chief executive, \nKyle Vogt, stepped down.\nThe 2023 Good Tech Awards\n  But not all self-driving cars are created equal, and this year I was grateful for the comparatively slow, methodical \napproach taken by Cruise's competitor, Waymo.\n  Waymo, which was spun out of Google in 2016, has been logging miles on public roads for more than a decade, \nand it shows. The half-dozen rides I took in Waymo cars this year felt safer and smoother than the Cruise rides I \ntook. And Waymo's safety data is compelling: According to a study the company conducted with Swiss Re, an \ninsurance firm, in 3.8 million self-driving miles Waymo's cars were significantly less likely to cause property damage \nthan human-driven cars, and led to no bodily injury claims whatsoever.\n  I'll put my cards on the table: I like self-driving cars, and I think society will be better off once they're widespread. \nBut they have to be safe, and Waymo's slow-and-steady approach seems better suited to the task.\n  To the National Institute of Standards and Technology, for managing America's A.I. transition\n  One of the more surprising -- and, to my mind, heartening -- tech trends of 2023 was seeing governments around \nthe world get involved in trying to understand and regulate A.I.\n  But all that involvement requires work -- and in the United States, a lot of that work has fallen to the National \nInstitute of Standards and Technology, a small federal agency that was previously better known for things like \nmaking sure clocks and scales were properly calibrated.\n  The Biden administration's executive order on artificial intelligence, released in October, designated NIST as one \nof the primary federal agencies responsible for keeping tabs on A.I. progress and mitigating its risks. The order \ndirects the agency to develop ways of testing A.I. systems for safety, come up with exercises to help A.I. companies \nidentify potentially harmful uses of their products, and produce research and guidelines for watermarking A.I.-\ngenerated content, among other things.\n  NIST, which employs about 3,400 people and has an annual budget of $1.24 billion, is tiny compared with other \nfederal agencies doing critical safety work. (For scale: The Department of Homeland Security has an annual budget \nof nearly $100 billion.) But it's important that the government build up its own A.I. capabilities to effectively regulate \nthe advances being made by private-sector A.I. labs, and we'll need to invest more in the work being done by NIST \nand other agencies in order to give ourselves a fighting chance.\n  And on that note: Happy holidays, and see you next year!\nhttps://www.nytimes.com/2023/12/25/technology/the-2023-good-tech-awards.html\nGraphic\n \nPHOTOS: Among the winners: Google's driverless car service, Waymo\nand Brent Seales, a University of Kentucky professor who is trying to decipher the ancient Herculaneum Scrolls. \n(PHOTOGRAPHS BY KELSEY McCLELLAN FOR THE NEW YORK TIMES\n PETE COMPARONI/UKPHOTO) (B5) This article appeared in print on page B1, B5.               \nLoad-Date: December 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "S.E.C. Is Reviewing Board Over Altman's Brief Firing",
        "media": "The New York Times",
        "time": "March 2, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "476 words",
        "byline": "By Cade Metz, Tripp Mickle and Matthew Goldstein",
        "story_text": "S.E.C. Is Reviewing Board Over Altman's Brief Firing\nThe New York Times\nMarch 2, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 476 words\nByline: By Cade Metz, Tripp Mickle and Matthew Goldstein\nBody\nThe U.S. regulator opened its inquiry after the board unexpectedly fired the company's chief executive, Sam \nAltman, in November.\nThe Securities and Exchange Commission began an inquiry into OpenAI soon after the company's board of \ndirectors unexpectedly removed Sam Altman, its chief executive, at the end of last year, three people familiar with \nthe inquiry said. \n  The regulator has sent official requests to OpenAI, the developer of the ChatGPT online chatbot, seeking \ninformation about the situation. It is unclear whether the S.E.C. is investigating Mr. Altman's behavior, the board's \ndecision to oust him or both.\n  Even as OpenAI has tried to turn the page on the dismissal of Mr. Altman, who was soon reinstated, the \ncontroversy continues to hound the company. In addition to the S.E.C. inquiry, the San Francisco artificial \nintelligence company has hired a law firm to conduct its own investigation into Mr. Altman's behavior and the \nboard's decision to remove him.\n  The board dismissed Mr. Altman on Nov. 17, saying it no longer had confidence in his ability to run OpenAI. It said \nhe had not been ''consistently candid in his communications,'' though it did not provide specifics. It agreed to \nreinstate him five days later.\n  Privately, the board worried that Mr. Altman was not sharing all of his plans to raise money from investors in the \nMiddle East for an A.I. chip project, people with knowledge of the situation have said.\n  Spokespeople for the S.E.C. and OpenAI and a lawyer for Mr. Altman all declined to comment.\n  The S.E.C.'s inquiry was reported earlier by The Wall Street Journal.\n  OpenAI kicked off an industrywide A.I. boom at the end of 2022 when it released ChatGPT. The company is \nconsidered a leader in what is called generative A.I., technologies that can generate text, sounds and images from \nshort prompts. A recent funding deal values the start-up at more than $80 billion.\n  Many believe that generative A.I., which represents a fundamental shift in the way computers behave, could \nremake the industry as thoroughly as the iPhone or the web browser. Others argue that the technology could cause \nserious harm, helping to spread online disinformation, replacing jobs with unusual speed and maybe even \nthreatening the future of humanity.\nS.E.C. Is Reviewing Board Over Altman's Brief Firing\n  After the release of ChatGPT, Mr. Altman became the face of the industry's push toward generative A.I. as he \nendlessly promoted the technology -- while acknowledging the dangers.\n  In an effort to resolve the turmoil surrounding Mr. Altman's ouster, he and the board agreed to remove two \nmembers and add two others: Bret Taylor, who is a former Salesforce executive, and former Treasury Secretary \nLawrence H. Summers.\n  Mr. Altman and the board also agreed that OpenAI would start its own investigation into the matter. That \ninvestigation, by the WilmerHale law firm, is expected to close soon.\nhttps://www.nytimes.com/2024/02/29/technology/sec-openai-board-sam-altman.html\nGraphic\n \nPHOTO: Sam Altman at a Senate hearing last spring. OpenAI's board fired him on Nov. 17, then reinstated him five \ndays later. (PHOTOGRAPH BY HAIYUN JIANG/THE NEW YORK TIMES) This article appeared in print on page \nB4.               \nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Europeans Take a Major Step Toward Regulating A.I.",
        "media": "The New York Times",
        "time": "June 15, 2023",
        "section": "TECHNOLOGY",
        "length": "931 words",
        "byline": "Adam Satariano",
        "story_text": "Europeans Take a Major Step Toward Regulating A.I.\nThe New York Times \nJune 14, 2023 Wednesday 11:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 931 words\nByline: Adam Satariano\nHighlight: A draft law in the European Parliament has become the world’s most far-reaching attempt to address the \npotentially harmful effects of artificial intelligence.\nBody\nA draft law in the European Parliament has become the world’s most far-reaching attempt to address the potentially \nharmful effects of artificial intelligence.\nThe European Union took an important step on Wednesday toward passing what would be one of the first major \nlaws to regulate artificial intelligence, a potential model for policymakers around the world as they grapple with how \nto put guardrails on the rapidly developing technology.\nThe European Parliament, a main legislative branch of the European Union, passed a draft law known as the A.I. \nAct, which would put new restrictions on what are seen as the technology’s riskiest uses. It would severely curtail \nuses of facial recognition software, while requiring makers of A.I. systems like the ChatGPT chatbot to disclose \nmore about the data used to create their programs.\nThe vote is one step in a longer process. A final version of the law is not expected to be passed until later this year.\nThe European Union is further along than the United States and other large Western governments in regulating A.I. \nThe 27-nation bloc has debated the topic for more than two years, and the issue took on new urgency after last \nyear’s release of ChatGPT, which intensified concerns about the technology’s potential effects on employment and \nsociety.\nPolicymakers everywhere from Washington to Beijing are now racing to control an evolving technology that is \nalarming even some of its earliest creators. In the United States, the White House has released policy ideas that \ninclude rules for testing A.I. systems before they are publicly available and protecting privacy rights. In China, draft \nrules unveiled in April would require makers of chatbots to adhere to the country’s strict censorship rules. Beijing is \nalso taking more control over the ways makers of A.I. systems use data.\nHow effective any regulation of A.I. can be is unclear. In a sign that the technology’s new abilities are emerging \nseemingly faster than lawmakers are able to address them, earlier versions of the E.U. law did not give much \nattention to so-called generative A.I. systems like ChatGPT, which can produce text, images and video in response \nto prompts.\nUnder the latest version of Europe’s bill passed on Wednesday, generative A.I. would face new transparency \nrequirements. That includes publishing summaries of copyrighted material used for training the system, a proposal \nsupported by the publishing industry but opposed by tech developers as technically infeasible. Makers of \ngenerative A.I. systems would also have to put safeguards in place to prevent them from generating illegal content.\nEuropeans Take a Major Step Toward Regulating A.I.\nFrancine Bennett, acting director of the Ada Lovelace Institute, an organization in London that has pushed for new \nA.I. laws, said the E.U. proposal was an “important landmark.”\n“Fast-moving and rapidly repurposable technology is of course hard to regulate, when not even the companies \nbuilding the technology are completely clear on how things will play out,” Ms. Bennett said. “But it would definitely \nbe worse for us all to continue operating with no adequate regulation at all.”\nThe European bill takes a “risk-based” approach to regulating A.I., focusing on applications with the greatest \npotential for human harm. This would include where A.I. systems were used to operate critical infrastructure like \nwater or energy, in the legal system, and when determining access to public services and government benefits. \nMakers of the technology would have to conduct risk assessments before putting the tech into everyday use, akin to \nthe drug approval process.\nA tech industry group, the Computer &amp; Communications Industry Association, said the European Union should \navoid overly broad regulations that inhibit innovation.\n“The E.U. is set to become a leader in regulating artificial intelligence, but whether it will lead on A.I. innovation still \nremains to be seen,” said Boniface de Champris, the group’s Europe policy manager. “Europe’s new A.I. rules need \nto effectively address clearly defined risks, while leaving enough flexibility for developers to deliver useful A.I. \napplications to the benefit of all Europeans.”\nOne major area of debate is the use of facial recognition. The European Parliament voted to ban uses of live facial \nrecognition, but questions remain about whether exemptions should be allowed for national security and other law \nenforcement purposes.\nAnother provision would ban companies from scraping biometric data from social media to build out databases, a \npractice that drew scrutiny after the facial-recognition company Clearview AI used it.\nTech leaders have been trying influence the debate. Sam Altman, the chief executive of OpenAI, the maker of \nChatGPT, has in recent months visited with at least 100 American lawmakers and other global policymakers in \nSouth America, Europe, Africa and Asia, including Ursula von der Leyen, president of the European Commission. \nMr. Altman has called for regulation of A.I., but has also said the European Union’s proposal may be prohibitively \ndifficult to comply with.\nAfter the vote on Wednesday, a final version of the law will be negotiated by representatives of the three branches \nof the European Union — the European Parliament, the European Commission and the Council of the European \nUnion. Officials said they hoped to reach a final agreement by the end of the year.\nPHOTO: The European Parliament passed a draft law that would put new restrictions on what are seen as the \nriskiest uses of A.I. (PHOTOGRAPH BY JULIEN WARNAND/EPA, VIA SHUTTERSTOCK) (B5) This article \nappeared in print on page B1, B5.\nLoad-Date: June 15, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Yellow.ai deploys 30% of global generative AI bots domestically",
        "media": "The Economic Times",
        "time": "January 23, 2024",
        "section": "TECH & INTERNET",
        "length": "544 words",
        "byline": "Annapurna Roy",
        "story_text": "Yellow.ai deploys 30% of global generative AI bots domestically\nThe Economic Times\nJanuary 23, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 544 words\nByline: Annapurna Roy\nBody\nAdoption of generative artificial intelligence for customer engagement is picking up pace in India.For instance, \nconversational AI company Yellow.ai, which deployed around 120 GenAI bots for businesses worldwide this \nfinancial year, saw about 30% of these deployed in India.While markets like the US are mostly using GenAI for \ncustomer support in a bid to cut costs, India Inc. is using them as an opportunity to grow revenues, generate \nbusiness leads and sales support, Yellow.ai cofounder and chief executive Raghu Ravinutala told ET.Founded in \n2016 in Bengaluru, Yellow.ai is backed by Sapphire Ventures, Westbridge Capital, Salesforce Ventures and \nLightspeed Venture Partners, among investors. It has raised about $102 million in funding so far, as per \nTracxn.Among its clients, Bajaj Auto Finance has generated over 100 leads using the San Mateo, California-\nheadquartered company’s GenAI chatbot, and a leading non-banking financier saw over 400 auto-loan applications, \nRavinutala noted. \nA top two-wheeler maker sold motorcycles worth about Rs 1 crore in the first day of launch through the GenAI \nassistant while a leading finance company secured potential customers or sales leads worth about $100 \nmillion.Ravinutala said Yellow.ai is considering a public listing in the US by 2026-27 by when the market is expected \nto recover from the current subdued macroeconomic climate. The company expects to turn profitable this \nyear.Yellow.ai has been witnessing a surge in demand for its GenAI offerings since the quarter ended October. At \nthe time, it rolled out around 100 bots across financial services, travel, retail and ecommerce, and technology \nsectors. The company follows the February to January period as its financial year.“Q4 (the quarter ending January) \nis the largest quarter we are ever having for India in terms of platform ARR (annual recurring revenue) and India is \nalso leading in terms of the GenAI adoption on the Yellow.ai platform,” Ravinutala said.The company expects the \nIndian market to grow more than 60% next year, when revenue from India is expected to be $20-30 million with the \noverall global revenue at $60-70 million run rate. It is currently at a $30-40 million revenue run rate globally, growing \nat 60-70% annually. In FY25, it expects revenue to double.According to research by Adobe, most companies in \nIndia are cutting marketing and customer experience budgets, with 42% having done so and 37% planning to do so \nover the next year. Nearly 60% plan to deploy GenAI in these areas.The global macroeconomic slowdown coupled \nwith companies’ increased urgency to adopt GenAI has created growth opportunities for Yellow.ai. “They \n(customers) are looking at cutting costs, and our core value proposition is reducing cost and customer support by \nreplacing agents and humans through automation,” Ravinutala said.Automation and efficiencies from GenAI have \nalso enabled the company to proceed with a measured approach to hiring and employee strength, Ravinutala said. \nThe company cut about 13% of its workforce at the start of 2023. It currently has 680 employees, of which about \n570 are based in India.“Over the next few years, we don't see this (employee strength) going to 1,000-2,000,” \nRavinutala said. For Reprint Rights: timescontent.com\nLoad-Date: January 23, 2024\nYellow.ai deploys 30% of global generative AI bots domestically"
    },
    {
        "file_name": "The_Economic_Times_Aug2023",
        "header": "Skilling platform Disprz bags $30 million from Lumos and others",
        "media": "The Economic Times",
        "time": "August 7, 2023",
        "section": "FUNDING",
        "length": "195 words",
        "byline": " ",
        "story_text": "Skilling platform Disprz bags $30 million from Lumos and others\nThe Economic Times\nAugust 8, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 195 words\nBody\nDisprz, a corporate learning and skilling platform, has raised $30 million in its Series C funding round led by Lumos \nCapital. 360 ONE Asset (IIFL Wealth) and returning investors Kae Capital, KOIS and Dallas Venture Capital also \nparticipated. The funding, a result of primary and secondary share sales, will be utilised for global market expansion \nand product development, including the integration of generative artificial intelligence across the learning and \nskilling cycle. Additionally, Disprz aims to form strategic partnerships and make strategic acquisitions, as per a \nstatement. \"We are right now in the middle of our $10 million to $100 million ARR (annual recurring revenues) \njourney. The raised capital will let us build our next generation of products. We are a multi-product company, we \nhave a suite of offerings on learning and upskilling for mid and large enterprises in emerging markets like India, \nsoutheast Asia, middle east and we've just made our trip to the US,\" founder and CEO Subramanian Viswanathan \ntold ET. Viswanathan said that the company currently has 12 clients in the US. In total, the company has 350. For \nReprint Rights: timescontent.com\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Aug2023",
        "header": "AN OUTCRY GROWS OVER DATA USED TO TRAIN AI",
        "media": "Wall Street Journal Abstracts",
        "time": "August 1, 2023",
        "section": "B; Pg. 1",
        "length": "21 words",
        "byline": "DEEPA SEETHARAMAN, KEACH HAGEY",
        "story_text": "AN OUTCRY GROWS OVER DATA USED TO TRAIN AI\nWall Street Journal Abstracts\nJuly 31, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 1\nLength: 21 words\nByline: DEEPA SEETHARAMAN, KEACH HAGEY\nBody\nABSTRACT\nAuthors, artists and internet publishers are seeking compensation for use of their work to train generative-AI; photo \n(M)\nGraphic\n \nPhotograph\nLoad-Date: August 1, 2023"
    },
    {
        "file_name": "The_Economic_Times_Aug2023",
        "header": "WPP is open to buying firms in India for AI push",
        "media": "The Economic Times",
        "time": "August 11, 2023",
        "section": "ELECTRONICS",
        "length": "493 words",
        "byline": "Javed Farooqui",
        "story_text": "WPP is open to buying firms in India for AI push\nThe Economic Times\nAugust 12, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ELECTRONICS\nLength: 493 words\nByline: Javed Farooqui\nBody\nWPP, the world's biggest advertising group, is open to acquiring companies in India that allow it to bolster its \nartificial intelligence (AI) capabilities, a top company executive said.\"We are open for acquisitions everywhere, \nincluding India, for talent and capability,\" WPP chief AI officer and Satalia CEO Daniel Hulme told ET. \"WPP has a \nhistory of growing strategically through acquisitions. We (Satalia) joined WPP because they know how to look after \nstartups and entrepreneurs.\"Hulme also said India has incredible talent in both creativity and technology. \n\"The WPP workforce here is not just strong in creativity but also in technology. We are going to see greater growth \nin those two areas and better collaboration between those two parts,\" he added.Around 10% of WPP's India \nworkforce comes from a tech background. The company has 11,000 employees in the country across multiple \nagencies.In August 2021, WPP acquired Satalia, a technology company offering market-leading AI solutions, to \nbolster its capabilities in experience, commerce and technology.\"The spirit of acquisition for WPP was to augment \ncapability in solving problems across the supply chains. The WPP supply chain includes the creation of content, \nproduction and dissemination. Each part of that process requires a different type of AI,\" he said.According to \nindustry reports, the AI boom has had an impact on the advertising and marketing industries since agencies can \nnow make data-driven decisions that promote the growth of their clients' businesses.There is a lot of excitement \naround generative AI since it will allow ad and marketing companies to come up with content ideas and push that \ncontent across multiple channels to maximise desired success criteria.\"Generative AI allows us to create text, \nsound and image content, which will extend to video soon. It will allow us to speed up the process of ideation and \nproduction. We can also use generative AI to understand how audiences perceive content,\" Hulme said.Although \ngenerative AI is boosting efficiency in the advertising sector, some people are also concerned about data privacy \nand intellectual property infringement.To tackle the issue of data privacy, WPP is building infrastructure to keep the \ndata safe.\"The first concern that brands have is that if you train these models with your own data, that data then \nbecomes available to other people. We are building walled gardens to ensure that that data is safe and secure,\" \nHulme said.On tackling copyright infringement, Hulme said the company makes sure that it uses only those models \nthat can demonstrate the provenance of that data, particularly for production-grade content.A Forrester analysis \npredicts that by 2030, AI will replace 7.5% of the workforce at US advertising companies. Hulme, however, is \nconfident that AI will free advertising specialists from mundane tasks so they can focus on more creative and \nstrategic work. For Reprint Rights: timescontent.com\nLoad-Date: August 11, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "With GenAI, database firm MongoDB gets set for big India play",
        "media": "The Economic Times",
        "time": "April 25, 2024",
        "section": "TECH & INTERNET",
        "length": "859 words",
        "byline": "Suraksha P",
        "story_text": "With GenAI, database firm MongoDB gets set for big India play\nThe Economic Times\nApril 25, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 859 words\nByline: Suraksha P\nBody\nNew York-headquartered database company MongoDB sees a “great opportunity” in India as large banks, airlines \nand financial services companies here launch AI business models, a top company executive said.Valued at about \n$30 billion, MongoDB counts Tata Digital, Tata AIG, Canara HSBC Life Insurance, Zomato, Devnagri, Ambee, \nInovaare and Observe.AI among its key clients.The company, which posted a revenue of $1.68 billion in the last \nfiscal year, a 31% increase year-on-year, has partnered with cloud majors such as Amazon Web Services (AWS), \nMicrosoft Azure and Google Cloud Platform (GCP), its global CEO Dev Ittycheria, told ET.“We expect India to be \none of the big growth engines in the future. We’re in the formative stage here. India is a great opportunity for us,” \nIttycheria said.“The big opportunity here is generative AI companies, large banks, commercial airline companies \nand financial services companies launching AI business models, leveraging advances with large language models \nlike Devnagri, Ambee, Inovaare and Observe.AI,” he said.There are around four million developers in India. About \n20% of the Fortune 500 companies have development centres in India. \nThere’s a burgeoning tech startup ecosystem as well, he said.The company’s India team with offices in Gurugram, \nBengaluru, Mumbai and Hyderabad are expanding and increasing their share in global headcount of 5,000, and the \nbusiness is growing quickly as a function of growth opportunity here, he added.MongoDB has tens of thousands of \ncustomers in over 100 countries. The MongoDB database platform has been downloaded hundreds of millions of \ntimes since 2007.For example, Tata Digital has implemented MongoDB Atlas to streamline a variety of data and \nimprove operations for its super app Tata Neu.MongoDB Atlas is a multi-cloud developer data platform that \naccelerates and simplifies how one builds with data. It provides an easy way to host and manage one’s data in the \ncloud. It combines operational data, metadata and vector data in one platform.“Our customers in India range from \nlarge companies to startups. We’re a developer data platform, which started with databases and evolved into a \ndatabase-as-a-service company with our cloud offerings,” he added.Insurer TATA AIG is another company that is \nusing MongoDB to manage high-volume data, improve operations and support various operational systems, \nincluding claims processing, customer data management, risk assessment and real-time analytics.“The use cases \nare broad from online transaction processing to time series, search, vector search for building AI-powered \napplications, all-in-one common interface, which can be run across different cloud providers—AWS, Azure and \nGCP—as well as on-premise in case the customer is not comfortable. It is the best of both worlds,” Ittycheria \nsaid.When business conditions change, to go from one cloud to another, one need not rewrite their application \narchitecture, he explained.Restaurant aggregator Zomato, for example, with more than 17.5 million customers, is \nusing MongoDB for order tracking, assignment, details, partner onboarding and handles hundreds of thousands of \nrequests per minute.Canara HSBC Life Insurance has also simplified its data model, reduced operational \ncomplexity and achieved 20% cost savings per policy insurance by using MongoDB Atlas.The adoption of both a \nhybrid and multi-cloud model has shifted the organisation away from purely on-premise databases.MongoDB's \nIndian AI startup clients:1. Devnagri is an AI-powered translation engine, helping brands to localise their content five \ntimes faster and more accurately. It is using MongoDB as its core database for training machine translation models, \nstoring diverse sentence chunks, including source English, machine translation, and human-verified translations. \nWith GenAI , database firm MongoDB gets set for big India play\nThis allows flexible handling of structured and unstructured content.2. Climate tech startup Ambee uses proprietary \nclimate and environmental data such as emissions, pollen levels, air quality, soil conditions to help organisations to \nmake decisions about their policies and business strategies. On average, Ambee adds around 10 to 15 GB of data \nevery hour, running AI models on MongoDB Atlas, they deliver data-as-a-service to their clients and provide \nrecommendations.3. Healthcare compliance platform Inovaare, uses MongoDB Atlas to power its AI-driven \nautomation solutions. The document data model of MongoDB enables Inovaare to store and query data of any \nstructure, facilitating efficient compliance management. The end-to-end data encryption, and cloud offered by \nMongoDB Atlas aid in cost reduction, and faster release cycles.4. AI startup Observe.AI leverages a LLM with 40 \nbillion parameters to provide customers with intelligence and coaching that maximise performance of their front-line \nsupport and sales teams. It processes and run models on millions of support touchpoints daily to generate insights \nfor their customers. Most of this unstructured data is stored in MongoDB. It helps to handle large and unpredictable \nworkloads and meet security requirements of large enterprise customers. For Reprint Rights: timescontent.com\nLoad-Date: April 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "How Big Tech Cut Corners to Harvest Data for Their A.I. Models",
        "media": "The New York Times",
        "time": "April 8, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "3276 words",
        "byline": "By Cade Metz, Cecilia Kang, Sheera Frenkel, Stuart A. Thompson and Nico Grant",
        "story_text": "How Big Tech Cut Corners to Harvest Data for Their A.I. Models\nThe New York Times\nApril 8, 2024 Monday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 3276 words\nByline: By Cade Metz, Cecilia Kang, Sheera Frenkel, Stuart A. Thompson and Nico Grant\nBody\nIn late 2021, OpenAI faced a supply problem.\nThe artificial intelligence lab had exhausted every reservoir of reputable English-language text on the internet as it \ndeveloped its latest A.I. system. It needed more data to train the next version of its technology -- lots more. \n  So OpenAI researchers created a speech recognition tool called Whisper. It could transcribe the audio from \nYouTube videos, yielding new conversational text that would make an A.I. system smarter.\n  Some OpenAI employees discussed how such a move might go against YouTube's rules, three people with \nknowledge of the conversations said. YouTube, which is owned by Google, prohibits use of its videos for \napplications that are ''independent'' of the video platform.\n  Ultimately, an OpenAI team transcribed more than one million hours of YouTube videos, the people said. The \nteam included Greg Brockman, OpenAI's president, who personally helped collect the videos, two of the people \nsaid. The texts were then fed into a system called GPT-4, which was widely considered one of the world's most \npowerful A.I. models and was the basis of the latest version of the ChatGPT chatbot.\n  The race to lead A.I. has become a desperate hunt for the digital data needed to advance the technology. To \nobtain that data, tech companies including OpenAI, Google and Meta have cut corners, ignored corporate policies \nand debated bending the law, according to an examination by The New York Times.\n  At Meta, which owns Facebook and Instagram, managers, lawyers and engineers last year discussed buying the \npublishing house Simon & Schuster to procure long works, according to recordings of internal meetings obtained by \nThe Times. They also conferred on gathering copyrighted data from across the internet, even if that meant facing \nlawsuits. Negotiating licenses with publishers, artists, musicians and the news industry would take too long, they \nsaid.\n  Like OpenAI, Google transcribed YouTube videos to harvest text for its A.I. models, five people with knowledge of \nthe company's practices said. That potentially violated the copyrights to the videos, which belong to their creators.\n  Last year, Google also broadened its terms of service. One motivation for the change, according to members of \nthe company's privacy team and an internal message viewed by The Times, was to allow Google to be able to tap \npublicly available Google Docs, restaurant reviews on Google Maps and other online material for more of its A.I. \nproducts.\n  The companies' actions illustrate how online information -- news stories, fictional works, message board posts, \nWikipedia articles, computer programs, photos, podcasts and movie clips -- has increasingly become the lifeblood \nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\nof the booming A.I. industry. Creating innovative systems depends on having enough data to teach the technologies \nto instantly produce text, images, sounds and videos that resemble what a human creates.\n  The volume of data is crucial. Leading chatbot systems have learned from pools of digital text spanning as many \nas three trillion words, or roughly twice the number of words stored in Oxford University's Bodleian Library, which \nhas collected manuscripts since 1602. The most prized data, A.I. researchers said, is high-quality information, such \nas published books and articles, which have been carefully written and edited by professionals.\n  For years, the internet -- with sites like Wikipedia and Reddit -- was a seemingly endless source of data. But as \nA.I. advanced, tech companies sought more repositories. Google and Meta, which have billions of users who \nproduce search queries and social media posts every day, were largely limited by privacy laws and their own \npolicies from drawing on much of that content for A.I.\n  Their situation is urgent. Tech companies could run through the high-quality data on the internet as soon as 2026, \naccording to Epoch, a research institute. The companies are using the data faster than it is being produced.\n  ''The only practical way for these tools to exist is if they can be trained on massive amounts of data without having \nto license that data,'' Sy Damle, a lawyer who represents Andreessen Horowitz, a Silicon Valley venture capital firm, \nsaid of A.I. models last year in a public discussion about copyright law. ''The data needed is so massive that even \ncollective licensing really can't work.''\n  Tech companies are so hungry for new data that some are developing ''synthetic'' information. This is not organic \ndata created by humans, but text, images and code that A.I. models produce -- in other words, the systems learn \nfrom what they themselves generate.\n  OpenAI said each of its A.I. models ''has a unique data set that we curate to help their understanding of the world \nand remain globally competitive in research.'' Google said that its A.I. models ''are trained on some YouTube \ncontent,'' which was allowed under agreements with YouTube creators, and that the company did not use data from \noffice apps outside of an experimental program. Meta said it had ''made aggressive investments'' to integrate A.I. \ninto its services and had billions of publicly shared images and videos from Instagram and Facebook for training its \nmodels.\n  For creators, the growing use of their works by A.I. companies has prompted lawsuits over copyright and licensing. \nThe Times sued OpenAI and Microsoft last year for using copyrighted news articles without permission to train A.I. \nchatbots. OpenAI and Microsoft have said using the articles was ''fair use,'' or allowed under copyright law, because \nthey transformed the works for a different purpose.\n  More than 10,000 trade groups, authors, companies and others submitted comments last year about the use of \ncreative works by A.I. models to the Copyright Office, a federal agency that is preparing guidance on how copyright \nlaw applies in the A.I. era.\n  Justine Bateman, a filmmaker, former actress and author of two books, told the Copyright Office that A.I. models \nwere taking content -- including her writing and films -- without permission or payment.\n  ''This is the largest theft in the United States, period,'' she said in an interview.\n  'Scale Is All You Need'\n  In January 2020, Jared Kaplan, a theoretical physicist at Johns Hopkins University, published a groundbreaking \npaper on A.I. that stoked the appetite for online data.\n  His conclusion was unequivocal: The more data there was to train a large language model -- the technology that \ndrives online chatbots -- the better it would perform. Just as a student learns more by reading more books, large \nlanguage models can better pinpoint patterns in text and be more accurate with more information.\nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\n  ''Everyone was very surprised that these trends -- these scaling laws as we call them -- were basically as precise \nas what you see in astronomy or physics,'' said Dr. Kaplan, who published the paper with nine OpenAI researchers. \n(He now works at the A.I. start-up Anthropic.)\n  ''Scale is all you need'' soon became a rallying cry for A.I.\n  Researchers have long used large public databases of digital information to develop A.I., including Wikipedia and \nCommon Crawl, a database of more than 250 billion web pages collected since 2007. Researchers often ''cleaned'' \nthe data by removing hate speech and other unwanted text before using it to train A.I. models.\n  In 2020, data sets were tiny by today's standards. One database containing 30,000 photographs from the photo \nwebsite Flickr was considered a vital resource at the time.\n  After Dr. Kaplan's paper, that amount of data was no longer enough. It became all about ''just making things really \nbig,'' said Brandon Duderstadt, the chief executive of Nomic, an A.I. company in New York.\n  When OpenAI unveiled GPT-3 in November 2020, it was trained on the largest amount of data to date -- about \n300 billion ''tokens,'' which are essentially words or pieces of words. After learning from that data, the system \ngenerated text with astounding accuracy, writing blog posts, poetry and its own computer programs.\n  In 2022, DeepMind, an A.I. lab owned by Google, went further. It tested 400 A.I. models and varied the amount of \ntraining data and other factors. The top-performing models used even more data than Dr. Kaplan had predicted in \nhis paper. One model, Chinchilla, was trained on 1.4 trillion tokens.\n  It was soon overtaken. Last year, researchers from China released an A.I. model, Skywork, which was trained on \n3.2 trillion tokens from English and Chinese texts. Google also unveiled an A.I. system, PaLM 2, which topped 3.6 \ntrillion tokens.\n  Transcribing YouTube\n  In May, Sam Altman, the chief executive of OpenAI, acknowledged that A.I. companies would use up all viable \ndata on the internet.\n  ''That will run out,'' he said in a speech at a tech conference.\n  Mr. Altman had seen the phenomenon up close. At OpenAI, researchers had gathered data for years, cleaned it \nand fed it into a vast pool of text to train the company's language models. They had mined the computer code \nrepository GitHub, vacuumed up databases of chess moves and drawn on data describing high school tests and \nhomework assignments from the website Quizlet.\n  By late 2021, those supplies were depleted, said eight people with knowledge of the company, who were not \nauthorized to speak publicly.\n  OpenAI was desperate for more data to develop its next-generation A.I. model, GPT-4. So employees discussed \ntranscribing podcasts, audiobooks and YouTube videos, the people said. They talked about creating data from \nscratch with A.I. systems. They also considered buying start-ups that had collected large amounts of digital data.\n  OpenAI eventually made Whisper, the speech recognition tool, to transcribe YouTube videos and podcasts, six \npeople said. But YouTube prohibits people from not only using its videos for ''independent'' applications, but also \naccessing its videos by ''any automated means (such as robots, botnets or scrapers).''\n  OpenAI employees knew they were wading into a legal gray area, the people said, but believed that training A.I. \nwith the videos was fair use. Mr. Brockman, OpenAI's president, was listed in a research paper as a creator of \nWhisper. He personally helped gather YouTube videos and fed them into the technology, two people said.\n  Mr. Brockman referred requests for comment to OpenAI, which said it uses ''numerous sources'' of data.\nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\n  Last year, OpenAI released GPT-4, which drew on the more than one million hours of YouTube videos that \nWhisper had transcribed. Mr. Brockman led the team that developed GPT-4.\n  Some Google employees were aware that OpenAI had harvested YouTube videos for data, two people with \nknowledge of the companies said. But they didn't stop OpenAI because Google had also used transcripts of \nYouTube videos to train its A.I. models, the people said. That practice may have violated the copyrights of YouTube \ncreators. So if Google made a fuss about OpenAI, there might be a public outcry against its own methods, the \npeople said.\n  Matt Bryant, a Google spokesman, said the company had no knowledge of OpenAI's practices and prohibited \n''unauthorized scraping or downloading of YouTube content.'' Google takes action when it has a clear legal or \ntechnical basis to do so, he said.\n  Google's rules allowed it to tap YouTube user data to develop new features for the video platform. But it was \nunclear whether Google could use YouTube data to build a commercial service beyond the video platform, such as \na chatbot.\n  Geoffrey Lottenberg, an intellectual property lawyer with the law firm Berger Singerman, said Google's language \nabout what it could and could not do with YouTube video transcripts was vague.\n  ''Whether the data could be used for a new commercial service is open to interpretation and could be litigated,'' he \nsaid.\n  In late 2022, after OpenAI released ChatGPT and set off an industrywide race to catch up, Google researchers \nand engineers discussed tapping other user data. Billions of words sat in people's Google Docs and other free \nGoogle apps. But the company's privacy restrictions limited how they could use the data, three people with \nknowledge of Google's practices said.\n  In June, Google's legal department asked the privacy team to draft language to broaden what the company could \nuse consumer data for, according to two members of the privacy team and an internal message viewed by The \nTimes.\n  The employees were told Google wanted to use people's publicly available content in Google Docs, Google \nSheets and related apps for an array of A.I. products. The employees said they didn't know if the company had \npreviously trained A.I. on such data.\n  At the time, Google's privacy policy said the company could use publicly available information only to ''help train \nGoogle's language models and build features like Google Translate.''\n  The privacy team wrote new terms so Google could tap the data for its ''A.I. models and build products and \nfeatures like Google Translate, Bard and Cloud AI capabilities,'' which was a wider collection of A.I. technologies.\n  ''What is the end goal here?'' one member of the privacy team asked in an internal message. ''How broad are we \ngoing?''\n  The team was told specifically to release the new terms on the Fourth of July weekend, when people were \ntypically focused on the holiday, the employees said. The revised policy debuted on July 1, at the start of the long \nweekend.\n  In August, two privacy team members said, they pressed managers on whether Google could start using data from \nfree consumer versions of Google Docs, Google Sheets and Google Slides. They were not given clear answers, \nthey said.\n  Mr. Bryant said that the privacy policy changes had been made for clarity and that Google did not use information \nfrom Google Docs or related apps to train language models ''without explicit permission'' from users, referring to a \nvoluntary program that allows users to test experimental features.\nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\n  ''We did not start training on additional types of data based on this language change,'' he said.\n  The Debate at Meta\n  Mark Zuckerberg, Meta's chief executive, had invested in A.I. for years -- but suddenly found himself behind when \nOpenAI released ChatGPT in 2022. He immediately pushed to match and exceed ChatGPT, calling executives and \nengineers at all hours of the night to push them to develop a rival chatbot, said three current and former employees, \nwho were not authorized to discuss confidential conversations.\n  But by early last year, Meta had hit the same hurdle as its rivals: not enough data.\n  Ahmad Al-Dahle, Meta's vice president of generative A.I., told executives that his team had used almost every \navailable English-language book, essay, poem and news article on the internet to develop a model, according to \nrecordings of internal meetings, which were shared by an employee. \n  Meta could not match ChatGPT unless it got more data, Mr. Al-Dahle told colleagues. In March and April 2023, \nsome of the company's business development leaders, engineers and lawyers met nearly daily to tackle the \nproblem.\n  Some debated paying $10 a book for the full licensing rights to new titles. They discussed buying Simon & \nSchuster, which publishes authors like Stephen King, according to the recordings.\n  They also talked about how they had summarized books, essays and other works from the internet without \npermission and discussed sucking up more, even if that meant facing lawsuits. One lawyer warned of ''ethical'' \nconcerns around taking intellectual property from artists but was met with silence, according to the recordings.\n  Mr. Zuckerberg demanded a solution, employees said.\n  ''The capability that Mark is looking for in the product is just something that we currently aren't able to deliver,'' one \nengineer said.\n  While Meta operates giant social networks, it didn't have troves of user posts at its disposal, two employees said. \nMany Facebook users had deleted their earlier posts, and the platform wasn't where people wrote essay-type \ncontent, they said.\n  Meta was also limited by privacy changes it introduced after a 2018 scandal over sharing its users' data with \nCambridge Analytica, a voter-profiling company.\n  Mr. Zuckerberg said in a recent investor call that the billions of publicly shared videos and photos on Facebook \nand Instagram are ''greater than the Common Crawl data set.''\n  During their recorded discussions, Meta executives talked about how they had hired contractors in Africa to \naggregate summaries of fiction and nonfiction. The summaries included copyrighted content ''because we have no \nway of not collecting that,'' a manager said in one meeting.\n  Meta's executives said OpenAI seemed to have used copyrighted material without permission. It would take Meta \ntoo long to negotiate licenses with publishers, artists, musicians and the news industry, they said, according to the \nrecordings.\n  ''The only thing that's holding us back from being as good as ChatGPT is literally just data volume,'' Nick Grudin, a \nvice president of global partnership and content, said in one meeting.\n  OpenAI appeared to be taking copyrighted material and Meta could follow this ''market precedent,'' he added.\n  Meta's executives agreed to lean on a 2015 court decision involving the Authors Guild versus Google, according \nto the recordings. In that case, Google was permitted to scan, digitize and catalog books in an online database after \nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\narguing that it had reproduced only snippets of the works online and had transformed the originals, which made it \nfair use.\n  Using data to train A.I. systems, Meta's lawyers said in their meetings, should similarly be fair use.\n  At least two employees raised concerns about using intellectual property and not paying authors and other artists \nfairly or at all, according to the recordings. One employee recounted a separate discussion about copyrighted data \nwith senior executives including Chris Cox, Meta's chief product officer, and said no one in that meeting considered \nthe ethics of using people's creative works.\n  'Synthetic' Data\n  OpenAI's Mr. Altman had a plan to deal with the looming data shortage.\n  Companies like his, he said at the May conference, would eventually train their A.I. on text generated by A.I. -- \notherwise known as synthetic data.\n  Since an A.I. model can produce humanlike text, Mr. Altman and others have argued, the systems can create \nadditional data to develop better versions of themselves. This would help developers build increasingly powerful \ntechnology and reduce their dependence on copyrighted data.\n  ''As long as you can get over the synthetic data event horizon, where the model is smart enough to make good \nsynthetic data, everything will be fine,'' Mr. Altman said.\n  A.I. researchers have explored synthetic data for years. But building an A.I system that can train itself is easier \nsaid than done. A.I. models that learn from their own outputs can get caught in a loop where they reinforce their \nown quirks, mistakes and limitations.\n  ''The data these systems need is like a path through the jungle,'' said Jeff Clune, a former OpenAI researcher who \nnow teaches computer science at the University of British Columbia. ''If they only train on synthetic data, they can \nget lost in the jungle.''\n  To combat this, OpenAI and others are investigating how two different A.I. models might work together to generate \nsynthetic data that is more useful and reliable. One system produces the data, while a second judges the \ninformation to separate the good from the bad. Researchers are divided on whether this method will work.\n  A.I. executives are barreling ahead nonetheless.\n  ''It should be all right,'' Mr. Altman said at the conference.\nhttps://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html\nGraphic\n \nPHOTOS: Researchers at OpenAI's office in San Francisco developed a speech recognition tool called Whisper to \ntranscribe audio from YouTube videos to amass conversational text for A.I. development.\nAfter OpenAI released ChatGPT, Google researchers and engineers discussed tapping user data to develop A.I., \npeople with knowledge of the discussions said. Google made changes to its privacy policy last year for its free \nconsumer apps. (PHOTOGRAPHS BY JASON HENRY FOR THE NEW YORK TIMES)\nJared Kaplan, a theoretical physicist, wrote a key paper on A.I. and data. (PHOTOGRAPH BY CHRIS J. \nRATCLIFFE/BLOOMBERG NEWS)\nHow Big Tech Cut Corners to Harvest Data for Their A.I. Models\nMark Zuckerberg, Meta's chief executive, pushed to catch up on A.I. (PHOTOGRAPH BY JASON ANDREW FOR \nTHE NEW YORK TIMES)\n Greg Brockman, OpenAI's president, led the team that developed GPT-4. (PHOTOGRAPH BY ANNA \nMONEYMAKER/GETTY IMAGES) (A15) This article appeared in print on page A1, A14, A15.               \nLoad-Date: April 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Apple Is Exploring A.I. Deals With Major News Publishers",
        "media": "The New York Times",
        "time": "December 23, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "813 words",
        "byline": "By Benjamin Mullin and Tripp Mickle",
        "story_text": "Apple Is Exploring A.I. Deals With Major News Publishers\nThe New York Times\nDecember 23, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 813 words\nByline: By Benjamin Mullin and Tripp Mickle\nBody\nThe company has discussed multiyear deals worth at least $50 million to train its generative A.I. systems on \npublishers' news articles.\nApple has opened negotiations in recent weeks with major news and publishing organizations, seeking permission \nto use their material in the company's development of generative artificial intelligence systems, according to four \npeople familiar with the discussions. \n  The technology giant has floated multiyear deals worth at least $50 million to license the archives of news articles, \nsaid the people with knowledge of talks, who spoke on the condition of anonymity to discuss sensitive negotiations. \nThe news organizations contacted by Apple include Condé Nast, publisher of Vogue and The New Yorker; NBC \nNews; and IAC, which owns People, The Daily Beast and Better Homes and Gardens.\n  The negotiations mark one of the earliest examples of how Apple is trying to catch up to rivals in the race to \ndevelop generative A.I., which allows computers to create images and chat like a human. The technology, which \nartificial intelligence experts refer to as neural networks, is built by using troves of photos or digital text to recognize \npatterns. By analyzing thousands of cat photos, for instance, a computer can learn to recognize a cat.\n  Microsoft, OpenAI, Google, Meta and other companies have released chatbots and other products built with the \ntechnology. The tools could change the way people work and generate billions of dollars in sales.\n  But Apple has been absent from the public discussion of A.I. Its virtual assistant, Siri, has remained largely \nstagnant in the decade since its release.\n  A spokeswoman for Apple declined to comment. During a call with analysts last month, Tim Cook, the company's \nchief executive, said Apple has work ''going on'' connected to A.I. but declined to elaborate.\n  Some of the publishers contacted by Apple were lukewarm on the overture. After years of on-again-off-again \ncommercial deals with tech companies like Meta, the owner of Facebook, publishers have grown wary of jumping \ninto business with Silicon Valley.\n  Several publishing executives were concerned that Apple's terms were too expansive, according to three people \nfamiliar with the negotiations. The initial pitch covered broad licensing of publishers' archives of published content, \nwith publishers potentially on the hook for any legal liabilities that could stem from Apple's use of their content.\n  Apple was also vague about how it intended to apply generative A.I. to the news industry, the people said, a \npotential competitive risk given Apple's substantial audience for news on its devices.\nApple Is Exploring A.I. Deals With Major News Publishers\n  Still, some news executives were optimistic that Apple's approach might eventually lead to a meaningful \npartnership. Two people familiar with the discussions struck a positive note on the long-term prospects of a deal, \ncontrasting Apple's approach of asking for permission with behavior from other artificial intelligence-enabled \ncompanies, which have been accused of seeking licensing deals with news organizations after they had already \nused their content to train generative models.\n  In recent years, Apple executives have been debating how to accumulate the data needed to build generative A.I. \nproducts, according to two people familiar with the work. Some of its rivals have been accused of taking written \nmaterial from across the internet without the permission of the artists, writers and coders who created it, leading to \nseveral copyright lawsuits.\n  Apple has been reluctant to take information from the internet, partly because of its commitment to privacy. After it \nacquired the social analytics start-up Topsy in 2013, Apple's leadership asked that Topsy stop collecting information \nfrom Twitter, saying that doing so violated the company's policy against collecting data on Apple customers, who \nmight also post on the social media site, these two people said.\n  The explosion of artificial intelligence has raised alarms among news executives, many of whom are concerned \nthat generative A.I. products like OpenAI's ChatGPT could draw in readers who would otherwise consume their \nnews on platforms for their own subscribers and advertisers.\n  Print news organizations, which decades ago saw their lucrative classifieds business demolished by online \ncompetitors, have been particularly wary about striking deals with A.I. organizations, engaging cautiously with an \neye toward preserving their existing businesses.\n  In a statement, an OpenAI spokesman said that the company respects ''the rights of content creators and owners \nand believes they should benefit from A.I. technology,'' citing its recent deals with the American Journalism Project \nand the German publisher Axel Springer.\n  ''We're optimistic we will continue to find mutually beneficial ways to work together in support of a rich news \necosystem,'' the OpenAI spokesman said.\nhttps://www.nytimes.com/2023/12/22/technology/apple-ai-news-publishers.html\nGraphic\n \nThis article appeared in print on page B5.               \nLoad-Date: December 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "The Race to Prevent ‘the Worst Case Scenario for Machine Learning’",
        "media": "The New York Times",
        "time": "June 25, 2023",
        "section": "BUSINESS",
        "length": "2067 words",
        "byline": "Issie Lapowsky",
        "story_text": "The Race to Prevent ‘the Worst Case Scenario for Machine Learning’\nThe New York Times \nJune 24, 2023 Saturday 14:42 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 2067 words\nByline: Issie Lapowsky\nHighlight: A.I. companies have an edge in blocking the creation and distribution of child sexual abuse material. \nThey’ve seen how social media companies failed.\nBody\nA.I. companies have an edge in blocking the creation and distribution of child sexual abuse material. They’ve seen \nhow social media companies failed.\nDave Willner has had a front-row seat to the evolution of the worst things on the internet.\nHe started working at Facebook in 2008, back when social media companies were making up their rules as they \nwent along. As the company’s head of content policy, it was Mr. Willner who wrote Facebook’s first official \ncommunity standards more than a decade ago, turning what he has said was an informal one-page list that mostly \nboiled down to a ban on “Hitler and naked people” into what is now a voluminous catalog of slurs, crimes and other \ngrotesqueries that are banned across all of Meta’s platforms.\nSo last year, when the San Francisco artificial intelligence lab OpenAI was preparing to launch Dall-E, a tool that \nallows anyone to instantly create an image by describing it in a few words, the company tapped Mr. Willner to be its \nhead of trust and safety. Initially, that meant sifting through all of the images and prompts that Dall-E’s filters flagged \nas potential violations — and figuring out ways to prevent would-be violators from succeeding.\nIt didn’t take long in the job before Mr. Willner found himself considering a familiar threat.\nJust as child predators had for years used Facebook and other major tech platforms to disseminate pictures of child \nsexual abuse, they were now attempting to use Dall-E to create entirely new ones. “I am not surprised that it was a \nthing that people would attempt to do,” Mr. Willner said. “But to be very clear, neither were the folks at OpenAI.”\nFor all of the recent talk of the hypothetical existential risks of generative A.I., experts say it is this immediate threat \n— child predators using new A.I. tools already — that deserves the industry’s undivided attention.\nIn a newly published paper by the Stanford Internet Observatory and Thorn, a nonprofit that fights the spread of \nchild sexual abuse online, researchers found that, since last August, there has been a small but meaningful uptick \nin the amount of photorealistic A.I.-generated child sexual abuse material circulating on the dark web.\nAccording to Thorn’s researchers, this has manifested for the most part in imagery that uses the likeness of real \nvictims but visualizes them in new poses, being subjected to new and increasingly egregious forms of sexual \nviolence. The majority of these images, the researchers found, have been generated not by Dall-E but by open-\nsource tools that were developed and released with few protections in place.\nThe Race to Prevent ‘the Worst Case Scenario for Machine Learning’\nIn their paper, the researchers reported that less than 1 percent of child sexual abuse material found in a sample of \nknown predatory communities appeared to be photorealistic A.I.-generated images. But given the breakneck pace \nof development of these generative A.I. tools, the researchers predict that number will only grow.\n“Within a year, we’re going to be reaching very much a problem state in this area,” said David Thiel, the chief \ntechnologist of the Stanford Internet Observatory, who co-wrote the paper with Thorn’s director of data science, Dr. \nRebecca Portnoff, and Thorn’s head of research, Melissa Stroebel. “This is absolutely the worst case scenario for \nmachine learning that I can think of.”\nDr. Portnoff has been working on machine learning and child safety for more than a decade.\nTo her, the idea that a company like OpenAI is already thinking about this issue speaks to the fact that this field is at \nleast on a faster learning curve than the social media giants were in their earliest days.\n“The posture is different today,” said Dr. Portnoff.\nStill, she said, “If I could rewind the clock, it would be a year ago.”\n‘We trust people’\nIn 2003, Congress passed a law banning “computer-generated child pornography” — a rare instance of \ncongressional future-proofing. But at the time, creating such images was both prohibitively expensive and \ntechnically complex.\nThe cost and complexity of creating these images has been steadily declining, but changed last August with the \npublic debut of Stable Diffusion, a free, open-source text-to-image generator developed by Stability AI, a machine \nlearning company based in London.\nIn its earliest iteration, Stable Diffusion placed few limits on the kind of images its model could produce, including \nones containing nudity. “We trust people, and we trust the community,” the company’s chief executive, Emad \nMostaque, told The New York Times last fall.\nIn a statement, Motez Bishara, the director of communications for Stability AI, said that the company prohibited \nmisuse of its technology for “illegal or immoral” purposes, including the creation of child sexual abuse material. “We \nstrongly support law enforcement efforts against those who misuse our products for illegal or nefarious purposes,” \nMr. Bishara said.\nBecause the model is open-source, developers can download and modify the code on their own computers and use \nit to generate, among other things, realistic adult pornography. In their paper, the researchers at Thorn and the \nStanford Internet Observatory found that predators have tweaked those models so that they are capable of creating \nsexually explicit images of children, too. The researchers demonstrate a sanitized version of this in the report, by \nmodifying one A.I.-generated image of a woman until it looks like an image of Audrey Hepburn as a child.\nStability AI has since released filters that try to block what the company calls “unsafe and inappropriate content.” \nAnd newer versions of the technology were built using data sets that exclude content deemed “not safe for work.” \nBut, according to Mr. Thiel, people are still using the older model to produce imagery that the newer one prohibits.\nUnlike Stable Diffusion, Dall-E is not open-source and is only accessible through OpenAI’s own interface. The \nmodel was also developed with many more safeguards in place to prohibit the creation of even legal nude imagery \nof adults. “The models themselves have a tendency to refuse to have sexual conversations with you,” Mr. Willner \nsaid. “We do that mostly out of prudence around some of these darker sexual topics.”\nThe company also implemented guardrails early on to prevent people from using certain words or phrases in their \nDall-E prompts. But Mr. Willner said predators still try to game the system by using what researchers call “visual \nsynonyms” — creative terms to evade guardrails while describing the images they want to produce.\nThe Race to Prevent ‘the Worst Case Scenario for Machine Learning’\n“If you remove the model’s knowledge of what blood looks like, it still knows what water looks like, and it knows \nwhat the color red is,” Mr. Willner said. “That problem also exists for sexual content.”\n‘Open questions’\nThorn has a tool called Safer, which scans images for child abuse and helps companies report them to the National \nCenter for Missing and Exploited Children, which runs a federally designated clearinghouse of suspected child \nsexual abuse material. OpenAI uses Safer to scan content that people upload to Dall-E’s editing tool. That’s useful \nfor catching real images of children, but Mr. Willner said that even the most sophisticated automated tools could \nstruggle to accurately identify A.I.-generated imagery.\nThat is an emerging concern among child safety experts: That A.I. will not just be used to create new images of real \nchildren but also to make explicit imagery of children who do not exist.\nThat content is illegal on its own and will need to be reported. But this possibility has also led to concerns that the \nfederal clearinghouse may become further inundated with fake imagery that would complicate efforts to identify real \nvictims. Last year alone, the center’s CyberTipline received roughly 32 million reports.\n“If we start receiving reports, will we be able to know? Will they be tagged or be able to be differentiated from \nimages of real children?” said Yiota Souras, the general counsel of the National Center for Missing and Exploited \nChildren.\nAt least some of those answers will need to come not just from A.I. companies, like OpenAI and Stability AI, but \nfrom companies that run messaging apps or social media platforms, like Meta, which is the top reporter to the \nCyberTipline.\nLast year, more than 27 million tips came from Facebook, WhatsApp and Instagram alone. Already, tech \ncompanies use a classification system, developed by an industry alliance called the Tech Coalition, to categorize \nsuspected child sexual abuse material by the victim’s apparent age and the nature of the acts depicted. In their \npaper, the Thorn and Stanford researchers argue that these classifications should be broadened to also reflect \nwhether an image was computer-generated.\nIn a statement to The New York Times, Meta’s global head of safety, Antigone Davis, said, “We’re working to be \npurposeful and evidence-based in our approach to A.I.-generated content, like understanding when the inclusion of \nidentifying information would be most beneficial and how that information should be conveyed.” Ms. Davis said the \ncompany would be working with the National Center for Missing and Exploited Children to determine the best way \nforward.\nBeyond the responsibilities of platforms, researchers argue that there is more that A.I. companies themselves can \nbe doing. Specifically, they could train their models to not create images of child nudity and to clearly identify \nimages as generated by artificial intelligence as they make their way around the internet. This would mean baking a \nwatermark into those images that is more difficult to remove than the ones either Stability AI or OpenAI have \nalready implemented.\nAs lawmakers look to regulate A.I., experts view mandating some form of watermarking or provenance tracing as \nkey to fighting not only child sexual abuse material but also misinformation.\n“You’re only as good as the lowest common denominator here, which is why you want a regulatory regime,” said \nHany Farid, a professor of digital forensics at the University of California, Berkeley.\nProfessor Farid is responsible for developing PhotoDNA, a tool launched in 2009 by Microsoft, which many tech \ncompanies now use to automatically find and block known child sexual abuse imagery. Mr. Farid said tech giants \nwere too slow to implement that technology after it was developed, enabling the scourge of child sexual abuse \nmaterial to openly fester for years. He is currently working with a number of tech companies to create a new \nThe Race to Prevent ‘the Worst Case Scenario for Machine Learning’\ntechnical standard for tracing A.I.-generated imagery. Stability AI is among the companies planning to implement \nthis standard.\nAnother open question is how the court system will treat cases brought against creators of A.I.-generated child \nsexual abuse material — and what liability A.I. companies will have. Though the law against “computer-generated \nchild pornography” has been on the books for two decades, it’s never been tested in court. An earlier law that tried \nto ban what was then referred to as virtual child pornography was struck down by the Supreme Court in 2002 for \ninfringing on speech.\nMembers of the European Commission, the White House and the U.S. Senate Judiciary Committee have been \nbriefed on Stanford and Thorn’s findings. It is critical, Mr. Thiel said, that companies and lawmakers find answers to \nthese questions before the technology advances even further to include things like full motion video. “We’ve got to \nget it before then,” Mr. Thiel said.\nJulie Cordua, the chief executive of Thorn, said the researchers’ findings should be seen as a warning — and an \nopportunity. Unlike the social media giants who woke up to the ways their platforms were enabling child predators \nyears too late, Ms. Cordua argues, there’s still time to prevent the problem of AI-generated child abuse from \nspiraling out of control.\n“We know what these companies should be doing,” Ms. Cordua said. “We just need to do it.”\nPHOTOS: Top, Rebecca Portnoff, the data science director at Thorn, a nonprofit that fights the spread of child \nsexual abuse online. Above, Julie Cordua, the chief executive of Thorn. Above right, Sam Altman, the chief \nexecutive of OpenAI, testified in May before a Senate Judiciary subcommittee on “Oversight of A.I.: Rules for \nArtificial Intelligence.” (PHOTOGRAPHS BY KRISTIAN THACKER FOR THE NEW YORK TIMES; STEPHEN \nGOLDSTEIN FOR THE NEW YORK TIMES; ELIZABETH FRANTZ/REUTERS) This article appeared in print on \npage BU5.\nLoad-Date: June 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Microsoft Makes a Play In the Tech Cold War",
        "media": "The New York Times",
        "time": "April 17, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1414 words",
        "byline": "By Paul Mozur and David E. Sanger",
        "story_text": "Microsoft Makes a Play In the Tech Cold War\nThe New York Times\nApril 17, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1414 words\nByline: By Paul Mozur and David E. Sanger\nBody\nMicrosoft said it would invest $1.5 billion in G42, an Emirati company with ties to China, as Washington and Beijing \nmaneuver to secure tech influence in the Persian Gulf.\nMicrosoft said on Tuesday that it would make a $1.5 billion investment in G42, an artificial intelligence giant in the \nUnited Arab Emirates, in a deal largely orchestrated by the Biden administration to box out China as Washington \nand Beijing battle over who will exercise technological influence in the Persian Gulf region and beyond. \n  Under the partnership, Microsoft will give G42 permission to sell Microsoft services that use powerful A.I. chips, \nwhich are used to train and fine-tune generative A.I. models. In return, G42, which has been under scrutiny by \nWashington for its ties to China, will use Microsoft's cloud services and accede to a security arrangement \nnegotiated in detailed conversations with the U.S. government. It places a series of protections on the A.I. products \nshared with G42 and includes an agreement to strip Chinese gear out of G42's operations, among other steps.\n  ''When it comes to emerging technology, you cannot be both in China's camp and our camp,'' said Gina \nRaimondo, the commerce secretary, who traveled twice to the Emirates to talk about security arrangements for this \nand other partnerships.\n  The accord is highly unusual, Brad Smith, Microsoft's president, said in an interview, reflecting the U.S. \ngovernment's extraordinary concern about protecting the intellectual property behind A.I. programs.\n  ''The U.S. is quite naturally concerned that the most important technology is guarded by a trusted U.S. company,'' \nsaid Mr. Smith, who will take a seat on G42's board.\n  The investment could help the United States push back against China's rising influence in the gulf region. If the \nmoves succeed, G42 will be brought into the U.S. fold and pare back its ties with China. The deal could also \nbecome a model for how U.S. firms leverage their technological leadership in A.I. to lure countries away from \nChinese tech, while reaping huge financial awards.\n  But the matter is sensitive, as U.S. officials have raised questions about G42. This year, a congressional \ncommittee wrote a letter urging the Commerce Department to look into whether G42 should be put under trade \nrestrictions for its ties to China, which include partnerships with Chinese firms and employees who came from \ngovernment-connected companies.\n  In an interview, Ms. Raimondo, who has been at the center of an effort to prevent China from obtaining the most \nadvanced semiconductors and the equipment to make them, said the agreement ''does not authorize the transfer of \nMicrosoft Makes a Play In the Tech Cold War\nartificial intelligence, or A.I. models, or GPUs'' -- the processors needed to develop A.I. applications -- and ''assures \nthose technologies can be safely developed, protected and deployed.''\n  While the Emirates and United States did not sign a separate accord, Ms. Raimondo said, ''We have been \nextensively briefed and we are comfortable that this agreement is consistent with our values.''\n  In a statement, Peng Xiao, the group chief executive of G42, said that ''through Microsoft's strategic investment, \nwe are advancing our mission to deliver cutting-edge A.I. technologies at scale.''\n  The United States and China have been racing to exert technological influence in the Persian Gulf, where \nhundreds of billions of dollars are up for grabs and major investors, including Saudi Arabia, are expected to spend \nbillions on the technology. In the rush to diversify away from oil, many leaders in the region have set their sights on \nA.I. -- and have been happy to play the United States and China off each other.\n  Although the United Arab Emirates is an important U.S. diplomatic and intelligence partner, and one of the largest \nbuyers of American weapons, it has increasingly expanded its military and economic ties with China. A portion of its \ndomestic surveillance system is built on Chinese technology and its telecommunications work on hardware from \nHuawei, a Chinese supplier. That has fed the worries of U.S. officials, who often visit the Persian Gulf nation to \ndiscuss security issues.\n  But U.S. officials are also concerned that the spread of powerful A.I. technology critical to national security could \neventually be used by China or by Chinese government-linked engineers, if not sufficiently guarded. Last month, a \nU.S.  cybersecurity review board sharply criticized Microsoft over a hack in which Chinese attackers gained access \nto data from top officials. Any major leak -- for instance, by G42's selling Microsoft A.I. solutions to companies set \nup in the region by China -- would go against Biden administration policies that have sought to limit China's access \nto the cutting-edge technology.\n  ''This is among the most advanced technology that the U.S. possesses,'' said Gregory Allen, a researcher at the \nCenter for Strategic and International Studies and a former U.S. defense official who worked on A.I. ''There should \nbe a very strategic rationale for offshoring it anywhere.''\n  For Microsoft, a deal with G42 offers potential access to huge Emirati wealth. The company, whose chairman is \nSheikh Tahnoon bin Zayed, the Emirates' national security adviser and the younger brother of the country's ruler, is \na core part of the Emirates' efforts to become a major A.I. player.\n  Despite a name whimsically drawn from ''The Hitchhiker's Guide to the Galaxy,'' in which the answer to the \n''ultimate question of life'' is 42, G42 is deeply embedded in the Emirati security state. It specializes in A.I. and \nrecently worked to build an Arabic chatbot, called Jais.\n  G42 is also focused on biotechnology and surveillance. Several of its executives, including Mr. Xiao, were \nassociated with a company called DarkMatter, an Emirati cyber-intelligence and hacking firm that employs former \nspies.\n  In its letter this year, the bipartisan House Select Committee on the Chinese Communist Party said Mr. Xiao was \nconnected to an expansive network of companies that ''materially support'' the Chinese military's technological \nadvancement.\n  The origins of Tuesday's accord go back to White House meetings last year, when top national security aides \nraised the question with tech executives of how to encourage business arrangements that would deepen U.S. ties \nto firms around the world, especially those China is also interested in.\n  Under the agreement, G42 will cease using Huawei telecom equipment, which the United States fears could \nprovide a back door for the Chinese intelligence agencies. The accord further commits G42 to seeking permission \nbefore it shares its technologies with other governments or militaries and prohibits it from using the technology for \nsurveillance. Microsoft will also have the power to audit G42's use of its technology.\nMicrosoft Makes a Play In the Tech Cold War\n  G42 would get use of A.I. computing power in Microsoft's data center in the Emirates, sensitive technology that \ncannot be sold in the country without an export license. Access to the computing power would likely give G42 a \ncompetitive edge in the region. A second phase of the deal, which could prove even more controversial and has not \nyet been negotiated, could transfer some of Microsoft's A.I. technology to G42.\n  American intelligence officials have raised concerns about G42's relationship to China in a series of classified \nassessments, The New York Times previously reported. Biden administration officials have also pushed their \nEmirati counterparts to cut the company's ties to China. Some officials believe the U.S. pressure campaign has \nyielded some results, but remain concerned about less overt ties between G42 and China.\n  One G42 executive previously worked at the Chinese A.I. surveillance company Yitu, which has extensive ties to \nChina's security services and runs facial-recognition-powered monitoring across the country. The company has also \nhad ties to a Chinese genetics giant, BGI, whose subsidiaries were placed on a blacklist by the Biden administration \nlast year. Mr. Xiao also led a firm that was involved in 2019 in starting and operating a social media app, ToTok, \nthat U.S. intelligence agencies said was an Emirati spy tool used to harvest user data.\n  In recent months, G42 has agreed to walk back some of its China ties, including divesting a stake it took in \nTikTok's owner, ByteDance, and pulling out Huawei technology from its operations, according to U.S. officials.\n  Edward Wong contributed reporting.Edward Wong contributed reporting.\nhttps://www.nytimes.com/2024/04/16/technology/microsoft-g42-uae-ai.html\nGraphic\n \nPHOTOS: Peng Xiao, G42's group chief executive, praised Microsoft's investment. (PHOTOGRAPH BY G42, VIA \nPRNEWSWIRE)\n G42 cameras in the United Arab Emirates last December. There is a rush to diversify away from oil in the region. \n(PHOTOGRAPH BY PETER DEJONG/ASSOCIATED PRESS) (B5) This article appeared in print on page B1, B5.               \nLoad-Date: April 17, 2024"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Jan2024",
        "header": "PA. PARTNERS WITH OPENAI TO INSTRUCT STATE WORKERS",
        "media": "Pittsburgh Post-Gazette",
        "time": "January 11, 2024",
        "section": "BUSINESS; Pg. D-3",
        "length": "538 words",
        "byline": "Pittsburgh Post-Gazette",
        "story_text": "PA. PARTNERS WITH OPENAI TO INSTRUCT STATE WORKERS\nPittsburgh Post-Gazette\nJanuary 11, 2024 Thursday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: BUSINESS; Pg. D-3\nLength: 538 words\nByline: Pittsburgh Post-Gazette\nBody\nGov. Josh Shapiro's administration will use artificial intelligence in a pilot program \"to help Commonwealth \nemployees understand where and how generative AI tools can be safely and securely leveraged in their daily \noperations,\" the administration said Wednesday.\nThe program, led by the state's Office of Administration, will be run through a partnership with OpenAI, the San \nFrancisco company's first agreement with a state entity. It will also involve members of Carnegie Mellon University's \nBlock Center for Society and Technology.\n\"I believe Pennsylvania can be a national leader in the safe and responsible use of generative AI in our \ngovernment operations - and this first-in-the-nation pilot with OpenAI will help us safely and securely learn from and \nuse this important technology to serve Pennsylvanians and empower our workforce,\" Mr. Shapiro said in a news \nrelease.\n\"By establishing a generative AI Governing Board within my administration and partnering with universities that are \nnational leaders in developing and deploying AI, we have already leaned into innovation to ensure our \nCommonwealth approaches generative AI use responsibly and ethically to capitalize on opportunity.\"\nSam Altman, CEO of OpenAI, said the program illustrates Pennsylvania's \"commitment to innovation.\"\n\"Our collaboration with Gov. Shapiro and the Pennsylvania team will provide valuable insights into how AI tools can \nresponsibly enhance state services,\" he said.\nThe program will begin this month. Office of Administration staff will use the AI tool for tasks including creating and \nediting text, updating policy language, drafting job descriptions, clarifying employee policy, and helping employees \ngenerate code. The program will expand after initial feedback is reviewed.\nMr. Shapiro said the version of ChatGPT the employees will use will include enhanced security and privacy features \nunavailable to other consumers.\n\"Commonwealth employees may not use any sensitive information - including any Pennsylvanian's personally \nidentifiable information - when utilizing ChatGPT for day-to-day operations,\" the administration said.\n\"Our goal with the pilot is to work closely with a small number of employees to figure out where we can have the \ngreatest impact using generative AI tools,\" said Office of Administration Secretary Neil Weaver, who is also \nchairman of the Generative AI Governing Board. \"Their input will help us understand the practical applications of \ngenerative AI in their daily work and how we can best support our workforce as the technology becomes more \nwidespread.\"\nPA. PARTNERS WITH OPENAI TO INSTRUCT STATE WORKERS\nThe announcement came a day after Mr. Shapiro announced that Excelitas Technologies Corp., a top photonics \ntechnology company, will move its headquarters to the Strip District - selecting Pittsburgh over locations in Ohio and \nTexas.\nThat is expected to create at least 250 jobs in four years. Excelitas will take over space in the Riverfront West \nbuilding in the 3 Crossings development vacated in 2022 by Argo AI, an autonomous vehicle startup that shut down \nafter Ford and Volkswagen discontinued their investments.\nThe move \"sends a clear signal that Western Pennsylvania is a national hub for life sciences, advanced \nmanufacturing and more,\" Mr. Shapiro said.\nGraphic\n \nPHOTO: Eric Risberg/Associated Press: Sam Altman participates in a discussion during the Asia-Pacific Economic \nCooperation (APEC) CEO Summit, Thursday, Nov. 16, 2023, in San Francisco. The co-founder and CEO of \nOpenAI is working with Gov. Josh Shapiro on a pilot program to incorporate artificial intelligence into government \noperations.\nLoad-Date: January 11, 2024"
    },
    {
        "file_name": "DealBook_Newsletter_Dec2023",
        "header": "Why a Warner Bros.-Paramount Merger Does (and Doesn’t) Makes Sense;",
        "media": "DealBook Newsletter",
        "time": "December 21, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1877 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Why a Warner Bros.-Paramount Merger Does (and Doesn’t) Makes Sense; \nDealBook Newsletter\nThe New York Times \nDecember 21, 2023 Thursday 10:34 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1877 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni &lt;p&gt;Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is \na co-anchor of CNBC&amp;#8217;s &#34;Squawk Box&#34; and the author of &amp;#8220;Too Big to \nFail.&amp;#8221; He is also a co-creator of the Showtime drama series &#34;Billions.&#34;&lt;/p&gt; &lt;p&gt;Ravi \nMattu is the managing editor of DealBook, based in London. He joined The New York Times in 2022 from the \nFinancial Times, where he held a number of senior roles in Hong Kong and London.&lt;/p&gt; &lt;p&gt;Bernhard \nWarner is a senior editor for DealBook, a newsletter from The Times, covering business trends, the economy and \nthe markets.&lt;/p&gt; &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on \nbusiness and how workplaces are changing.&lt;/p&gt; &lt;p&gt;Michael de la Merced joined The Times as a reporter \nin 2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry.&lt;/p&gt; &lt;p&gt;Lauren Hirsch joined The Times from CNBC in 2020, \ncovering deals and the biggest stories on Wall Street.&lt;/p&gt; &lt;p&gt;Ephrat Livni reports from Washington on \nthe intersection of business and policy for DealBook. Previously, she was a senior reporter at Quartz, covering law \nand politics, and has practiced law in the public and private sectors.&amp;#160;&amp;#160;&lt;/p&gt;\nHighlight: A potential deal could bolster their streaming businesses and negotiating power with cable operators. \nBut their crushing debt load could be a turn-off.\nBody\nA potential deal could bolster their streaming businesses and negotiating power with cable operators. But their \ncrushing debt load could be a turn-off.\nThe wrinkles in a potential media merger\nMedia deal makers aren’t waiting until 2024 to get started on potential big-ticket M.&amp;A.\nNews that David Zaslav, the C.E.O. of Warner Bros. Discovery, expressed interest in combining with Paramount set \ntongues wagging about a possible union of Hollywood’s top deal candidates. But it’s unclear whether this will be the \ncombination that gets completed, DealBook’s Lauren Hirsch and Michael de la Merced write.\nA deal could make sense. Their streaming platforms — Max and Paramount+ — are far smaller than Netflix or \nDisney+, so putting them together might create a more robust competitor. (Of note: Both companies own valuable \nsports streaming rights, which could help draw subscribers.)\nAnd it could give the united business more leverage in negotiations with cable providers on the fees for carrying \nlegacy television networks like Comedy Central and Discovery, especially as those channels suffer from falling \nratings and stagnant ad sales.\nBut there are plenty of reasons not to do a deal. Warner Bros. Discovery has $40 billion in debt and $5 billion in free \ncash flow, while Paramount has negative cash flow and $15 billion in debt. In other words, the combined company \nWhy a Warner Bros. -Paramount Merger Does (and Doesn’t) Makes Sense DealBook Newsletter\nwould have a crushing debt load and little money to pay that down or spend on content — potentially forcing Zaslav \nto cut more costs, after previous efforts torched his standing with content creators.\nThe new business would also be heavily reliant on declining TV channels, a situation that investors don’t like. \n(Paramount, however, may be able to sell BET and VH1 to a buyer such as the media mogul Byron Allen.)\nInvestors aren’t enthusiastic about the potential combination: Warner Bros. Discovery shares fell almost 6 percent \non Wednesday after Axios scooped the talks, while Paramount’s stock declined 2 percent.\nThere are other unknowns:\n• Shari Redstone, who runs Paramount’s parent, may be up for a deal, given that she’s exploring selling a \ncontrolling stake in her company to Skydance, a studio backed by the investment firm RedBird Capital. But \nis the media mogul John Malone, who sits on the Warner Bros. Discovery board, also game?\n• The Biden administration’s antitrust enforcers, who just finalized an aggressive overhaul of merger rules, is \nlikely to be skeptical of such a combination.\n• How far can talks go without running afoul of I.R.S. rules that would impose a big tax hit on Warner Bros. \nDiscovery if it does a big deal before April?\nSome observers think there’s a Kabuki element to these talks. CNBC’s Alex Sherman and The Information’s Martin \nPeers wonder whether Zaslav’s approach to Paramount, and its quick leak to the media, was a market trial balloon \n— or a way to draw out Comcast, whose NBCUniversal has long been considered a potential buyer of Warner Bros. \nDiscovery. (NBCUniversal, with its deeper pockets, is financially a more attractive partner for Zaslav’s company, \nthough it would also face antitrust concerns.)\nNot all deal makers think that’s the case here. But with investors widely believing that the media industry must \nconsolidate in some way, the only question is which deals get done.\nHERE’S WHAT’S HAPPENING \nApple loses bid to delay a sales ban on its smartwatch. The International Trade Commission denied the company’s \neffort to pause the action while Apple appeals a ruling that it infringed a competitor’s patents. Apple said this week \nthat it would stop selling the latest versions of its popular device in U.S. stores starting on Thursday. President \nBiden would have until Dec. 25 to veto the original decision.\nThe Biden administration may raise tariffs on Chinese electric vehicle makers. Officials are considering increasing \nthe 25 percent levy (imposed by the Trump administration) to boost the U.S. clean energy sector, according to The \nWall Street Journal. Meanwhile, China said on Thursday that it would halt the export of rare earth metals and \nmagnets, crucial ingredients in the making of military hardware and EVs.\nMore companies warn of supply chain disruptions from Red Sea attacks. Ikea and Electrolux said delivery of \nproducts may be delayed, as Houthi rebels in Yemen vow to step up their attacks on ships. More than 100 \ncontainer ships have been redirected to circumnavigate Africa, a detour that could add more than a week to journey \ntimes and push shipping rates higher.\nAn A.I. darling passes the hat, again\nAnthropic, the highly touted artificial intelligence start-up, is in talks to raise $750 million from backers including \nMenlo Ventures at a valuation of at least $15 billion, according to The Information. It’s a sign of how much money it \ntakes to compete in the A.I. wars — and how investors are (mostly) willing to keep paying.\nConsider the eye-popping numbers of the potential investment: At $15 billion, excluding the potential new \ninvestment, Anthropic’s valuation would be triple what it was in a fund-raising round this spring. And, according to \nThe Information, it would be 75 times the company’s annualized revenue — more than the 66 times multiple in \nOpenAI’s current share sale.\nWhy a Warner Bros. -Paramount Merger Does (and Doesn’t) Makes Sense DealBook Newsletter\nAnthropic has already raised five rounds this year, according to data from Crunchbase. The company has collected \n$7.6 billion from investors, including tech giants like Amazon and Google that are eager to hook Anthropic’s Claude \nA.I. model into their sprawling cloud computing platforms.\nThat huge sum is necessary, considering the extremely expensive costs of the computing power needed to develop \nA.I. systems. (That’s a reason much of Microsoft’s $10 billion investment in OpenAI is in cloud credits.)\nIt suggests that investors remain interested in A.I. leaders. Overall investment in generative A.I. start-ups declined \nin the third quarter, according to PitchBook, with some investors citing growing pains with the technology and some \ncooling of the fervor for chatbots. Anthropic is clearly an exception, as is Mistral, a French start-up that in its first \nseven months has raised more than $650 million and closed a new funding round this month.\nInvestors are still willing to back a business with unorthodox corporate governance. Oversight at Anthropic isn’t as \novertly messy as OpenAI’s setup; it has a board that has a fiduciary responsibility to shareholders, for instance.\nBut the start-up, whose founders left OpenAI because of concerns about safety, has also created a so-called long-\nterm benefit trust, made up of financially disinterested directors meant to ensure the company lives up to its mission \nof producing A.I. that benefits humanity.\nThe banking sector’s $160 billion conundrum \nSince the collapse of Silicon Valley Bank last spring, Wall Street has been on high alert for the next big systemic \nrisk. Atop its list of worries is the banking sector’s exposure to the souring commercial real estate market.\nA new study puts a number on what’s at stake. Banks face up to $160 billion in losses from an anticipated wave of \ndefaults on their commercial real estate loans, researchers from Columbia, Stanford, U.S.C., and Northwestern \nwrite in a working paper published by the National Bureau of Economic Research.\nSeparate research this week estimated that commercial real estate, or C.R.E., values are set to drop by more than \n$500 billion in 2024. And Morgan Stanley calculated earlier this year that lenders would need to negotiate more \nthan $1.5 trillion of their C.R.E. portfolios by the end of 2025 to avert defaults.\nThe potential tsunami of losses could put banks at risk. “Our analysis, reflecting market conditions up to Q3 2023, \nreveal that C.R.E. risk can induce anywhere from dozens to over 300 mainly smaller regional banks joining the \nranks of banks at risk of solvency runs,” the researchers wrote in the N.B.E.R. paper.\nC.R.E. is the lifeblood of most banks’ lending businesses, a market estimated at roughly $20 trillion. The sector has \ngrown more precarious because of a potentially toxic cocktail of post-pandemic office vacancies, the work-from-\nhome trend, the highest interest rates in decades and a slowing economy.\nRegulators are concerned, too. In its annual report released last week, the Financial Stability Oversight Council — a \nwatchdog created in the wake of the 2008 banking crisis — called commercial real estate the biggest financial risk \nto the economy. The massive C.R.E. crunch may also force banks to cut back on lending elsewhere, the F.S.O.C. \nwarned.\nBuy now, pay “phantom debt” later \nStrong retail spending has been one of the surprises of this holiday season, bucking economists’ predictions that \nconsumers were about to pull back in the face of high inflation and reduced savings.\nThe resurgence of so-called “buy now, pay later” loans may be fueling the shopping splurge, and some economists \nare worried, report The Times’s Ben Casselman and Jordyn Holman.\nThe loans, which allow consumers to pay for purchases in installments, often interest-free, have soared in \npopularity because of high prices and interest rates. Retailers have used them to attract customers and to get \npeople to spend more.\nWhy a Warner Bros. -Paramount Merger Does (and Doesn’t) Makes Sense DealBook Newsletter\nBut such loans may be encouraging younger and lower-income Americans to take on too much debt, according to \nconsumer groups and some lawmakers. And because such loans aren’t routinely reported to credit bureaus or \ncaptured in public data, they could also represent a hidden source of risk to the financial system.\n“The more I dig into it, the more concerned I am,” said Tim Quinlan, a Wells Fargo economist who recently \npublished a report that described pay-later loans as “phantom debt.”\nTHE SPEED READ \nDeals\n• Warburg Pincus has tapped Credit Suisse’s former chairman, Antonio Horta-Osorio, on a 6 billion euro ($6.6 \nbillion) bid for Altice’s Portuguese telecoms assets. (FT)\n• Swisscom is reportedly weighing an offer for Vodafone’s Italian unit. (Bloomberg)\n• The management consulting firm Aon has agreed to buy the insurance broker NFP in a deal valued at $13.4 \nbillion. (Reuters)\n• “The US backlash against Nippon Steel is wholly misguided” (FT)\nPolicy\n• The F.T.C. has proposed sweeping new rules designed to curb how tech companies track and monetize \nchildren’s data. (NYT)\n• Europe’s top court ruled that UEFA’s control of European soccer is an illegal monopoly, giving a significant \nboost to efforts to create a lucrative new competition. (ESPN)\n• “The World’s Most Complicated Tax System Just Got Easier” (WSJ)\nBest of the rest\n• Bobby Kotick, the C.E.O. of Activision Blizzard who orchestrated the gaming sector’s biggest merger, will step \ndown next week. (CNBC)\n• A House committee investigating antisemitism at Harvard has requested documents pertaining to plagiarism \nallegations leveled against the university’s president, Claudine Gay. (The Harvard Crimson)\n• A North Carolina man pleaded guilty to orchestrating a stock manipulation scheme involving the Your \nHometown Deli in Paulsboro, N.J. (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: David Zaslav, the C.E.O. of Warner Bros. Discovery, set the media world buzzing yesterday after holding \npotential merger talks with Paramount. (PHOTOGRAPH BY Haiyun Jiang for The New York Times FOR THE NEW \nYORK TIMES)\nLoad-Date: December 21, 2023"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "No plans to leave Europe: OpenAI CEO Sam Altman",
        "media": "The Economic Times",
        "time": "May 26, 2023",
        "section": "TECH & INTERNET",
        "length": "418 words",
        "byline": " ",
        "story_text": "No plans to leave Europe: OpenAI CEO Sam Altman\nThe Economic Times\nMay 27, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 418 words\nBody\nAmid news of OpenAI possibly leaving Europe due to regulators tightening the noose on the development of \nartificial intelligence (AI), the firm's chief executive Sam Altman said on Friday that they are excited to continue to \noperate in the region and have no plans to leave.Altman tweeted on Friday, \"Very productive week of conversations \nin Europe about how to best regulate AI! We are excited to continue to operate here and of course, have no plans \nto leave.\"The OpenAI CEO spent the past week crisscrossing Europe, meeting policymakers in France, Spain, \nPoland, Germany, and the UK to discuss the future of AI and the progress of ChatGPT. Threats to leave EUOn \nWednesday, Altman, while speaking at an event in London, had said that the ChatGPT maker may leave the EU if \nthe bloc \"overregulated\".\"The current draft of the EU AI Act would be over-regulating, but we have heard it's going \nto get pulled back,\" Altman said. \"There's so much they could do like changing the definition of general-purpose AI \nsystems. There's a lot of things that could be done\"A General Purpose AI System is a category proposed by \nlawmakers to account for AI tools with more than one application, such as generative AI models like Microsoft-\nbacked ChatGPT.\nHowever, EU lawmakers were not quite happy with Altman's threats. \"I don't see any dilution happening anytime \nsoon,\" Dragos Tudorache, a Romanian member of the European Parliament who is leading the drafting of EU \nproposals,told news agency Reuters.According to the Reuters report, Dutch MEP Kim van Sparrentak, who has \nalso worked on the draft EU law, said she and her colleagues \"shouldn't let ourselves be blackmailed by American \ncompanies.\"She said, \"If OpenAI can't comply with basic data governance, transparency, safety, and security \nrequirements, then their systems aren't fit for the European market.\"In early May, EU parliamentarians reached \ncommon ground on the draft of the EU AI Act, which will now be debated between the representatives of the \nParliament, the Council, and the Commission.OpenAI has closedan investment fund called OpenAI Startup Fund \nwith a value of more than $175 million on Thursday. The AI firm has been investing in startups working in artificial \nintelligence for a while. According to media reports, the company launched the OpenAI Startup Fund and said it \nwould seek to back companies \"pushing the boundaries of how powerful AI can positively impact the world and \nprofoundly change people's lives\". For Reprint Rights: timescontent.com\nLoad-Date: May 26, 2023"
    },
    {
        "file_name": "The_Economic_Times_Feb2023",
        "header": "China's JD.Com will launch ChatGPT-like product called ChatJD",
        "media": "The Economic Times",
        "time": "February 10, 2023",
        "section": "TECH & INTERNET",
        "length": "423 words",
        "byline": " ",
        "story_text": "China's JD.Com will launch ChatGPT-like product called ChatJD\nThe Economic Times\nFebruary 11, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 423 words\nBody\nChinese e-commerce company JD.Com Inc's unit JD Cloud will launch a product similar to ChatGPT called ChatJD \nthat will be targeted at other businesses, the company said on Friday, reported news agency ReutersThere has \nbeen a lot of interest in generative AI since OpenAI's ChatGPT went live last year. Another Chinese tech giant \nBaidu said it would finish internal testing of its own ChatGPT-style AI chatbot called 'Ernie Bot' in March, joining \ntech companies around the world in the race to develop generative AI technology.Ernie, meaning \"Enhanced \nRepresentation through Knowledge Integration,\" is a large AI-powered language model introduced in 2019, Baidu \nsaid. \nIt has gradually grown to be able to perform tasks including language understanding, language generation, and \ntext-to-image generation, it added.Google, the world's largest search engine, will make artificial intelligence-based \nlarge language models like LaMDA available \"in the coming weeks and months\", according to chief executive officer \nSundar Pichai.OpenAI on February 1, launched a paid version of ChatGPT. The subscription include features such \nas general access to ChatGPT, even during peak times; faster response times; priority access to new features and \nimprovements.The paid version of the AI chatbot can be availed for $20 per month.Currently, ChatGPT Plus is \navailable only to users in the United States. OpenAI said it will begin the process of inviting people waitlist over the \ncoming weeks.\"We plan to expand access and support to additional countries and regions soon,\" the company said \nin a post.Bard's costly mistakeAlphabet's shares tanked more than 9% during regular trading on Thursday, wiping \noff $100 billion off of its market cap, after a report emerged pointing to a factual error made by its newly launched AI \nchatbot Bard.The error was highlighted in a report by news agency Reuters.The company posted a GIF of its new \nAI Bard in action which showed the chatbot giving a factually inaccurate response to a prompt.In the GIF, the \nchatbot is prompted, \"What new discoveries from the James Webb Space Telescope (JWST) can I tell my 9-year \nold about?\"Bard responded with a number of answers, including one suggesting the JWST was used to take the \nvery first pictures of a planet outside the Earth's solar system, or exoplanets.This is where it went wrong as the first \npictures of exoplanets were, however, taken by the European Southern Observatory's Very Large Telescope (VLT) \nin 2004, as confirmed by NASA. For Reprint Rights: timescontent.com\nLoad-Date: February 10, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "Build Data-driven Culture: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 24, 2023",
        "section": "FRONT PAGE",
        "length": "876 words",
        "byline": "Kala Vijayraghavan & Lijee Philip",
        "story_text": "Build Data-driven Culture: Experts\nEconomic Times (E-Paper Edition)\nMay 24, 2023 Wednesday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 876 words\nByline: Kala Vijayraghavan & Lijee Philip\nHighlight: Industry captains suggest regulation, employee training to stay up-to-date with artificial intelligence\nBody\nMumbai: India Inc needs to reskill employees and improve efficiencies as it seeks to keep pace with the rapid \ngrowth of artificial intelligence (AI), even as it grapples with assessing the impact of this potentially transformative \ntechnology on different  sectors and organisations, said senior industry executives.  They told ETthat the \ngovernment should address the ethics issue around AI and that some amount of regulation could be needed to \nprotect companies.  AI refers to the simulation of human intelligence processes by machines, especially computers. \nHindustan Unilever chief executive Sanjiv Mehta said India must prioritise regulations for artificial intelligence ethics, \ndata privacy and protection of intellectual property rights (IPR), while reskilling the workforce where jobs are at a \nrisk and building an AI-ready workforce proactively. \n“Generative AI has the potential to transform Indian businesses by enabling personalised customer experiences, \nboosting productivity, accelerating innovations and revolutionising education,” said Mehta. “However, to harness the \nbenefits, we need a balanced approach.” SC Invites Bids for AI Tools The apex court is seeking AI tools for \ntranscription of proceedings, oral arguments. “Collaboration between government, academia and businesses is \nessential to harness the benefits while establishing responsible adoption of generative AI in the country,” said \nHUL's Mehta. Financial services, banking and insurance businesses are quite resilient in their structural set-up, as \nthey are highly digitised and can use artificial intelligence to remain competitive, said experts.  They also said \ncompanies that want to use AI to make businesses more efficient must also invest in training employees to build a \nmore data-driven culture and make data accessible through data analytics and business intelligence tools to help in \ndecision-making. Tata Sons chairman N Chandrasekaran recently said at a media event that AI will be a major \ndisruptor and significantly impact jobs, skills and the regulatory environment. “AI is going to change the productive \nequation by an order of magnitude; it has implications on jobs and skills for the future. It is a huge regulatory issue \nbecause already, different governments have started reacting differently. We have got to take the lead to come up \nwith some kind of a regulatory framework,” he said. Generative AI spells a fundamental shift in jobs, said Rajan \nNavani, co-chair of the Confederation of Indian Industry's AI committee. “It opens the way for massive disruption as \nboth established businesses and new entrants drive innovation and develop new business models that could make \nmany existing jobs redundant.” He said the government should address the ethical issues around AI, which could \nnecessitate some regulation for protecting companies. “AI is a game changer in areas related to data analytics, \nenabling real-time decision processes, enhancing efficiency, speed and predictability of responses and automating \nroutine processes,” said Suresh Narayanan, chief executive, Nestl. “Worries come in related to ChatGPT-type LLM \nplatforms where IP protection, plagiarism and authenticity of content without religious, race, gender or other biases \ncreep in.” Indian businesses are increasingly leveraging AI as part of accentuating customer experience and \nboosting efficiency for customers. “AI is a game changer and will drive the next wave of innovation and \nadvancement. It must  also be used in a responsible way. That way, companies can really leverage it to delight \nconsumers and create new experiences,” said Sudarshan Venu, managing director, TVS Motor. NEED TO BRIDGE \nBuild Data-driven Culture: Experts\nGAP Reliance Industries Ltd is reported to have set aside $2 billion for its multi-design strategy approach to \ntransform into a technology and innovation powerhouse. The conglomerate's strategy involves spending $1.6 billion \non purchasing stakes in technology-driven companies in different countries, including the US, the UK and India. The \nremaining amount will be invested in creating inhouse tech in emerging technologies, including AI, machine learning \n(ML), blockchain, augmented reality, Internet of Things, robotics and Big Data analytics. Clearly, there is disparity in \nAI adoption, especially in segments such as agriculture and micro, small and medium enterprises, where digitisation \nis relatively low. While a generational change is needed, the current levels of change are largely incremental, said \nNavani. “Will it spur more falsehoods, fake news, hate material, etc?” said Narayanan.  “Hence the need for \nregulation so we don't land up with the social media chaos we now have on various platforms. AI/ ML can be \nvaluable as simulated online training tools, especially in hyper-specialised processes that need assimilation over a \nperiod of time.” Tata group is also preparing to make AI an enabler for businesses. Group chairman \nChandrasekaran earlier said training is a core competence of the company and that it had already created pilots to \nexplore the potential of AI and ML. “We might set up a centre of excellence for the group and we are already putting \nthe framework in place. We will put a lot of hero projects across the group on AI and machine learning,” he had \nsaid.\nLoad-Date: May 24, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Dec2023",
        "header": "MediaTek Goes Big on Premium with New Mobile Processors",
        "media": "Economic Times (E-Paper Edition)",
        "time": "December 10, 2023",
        "section": "COMPANIES & ECONOMY",
        "length": "360 words",
        "byline": "Subhrojit Mallick",
        "story_text": "MediaTek Goes Big on Premium with New Mobile Processors\nEconomic Times (E-Paper Edition)\nDecember 11, 2023 Monday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES & ECONOMY\nLength: 360 words\nByline: Subhrojit Mallick\nBody\nNew Delhi:Taiwanese chipmaker MediaTek is gunning for the premium segment in coming years taking on \nformidable US rivals Qualcomm and Apple with the launch of its latest line-up of flagship mobile processors \nfocussing on high performance and generative AI capabilities, a top company executive said. “Our revenues \nincreased from $7.9 billion to $14 billion in calendar 2023 globally. A big milestone this year is that we’ve been able \nto generate $1 billion in revenue from our flagship chipsets globally,” MediaTek India managing director Anku Jain \ntold ET. \n Globally, MediaTek enjoys a lion’s share of the mobile processor market with 30% in terms of volumes, driven by a \nchange in the company’s philosophy from being followers of current tech-  nological trends to becoming a \ntechnology leader. As per Cybermedia Research, as many as 20 million MediaTek-powered phones were shipped \nto India in Q3 2023, capturing 46% market share, compared to 12 million powered by Qualcomm, which had 27% \nmarket share in volume terms, underlining the Taiwanese brand’s dominance in the India market. “Internally, we \nused to say we are a very good follower, being very efficient and ef-  fective in following the technology. But in the \nlast five-six years, the mindset has changed to wanting to become technology leaders,” Jain said, adding that since \nthen, MediaTek has invested in leading-edge products. It is also part of 3GPP and has been actively working with \nstakeholders to set telecom standards for the world in 5G and 6G. “We were the first ones to launch a 5G chipset, \nwhile for 4G, we were three-four years behind. That is the kind of shift that has happened,” Jain added. The \nchipmaker is now loo-  king to lead the generative AI space with its latest chipset that has the capability to run a \n33-billion parameter large language model, a key ingredient in ChatGPTlike apps. Jain added aside from tech \nadvances, MediaTek had also improved its brand image, in that, while smartphone players would previously shy \naway from naming the chipset brand on stage, they now invite executives from the company to talk at major launch \nevents. subhrojit.mallick@timesgroup.com\nLoad-Date: December 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2023",
        "header": "Publishers Worry A.I. Chatbots Will Cut Readership",
        "media": "The New York Times - International Edition",
        "time": "March 31, 2023",
        "section": "BUSINESS",
        "length": "1316 words",
        "byline": "Katie Robertson",
        "story_text": "Publishers Worry A.I. Chatbots Will Cut Readership\nThe New York Times - International Edition\nApril 1, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1316 words\nByline: Katie Robertson\nBody\nMany sites get at least half their traffic from search engines. Fuller results generated by new chatbots could mean \nfar fewer visitors.       \nThe publishing industry has spent the past two decades struggling to adjust to the internet, as print circulation has \nplummeted and tech companies have gobbled up rivers of advertising revenue.       \nNow come the chatbots.       \nNew artificial intelligence tools from Google and Microsoft give answers to search queries in full paragraphs rather \nthan a list of links. Many publishers worry that far fewer people will click through to news sites as a result, shrinking \ntraffic - and, by extension, revenue.       \nThe new A.I. search tools remain in limited release, so publishers such as Condé Nast and Vice have not yet seen \nan effect on their business. But in an effort to prevent the industry from being upended without their input, many are \npulling together task forces to weigh options, making the topic a priority at industry conferences and, through a \ntrade organization, planning a push to be paid for the use of their content by chatbots.       \n\"You could essentially call this the Wikipedia-ization of a lot of information,\" said Bryan Goldberg, the chief \nexecutive of BDG, which publishes lifestyle and culture websites like Bustle, Nylon and Romper. \"You're bringing \ntogether Wikipedia-style answers to an infinite number of questions, and that's just going to nuke many corners of \nthe open web.\"       \nContent publishers have an uneven but largely reciprocal relationship with search engines. The search sites benefit \nfrom having trusted sources of information in the results, and the publishers benefit from the traffic to their sites that \nthe search engines generate.       \nSearch traffic from Google accounts for half of overall visits, or more, to many sites, said Brian Morrissey, who \nwrites The Rebooting, a media business newsletter.       \n\"Search has been the mainstay of the publishing business on the internet,\" he said.       \nKyle Sutton, director of search and product at the newspaper publisher Gannett, said the relationship had, until \nnow, been mutually beneficial.       \n\"While all search results are taking from our data and, from our perspective, crawling our content, aggregating our \ncontent, there is the return there of them driving traffic to our site,\" Mr. Sutton said. \"So I think that relationship is \nkind of first and foremost what we want to see maintained.\"       \nPublishers Worry A.I. Chatbots Will Cut Readership\nThe new offerings could change all of that, said Barbara Peng, the president of the digital news brand Insider. \nMicrosoft is incorporating the chatbot into Bing, its search engine. Google's search chatbot, Bard, is separate from \nits main search engine.       \n\"This will be revolutionary,\" Ms. Peng said, adding, \"It will take some time, and there is a good portion of hype \nmixed in there, too, but I do think it will change the relationship people have with finding and consuming \ninformation.\"       \nThe impact of \"generative\" A.I., which can generate text, images and other media from prompts, has become a top \npriority in discussions among publishers. A conference in New York in May, the World Congress of News Media, \nwill feature keynote speeches on the issue, according to a schedule on its website.       \nVice Media has created a task force in recent months to examine its own approach, said Cory Haik, the chief \noperating officer. \"It will have a huge impact on publishing in ways that we can't even get our heads around yet,\" \nshe predicted.       \nThe Washington Post announced on Tuesday that it had appointed a deputy business editor to lead an internal \ngroup looking at A.I.'s impact on The Post's journalism and digital strategy.       \nNews Corp's chief executive, Robert Thomson, who for years has led a push to get tech companies to pay for news \ncontent, said in an interview: \"If you don't get out early and define what the issues are and the obligations, then you \nwill find yourself on the defensive.\"       \nMr. Thomson said tech companies should pay to use publishers' content to produce results from A.I. chatbots. The \nchatbots generate their results by synthesizing information from the internet. He added that News Corp, which owns \nThe Wall Street Journal and The New York Post among other outlets, was in talks with \"a couple of companies\" \nabout the use of its content, though he declined to specify which ones.       \n\"There is a recognition at their end that discussions are necessary,\" he said.       \nRoger Lynch, the chief executive of Condé Nast, which owns titles like Vogue, Vanity Fair and Glamour, agreed that \ncontent creators should be compensated. He said one upside for publishers was that audiences might soon find it \nharder to know what information to trust on the web, so \"they'll have to go to trusted sources.\"       \nThe News Media Alliance, which represents 2,000 outlets around the world, including The New York Times, is \nworking on principles that it says should guide the use and development of A.I. systems, and regulation around \nthem, to protect publishers. According to a draft, the principles say the use of publisher content for the development \nof A.I. should require \"a negotiated agreement and explicit permission.\"       \nThe guidelines also call on tech companies to \"provide sufficient value\" for high-quality, trustworthy journalism \ncontent and brands, and state that any new laws or regulations that make exceptions to copyright law for A.I. must \nnot weaken protections for publishers.       \n\"Without these protections, publishers - far too many of whom already struggle to survive in the online ecosystem \ndue to marketplace imbalances - face an existential crisis that threatens our communities' access to reliable and \ntrustworthy journalism,\" the document states.       \nDanielle Coffey, executive vice president of the News Media Alliance, said a solution could be found in the \nJournalism Competition and Preservation Act, a bill that would allow publishers to collectively negotiate with tech \ncompanies over revenue sharing and, as written, would account for the use of content by generative A.I. The bill, \nwhich failed to pass last year, is expected to be reintroduced on Thursday by Senators Amy Klobuchar, Democrat \nof Minnesota, and John Kennedy, Republican of Louisiana.       \nYusuf Mehdi, Microsoft's head of Bing, said in an interview that directing users to click through to publishers was \"a \ntop goal.\" And although the new Bing has been around for less than two months, the data was \"already showing \nthat we are driving, in fact, more traffic to publishers,\" he said.       \nPublishers Worry A.I. Chatbots Will Cut Readership\n\"Part of the reason that traffic is up is that we don't just do a good job of answering the question, but we provide \nlinks,\" he said, pointing to footnotes in the answers on Bing's chatbot that show the information's source.       \nMr. Mehdi said Microsoft was at the beginning of its conversations with publishers around the new search. \"It is our \nintention that we would like to share incremental revenue that happens in that chat experience,\" he said.       \nMicrosoft is considering showing more articles from a certain publisher below the footnote or selling ads against the \nlinks in the chat answer and splitting the proceeds, Mr. Mehdi said.       \nA Google spokeswoman said in a statement that the company was \"deeply committed to supporting a healthy and \nvibrant news ecosystem\" and would put a priority on sending traffic.       \n\"This is the very early days of testing an experience in Bard, and we'll be welcoming conversations with publishers \nto get their input,\" she said.       \nFor the past two years, BDG has focused on products like live events, email newsletters and premium branded \ncontent to limit exposure to the whims of search traffic, Mr. Goldberg said.       \n\"I think the best publishers had already anticipated this was coming years ago and are many years into our \ntransformation,\" he said. \nLoad-Date: March 31, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "The Digest",
        "media": "The New York Times",
        "time": "November 18, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "476 words",
        "byline": "By Reuters",
        "story_text": "The Digest\nThe New York Times\nNovember 18, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 476 words\nByline: By Reuters\nBody\nTECHNOLOGY\nAmazon Is Cutting JobsTied to Alexa Products \n  Amazon is trimming jobs at its Alexa voice assistant unit, the company announced on Friday.\n  The cuts affect several hundred employees working on Alexa, according to a company email, but a spokeswoman \ndeclined to provide a specific number.\n  ''We're shifting some of our efforts to better align with our business priorities, and what we know matters most to \ncustomers -- which includes maximizing our resources and efforts focused on generative A.I.,'' Daniel Rausch, vice \npresident of Alexa and Fire TV, said in the email. ''These shifts are leading us to discontinue some initiatives.''\n  While most of the jobs affected were in the devices division, a few involved Alexa-related products in a different \nunit, a spokeswoman said.\n  Amazon has said its devices and services business is not profitable, and it has struggled to generate any profits \nfrom Alexa.\n  REUTERS\n  MEDICINE\n  $2.5 Billion Eli Lilly PlantIs Planned for Germany\n  Eli Lilly, the U.S. drugmaker, will build its first plant in Germany in a western town, Alzey, for $2.5 billion, the \ncompany said on Friday, as the sector scrambles to meet soaring demand for new diabetes and obesity therapies.\n  The investment will help expand production of diabetes and obesity drugs, including Mounjaro and Trulicity, and \nthe injection pens to administer them, said Eli Lilly, based in Indianapolis.\n  ''Germany's work force will play a vital role in bolstering Lilly's incretin supply when the new site is operational \nbeginning in 2027,'' Lilly said in a statement. Incretins are peptide-based drugs such as Mounjaro that mimic gut \nhormones to suppress appetite and stimulate insulin secretion.\n  The diabetes drug Mounjaro, which has been used off-label for weight loss, has been cleared for that use in the \nUnited States and can now be promoted by Lilly as an obesity treatment. REUTERS\nThe Digest\n  AUTOMOBILES\n  Fisker Targets BottlenecksIn Delivering E.V.s\n  Fisker said on Friday that its new distribution strategy for its electric vehicles would help improve delivery speed \nand volume, which the company noted was a bottleneck that curbed production.\n  This week, Fisker cut its production target for the year to 13,000 to 17,000 vehicles, from 20,000 to 23,000, to \navoid the accumulation of inventory and better manage working capital.\n  Fisker delivered 107 vehicles on Thursday, crossing the 100 mark for the first time after executing a new strategy \nthat brought in revenue of $7.5 million in one day.\n  Fisker said it had added several logistics partners to transport Ocean sport utility vehicles to delivery locations so \nthey could be handed over to customers quickly.\n  An employee can drive an ordered car to a customer if that person lives within 60 miles of a Fisker fulfillment \nlocation, eliminating the use of vehicle transport, the company said.\n  REUTERS\nhttps://www.nytimes.com/2023/11/16/business/18bizdigest.html\nGraphic\n \nPHOTO (PHOTOGRAPH BY MIKE SEGAR/REUTERS) This article appeared in print on page B2.               \nLoad-Date: November 18, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Dec2023",
        "header": "After a Dry Spell, IT Sights Green Shoots with Higher Budget for ’24",
        "media": "Economic Times (E-Paper Edition)",
        "time": "December 13, 2023",
        "section": "STARTUPS & TECH",
        "length": "481 words",
        "byline": "Romita Majumdar",
        "story_text": "After a Dry Spell, IT Sights Green Shoots with Higher Budget for ’24\nEconomic Times (E-Paper Edition)\nDecember 14, 2023 Thursday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 481 words\nByline: Romita Majumdar\nHighlight: Tech spend may rise 9% next year vs 2% in 2023; resumption of paused projects seen\nBody\nMumbai:Green shoots have started showing for the IT services companies after a catastrophic year when tech \ndemand nosedived amid geopolitical and macroeconomic concerns, and analysts expect a revival in IT spending in \n2024. IT budgets for calendar 2024 are expected to go up by 9% compared to amere 2% growth in 2023 budgets, \nresearch and analysis firm HFS Research told ET. Analysts from firms including Macquarie Group and S&P Global \nsaid the environment has improved slightly and the commentary around renewals is not just about large multi-year \ndeals, but also about programs that were paused earlier. If the spending resumes in CY24, it will significantly \nbenefit Indian IT companies, many of whom  reduced growth forecasts and some even guided for a revenue \ndegrowth in the current fiscal. \nAtop official at an IT firm said some of the paused projects have started moving and that the company expects \nNorth America to recover in the latter half of 2024. “In North America, we have reason to be more optimistic,” the \nexecutive told ET. “Unemployment continues to be low. Inflation is coming down, banks are making money and \nsentiments are improving…” However, the industry remains cautious as uncertainty persists in  the market. “In \nsome verticals, the pace of growth and paused projects have started resuming but that has not happened across \nthe board,” the person said, indicating that North America may recover sooner than Europe and that growth may \nstill be muted for the next two quarters. Aspate of conflicts and humanitarian crises, a banking debacle, plummeting \nconsumer confidence levels in the largest IT services market, and the fastest pace of rate increases by central \nbanks in Europe and the US have combined to crush demand in 2023. During the year, companies  like Accenture, \nInfosys, Wipro, and HCLTech slashed revenue growth guidance since companies hit a pause on spending on \ntechnology projects given the uncertainty around an impending recession. Phil Fersht, chief executive of HFS \nResearch, said the firm’s latest Pulse study of 600 major enterprises indicates a rebound growth increase of 9% for \ntech spend in CY 24, after slumping to barely more than 2% growth in 2023. “However, only some of the major IT \nservices firms will benefit as enterprise clients are looking to invest new money in technology solutions, not merely \nthe same old labour-driven support services,” he cautioned.  The two major drivers of growth are machine learning \nand generative AI. “After these areas, we are seeing strong demand in 5G, data platforms, and process \nautomation,” Fersht said. “If some service providers can embed these technologies into current major renewals, \nthey should see some healthy growth.” Ravi Menon, research analyst at Macquarie Capital, said IT services \nbudgets are likely to increase 2-4% in 2024 compared to 2022 budgets. romita.majumdar@timesgroup.com\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "Newsletter_Apr2024",
        "header": "The Politics of a Steel Deal Hangs Over Biden’s Japan Summit; DealBook",
        "media": "Newsletter",
        "time": "April 10, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1921 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "The Politics of a Steel Deal Hangs Over Biden’s Japan Summit; DealBook \nNewsletter\nThe New York Times \nApril 10, 2024 Wednesday 11:06 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1921 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The president’s effort to court voters in crucial swing states is influencing economic and trade policy, and \nworrying longstanding allies.\nBody\nThe president’s effort to court voters in crucial swing states is influencing economic and trade policy, and worrying \nlongstanding allies.\nDeal making runs into presidential politics \nPresident Biden holds talks on Wednesday for Fumio Kishida, Japan’s prime minister, part of a state visit designed \nto show the U.S.’s commitment to a staunch ally. Despite the pomp and ceremony, the presidential election will \nloom over the meetings, with Biden’s opposition to Nippon Steel’s bid for U.S. Steel showing how the chase for \nvotes is affecting deal making and economic policy.\nBiden views relations with Japan as crucial. The summit will be just the fifth state visit of his administration, and \nreflects a different approach to that of his predecessor, Donald Trump. Both have been tough on China, but Biden \nhas built alliances to hammer home the point. The president has cultivated relationships with Japan and South \nKorea (neighbors and big trading partners with China) and India (a regional rival), as well as Europe.\nBiden is balancing that with swing-state politics. The president has campaigned in Philadelphia more than any other \nplace during his presidency. It’s not quite U.S. Steel country, and some Democrats are urging him to visit other \nparts of the state where Nippon Steel’s $14 billion bid for the Pittsburgh-based company is deeply unpopular.\nThe president needs to win over blue-collar voters to win Pennsylvania. Both Biden and Trump have courted union \nworkers, notably during the auto industry strike last year. Biden is the first sitting president to visit a picket line.\nThe Politics of a Steel Deal Hangs Over Biden’s Japan Summit DealBook Newsletter\nTrade policy is key to such efforts. Trump ran in 2016 on an “America first” message. Slapping trade barriers on \nChina was a key part of his argument that he would boost manufacturing at home. Trump has promised more wide-\nranging tariffs if re-elected.\nBiden has continued many of the same policies and is trying to avoid being outflanked by Trump.\nThe steel deal has run into that political reality. Nippon Steel thought its offer for U.S. Steel would be \nstraightforward, but the United Steelworkers union pushed back. Biden came out against the deal, citing national \nsecurity concerns. “I told our steel workers I have their backs, and I meant it,” he said. The union has endorsed \nBiden.\nJapanese officials are said to be surprised by Biden’s opposition. “For the United States to say that a Japanese \ncompany investing in an American manufacturing firm constitutes a threat to American national security is strange \nand troubling,” Michael R. Strain, an economist at the conservative American Enterprise Institute, told The Times.\nBut Japan sees a bigger potential threat in American politics. The country’s business and political elite is even more \nworried that Trump could return to the White House. “Hope for the best, but prepare for the worst,” is how one top \nbusinessman explained it to Politico.\n• In other election news: Ron Klain, Biden’s former chief of staff, reportedly criticized the president’s electoral \nstrategy, saying he was spending too much energy on long-term infrastructure projects rather than \nimmediate economic needs. “I think the president is out there too much talking about bridges,” he said, \naccording to Politico, rather than focusing on the cost of household goods that matter more to voters.\nHERE’S WHAT’S HAPPENING \nBoeing’s shares fall on new whistle-blower allegations. The F.A.A. is investigating a Boeing engineer’s claims that \nthe plane maker cut corners to assemble the fuselage of the 787 Dreamliner, an accusation the company rejected. \nMeanwhile, problems swirling around Boeing’s 737 Max 9 planes have hit its business hard. Boeing delivered 83 \nnew planes last quarter, its lowest number since 2021.\nFitch downgrades China’s sovereign debt outlook over growth concerns. The ratings agency cited a slowing \neconomy and the risk of a crunch on public finances for the change. The decision follows a similar move by \nMoody’s in December and comes as China has struggled to reboot its economy following the pandemic. \nArizona reinstates a 160-year-old abortion ban. The state’s Republican-controlled Supreme Court on Tuesday \nvoted to ban nearly all abortions in Arizona, a decision that appears destined to become a major campaign issue in \nthe swing state. Sensing that the move could hurt their chances at the polls in November, various Republican \npoliticians have called on the state’s Legislature to repeal it. \nA.I.’s power problems \nBig Tech has invested billions and dedicated vast computing resources to turbocharge the artificial intelligence \nboom, which doesn’t appear to be ending any time soon. But a growing chorus of executives see a wild card that \ncould hold back growth: energy constraints.\nArm is the latest to sound the alarm. Rene Haas, C.E.O. of the SoftBank-backed chip designer, warned that A.I. \ncould overwhelm power grids as it becomes more widely used by businesses and consumers. “By the end of the \ndecade, A.I. data centers could consume as much as 20 percent to 25 percent of U.S. power requirements. Today \nthat’s probably 4 percent or less,” he told The Wall Street Journal. “That’s hardly very sustainable.”\nHaas hopes that a new $110 million research pact involving leading universities in the U.S. and Japan, and backed \nby Arm, Nvidia and Amazon, will help.\nA.I. is an electricity hog. That’s especially true of generative artificial intelligence, which powers chatbots such as \nOpenAI’s ChatGPT and Google’s Gemini. The International Energy Agency has noted that a ChatGPT query \nThe Politics of a Steel Deal Hangs Over Biden’s Japan Summit DealBook Newsletter\nrequires 10 times the amount of energy of a Google search. Global A.I. energy demand at data centers is expected \nto more than double to 1,000 terawatt-hours annually by 2026 — “roughly equivalent to the electricity consumption \nof Japan,” the I.E.A. said.\nThe current power grid won’t cut it. Sam Altman, the C.E.O. of OpenAI, argues that a breakthrough in nuclear \npower — he’s invested $375 million in the fusion start-up Helion Energy — or cheaper solar storage is needed to \nmeet the sector’s voracious energy requirements. Microsoft is also betting on nuclear to power its needs.\nA new chip design could also ease the load. Intel on Tuesday unveiled Gaudi 3, a high-end semiconductor that is \ntargeting Nvidia’s dominance in the sector. Intel said the chip is more power efficient and can be used to more \nquickly train A.I. models.\nAnd in another sign the chip war is heating up, Google is developing a similar kind of chip in-house to lessen its \nreliance on Nvidia, as well as defray rising A.I. costs.\nDude Perfect’s multimillion-dollar trick shot \nWhen five roommates at Texas A&amp;M University started making videos of basketball trick shots and posting \nthem on YouTube in 2009, they never expected it to become a multimillion-dollar enterprise.\nThe friends behind Dude Perfect have just secured a huge investment, the latest example of how content creators \nare turning the media business on its head.\nDude Perfect is branching out. The group said on Tuesday that they had raised at least $100 million from \nHighmount Capital, a private investment firm. They will use the money to expand beyond YouTube, including \nopening a retail store and a streaming platform, as well as a line of games and a theme park.\nThey’re part of a new wave of streaming entrepreneurs. Under the old model, content creators would pitch studio or \nnetwork executives to make programs for a big platform like Nickelodeon, and then build on that to find other ways \nof making money, such as merchandise or live events. Now, it’s possible to build fan engagement on a small \nbudget.\nThey’re not the only YouTubers to follow this model. Ryans World, a channel featuring 12-year-old Ryan Kanji that \nstarted with him opening toy boxes, will release a self-titled feature film that will arrive in U.S. theaters this summer.\nThere is a Taylor Swift-inspired twist: A big studio won’t distribute the movie, as Swift did when she released her \nconcert tour film last year.\nMeanwhile, MrBeast, YouTube’s biggest star, signed a deal with Amazon Prime last month to create a reality \ncompetition series; he recently started posting videos on X.\nYouTubers know their audience in a way that old media didn’t. “YouTube is the place where new franchises are \nmade,” Will Harrison, managing director at the consultancy Seven Dials Media and a former chief commercial \nofficer for the Harry Potter franchise at Warner Bros., told DealBook. “They’ve done the hard part already by \nbuilding the audience and the brand.”\nWhat a surge in crypto can buy \nWith Bitcoin soaring, crypto fervor is back in the markets — and on Capitol Hill. There’s new hope that long awaited \nlegislation on stablecoins, a popular kind of cryptocurrency, will pass this year amid a surge in industry lobbying.\nOne of the bill’s biggest backers is Patrick McHenry, the North Carolina Republican who leads the House Financial \nServices Committee and who has picked up donations from various cryptocurrency firms in recent years. The \nchallenge: McHenry is set to retire at the term’s end.\nThere is bipartisan support for crypto legislation, McHenry said at the Bitcoin Policy Summit in Washington on \nTuesday. McHenry and his Democratic counterpart on the committee, Maxine Waters of California, have said they \nThe Politics of a Steel Deal Hangs Over Biden’s Japan Summit DealBook Newsletter\nare “very close” to an agreement on how to regulate stablecoins, which have become a popular way for people to \ntrade cryptocurrencies.\nAs the name suggests, such tokens are considered relatively stable because they are pegged to assets like the \nU.S. dollar. But some investors were burned by the 2022 collapse of one prominent stablecoin, Terra. And \nlawmakers, including Senator Elizabeth Warren, Democrat of Massachusetts, have warned that various \ncryptocurrencies, including stablecoins, are being used to finance terrorism and crime gangs.\nA stablecoin bill could appear in the Senate, too. Senators Kirsten Gillibrand, Democrat of New York, and Cynthia \nLummis, a Wyoming Republican who has invested in Bitcoin and was also at the summit, said they would unveil \nsimilar legislation in days or weeks.\nCrypto lobbying is on the rise. Stablecoin companies have been in talks with regulators and lawmakers since 2021. \nAround that time, the Treasury called on Congress to take up stablecoin legislation. Major issuers like Tether and \nCircle hope legislation will foster adoption and turn their tokens into common forms of payment. As such, they have \nramped up their lobbying spending into the millions.\nTHE SPEED READ \nDeals\n• The German generic drugmaker Stada is said to be talking to buyout firms about a potential $8.7 billion sale. \n(Bloomberg)\n• Automattic, the company behind WordPress.com, bought the messaging app Beeper, to develop a single way \nof sending texts across multiple platforms. (NYT)\nPolicy\n• “Treasury Softens Stock Buyback Tax Hit on Foreign Companies” (WSJ)\n• The E.U. has opened an investigation into whether China has granted market-destabilizing subsidies to \ndomestic wind turbine companies. (FT)\nBest of the rest\n• “How American Drones Failed to Turn the Tide in Ukraine” (WSJ)\n• There’s a new champ in college basketball: For the first time, more viewers watched the N.C.A.A. women’s \nfinal than the men’s match. But the men far outscored the women in TV money. (NPR, WSJ)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: The White House rolled out the red carpet for Fumio Kishida, Japan’s prime minister, but local politics are \nhitting relations between the countries. (PHOTOGRAPH BY Haiyun Jiang for The New York Times FOR THE NEW \nYORK TIMES)\nLoad-Date: April 10, 2024"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "AI video startup Gan.ai raises $5.25 million",
        "media": "The Economic Times",
        "time": "May 24, 2023",
        "section": "FUNDING",
        "length": "483 words",
        "byline": "Supriya Roy",
        "story_text": "AI video startup Gan.ai raises $5.25 million\nThe Economic Times\nMay 25, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 483 words\nByline: Supriya Roy\nBody\nGenerative artificial intelligence-based video creation platform Gan.ai on Tuesday said it has raised $5.25 million \nin a seed funding round led by Surge, which is Sequoia Capital India's rapid scale-up programme.Emergent \nVentures and other angel investors participated in the round.With Gan.ai's video personalisation software, brands \nsuch as Mumbai Indians and Swiggy record a video once, add dynamic keywords to a script, and have the platform \ngenerate millions of hyper-customised videos. The enterprise clients also create personalised landing pages with \nGan.ai to deliver videos.The platform also integrates with Shopify, Calendly, Stripe, Salesforce and Hubspot for \nbusinesses to create shopping and payment experiences. Additionally, its end-to-end solution provides businesses \nwith granular customer insights and video performance analytics.The company spent its founding year 2021 in \nbuilding its core technology capabilities and the subsequent year, when it was also part of Surge's seventh cohort, \nin commercialising its operation with clients such as Swiggy, Zomato, Mobile Premier League, Samsung, Vivo, \nBajaj Auto, among others.Gan.ai services 40 clients in total, of which some 12 are in the US. \nAbout 90% of its revenue comes from India and 10% from the US.By the end of 2023, the company expects the \nmajority of its revenues to come from the US, founder and CEO Suvrat Bhooshan told ET.The startup, with global \nheadquarters in California and India headquarters in Noida, has 36 employees--35 in India and 1 heading \nenterprising sales in the US.\"We're excited to grow our operations with the new funds, and expand our sales and \nengineering teams across US and India... We aim to increase our engineering talent from the current 15 to 25 to \nbuild a strong deep learning team,\" Bhooshan told ET.Tejnoor Grover, senior manager of product marketing and \ngrowth at Mobile Premier League, said, \"We record videos with influencers and celebrities, and now with Gan.ai, \nwhen they call out your name and tell you to take a personalised call-to-action, the results are astounding. We saw \na 5x increase in our video completion rate, 3x increase in open rates, and 1.5x increase in our click-through-\nrate.\"Gan.ai was founded in March 2021 by Bhooshan, who has a master's degree in computer science from \nStanford University. Bhooshan previously worked at Facebook AI Research (FAIR). He's also worked as a \nvolunteer of AI technologies in Aadhaar issuer and enabler Unique Identification Authority of India's operations and \nalso at Prime Venture Partners as an entrepreneur-in-residence.Gan.ai's leadership also includes Anupreet Singh \nas chief revenue officer, and Kushaagra Goyal as chief technology officer. Singh was US and Europe markets lead \nat Mettl and also a go-to-market executive at Slintel. Goyal has previously worked at Databricks, Rubrik and \nSamsung. For Reprint Rights: timescontent.com\nLoad-Date: May 24, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "CCMB Picks AWS' Cloud to Drive Genome Research Projects",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 23, 2023",
        "section": "COMPANIES",
        "length": "641 words",
        "byline": "Our Bureau",
        "story_text": "CCMB Picks AWS' Cloud to Drive Genome Research Projects\nEconomic Times (E-Paper Edition)\nSeptember 23, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 641 words\nByline: Our Bureau\nHighlight: AWS has already seen reduced time taken for genomics analysis by up to 98%: Sharma\nBody\nBengaluru:Amazon Web Services (AWS) India Private Ltd has expanded its cloud service offerings to premier \nresearch organisation Centre for Cellular and Molecular Biology (CCMB) to accelerate its genome sequencing \nresearch projects. “AWS has already seen reduced time taken for genomics analysis by up to 98% (from 550 days \nto just 9 days), accelerating research efforts on the study of genetics and human diseases,” Rahul Sharma, \nRegional Managing Director, Asia Pacific & Japan, Public Sector at AWS told ET. CCMB turned to cloud computing \nto seamlessly scale up its data storage and analysis needs replacing the use of on-premises servers that created \nchallenges for scalability and performance. It widens CCMB's scope of investigation, “enhancing our ability to \ncollaborate, and enabling us to focus on the hard research problems at hand such as studying genetic variations \nand their impact on diseases,” said Divya Tej Sowpati, genomics scientist at the CSIR CCMB. \nEnabled by cloud, healthcare organisations can access large health data sets and resources easily, and more \nrapidly to accelerate collaboration to improve the quality of patient-centric care, Sharma added. The announcement \nwas made by AWS India at the Public Sector Symposium in New Delhi on Friday. This follows a series of similar \npartnerships in India's public sector across healthcare, education, and space industries. AWS, the $80 billion cloud \ncomputing arm of US-based online retail giant Amazon, this month also signed a strategic Memorandum of \nUnderstanding with the Indian Space Research Organization (ISRO) and Indian National Space Promotion and \nAuthorization Centre (IN-SPACe) to support space-tech innovations through cloud computing. It also received cloud \nservice provider (CSP) empanelment from India's Ministry of Electronic and Information Technology (MeitY) for \ncloud services provided using the AWS Asia Pacific (Hyderabad) Region. In May this year, chief executive officer of \nAWS Adam Selipsky told ET that it will invest $12.7 billion (Rs 1.05 lakh crore) in India's cloud infrastructure, taking \nits total bet in the country to $16.4 billion by 2030 to meet the growing customer demand for cloud services in India. \nCurrently, AWS hosts two of India's largest digital public infrastructures (DPI) — document storage network \nDigiLocker and vaccination platform Cowin. AWS also has two data centre infrastructure regions in India — AWS \nAsia Pacif- ic (Mumbai) Region, launched in 2016, and the AWS Asia Pacific (Hyderabad) region, launched in No-\nvember 2022. There were among 19 AWS regions globally whose electricity consumption was attributed to 100% \nrenewable energy. “We are constantly adding new tools and features to enable AWS Partners to speed up \ncustomers' migration to AWS, and help public sector organisations keep up with the rapid pace of change,” Sharma \nsaid. Sharma believes the need for urgent digital skills training remains a key priority for industry and government \nacross India and that AWS is enabling to address the digital skills gap. “We have trained over 4 million individuals in \nIndia with cloud skills since 2017,” he said. In July 2023, the Directorate General of Training in India, announced its \ncollaboration with AWS India to upskill students in cloud computing, data annotation, AI and ML, to boost their \ncapabilities and employability. So far, AWS's public sector customers in India include Digital India Corporation \n(MeitY), Government of Telangana, MPSEDC, CCMB, ConveGenius, National Skill Development Corporation, \nPhysicsWallah, Prasar Bharati News Services, and the University of Delhi.  In India, Sharma adds, AWS aims to \nCCMB Picks AWS' Cloud to Drive Genome Research Projects\ndemocratise access to cloud-enabled technology such as artificial intelligence (AI), generative AI, and ML to help \npublic sector organisations build new solutions to solve pressing citizen challenges.\nLoad-Date: September 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Blocks Epic Games From Using iPhone Tools in Escalation of Feud",
        "media": "The New York Times",
        "time": "March 7, 2024",
        "section": "TECHNOLOGY",
        "length": "836 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple Blocks Epic Games From Using iPhone Tools in Escalation of Feud\nThe New York Times \nMarch 6, 2024 Wednesday 00:25 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 836 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: The move tests the European Union’s new tech competition law, which was designed to allow competing \napp stores.\nBody\nThe move tests the European Union’s new tech competition law, which was designed to allow competing app \nstores.\nWhen the European Union passed a 2022 law to loosen Apple’s grip on the app economy, Epic Games, the maker \nof Fortnite, began planning to launch a competing app store for developers.\nBut before that law could go into effect this week, Apple has blocked Epic’s European subsidiary from using iPhone \nsoftware tools, making it impossible for the game developer to create the Epic Games Store.\nIn correspondence from Apple to Epic Games, the tech giant said that Epic had shown in the past it was unwilling to \nfollow Apple’s rules to protect the App Store and that it couldn’t return to the Developer Program that supports it. \nApple also objected to Epic’s criticism of Apple’s plans to comply with Europe’s tech competition law.\nApple’s move is the latest salvo in a long-running battle with Epic. In 2020, Epic broke the App Store’s rules by \nencouraging customers to pay it directly for features in Fortnite. Apple threw Epic out of the App Store, and Epic \nsued Apple for violating antitrust laws by requiring developers to use its payment system.\nWith its rejection of Epic’s access to developer tools in Europe, Apple is testing the boundaries of the European \nUnion’s tech competition law. The Digital Markets Act, which takes effect Thursday, requires Apple to give app \nmakers alternatives for selling software to iPhone and iPad users, including the ability to use alternative payment \nsystems and competing app stores.\nAn Apple spokesman said in a statement that “Apple has the right to terminate” any of Epic’s games and that it had \ndone so because of Epic’s “egregious breach of its contractual obligations.”\nTim Sweeney, the chief executive of Epic, said his company had invested billions of dollars to create the Epic \nGames Store and would file a complaint to European regulators over Apple’s action.\n“We see Apple’s decision to block us from competing as a blatant effort to kneecap its leading competitor,” Mr. \nSweeney said, adding: “This isn’t just about Epic versus Apple. The D.M.A. is about ensuring consumers the benefit \nof competition, of better prices.”\nIn 2018, Epic Games launched a digital store to distribute games on PCs and other devices. The store currently \ntakes a 12 percent commission for every game it sells, which is less than the 30 percent Apple typically collects.\nApple Blocks Epic Games From Using iPhone Tools in Escalation of Feud\nEpic is the among the first app makers to complain that Apple is blocking competing app stores. But other \ndevelopers have criticized Apple’s plans to comply with the Digital Markets Act and called on E.U. regulators to \ninvestigate the tech giant.\nShould the European Commission, the European Union’s executive arm, open a formal investigation into \ncomplaints from Epic or other developers, it could set up a lengthy legal battle that might force Apple to change or \nrisk fines of up to 10 percent of its global annual revenue, which was nearly $400 billion last year.\nAn investigation would deepen the challenges confronting Apple over its App Store policies. On Monday, E.U. \nregulators fined Apple 1.8 billion euros ($1.95 billion) for thwarting competition among streaming music rivals. Last \nyear, South Korea’s telecommunications regulator said it might fine Apple $15.4 million for “unfair practices.”\nApple’s dispute with Epic’s plans to create a competing app store in Europe began last month. Epic wrote Apple \nsaying it planned to use its subsidiary in Sweden to bring the Epic Games Store and Fortnite to iPhones and iPads \nin Europe. Initially, Apple granted the subsidiary, Epic Games Sweden A.B., a developer account, but it later \nterminated the account.\nIn an email to Mr. Sweeney, which Epic Games posted on its website, Phil Schiller, who leads the App Store, \nquestioned Epic’s willingness to follow Apple’s rules. He said that Epic had deliberately broken Apple’s policies \nbefore filing its lawsuit in the United States and that Mr. Sweeney had called Apple’s plan to comply with Europe’s \ntech law “hot garbage” and a “horror show.”\n“Your colorful criticism of our D.M.A. compliance plan, coupled with Epic’s past practices of intentionally violating \ncontractual provisions with which it disagrees, strongly suggest that Epic Sweden does not plan to follow the rules,” \nMr. Schiller wrote.\nMr. Sweeney replied that Epic was “acting in good faith and will comply with all terms of current and future \nagreements with Apple.”\nA lawyer representing Apple later wrote Epic Games to tell it that its Sweden subsidiary’s account had been \nterminated. Mr. Sweeney said the correspondence was the totality of Epic’s exchange with Apple.\nPHOTOS: Epic Games, the maker of Fortnite, was planning to create its own app store. However, by not allowing \nEpic access to its iPhone software tools in Europe, Apple has made it impossible for the game developer to create \nthe Epic Games Store. (PHOTOGRAPHS BY FREDERIC J. BROWEN/AGENCE FRANCE-PRESSE — GETTY \nIMAGES; PHILIP PACHECO/GETTY IMAGES) This article appeared in print on page B5.\nLoad-Date: March 7, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "The A.I. Revolution Will Change Work. Nobody Agrees How.",
        "media": "The New York Times",
        "time": "June 12, 2023",
        "section": "BUSINESS",
        "length": "1273 words",
        "byline": "Sarah Kessler",
        "story_text": "The A.I. Revolution Will Change Work. Nobody Agrees How.\nThe New York Times \nJune 10, 2023 Saturday 19:46 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1273 words\nByline: Sarah Kessler\nHighlight: The tally of how many jobs will be “affected by” world-changing technology is different depending on who \nyou ask.\nBody\nThe tally of how many jobs will be “affected by” world-changing technology is different depending on who you ask.\nIn 2013, researchers at Oxford University published a startling number about the future of work: 47 percent of all \nUnited States jobs, they estimated, were “at risk” of automation “over some unspecified number of years, perhaps a \ndecade or two.”\nBut a decade later, unemployment in the country is at record low levels. The tsunami of grim headlines back then — \nlike “The Rich and Their Robots Are About to Make Half the World’s Jobs Disappear” — look wildly off the mark.\nBut the study’s authors say they didn’t actually mean to suggest doomsday was near. Instead, they were trying to \ndescribe what technology was capable of.\nIt was the first stab at what has become a long-running thought experiment, with think tanks, corporate research \ngroups and economists publishing paper after paper to pinpoint how much work is “affected by” or “exposed to” \ntechnology.\nIn other words: If cost of the tools weren’t a factor, and the only goal was to automate as much human labor as \npossible, how much work could technology take over?\nWhen the Oxford researchers, Carl Benedikt Frey and Michael A. Osborne, were conducting their study, IBM \nWatson, a question-answering system powered by artificial intelligence, had just shocked the world by winning \n“Jeopardy!” Test versions of autonomous vehicles were circling roads for the first time. Now, a new wave of studies \nfollows the rise of tools that use generative A.I.\nIn March, Goldman Sachs estimated that the technology behind popular A.I. tools such as DALL-E and ChatGPT \ncould automate the equivalent of 300 million full-time jobs. Researchers at Open AI, the maker of those tools, and \nthe University of Pennsylvania found that 80 percent of the U.S. work force could see an effect on at least 10 \npercent of their tasks.\n“There’s tremendous uncertainty,” said David Autor, a professor of economics at the Massachusetts Institute of \nTechnology, who has been studying technological change and the labor market for more than 20 years. “And \npeople want to provide those answers.”\nBut what exactly does it mean to say that, for instance, the equivalent of 300 million full-time jobs could be affected \nby A. I.?\nThe A.I. Revolution Will Change Work. Nobody Agrees How.\nIt depends, Mr. Autor said. “Affected could mean made better, made worse, disappeared, doubled.”\nOne complicating factor is that technology tends to automate tasks, not entire occupations. In 2016, for instance, \nthe artificial intelligence pioneer Geoffrey Hinton considered new “deep learning” technology capable of reading \nmedical images. He concluded that “if you work as a radiologist, you are like the coyote that’s already over the edge \nof the cliff but hasn’t yet looked down.”\nHe gave it five years, maybe ten, before algorithms would “do better” than humans. What he probably overlooked \nwas that reading the images is just one of many tasks (30 of them, according to the U.S. government) that \nradiologists do. They also do things like “confer with medical professionals” and “provide counseling.” Today, some \nin the field worry about an impending shortage of radiologists. And Mr. Hinton has since become a vocal public critic \nof the same technology he helped create.\nMr. Frey and Mr. Osborne calculated their 47 percent number in part by asking technology experts to rate how likely \nentire occupations like “telemarketer” or “accountant” were to be automated. But three years after their paper \npublished, a group of researchers at the ZEW Center for European Economic Research, based in Mannheim, \nGermany, published a similar study that assessed tasks — like “explain products or services” — and found that just \n9 percent of occupations across 21 countries could be automated.\n“People like numbers,” said Melanie Arntz, the lead author of the ZEW paper. “People always think that the number \nmust be somehow solid, you know, because it’s a number. But numbers can really be very misleading.”\nIn some scenarios, A.I. has essentially created a tool, not a full job replacement. You’re now a digger who can use \nan excavator instead of a shovel. Or a nurse practitioner with access to better information for diagnosing a patient. \nIt’s possible that you should charge more per hour, because you’re going to get a lot more done.\nIn other scenarios, the technology is replacing your labor rather complementing it. Or turning your job from one that \nrequires special skills to one that doesn’t. That is not likely to go well for you.\nIn either case, says Mr. Autor, technological developments throughout history have tended to mostly affect wages \nand wealth distribution — not how many jobs are available. “This kind of exercise risks missing the forest by \nfocusing on one very prominent tree,” he said of studies that look at how much human work could be replaced by \nA.I.\nWhat he considers to be another key focus — how artificial intelligence will change the value of skills — is difficult to \npredict, because the answer depends partly on how new tools are designed, regulated and used.\nTake customer service. Many companies have handed the task of answering phones to an automated decision \ntree, bringing in the human operator only to troubleshoot. But one Fortune 500 enterprise software company has \napproached the problem differently. It created a generative A.I. tool to provide the agents with suggestions for what \nto say — keeping humans, and their ability to read social cues, in the loop. When researchers at Stanford and \nM.I.T. compared the performance of groups who were given the tool with those who weren’t, they found the tool \nsignificantly improved the performance of lower-skilled agents.\nEven if a job becomes completely automated, how displaced workers fare will depend on how companies decide to \nuse technology in new kinds of work, especially work we can’t yet imagine, said Daron Acemoglu, a professor at \nM.I.T. and an author of “Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity.” \nThese choices will include whether to automate work entirely or use technology to augment human expertise.\nHe said that the seemingly scary numbers predicting how many jobs A.I. could eliminate, even if it’s not clear how, \nwere a “wake up call.”\nHe believes that people could “steer in a better direction,” he said, but he is not optimistic. He does not think we are \non a “pro-human” path.\nThe A.I. Revolution Will Change Work. Nobody Agrees How.\nAll estimates for how much work A.I. could take over are very dependent on humans: the researchers making the \nassumptions about what technology can do. Mr. Frey and Mr. Osborne invited experts to a workshop to score the \nlikelihood of occupations becoming automated. More recent studies rely on information such as a database tracking \nA.I. capabilities, created by the Electronic Frontier Foundation, a nonprofit digital rights group. Or they rely on \nworkers using platforms like CrowdFlower, where people complete small tasks for money. The workers score tasks \non factors that make them prone to automation. For instance, if it’s something with a high tolerance for error, it’s a \nbetter candidate for a technology like ChatGPT to automate.\nThe exact numbers are not the point, say many researchers involved in this type of analysis.\n“I would describe our methodology as almost certainly precisely wrong, but hopefully directionally correct,” said \nMichael Chui, an A.I. expert at McKinsey who co-authored a 2017 white paper suggesting that about half of work, \nand 5 percent of occupations, could be automated.\nWhat the data describes is, in some ways, more mundane than often assumed: Big changes are coming, and it’s \nworth paying attention.\nThis article appeared in print on page BU5.\nLoad-Date: June 12, 2023"
    },
    {
        "file_name": "took_its_next_leap_in_artificial_intelligence_Wednesday_with_the_launch_of_Dec2023",
        "header": "Google launches Gemini, upping the stakes in the global AI race; Google",
        "media": "took its next leap in artificial intelligence Wednesday with the launch of",
        "time": "December 6, 2023",
        "section": "NATION WORLD",
        "length": "993 words",
        "byline": "MICHAEL LIEDTKE and MATT O'BRIEN",
        "story_text": "Google launches Gemini, upping the stakes in the global AI race; Google \ntook its next leap in artificial intelligence Wednesday with the launch of \nproject Gemini, an AI model trained to behave in human-like ways that's \nlikely to intensify the debate about the technology's potential promise and \nperils\nDayton Daily News (Ohio)\nDecember 6, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 993 words\nByline: MICHAEL LIEDTKE and MATT O'BRIEN\nBody\nGoogle took its next leap in artificial intelligence Wednesday with the launch of project Gemini, an AI model trained \nto behave in human-like ways that's likely to intensify the debate about the technology's potential promise and \nperils.\nThe rollout will unfold in phases, with less sophisticated versions of Gemini called \"Nano\" and \"Pro\" being \nimmediately incorporated into Google's AI-powered chatbot Bard and its Pixel 8 Pro smartphone. \nWith Gemini providing a helping hand, Google promises Bard will become more intuitive and better at tasks that \ninvolve planning. On the Pixel 8 Pro, Gemini will be able to quickly summarize recordings made on the device and \nprovide automatic replies on messaging services, starting with WhatsApp, according to Google. \nGemini's biggest advances won't come until early next year when its Ultra model will be used to launch \"Bard \nAdvanced,\" a juiced-up version of the chatbot that initially will only be offered to a test audience. \nThe AI, at first, will only work in English throughout the world, although Google executives assured reporters during \na briefing that the technology will have no problem eventually diversifying into other languages. \nBased on a demonstration of Gemini for a group of reporters, Google's \"Bard Advanced\" might be capable of \nunprecedented AI multitasking by simultaneously recognizing and understanding presentations involving text, \nphotos and video. \nGemini will also eventually be infused into Google's dominant search engine, although the timing of that transition \nhasn't been spelled out yet. \n\"This is a significant milestone in the development of AI, and the start of a new era for us at Google,\" declared \nDemis Hassabis, CEO of Google DeepMind, the AI division behind Gemini. Google prevailed over other bidders, \nincluding Facebook parent Meta, to acquire London-based DeepMind nearly a decade ago, and since melded it \nwith its \"Brain\" division to focus on Gemini's development. \nThe technology's problem-solving skills are being touted by Google as being especially adept in math and physics, \nfueling hopes among AI optimists that it may lead to scientific breakthroughs that improve life for humans. \nGoogle launches Gemini, upping the stakes in the global AI race Google took its next leap in artificial \nintelligence Wednesday with the launch of project Gemini....\nBut an opposing side of the AI debate worries about the technology eventually eclipsing human intelligence, \nresulting in the loss of millions of jobs and perhaps even more destructive behavior, such as amplifying \nmisinformation or triggering the deployment of nuclear weapons. \n\"We're approaching this work boldly and responsibly,\" Google CEO Sundar Pichai wrote in a blog post. \"That \nmeans being ambitious in our research and pursuing the capabilities that will bring enormous benefits to people and \nsociety, while building in safeguards and working collaboratively with governments and experts to address risks as \nAI becomes more capable.\" \nGemini's arrival is likely to up the ante in an AI competition that has been escalating for the past year, with San \nFrancisco startup OpenAI and long-time industry rival Microsoft. \nBacked by Microsoft's financial muscle and computing power, OpenAI was already deep into developing its most \nadvanced AI model, GPT-4, when it released the free ChatGPT tool late last year. That AI-fueled chatbot rocketed \nto global fame, bringing buzz to the commercial promise of generative AI and pressuring Google to push out Bard \nin response. \nJust as Bard was arriving on the scene, OpenAI released GPT-4 in March and has since been building in new \ncapabilities aimed at consumers and business customers, including a feature unveiled in November that enables \nthe chatbot to analyze images. It's been competing for business against other rival AI startups such as Anthropic \nand even its partner, Microsoft, which has exclusive rights to OpenAI's technology in exchange for the billions of \ndollars that it has poured into the startup. \nThe alliance so far has been a boon for Microsoft, which has seen its market value climb by more than 50% so far \nthis year, primarily because of investors' belief that AI will turn into a gold mine for the tech industry. Google's \ncorporate parent, Alphabet, also has been riding the same wave with its market value rising more than $500 billion, \nor about 45%, so far this year. Despite the anticipation surrounding Gemini in recent months, its launch barely \nbudged Alphabet's stock in Wednesday's morning trading. \nMicrosoft's deepening involvement in OpenAI during the past year, coupled with OpenAI's more aggressive \nattempts to commercialize its products, has raised concerns that the non-profit has strayed from its original mission \nto protect humanity as the technology progresses. \nThose worries were magnified last month when OpenAI's board abruptly fired CEO Sam Altman in a dispute \nrevolving around undisclosed issues of trust. After backlash that threatened to destroy the company and result in a \nmass exodus of AI engineering talent to Microsoft, OpenAI brought Altman back as CEO and reshuffled its board. \nWith Gemini coming out, OpenAI may find itself trying to prove its technology remains smarter than Google's. \n\"I am in awe of what it's capable of,\" Google DeepMind vice president of product Eli Collins said of Gemini. \nIn a virtual press conference, Google declined to share Gemini's parameter count  one but not the only measure of \na model's complexity. A white paper released Wednesday outlined the most capable version of Gemini \noutperforming GPT-4 on multiple-choice exams, grade-school math and other benchmarks, but acknowledged \nongoing struggles in getting AI models to achieve higher-level reasoning skills. \nSome computer scientists see limits in how much can be done with large language models, which work by \nrepeatedly predicting the next word in a sentence and are prone to making up errors known as hallucinations. \n\"We made a ton of progress in what's called factuality with Gemini. So Gemini is our best model in that regard. But \nit's still, I would say, an unsolved research problem,\" Collins said.\nGraphic\nGoogle launches Gemini, upping the stakes in the global AI race Google took its next leap in artificial \nintelligence Wednesday with the launch of project Gemini....\n \nFile - Alphabet CEO Sundar Pichai speaks about Google DeepMind at a Google I/O event in Mountain View, Calif., \nMay 10, 2023. Google took its next leap in artificial intelligence Wednesday with the launch of a project called \nGemini that's trained to think more like humans and behave in ways likely to intensify the debate about the \ntechnology's potential promise and perils. Google DeepMind is the AI division behind Gemini. (AP Photo/Jeff Chiu, \nFile)\nLoad-Date: December 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Mar2023",
        "header": "CHATGPT MANIA LURES ENTERPRISE STARTUPS",
        "media": "Wall Street Journal Abstracts",
        "time": "March 8, 2023",
        "section": "B; Pg. 6",
        "length": "38 words",
        "byline": "ANGUS LOTEN",
        "story_text": "CHATGPT MANIA LURES ENTERPRISE STARTUPS\nWall Street Journal Abstracts\nMarch 7, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 6\nLength: 38 words\nByline: ANGUS LOTEN\nBody\nABSTRACT\nEnterprise-software startups are pouring money into generative artificial-intelligence technology underlying \napplications like OpenAI’s ChatGPT chatbot, hoping to leverage market buzz to grab attention of investors; photo \n(M)\nGraphic\n \nPhotograph\nLoad-Date: March 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "A.I. Spurs An Industry To Detect It",
        "media": "The New York Times",
        "time": "May 20, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1236 words",
        "byline": "By Tiffany Hsu and Steven Lee Myers",
        "story_text": "A.I. Spurs An Industry To Detect It\nThe New York Times\nMay 20, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1236 words\nByline: By Tiffany Hsu and Steven Lee Myers\nBody\nMore than a dozen companies have popped up to offer services aimed at identifying whether photos, text and \nvideos are made by humans or machines.\nAndrey Doronichev was alarmed last year when he saw a video on social media that appeared to show the \npresident of Ukraine surrendering to Russia. \n  The video was quickly debunked as a synthetically generated deepfake, but to Mr. Doronichev, it was a worrying \nportent. This year, his fears crept closer to reality, as companies began competing to enhance and release artificial \nintelligence technology despite the havoc it could cause.\n  Generative A.I. is now available to anyone, and it's increasingly capable of fooling people with text, audio, images \nand videos that seem to be conceived and captured by humans. The risk of societal gullibility has set off concerns \nabout disinformation, job loss, discrimination, privacy and broad dystopia.\n  For entrepreneurs like Mr. Doronichev, it has also become a business opportunity. More than a dozen companies \nnow offer tools to identify whether something was made with artificial intelligence, with names like Sensity AI \n(deepfake detection), Fictitious.AI (plagiarism detection) and Originality.AI (also plagiarism).\n  Mr. Doronichev, a Russian native, founded a company in San Francisco, Optic, to help identify synthetic or \nspoofed material -- to be, in his words, ''an airport X-ray machine for digital content.''\n  In March, it unveiled a website where users can check images to see if they were made by actual photographs or \nartificial intelligence. It is working on other services to verify video and audio.\n  ''Content authenticity is going to become a major problem for society as a whole,'' said Mr. Doronichev, who was \nan investor for a face-swapping app called Reface. ''We're entering the age of cheap fakes.'' Since it doesn't cost \nmuch to produce fake content, he said, it can be done at scale.\n  The overall generative A.I. market is expected to exceed $109 billion by 2030, growing 35.6 percent a year on \naverage until then, according to the market research firm Grand View Research. Businesses focused on detecting \nthe technology are a growing part of the industry.\n  Months after being created by a Princeton University student, GPTZero claims that more than a million people \nhave used its program to suss out computer-generated text. Reality Defender was one of 414 companies chosen \nfrom 17,000 applications to be funded by the start-up accelerator Y Combinator this winter.\nA.I. Spurs An Industry To Detect It\n  Copyleaks raised $7.75 million last year in part to expand its anti-plagiarism services for schools and universities \nto detect artificial intelligence in students' work. Sentinel, whose founders specialized in cybersecurity and \ninformation warfare for the British Royal Navy and the North Atlantic Treaty Organization, closed a $1.5 million seed \nround in 2020 that was backed in part by one of Skype's founding engineers to help protect democracies against \ndeepfakes and other malicious synthetic media.\n  Major tech companies are also involved: Intel's FakeCatcher claims to be able to identify deepfake videos with 96 \npercent accuracy, in part by analyzing pixels for subtle signs of blood flow in human faces.\n  Within the federal government, the Defense Advanced Research Projects Agency plans to spend nearly $30 \nmillion this year to run Semantic Forensics, a program that develops algorithms to automatically detect deepfakes \nand determine whether they are malicious.\n  Even OpenAI, which turbocharged the A.I. boom when it released its ChatGPT tool late last year, is working on \ndetection services. The company, based in San Francisco, debuted a free tool in January to help distinguish \nbetween text composed by a human and text written by artificial intelligence.\n  OpenAI stressed that while the tool was an improvement on past iterations, it was still ''not fully reliable.'' The tool \ncorrectly identified 26 percent of artificially generated text but falsely flagged 9 percent of text from humans as \ncomputer generated.\n  The OpenAI tool is burdened with common flaws in detection programs: It struggles with short texts and writing \nthat is not in English. In educational settings, plagiarism-detection tools such as TurnItIn have been accused of \ninaccurately classifying essays written by students as being generated by chatbots.\n  Detection tools inherently lag behind the generative technology they are trying to detect. By the time a defense \nsystem is able to recognize the work of a new chatbot or image generator, like Google Bard or Midjourney, \ndevelopers are already coming up with a new iteration that can evade that defense. The situation has been \ndescribed as an arms race or a virus-antivirus relationship where one begets the other, over and over.\n  ''When Midjourney releases Midjourney 5, my starter gun goes off, and I start working to catch up -- and while I'm \ndoing that, they're working on Midjourney 6,'' said Hany Farid, a professor of computer science at the University of \nCalifornia, Berkeley, who specializes in digital forensics and is also involved in the A.I. detection industry. ''It's an \ninherently adversarial game where as I work on the detector, somebody is building a better mousetrap, a better \nsynthesizer.''\n  Despite the constant catch-up, many companies have seen demand for A.I. detection from schools and educators, \nsaid Joshua Tucker, a professor of politics at New York University and a co-director of its Center for Social Media \nand Politics. He questioned whether a similar market would emerge ahead of the 2024 election.\n  ''Will we see a sort of parallel wing of these companies developing to help protect political candidates so they can \nknow when they're being sort of targeted by these kinds of things,'' he said.\n  Experts said that synthetically generated video was still fairly clunky and easy to identify, but that audio cloning \nand image-crafting were both highly advanced. Separating real from fake will require digital forensics tactics such \nas reverse image searches and IP address tracking.\n  Available detection programs are being tested with examples that are ''very different than going into the wild, \nwhere images that have been making the rounds and have gotten modified and cropped and downsized and \ntranscoded and annotated and God knows what else has happened to them,'' Mr. Farid said.\n  ''That laundering of content makes this a hard task,'' he added.\n  The Content Authenticity Initiative, a consortium of 1,000 companies and organizations, is one group trying to \nmake generative technology obvious from the outset. (It's led by Adobe, with members such as The New York \nTimes and artificial intelligence players like Stability A.I.) Rather than piece together the origin of an image or a \nA.I. Spurs An Industry To Detect It\nvideo later in its life cycle, the group is trying to establish standards that will apply traceable credentials to digital \nwork upon creation.\n  Adobe said last week that its generative technology Firefly would be integrated into Google Bard, where it will \nattach ''nutrition labels'' to the content it produces, including the date an image was made and the digital tools used \nto create it.\n  Jeff Sakasegawa, the trust and safety architect at Persona, a company that helps verify consumer identity, said \nthe challenges raised by artificial intelligence had only begun.\n  ''The wave is building momentum,'' he said. ''It's heading toward the shore. I don't think it's crashed yet.''\nhttps://www.nytimes.com/2023/05/18/technology/ai-chat-gpt-detection-tools.html\nGraphic\n \nPHOTOS: Jeff Sakasegawa, top, in New York, is the trust and safety architect at Persona, which verifies consumer \nidentity. Andrey Doronichev, above, in San Francisco, where his company, Optic, identifies fake content. \n(PHOTOGRAPHS BY BRITTAINY NEWMAN FOR THE NEW YORK TIMES\n KELSEY MCCLELLAN FOR THE NEW YORK TIMES) (B5) This article appeared in print on page B1, B5.               \nLoad-Date: May 20, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE",
        "media": "Wall Street Journal Abstracts",
        "time": "April 11, 2023",
        "section": "A; Pg. 12",
        "length": "26 words",
        "byline": "JAMES MACKENZIE",
        "story_text": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE\nWall Street Journal Abstracts\nApril 8, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 12\nLength: 26 words\nByline: JAMES MACKENZIE\nBody\nABSTRACT\nJames Mackenzie letter responds to Peggy Noonan’s April 1 declarations column on dangers in generative \nartificial intelligence like OpenAI’s ChatGPT\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "‘Telco to Techco Switch Inevitable’",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 15, 2023",
        "section": "COMPANIES",
        "length": "483 words",
        "byline": "Subhrojit.Mallick@timesgroup.com",
        "story_text": "‘Telco to Techco Switch Inevitable’\nEconomic Times (E-Paper Edition)\nNovember 16, 2023 Thursday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 483 words\nByline: Subhrojit.Mallick@timesgroup.com\nHighlight: Red Hat chief technologist says the transformation will be driven by an existential crisis stemming from \nlower per-user revenue, increasing capex and evolving consumer needs\nBody\nNew Delhi: The transformation of telecommunication companies in India and around the world into full-fledged tech \ncompanies —or a telco to a techco — is inevitable and is being driven by an existential crisis stemming from lower \naverage revenue per user (ARPU), increasing capital expenditure and evolving consumer needs, said a top \nexecutive of US-based open-source solutions provider Red Hat. “It’s a universal trend…but in India, there are \nprobably a few more levels. The telco to techco transformation has to happen. \nIt’s not an if, but when. It is almost an existential crisis,” Red Hat chief technologist Azhar Sayeed told ET . He \nadded that the cost dynamics stemming from lower ARPU levels are driving the need to transform and add more \nvalue to services being offered to consumers. “The ARPU here is $6-7, something like that, while the ARPU inthe \nUS is $35. There’s no comparison—despite the volume of subscribers here—in the context of infrastructure you \nneed to line up to deliver that kind of service,” Sayeed said. Telecom operators such as Bharti Airtel and Vodafone \nIdea have been calling for tariff hikes, claiming that India is at the bottom in terms of both ARPU and cost per \ngigabyte (GB) ofdata. Sayeed said improvement in cost dynamics will not come from providing connectivity alone. \n“Unless they move up the value chain, unless they figure out howto automate an operator infrastructure, and be \nmore efficient, nimble, and flexible, they cannot survive in this cost structure. Because the delta is shrinking.” \nDespite a global slowdown in spending by tech companies, the fintech, telecom and government spending on tech \nhas increased, he said. “Overall, we are very much encouraged by the big telcos. But not only that, some of the \nlargest projects in India are actually built on Red Hat—the Aadhaar stack with 1.3 billion users. The DigiLocker and \nUPI and GST stacks also runon our platform,” he said. In fact, telecom operators routinely work with Red Hat for its \ncloud-based solutions, Sayeed said, adding that the top telecom operators in India are implementing alot of Red \nHat capabilities for their 5G deploymenttoday. “They use our cloud platform, some of them use our automation \nmonitors, but there’s still more to be done. It’s a journey, and it has started, and they are moving at a rapid pace,” \nhe said. The ongoing transformation was evident in the showcases by the telecom operators at the recently-\nconcluded India Mobile Congress. All three telcos stepped beyond their connectivity showcases to demonstrate \nfuture capabilities in home entertainment, enterprise solutionsand more. TheUS-based firm is using generative AI \nto build out its tools and also helping enterprise customers scale up faster. The company has capabilities where it \nneeds to be pointed towards a customer repository and can generate automation playbooks without the need for \nhuman programmers.\nLoad-Date: November 15, 2023\n‘Telco to Techco Switch Inevitable’"
    }
]