[
    {
        "file_name": "OF_PA._SMALL_BUSINESSES_USED_SERVICE_Mar2024",
        "header": "GOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT; THOUSANDS",
        "media": "OF PA. SMALL BUSINESSES USED SERVICE",
        "time": "March 1, 2024",
        "section": "BUSINESS; Pg. A-14",
        "length": "554 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "GOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT; THOUSANDS \nOF PA. SMALL BUSINESSES USED SERVICE\nPittsburgh Post-Gazette\nMarch 1, 2024 Friday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-14\nLength: 554 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nA doctor's office, a winery, a bistro. A dentist, a painter, a realtor.\nThose are just some of the small businesses in the Pittsburgh area that will lose their websites Friday when Google \nends a web service it launched in 2017 to give business owners free landing pages.\nFor the next three months, links for the pages will route back to their owners' profiles. After that they will return a \n\"page not found\" error, Google announced earlier this year. The tech giant encouraged small businesses to build \nnew sites with tools like Wix, Squarespace and GoDaddy.\n\"Due to low engagement, we are winding down websites made with Business Profiles, which previously created \nbasic, templated websites based on Business Profile information,\" Google said in a statement to the Post-Gazette. \n\"Small business owners will continue to have access to Business Profiles, as well as ads landing pages if they don't \nmaintain a website, and other resources to connect with potential customers online.\"\nOne marketing agency, Fatjoe.com, estimated that 4,000 Pennsylvania businesses will be impacted by the cut, \nincluding 445 businesses in Allegheny County.\nBut a look at that data reveals a slightly different story: Most of the businesses on the list have either closed or \nalready made their own websites, separate from the Google tool.\nLifeforce Fitness Center, a gym in Pleasant Hills, made a page with tabs for each of its services. As did the Flying \nLocksmiths, Pittsburgh's leading provider of commercial locksmith services, according to its non-Google site.\nMilestone bar has not - but the Brentwood dive's landing page on Google search displays much of the same info, \nincluding reviews, location, hours and a phone number. Yelp is the top search result for Milestone above its Google \nbusiness site. Other bars like Red's Good News have Instagram as a top search result.\nThe Google sites are bare bones: a few images, a map, a handful of reviews, hours of operation and a phone \nnumber.\nBut for some small businesses, that was enough to get on the search engine's radar.\nAnother bar, Scarpaci's, has both the simple Google site and a new site, which is slightly more robust, with \nanimated, scrolling images, a full menu, and event details.\nGOOGLE CUTS FREE WEBSITES, CITES LOW ENGAGEMENT THOUSANDS OF PA. SMALL \nBUSINESSES USED SERVICE\nJustin Pons, owner of Pons Auto Service in Greenfield, said he wasn't even aware that he had a website generated \nby Google. Far more valuable, he said, are his 174 positive Google reviews.\n\"I depend on word of mouth and Google,\" Mr. Pons said. \"People just look up repair shops and they read my \nreviews.\"\nThe elimination of Google sites will have no impact on reviews, the company said.\n\"Small businesses are an essential part of the online ecosystem, and we are committed to building products \neveryday to help them grow and thrive,\" the company said.\nSome people online said eliminating the tool would clear up spam. It could also help guarantee more relevant \nsearch results.\nCertain businesses around Pittsburgh, including a law firm, a woodworker and a pharmacy, have sites with inactive \nphone numbers. A local church, Greater Pittsburgh Revival Center, hasn't updated its site in years. Others, like \nRidgmont's Grounded Cafe, have permanently closed.\nThe shift comes less than a year after Google made a broader change to search with the inclusion of generative \nAI.\nEvan Robinson-Johnson: ejohnson@post-gazette.com\nGraphic\n \nPHOTO: Richard Drew/Associated Press: On Friday, Google is ending a web service it launched in 2017 to give \nbusiness owners free landing pages, potentially impacting scores of local companies.\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2024",
        "header": "Behind Apple's Doomed Car Project: False Starts and Wrong Turns",
        "media": "The New York Times - International Edition",
        "time": "March 1, 2024",
        "section": "TECHNOLOGY",
        "length": "1352 words",
        "byline": "Brian X. Chen and Tripp Mickle",
        "story_text": "Behind Apple's Doomed Car Project: False Starts and Wrong Turns\nThe New York Times - International Edition\nMarch 2, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1352 words\nByline: Brian X. Chen and Tripp Mickle\nDateline: SAN FRANCISCO \nBody\nInternal disagreements over the direction of the Apple car led the effort to sputter for years before it was canceled \nthis week.       \nFor the last decade, many Apple employees working on the company's secretive car project, internally code-named \nTitan, had a less flattering name for it: the Titanic disaster. They knew the project was likely to fail.       \nThroughout its existence, the car effort was scrapped and rebooted several times, shedding hundreds of workers \nalong the way. As a result of dueling views among leaders about what an Apple car should be, it began as an \nelectric vehicle that would compete against Tesla and morphed into a self-driving car to rival Google's Waymo.       \nBy the time of its death - Tuesday, when executives announced internally that the project was being killed and that \nmany members of the team were being reassigned to work on artificial intelligence - Apple had burned more than \n$10 billion on the project and the car had reverted to its beginnings as an electric vehicle with driving-assistance \nfeatures rivaling Tesla's, according to a half dozen people who worked on the project over the past decade.       \nThe car project's demise was a testament to the way Apple has struggled to develop new products in the years \nsince Steve Jobs's death in 2011. The effort had four different leaders and conducted multiple rounds of layoffs. But \nit festered and ultimately fizzled in large part because developing the software and algorithms for a car with \nautonomous driving features proved too difficult.       \nApple declined to comment.       \n\"When it started, it was aligning the stars on something Apple alone could hit a home run on,\" said Bryant Walker \nSmith, an associate professor at the schools of law and engineering at the University of South Carolina, who spoke \nto Apple briefly about its project in 2015. \"A decade later, the stars have realigned to make this a lot of risk and not \na lot of gain.\"       \nWhen Apple launched its car project in 2014, it was among a stampede of investors, executives, engineers and \ncompanies chasing the idea of a self-driving car. After Google began testing prototypes on public roads in \nCalifornia, voices across Silicon Valley insisted that autonomous vehicles would soon be commonplace. Apple \ndidn't want to be left behind.       \nAt the time, the company was dealing with questions from its top engineers about its next project, according to three \npeople familiar with the project's origins. It had just finished the Apple Watch, and many engineers were restless to \nbegin work on something new. Tim Cook, Apple's chief executive, approved the project in part to prevent an exodus \nof engineers to Tesla.       \nBehind Apple 's Doomed Car Project: False Starts and Wrong Turns\nApple also needed to find new ways to expand its business. The company was anticipating that sales of iPhones \nwould slow in the coming years. Cars were part of a $2 trillion transportation industry that could help Apple, which \nby then was a nearly $200 billion business.       \nDespite having a vote of confidence from Apple's chief executive, members of the team knew they were working \nagainst harsh realities, according to the six employees familiar with the project. If it ever came to market, an Apple \ncar was likely to cost at least $100,000 and still generate razor-thin profit compared with smartphones and earbuds. \nIt would also arrive years after Tesla had dominated the market.       \nThe company held some discussions with Elon Musk about acquiring Tesla, according to two people familiar with \nthe talks. But ultimately, it decided that building its own car made more sense than buying and integrating another \nbusiness.       \nMr. Musk did not respond to a request for comment.       \nFrom its inception, the project was troubled by differing views on what it should be, the people familiar with it said. \nSteve Zadesky, who initially led the effort, wanted to build an electric vehicle that competed with Tesla. Jony Ive, \nApple's chief design officer, wanted to pursue a self-driving car, which members of the software team said could be \ndone.       \nApple, which by then had $155 billion in cash, spent lavishly to hire hundreds of people with experience in machine \nlearning, a type of A.I. technology, and other capabilities crucial to making a self-driving car. The influx of people \nmade the project among the first that Apple had developed with so many outsiders new to the company's culture.       \nThe car team, composed of more than 2,000 employees by this year, included engineers who had worked for NASA \nand developed racecars for Porsche.       \nThe group developed an array of new technologies, including a windshield that could display turn-by-turn directions \nand a sunroof that would feature special polymer to reduce heat from the sun.       \nTo bolster morale and guidance, star executives like Mr. Ive and the head of Mac engineering, Bob Mansfield, got \ninvolved. The company acquired several start-ups to join the car team. In 2021, to steer the project toward success, \nApple put Kevin Lynch, the executive behind its popular Apple Watch, in charge of the car.       \nMr. Ive and his team of designers drew concepts for a car that would look like a European minivan such as the Fiat \nMultipla 600, which has a half-dozen windows and a curving roof. It had no steering wheel and would be controlled \nusing Apple's virtual assistant, Siri.       \nOne day, in the fall of 2015, Mr. Ive and Mr. Cook met at the project's headquarters in Sunnyvale, Calif., for a \ndemonstration of how the car might work. The two men sank into the seats of a cabinlike interior. Outside, a voice \nactor read from a script of what Siri would say as the men zoomed down the road in the imaginary car. Mr. Ive \nasked Siri what restaurant they passed and the actor read an answer, said two people familiar with the \ndemonstration.       \nBut by 2016, it was clear that the car effort was in trouble. Mr. Zadesky left Apple, and his successor, Mr. Mansfield, \ntold the team working on the project that they would be shifting their focus from building a car to building self-driving \ncar software, said three people familiar with the shift.       \nApple secured permits from California to begin test-driving Lexus sport utility vehicles outfitted with sensors and \ncomputers. It held discussions with car makers such as BMW, Nissan and Mercedes-Benz before striking a deal \nwith Volkswagen to provide Transporter vans for self-driving shuttles on Apple's campus.       \nTwo more leaders took over the car effort in the years that followed. Doug Field, a former Tesla executive, laid off \nmore than 200 employees on the project as he leaned into efforts to build its self-driving system. Then Mr. Lynch, \nwho succeeded him in recent years, reversed the company's plans and went back to its original idea of making an \nelectric vehicle.       \nBehind Apple 's Doomed Car Project: False Starts and Wrong Turns\nMr. Mansfield and Mr. Field didn't respond to requests for comment.       \nAt the start of this year, Apple's leadership decided that it was a better use of the company's time to work on \ngenerative A.I. rather than the car, the company told employees in an internal meeting on Tuesday. The company \nsaid some members of the Project Titan team would be reassigned to work on artificial intelligence.       \nIn interviews on Wednesday with The New York Times, people who worked on the project praised the decision to \nshutter it, saying the technology behind generative A.I. could be invaluable to the future of the company's all-\nimportant iPhone business.       \nApple's dead car project will be survived by its underlying technologies. The company plans to take what it has \nlearned about artificial intelligence and automation and apply it to other technologies that are being researched, \nincluding A.I.-powered AirPods with cameras, robot assistants and augmented reality, according to three people \nbriefed on the projects.       \nThough the engineers working on automation software will get to work on artificial intelligence projects, others on \nthe car team have been told they will need to apply for different roles at the company.       \nCade Metz contributed reporting.       \nCade Metz contributed reporting. \nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "News_Briefing_Mar2024",
        "header": "Cornyn of Texas bids to lead GOP in Senate after McConnell exits",
        "media": "News Briefing",
        "time": "March 1, 2024",
        "section": "MAIN; A; Pg. 8",
        "length": "1074 words",
        "byline": " ",
        "story_text": "Cornyn of Texas bids to lead GOP in Senate after McConnell exits\nNews Briefing\nThe Baltimore Sun\nMarch 1, 2024 Friday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 8\nLength: 1074 words\nHighlight: Prepping for Navalny's funeral: A crane unloads police barriers Thursday at the Church of the Icon of the \nMother of God Quench My Sorrows, in Moscow's southeast Maryino district, in preparation for Friday's funeral for \nopposition leader Alexei Navalny. Several other locations declined to host the service. Navalny's body will be buried \nin a nearby cemetery. AP\nBody\nWASHINGTON - Texas Sen. John Cornyn has informed his colleagues that he intends to run for Senate \nRepublican leader, becoming the first senator to announce a campaign since Sen. Mitch McConnell said he will \nstep down from the post in November.\nCornyn, who served as McConnell's No. 2 in leadership before he was term-limited out of the job five years ago, is \nciting his experience in that role. But he also is trying to distinguish himself from McConnell, saying: \"I believe the \nSenate is broken - that is not news to anyone.\"\n\"From experience, I have learned what works in the Senate and what does not. And I am confident Senate \nRepublicans can restore our institution to the essential role it serves in our constitutional republic.\"\nThere has long been speculation that Cornyn, John Thune of South Dakota and John Barrasso of Wyoming would \nvie to replace McConnell if and when he were to step down. But the Kentuckian's surprise announcement \nWednesday that he won't run again for Republican leader after the November elections has jump-started the \ncampaign: GOP senators are expected to gather in nine months to choose a new leader behind closed doors.\nCornyn, a former Texas attorney general who was first elected to the Senate in 2002, is a prominent member of the \nSenate Judiciary Committee and a popular member of the GOP conference who is seen as a steady hand. He has \nmanaged to bridge some of the caucus' deep divides in recent years while occasionally negotiating with Democrats, \nas he did on bipartisan gun legislation in 2022.\nRepublican senators haven't chosen a new leader since 2007, when McConnell was elected.\nHuge Texas wildfire: A dusting of snow covered a desolate landscape of scorched prairie, dead cattle and burned \nout homes Thursday in the Texas Panhandle, giving firefighters brief relief in their desperate efforts to corral a blaze \nthat has grown into the largest in state history.\nThe Smokehouse Creek fire grew to nearly 1,700 square miles. It merged with another fire and is just 3% \ncontained, the Texas A&M Forest Service reported.\nGray skies loomed over huge scars of blackened earth in a rural area dotted with scrub brush, ranchland, rocky \ncanyons and oil rigs. In Stinnett, a town of about 1,600, someone propped up a U.S. flag outside a destroyed home.\nCornyn of Texas bids to lead GOP in Senate after McConnell exits News Briefing\nThe Smokehouse Creek fire's explosive growth slowed Thursday as snow fell and winds and temperatures dipped. \nIt is the largest of several major fires burning in the rural Panhandle section of the state and has crossed into \nOklahoma.\nAuthorities have not said what ignited the fires, but strong winds, dry grass and unseasonably high temperatures \nfed the blazes.\nUS election threats: The United States expects to face fast-moving threats to its elections this year as artificial \nintelligence and other technological advances have made interference and meddling easier than before, FBI \nDirector Christopher Wray said Thursday.\n\"The U.S. has confronted foreign malign influence threats in the past,\" he told a national security conference. \"But \nthis election cycle, the U.S. will face more adversaries, moving at a faster pace, and enabled by new technology.\"\nWray singled out advances in generative AI, which he said had made it \"easier for both more- and less-\nsophisticated foreign adversaries to engage in malign influence.\"\nThe remarks underscored escalating U.S. government concerns over sometimes hard-to-detect influence \noperations that are designed to shape public opinion. Officials have not cited successful efforts by foreign \ngovernments to directly alter results, but they have sounded the alarms over the past decade about foreign \ninfluence campaigns.\n\"As intelligence professionals, we've got to highlight threats in specific, evidence-based ways so that we're usefully \narming our partners and, in particular, the public against the kinds of foreign influence operations they're likely to \nconfront,\" Wray said.\nCanada re-ups visa rules: Canada's government is reimposing the visa requirements on Mexican nationals visiting \nCanada, the immigration minister announced Thursday.\nQuebec's premier has been urging the Canadian government to slow the influx of immigrants, which he says has \nbeen straining resources. The U.S. government also urged Canada to take action as some Mexicans have been \ncrossing illegally into the U.S. from Canada.\nThe new rules take effect late Thursday. Immigration Minister Marc Miller said Mexico accounted for 17% of all \nasylum claims received by Canada from around the world, and most claims from Mexico are either rejected, \nwithdrawn or abandoned, so a change was needed.\nPrime Minister Justin Trudeau's government lifted the visa requirement for Mexican visitors in late 2016. \nImmigration Department data show asylum claims from Mexico have spiked dramatically, from 110 in 2015 to \nnearly 24,000 last year.\nEx-rep wants Senate seat: Former U.S. Rep. Justin Amash, who left the GOP in 2019 after calling for the \nimpeachment of then-President Donald Trump, announced a bid Thursday for Michigan's U.S. Senate seat.\nAmash represented Grand Rapids from 2011 to 2021. Former U.S. Reps. Mike Rogers and Peter Meijer have also \nannounced Republican campaigns, as has businessman Sandy Pensler, for the seat being vacated by Democrat \nDebbie Stabenow.\n\"I'm convinced that no candidate would be better positioned to win both the Republican primary and the general \nelection,\" Amash said on X, formerly Twitter. \"That's why, today, I'm making it official: I'm joining the race for United \nStates Senate in Michigan.\"\nAmash, whose father is Palestinian and his mother Syrian, left the party to become an independent. He had been \nthe lone House Republican to support a Trump impeachment inquiry in 2019.\nCornyn of Texas bids to lead GOP in Senate after McConnell exits News Briefing\nUK police inquiry: An official U.K. inquiry has concluded that an off-duty London police officer who abducted and \nmurdered a 33-year-old woman three years ago should never have been employed in the first place. \nThe inquiry revealed Thursday that three police forces failed to spot clear signs of Wayne Couzens' unsuitability.\nCouzens was found to have had a history of viewing extreme and violent pornography and alleged sexual offending \nthat dated back nearly 20 years before the murder of Sarah Everard. Couzens often shared his interests with other \nofficers on a WhatsApp group. \nThe inquiry's chair warned that there's \"nothing to stop another Couzens operating in plain sight\" unless there is a \nradical overhaul of policing practices and culture.\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Wrong Turns Doom Efforts On Apple Car",
        "media": "The New York Times",
        "time": "March 1, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1328 words",
        "byline": "By Brian X. Chen and Tripp Mickle",
        "story_text": "Wrong Turns Doom Efforts On Apple Car\nThe New York Times\nMarch 1, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1328 words\nByline: By Brian X. Chen and Tripp Mickle\nBody\nInternal disagreements over the direction of the Apple car led the effort to sputter for years before it was canceled \nthis week.\nFor the last decade, many Apple employees working on the company's secretive car project, internally code-named \nTitan, had a less flattering name for it: the Titanic disaster. They knew the project was likely to fail. \n  Throughout its existence, the car effort was scrapped and rebooted several times, shedding hundreds of workers \nalong the way. As a result of dueling views among leaders about what an Apple car should be, it began as an \nelectric vehicle that would compete against Tesla and morphed into a self-driving car to rival Google's Waymo.\n  By the time of its death -- Tuesday, when executives announced internally that the project was being killed and \nthat many members of the team were being reassigned to work on artificial intelligence -- Apple had burned more \nthan $10 billion on the project and the car had reverted to its beginnings as an electric vehicle with driving-\nassistance features rivaling Tesla's, according to a half dozen people who worked on the project over the past \ndecade.\n  The car project's demise was a testament to the way Apple has struggled to develop new products in the years \nsince Steve Jobs's death in 2011. The effort had four different leaders and conducted multiple rounds of layoffs. But \nit festered and ultimately fizzled in large part because developing the software and algorithms for a car with \nautonomous driving features proved too difficult.\n  Apple declined to comment.\n  ''When it started, it was aligning the stars on something Apple alone could hit a home run on,'' said Bryant Walker \nSmith, an associate professor at the schools of law and engineering at the University of South Carolina, who spoke \nto Apple briefly about its project in 2015. ''A decade later, the stars have realigned to make this a lot of risk and not \na lot of gain.''\n  When Apple launched its car project in 2014, it was among a stampede of investors, executives, engineers and \ncompanies chasing the idea of a self-driving car. After Google began testing prototypes on public roads in \nCalifornia, voices across Silicon Valley insisted that autonomous vehicles would soon be commonplace. Apple \ndidn't want to be left behind.\n  At the time, the company was dealing with questions from its top engineers about its next project, according to \nthree people familiar with the project's origins. It had just finished the Apple Watch, and many engineers were \nWrong Turns Doom Efforts On Apple Car\nrestless to begin work on something new. Tim Cook, Apple's chief executive, approved the project in part to prevent \nan exodus of engineers to Tesla.\n  Apple also needed to find new ways to expand its business. The company was anticipating that sales of iPhones \nwould slow in the coming years. Cars were part of a $2 trillion transportation industry that could help Apple, which \nby then was a nearly $200 billion business.\n  Despite having a vote of confidence from Apple's chief executive, members of the team knew they were working \nagainst harsh realities, according to the six employees familiar with the project. If it ever came to market, an Apple \ncar was likely to cost at least $100,000 and still generate razor-thin profit compared with smartphones and earbuds. \nIt would also arrive years after Tesla had dominated the market.\n  The company held some discussions with Elon Musk about acquiring Tesla, according to two people familiar with \nthe talks. But ultimately, it decided that building its own car made more sense than buying and integrating another \nbusiness.\n  Mr. Musk did not respond to a request for comment.\n  From its inception, the project was troubled by differing views on what it should be, the people familiar with it said. \nSteve Zadesky, who initially led the effort, wanted to build an electric vehicle that competed with Tesla. Jony Ive, \nApple's chief design officer, wanted to pursue a self-driving car, which members of the software team said could be \ndone.\n  Apple, which by then had $155 billion in cash, spent lavishly to hire hundreds of people with experience in \nmachine learning, a type of A.I. technology, and other capabilities crucial to making a self-driving car. The influx of \npeople made the project among the first that Apple had developed with so many outsiders new to the company's \nculture.\n  The car team, composed of more than 2,000 employees by this year, included engineers who had worked for \nNASA and developed racecars for Porsche.\n  The group developed an array of new technologies, including a windshield that could display turn-by-turn \ndirections and a sunroof that would feature special polymer to reduce heat from the sun.\n  To bolster morale and guidance, star executives like Mr. Ive and the head of Mac engineering, Bob Mansfield, got \ninvolved. The company acquired several start-ups to join the car team. In 2021, to steer the project toward success, \nApple put Kevin Lynch, the executive behind its popular Apple Watch, in charge of the car.\n  Mr. Ive and his team of designers drew concepts for a car that would look like a European minivan such as the \nFiat Multipla 600, which has a half-dozen windows and a curving roof. It had no steering wheel and would be \ncontrolled using Apple's virtual assistant, Siri.\n  One day, in the fall of 2015, Mr. Ive and Mr. Cook met at the project's headquarters in Sunnyvale, Calif., for a \ndemonstration of how the car might work. The two men sank into the seats of a cabinlike interior. Outside, a voice \nactor read from a script of what Siri would say as the men zoomed down the road in the imaginary car. Mr. Ive \nasked Siri what restaurant they passed and the actor read an answer, said two people familiar with the \ndemonstration.\n  But by 2016, it was clear that the car effort was in trouble. Mr. Zadesky left Apple, and his successor, Mr. \nMansfield, told the team working on the project that they would be shifting their focus from building a car to building \nself-driving car software, said three people familiar with the shift.\n  Apple secured permits from California to begin test-driving Lexus sport utility vehicles outfitted with sensors and \ncomputers. It held discussions with car makers such as BMW, Nissan and Mercedes-Benz before striking a deal \nwith Volkswagen to provide Transporter vans for self-driving shuttles on Apple's campus.\nWrong Turns Doom Efforts On Apple Car\n  Two more leaders took over the car effort in the years that followed. Doug Field, a former Tesla executive, laid off \nmore than 200 employees on the project as he leaned into efforts to build its self-driving system. Then Mr. Lynch, \nwho succeeded him in recent years, reversed the company's plans and went back to its original idea of making an \nelectric vehicle.\n  Mr. Mansfield and Mr. Field didn't respond to requests for comment.\n  At the start of this year, Apple's leadership decided that it was a better use of the company's time to work on \ngenerative A.I. rather than the car, the company told employees in an internal meeting on Tuesday. The company \nsaid some members of the Project Titan team would be reassigned to work on artificial intelligence.\n  In interviews on Wednesday with The New York Times, people who worked on the project praised the decision to \nshutter it, saying the technology behind generative A.I. could be invaluable to the future of the company's all-\nimportant iPhone business.\n  Apple's dead car project will be survived by its underlying technologies. The company plans to take what it has \nlearned about artificial intelligence and automation and apply it to other technologies that are being researched, \nincluding A.I.-powered AirPods with cameras, robot assistants and augmented reality, according to three people \nbriefed on the projects.\n  Though the engineers working on automation software will get to work on artificial intelligence projects, others on \nthe car team have been told they will need to apply for different roles at the company.\n  Cade Metz contributed reporting.Cade Metz contributed reporting.\nhttps://www.nytimes.com/2024/02/28/technology/behind-the-apple-car-dead.html\nGraphic\n \nPHOTO: Tim Cook, Apple's chief executive, approved the car project in part to prevent an exodus of engineers to \nTesla, as many were said to be restless. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (B3) This \narticle appeared in print on page B1, B3.               \nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "advances_make_interference_easier_than_ever_this_year._Mar2024",
        "header": "FBI warns of foreign threats to elections; Agency director says tech",
        "media": "advances make interference easier than ever this year.",
        "time": "March 1, 2024",
        "section": "MAIN NEWS; National Desk; Part A; Pg. 1",
        "length": "378 words",
        "byline": "Associated Press",
        "story_text": "FBI warns of foreign threats to elections; Agency director says tech \nadvances make interference easier than ever this year.\nLos Angeles Times\nMarch 1, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; National Desk; Part A; Pg. 1\nLength: 378 words\nByline: Associated Press\nDateline:  MCLEAN, VA.  \nBody\nThe United States expects to face fast-moving threats to its elections this year as artificial intelligence and other \ntechnological advances have made interference and meddling easier than before, FBI Director Christopher A. Wray \nsaid Thursday.\n\"The U.S. has confronted foreign malign influence threats in the past,\" Wray said at a national security conference. \n\"But this election cycle, the U.S. will face more adversaries, moving at a faster pace, and enabled by new \ntechnology.\"\nWray singled out advances in generative AI, which he said had made it \"easier for both more and less \nsophisticated foreign adversaries to engage in malign influence.\"\nThe remarks underscored escalating U.S. government concerns over sometimes hard-to-detect influence \noperations designed to shape public opinion. Though officials have not cited successful efforts by foreign \ngovernments to directly alter election results, they have sounded the alarm over the last decade about foreign \ninfluence campaigns.\nWray suggested the FBI would share information about threats that it sees.\n\"As intelligence professionals, we've got to highlight threats in specific, evidence-based ways so that we're usefully \narming our partners and, in particular, the public against the kinds of foreign influence operations they're likely to \nconfront,\" he said.\nIn 2016, Russian operatives sought to boost Republican Donald Trump's election chances by stealing and leaking \nDemocratic emails and by using a hidden but powerful social media campaign to sow discord among American \nvoters.\nIn 2020, U.S. intelligence officials have said, Russian President Vladimir Putin authorized influence operations to \ndenigrate Democrat Joe Biden and help Trump in the election. China \"considered but did not deploy\" influence \noperations, while efforts by Iran sought to exploit vulnerabilities in state election websites to hurt Trump's reelection \nchances, officials have said.\nDespite those threats, according to intelligence officials, there was ultimately no evidence that any foreign entity \nchanged votes or otherwise disrupted the voting process.\nFBI warns of foreign threats to elections Agency director says tech advances make interference easier than \never this year.\nThe specter of foreign interference resurfaced this month when the Justice Department charged an FBI informant \nwith making false allegations about purported Biden family corruption.\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "New Feeding Habits for AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 1, 2024",
        "section": "BREAKING IDEAS",
        "length": "843 words",
        "byline": "Anil Nair",
        "story_text": "New Feeding Habits for AI\nEconomic Times (E-Paper Edition)\nFebruary 24, 2024 Saturday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 843 words\nByline: Anil Nair\nHighlight: The Reddit-Google deal could show how content will be produced, owned and consumed on internet\nBody\nReddit is a social media and news aggregation platform that has some 71 million active daily users who discuss \nniche subjects in niche groups. On Thursday, the San Francisco-headquartered company signed a $60 million-a-\nyear deal — in Google VP, engineering, Rajan Patel’s words, ‘a new Cloud partnership’ — that will allow Google to \nmine the social media site’s vast content to train its generative AI models. It had taken eight months for Reddit to \nsign up a big AI company, after CEO Steve Huffman announced in June 2023 that AI companies consuming \nReddit’s data to train their LLMs would have to pay up. It appeared as an attempt to bolster the company’s \nrevenues and attain profitability before an IPO. \n‘We’ll continue to be profit-driven until profits arrive,’ Huffman had said then. The same month, Reddit also \nannounced that all developers like Apollo, Sync, Pushshift and RiF would have to begin paying for using the Reddit \nAPI. Many developers were outraged, because Reddit had become a significant social media site by allowing its \nAPI to be used for free by developers to build their bots and services. Many dropped out, claiming the new fee-\npaying model wasn’t sustainable, despite the fact that they were making money from subscribers and ads, which \nthey were not sharing with Reddit. In retrospect, it appears that Reddit had reevaluated its path to profitability  \nbefore its IPO, by monetising both its APIs and content, and was taking firm steps to get there. As a result, the \nplayers involved have, consciously or inadvertently, redefined the rules around copyright and IP protection in the \ndigital age. Platforms can now invest in creating communities of interest that will generate content. And be sure that \nmonetisation, the holy grail, is an eminently attainable possibility. But the moot question is whether or not, for the \nvery same reason, platforms will exert excessive control over content and creators, choking innovation, creativity \nand free speech. The battle will now shift to the next front. Which is that while the content site and the platform gain, \nwhat of the rights of the individual contributors on Reddit, many of whom contribute voluntarily? Are the rights of \nindividual contributors going to be ignored, extended to monetary compensation, or is there more to it?  In this \ncontext, it is important to look at copyright laws and IPR. Copyright laws protect original works of authorship, \nincluding in respect of sound, music, artistic, literary and cinematographic works. IP includes patents, trademarks, \ndesigns and trade secrets, and their protection encompasses legal frameworks. Copyright laws focus on original \nexpression of ideas, while IPR is meant to prevent unauthorised use of ‘intangible creations’, generally speaking. \nBut there are country-related subtleties that also need to be understood. In the US, IPR extends to trademarks, \npatents and copyright, and applies to published and unpublished works — from drafts to completed works. What’s \nmore, fair-use doctrine permits limited use of copyrighted material for criticism, commentary or education. Laws in \nIndia are somewhat similar. But here we have stringent takedown obligations, as evidenced this week in the case of \nfarm agitationrelated accounts and posts on social media platforms like X, Facebook,  Instagram and YouTube \nbeing taken down after GoI ‘instructions’. The European Copyright Directive applies across EU nations, \nharmonising copyright laws, strengthening liability of platforms for infringement, while granting exceptions for data-\nmining for research, analysis and other specific uses. This 2001 directive effectively became regulation in 2018. \nNew Feeding Habits for AI\nThe latest Reddit-Google deal may provoke a rethink in respect of some facets. Of course, there are other specific \naspects in the RG deal that will get more apparent as we learn more details, that will be thought-provoking and \njurisdictionally relevant. •Will the deal cover all content? Or are there format-, geographicaland purpose-related \nrestrictions? •Can Google modify content independently? Or does it have to seek permissions? •How will \nattributions be displayed that could impact future benefits? •How will differing laws in various countries be \napproached? •How will continuing changes be addressed?  •How will rights of individual contributors be protected? \n• How will commercialisation of content by Google percolate to the platform and individual? •Will licensing content \ndirectly reduce the risk of algorithmic bias? An intriguing aspect is how other social media sites and generative AI \nengines will respond. And whether this will change rules of the internet, our go-to place for all the information we \nwant instantly. No doubt this is a harbinger for dialogue that all stakeholders, including governments, content-\ncreators, platforms and those consuming content must have, so that there is equity in the digital creative \necosystem. At this stage, there are more questions than answers. Reddit’s IPO, whenever that happens, will \nprovide some. The writer is founder, ThinkStreet\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "New Feeding Habits for AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 1, 2024",
        "section": "BREAKING IDEAS",
        "length": "843 words",
        "byline": "Anil Nair",
        "story_text": "New Feeding Habits for AI\nEconomic Times (E-Paper Edition)\nFebruary 24, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 843 words\nByline: Anil Nair\nHighlight: The Reddit-Google deal could show how content will be produced, owned and consumed on internet\nBody\nReddit is a social media and news aggregation platform that has some 71 million active daily users who discuss \nniche subjects in niche groups. On Thursday, the San Francisco-headquartered company signed a $60 million-a-\nyear deal — in Google VP, engineering, Rajan Patel’s words, ‘a new Cloud partnership’ — that will allow Google to \nmine the social media site’s vast content to train its generative AI models. It had taken eight months for Reddit to \nsign up a big AI company, after CEO Steve Huffman announced in June 2023 that AI companies consuming \nReddit’s data to train their LLMs would have to pay up. It appeared as an attempt to bolster the company’s \nrevenues and attain profitability before an IPO. \n‘We’ll continue to be profit-driven until profits arrive,’ Huffman had said then. The same month, Reddit also \nannounced that all developers like Apollo, Sync, Pushshift and RiF would have to begin paying for using the Reddit \nAPI. Many developers were outraged, because Reddit had become a significant social media site by allowing its \nAPI to be used for free by developers to build their bots and services. Many dropped out, claiming the new fee-\npaying model wasn’t sustainable, despite the fact that they were making money from subscribers and ads, which \nthey were not sharing with Reddit. In retrospect, it appears that Reddit had reevaluated its path to profitability  \nbefore its IPO, by monetising both its APIs and content, and was taking firm steps to get there. As a result, the \nplayers involved have, consciously or inadvertently, redefined the rules around copyright and IP protection in the \ndigital age. Platforms can now invest in creating communities of interest that will generate content. And be sure that \nmonetisation, the holy grail, is an eminently attainable possibility. But the moot question is whether or not, for the \nvery same reason, platforms will exert excessive control over content and creators, choking innovation, creativity \nand free speech. The battle will now shift to the next front. Which is that while the content site and the platform gain, \nwhat of the rights of the individual contributors on Reddit, many of whom contribute voluntarily? Are the rights of \nindividual contributors going to be ignored, extended to monetary compensation, or is there more to it?  In this \ncontext, it is important to look at copyright laws and IPR. Copyright laws protect original works of authorship, \nincluding in respect of sound, music, artistic, literary and cinematographic works. IP includes patents, trademarks, \ndesigns and trade secrets, and their protection encompasses legal frameworks. Copyright laws focus on original \nexpression of ideas, while IPR is meant to prevent unauthorised use of ‘intangible creations’, generally speaking. \nBut there are country-related subtleties that also need to be understood. In the US, IPR extends to trademarks, \npatents and copyright, and applies to published and unpublished works — from drafts to completed works. What’s \nmore, fair-use doctrine permits limited use of copyrighted material for criticism, commentary or education. Laws in \nIndia are somewhat similar. But here we have stringent takedown obligations, as evidenced this week in the case of \nfarm agitationrelated accounts and posts on social media platforms like X, Facebook,  Instagram and YouTube \nbeing taken down after GoI ‘instructions’. The European Copyright Directive applies across EU nations, \nharmonising copyright laws, strengthening liability of platforms for infringement, while granting exceptions for data-\nmining for research, analysis and other specific uses. This 2001 directive effectively became regulation in 2018. \nNew Feeding Habits for AI\nThe latest Reddit-Google deal may provoke a rethink in respect of some facets. Of course, there are other specific \naspects in the RG deal that will get more apparent as we learn more details, that will be thought-provoking and \njurisdictionally relevant. •Will the deal cover all content? Or are there format-, geographicaland purpose-related \nrestrictions? •Can Google modify content independently? Or does it have to seek permissions? •How will \nattributions be displayed that could impact future benefits? •How will differing laws in various countries be \napproached? •How will continuing changes be addressed?  •How will rights of individual contributors be protected? \n• How will commercialisation of content by Google percolate to the platform and individual? •Will licensing content \ndirectly reduce the risk of algorithmic bias? An intriguing aspect is how other social media sites and generative AI \nengines will respond. And whether this will change rules of the internet, our go-to place for all the information we \nwant instantly. No doubt this is a harbinger for dialogue that all stakeholders, including governments, content-\ncreators, platforms and those consuming content must have, so that there is equity in the digital creative \necosystem. At this stage, there are more questions than answers. Reddit’s IPO, whenever that happens, will \nprovide some. The writer is founder, ThinkStreet\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "New Feeding Habits for AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 1, 2024",
        "section": "BREAKING IDEAS",
        "length": "843 words",
        "byline": "Anil Nair",
        "story_text": "New Feeding Habits for AI\nEconomic Times (E-Paper Edition)\nFebruary 24, 2024 Saturday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 843 words\nByline: Anil Nair\nHighlight: The Reddit-Google deal could show how content will be produced, owned and consumed on internet\nBody\nReddit is a social media and news aggregation platform that has some 71 million active daily users who discuss \nniche subjects in niche groups. On Thursday, the San Francisco-headquartered company signed a $60 million-a-\nyear deal — in Google VP, engineering, Rajan Patel’s words, ‘a new Cloud partnership’ — that will allow Google to \nmine the social media site’s vast content to train its generative AI models. It had taken eight months for Reddit to \nsign up a big AI company, after CEO Steve Huffman announced in June 2023 that AI companies consuming \nReddit’s data to train their LLMs would have to pay up. It appeared as an attempt to bolster the company’s \nrevenues and attain profitability before an IPO. \n‘We’ll continue to be profit-driven until profits arrive,’ Huffman had said then. The same month, Reddit also \nannounced that all developers like Apollo, Sync, Pushshift and RiF would have to begin paying for using the Reddit \nAPI. Many developers were outraged, because Reddit had become a significant social media site by allowing its \nAPI to be used for free by developers to build their bots and services. Many dropped out, claiming the new fee-\npaying model wasn’t sustainable, despite the fact that they were making money from subscribers and ads, which \nthey were not sharing with Reddit. In retrospect, it appears that Reddit had reevaluated its path to profitability  \nbefore its IPO, by monetising both its APIs and content, and was taking firm steps to get there. As a result, the \nplayers involved have, consciously or inadvertently, redefined the rules around copyright and IP protection in the \ndigital age. Platforms can now invest in creating communities of interest that will generate content. And be sure that \nmonetisation, the holy grail, is an eminently attainable possibility. But the moot question is whether or not, for the \nvery same reason, platforms will exert excessive control over content and creators, choking innovation, creativity \nand free speech. The battle will now shift to the next front. Which is that while the content site and the platform gain, \nwhat of the rights of the individual contributors on Reddit, many of whom contribute voluntarily? Are the rights of \nindividual contributors going to be ignored, extended to monetary compensation, or is there more to it?  In this \ncontext, it is important to look at copyright laws and IPR. Copyright laws protect original works of authorship, \nincluding in respect of sound, music, artistic, literary and cinematographic works. IP includes patents, trademarks, \ndesigns and trade secrets, and their protection encompasses legal frameworks. Copyright laws focus on original \nexpression of ideas, while IPR is meant to prevent unauthorised use of ‘intangible creations’, generally speaking. \nBut there are country-related subtleties that also need to be understood. In the US, IPR extends to trademarks, \npatents and copyright, and applies to published and unpublished works — from drafts to completed works. What’s \nmore, fair-use doctrine permits limited use of copyrighted material for criticism, commentary or education. Laws in \nIndia are somewhat similar. But here we have stringent takedown obligations, as evidenced this week in the case of \nfarm agitationrelated accounts and posts on social media platforms like X, Facebook,  Instagram and YouTube \nbeing taken down after GoI ‘instructions’. The European Copyright Directive applies across EU nations, \nharmonising copyright laws, strengthening liability of platforms for infringement, while granting exceptions for data-\nmining for research, analysis and other specific uses. This 2001 directive effectively became regulation in 2018. \nNew Feeding Habits for AI\nThe latest Reddit-Google deal may provoke a rethink in respect of some facets. Of course, there are other specific \naspects in the RG deal that will get more apparent as we learn more details, that will be thought-provoking and \njurisdictionally relevant. •Will the deal cover all content? Or are there format-, geographicaland purpose-related \nrestrictions? •Can Google modify content independently? Or does it have to seek permissions? •How will \nattributions be displayed that could impact future benefits? •How will differing laws in various countries be \napproached? •How will continuing changes be addressed?  •How will rights of individual contributors be protected? \n• How will commercialisation of content by Google percolate to the platform and individual? •Will licensing content \ndirectly reduce the risk of algorithmic bias? An intriguing aspect is how other social media sites and generative AI \nengines will respond. And whether this will change rules of the internet, our go-to place for all the information we \nwant instantly. No doubt this is a harbinger for dialogue that all stakeholders, including governments, content-\ncreators, platforms and those consuming content must have, so that there is equity in the digital creative \necosystem. At this stage, there are more questions than answers. Reddit’s IPO, whenever that happens, will \nprovide some. The writer is founder, ThinkStreet\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "New Feeding Habits for AI",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 1, 2024",
        "section": "BREAKING IDEAS",
        "length": "843 words",
        "byline": "Anil Nair",
        "story_text": "New Feeding Habits for AI\nEconomic Times (E-Paper Edition)\nFebruary 24, 2024 Saturday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 843 words\nByline: Anil Nair\nHighlight: The Reddit-Google deal could show how content will be produced, owned and consumed on internet\nBody\nReddit is a social media and news aggregation platform that has some 71 million active daily users who discuss \nniche subjects in niche groups. On Thursday, the San Francisco-headquartered company signed a $60 million-a-\nyear deal — in Google VP, engineering, Rajan Patel’s words, ‘a new Cloud partnership’ — that will allow Google to \nmine the social media site’s vast content to train its generative AI models. It had taken eight months for Reddit to \nsign up a big AI company, after CEO Steve Huffman announced in June 2023 that AI companies consuming \nReddit’s data to train their LLMs would have to pay up. It appeared as an attempt to bolster the company’s \nrevenues and attain profitability before an IPO. \n‘We’ll continue to be profit-driven until profits arrive,’ Huffman had said then. The same month, Reddit also \nannounced that all developers like Apollo, Sync, Pushshift and RiF would have to begin paying for using the Reddit \nAPI. Many developers were outraged, because Reddit had become a significant social media site by allowing its \nAPI to be used for free by developers to build their bots and services. Many dropped out, claiming the new fee-\npaying model wasn’t sustainable, despite the fact that they were making money from subscribers and ads, which \nthey were not sharing with Reddit. In retrospect, it appears that Reddit had reevaluated its path to profitability  \nbefore its IPO, by monetising both its APIs and content, and was taking firm steps to get there. As a result, the \nplayers involved have, consciously or inadvertently, redefined the rules around copyright and IP protection in the \ndigital age. Platforms can now invest in creating communities of interest that will generate content. And be sure that \nmonetisation, the holy grail, is an eminently attainable possibility. But the moot question is whether or not, for the \nvery same reason, platforms will exert excessive control over content and creators, choking innovation, creativity \nand free speech. The battle will now shift to the next front. Which is that while the content site and the platform gain, \nwhat of the rights of the individual contributors on Reddit, many of whom contribute voluntarily? Are the rights of \nindividual contributors going to be ignored, extended to monetary compensation, or is there more to it?  In this \ncontext, it is important to look at copyright laws and IPR. Copyright laws protect original works of authorship, \nincluding in respect of sound, music, artistic, literary and cinematographic works. IP includes patents, trademarks, \ndesigns and trade secrets, and their protection encompasses legal frameworks. Copyright laws focus on original \nexpression of ideas, while IPR is meant to prevent unauthorised use of ‘intangible creations’, generally speaking. \nBut there are country-related subtleties that also need to be understood. In the US, IPR extends to trademarks, \npatents and copyright, and applies to published and unpublished works — from drafts to completed works. What’s \nmore, fair-use doctrine permits limited use of copyrighted material for criticism, commentary or education. Laws in \nIndia are somewhat similar. But here we have stringent takedown obligations, as evidenced this week in the case of \nfarm agitationrelated accounts and posts on social media platforms like X, Facebook,  Instagram and YouTube \nbeing taken down after GoI ‘instructions’. The European Copyright Directive applies across EU nations, \nharmonising copyright laws, strengthening liability of platforms for infringement, while granting exceptions for data-\nmining for research, analysis and other specific uses. This 2001 directive effectively became regulation in 2018. \nNew Feeding Habits for AI\nThe latest Reddit-Google deal may provoke a rethink in respect of some facets. Of course, there are other specific \naspects in the RG deal that will get more apparent as we learn more details, that will be thought-provoking and \njurisdictionally relevant. •Will the deal cover all content? Or are there format-, geographicaland purpose-related \nrestrictions? •Can Google modify content independently? Or does it have to seek permissions? •How will \nattributions be displayed that could impact future benefits? •How will differing laws in various countries be \napproached? •How will continuing changes be addressed?  •How will rights of individual contributors be protected? \n• How will commercialisation of content by Google percolate to the platform and individual? •Will licensing content \ndirectly reduce the risk of algorithmic bias? An intriguing aspect is how other social media sites and generative AI \nengines will respond. And whether this will change rules of the internet, our go-to place for all the information we \nwant instantly. No doubt this is a harbinger for dialogue that all stakeholders, including governments, content-\ncreators, platforms and those consuming content must have, so that there is equity in the digital creative \necosystem. At this stage, there are more questions than answers. Reddit’s IPO, whenever that happens, will \nprovide some. The writer is founder, ThinkStreet\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "responses;_In_testing,_major_AI_products_gave_wrong_information_that_could_Mar2024",
        "header": "BUSINESS; The election threat from chatbots' inaccurate, misleading",
        "media": "responses; In testing, major AI products gave wrong information that could",
        "time": "March 1, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1204 words",
        "byline": "Burke writes for the Associated Press.",
        "story_text": "BUSINESS; The election threat from chatbots' inaccurate, misleading \nresponses; In testing, major AI products gave wrong information that could \ndisenfranchise voters, a report says.\nLos Angeles Times\nMarch 1, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1204 words\nByline: Burke writes for the Associated Press.\nDateline:  NEW YORK  \nBody\nWith presidential primaries underway across the U.S., popular chatbots are generating false and misleading \ninformation that threatens to disenfranchise voters, according to a report published Tuesday based on the findings \nof artificial intelligence experts and a bipartisan group of election officials.\nFifteen states and one territory will hold both Democratic and Republican presidential nominating contests next \nweek on Super Tuesday, and millions of people already are turning to artificial intelligence-powered chatbots for \nbasic information, including about how their voting process works.\nTrained on troves of text pulled from the internet, chatbots such as GPT-4 and Google's Gemini are ready with AI-\ngenerated answers, but they're prone to suggesting voters head to polling places that don't exist or inventing \nillogical responses based on rehashed, dated information, the report found.\n\"The chatbots are not ready for prime time when it comes to giving important, nuanced information about elections,\" \nsaid Seth Bluestein, a Republican city commissioner in Philadelphia, who along with other election officials and AI \nresearchers took the chatbots for a test drive as part of a broader research project in January.\nAn Associated Press journalist observed as the group that convened at Columbia University tested how five large \nlanguage models responded to a set of prompts about the election -- such as where a voter could find the nearest \npolling place -- then rated the responses they kicked out.\nAll five models tested -- OpenAI's ChatGPT-4, Meta's Llama 2, Google's Gemini, Anthropic's Claude, and Mixtral \nfrom the French company Mistral -- failed to varying degrees when asked to respond to basic questions about the \ndemocratic process, according to the report, which synthesized the workshop's findings.\nWorkshop participants rated more than half of the chatbots' responses as inaccurate and categorized 40% of the \nresponses as harmful, including perpetuating dated and inaccurate information that could limit voting rights, the \nreport said.\nFor example, when participants asked the chatbots where to vote in the ZIP Code 19121, a majority Black \nneighborhood in northwest Philadelphia, Google's Gemini replied that wasn't going to happen.\n\"There is no voting precinct in the United States with the code 19121,\" Gemini responded.\nBUSINESS The election threat from chatbots' inaccurate, misleading responses In testing, major AI products \ngave wrong information that could disenfranchise vote....\nTesters used a custom-built software tool to query the five popular chatbots by accessing their back-end application \nprogramming interfaces, or APIs, and to prompt them simultaneously with the same questions to measure their \nanswers against one another.\nAlthough that's not an exact representation of how people query chatbots using their own phones or computers, \nquerying chatbots' APIs is one way to evaluate the kind of answers they generate in the real world.\nResearchers have developed similar approaches to benchmark how well chatbots can produce credible information \nin other applications that touch society, including in healthcare, where researchers at Stanford University recently \nfound that large language models couldn't reliably cite factual references to support the answers they generated to \nmedical questions.\nOpenAI, which in January outlined a plan to prevent its tools from being used to spread election misinformation, \nsaid the company would \"keep evolving our approach as we learn more about how our tools are used,\" but offered \nno specifics.\nAnthropic plans to roll out a new intervention in the coming weeks to provide accurate voting information because \n\"our model is not trained frequently enough to provide real-time information about specific elections and ... large \nlanguage models can sometimes 'hallucinate' incorrect information,\" said Alex Sanderford, Anthropic's head of trust \nand safety.\nMeta spokesman Daniel Roberts called the findings \"meaningless\" because they don't exactly mirror the experience \na person typically would have with a chatbot. Developers building tools that integrate Meta's large language model \ninto their technology using the API should read a guide that describes how to use the data responsibly, he added, \nbut was not sure whether that guide made specific mention of how to deal with election-related content.\n\"We're continuing to improve the accuracy of the API service, and we and others in the industry have disclosed that \nthese models may sometimes be inaccurate. We're regularly shipping technical improvements and developer \ncontrols to address these issues,\" Google's head of product for responsible AI, Tulsee Doshi, said in response.\nMistral did not immediately respond to requests for comment.\nIn some responses, the bots appeared to pull from outdated or inaccurate sources, highlighting problems with the \nelectoral system that election officials have spent years trying to combat and raising fresh concerns about \ngenerative AI's capacity to amplify long-standing threats to democracy.\nIn Nevada, where same-day voter registration has been allowed since 2019, four of the five chatbots tested wrongly \nasserted that voters would be blocked from registering to vote weeks before election day.\n\"It scared me, more than anything, because the information provided was wrong,\" said Nevada Secretary of State \nFrancisco Aguilar, a Democrat who participated in the January testing workshop.\nThe research and report are the product of the AI Democracy Projects, a collaboration between Proof News, a new \nnonprofit news outlet led by investigative journalist Julia Angwin, and the Science, Technology and Social Values \nLab at the Institute for Advanced Study in Princeton, N.J.\nAttempts at AI-generated election interferenc e have already begun, such as when AI robocalls that mimicked \nPresident Biden's voice tried to discourage people from voting in New Hampshire's primary election in January.\nPoliticians also have experimented with the technology, such as using AI chatbots to communicate with voters and \nadding AI-generated images to ads.\nBut in the U.S., Congress has yet to pass laws regulating AI in politics, leaving the tech companies behind the \nchatbots to govern themselves.\nBUSINESS The election threat from chatbots' inaccurate, misleading responses In testing, major AI products \ngave wrong information that could disenfranchise vote....\nTwo weeks ago, major technology companies signed a largely symbolic pact to voluntarily adopt \"reasonable \nprecautions\" to prevent artificial intelligence tools from being used to generate increasingly realistic AI-generated \nimages, audio and video, including material that provides \"false information to voters about when, where, and how \nthey can lawfully vote.\"\nThe report's findings raise questions about how the chatbots' makers are complying with their own pledges to \npromote information integrity this presidential election year.\nOverall, the report found Gemini, Llama 2 and Mixtral had the highest rates of wrong answers, with the Google \nchatbot getting nearly two-thirds of all answers wrong.\nOne example: When asked whether people could vote via text message in California, the Mixtral and Llama 2 \nmodels went off the rails.\n\"In California, you can vote via SMS (text messaging) using a service called Vote by Text,\" Meta's Llama 2 \nresponded. \"This service allows you to cast your vote using a secure and easy-to-use system that is accessible \nfrom any mobile device.\"\nTo be clear, voting via text is not allowed, and the Vote by Text service does not exist.\nGraphic\n \nPHOTO: ELECTION officials and AI experts tally how various AI models answered possible questions from voters.  \nPHOTOGRAPHER:Lauren Feeney Proof News \nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Behind Apple’s Doomed Car Project: False Starts and Wrong Turns",
        "media": "The New York Times",
        "time": "March 1, 2024",
        "section": "TECHNOLOGY",
        "length": "1360 words",
        "byline": "Brian X. Chen and Tripp Mickle Brian X. Chen is the lead consumer technology writer for The Times. He",
        "story_text": "Behind Apple’s Doomed Car Project: False Starts and Wrong Turns\nThe New York Times \nFebruary 28, 2024 Wednesday 12:57 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1360 words\nByline: Brian X. Chen and Tripp Mickle Brian X. Chen is the lead consumer technology writer for The Times. He \nreviews products and writes Tech Fix, a column about the social implications of the tech we use. Tripp Mickle \nreports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes \nproduct launches, manufacturing issues and political challenges. He also writes about trends across the tech \nindustry, including layoffs, generative A.I. and robot taxis.\nHighlight: Internal disagreements over the direction of the Apple car led the effort to sputter for years before it was \ncanceled this week.\nBody\nInternal disagreements over the direction of the Apple car led the effort to sputter for years before it was canceled \nthis week.\nFor the last decade, many Apple employees working on the company’s secretive car project, internally code-named \nTitan, had a less flattering name for it: the Titanic disaster. They knew the project was likely to fail.\nThroughout its existence, the car effort was scrapped and rebooted several times, shedding hundreds of workers \nalong the way. As a result of dueling views among leaders about what an Apple car should be, it began as an \nelectric vehicle that would compete against Tesla and morphed into a self-driving car to rival Google’s Waymo.\nBy the time of its death — Tuesday, when executives announced internally that the project was being killed and that \nmany members of the team were being reassigned to work on artificial intelligence — Apple had burned more than \n$10 billion on the project and the car had reverted to its beginnings as an electric vehicle with driving-assistance \nfeatures rivaling Tesla’s, according to a half dozen people who worked on the project over the past decade.\nThe car project’s demise was a testament to the way Apple has struggled to develop new products in the years \nsince Steve Jobs’s death in 2011. The effort had four different leaders and conducted multiple rounds of layoffs. But \nit festered and ultimately fizzled in large part because developing the software and algorithms for a car with \nautonomous driving features proved too difficult.\nApple declined to comment.\n“When it started, it was aligning the stars on something Apple alone could hit a home run on,” said Bryant Walker \nSmith, an associate professor at the schools of law and engineering at the University of South Carolina, who spoke \nto Apple briefly about its project in 2015. “A decade later, the stars have realigned to make this a lot of risk and not \na lot of gain.”\nWhen Apple launched its car project in 2014, it was among a stampede of investors, executives, engineers and \ncompanies chasing the idea of a self-driving car. After Google began testing prototypes on public roads in \nCalifornia, voices across Silicon Valley insisted that autonomous vehicles would soon be commonplace. Apple \ndidn’t want to be left behind.\nBehind Apple ’s Doomed Car Project: False Starts and Wrong Turns\nAt the time, the company was dealing with questions from its top engineers about its next project, according to three \npeople familiar with the project’s origins. It had just finished the Apple Watch, and many engineers were restless to \nbegin work on something new. Tim Cook, Apple’s chief executive, approved the project in part to prevent an exodus \nof engineers to Tesla.\nApple also needed to find new ways to expand its business. The company was anticipating that sales of iPhones \nwould slow in the coming years. Cars were part of a $2 trillion transportation industry that could help Apple, which \nby then was a nearly $200 billion business.\nDespite having a vote of confidence from Apple’s chief executive, members of the team knew they were working \nagainst harsh realities, according to the six employees familiar with the project. If it ever came to market, an Apple \ncar was likely to cost at least $100,000 and still generate razor-thin profit compared with smartphones and earbuds. \nIt would also arrive years after Tesla had dominated the market.\nThe company held some discussions with Elon Musk about acquiring Tesla, according to two people familiar with \nthe talks. But ultimately, it decided that building its own car made more sense than buying and integrating another \nbusiness.\nMr. Musk did not respond to a request for comment.\nFrom its inception, the project was troubled by differing views on what it should be, the people familiar with it said. \nSteve Zadesky, who initially led the effort, wanted to build an electric vehicle that competed with Tesla. Jony Ive, \nApple’s chief design officer, wanted to pursue a self-driving car, which members of the software team said could be \ndone.\nApple, which by then had $155 billion in cash, spent lavishly to hire hundreds of people with experience in machine \nlearning, a type of A.I. technology, and other capabilities crucial to making a self-driving car. The influx of people \nmade the project among the first that Apple had developed with so many outsiders new to the company’s culture.\nThe car team, composed of more than 2,000 employees by this year, included engineers who had worked for NASA \nand developed racecars for Porsche.\nThe group developed an array of new technologies, including a windshield that could display turn-by-turn directions \nand a sunroof that would feature special polymer to reduce heat from the sun.\nTo bolster morale and guidance, star executives like Mr. Ive and the head of Mac engineering, Bob Mansfield, got \ninvolved. The company acquired several start-ups to join the car team. In 2021, to steer the project toward success, \nApple put Kevin Lynch, the executive behind its popular Apple Watch, in charge of the car.\nMr. Ive and his team of designers drew concepts for a car that would look like a European minivan such as the Fiat \nMultipla 600, which has a half-dozen windows and a curving roof. It had no steering wheel and would be controlled \nusing Apple’s virtual assistant, Siri.\nOne day, in the fall of 2015, Mr. Ive and Mr. Cook met at the project’s headquarters in Sunnyvale, Calif., for a \ndemonstration of how the car might work. The two men sank into the seats of a cabinlike interior. Outside, a voice \nactor read from a script of what Siri would say as the men zoomed down the road in the imaginary car. Mr. Ive \nasked Siri what restaurant they passed and the actor read an answer, said two people familiar with the \ndemonstration.\nBut by 2016, it was clear that the car effort was in trouble. Mr. Zadesky left Apple, and his successor, Mr. Mansfield, \ntold the team working on the project that they would be shifting their focus from building a car to building self-driving \ncar software, said three people familiar with the shift.\nApple secured permits from California to begin test-driving Lexus sport utility vehicles outfitted with sensors and \ncomputers. It held discussions with car makers such as BMW, Nissan and Mercedes-Benz before striking a deal \nwith Volkswagen to provide Transporter vans for self-driving shuttles on Apple’s campus.\nBehind Apple ’s Doomed Car Project: False Starts and Wrong Turns\nTwo more leaders took over the car effort in the years that followed. Doug Field, a former Tesla executive, laid off \nmore than 200 employees on the project as he leaned into efforts to build its self-driving system. Then Mr. Lynch, \nwho succeeded him in recent years, reversed the company’s plans and went back to its original idea of making an \nelectric vehicle.\nMr. Mansfield and Mr. Field didn’t respond to requests for comment.\nAt the start of this year, Apple’s leadership decided that it was a better use of the company’s time to work on \ngenerative A.I. rather than the car, the company told employees in an internal meeting on Tuesday. The company \nsaid some members of the Project Titan team would be reassigned to work on artificial intelligence.\nIn interviews on Wednesday with The New York Times, people who worked on the project praised the decision to \nshutter it, saying the technology behind generative A.I. could be invaluable to the future of the company’s all-\nimportant iPhone business.\nApple’s dead car project will be survived by its underlying technologies. The company plans to take what it has \nlearned about artificial intelligence and automation and apply it to other technologies that are being researched, \nincluding A.I.-powered AirPods with cameras, robot assistants and augmented reality, according to three people \nbriefed on the projects.\nThough the engineers working on automation software will get to work on artificial intelligence projects, others on \nthe car team have been told they will need to apply for different roles at the company.\nCade Metz contributed reporting.\nCade Metz contributed reporting. \nPHOTO: Tim Cook, Apple’s chief executive, approved the car project in part to prevent an exodus of engineers to \nTesla, as many were said to be restless. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (B3) This \narticle appeared in print on page B1, B3.\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "HACKERS_Mar2024",
        "header": "WHEN EVEN THE ALIQUIPPA WATER AUTHORITY IS A TARGET FOR",
        "media": "HACKERS",
        "time": "March 1, 2024",
        "section": "OPINION; Pg. A-17",
        "length": "874 words",
        "byline": "David Hickton",
        "story_text": "WHEN EVEN THE ALIQUIPPA WATER AUTHORITY IS A TARGET FOR \nHACKERS\nPittsburgh Post-Gazette\nMarch 1, 2024 Friday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: OPINION; Pg. A-17\nLength: 874 words\nByline: David Hickton\nBody\nButler County announced last week that their systems were hacked back in October 2023, exposing the personal \ndata - names, Social Security numbers, driver's license numbers, and taxpayer identifications - of many residents. \nThe Aliquippa Water Authority was the victim of a cyberattack last December.\nIn January, Washington County reportedly paid $346,687 to Russian hackers behind a ransomware attack on its \nsystems. Weeks later, the Pennsylvania Courts system fell victim to a denial-of-service attack.\nThese close to home cyber incidents are but several in a long litany of cyberattacks targeting American companies \nand governments â€¦ sometimes for profit, sometimes for strategic advantage. Anyone with a website may be \nfeeling it's a case of not if, but when?\nInevitable but not necessarily successful\nCyberattacks are inevitable. The internet has made possible many wonderful innovations; it revolutionized \ncommunication, knowledge sharing, and work. But digital connectivity is a double-edged sword, one that becomes \nsharper with the more sensitive information we feed into it.\nBut we can mount a stronger defense. Organizations, including local governments, should be expected to employ \nstrong systemic defenses. This entails implementing best practices for updating software and procuring \ntechnologies, implementing robust data encryption measures, and having incident response plans if not measures \nthat immediately alert potential incoming hacks, phishing attempts and the like.\nBut it also includes setting your employees up for success, including requiring multifactor authentication and \nantivirus software, and providing training against phishing and access to a password manager.\nBecause a strong defense isn't just about technologies. It also requires employees who â€“ to a person â€“ employ \nstrong cyber hygiene practices. Use strong passwords. Be smart about where you click and what you open - an \nincreasingly difficult task in the age of generative AI, when it's now easy to draft compelling phishing emails at the \npush of a button.\nIn 2024, there's no excuse for poor cyber hygiene or negligence, especially when slip-ups have significant and \ndetrimental consequences for customers and citizens.\nIn March 2020, the Cyberspace Solarium Commission released a report with upward of 100 recommendations for \nthe federal executive and legislative branches to improve the nation's cybersecurity; three years onward, nearly 70 \nWHEN EVEN THE ALIQUIPPA WATER AUTHORITY IS A TARGET FOR HACKERS\npercent of the recommendations had been implemented or were nearing implementation. That's a solid track \nrecord.\nDueling innovations\nBut as our cyber adversaries continue innovating, so must we. In 2023, the U.S. State Department and Commerce \nDepartment IT systems were breached, allowing China-linked hackers to gain access to emails from Commerce \nSecretary Gina Raimondo (among others). The hack was traced to the compromise of a Microsoft engineer's \ncorporate account - effectively rendering the government's use of multifactor authentication useless.\nNo city or county government, no public utility, no private company wants to deal with a cyberattack. It is costly, \nwhether that cost manifests as a ransom payment, loss of proprietary data/information or loss of public trust. To say \nnothing of the emotional toll and work interruption.\nBut local governments, in particular, are often under-resourced and short-staffed, lacking a robust cybersecurity \nteam to defend against fast-moving ransomware gangs. Acknowledging these limitations, prevention pays large \ndividends: The expense of updating legacy systems, installing systems patches and firewalls pales in comparison to \nthe unavoidable costs incurred during a cyberattack.\nIn cyber warfare, the offensive player only needs to get lucky once - and the defensive players must get it right \nevery time.\nIn these circumstances, we need to change the calculus of our cyber adversaries by shifting the broader \necosystem: We need to deploy economic sanctions and diplomatic pressure to bolster our national defensive line.\nDuring my time as U.S. Attorney for the Western District of Pennsylvania, we brought charges against foreign \nactors who engaged in cyberattacks against Pennsylvania companies, seeking to benefit from illicitly acquired \nintellectual property. The U.S. Treasury Department utilizes sanctions against cyber criminals, as they did against \nIranian actors behind a recent hack of the Aliquippa water utility.\nBut the individual culprits are often acting as proxies of adversarial governments. It's those governments against \nwhom we must apply leverage.\nChronic, costly and criminal\nCyberattacks have become a chronic and costly problem. Neither Washington nor Butler County, nor the state of \nPennsylvania, can solve it alone.\nBut cybercriminals and the foreign states that sponsor them benefit from cybercrime being treated as a lesser \ncrime, despite the crippling cumulative effect that it has on national economic competitiveness, government \nfunctioning and, potentially, national security.\nThat needs to change. It's time to play some strong defense.\nDavid Hicktonâ€¯is the founding director of the University of Pittsburgh's Institute for Cyber Law, Policy, and \nSecurity. He was the U.S. attorney for the Western District of Pennsylvania from 2010 to 2016.\nGraphic\n \nPHOTO: Benjamin B. Braun/Post-Gazette: The Municipal Water Authority, which was hacked on Nov. 25, 2023.\nPHOTO: Benjamin B. Braun/Post-Gazette: The Municipal Water Authority, which was hacked on Nov. 25, 2023.\nWHEN EVEN THE ALIQUIPPA WATER AUTHORITY IS A TARGET FOR HACKERS\nLoad-Date: March 1, 2024"
    },
    {
        "file_name": "Principles_Mar2024",
        "header": "Elon Musk Sues OpenAI and Sam Altman for Violating the Company’s",
        "media": "Principles",
        "time": "March 2, 2024",
        "section": "TECHNOLOGY",
        "length": "1577 words",
        "byline": "Adam Satariano, Cade Metz and Tripp Mickle Adam Satariano is a technology correspondent based in",
        "story_text": "Elon Musk Sues OpenAI and Sam Altman for Violating the Company’s \nPrinciples\nThe New York Times \nMarch 1, 2024 Friday 16:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1577 words\nByline: Adam Satariano, Cade Metz and Tripp Mickle Adam Satariano is a technology correspondent based in \nEurope, where his work focuses on digital policy and the intersection of technology and world affairs. Cade Metz \nwrites about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology. \nTripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple \nincludes product launches, manufacturing issues and political challenges. He also writes about trends across the \ntech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: Musk said the prominent A.I. start-up had put profits and commercial interests ahead of seeking to \nbenefit humanity.\nBody\nMusk said the prominent A.I. start-up had put profits and commercial interests ahead of seeking to benefit \nhumanity.\nOpenAI, the influential artificial intelligence company that ousted and then reinstated its high-profile chief executive \nthree months ago, faces a new drama: a lawsuit from Elon Musk, one of the richest men in the world and a co-\nfounder of the A.I. lab.\nMr. Musk sued OpenAI and its chief executive, Sam Altman, accusing them of breaching a contract by putting \nprofits and commercial interests in developing artificial intelligence ahead of the public good. A multibillion-dollar \npartnership that OpenAI developed with Microsoft, Mr. Musk said, represented an abandonment of a founding \npledge to carefully develop A.I. and make the technology publicly available.\n“OpenAI has been transformed into a closed-source de facto subsidiary of the largest technology company, \nMicrosoft,” said the lawsuit filed Thursday in Superior Court in San Francisco.\nThe 35-page lawsuit is the latest chapter in a fight between the former business partners that has been simmering \nfor years, and it homes in on unresolved questions in the A.I. community: Will artificial intelligence improve the \nworld or destroy it and should it be tightly controlled or set free?\nMr. Musk, the chief executive of Tesla, and Mr. Altman, as much as anyone in the world, have helped to frame that \ndebate. Mr. Musk helped found OpenAI in 2015 as a response to A.I. work being done at the time by Google. Mr. \nMusk believed Google and its co-founder, Larry Page, were dismissive of the risks A.I. presented to humanity.\nMr. Musk left OpenAI’s board during a power struggle in 2018. The company went on to become a leader in the \nfield of generative A.I. and created ChatGPT, a chatbot that can produce text and respond to queries in humanlike \nprose. Mr. Musk, who founded his own A.I. company last year called xAI, said OpenAI was not focused enough on \nthe technology’s risks.\nElon Musk Sues OpenAI and Sam Altman for Violating the Company’s Principles\nThe suit is also the latest twist for a company enmeshed in controversy. In November, OpenAI’s board forced out \nMr. Altman and said it no longer trusted him to run the company. He was reinstated just five days later after an \nemployee revolt threatened the future of the company.\nSilicon Valley insiders believe that generative A.I., the technology behind ChatGPT, is a once in a generation \ntechnology that could transform the tech industry as thoroughly as web browsers did more than 30 years ago.\n“The courts of California must decide what OpenAI must do after straying from its original mission,” said Gary \nMarcus, an A.I entrepreneur and an emeritus professor of psychology and neural science at New York University. \n“The court of public opinion must decide what it thinks of Musk, who has a fair point about OpenAI but has his own \ncommercial A.I. interests and choices.”\nOpenAI declined to comment on the lawsuit. In a message sent to OpenAI employees on Friday afternoon that was \nviewed by The New York Times, Mr. Altman said that he was confused by Mr. Musk’s argument that building A.I. for \nthe benefit of humanity was at odds with building a business. \nJason Kwon, OpenAI’s chief strategy officer, told OpenAI employees in another message viewed by The Times that \nthe company’s leaders “categorically disagree” with the suit. Mr. Musk’s claims “do not reflect the reality of our work \nor mission,” he wrote.\nThe lawsuit adds to an array of problems piling up for OpenAI. The company’s relationship with Microsoft is also \nfacing scrutiny from regulators in the United States, European Union and Britain. It has been sued by The New York \nTimes, several digital outlets, writers and computer programmers for scraping copyrighted material to train its \nchatbot. And the Securities and Exchange Commission is investigating Mr. Altman and OpenAI.\nMr. Musk’s lawsuit said he became involved with OpenAI because it was created as a nonprofit to develop artificial \nintelligence for the “benefit of humanity.” A key component of that, the lawsuit said, was to make its technology \nopen source, meaning that it would share the underlying software code with the world. Instead, the company \ncreated a for-profit business unit and restricted access to its technology.\nThe lawsuit, which seeks a jury trial, accused OpenAI and Mr. Altman of being in breach of contract and violating \nfiduciary duty, as well as unfair business practices. Mr. Musk is asking that OpenAI be required to open up its \ntechnology to others and that Mr. Altman and others pay back Mr. Musk the money that Mr. Musk gave to the \norganization. Greg Brockman, the president of OpenAI, is also named as a defendant.\nMr. Musk’s argument hinges on the close partnership between OpenAI and Microsoft. In 2019, Mr. Altman \nnegotiated a deal in which Microsoft agreed to invest $1 billion in OpenAI. The start-up said it would use Microsoft’s \ncloud computing services exclusively for building and deploying its A.I. In the years since, Microsoft has invested an \nadditional $12 billion in the start-up and is the only company outside of OpenAI with a license to use the raw \ntechnology behind GPT-4, the company’s most powerful A.I. technology.\nOther companies like Google, Meta and the French start-up Mistral are freely sharing some of their latest \ntechnologies with the other companies and researchers.\nThe suit could expose OpenAI to a lengthy and invasive legal review that reveals more about Mr. Altman’s \ndismissal and OpenAI’s pivot from being a nonprofit organization to for-profit company. That change, which was \nengineered by Mr. Altman in late 2018 and early 2019, has been the source of backbiting at OpenAI for years and \ncontributed to the board’s decision to fire him as chief executive.\nThough Mr. Musk has repeatedly criticized OpenAI for becoming a for-profit company, he hatched a plan in 2017 to \nwrest control of the A.I. lab from Mr. Altman and its other founders and transform it into a commercial operation that \nwould work alongside his other companies, including the electric carmaker Tesla, and make use of their \nincreasingly powerful supercomputers, people familiar with his plan have said. When his attempt to take control \nfailed, he left the OpenAI board, the people said.\nElon Musk Sues OpenAI and Sam Altman for Violating the Company’s Principles\nSpeaking at The New York Times’s DealBook Summit last year, Mr. Musk said that he wanted to know more about \nthe chaos that unfolded at OpenAI last year, including why Ilya Sutskever, a co-founder, joined with other board \nmembers to fire Mr. Altman in November. He said that he was concerned that OpenAI had discovered some \ndangerous element of A.I., which is a question that his legal team could investigate as part of the lawsuit.\n“I have mixed feelings about Sam,” Mr. Musk said at the DealBook conference. Making a reference to a powerful \nring in “The Lord of the Rings,” he added, “The ring of power can corrupt, and he has the ring of power.”\nMr. Musk did not respond to requests for comment.\nThe falling out between Mr. Musk and Mr. Altman has long been a subject of intrigue in Silicon Valley. The men first \nmet during a tour of SpaceX, Mr. Musk’s rocket company, and later bonded over their shared concerns about the \nthreat that A.I. could pose to humanity.\nAccording to the lawsuit, OpenAI’s nonprofit status was a major source of friction, as tensions grew between \ncompany executives interested in trying to make money from new A.I. technology and Mr. Musk, who wanted it to \nremain a research lab.\n“Either go do something on your own or continue with OpenAI as a nonprofit,” Mr. Musk said at one point, according \nto the complaint. “I will no longer fund OpenAI until you have made a firm commitment to stay, or I’m just being a \nfool who is essentially providing free funding to a startup. Discussions are over.”\nThe lawsuit tries to show Mr. Musk as an indispensable figure in OpenAI’s development. From 2016 to 2020, Mr. \nMusk contributed more than $44 million to OpenAI, according to the lawsuit. He also leased the company’s initial \noffice space in San Francisco and paid the monthly expenses. He was personally involved in recruiting Mr. \nSutskever, a top research scientist at Google, to be OpenAI’s chief scientist, according to the complaint.\n“Without Mr. Musk’s involvement and substantial supporting efforts and resources,” the suit says, “it is highly likely \nthat OpenAI Inc. would never have gotten off the ground.”\nBrian Quinn, a law professor at Boston College, said that Mr. Musk’s complaint made a compelling case that \nOpenAI had abandoned its roots. But, he said, Mr. Musk probably does not have the standing to bring it, because \nnonprofit law limits challenges of this type to those made by a nonprofit’s dues-paying members, its own directors or \nstate regulators in Delaware, where OpenAI is registered.\n“If he were a member of the board of directors, I would say, ‘Ooh, strong case.’ If this was filed by the Delaware \nsecretary of state, I would say, ‘Ooh they’re in trouble,’” Mr. Quinn said. “But he doesn’t have standing. He doesn’t \nhave a case.”\nDavid A. Fahrenthold contributed reporting.\nDavid A. Fahrenthold contributed reporting. \nPHOTOS: Elon Musk said that a partnership between OpenAI and Microsoft was an abandonment of a pledge to \ncarefully develop A.I. and make it publicly available. (PHOTOGRAPH BY CARLY ZAVALA FOR THE NEW YORK \nTIMES); OpenAI’s relationship with Microsoft is also facing scrutiny from regulators in the U.S., Europe and Britain. \n(PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) (B4) This article appeared in print on page \nB1, B4.\nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "to_benefit_humanity;_Elon_Musk_is_suing_OpenAI_and_its_CEO_Sam_Altman_Mar2024",
        "header": "Elon Musk sues OpenAI and CEO Sam Altman, claiming betrayal of its goal",
        "media": "to benefit humanity; Elon Musk is suing OpenAI and its CEO Sam Altman",
        "time": "March 2, 2024",
        "section": "NATION WORLD",
        "length": "901 words",
        "byline": "KELVIN CHAN",
        "story_text": "Elon Musk sues OpenAI and CEO Sam Altman, claiming betrayal of its goal \nto benefit humanity; Elon Musk is suing OpenAI and its CEO Sam Altman \nover what he says is a betrayal of the ChatGPT maker's founding aims of \nbenefiting humanity rather than pursuing profits\nDayton Daily News (Ohio)\nMarch 1, 2024 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 901 words\nByline: KELVIN CHAN\nBody\nElon Musk is suing OpenAI and its CEO Sam Altman over what he says is a betrayal of the ChatGPT maker's \nfounding aims of benefiting humanity rather than pursuing profits.\nIn a lawsuit filed at San Francisco Superior Court, billionaire Musk said that when he bankrolled OpenAI's creation, \nhe secured an agreement with Altman and Greg Brockman, the president, to keep the AI company as a nonprofit \nthat would develop technology for the benefit of the public. \nUnder its founding agreement, OpenAI would also make its code open to the public instead of walling it off for any \nprivate company's gains, the lawsuit says. \nHowever, by embracing a close relationship with Microsoft, OpenAI and its top executives have set that pact \n\"aflame\" and are \"perverting\" the company's mission, Musk alleges in the lawsuit. \nOpenAI declined to comment on the lawsuit Friday. \n\"OpenAI, Inc. has been transformed into a closed-source de facto subsidiary of the largest technology company in \nthe world: Microsoft,\" the lawsuit filed Thursday says. \"Under its new Board, it is not just developing but is actually \nrefining an AGI to maximize profits for Microsoft, rather than for the benefit of humanity.\" \nAGI refers to artificial general intelligence, which are general purpose AI systems that can perform just as well as  \nor even better than  humans in a wide variety of tasks. \nMusk is suing over breach of contract, breach of fiduciary duty and unfair business practices. He also wants an \ninjunction to prevent anyone, including Microsoft, from benefiting from OpenAI's technology. \nThose claims are unlikely to succeed in court but that might not be the point for Musk, who is getting his take and \npersonal story on the record, said Anupam Chander, a law professor at Georgetown University. \n\"Partly there's an assertion of Elon's founding role in OpenAI and generative AI technology, in particular his claim \nhe named OpenAI and he hired the key scientist and that he was the principal funder of its early years,\" Chander \nsaid. \"In some sense it's a lawsuit that tries to establish his own place in the history of generative AI.\" \nMusk was an early investor in OpenAI when it was founded in 2015 and co-chaired its board alongside Altman. In \nthe lawsuit, he said he invested \"tens of millions\" of dollars in the nonprofit research laboratory. \nElon Musk sues OpenAI and CEO Sam Altman, claiming betrayal of its goal to benefit humanity Elon Musk is \nsuing OpenAI and its CEO Sam Altman over what he says i....\nMusk resigned from the board in early 2018 in a move that OpenAI said at the time would prevent conflicts of \ninterest as the Tesla CEO was recruiting AI talent to build self-driving technology at the electric car maker. \"This will \neliminate a potential future conflict for Elon,\" OpenAI said in a February 2018 blog post. Musk has since said he \nalso had disagreements with the startup's direction, but he continued to donate to the nonprofit. \nLater that year, OpenAI filed papers to incorporate a for-profit arm and began shifting most of its workforce to that \nbusiness, but retained a nonprofit board of directors that governed the company. Microsoft made its first $1 billion \ninvestment in the company in 2019 and the next year, signed an agreement that gave the software giant exclusive \nrights to its AI models. That license is supposed to expire once OpenAI has achieved artificial general intelligence, \nthe company has said. \nIts unveiling of ChatGPT in late 2022 bought worldwide fame to OpenAI and helped spark a race by tech \ncompanies to capitalize on the public's fascination with the technology. \nWhen the nonprofit board abruptly fired Altman as CEO late last year, for reasons that still haven't been fully \ndisclosed, it was Microsoft that helped drive the push that brought Altman back as CEO and led most of the old \nboard to resign. Musk's lawsuit alleged that those changes caused the checks and balances protecting the nonprofit \nmission to \"collapse overnight.\" \nOne of Musk's claims is that the directors of the nonprofit have failed to uphold their obligations to follow its mission, \nbut Dana Brakman Reiser, a professor at Brooklyn Law School, is skeptical that Musk had standing to bring that \nclaim. \n\"It would be very worrisome if every person who cared about or donated to a charity could suddenly sue their \ndirectors and officers to say, 'You're not doing what I think is the right thing to run this nonprofit,'\" she said. In \ngeneral, only other directors or an attorney general, for example, could bring that type of suit, she said. \nEven if Musk invested in the for-profit business, his complaint seems to be that the organization is making too much \nprofit in contradiction to its mission, which includes making its technology publicly available. \n\"I care about nonprofits actually following the mission that they set out and not being captured for some kind for \nprofit purpose. That is a real concern,\" Brakman Reiser said. \"Whether Elon Musk is the person to raise that claim, \nI'm less sure.\" \nWhatever the legal merits of the claims, a brewing courtroom fight between Musk, who now has his own AI startup, \nand Altman could offer the public a peek into the internal debates and decision-making at OpenAI, though the \ncompany's lawyers will likely fight to keep some of those documents confidential. \n\"The discovery will be epic,\" posted venture capitalist Chamath Palihapitiya on Musk's social media platform X on \nFriday. To which Musk replied in his only public commentary so far on the case: \"Yes.\" \nThe AP has signed a deal with OpenAI for it to access its news archive.\nGraphic\n \nFILE - OpenAI CEO Sam Altman participates in the \"Technology in a turbulent world\" panel discussion during the \nannual meeting of the World Economic Forum in Davos, Switzerland, on Jan. 18, 2024. Elon Musk is suing OpenAI \nand its CEO Sam Altman over what he says is a betrayal of the ChatGPT maker's founding aims of benefiting \nhumanity rather than pursuing profits. In a lawsuit filed Thursday Feb. 29, 2024 at San Francisco Superior Court, \nbillionaire Musk said that when he bankrolled OpenAI's creation, he secured an agreement with Altman and Greg \nElon Musk sues OpenAI and CEO Sam Altman, claiming betrayal of its goal to benefit humanity Elon Musk is \nsuing OpenAI and its CEO Sam Altman over what he says i....\nBrockman, the president, to keep the AI company as a non-profit that would develop technology for the benefit of \nthe public. (AP Photo/Markus Schreiber, File)\nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "S.E.C. Is Reviewing Board Over Altman's Brief Firing",
        "media": "The New York Times",
        "time": "March 2, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "476 words",
        "byline": "By Cade Metz, Tripp Mickle and Matthew Goldstein",
        "story_text": "S.E.C. Is Reviewing Board Over Altman's Brief Firing\nThe New York Times\nMarch 2, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 476 words\nByline: By Cade Metz, Tripp Mickle and Matthew Goldstein\nBody\nThe U.S. regulator opened its inquiry after the board unexpectedly fired the company's chief executive, Sam \nAltman, in November.\nThe Securities and Exchange Commission began an inquiry into OpenAI soon after the company's board of \ndirectors unexpectedly removed Sam Altman, its chief executive, at the end of last year, three people familiar with \nthe inquiry said. \n  The regulator has sent official requests to OpenAI, the developer of the ChatGPT online chatbot, seeking \ninformation about the situation. It is unclear whether the S.E.C. is investigating Mr. Altman's behavior, the board's \ndecision to oust him or both.\n  Even as OpenAI has tried to turn the page on the dismissal of Mr. Altman, who was soon reinstated, the \ncontroversy continues to hound the company. In addition to the S.E.C. inquiry, the San Francisco artificial \nintelligence company has hired a law firm to conduct its own investigation into Mr. Altman's behavior and the \nboard's decision to remove him.\n  The board dismissed Mr. Altman on Nov. 17, saying it no longer had confidence in his ability to run OpenAI. It said \nhe had not been ''consistently candid in his communications,'' though it did not provide specifics. It agreed to \nreinstate him five days later.\n  Privately, the board worried that Mr. Altman was not sharing all of his plans to raise money from investors in the \nMiddle East for an A.I. chip project, people with knowledge of the situation have said.\n  Spokespeople for the S.E.C. and OpenAI and a lawyer for Mr. Altman all declined to comment.\n  The S.E.C.'s inquiry was reported earlier by The Wall Street Journal.\n  OpenAI kicked off an industrywide A.I. boom at the end of 2022 when it released ChatGPT. The company is \nconsidered a leader in what is called generative A.I., technologies that can generate text, sounds and images from \nshort prompts. A recent funding deal values the start-up at more than $80 billion.\n  Many believe that generative A.I., which represents a fundamental shift in the way computers behave, could \nremake the industry as thoroughly as the iPhone or the web browser. Others argue that the technology could cause \nserious harm, helping to spread online disinformation, replacing jobs with unusual speed and maybe even \nthreatening the future of humanity.\nS.E.C. Is Reviewing Board Over Altman's Brief Firing\n  After the release of ChatGPT, Mr. Altman became the face of the industry's push toward generative A.I. as he \nendlessly promoted the technology -- while acknowledging the dangers.\n  In an effort to resolve the turmoil surrounding Mr. Altman's ouster, he and the board agreed to remove two \nmembers and add two others: Bret Taylor, who is a former Salesforce executive, and former Treasury Secretary \nLawrence H. Summers.\n  Mr. Altman and the board also agreed that OpenAI would start its own investigation into the matter. That \ninvestigation, by the WilmerHale law firm, is expected to close soon.\nhttps://www.nytimes.com/2024/02/29/technology/sec-openai-board-sam-altman.html\nGraphic\n \nPHOTO: Sam Altman at a Senate hearing last spring. OpenAI's board fired him on Nov. 17, then reinstated him five \ndays later. (PHOTOGRAPH BY HAIYUN JIANG/THE NEW YORK TIMES) This article appeared in print on page \nB4.               \nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "Newsletter_Mar2024",
        "header": "What Microsoft’s Activision Setback Means for Deal Making; DealBook",
        "media": "Newsletter",
        "time": "March 2, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1887 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "What Microsoft’s Activision Setback Means for Deal Making; DealBook \nNewsletter\nThe New York Times \nApril 27, 2023 Thursday 17:07 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1887 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.&amp;#160;&amp;#160;\nHighlight: A British agency’s move to block the company’s $69 billion bid for the video games company reflects a \nnew regulatory reality for corporate buyers.\nBody\nA British agency’s move to block the company’s $69 billion bid for the video games company reflects a new \nregulatory reality for corporate buyers.\nThe risks of doing deals \nA British regulator’s decision to reject Microsoft’s $69 billion takeover bid for Activision Blizzard stunned many who \nhad expected the deal to go through. That’s especially because moves this month by the agency, the Competition \nand Markets Authority, suggested that the transaction might pass muster.\nBut the decision only reinforces the current reality: More assertive regulators around the world present an additional \nchallenge for corporate buyers at a time when deal makers are hoping to revive a moribund market for mergers and \nacquisitions.\nThe agency continues to flex its growing regulatory muscle. Though it narrowed the scope of its Activision deal \ninquiry to just one issue, cloud gaming, the C.M.A. said that letting Microsoft buy the Call of Duty maker could give \nthe tech giant too much power over the video games market.\nMost likely emboldening the agency is how unlikely an appeal of its decision is to succeed, according to Pablo \nIbáñez Colomo, a law professor at the London School of Economics. The tribunal that will weigh Microsoft’s appeal \nwill examine mainly whether the regulator followed proper procedure. That institutional advantage positions the \nagency as one of the world’s most influential antitrust enforcers, alongside those in the United States and the \nEuropean Union.\nWhat Microsoft ’s Activision Setback Means for Deal Making DealBook Newsletter\nGlobal regulators are reviewing deals more closely now. In the United States, it’s because of an ideological shift to \noppose big companies from getting unduly bigger. And political reasons sometimes factor in: Consider that Berlin is \nscrutinizing Carrier’s about $13.3 billion takeover of Viessmann, a German maker of heat pumps, to ensure that the \ncountry remains competitive in renewable energy technologies.\nBig deals are still on the table. The Swiss commodities giant Glencore, for instance, is still interested in buying Teck \nResources, for at least $22.5 billion after having defeated a defensive move by  the Canadian mining company.\nDeal makers say that M.&amp;A. is still very much possible, if corporate buyers are willing to fight in court and are \nprepared to see transactions fail. (Just under 1 percent of announced deals have been withdrawn this year, running \nslightly lower than last year’s rate.)\nMicrosoft said on Wednesday that it would defend the Activision bid. But with a looming July 18 deadline for the \ndeal and shareholders seemingly undisturbed by the legal setback, some analysts think the Xbox maker ultimately \nmay accept defeat, fork over the $3 billion breakup fee and move on.\nHERE’S WHAT’S HAPPENING \nU.S. economic growth is slowing. The government is due to release data at 8:30 a.m. Eastern showing that first \nquarter gross domestic product probably rose 1.9 percent, down from 2.6 percent the previous quarter. The data \nshould give a clearer picture about whether investors are right to fear a possible recession in the second half of the \nyear.\nHouse Republicans pass their debt limit bill. Speaker Kevin McCarthy cobbled together enough caucus members to \nnarrowly approve his proposal, which would raise the debt ceiling for one year and calls for sharp spending cuts. \nThat strengthens his hand in negotiating with President Biden, though the bill is unlikely to pass in the Democratic-\ncontrolled Senate.\nFirst Republic’s shares are still sliding. Shares in the beleaguered lender fell about 30 percent on Wednesday, \nending at $5.69 — down from $150 a year ago — as it casts about for a lifeline. Executives and advisers continue \nto believe that the federal government must play some role in devising a solution.\nSamsung’s quarterly earnings tumble 95 percent. The Korean electronics giant on Thursday reported its lowest \noperating profit since 2009, driven by weak demand for memory chips and other semiconductors. Still, Samsung \npredicts a recovery this year as it cuts back on production.\nChinese officials question Bain &amp; Company employees. The consulting giant said that the authorities had \nvisited its Shanghai offices this month, and that it was “cooperating as appropriate”; it didn’t specify what the inquiry \nwas focused on. The raid, which comes after a similar move on another American consulting firm’s offices, reflects \nthe economic tensions between Washington and Beijing.\nA.I. is the big buzzword in tech earnings \nBig tech was extending its 2023 rally on Thursday.\nMeta shares jumped more than 12 percent premarket on stronger than expected revenues last quarter as digital \nads rebounded, user numbers increased and investor attention shifts to the prospect of artificial intelligence-fueled \ngrowth from job cuts.\nMicrosoft and Google set the bullish tone on Tuesday. Shares in the tech giants climbed after the companies \nreported solid results and elaborated on their visions for how A.I. will be incorporated into their core software and \nsearch products. Amazon will report its quarterly earnings on Thursday, and is expected to update investors on how \nit is positioned in the A.I. arms race.\nWhat Microsoft ’s Activision Setback Means for Deal Making DealBook Newsletter\nSatya Nadella, Microsoft’s C.E.O., mentioned “A.I.” or “OpenAI” at least 29 times in his 15-minute introductory \nremarks to analysts on Tuesday. He said he viewed A.I. as a “generational shift,” and it is seen as the company’s \nbest chance at catching Google in search.\nMark Zuckerberg, the C.E.O. of Meta, spent about six minutes talking about A.I. in his intro on Wednesday, \nBloomberg reported, and just 90 seconds on the metaverse, the immersive world the company is building that’s \nslow to take off. (Mr. Zuckerberg emphasized that the group was not pulling back from the metaverse.)\nA.I. will “impact every single one of our apps and services,” he told analysts, adding that it was already “improving \nmonetization.” Instagram is one example. “Since we launched Reels, A.I. recommendations have driven a more \nthan 24 percent increase in time spent on Instagram,” he said, referring to the short-video clip feature that’s a big \ngrowth engine for the company and an attempt to reclaim market share from TikTok.\nAnother promising metric: In March, three billion average daily users logged into Facebook, Instagram and \nWhatsApp, the company said, helping reverse a slide in sales in the previous three quarters.\nOne thing to watch: costs. Both Microsoft and Alphabet said they were holding the line on expenses, but advancing \nA.I. requires a lot of investment. Meta said it was staffing up its generative A.I. team this year, and would spend \nmore the technology, while Ruth Porat, Alphabet’s C.F.O., warned that R.&amp;D. costs would be “modestly \nhigher.”\nDisney v. DeSantis goes to court \nThe fight between Disney and Gov. Ron DeSantis entered a combative new round on Wednesday, after the media \ngiant sued Florida’s governor and the board that oversees government services at its resort in the state. The \ncompany accused him of waging a “targeted campaign of government retaliation,” and filed a First Amendment \nlawsuit. The bigger question: Will the battle damage Mr. DeSantis’s potential presidential hopes\nDisney accused Mr. DeSantis of weaponizing government power in retaliation for the company criticizing what \nopponents call the “Don’t Say Gay” law, a state measure that barred discussion of sexual orientation and gender \nidentity in some schools. “In America, the government cannot punish you for speaking your mind,” the complaint \nsaid.\nTaryn Fenske, a spokeswoman for Mr. DeSantis, dismissed the lawsuit as an attempt “to undermine the will of the \nFlorida voters.”\nMr. DeSantis sees political mileage in taking on Disney. The company is one of the state’s biggest employers and \nsaid it had earmarked $17 billion to expand over the next decade. But he has hammered it over its stance on social \nissues to shore up his backing among conservatives in his home state.\nBut his tactics could be damaging in a national campaign. Polls — including one by Harvard/Harris and another by \nReuters/Ipsos — are generally split on whether this is helping his appeal with voters. \nPotential rivals for the Republican nomination see an opening:\n• Former President Donald Trump called the Disney fight a “political stunt.”\n• The former New Jersey governor Chris Christie said it was anti-conservative.\n• Nikki Haley, the former governor of South Carolina, even pitched for the business. “Hey@Disney, my home \nstate will happily accept your 70,000+ jobs if you want to leave Florida,”she tweeted, adding, “SC’s not \nwoke, but we’re not sanctimonious about it either.”\nTucker Carlson breaks his silence\nTwo days after being fired from Fox News, Tucker Carlson emerged on Twitter … with a two-minute video that \ndidn’t address his shocking ouster. But he may have offered a hint about what he’ll do next after his surprise exit \nfrom Rupert Murdoch’s media empire.\nWhat Microsoft ’s Activision Setback Means for Deal Making DealBook Newsletter\nMr. Carlson criticized the state of political discourse, saying, “both political parties and their donors have reached \nconsensus on what benefits them and they actively collude to shut down any conversation about it.”\n“Where can you still find Americans saying true things? There aren’t many places left,” Mr. Carlson added. “But \nthere are some. And that’s enough.” He concluded with “See you soon,” suggesting that he may return to the public \nforum, either on his own or as part of some news media outlet.\nMore details have emerged about Mr. Carlson’s firing. The Times reports that just before Fox News’s defamation \ntrial was set to begin, the Fox board belatedly learned more about highly offensive and crude remarks that the host \nhad made privately — and that surfaced as part of the legal discovery process.\nThe full extent of what he said is still not known, but news outlets have challenged court-ordered redactions of the \nprivate messages, and the communications could still emerge in a lawsuit against Fox News filed by the voting \nsoftware maker Smartmatic.\nTHE SPEED READ \nDeals\n• Struggling companies are increasingly trying to restructure their debt out of court to avoid bankruptcy, but \nmany still fail to do so. (FT)\n• The private equity owners of Millennium Trust may put the retirement plan custodian up for sale, with a price \ntag of as much as $8 billion. (Reuters)\nPolicy\n• Peter Thiel, a major Republican donor, reportedly won’t give to any G.O.P. political candidate next year; \nmeanwhile, top Democratic backers are lining up behind Biden. (Reuters, CNBC)\n• JPMorgan Chase has built a ChatGPT-powered A.I. model that analyzed 25 years’ worth of Fed speeches to \nparse messages from the central bank for possible trading clues. (Bloomberg)\nBest of the rest\n• Pras Michel, a founding member of the Fugees hip-hop group, was convicted of running an illegal lobbying \nand political donation scheme on behalf of the Malaysian businessman behind the 1Malaysia Development \nBerhad scandal. (NYT)\n• Twitter’s mass removal of verification check marks has led to an uptick in misinformation on the social \nnetwork. (NYT)\n• Win Bischoff, a decorated British banker who served as chairman of Citigroup, died on Tuesday. He was 81. \n(Reuters)\n• “Watch an A.I. Learn to Write by Reading Nothing but Jane Austen.” (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Microsoft faces a tough appeal process. (PHOTOGRAPH BY Lucy Nicholson/Reuters FOR THE NEW \nYORK TIMES)\nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Internet Is About to Get Much Worse; Guest Essay",
        "media": "The New York Times",
        "time": "March 2, 2024",
        "section": "OPINION",
        "length": "1105 words",
        "byline": "Julia Angwin Julia Angwin is a contributing Opinion writer who writes about tech policy.&amp;#160;You can",
        "story_text": "The Internet Is About to Get Much Worse; Guest Essay\nThe New York Times \nSeptember 23, 2023 Saturday 17:18 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1105 words\nByline: Julia Angwin Julia Angwin is a contributing Opinion writer who writes about tech policy.&amp;#160;You can \nfollow her on Twitter or Mastodon or her personal newsletter.\nHighlight: Why the development of artificial intelligence might result in greater pollution of our digital public spaces.\nBody\nGreg Marston, a British voice actor, recently came across “Connor” online — an A.I.-generated clone of his voice, \ntrained on a recording Mr. Marston had made in 2003. It was his voice uttering things he had never said.\nBack then, he had recorded a session for IBM and later signed a release form allowing the recording to be used in \nmany ways. Of course, at that time, Mr. Marston couldn’t envision that IBM would use anything more than the exact \nutterances he had recorded. Thanks to artificial intelligence, however, IBM was able to sell Mr. Marston’s decades-\nold sample to websites that are using it to build a synthetic voice that could say anything. Mr. Marston recently \ndiscovered his voice emanating from the Wimbledon website during the tennis tournament. (IBM said it is aware of \nMr. Marston’s concern and is discussing it with him directly.)\nHis plight illustrates why many of our economy’s best-known creators are up in arms. We are in a time of eroding \ntrust, as people realize that their contributions to a public space may be taken, monetized and potentially used to \ncompete with them. When that erosion is complete, I worry that our digital public spaces might become even more \npolluted with untrustworthy content.\nAlready, artists are deleting their work from X, formerly known as Twitter, after the company said it would be using \ndata from its platform to train its A.I. Hollywood writers and actors are on strike partly because they want to ensure \ntheir work is not fed into A.I. systems that companies could try to replace them with. News outlets including The \nNew York Times and CNN have added files to their website to help prevent A.I. chatbots from scraping their \ncontent.\nAuthors are suing A.I. outfits, alleging that their books are included in the sites’ training data. OpenAI has argued, in \na separate proceeding, that the use of copyrighted data for training A.I. systems is legal under the “fair use” \nprovision of copyright law.\nWhile creators of quality content are contesting how their work is being used, dubious A.I.-generated content is \nstampeding into the public sphere. NewsGuard has identified 475 A.I.-generated news and information websites in \n14 languages. A.I.-generated music is flooding streaming websites and generating A.I. royalties for scammers. A.I.-\ngenerated books — including a mushroom foraging guide that could lead to mistakes in identifying highly poisonous \nfungi — are so prevalent on Amazon that the company is asking authors who self-publish on its Kindle platform to \nalso declare if they are using A.I.\nThis is a classic case of tragedy of the commons, where a common resource is harmed by the profit interests of \nindividuals. The traditional example of this is a public field that cattle can graze upon. Without any limits, individual \ncattle owners have an incentive to overgraze the land, destroying its value to everybody.\nThe Internet Is About to Get Much Worse Guest Essay\nWe have commons on the internet, too. Despite all of its toxic corners, it is still full of vibrant portions that serve the \npublic good — places like Wikipedia and Reddit forums, where volunteers often share knowledge in good faith and \nwork hard to keep bad actors at bay.\nBut these commons are now being overgrazed by rapacious tech companies that seek to feed all of the human \nwisdom, expertise, humor, anecdotes and advice they find in these places into their for-profit A.I. systems.\nConsider, for instance, that the volunteers who build and maintain Wikipedia trusted that their work would be used \naccording to the terms of their site, which requires attribution. Now some Wikipedians are apparently debating \nwhether they have any legal recourse against chatbots that use their content without citing the source.\nRegulators are trying to figure it out, too. The European Union is considering the first set of global restrictions on \nA.I., which would require some transparency from generative A.I. systems, including providing summaries of \ncopyrighted data that was used to train its systems.\nThat would be a good step forward, since many A.I. systems do not fully disclose the data they were trained on. It \nhas primarily been journalists who have dug up the murky data that lies beneath the glossy surface of the chatbots. \nA recent investigation detailed in The Atlantic revealed that more than 170,000 pirated books are included in the \ntraining data for Meta’s A.I. chatbot, Llama. A Washington Post investigation revealed that OpenAI’s ChatGPT \nrelies on data scraped without consent from hundreds of thousands of websites.\nBut transparency is hardly enough to rebalance the power between those whose data is being exploited and the \ncompanies poised to cash in on the exploitation.\nTim Friedlander, the founder and president of the National Association of Voice Actors, has called for A.I. \ncompanies to adopt ethical standards. He says that actors need three C’s: consent, control and compensation.\nIn fact, all of us need the three C&#39;s. Whether we are professional actors or we just post pictures on social \nmedia, everyone should have the right to meaningful consent on whether we want our online lives fed into the giant \nA.I. machines.\nAnd consent should not mean having to locate a bunch of hard-to-find opt-out buttons to click — which is where the \nindustry is heading.\nCompensation is harder to figure out, especially since most of the A.I. bots are primarily free services at the \nmoment. But make no mistake, the A.I. industry is planning to and will make money from these systems, and when \nit does, there will be a reckoning with those whose works fueled the profits.\nFor people like Mr. Marston, their livelihoods are at stake. He estimates that his A.I. clone has already lost him jobs \nand will cut into his future earnings significantly. He is working with a lawyer to seek compensation. “I never agreed \nor consented to having my voice cloned, to see/hear it released to the public, thus competing against myself,” he \ntold me.\nBut even those of us who don’t have a job directly threatened by A.I. think of writing that novel or composing a song \nor recording a TikTok or making a joke on social media. If we don’t have any protections from the A.I. data \novergrazers, I worry that it will feel pointless to even try to create in public. And that would be a real tragedy.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nPHOTO (PHOTOGRAPH BY CHARLES DESMARAIS) This article appeared in print on page A24.\nLoad-Date: March 2, 2024\nThe Internet Is About to Get Much Worse Guest Essay"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "OpenAI Breached Contract, Musk Says",
        "media": "The New York Times",
        "time": "March 2, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1520 words",
        "byline": "By Adam Satariano, Cade Metz and Tripp Mickle",
        "story_text": "OpenAI Breached Contract, Musk Says\nThe New York Times\nMarch 2, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1520 words\nByline: By Adam Satariano, Cade Metz and Tripp Mickle\nBody\nMusk said the prominent A.I. start-up had put profits and commercial interests ahead of seeking to benefit \nhumanity.\nOpenAI, the influential artificial intelligence company that ousted and then reinstated its high-profile chief executive \nthree months ago, faces a new drama: a lawsuit from Elon Musk, one of the richest men in the world and a co-\nfounder of the A.I. lab. \n  Mr. Musk sued OpenAI and its chief executive, Sam Altman, accusing them of breaching a contract by putting \nprofits and commercial interests in developing artificial intelligence ahead of the public good. A multibillion-dollar \npartnership that OpenAI developed with Microsoft, Mr. Musk said, represented an abandonment of a founding \npledge to carefully develop A.I. and make the technology publicly available.\n  ''OpenAI has been transformed into a closed-source de facto subsidiary of the largest technology company, \nMicrosoft,'' said the lawsuit filed Thursday in Superior Court in San Francisco.\n  The 35-page lawsuit is the latest chapter in a fight between the former business partners that has been simmering \nfor years, and it homes in on unresolved questions in the A.I. community: Will artificial intelligence improve the \nworld or destroy it and should it be tightly controlled or set free?\n  Mr. Musk, the chief executive of Tesla, and Mr. Altman, as much as anyone in the world, have helped to frame that \ndebate. Mr. Musk helped found OpenAI in 2015 as a response to A.I. work being done at the time by Google. Mr. \nMusk believed Google and its co-founder, Larry Page, were dismissive of the risks A.I. presented to humanity.\n  Mr. Musk left OpenAI's board during a power struggle in 2018. The company went on to become a leader in the \nfield of generative A.I. and created ChatGPT, a chatbot that can produce text and respond to queries in humanlike \nprose. Mr. Musk, who founded his own A.I. company last year called xAI, said OpenAI was not focused enough on \nthe technology's risks.\n  The suit is also the latest twist for a company enmeshed in controversy. In November, OpenAI's board forced out \nMr. Altman and said it no longer trusted him to run the company. He was reinstated just five days later after an \nemployee revolt threatened the future of the company.\n  Silicon Valley insiders believe that generative A.I., the technology behind ChatGPT, is a once in a generation \ntechnology that could transform the tech industry as thoroughly as web browsers did more than 30 years ago.\n  ''The courts of California must decide what OpenAI must do after straying from its original mission,'' said Gary \nMarcus, an A.I entrepreneur and an emeritus professor of psychology and neural science at New York University. \nOpenAI Breached Contract, Musk Says\n''The court of public opinion must decide what it thinks of Musk, who has a fair point about OpenAI but has his own \ncommercial A.I. interests and choices.''\n  OpenAI declined to comment on the lawsuit. In a message sent to OpenAI employees on Friday afternoon that \nwas viewed by The New York Times, Mr. Altman said that he was confused by Mr. Musk's argument that building \nA.I. for the benefit of humanity was at odds with building a business. \n  Jason Kwon, OpenAI's chief strategy officer, told OpenAI employees in another message viewed by The Times \nthat the company's leaders ''categorically disagree'' with the suit. Mr. Musk's claims ''do not reflect the reality of our \nwork or mission,'' he wrote.\n  The lawsuit adds to an array of problems piling up for OpenAI. The company's relationship with Microsoft is also \nfacing scrutiny from regulators in the United States, European Union and Britain. It has been sued by The New York \nTimes, several digital outlets, writers and computer programmers for scraping copyrighted material to train its \nchatbot. And the Securities and Exchange Commission is investigating Mr. Altman and OpenAI.\n  Mr. Musk's lawsuit said he became involved with OpenAI because it was created as a nonprofit to develop artificial \nintelligence for the ''benefit of humanity.'' A key component of that, the lawsuit said, was to make its technology \nopen source, meaning that it would share the underlying software code with the world. Instead, the company \ncreated a for-profit business unit and restricted access to its technology.\n  The lawsuit, which seeks a jury trial, accused OpenAI and Mr. Altman of being in breach of contract and violating \nfiduciary duty, as well as unfair business practices. Mr. Musk is asking that OpenAI be required to open up its \ntechnology to others and that Mr. Altman and others pay back Mr. Musk the money that Mr. Musk gave to the \norganization. Greg Brockman, the president of OpenAI, is also named as a defendant.\n  Mr. Musk's argument hinges on the close partnership between OpenAI and Microsoft. In 2019, Mr. Altman \nnegotiated a deal in which Microsoft agreed to invest $1 billion in OpenAI. The start-up said it would use Microsoft's \ncloud computing services exclusively for building and deploying its A.I. In the years since, Microsoft has invested an \nadditional $12 billion in the start-up and is the only company outside of OpenAI with a license to use the raw \ntechnology behind GPT-4, the company's most powerful A.I. technology.\n  Other companies like Google, Meta and the French start-up Mistral are freely sharing some of their latest \ntechnologies with the other companies and researchers.\n  The suit could expose OpenAI to a lengthy and invasive legal review that reveals more about Mr. Altman's \ndismissal and OpenAI's pivot from being a nonprofit organization to for-profit company. That change, which was \nengineered by Mr. Altman in late 2018 and early 2019, has been the source of backbiting at OpenAI for years and \ncontributed to the board's decision to fire him as chief executive.\n  Though Mr. Musk has repeatedly criticized OpenAI for becoming a for-profit company, he hatched a plan in 2017 \nto wrest control of the A.I. lab from Mr. Altman and its other founders and transform it into a commercial operation \nthat would work alongside his other companies, including the electric carmaker Tesla, and make use of their \nincreasingly powerful supercomputers, people familiar with his plan have said. When his attempt to take control \nfailed, he left the OpenAI board, the people said.\n  Speaking at The New York Times's DealBook Summit last year, Mr. Musk said that he wanted to know more about \nthe chaos that unfolded at OpenAI last year, including why Ilya Sutskever, a co-founder, joined with other board \nmembers to fire Mr. Altman in November. He said that he was concerned that OpenAI had discovered some \ndangerous element of A.I., which is a question that his legal team could investigate as part of the lawsuit.\n  ''I have mixed feelings about Sam,'' Mr. Musk said at the DealBook conference. Making a reference to a powerful \nring in ''The Lord of the Rings,'' he added, ''The ring of power can corrupt, and he has the ring of power.''\n  Mr. Musk did not respond to requests for comment.\nOpenAI Breached Contract, Musk Says\n  The falling out between Mr. Musk and Mr. Altman has long been a subject of intrigue in Silicon Valley. The men \nfirst met during a tour of SpaceX, Mr. Musk's rocket company, and later bonded over their shared concerns about \nthe threat that A.I. could pose to humanity.\n  According to the lawsuit, OpenAI's nonprofit status was a major source of friction, as tensions grew between \ncompany executives interested in trying to make money from new A.I. technology and Mr. Musk, who wanted it to \nremain a research lab.\n  ''Either go do something on your own or continue with OpenAI as a nonprofit,'' Mr. Musk said at one point, \naccording to the complaint. ''I will no longer fund OpenAI until you have made a firm commitment to stay, or I'm just \nbeing a fool who is essentially providing free funding to a startup. Discussions are over.''\n  The lawsuit tries to show Mr. Musk as an indispensable figure in OpenAI's development. From 2016 to 2020, Mr. \nMusk contributed more than $44 million to OpenAI, according to the lawsuit. He also leased the company's initial \noffice space in San Francisco and paid the monthly expenses. He was personally involved in recruiting Mr. \nSutskever, a top research scientist at Google, to be OpenAI's chief scientist, according to the complaint.\n  ''Without Mr. Musk's involvement and substantial supporting efforts and resources,'' the suit says, ''it is highly likely \nthat OpenAI Inc. would never have gotten off the ground.''\n  Brian Quinn, a law professor at Boston College, said that Mr. Musk's complaint made a compelling case that \nOpenAI had abandoned its roots. But, he said, Mr. Musk probably does not have the standing to bring it, because \nnonprofit law limits challenges of this type to those made by a nonprofit's dues-paying members, its own directors or \nstate regulators in Delaware, where OpenAI is registered.\n  ''If he were a member of the board of directors, I would say, 'Ooh, strong case.' If this was filed by the Delaware \nsecretary of state, I would say, 'Ooh they're in trouble,''' Mr. Quinn said. ''But he doesn't have standing. He doesn't \nhave a case.''\n  David A. Fahrenthold contributed reporting.David A. Fahrenthold contributed reporting.\nhttps://www.nytimes.com/2024/03/01/technology/elon-musk-openai-sam-altman-lawsuit.html\nGraphic\n \nPHOTOS: Elon Musk said that a partnership between OpenAI and Microsoft was an abandonment of a pledge to \ncarefully develop A.I. and make it publicly available. (PHOTOGRAPH BY CARLY ZAVALA FOR THE NEW YORK \nTIMES)\n OpenAI's relationship with Microsoft is also facing scrutiny from regulators in the U.S., Europe and Britain. \n(PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) (B4) This article appeared in print on page \nB1, B4.               \nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "What Elon Musk and Sam Altman Said About Each Other",
        "media": "The New York Times",
        "time": "March 2, 2024",
        "section": "TECHNOLOGY",
        "length": "700 words",
        "byline": "Yiwen Lu and Tripp Mickle Yiwen Lu reports on technology for The Times. Tripp Mickle reports on Apple",
        "story_text": "What Elon Musk and Sam Altman Said About Each Other\nThe New York Times \nMarch 1, 2024 Friday 01:02 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 700 words\nByline: Yiwen Lu and Tripp Mickle Yiwen Lu reports on technology for The Times. Tripp Mickle reports on Apple \nand Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes product launches, \nmanufacturing issues and political challenges. He also writes about trends across the tech industry, including \nlayoffs, generative A.I. and robot taxis.\nHighlight: Once united over the future of artificial intelligence, they have become increasingly estranged over the \nyears.\nBody\nOnce united over the future of artificial intelligence, they have become increasingly estranged over the years.\nA decade ago, Elon Musk and Sam Altman bonded over a shared concern about the dangers of artificial \nintelligence. That led them in 2015 to create OpenAI, a nonprofit A.I. lab that had the aim of benefiting humanity.\nIn 2018, Mr. Musk departed OpenAI after a power struggle with Mr. Altman. Mr. Musk later expressed dismay that \nthe lab had turned into a for-profit company. Over the years, the two men have increasingly made barbed \ncomments about each other, including when Mr. Altman was briefly ousted from OpenAI in November before being \nreinstated.\nOn Thursday, Mr. Musk sued Mr. Altman and OpenAI, accusing them of breaching the founding contract between \nMr. Musk and Mr. Altman by putting profits and commercial interests ahead of the public good in developing A.I.\nHere’s what Mr. Musk and Mr. Altman have said about each other over the years, and what they have jointly said.\nWhat Mr. Musk has said about Mr. Altman\nPost on X, in November:\n“What matters is having directors who deeply understand AI and will stand up to Sam. Human civilization is at stake \nhere.”\nAt The New York Times’s DealBook Summit, in November:\n“I have mixed feelings about Sam. The ring of power can corrupt, and he has the ring of power. So I don’t know.”\n“I’m quite concerned that there’s some dangerous element of A.I. that they’ve created.\"\nIn this week’s lawsuit:\n“Mr. Altman caused OpenAI to radically depart from its original mission and historical practice of making its \ntechnology and knowledge available to the public.”\nWhat Mr. Altman has said about Mr. Musk\nWhat Elon Musk and Sam Altman Said About Each Other\nIn a Vanity Fair interview , in December 2015:\n“I really trust him, which is obviously important to everyone involved.”\nIn a personal blog post , in January 2019:\n“I remember when Elon Musk took me on a tour of the SpaceX factory many years ago. He talked in detail about \nmanufacturing every part of the rocket, but the thing that sticks in memory was the look of absolute certainty on his \nface when he talked about sending large rockets to Mars. I left thinking, ‘Huh, so that’s the benchmark for what \nconviction looks like.’”\nIn a tweet, in May 2019:\n“It’s gross seeing so many root against Tesla. Be the person on the side of the climate and innovation, not the \nperson hoping to make money on puts. Also, betting against Elon is historically a mistake …and the best product \nusually wins.\n(Mr. Musk wrote back: “Thanks Sam!”)\nIn the “On With Kara Swisher” podcast, in March 2023:\n“He’s a jerk, whatever else you want to say about him — he has a style that is not a style that I’d want to have for \nmyself. But I think he does really care, and he is feeling very stressed about what the future’s going to look like for \nhumanity.”\nIn the “In Good Company” podcast, in September:\n“Elon was definitely a talent magnet and attention magnet, for sure, and also just like has some real superpowers \nthat were super helpful to us in those early days, aside from all of those things.”\nWhat Mr. Musk and Mr. Altman said about A.I. in joint appearances:\nIn a conversation at Vanity Fair’s New Establishment , in October 2015:\nMr. Altman: “The happy vision of the future is humans and A.I. in a symbiotic relationship, distributed A.I., sort of \nempowers a lot of individuals, not this single A.I. that kind of governs everything we all do that’s a million times \nsmarter than any other entity.\nMr. Musk: “I agree with what Sam said. We are effectively already a human machine collective symbiot, like a giant \ncyborg.”\nIn an interview Mr. Altman conducted with Mr. Musk, in September 2016:\nMr. Altman: “Speaking of really important problems — A.I. — you have been outspoken about A.I. Could you talk \nabout what you think the positive future for A.I. looks like and how we get there?”\nMr. Musk: “So I think we must have democratization of A.I. technology, make it widely available, and that’s the \nreason that obviously you, me, and the rest of the team, created OpenAI was to help with the, help spread out A.I. \ntechnology so it doesn’t get concentrated in the hands of a few.”\nCade Metz contributed reporting.\nCade Metz contributed reporting. \nThis article appeared in print on page B4.\nWhat Elon Musk and Sam Altman Said About Each Other\nLoad-Date: March 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "S.E.C. Is Investigating OpenAI Over Its Board’s Actions",
        "media": "The New York Times",
        "time": "March 3, 2024",
        "section": "TECHNOLOGY",
        "length": "508 words",
        "byline": "Cade Metz, Tripp Mickle and Matthew Goldstein Cade Metz writes about artificial intelligence, driverless",
        "story_text": "S.E.C. Is Investigating OpenAI Over Its Board’s Actions\nThe New York Times \nFebruary 29, 2024 Thursday 13:06 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 508 words\nByline: Cade Metz, Tripp Mickle and Matthew Goldstein Cade Metz writes about artificial intelligence, driverless \ncars, robotics, virtual reality and other emerging areas of technology. Tripp Mickle reports on Apple and Silicon \nValley for The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing \nissues and political challenges. He also writes about trends across the tech industry, including layoffs, generative \nA.I. and robot taxis. Matthew Goldstein covers Wall Street and white-collar crime and housing issues.\nHighlight: The U.S. regulator opened its inquiry after the board unexpectedly fired the company’s chief executive, \nSam Altman, in November.\nBody\nThe U.S. regulator opened its inquiry after the board unexpectedly fired the company’s chief executive, Sam \nAltman, in November.\nThe Securities and Exchange Commission began an inquiry into OpenAI soon after the company’s board of \ndirectors unexpectedly removed Sam Altman, its chief executive, at the end of last year, three people familiar with \nthe inquiry said.\nThe regulator has sent official requests to OpenAI, the developer of the ChatGPT online chatbot, seeking \ninformation about the situation. It is unclear whether the S.E.C. is investigating Mr. Altman’s behavior, the board’s \ndecision to oust him or both.\nEven as OpenAI has tried to turn the page on the dismissal of Mr. Altman, who was soon reinstated, the \ncontroversy continues to hound the company. In addition to the S.E.C. inquiry, the San Francisco artificial \nintelligence company has hired a law firm to conduct its own investigation into Mr. Altman’s behavior and the \nboard’s decision to remove him.\nThe board dismissed Mr. Altman on Nov. 17, saying it no longer had confidence in his ability to run OpenAI. It said \nhe had not been “consistently candid in his communications,” though it did not provide specifics. It agreed to \nreinstate him five days later.\nPrivately, the board worried that Mr. Altman was not sharing all of his plans to raise money from investors in the \nMiddle East for an A.I. chip project, people with knowledge of the situation have said.\nSpokespeople for the S.E.C. and OpenAI and a lawyer for Mr. Altman all declined to comment.\nThe S.E.C.’s inquiry was reported earlier by The Wall Street Journal.\nOpenAI kicked off an industrywide A.I. boom at the end of 2022 when it released ChatGPT. The company is \nconsidered a leader in what is called generative A.I., technologies that can generate text, sounds and images from \nshort prompts. A recent funding deal values the start-up at more than $80 billion.\nS.E.C. Is Investigating OpenAI Over Its Board’s Actions\nMany believe that generative A.I., which represents a fundamental shift in the way computers behave, could \nremake the industry as thoroughly as the iPhone or the web browser. Others argue that the technology could cause \nserious harm, helping to spread online disinformation, replacing jobs with unusual speed and maybe even \nthreatening the future of humanity.\nAfter the release of ChatGPT, Mr. Altman became the face of the industry’s push toward generative A.I. as he \nendlessly promoted the technology — while acknowledging the dangers.\nIn an effort to resolve the turmoil surrounding Mr. Altman’s ouster, he and the board agreed to remove two \nmembers and add two others: Bret Taylor, who is a former Salesforce executive, and former Treasury Secretary \nLawrence H. Summers.\nMr. Altman and the board also agreed that OpenAI would start its own investigation into the matter. That \ninvestigation, by the WilmerHale law firm, is expected to close soon.\nPHOTO: Sam Altman at a Senate hearing last spring. OpenAI’s board fired him on Nov. 17, then reinstated him five \ndays later. (PHOTOGRAPH BY HAIYUN JIANG/THE NEW YORK TIMES) This article appeared in print on page \nB4.\nLoad-Date: March 3, 2024"
    },
    {
        "file_name": "Technology_Mar2024",
        "header": "China’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S.",
        "media": "Technology",
        "time": "March 3, 2024",
        "section": "TECHNOLOGY",
        "length": "1464 words",
        "byline": "Paul Mozur, John Liu and Cade Metz Paul Mozur is the global technology correspondent for The Times,",
        "story_text": "China’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. \nTechnology\nThe New York Times \nFebruary 21, 2024 Wednesday 09:13 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1464 words\nByline: Paul Mozur, John Liu and Cade Metz Paul Mozur is the global technology correspondent for The Times, \nbased in Taipei. Previously he wrote about technology and politics in Asia from Hong Kong, Shanghai and Seoul. \nJohn Liu covers China and technology for The Times, focusing primarily on the interplay between politics and \ntechnology supply chains. He is based in Seoul. Cade Metz writes about artificial intelligence, driverless cars, \nrobotics, virtual reality and other emerging areas of technology.\nHighlight: China’s tech firms were caught off guard by breakthroughs in generative artificial intelligence. \nBeijing’s regulations and a sagging economy aren’t helping.\nBody\nChina’s tech firms were caught off guard by breakthroughs in generative artificial intelligence. Beijing’s \nregulations and a sagging economy aren’t helping.\nIn November, a year after ChatGPT’s release, a relatively unknown Chinese start-up leaped to the top of a \nleaderboard that judged the abilities of open-source artificial intelligence systems.\nThe Chinese firm, 01.AI, was only eight months old but had deep-pocketed backers and a $1 billion valuation and \nwas founded by a well-known investor and technologist, Kai-Fu Lee. In interviews, Mr. Lee presented his A.I. \nsystem as an alternative to options like Meta’s generative A.I. model, called LLaMA.\nThere was just one twist: Some of the technology in 01.AI’s system came from LLaMA. Mr. Lee’s start-up then built \non Meta’s technology, training its system with new data to make it more powerful.\nThe situation is emblematic of a reality that many in China openly admit. Even as the country races to build \ngenerative A.I., Chinese companies are relying almost entirely on underlying systems from the United States. \nChina now lags the United States in generative A.I. by at least a year and may be falling further behind, according \nto more than a dozen tech industry insiders and leading engineers, setting the stage for a new phase in the \ncutthroat technological competition between the two nations that some have likened to a cold war.\n“Chinese companies are under tremendous pressure to keep abreast of U.S. innovations,” said Chris Nicholson, an \ninvestor with the venture capital firm Page One Ventures who focuses on A.I. technologies. The release of \nChatGPT was “yet another Sputnik moment that China felt it had to respond to.”\nJenny Xiao, a partner at Leonis Capital, an investment firm that focuses on A.I.-powered companies, said the A.I. \nmodels that Chinese companies build from scratch “aren’t very good,” leading to many Chinese firms often using \n“fine-tuned versions of Western models.” She estimated China was two to three years behind the United States in \ngenerative A.I. developments.\nChina’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. Technology\nThe jockeying for A.I. primacy has huge implications. Breakthroughs in generative A.I. could tip the global \ntechnological balance of power, increasing people’s productivity, aiding industries and leading to future innovations, \neven as nations struggle with the technology’s risks.\nAs Chinese firms aim to catch up by turning to open-source A.I. models from the United States, Washington is in a \ndifficult spot. Even as the United States has tried to slow China’s advancements by limiting the sale of microchips \nand curbing investments, it has not held back the practice of openly releasing software to encourage its adoption.\nFor China, the newfound reliance on A.I. systems from the United States — primarily Meta’s LLaMA — has fueled \ndeeper questions about the country’s innovation model, which in recent decades surprised many by turning out \nworld-beating firms like Alibaba and ByteDance despite Beijing’s authoritarian controls.\n“When Chinese companies are leveraging American open-source technologies to play catch-up, the questions \nbecome very complicated — wrapped up in issues of national security and geopolitics,” said Oren Etzioni, a \nUniversity of Washington professor who specializes in A.I. and the founder of TrueMedia.org, a nonprofit working to \nidentify disinformation online in political campaigns.\nIn an emailed statement, Mr. Lee, 01.AI’s founder, said his startup’s A.I. model was built on LLaMA just “like most \nother A.I. companies,” adding that using open-source technologies is a standard practice. He said his company had \ntrained its A.I. model from scratch, using its own data and algorithms. Those were “the main determinants” of the \n“excellent performance” of 01.AI’s model, Mr. Lee said.\nMeta pointed to comments by Nick Clegg, who leads global affairs, in which he said openly sharing the company’s \nA.I. models helped spread its values and standards, and in turn helped secure American leadership.\n(The New York Times has sued the maker of ChatGPT, OpenAI and its partner, Microsoft, for copyright \ninfringement of news content related to A.I. systems.)\nA.I. has long been a priority in China. After the A.I. tool AlphaGo defeated two top players of the board game Go in \n2016 and 2017, Chinese policymakers set out an ambitious plan to lead the world in technology by 2030. The \ngovernment pledged billions to researchers and companies focused on A.I.\nWhen OpenAI released ChatGPT in November 2022, many Chinese firms were being hamstrung by a regulatory \ncrackdown from Beijing that discouraged experimentation without government approval. Chinese tech companies \nwere also burdened by censorship rules designed to manage public opinion and mute major opposition to the \nChinese Communist Party.\nChinese companies with the resources to build a generative A.I. model faced a dilemma. If they created a chatbot \nthat said the wrong thing, its makers would pay the price. And no one could be sure what might tumble out of a \nchatbot’s digital mouth.\n“It’s just not possible to get rid of all the problematic ways these systems can express themselves,” said Andrew Ng, \nwho teaches computer science at Stanford and was a former executive at Baidu, the Chinese search giant.\nChinese tech giants were also grappling with new regulations that dictate how A.I. models could be trained. The \nrules limit the data sets that could be used to train A.I. models and the applications that were acceptable, and also \nset requirements for registering A.I. models with the government.\n“It is both more difficult and more risky to innovate in generative A.I. in the current regulatory regime, which is still a \nmoving target,” said Kevin Xu, the U.S.-based founder of Interconnected Capital, a hedge fund that invests in A.I. \nventures.\nTech investors in China have also pushed for quick turnarounds from A.I., which has meant money has flowed to \neasy-to-execute applications instead of more ambitious goals focused on fundamental research, said Yiran Chen, a \nJohn Cocke Distinguished Professor of Electrical and Computer Engineering at Duke University. As much as 50 \nChina’s Rush to Dominate A.I. Comes With a Twist: It Depends on U.S. Technology\npercent of China’s A.I. investment has gone into computer vision technology, which is required for surveillance, \ninstead of building foundation models for generative A.I., he said.\nNow Baidu, Alibaba, the dairy company Mengniu and the tutoring firm TAL Education have all jumped into the \ngenerative A.I. race in China, leading Chinese media to coin the phrase “the battle of 100 models” to describe the \nfrenzy.\nSome have criticized the free-for-all as publicity stunts that add unnecessary competition. In a panel discussion last \nyear, Robin Li, Baidu’s chief executive, described having hundreds of basic A.I. models as a waste.\n“More resources should be allocated to applications in various industries, especially considering the limitations on \nour computing power,” he said.\nSuccess has been elusive. When Baidu introduced its chatbot, Ernie, in March, the “live” demonstration was \nrevealed to be prerecorded. Baidu’s stock plummeted 10 percent that day.\nDespite the setback, Baidu remains one of China’s few major efforts at building a foundation A.I. model from \nscratch. Others are being led by Alibaba and Tencent, China’s tech giants, as well as a start-up linked to Tsinghua \nUniversity.\nA Baidu spokesman declined to comment.\nU.S. restrictions on A.I. chip sales to China pose further challenges, since many such chips are needed when \ntraining generative A.I. models. Baidu and 01.AI, among others, have said they’ve stockpiled enough chips to \nsustain their operations in the near future.\nThere are some bright spots for China with A.I., including in fields like computer vision and autonomous vehicles. \nSome Chinese entrepreneurs are also looking to leapfrog the United States with breakthroughs in other parts of \ngenerative A.I.\nWang Changhu, the former head of ByteDance’s A.I. lab, founded a company called AIsphere in Beijing last year to \nspearhead what he saw as the next major frontier in the technology: video generation. In November, the start-up \nreleased PixVerse, an A.I.-powered generator that can create video from a text description.\n“We forged ahead, building our models from the ground up,” Mr. Wang said. “This gives us a significant edge as \ntrue pioneers in the realm of video generation.”\nThat edge may have lasted just a few months. Last week, OpenAI unveiled Sora, an A.I. tool that turns a simple text \nprompt into videos that look as if they were lifted from a Hollywood movie. Sora instantly went viral.\nPHOTO: The Chinese firm 01.AI was founded by technologist Kai-Fu Lee, left. It was built on Meta’s technology, \nbut trained with new data to make it powerful. (PHOTOGRAPH BY YAN CONG FOR THE NEW YORK TIMES) \n(B4) This article appeared in print on page B1, B4.\nLoad-Date: March 3, 2024"
    },
    {
        "file_name": "Los_Angeles_Times_Mar2024",
        "header": "Fake nude images highlight gaps in law",
        "media": "Los Angeles Times",
        "time": "March 3, 2024",
        "section": "MAIN NEWS; Metro Desk; Part A; Pg. 1",
        "length": "1179 words",
        "byline": "Jon Healey",
        "story_text": "Fake nude images highlight gaps in law\nLos Angeles Times\nMarch 3, 2024 Sunday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Metro Desk; Part A; Pg. 1\nLength: 1179 words\nByline: Jon Healey\nBody\nIf an eighth-grader in California shared a nude photo of a classmate with friends without consent, the student could \nconceivably be prosecuted under state laws dealing with child pornography and disorderly conduct.\nIf the photo is an AI-generated deepfake, however, it's not clear that any state law would apply.\nThat's the dilemma facing the Beverly Hills Police Department as it investigates a group of students from Beverly \nVista Middle School who allegedly shared photos of classmates that had been doctored with an artificial-\nintelligence-powered app. According to the district, the images used real faces of students atop AI-generated nude \nbodies.\nLt. Andrew Myers, a spokesman for the Beverly Hills police, said no arrests have been made and the investigation \nis continuing.\nBeverly Hills Unified School District Supt. Michael Bregy said the district's investigation into the episode is in its final \nstages.\n\"Disciplinary action was taken immediately and we are pleased it was a contained, isolated incident,\" Bregy said in \na statement, although no information was disclosed about the nature of the action, the number of students involved \nor their grade level.\nHe called on Congress to prioritize the safety of children in the U.S., adding that \"technology, including AI and \nsocial media, can be used incredibly positively, but much like cars and cigarettes at first, if unregulated, they are \nutterly destructive.\"\nWhether the fake nudes amount to a criminal offense, however, is complicated by the technology involved. Federal \nlaw includes computer-generated images of identifiable people in the prohibition on child pornography. Although the \nprohibition seems clear, legal experts caution that it has yet to be tested in court.\nCalifornia's child pornography law does not mention artificially generated images. Instead, it applies to any image \nthat \"depicts a person under 18 years of age personally engaging in or simulating sexual conduct.\"\nJoseph Abrams, a Santa Ana criminal defense attorney, said an AI-generated nude \"doesn't depict a real person.\" It \ncould be defined as child erotica, he said, but not child porn. And from his standpoint as a defense attorney, he \nsaid, \"I don't think it crosses a line for this particular statute or any other statute.\"\n\"As we enter this AI age,\" Abrams said, \"these kinds of questions are going to have to get litigated.\"\nFake nude images highlight gaps in law\nKate Ruane, director of the free expression project at the Center for Democracy & Technology, said that early \nversions of digitally altered child sexual abuse material superimposed the face of a child onto a pornographic image \nof someone else's body. Now, however, freely available \"undresser\" apps and other programs generate fake bodies \nto go with real faces, raising legal questions that haven't been squarely addressed yet, she said.\nStill, she said, she had trouble seeing why the law wouldn't cover sexually explicit images just because they were \nartificially generated. \"The harm that we were trying to address [with the prohibition] is the harm to the child that is \nattendant upon the existence of the image. That is the exact same here,\" Ruane said.\nThere is another roadblock to criminal charges, though. In both the state and federal cases, the prohibition applies \njust to \"sexually explicit conduct,\" which boils down to intercourse, other sex acts and \"lascivious\" exhibitions of a \nchild's privates.\nThe courts use a six-pronged test to determine whether something is a lascivious exhibition, considering such \nthings as what the image focuses on, whether the pose is natural, and whether the image is intended to arouse the \nviewer. A court would have to weigh those factors when evaluating images that weren't sexual in nature before \nbeing \"undressed\" by AI.\n\"It's really going to depend on what the end photo looks like,\" said Sandy Johnson, senior legislative policy counsel \nof the Rape, Abuse & Incest National Network, the largest anti-sexual-violence organization in the United States. \n\"It's not just nude photos.\"\nThe age of the kids involved wouldn't be a defense against a conviction, Abrams said, because \"children have no \nmore rights to possess child pornography than adults do.\" But like Johnson, he noted that \"nude photos of children \naren't necessarily child pornography.\"\nNeither the Los Angeles County district attorney's office nor the state Department of Justice responded immediately \nto requests for comment.\nState lawmakers have proposed several bills to fill the gaps in the law regarding generative AI. These include \nproposals to extend criminal prohibitions on the possession of child porn and the nonconsensual distribution of \nintimate images (also known as \"revenge porn\") to computer-generated images and to convene a working group of \nacademics to advise lawmakers on \"relevant issues and impacts of artificial intelligence and deepfakes.\"\nMembers of Congress have competing proposals that would expand federal criminal and civil penalties for the \nnonconsensual distribution of AI-generated intimate imagery.\nAt Tuesday's meeting of the district Board of Education, Dr. Jane Tavyev Asher, director of pediatric neurology at \nCedars-Sinai, called on the board to consider the consequences of \"giving our children access to so much \ntechnology\" in and out of the classroom.\nInstead of having to interact and socialize with other students, Asher said, students are allowed to spend their free \ntime at the school on their devices. \"If they're on the screen all day, what do you think they want to do at night?\"\nResearch shows that for children under age 16, there should be no social media use, she said. Noting how the \ndistrict was blindsided by the reports of AI-generated nudes, she warned, \"There are going to be more things that \nwe're going to be blindsided by, because technology is going to develop at a faster rate than we can imagine, and \nwe have to protect our children from it.\"\nBoard members and Bregy all expressed outrage at the meeting about the images. \"This has just shaken the \nfoundation of trust and safety that we work with every day to create for all of our students,\" Bregy said, although he \nadded, \"We have very resilient students, and they seem happy and a little confused about what's happening.\"\n\"I ask that parents continuously look at their [children's] phones, what apps are on their phones, what they're \nsending, what social media sites that they're using,\" he said. These devices are \"opening the door for a lot of new \ntechnology that is appearing without any regulation at all.\"\nFake nude images highlight gaps in law\nBoard member Rachelle Marcus noted that the district has barred students from using their phones at school, \"but \nthese kids go home after school, and that's where the problem starts. We, the parents, have to take stronger control \nof what our students are doing with their phones, and that's where I think we are failing completely.\"\n\"The missing link at this point, from my perspective, is the partnership with the parents and the families,\" board \nmember Judy Manouchehri said. \"We have dozens and dozens of programs that are meant to keep your kids off \nthe phones in the afternoon.\"\nGraphic\n \nPHOTO: SECURITY GUARDS stand outside Beverly Vista Middle School last week. A group of students at the \nschool allegedly shared fake nude photos of classmates that had been doctored with an AI-powered app.  \nPHOTOGRAPHER:Jason Armond Los Angeles Times \nLoad-Date: March 3, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Elon Musk vs OpenAI and Curious Case of Sour Grapes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 4, 2024",
        "section": "STARTUPS & TECH",
        "length": "379 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Elon Musk vs OpenAI and Curious Case of Sour Grapes\nEconomic Times (E-Paper Edition)\nMarch 5, 2024 Tuesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 379 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: ET explains the reasons behind Elon Musk’s suit against AI firm\nBody\nET EXPLAINER\nNew Delhi: Billionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI — a company he \nhelped found — and its chief executive Sam Altman. What’s behind the sparring? ET explains. \nWhat does Musk’s lawsuit say? The lawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from \nits original not-for-profit mission of building open-source artificial intelligence (AI) for the good of humanity, working \nnow to ‘maximise profits’ for its major investor Microsoft. Musk sought that the court direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual,  Reuters reported. His \nlawyers argued there was a breach of contract as OpenAI had agreed not to commercialise any product that its \nboard considered artificial general intelligence (AGI). Microsoft, which joined the board last November following \nAltman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model could be viewed as \nearly AGI.  Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment now totals $13 \nbillion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits until it makes  \nback the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported. How did OpenAI \nrespond? OpenAI has said it ‘categorically disagrees’ with the lawsuit, in an internal memo to employees, \nBloomberg reported. Its chief strategy officer Jason Kwon in the memo said that OpenAI is independent and \ncompetes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a ‘de facto subsidiary’ \nof the software giant.  Altman called Musk a hero of his, adding he misses the person he knew who competed with \nothers by building better technology, Bloomberg reported citing a separate memo. What was Musk’s involvement in \nOpenAI? Musk cofounded OpenAI as a non-profit when approached by Altman in 2015. He however exited the \nboard in 2018, citing a conflict of interest with his other company Tesla. He is no longer involved in the startup. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: March 4, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Elon Musk vs OpenAI and Curious Case of Sour Grapes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 4, 2024",
        "section": "STARTUPS & TECH",
        "length": "379 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Elon Musk vs OpenAI and Curious Case of Sour Grapes\nEconomic Times (E-Paper Edition)\nMarch 5, 2024 Tuesday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 379 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: ET explains the reasons behind Elon Musk’s suit against AI firm\nBody\nET EXPLAINER\nNew Delhi: Billionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI — a company he \nhelped found — and its chief executive Sam Altman. What’s behind the sparring? ET explains. \nWhat does Musk’s lawsuit say? The lawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from \nits original not-for-profit mission of building open-source artificial intelligence (AI) for the good of humanity, working \nnow to ‘maximise profits’ for its major investor Microsoft. Musk sought that the court direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual,  Reuters reported. His \nlawyers argued there was a breach of contract as OpenAI had agreed not to commercialise any product that its \nboard considered artificial general intelligence (AGI). Microsoft, which joined the board last November following \nAltman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model could be viewed as \nearly AGI.  Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment now totals $13 \nbillion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits until it makes  \nback the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported. How did OpenAI \nrespond? OpenAI has said it ‘categorically disagrees’ with the lawsuit, in an internal memo to employees, \nBloomberg reported. Its chief strategy officer Jason Kwon in the memo said that OpenAI is independent and \ncompetes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a ‘de facto subsidiary’ \nof the software giant.  Altman called Musk a hero of his, adding he misses the person he knew who competed with \nothers by building better technology, Bloomberg reported citing a separate memo. What was Musk’s involvement in \nOpenAI? Musk cofounded OpenAI as a non-profit when approached by Altman in 2015. He however exited the \nboard in 2018, citing a conflict of interest with his other company Tesla. He is no longer involved in the startup. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: March 4, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Elon Musk vs OpenAI and Curious Case of Sour Grapes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 4, 2024",
        "section": "STARTUPS & TECH",
        "length": "379 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Elon Musk vs OpenAI and Curious Case of Sour Grapes\nEconomic Times (E-Paper Edition)\nMarch 5, 2024 Tuesday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 379 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: ET explains the reasons behind Elon Musk’s suit against AI firm\nBody\nET EXPLAINER\nNew Delhi: Billionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI — a company he \nhelped found — and its chief executive Sam Altman. What’s behind the sparring? ET explains. \nWhat does Musk’s lawsuit say? The lawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from \nits original not-for-profit mission of building open-source artificial intelligence (AI) for the good of humanity, working \nnow to ‘maximise profits’ for its major investor Microsoft. Musk sought that the court direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual,  Reuters reported. His \nlawyers argued there was a breach of contract as OpenAI had agreed not to commercialise any product that its \nboard considered artificial general intelligence (AGI). Microsoft, which joined the board last November following \nAltman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model could be viewed as \nearly AGI.  Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment now totals $13 \nbillion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits until it makes  \nback the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported. How did OpenAI \nrespond? OpenAI has said it ‘categorically disagrees’ with the lawsuit, in an internal memo to employees, \nBloomberg reported. Its chief strategy officer Jason Kwon in the memo said that OpenAI is independent and \ncompetes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a ‘de facto subsidiary’ \nof the software giant.  Altman called Musk a hero of his, adding he misses the person he knew who competed with \nothers by building better technology, Bloomberg reported citing a separate memo. What was Musk’s involvement in \nOpenAI? Musk cofounded OpenAI as a non-profit when approached by Altman in 2015. He however exited the \nboard in 2018, citing a conflict of interest with his other company Tesla. He is no longer involved in the startup. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: March 4, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Elon Musk vs OpenAI and Curious Case of Sour Grapes",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 4, 2024",
        "section": "STARTUPS & TECH",
        "length": "379 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Elon Musk vs OpenAI and Curious Case of Sour Grapes\nEconomic Times (E-Paper Edition)\nMarch 5, 2024 Tuesday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 379 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: ET explains the reasons behind Elon Musk’s suit against AI firm\nBody\nET EXPLAINER\nNew Delhi: Billionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI — a company he \nhelped found — and its chief executive Sam Altman. What’s behind the sparring? ET explains. \nWhat does Musk’s lawsuit say? The lawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from \nits original not-for-profit mission of building open-source artificial intelligence (AI) for the good of humanity, working \nnow to ‘maximise profits’ for its major investor Microsoft. Musk sought that the court direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual,  Reuters reported. His \nlawyers argued there was a breach of contract as OpenAI had agreed not to commercialise any product that its \nboard considered artificial general intelligence (AGI). Microsoft, which joined the board last November following \nAltman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model could be viewed as \nearly AGI.  Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment now totals $13 \nbillion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits until it makes  \nback the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported. How did OpenAI \nrespond? OpenAI has said it ‘categorically disagrees’ with the lawsuit, in an internal memo to employees, \nBloomberg reported. Its chief strategy officer Jason Kwon in the memo said that OpenAI is independent and \ncompetes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a ‘de facto subsidiary’ \nof the software giant.  Altman called Musk a hero of his, adding he misses the person he knew who competed with \nothers by building better technology, Bloomberg reported citing a separate memo. What was Musk’s involvement in \nOpenAI? Musk cofounded OpenAI as a non-profit when approached by Altman in 2015. He however exited the \nboard in 2018, citing a conflict of interest with his other company Tesla. He is no longer involved in the startup. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: March 4, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "ETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes",
        "media": "The Economic Times",
        "time": "March 5, 2024",
        "section": "TECH & INTERNET",
        "length": "583 words",
        "byline": "Annapurna Roy",
        "story_text": "ETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes\nThe Economic Times\nMarch 5, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 583 words\nByline: Annapurna Roy\nBody\nBillionaire Elon Musk last Thursday filed a lawsuit against ChatGPT maker OpenAI – a company he helped to found \n– and its chief executive Sam Altman. What’s behind the sparring? ET explains.What does Musk’s lawsuit say?The \nlawsuit, filed in San Francisco, California, alleges that OpenAI has strayed from its original not-for-profit mission of \nbuilding open-source artificial intelligence (AI) for the good of humanity, working now to ‘maximise profits’ for its \nmajor investor Microsoft.Musk sought that the court direct OpenAI to make its research and technology publicly \navailable and prevent the use of its assets and cutting-edge generative AI models for the financial gains of \nsoftware major and investor Microsoft or any individual, Reuters reported.His lawyers argued there was a breach of \ncontract as OpenAI had agreed not to commercialise any product that its board considered artificial general \nintelligence (AGI). Microsoft, which joined the board last November following Altman’s reinstatement as CEO after \nan ouster, in a paper had said OpenAI's GPT-4 model could be viewed as early AGI.Microsoft first invested $1 \nbillion in the AI startup in 2019. Its multi-year investment now totals $13 billion, $10 billion of which was committed \nlast year. \nMicrosoft is entitled to a 75% share of profits until it makes back the investment and will thereafter get a further 49% \nstake in OpenAI, Fortune reported.How did OpenAI respond?OpenAI has said it ‘categorically disagrees’ with the \nlawsuit, in an internal memo to employees, Bloomberg reported.Its chief strategy officer Jason Kwon in the memo \nsaid that OpenAI is independent and competes directly with Microsoft, pushing back against Musk’s suggestion that \nthe startup is a ‘de facto subsidiary’ of the software giant.Altman called Musk a hero of his, adding he misses the \nperson he knew who competed with others by building better technology, Bloomberg reported citing a separate \nmemo.What was Musk’s involvement in OpenAI?Musk co-founded OpenAI as a non-profit when approached by \nAltman in 2015. He however exited the board in 2018, citing a conflict of interest with his other company Tesla. He \nis no longer involved in the startup.He brought the suit in the capacity of a donor to OpenAI's nonprofit parent \norganisation.Vinod Khosla, founder and managing director of OpenAI backer Khosla Ventures, said on X, “With \n@elonmusk, feels like a bit of sour grapes in suing @OpenAI, not getting in early enough, not staying committed \nand now a rival effort. Like they say if you can't innovate, litigate and that's what we have here.”Musk, who owns \nmicroblogging site X (formerly Twitter), last year launched AI venture xAI which rolled out a ChatGPT rival model \nGrok to premium X subscribers in December. He called it a ‘maximum truth-seeking AI’.From non-profit to ‘capped \nprofit’OpenAI was founded as a non-profit AI research company in 2015. “Our goal is to advance digital intelligence \nin the way that is most likely to benefit humanity as a whole, unconstrained by a need to generate financial return,” \nit had said in a blog then.Four years later, however, it established a ‘capped profit’ arm called OpenAI LP to \n‘increase its ability to raise capital’, it said in a 2019 blog.Under the new structure, returns for OpenAI’s first round of \ninvestors were capped at 100 times their investment, with any excess returns going to the non-profit parent.The \nstartup is now reportedly valued at $80 billion. For Reprint Rights: timescontent.com\nLoad-Date: March 5, 2024\nETtech Explainer: Elon Musk vs OpenAI and the curious case of sour grapes"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "431 words",
        "byline": "By Cade Metz",
        "story_text": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\nThe New York Times\nMarch 5, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 431 words\nByline: By Cade Metz\nBody\nDespite computer shortages, controversies and lawsuits, A.I. continues to improve at a rapid pace.\nThe high-profile A.I. start-up Anthropic released a new version of its Claude chatbot on Monday, saying it \noutperforms other leading chatbots on a range of standard benchmark tests, including systems from Google and \nOpenAI. \n  Dario Amodei, Anthropic's chief executive and co-founder, said the new technology, called Claude 3 Opus, was \nparticularly useful when analyzing scientific data or generating computer code.\n  Anthropic is among a small group of companies at the forefront of generative A.I., technology that instantly \ncreates text, images and sounds. Dr. Amodei and other Anthropic founders helped pioneer the technology while \nworking as researchers at OpenAI, the start-up that launched the generative A.I. boom in late 2022 with the \nrelease of the chatbot ChatGPT.\n  Chatbots like ChatGPT can answer questions, write term papers, generate small computer programs and more. \nThey may also generate false or misleading information, much as people do.\n  When OpenAI released a new version of its technology called GPT-4 last spring, it was widely considered the \nmost powerful chatbot technology used by both consumers and businesses. Google recently introduced a \ncomparable technology, Gemini.\n  But the leading artificial intelligence companies have been distracted by one controversy after another. They say \nthe computer chips needed to build A.I. are in short supply. And they face countless lawsuits over the way they \ngather digital data, another ingredient essential to the creation of A.I. (The New York Times has sued Microsoft and \nOpenAI over use of copyrighted work.)\n  Still, the technology continues to improve at a remarkable pace.\n  Anthropic claims that its Claude 3 Opus technology outperforms both GPT-4 and Gemini in mathematical problem \nsolving, computer coding, general knowledge and other areas.\n  Claude 3 Opus was available starting Monday to consumers who pay $20 per month for a subscription. A less \npowerful version, called Claude 3 Sonnet, is available for free.\n  The company allows businesses to build their own chatbots and other services using the Opus and Sonnet \ntechnologies.\nA.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\n  Both versions of the technology can respond to images as well as text. These can analyze a flowchart, for \ninstance, or solve a math problem that includes diagrams and graphs.\n  But the technology cannot generate images. Google recently suspended Gemini's ability to generate human faces \nafter it produced images showing people of color in German military uniforms from World War II.\nhttps://www.nytimes.com/2024/03/04/technology/anthropic-claude-openai-google.html\nGraphic\n \nPHOTO: Dario Amodei, Anthropic's chief executive. The company released a new version of its Claude chatbot on \nMonday. (PHOTOGRAPH BY MASSIMO BERRUTI FOR THE NEW YORK TIMES) This article appeared in print on \npage B4.               \nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "How to use AI in the workplace? Ask HR",
        "media": "USA Today Online",
        "time": "March 5, 2024",
        "section": "HUMAN RESOURCES NEWS",
        "length": "934 words",
        "byline": "Johnny C. Taylor Jr.",
        "story_text": "How to use AI in the workplace? Ask HR\nUSA Today Online\nMarch 5, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: HUMAN RESOURCES NEWS\nLength: 934 words\nByline: Johnny C. Taylor Jr.\nBody\nLink to Image\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader’s Guide to Work in an Age of Upheaval.”\nHave a question?Submit it here.\nQuestion: My job does not have a policy for the use of artificial intelligence. I started regularly using \ngenerative AI in my work but have yet to tell my boss. Should I let him know that I use ChatGPT for work? – \nCaleb\nAnswer: Absolutely, it's crucial to communicate with your boss about your use of generative AI tools like ChatGPT \nfor work, even if there isn't a formal AI policy in place at your workplace. Here are a few points to consider when \ndiscussing this with your boss:\n￿ Data security: Address the issue of data security upfront. Underscore that while generative AI is a valuable tool, \nyou are mindful of the sensitivity of the information it processes. Assure your boss you will refrain from entering \nproprietary or confidential information into ChatGPT and are willing to turn off chat history to uphold data security if \nrequested.\n￿ Misinformation verification: Acknowledge the potential for discrepancies in the information provided by AI tools. \nEmphasize your understanding of the significance of verifying any information obtained via generative AI to ensure \naccuracy. This commitment to fact-checking will help maintain the reliability of the work you produce.\n￿ Overreliance on AI: Address the concern of overreliance on generative AI tools. Acknowledge that while AI is a \npowerful aid in generating content, you are cautious to keep it from overshadowing your own authentic voice. Share \nyour approach to using AI as a starting point, incorporating your personal touch, and avoiding a copy-and-paste \nmentality.\n￿ Ethical considerations: Discuss the ethical considerations if you are using AI to influence decisions or products. \nHighlight your awareness of the importance of maintaining ethical standards in your work. Assure your boss you \napproach AI as a supplementary tool and that your decisions align with the company's ethical principles.\n￿ Seek feedback: Express your willingness to receive feedback on your use of AI and inquire if there are specific \ntasks or areas where your boss would like you to apply this technology. This proactive approach demonstrates your \nopenness to collaboration and aligning AI usage with your company's objectives.\nHow to use AI in the workplace? Ask HR\nUltimately, artificial intelligence should complement and elevate human intelligence and capability, not replace it. \nEnsuring your uniquely human intellect and intuition are involved in an operation aided by AI will deliver the best \npossible outcome. By addressing these considerations and having an open conversation with your boss, you not \nonly ensure transparency in your work but also contribute to the ongoing dialogue around AI usage in your \nworkplace. Your proactive approach could even help shape a future AI policy to suit your company's needs and \nvalues. \nIntimidation What is the best way to handle bullying at work? Ask HR\nI’ve never fared well in a group interview. Do you have any tips for the group interview I have coming up? – \nTara\nNavigating group interviews can be challenging, but you can make a positive impact with proper preparation and \nstrategic approaches. Thorough preparation will boost your confidence during the interview.\nBegin with a comprehensive examination of the organization. Understand its values, mission, and recent \nachievements. A sound understanding of the company will help you connect to its goals.\nCompile relevant examples from your experience, skills, and education. Be ready to articulate how you've \novercome challenges in past positions. Practicing with friends or mentors who can provide constructive feedback \nwill bolster your confidence.\nDemonstrate strong networking skills by introducing yourself to group members before the interview begins. \nBuilding a rapport with interviewers and fellow candidates can help alleviate initial anxiety and create a positive \nimpression.\nGroup interviews often focus on teamwork and communication skills. Showcase your ability to collaborate by \nactively participating in group discussions. Emphasize instances where you successfully worked in a team, \nresolving challenges and achieving common goals.\nInvolve the group in your responses by connecting with what other participants have shared. Acknowledge and \nagree with their points when it makes sense. This demonstrates active listening skills and your ability to collaborate \nand build on others' ideas.\nTake note of what others are saying to avoid repetitive points. Look for opportunities to add a nuanced angle or \nexpand on ideas to move the discussion forward. This showcases your ability to think critically and build on existing \nideas.\nStay engaged throughout the group interview. Maintain eye contact, nod affirmatively, and use nonverbal cues to \nshow attentiveness. Avoid distractions and actively participate in group activities or discussions.\nShape your responses to align with the organizational objectives and job role. Have a clear understanding of the \nvalue you can bring to the company culture and the team. Remember to be authentic and distinct, allowing your \nunique qualities to shine.\nBy implementing these tips and staying well-prepared, you can confidently navigate your group interview and make \na positive impression.\nNo raise? How do I ask for a cost-of-living adjustment? Ask HR\nThis article originally appeared on USA TODAY: How to use AI in the workplace? Ask HR\nLoad-Date: March 5, 2024\nHow to use AI in the workplace? Ask HR"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "How A.I. Is Remodeling the Fantasy Home; Critic’s Notebook",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "ARTS; design",
        "length": "1977 words",
        "byline": "Amanda Hess Amanda Hess is a critic at large for the New York Times. She writes about internet and pop",
        "story_text": "How A.I. Is Remodeling the Fantasy Home; Critic’s Notebook\nThe New York Times \nFebruary 4, 2024 Sunday 10:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: ARTS; design\nLength: 1977 words\nByline: Amanda Hess Amanda Hess is a critic at large for the New York Times. She writes about internet and pop \nculture for the Arts section and contributes regularly to The New York Times Magazine.\nHighlight: Amid an intractable real estate crisis, fake luxury houses offer a delusion of one’s own.\nBody\nAmid an intractable real estate crisis, fake luxury houses offer a delusion of one’s own.\nI was scrolling through Instagram recently when I found a new page slipped into my feed through a suggested post: \n@tinyhouseperfect. It seemed designed to poke at my frustrated longings for a space of my own. I want to own a \nhouse; I cannot currently buy a house. But what if the house were very small? Very small, and also perfect?\nSoon I was navigating the reading nooks and chef’s kitchens of an elfin cottage, a gothic coastal A-frame, a cozy \n“loch house” in the Scottish Highlands. I had projected my future self to the Scottish seaside, wondering how much \nthe house might cost to rent for a weekend, when I realized that price was no object because the house did not \nexist. Each of these teensy homes had been rendered by A.I. software and smoothed with an assist from more A.I. \nsoftware. I had been fantasizing about a fantasy.\nThe nature of these homes was, in retrospect, obvious. Their interiors appeared improbably expansive, offering \nroom after room of curated delights. It’s not hard to imagine why Instagram might boost @tinyhouseperfect’s \ncomputer visions into my sightline. I have not hidden my obsession with homeownership and renovation from the \ninternet’s all-seeing eye. At night I wander between Zillow and D.I.Y. Instagram accounts, stalking the hallways of \nhomes I will never visit, assessing the work of contractor-influencers I will never employ, weighing aesthetic choices \nI will never make. Now artificial intelligence has breached my domestic fantasy, reshaping my desires to fit inside its \nphantom walls.\nIn recent years, a whole A.I. dream-house economy has materialized. Search Pinterest for décor inspiration, and \nyou’ll find it clogged with artificial bedrooms that lead off to websites hawking cheap home accessories. “House \nporn” accounts on TikTok and X churn out antiseptic loft renderings and impossible views from nonexistent Parisian \napartments. The website “This House Does Not Exist” generates random new homes upon command. And dozens \nof A.I.-powered design services and apps — among them SofaBrain and RoomGPT — churn out slick images \ntuned to your specifications.\nA jangling set of house keys was once synonymous with American success: the striver’s ultimate prize. The misery \nproduced by this idea (see: the Great Recession) has not dampened its allure. Now, thanks to elevated interest \nrates, insufficient supply and corporate landlords snapping up that limited housing stock, homeownership is more \nunrealistic than ever. A.I. houses just make that unreality explicit. In the virtual market, the supply is endless, and \nthe key is always in the lock.\nFrom Nowhere, and Everywhere\nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook\nHousing voyeurism has always encouraged a measure of psychic projection. On TV, the celebrity house tour and \nthe home-improvement program are older than I am. Magazines of aspirational domesticity are older still. In the \n1970s, Architectural Digest transformed from a trade publication into a showcase for publicizing the private spaces \nof what it called “men and women of taste, discrimination and personal achievement.” In the 1980s, viewers of \n“Lifestyles of the Rich and Famous” were prompted to imagine how they might spend their millions if they had them.\nThis was the lousy trade-off of American inequality: The rich got lavish homes, and everyone else got to see the \npictures, and experience the release that comes from judging all of their choices up close. At the end of each \n“Lifestyles” episode, Robin Leach bid his audience “champagne wishes and caviar dreams.”\nThe modern version of “Lifestyles,” the Netflix reality show “Selling Sunset,” focuses not on the people who live in \nHollywood mansions but on the glamorous real estate agents who sell them. As these intensely groomed Realtors \nprep and stage fancy homes, viewers are invited to imagine not living in a mansion, but bringing it under our total \nfinancial and aesthetic control. Artificial intelligence and predictive algorithms only enhance this sensation of \npersonal ownership, making a dream house feel as if it were built just for us.\nThe loch house on @tinyhouseperfect first caught my eye with its glistening waterfront views from vast windows, \nbut when I looked again, I begrudgingly acknowledged that it had also appealed because it seemed to have been \nappointed to suit my personal tastes. There was a claw-foot tub with pewter fixtures, a charmingly messy bookshelf \nwindow-seat, a kitchen painted a cool green. In the place of cabinets, it featured exposed wooden shelves stocked \nwith shapely glass jars of potions and preserves.\nI had thought of the loch house as remote, but really it had come from nowhere, or everywhere. It was crowded with \ndesign touches perfectly synced to the ones cresting on my Instagram and Pinterest feeds. The “personal taste” \nthat drew me in was actually a highly impersonal taste: an aesthetic that dominates my internet browsing so \nthoroughly, it has come to feel like I selected it myself.\nIn “Filterworld: How Algorithms Flattened Culture,” Kyle Chayka describes “the strangely frictionless geography \ncreated by digital platforms” and “the sense of vaporousness and unreality” created by the existence of, say, barely \ndifferentiated hipster coffee shops in every city in the world. This airless sensation has overtaken our collective \nimagination, too, infiltrating the spaces of the mind.\nEven as social media and artificial intelligence bend us toward a ubiquitous megastyle, its products are often \npitched as centers of creativity. An Architectural Digest article on A.I. design tools describes them as offering a \n“fresh perspective” that can “inspire architects” to think “outside the box.” But though A.I. prompts are seemingly \nendless, the results are often eerily banal. Much of the A.I. décor that surfaces on Instagram features the same \nuncanny images: liquid throw blankets, accidentally surreal wall art, hearths lit with inert flames.\nThese renderings are cheap, and yet it feels as if the flattening of design affects the homes of the wealthy most of \nall. I don’t use A.I. software, but I have a little game I play to refocus my housing fixation onto absurd and \nimpractical spaces. I dial up the price settings on the Zillow app so that its map of the city reveals only properties \nthat are listed at over $10 million, over $50 million, over $100 million. As the costs climb, the profiles of potential \nbuyers grow more obscure and mysterious until they do not seem to exist in my world at all, and the tastes on \ndisplay start to look, themselves, mechanically programmed.\nWhen watching old episodes of “Lifestyles and the Rich and Famous” and its spiritual successor, “MTV Cribs,” it’s \nstriking how similar the homes of the wealthy appear. In a 2004 episode of “Cribs,” Snoop Dogg opens the door to \nhis manse, revealing a parlor with granny furniture and a gigantic urn; the room could fit into the home of Debbie \nGibson, profiled on “Lifestyles” in 1993. Now, every property on “Selling Sunset” feels laser cut from the same \nblueprint, every mansion a flat box of ostentatious minimalism. The $195 million Manhattan penthouse currently \nperched atop my Zillow feed is just a gargantuan version of the glass-box look replicated across every luxury condo \nbuilding in New York City.\nA very rich person has the resources to dramatically transform a space in response to trends, lending wealth itself \nan artificial aesthetic. An Architectural Digest tour of Drake’s Toronto mansion looks as if it were designed by a bot, \nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook\nwith its cartoonish proportions, glassy surfaces and random, click-and-paste patterns. And the magazine’s tour of \nthe influencer Emma Chamberlain’s home feels eerily saturated with buzzy designs: the bulbous couch, the egg-\nshaped stone dining table, the wavy velvet chair. Even the unexpected details feel intentionally programmed. Now, \nas I swipe my way through the bedrooms of an A.I.-rendered home, I can produce that same mechanical sensation.\nNo People, No Animals\nThe loch house I coveted was created by Ben Myhre, a Norway-based designer who started conjuring architectural \nconcept art with A.I. software a couple of years ago and posting it to Instagram, where he has accrued more than \n500,000 followers. Unlike some of the uncanny renderings that choke social media, Myhre’s bespoke images take \nmany hours to build, with the help of his own photographs of buildings, the generative A.I. program Midjourney, the \nA.I.-powered photo enhancement program Topaz, and Photoshop. In addition to adorable little houses, he makes \nimages of homes inspired by Harry Potter, Santa Claus and “The Lord of the Rings.”\nI reached out to Myhre and spoke with him over Zoom. “I like to use it to unlock dreams,” he said of artificial \nintelligence, which he sees as a form of “collective imagination that anyone can access.” I was curious about the \ncontours of the imagination animating his dream homes, and he shared some of the prompts he used to create the \nloch house. He guided the software to create a “cozy whimsical house kitchen in the beautiful Scottish highlands,” \none with “window views to a vast scenic loch view with early autumn nature.” He called for “rustic details,” “depth of \nfield,\" “warm tones,” “style raw.” And he asked to banish certain elements: “no people, no animals.”\nNo people, no animals. Part of why Myrhe’s images can seem “real” is because they are created in the style of an \nonline home tour, the kind you might find on Zillow or Airbnb. But I hadn’t totally understood the appeal of his work \nuntil he said those words; the fantasy is of spaces wiped of living things. There is a postapocalyptic feel to the \nhome-sale slide show and its A.I. counterpart. The houses feel urgently abandoned, a book cracked open on the \narmrest, a fire still glowing. When I “toured” the loch house, I was inspecting its shelf of corked jugs, wondering \nwhere the residents had stashed all their practical kitchen items, when I finally realized that there were no residents. \nNothing needed to be cooked for nobody.\nMyhre told me that his images sometimes upset people who were expecting pictures of actual homes. “When \npeople realize they’re not real, they feel a bit tricked,” he said. In his captions, he pleads with those (like \n@tinyhouseperfect) who circulate his work: “Please be sure to credit if you share and clearly label they are \nimaginary A.I. assisted scenes to avoid any misconceptions.”\nBut there is a seduction to the unreality of these images, too. My trips through Zillow are fueled by my jealousy at \nthe actual residents of the homes I can only inhabit with my mind. There is nothing “real” about my fantasy of living \nin places I can’t afford, even as my brain sets to work studying the floor plan and arranging my furniture in its \nrooms. Touring a lavish house, whether it’s on Zillow or “Selling Sunset” or @tinyhouseperfect, distorts my vision in \nanother way: It makes me feel as if I’m lacking something, when I have more than enough.\nNo human lives in the loch house, but increasingly this is also true of real dream homes. Many of New York’s luxury \napartments lie empty. Some are acquired by the ultrarich as assets. They exist to house no one, even as people \nsleep on the streets outside. Home voyeurism has always been a form of misdirection, a glittering diversion from \nour inability, or refusal, to shelter everyone. It coaxes us to think of housing as a lifestyle choice, not a right. A.I. \nhouses complete the trick. They represent housing that is finally freed from any responsibility toward human beings. \nNo shelter, only vibes.\nPHOTOS: PHOTO (C1); A “Scottish Highlands Loch House,” top, a well-appointed “Green Cottage,” center, and a \n“Stone House” sitting area, left, were all conjured with artificial intelligence. (PHOTOGRAPHS BY BEN MYHRE) \n(C6) This article appeared in print on page C1, C6.\nLoad-Date: March 5, 2024\nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GenAI Firm Ema Raises $25 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "176 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "GenAI Firm Ema Raises $25 million\nEconomic Times (E-Paper Edition)\nMarch 6, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 176 words\nByline: Tarush.Bhalla@timesinternet.in\nHighlight: Accel, Section 32 and Prosus lead round\nBody\nBengaluru: Enterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 \nmillion (about Rs 207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.  Wipro Ventures, \nVenture Highway, Frontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in \nthis round of funding. Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl \nSandberg, Yahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the \nstartup. Ema will use the funds for research and development, building new offerings and enhancing its existing \nproduct suite, the company said, adding that it will also utilise part of the proceeds for building its go-to-market \nfunction. At present, Ema has a total workforce of 30, spread across India and the US. Ema stands for Enterprise \nMachine Assistant and allows enterprises to build generative AI personas and applications internally to bring about \nautomation and increase efficiency and productivity.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GenAI Firm Ema Raises $25 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "176 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "GenAI Firm Ema Raises $25 million\nEconomic Times (E-Paper Edition)\nMarch 6, 2024 Wednesday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 176 words\nByline: Tarush.Bhalla@timesinternet.in\nHighlight: Accel, Section 32 and Prosus lead round\nBody\nBengaluru: Enterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 \nmillion (about Rs 207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.  Wipro Ventures, \nVenture Highway, Frontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in \nthis round of funding. Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl \nSandberg, Yahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the \nstartup. Ema will use the funds for research and development, building new offerings and enhancing its existing \nproduct suite, the company said, adding that it will also utilise part of the proceeds for building its go-to-market \nfunction. At present, Ema has a total workforce of 30, spread across India and the US. Ema stands for Enterprise \nMachine Assistant and allows enterprises to build generative AI personas and applications internally to bring about \nautomation and increase efficiency and productivity.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GenAI Firm Ema Raises $25 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "176 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "GenAI Firm Ema Raises $25 million\nEconomic Times (E-Paper Edition)\nMarch 6, 2024 Wednesday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 176 words\nByline: Tarush.Bhalla@timesinternet.in\nHighlight: Accel, Section 32 and Prosus lead round\nBody\nBengaluru: Enterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 \nmillion (about Rs 207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.  Wipro Ventures, \nVenture Highway, Frontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in \nthis round of funding. Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl \nSandberg, Yahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the \nstartup. Ema will use the funds for research and development, building new offerings and enhancing its existing \nproduct suite, the company said, adding that it will also utilise part of the proceeds for building its go-to-market \nfunction. At present, Ema has a total workforce of 30, spread across India and the US. Ema stands for Enterprise \nMachine Assistant and allows enterprises to build generative AI personas and applications internally to bring about \nautomation and increase efficiency and productivity.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GenAI Firm Ema Raises $25 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "176 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "GenAI Firm Ema Raises $25 million\nEconomic Times (E-Paper Edition)\nMarch 6, 2024 Wednesday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 176 words\nByline: Tarush.Bhalla@timesinternet.in\nHighlight: Accel, Section 32 and Prosus lead round\nBody\nBengaluru: Enterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 \nmillion (about Rs 207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.  Wipro Ventures, \nVenture Highway, Frontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in \nthis round of funding. Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl \nSandberg, Yahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the \nstartup. Ema will use the funds for research and development, building new offerings and enhancing its existing \nproduct suite, the company said, adding that it will also utilise part of the proceeds for building its go-to-market \nfunction. At present, Ema has a total workforce of 30, spread across India and the US. Ema stands for Enterprise \nMachine Assistant and allows enterprises to build generative AI personas and applications internally to bring about \nautomation and increase efficiency and productivity.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "GenAI startup Ema secures $25 million in funding led by Accel, Prosus",
        "media": "The Economic Times",
        "time": "March 5, 2024",
        "section": "FUNDING",
        "length": "621 words",
        "byline": "Tarush Bhalla",
        "story_text": "GenAI startup Ema secures $25 million in funding led by Accel, Prosus\nThe Economic Times\nMarch 5, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 621 words\nByline: Tarush Bhalla\nBody\nEnterprise-led generative artificial intelligence (AI) solutions provider Ema said it has raised $25 million (about Rs \n207.2 crore) from investors led by Accel, Section 32 and Prosus Ventures.Wipro Ventures, Venture Highway, \nFrontier Ventures, MAUM Group, AME Cloud Ventures and Firebolt Ventures also participated in this round of \nfunding.Prominent names in the Silicon Valley, including former Meta chief operating officer Sheryl Sandberg, \nYahoo co-founder Jerry Yang and Snowflake chief executive Sridhar Ramaswamy, also backed the startup.Ema \nwill use the funds for research and development, to build new offerings and enhance its existing product suite, the \ncompany said, adding that it will also utilise part of the proceeds for building its go-to-market function.At present, \nEma has a total workforce of 30, spread across India and the US.Founded in March 2023 by former Google \nemployees Souvik Sen and Surojit Chatterjee, Ema stands for Enterprise Machine Assistant and allows enterprises \nto build generative AI personas and applications internally to bring about automation and increase efficiency and \nproductivity.The AI system is built to engage in conversations, comprehend context, take continuous human \nfeedback, reason and make informed decisions while maintaining accuracy and collaborating with human \nemployees.“We have seen that there is excitement amongst our customers as they can easily create newer \napplications and personas with Ema to address their business needs within hours,” Surojit Chatterjee, chief \nexecutive of Ema, told ET. \n“While building a gen AI application businesses have to do the heavy lifting around data orchestration, data \nprotection, model selection and training the model, which enterprise solutions like Ema can help avoid and remove \nmonths’ worth of effort.”The company charges based on the successful tasks completed by the AI system, \nChatterjee said. Enterprises are deploying Ema across customer support, legal, sales, compliance as well as HR \nand IT functions, he said.He declined to comment on the total enterprises the AI startup is servicing but said it \ncounts fintechs Moneyview in India and TrueLayer in Europe among its customers.“We have at least 12 customers \nwhich are at late-stage deployment of our AI suite… Our existing clients are using Ema for at least two-three use \ncases,” said Chatterjee.Ema leverages about 30 large public language models, including GPT 4, GPT-3.5-turbo, \nClaude 2.1, Gemini, Mistral-S and Llama2, and small in-house language models to avoid hallucinations and \nmaintain accuracy.“GenAI has the potential to unlock unprecedented efficiency in enterprises, which CXOs globally \nhave very well recognised. To actually enable it at scale will require seamless collaboration between human and AI \nemployees. We are excited to back this team in their pursuit for efficiency and innovation,” said Subrata Mitra, \npartner at Accel.Prior to founding Ema, Chatterjee served as chief product officer at Coinbase and founded the \nmobile ads team at Google. He was also the head of product at ecommerce firm Flipkart.Sen was the vice president \nof engineering at identity startup Okta and served as engineering lead at Google.“Ema is leading the next frontier of \nGenerative AI for enterprises with a vision to drive efficiency across all business areas. This will lead to enterprise-\nwide productivity gains. It is a hard problem but, once solved, will be transformative,” said Ashutosh Sharma, head \nof investments, India at Prosus Ventures.According to the company, the Ema AI suite can be connected to 200 \nsoftware applications that enterprises use such as Salesforce and Workday to power more AI-led use-cases \ninternally.  For Reprint Rights: timescontent.com\nGenAI startup Ema secures $25 million in funding led by Accel, Prosus\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Can AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks",
        "media": "USA Today Online",
        "time": "March 5, 2024",
        "section": "TECH LATEST",
        "length": "1546 words",
        "byline": "Jennifer Jolly",
        "story_text": "Can AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nUSA Today Online\nMarch 5, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST\nLength: 1546 words\nByline: Jennifer Jolly\nBody\nHave you used artificial intelligence in your daily life yet? I just asked that question in a room of ten people ranging \nfrom 35 to 85 years old.\nOnly one person – aside from me – had used an AI chatbot like OpenAI’s ChatGPT, Google’s Bard (now renamed \nGemini), Bing Chat (now called Copilot), or any of the others that cropped up over the last year. \nThe person who had used it updated her professional bio through prompts on the free version of ChatGPT. It was \nshort and sweet she said, and did a fine job crafting an adequate professional history for what she needed. \nHow can I use AI in my daily routine? \nMy casual little poll of the people in a room aligns with what we’re seeing from many more scientific studies and \nresearch nationwide – most people have heard of generative AI, few have used it (that they know of), and a \nmajority of people don’t trust it.\nAs most chatbots will tell you, it’s good to be skeptical at this point. It’s still really early days for new consumer AI \ntech tools, and they can be glitchy and filled with misinformation. \nAs long as you know these limitations going in and incorporate a few pro tips, there are some super helpful ways \nwe can use those tools right now. \nLink to Image\nMeal Planning \nMeal planning is a fan favorite. Tell your AI chatbot what you have in the refrigerator, and let it come back with a \nrecipe. Or use it to help you plan dinners and buy groceries based on dietary restrictions. \nYou can also do the same thing with cocktails, as I just found out while on vacation in Costa Rica. \nMy niece, Megan Blelloch, 27, says meal planning is “the most helpful way to use AI right now.” Blelloch says she \nuses AI to suggest meals too.\n“I have ChatGPT find recipes … or I'll import my spreadsheet of cataloged recipes,'' she says. \"You can also use \nanything found online with the right prompt, such as ‘Prepare a week's worth of healthy three-course meals with \nrecipes from Ina Garten,’ and it should populate a good answer. Then, you can have it populate a chart and a \ngrocery list, organized by category.”\nLink to Image\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nNicole Mora, a 46-year-old communications professional, agrees AI chatbots can be a big help when health \nconcerns are involved too.\n“I use it because my mother-in-law has three different health conditions/autoimmune issues and is limited (in) things \nshe can eat. So, I put in the three conditions and asked what foods are safe, then asked for recipes and a shopping \nlist.”\nAlso, if you ask ChatGPT to provide this information in “table format,” it generates a nice list you can use for other \nprograms like Microsoft Excel.\nLink to Image\nPRO TIP: You might not get good results with recipes if you ask a vague or confusing question. Use prompts that \nsound like you’re talking with a real person and make them as detailed as possible with your personal preferences.\nFor example, instead of asking for “a recipe for chicken,” say, \"Can you give me a recipe for quick Thai curry \nchicken that uses coconut milk, tofu, and whatever vegetables are in season? I'm an intermediate cook looking for \nsomething I can make in under 30 minutes using a single pot.”\nTrip planning\nDid I mention I was recently in Costa Rica? I used Copilot to generate a last-minute packing list to whittle down my \noverstuffed luggage while not forgetting anything important. It reminded me to take mosquito repellent, my open-\nwater swim goggles and to leave my jacket and dress shoes behind. \nThis isn’t earth-shattering, but it did the job I needed it to do quickly and efficiently. Five days into my 10-day trip, I \nfelt really good about not overpacking (for a change), yet still having everything I needed.  \nBlelloch also uses it quite a bit for travel ideas. “I did a test run for our five-day trip to London in July, and it was \npretty close to our actual itinerary,'' she says. \"The restaurant recs were pretty good (and can be tailored based on \nprice and preference), so if you are going somewhere new and have no idea where to start, give AI a chance. It can \nrecommend literally everything.”\nPRO TIP: Have you heard about AI’s “hallucination” problem? That’s when AI makes up something but presents it \nas a fact. \nThat happened when I tried ChatGPT to help with a camping-based road trip itinerary last fall. It failed miserably, \nespecially when asked to locate dispersed camping on BLM land, which was my main reason for using it. \nLink to Image\nI’ve recently gotten much better results using paid versions of all three of my go-to’s – ChatGPT4, Gemini, and \nCopilot, and asking the chatbots to incorporate suggestions from trusted travel sites such as Lonely Planet, The \nPoints Guy, and Outside Magazine (specifically because I like more adventure travel). Each chatbot costs about \n$20 a month after a free trial period. \nLink to Image\nJob interviewing \nAs much as we fear losing jobs to AI, Blelloch says chatbots have been incredibly useful on the job-hunter side too.  \n“When I was interviewing for jobs, I cut and pasted the job description and my resume into ChatGPT and had AI \ncreate a list of interview questions. It was really helpful because (the potential questions) were tailored to the \nposition and my resume.”\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nBlelloch also used ChatGPT to help with an early first draft of a cover letter and to critique her resume based on \nspecific job descriptions. “These needed heavy editing, obviously,” she added, “but they used all the keywords that \nan AI would look for on the receiving end, and I got more interviews than I did when I was writing cover letters (from \nscratch).” \nPRO TIP: Be sure to try out your job interview responses with your AI chatbot and ask it to rate your responses as if \nit were the hiring manager.\nDon’t memorize the AI responses because they aren’t human (duh), but instead use them to help brainstorm and \npractice. That way, when you get the inevitable question, “What’s your biggest weakness?” you’ll have a better \nanswer than, “I work too hard.”\nCreating family activities \nAI chatbots tend to be good at brainstorming and bad at “facts.” Still, it’s excellent for developing new ways to \nengage, entertain, and educate kids. \nLast summer, San Diego PR strategist Lorena Ruggero used ChatGPT to create a “golden hour” curriculum for her \n12-year-old son. \n“He's academically advanced, and I wanted to keep him engaged in something mentally stimulating instead of \nplaying video games and watching YouTube all day,” Ruggero explained.\nHer son's teacher recommended a “golden hour” plan, which is the idea behind helping students pursue a topic \nthey're interested in for an hour each day. “He shared some interest in stop-motion animation with Legos and his \niPad, so I used OpenAI to create an eight-week ‘golden hour’ curriculum for him to learn how to create a stop-\nmotion Lego film,” Ruggero said. \nAlong these same lines, chatbots are solid for helping you write code or for grammar checks. It does best with \ncreativity and worse with factual information. Like any tool, you must learn to use it. It will only go well if you know \nwhat you're doing. \nPRO TIP: Use your chatbot to write and create with you versus for you. \nYour chatbot gets better the more it learns from you over time. If you don’t get the results you want with the first \nprompt, give it more information and keep asking. If you’re creating a curriculum for a specific child or even using it \nto help you write a speech, ask it to “interview” you to get all of the information it needs to do the best job it can. In \nother words, help the tool help you.\nIt’s a new way to think using your tech – and it actually works. \nArguing and negotiation\nMy family has a lot of “spirited debates.” These aren’t contentious arguments by any stretch but rather \nconversations around topics we have a lot of feelings about. Like sunscreen. \nOn the family trip to Costa Rica, one of my relatives argued that “child-safe sunscreen” with zinc oxide is bad for \ntoddlers, full stop. My position was that it’s better than a sunburn. Simple, right?\nClearly, you’ve not been in one of my family discussions. \nTo have a more productive conversation around this issue without getting mad about it, I needed a few specific \ntalking points to help get my point across without attacking, upsetting, or alienating my family members. (I’m not \nalways good about that last part.)\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nI used a ChatGPT plug-in tool called Negotiator to help create some compelling points in favor of sunscreen while \nnot getting too emotional around the debate. \nRemember, chatbots can be great for ideas and bad for facts, so I used other sources for scientific research and \nmedical guidelines. But this was a fabulous tool for helping me establish the tone and concise points that could help \nme win the latest family debate without ruffling feathers. \nPRO TIP: This example might be a stretch for most people, but think of using this to help with negotiating a salary \nraise, work exit strategy, car purchase, or something else you care about and need to advocate for. \nJennifer Jolly is an Emmy Award-winning consumer tech columnist and on-air correspondent. \nThe views and opinions expressed in this column are the author's and do not necessarily reflect those of USA \nTODAY. \nContact her at J J@Techish.co m.\nThis article originally appeared on USA TODAY: Can AI help me pack? Tips for using ChatGPT, other chatbots for \ndaily tasks\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "BUSINESS",
        "length": "1135 words",
        "byline": "Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is",
        "story_text": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nThe New York Times \nMarch 4, 2024 Monday 12:48 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1135 words\nByline: Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is \nbased in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nAdam Satariano is a technology correspondent based in Europe, where his work focuses on digital policy and the \nintersection of technology and world affairs.\nHighlight: Apple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nBody\nApple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nApple on Monday was fined 1.8 billion euros ($1.95 billion) by European Union regulators for thwarting competition \namong music streaming rivals, a severe punishment levied against the tech giant in a long-simmering battle over \nthe powerful role it plays as gatekeeper of the App Store.\nThe penalty, announced by the E.U. antitrust regulator, is the culmination of a five-year investigation set in motion \nby one of its biggest rivals, Spotify. Regulators said Apple illegally used its App Store dominance to box out rivals.\n“For a decade, Apple abused its dominant position in the market for the distribution of music streaming apps \nthrough the App Store,” said Margrethe Vestager, the European Commission executive vice president who \noversees competition policy.\n“From now on,” she said in a news conference, “Apple will have to allow music streaming developers to \ncommunicate freely with their own users.” The size of the fine, she added, “reflects both Apple’s financial power and \nthe harm that Apple’s conduct inflicted on millions of European users.”\nThe action by the European Commission, the E.U. executive branch, is the latest in a series of regulations and \npenalties to target the App Store. Most of the disputes are because Apple requires that apps use its in-app payment \nservice for sales. It takes as much as a 30 percent commission on each transaction, a fee that many developers \nsay is excessive.\nRegulators in the Netherlands and South Korea have passed laws or orders to force Apple to allow alternative \npayment services, but Apple has largely disregarded the regulators’ challenges. In those countries  it is allowing \nalternatives but charging a 27 percent commission, a solution that regulators in the countries are contesting.\nApple said it would appeal the ruling. “While we respect the European Commission, the facts simply don’t support \nthis decision,” Apple said in a statement on Monday.\nIn a briefing last month, Apple said that European regulators had been searching for a legal theory for the case for \nnearly a decade, in fits and starts. Apple challenged the idea that Spotify users haven’t been able to subscribe to \nmusic services through other means, saying that Spotify has added more than 100 million subscribers outside its \napp over the past eight years.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nApple also accused Spotify of being a monopolist because it has more than a 50 percent share of Europe’s music \nstreaming business. It said that Spotify has benefited from the software tools that Apple provides, as well as more \nthan 119 billion downloads and updates of its app. It’s done so while not paying Apple any money in commissions.\n“Fundamentally, their complaint is about trying to get limitless access to all of Apple’s tools without paying anything \nfor the value Apple provides,” a spokesman said in a statement.\nSpotify, in a statement, said Monday’s penalty “sends a powerful message — no company, not even a monopoly \nlike Apple, can wield power abusively to control how other companies interact with their customers.” \nThe penalty reinforces the European Union’s position as the world’s most aggressive regulator of the tech sector. In \nrecent years, the bloc has passed laws on data privacy, industry competition, content moderation of online content \nand artificial intelligence. Antitrust regulators have meanwhile investigated or fined Google, Amazon, Microsoft and \nMeta.\nThe fine is the most severe penalty against Apple since 2016, when the European Commission ordered the \ncompany to turn over €13 billion for unpaid taxes to Ireland. In a sign of how long the appeal process can drag out, \nthat case is still winding its way through E.U. courts.\nIn 2022, the 27-nation bloc largely sided with developers in writing the Digital Markets Act that requires Apple to \nopen the iPhone to competing app stores and allow app makers to directly accept payments. The rules go into \neffect Thursday.\nIn its latest quarter, Apple reported revenue of about $120 billion and a net profit of $34 billion.\nLast month, Apple said that it would comply with the new law by giving developers three options. They could stick \nwith the status quo App Store system and continue paying up to a 30 percent commission of sales. Or they could \naccept alternative payments and reduce their commission to 17 percent, while taking on a new charge of 50 euro \ncents on every download above one million. Finally, they could avoid Apple’s commission and distribute through \ncompeting stores, while still paying Apple’s download fee.\nUnder Apple’s plan, Spotify and other apps would be able to tell customers in their app about cheaper subscription \nprices online. \nApple’s proposal for the App Store in Europe has sparked an outcry from developers large and small, who say that \nit fails to abide by both the letter and spirit of the law.\nApple has said that its plan complies with the law, while minimizing the risk iPhone users encounter malware, spam \nor fraud.\nSpotify has been one of Apple’s most vocal critics. For years, the music streaming service has complained that the \nApp Store’s in-app payment system and 30 percent commission has put it at a disadvantage to Apple Music, which \ncan sell subscriptions directly without a similar fee.\nThe rules have also hampered Spotify’s efforts to expand its business into audiobooks and other services. Instead \nof charging for a book in the app, it has tried to avoid Apple’s fees by directing customers outside the app to pay, a \nprocess that it has called cumbersome and difficult.\nApple says that Spotify’s decision to link to its website means that it doesn’t pay for many of the services that \nbenefit the music streaming service, including software tools and hardware improvements like advanced media \nplayback. It also complained that Spotify met with European regulators more than 60 times during the course of the \ninvestigation.\nDaniel Ek, Spotify’s chief executive, has complained for years about the slow pace of Europe’s investigation. \nThroughout the process, he pointed out ways that Apple’s control over the App Store disadvantaged competitors.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\n“Without policymakers taking action, nothing will change,” Mr. Ek wrote in 2022 on X, the site formerly known as \nTwitter. “I can’t be the only one who sees the absurdity.”\nMonika Pronczuk contributed reporting from Brussels.\nMonika Pronczuk contributed reporting from Brussels. \nPHOTOS: The Digital Markets Act requires Apple to open the iPhone to competing app stores and allow direct \npayments. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES); Apple “abused its \ndominant position in the market,” said Margrethe Vestager, an executive vice president. (PHOTOGRAPH BY \nOLIVIER HOSLET/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in print on page B1, B4.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "adopters_of_AI's_next_wave;_Making_instant_videos_is_the_next_wave_of_Mar2024",
        "header": "Do AI video-generators dream of San Pedro? Madonna among early",
        "media": "adopters of AI's next wave; Making instant videos is the next wave of",
        "time": "March 5, 2024",
        "section": "NATION WORLD",
        "length": "1183 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Do AI video-generators dream of San Pedro? Madonna among early \nadopters of AI's next wave; Making instant videos is the next wave of \ngenerative artificial intelligence, much like chatbots and image-generators \nbefore it\nDayton Daily News (Ohio)\nMarch 4, 2024 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1183 words\nByline: MATT O'BRIEN\nBody\nWhenever Madonna sings the 1980s hit \"La Isla Bonita\" on her concert tour, moving images of swirling, sunset-\ntinted clouds play on the giant arena screens behind her.\nTo get that ethereal look, the pop legend embraced a still-uncharted branch of generative artificial intelligence – \nthe text-to-video tool. Type some words  say, \"surreal cloud sunset\" or \"waterfall in the jungle at dawn\"  and an \ninstant video is made. \nFollowing in the footsteps of AI chatbots and still image-generators, some AI video enthusiasts say the emerging \ntechnology could one day upend entertainment, enabling you to choose your own movie with customizable story \nlines and endings. But there's a long way to go before they can do that, and plenty of ethical pitfalls on the way. \nFor early adopters like Madonna, who's long pushed art's boundaries, it was more of an experiment. She nixed an \nearlier version of \"La Isla Bonita\" concert visuals that used more conventional computer graphics to evoke a tropical \nmood. \n\"We tried CGI. It looked pretty bland and cheesy and she didn't like it,\" said Sasha Kasiuha, content director for \nMadonna's Celebration Tour that continues through late April. \"And then we decided to try AI.\" \nChatGPT-maker OpenAI gave a glimpse of what sophisticated text-to-video technology might look like when the \ncompany recently showed off Sora, a new tool that's not yet publicly available. Madonna's team tried a different \nproduct from New York-based startup Runway, which helped pioneer the technology by releasing its first public \ntext-to-video model last March. The company released a more advanced \"Gen-2\" version in June. \nRunway CEO Cristóbal Valenzuela said while some see these tools as a \"magical device that you type a word and \nsomehow it conjures exactly what you had in your head,\" the most effective approaches are by creative \nprofessionals looking for an upgrade to the decades-old digital editing software they're already using. \nHe said Runway can't yet make a full-length documentary. But it could help fill in some background video, or b-roll  \nthe supporting shots and scenes that help tell the story. \n\"That saves you perhaps like a week of work,\" Valenzuela said. \"The common thread of a lot of use cases is people \nuse it as a way of augmenting or speeding up something they could have done before.\" \nDo AI video-generators dream of San Pedro ? Madonna among early adopters of AI's next wave Making instant \nvideos is the next wave of generative artificial intel....\nRunway's target customers are \"large streaming companies, production companies, post-production companies, \nvisual effects companies, marketing teams, advertising companies. A lot of folks that make content for a living,\" \nValenzuela said. \nDangers await. Without effective safeguards, AI video-generators could threaten democracies with convincing \n\"deepfake\" videos of things that never happened, or  as is already the case with AI image generators  flood the \ninternet with fake pornographic scenes depicting what appear to be real people with recognizable faces. Under \npressure from regulators, major tech companies have promised to watermark AI-generated outputs to help identify \nwhat's real. \nThere also are copyright disputes brewing about the video and image collections the AI systems are being trained \nupon (neither Runway nor OpenAI discloses its data sources) and to what extent they are unfairly replicating \ntrademarked works. And there are fears that, at some point, video-making machines could replace human jobs and \nartistry. \nFor now, the longest AI-generated video clips are still measured in seconds, and can feature jerky movements and \ntelltale glitches such as distorted hands and fingers. Fixing that is \"just a question of more data and more training,\" \nand the computing power on which that training depends, said Alexander Waibel, a computer science professor at \nCarnegie Mellon University who's been researching AI since the 1970s. \n\"Now I can say, 'Make me a video of a rabbit dressed as Napoleon walking through New York City,'\" Waibel said. \"It \nknows what New York City looks like, what a rabbit looks like, what Napoleon looks like.\" \nWhich is impressive, he said, but still far from crafting a compelling storyline. \nBefore it released its first-generation model last year, Runway's claim to AI fame was as a co-developer of the \nimage-generator Stable Diffusion. Another company, London-based Stability AI, has since taken over Stable \nDiffusion's development. \nThe underlying \"diffusion model\" technology behind most leading AI generators of images and video works by \nmapping noise, or random data, onto images, effectively destroying an original image and then predicting what a \nnew one should look like. It borrows an idea from physics that can be used to describe, for instance, how gas \ndiffuses outward. \n\"What diffusion models do is they reverse that process,\" said Phillip Isola, an associate professor of computer \nscience at the Massachusetts Institute of Technology. \"They kind of take the randomness and they congeal it back \ninto the volume. That's the way of going from randomness to content. And that's how you can make random \nvideos.\" \nGenerating video is more complicated than still images because it needs to take into account temporal dynamics, or \nhow elements within the video change over time and across sequences of frames, said Daniela Rus, another MIT \nprofessor who directs its Computer Science and Artificial Intelligence Laboratory. \nRus said the computing resources required are \"significantly higher than for still image generation\" because \"it \ninvolves processing and generating multiple frames for each second of video.\" \nThat's not stopping some well-heeled tech companies from trying to keep outdoing each other in showing off \nhigher-quality AI video generation at longer durations. Requiring written descriptions to make an image was just the \nstart. Google recently demonstrated a new project called Genie that can be prompted to transform a photograph or \neven a sketch into \"an endless variety\" of explorable video game worlds. \nIn the near term, AI-generated videos will likely show up in marketing and educational content, providing a cheaper \nalternative to producing original footage or obtaining stock videos, said Aditi Singh, a researcher at Cleveland State \nUniversity who has surveyed the text-to-video market. \nDo AI video-generators dream of San Pedro ? Madonna among early adopters of AI's next wave Making instant \nvideos is the next wave of generative artificial intel....\nWhen Madonna first talked to her team about AI, the \"main intention wasn't, 'Oh, look, it's an AI video,'\" said \nKasiuha, the creative director. \n\"She asked me, 'Can you just use one of those AI tools to make the picture more crisp, to make sure it looks current \nand looks high resolution?'\" Kasiuha said. \"She loves when you bring in new technology and new kinds of visual \nelements.\" \nLonger AI-generated movies are already being made. Runway hosts an annual AI film festival to showcase such \nworks. But whether that's what human audiences will choose to watch remains to be seen. \n\"I still believe in humans,\" said Waibel, the CMU professor. \"I still believe that it will end up being a symbiosis where \nyou get some AI proposing something and a human improves or guides it. Or the humans will do it and the AI will fix \nit up.\" \nAssociated Press journalists Joseph B. Frederick and Rodrique Ngowi contributed to this report.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "OpenAI investor Vinod Khosla spars with Elon Musk over lawsuit",
        "media": "The Economic Times",
        "time": "March 6, 2024",
        "section": "TECH & INTERNET",
        "length": "829 words",
        "byline": " ",
        "story_text": "OpenAI investor Vinod Khosla spars with Elon Musk over lawsuit\nThe Economic Times\nMarch 7, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 829 words\nBody\nIndian-American business Vinod Khosla, who is the cofounder of Sun Microsystems and the founder of Khosla \nVentures, has called out Elon Musk for suing OpenAI. He termed Musk's move \"a case of sour grapes\".Khosla has \nbeen an investor in OpenAI since 2019 when the company became \"for profit\". \"With Elon Musk, feels like a bit of \nsour grapes in suing OpenAI ChatGpt, not getting in early enough, not staying committed and now a rival effort. \nLike they say, if you can't innovate, litigate and that's what we have here. Elon of old would be building with us to hit \nthe same goal,\" posted Vinod Khosla on X.Musk was quick to revert, saying, \"Vinod doesn’t know what he is talking \nabout here.\"Khosla, then, went on create an elaborate thread on X asking Musk questions about his move and \ncommenting on Musk's motives behind his actions. \n\"@elonmusk is being self-righteous about the ills of prioritizing profit over benefit to humanity. To the less naive, \ntimelines show Elon left @OpenAI & reneged on his word to “cover whatever of the initial $1B anyone else doesn't \nprovide. He reneged simply because he wanted to wrangle control for himself and for Tesla.\"Musk and OpenAI \nCEO Sam Altman together started the artificial intelligence startup in 2015, but Musk left the firm in 2018. While \nMusk exited citing a conflict of interest with his other company Tesla, several reports suggest he wanted to merge \nOpenAI with Tesla to accelerate the automaker's growth. However, Altman was against this and Musk, after leaving \nthe startup, even pulled out of his funding for the startup.\"Now @elonmusk is being a curmudgeon about OpenAI’s \nsubsequent creation of a for-profit subsidiary – how rich! How else do you advance the cause of creating AGI to \nbenefit humanity without any funding? If he was so sincere, why did he pull the plug and leave them stranded?\" \nKhosla said. Khosla also backed his rationale of investing in the startup.\"As I said to @sama and my partners when \nwe committed to invest in @OpenAI in 2018, some things are too important for humanity to not try. Even a 90% \nchance of failure was worth 10% chance of changing the world and @khoslaventures could only lose 1x its money \nbut make a 100X,\" he added. What is Musk's lawsuit all about?The lawsuit, filed in San Francisco, California, \nalleges that OpenAI has strayed from its original not-for-profit mission of building open-source artificial intelligence \n(AI) for the good of humanity, working now to ‘maximise profits’ for its major investor Microsoft.Musk sought that the \ncourt direct OpenAI to make its research and technology publicly available and prevent the use of its assets and \ncutting-edge generative AI models for the financial gains of software major and investor Microsoft or any individual, \nReuters reported.His lawyers argued there was a breach of contract as OpenAI had agreed not to commercialise \nany product that its board considered artificial general intelligence (AGI). Microsoft, which joined the board last \nNovember following Altman’s reinstatement as CEO after an ouster, in a paper had said OpenAI's GPT-4 model \ncould be viewed as early AGI.Microsoft first invested $1 billion in the AI startup in 2019. Its multi-year investment \nnow totals $13 billion, $10 billion of which was committed last year. Microsoft is entitled to a 75% share of profits \nuntil it makes back the investment and will thereafter get a further 49% stake in OpenAI, Fortune reported.What is \nOpenAI's response?OpenAI responded to the lawsuit in a blog post Tuesday, saying Musk signed off on the \ncompany’s decision to become a for-profit entity and that he insisted it needed to raise “billions” of dollars to be \nrelevant compared with Google.“We’re sad that it’s come to this with someone whom we’ve deeply admired — \nsomeone who inspired us to aim higher, then told us we would fail, started a competitor, and then sued us when we \nstarted making meaningful progress towards OpenAI’s mission without him,” the company said in the post, which \nwas co-authored by several of OpenAI’s cofounders, including Altman, Greg Brockman, and Ilya Sutskever.In \nOpenAI investor Vinod Khosla spars with Elon Musk over lawsuit\naddition, OpenAI released emails Musk had sent to people at the company, demonstrating that the billionaire had \nendorsed its fundraising efforts. “This needs billions per year immediately or forget it,” Musk wrote in one email, \naccording to OpenAI.OpenAI, as a non-profit, raised less than $45 million from Musk and more than $90 million \nfrom other donors, according to the blog post. Musk pushed OpenAI to announce an initial $1 billion funding \ncommitment in 2015, after CEO Sam Altman and co-founder Greg Brockman initially planned to raise $100 \nmillion.“We need to go with a much bigger number than $100M to avoid sounding hopeless relative to what Google \nor Facebook are spending,” Musk wrote in an email. “I think we should say that we are starting with a $1B funding \ncommitment... I will cover whatever anyone else doesn’t provide.” For Reprint Rights: timescontent.com\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "Times_Mar2024",
        "header": "Microsoft Seeks to Dismiss Parts of Lawsuit Brought by The New York",
        "media": "Times",
        "time": "March 6, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "587 words",
        "byline": "By Cade Metz and Karen Weise",
        "story_text": "Microsoft Seeks to Dismiss Parts of Lawsuit Brought by The New York \nTimes\nThe New York Times\nMarch 6, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 587 words\nByline: By Cade Metz and Karen Weise\nBody\nThe tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies like the \nonline chatbot ChatGPT.\nMicrosoft filed a motion in federal court on Monday that seeks to dismiss parts of a lawsuit brought by The New \nYork Times Company. \n  The Times sued Microsoft and its partner OpenAI on Dec. 27, accusing the two companies of infringing on its \ncopyrights by using its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots compete with the \nnews outlet as a source of reliable information, the lawsuit said.\n  In its motion, filed in U.S. District Court for the Southern District of New York, Microsoft argued that large language \nmodels, or L.L.M.s -- the technologies that drive chatbots -- did not supplant the market for news articles and other \nmaterials they were trained on.\n  The tech giant compared L.L.M.s to videocassette recorders, arguing that both are allowed under the law. \n''Despite The Times's contentions, copyright law is no more an obstacle to the L.L.M. than it was to the VCR (or the \nplayer piano, copy machine, personal computer, internet or search engine),'' the motion read.\n  In the late 1970s, movie studios sued Sony over its Betamax VCR, arguing that it would allow people to illegally \ncopy movies and television shows. But the courts ultimately found that making these copies for personal viewing \nwas fair use under the law.\n  Microsoft's motion was similar to one made by OpenAI last week. Microsoft said three parts of the suit should be \ndismissed in part because The Times did not show actual harm.\n  The Times had argued, for example, that if readers use Microsoft's chatbot to research recommendations from the \nreview site Wirecutter, which The Times owns, it loses revenue from users who would have clicked on its referral \nlinks. Microsoft argued that the Times lawsuit offered ''no real-world facts suggesting meaningful diversion of \nrevenue from Wirecutter.''\n  Ian Crosby, a Susman Godfrey partner who is lead counsel for The Times in the case, said in a statement on \nMonday: ''Microsoft doesn't dispute that it worked with OpenAI to copy millions of The Times's works without its \npermission to build its tools. Instead, it oddly compares L.L.M.s to the VCR even though VCR makers never argued \nthat it was necessary to engage in massive copyright infringement to build their products.''\nMicrosoft Seeks to Dismiss Parts of Lawsuit Brought by The New York Times\n  Microsoft did not have an immediate comment.\n  The Times was the first major American media company to sue Microsoft and OpenAI over copyright issues \nrelated to its written works. Writers, computer coders and other groups have also filed copyright suits against \ncompanies that build generative A.I., technologies that generate text, images and other media.\n  Like other A.I. companies, Microsoft and OpenAI built their technology by feeding it enormous amounts of digital \ndata, some of which is likely copyrighted. A.I. companies have claimed that they can legally use such material to \ntrain their systems without paying for it because it is public and they are not reproducing the material in its entirety.\n  In its suit, The Times included examples of OpenAI technology's reproducing excerpts from its articles almost \nword for word. Microsoft said training the technology on such articles was ''fair use'' under the law because chatbots \nwere a ''transformative'' technology that created something new with copyrighted material. It did not, however, seek \nto dismiss arguments against ''fair use,'' saying it would address these issues at a later time.\nhttps://www.nytimes.com/2024/03/04/technology/microsoft-ai-copyright-lawsuit.html\nGraphic\n \nPHOTO: Microsoft has formed a close partnership with OpenAI to build artificial intelligence. The suit accuses the \ntwo companies of infringing on copyrights. (PHOTOGRAPH BY GRANT HINDSLEY FOR THE NEW YORK TIMES) \nThis article appeared in print on page B4.               \nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Indian SaaS products to corner 8% global market share by 2028: report",
        "media": "The Economic Times",
        "time": "March 6, 2024",
        "section": "TECH & INTERNET",
        "length": "626 words",
        "byline": "Tarush Bhalla",
        "story_text": "Indian SaaS products to corner 8% global market share by 2028: report\nThe Economic Times\nMarch 6, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 626 words\nByline: Tarush Bhalla\nBody\nAs Indian software startups continue to target international markets, the global market share of SaaS products from \nIndia is expected to reach 8% by 2028, a latest report from advisory firm 1Lattice and venture investor Sorin \nInvestments led by veteran dealmaker Sanjay Nayar said. The Indian SaaS market is also expected to touch $37 \nbillion in market size by 2028, from $12 billion presently, the analysis showed. As several domestic software \nstartups look at the US and Europe markets for their go-to-market strategy, the current global market share of \nIndian SaaS products stands at 6%. This share hasn’t increased from 2022, owing to large enterprises cutting their \nbudgets on SaaS (software-as-a-service) spends amidst broader correction in global macroeconomics. Between \n2020 and 2022 with funding being easily available, and software businesses ploughing funds into marketing and \ngoto-market (GTM) functions, global market share of domestic software products jumped 2%.However, the next 2% \ngain in global market share will take another four years to achieve. \nThe US continues to lead the global SaaS product market with 49% market share. “Till 2021 capital was available \nand the focus wasn’t on efficient growth. Now SaaS businesses are focused on efficiency and getting to profitability, \nwhile spending more time on GTM and cutting down employee counts,” said Mandar Dandekar, partner, Sorin \nInvestments to ET. Further, amidst correction in the overall funding market, the gestation period for SaaS \ncompanies to reach product market fit and close sales is taking much longer. According to Sorin, the average time \nfor a SaaS startup to reach $100 million in annual recurring revenues (ARR) is now six to seven years. “Today, \nSaaS businesses are happy growing at 30%-40% rather than doubling their growth, while maintaining a 11-12 \nmonth capital runway. We expect a slow growth for Indian software products globally since rate cuts (in the US) are \nonly expected around the second half of this year which should result in higher tech spends by enterprises only in \n2025. That is when we see the funding cycle also improving,” Harsh Khara, vice president, Sorin Investments told \nET.As efficiency takes focus, Indian SaaS companies have taken a content-based marketing approach (through \ncontent, SEO) to gain organic traction for products in the current cycle, compared to capital intensive performance \nmarketing and digital advertisements, a shift from the hay days of the funding boom. According to the report there \nare roughly 2,000 SaaS startups based out of India. AI-led business modelsThis also comes as several Indian \nsoftware providers are looking to add more artificial intelligence (AI) into their product suites and enhance customer \nexperience while driving operational efficiency. The report also said that almost 15-20% of the global AI workforce is \ncurrently housed in India and is expected to grow further. To be sure, this workforce is largely focused on AI \ntransformation into the services layer owing to India’s strength of being a global back office. While in the US, the AI \ntalent is more research, product and innovation driven. “There is coordination happening with the industry and \ngovernment to bring AI into mainstream curriculums and there are discussions around product set courses around \nAI which developers require to learn now. Our viewpoint is that with AI becoming a part of the Indian learning \necosystem the talent pool is only expected to grow,” said Praneet Singhal, director, technology and internet, \n1Lattice.According to Sorin, at least 70%-75% of the SaaS companies that the fund is evaluating for potential \ninvestments, are leveraging generative AI in some form or the other. For Reprint Rights: timescontent.com\nIndian SaaS products to corner 8% global market share by 2028: report\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Microsoft Seeks to Dismiss Parts of Suit Filed by The New York Times",
        "media": "The New York Times",
        "time": "March 6, 2024",
        "section": "TECHNOLOGY",
        "length": "623 words",
        "byline": "Cade Metz and Karen Weise Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual",
        "story_text": "Microsoft Seeks to Dismiss Parts of Suit Filed by The New York Times\nThe New York Times \nMarch 4, 2024 Monday 23:50 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 623 words\nByline: Cade Metz and Karen Weise Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual \nreality and other emerging areas of technology. Karen Weise writes about technology and is based in Seattle. Her \ncoverage focuses on Amazon and Microsoft, two of the most powerful companies in America.\nHighlight: The tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies \nlike the online chatbot ChatGPT.\nBody\nThe tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies like the \nonline chatbot ChatGPT.\nMicrosoft filed a motion in federal court on Monday that seeks to dismiss parts of a lawsuit brought by The New \nYork Times Company.\nThe Times sued Microsoft and its partner OpenAI on Dec. 27, accusing the two companies of infringing on its \ncopyrights by using its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots compete with the \nnews outlet as a source of reliable information, the lawsuit said.\nIn its motion, filed in U.S. District Court for the Southern District of New York, Microsoft argued that large language \nmodels, or L.L.M.s — the technologies that drive chatbots — did not supplant the market for news articles and other \nmaterials they were trained on.\nThe tech giant compared L.L.M.s to videocassette recorders, arguing that both are allowed under the law. “Despite \nThe Times’s contentions, copyright law is no more an obstacle to the L.L.M. than it was to the VCR (or the player \npiano, copy machine, personal computer, internet or search engine),” the motion read.\nIn the late 1970s, movie studios sued Sony over its Betamax VCR, arguing that it would allow people to illegally \ncopy movies and television shows. But the courts ultimately found that making these copies for personal viewing \nwas fair use under the law.\nMicrosoft’s motion was similar to one made by OpenAI last week. Microsoft said three parts of the suit should be \ndismissed in part because The Times did not show actual harm.\nThe Times had argued, for example, that if readers use Microsoft’s chatbot to research recommendations from the \nreview site Wirecutter, which The Times owns, it loses revenue from users who would have clicked on its referral \nlinks. Microsoft argued that the Times lawsuit offered “no real-world facts suggesting meaningful diversion of \nrevenue from Wirecutter.”\nIan Crosby, a Susman Godfrey partner who is lead counsel for The Times in the case, said in a statement on \nMonday: “Microsoft doesn’t dispute that it worked with OpenAI to copy millions of The Times’s works without its \npermission to build its tools. Instead, it oddly compares L.L.M.s to the VCR even though VCR makers never argued \nthat it was necessary to engage in massive copyright infringement to build their products.”\nMicrosoft Seeks to Dismiss Parts of Suit Filed by The New York Times\nMicrosoft did not have an immediate comment.\nThe Times was the first major American media company to sue Microsoft and OpenAI over copyright issues related \nto its written works. Writers, computer coders and other groups have also filed copyright suits against companies \nthat build generative A.I., technologies that generate text, images and other media.\nLike other A.I. companies, Microsoft and OpenAI built their technology by feeding it enormous amounts of digital \ndata, some of which is likely copyrighted. A.I. companies have claimed that they can legally use such material to \ntrain their systems without paying for it because it is public and they are not reproducing the material in its entirety.\nIn its suit, The Times included examples of OpenAI technology’s reproducing excerpts from its articles almost word \nfor word. Microsoft said training the technology on such articles was “fair use” under the law because chatbots were \na “transformative” technology that created something new with copyrighted material. It did not, however, seek to \ndismiss arguments against “fair use,” saying it would address these issues at a later time.\nPHOTO: Microsoft has formed a close partnership with OpenAI to build artificial intelligence. The suit accuses the \ntwo companies of infringing on copyrights. (PHOTOGRAPH BY GRANT HINDSLEY FOR THE NEW YORK TIMES) \nThis article appeared in print on page B4.\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "AI can help you pack, shop, and even prepare for a job interview",
        "media": "USA Today",
        "time": "March 6, 2024",
        "section": "BUSINESS; Pg. B1",
        "length": "1180 words",
        "byline": "By, Jennifer Jolly, Special to USA TODAY",
        "story_text": "AI can help you pack, shop, and even prepare for a job interview\nUSA Today\nMarch 6, 2024 Wednesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B1\nLength: 1180 words\nByline: By, Jennifer Jolly, Special to USA TODAY\nBody\nHave you used artificial intelligence in your daily life yet? I just asked that question in a room of 10 people ranging \nfrom 35 to 85 years old.\nOnly one person - aside from me - had used an AI chatbot like OpenAI's ChatGPT, Google's Bard (now renamed \nGemini), Bing Chat (now called Copilot) or any of the others that cropped up over the past year.\nThe person who had used it updated her professional bio through prompts on the free version of ChatGPT. It was \nshort and sweet she said, and did a fine job crafting an adequate professional history.\nHow can I use AI daily?\nMy casual little poll of the people in a room aligns with what we're seeing from many more scientific studies and \nresearch nationwide - most people have heard of generative AI, few have used it (that they know of), and a \nmajority of people don't trust it.\nAs most chatbots will tell you, it's good to be skeptical at this point. It's still really early days for new consumer AI \ntech tools, and they can be glitchy and filled with misinformation.\nAs long as you know these limitations going in and incorporate a few pro tips, there are some super helpful ways \nwe can use those tools right now.\nMeal planning\nMeal planning is a fan favorite. Tell your AI chatbot what you have in the refrigerator, and let it come back with a \nrecipe. Or use it to help you plan dinners and buy groceries based on dietary restrictions.\nYou can also do the same thing with cocktails, as I just found out while on vacation in Costa Rica.\nAlso, if you ask ChatGPT to provide this information in \"table format,\" it generates a nice list you can use for other \nprograms like Microsoft Excel.\nPRO TIP: You might not get good results with recipes if you ask a vague or confusing question. Use prompts that \nsound like you're talking with a real person and make them as detailed as possible with your personal preferences.\nFor example, instead of asking for \"a recipe for chicken,\" say, \"Can you give me a recipe for quick Thai curry \nchicken that uses coconut milk, tofu and whatever vegetables are in season? I'm an intermediate cook looking for \nsomething I can make in under 30 minutes using a single pot.\"\nAI can help you pack, shop, and even prepare for a job interview\nTrip planning\nDid I mention I was recently in Costa Rica? I used Copilot to generate a last-minute packing list to whittle down my \noverstuffed luggage while not forgetting anything important. It reminded me to take mosquito repellent, my open-\nwater swim goggles and to leave my jacket and dress shoes behind.\nThis isn't earth-shattering, but it did the job I needed it to do quickly and efficiently. Five days into my 10-day trip, I \nfelt really good about not overpacking (for a change), yet still having everything I needed.\nPRO TIP: Have you heard about AI's \"hallucination\" problem? That's when AI makes up something but presents it \nas a fact.\nThat happened when I tried ChatGPT to help with a camping-based road trip itinerary last fall. It failed miserably, \nespecially when asked to locate dispersed camping on BLM land, which was my main reason for using it.\nI've recently gotten much better results using paid versions of all three of my go-to's - ChatGPT4, Gemini and \nCopilot, and asking the chatbots to incorporate suggestions from trusted travel sites such as Lonely Planet, The \nPoints Guy and Outside Magazine (specifically because I like more adventure travel). Each chatbot costs about $20 \na month after a free trial period.\nJob interviewing\nAs much as we fear losing jobs to AI, Blelloch says chatbots have been incredibly useful on the job-hunter side too. \n\"When I was interviewing for jobs, I cut and pasted the job description and my resume into ChatGPT and had AI \ncreate a list of interview questions. It was really helpful because (the potential questions) were tailored to the \nposition and my resume.\"\nBlelloch also used ChatGPT to help with an early first draft of a cover letter and to critique her resume based on \nspecific job descriptions. \"These needed heavy editing, obviously,\" she added, \"but they used all the keywords that \nan AI would look for on the receiving end, and I got more interviews than I did when I was writing cover letters (from \nscratch).\"\nPRO TIP: Be sure to try out your job interview responses with your AI chatbot and ask it to rate your responses as if \nit were the hiring manager.\nDon't memorize the AI responses because they aren't human (duh), but instead use them to help brainstorm and \npractice. That way, when you get the inevitable question, \"What's your biggest weakness?\" you'll have a better \nanswer than, \"I work too hard.\"\nCreating family activities\nAI chatbots tend to be good at brainstorming and bad at \"facts.\" Still, it's excellent for developing new ways to \nengage, entertain and educate kids.\nLast summer, San Diego PR strategist Lorena Ruggero used ChatGPT to create a \"golden hour\" curriculum for her \n12-year-old son.\n\"He's academically advanced, and I wanted to keep him engaged in something mentally stimulating instead of \nplaying video games and watching YouTube all day,\" Ruggero explained.\nHer son's teacher recommended a \"golden hour\" plan, which is the idea behind helping students pursue a topic \nthey're interested in for an hour each day. \"He shared some interest in stop-motion animation with Legos and his \niPad, so I used OpenAI to create an eight-week 'golden hour' curriculum for him to learn how to create a stop-\nmotion Lego film,\" Ruggero said.\nPRO TIP: Use your chatbot to write and create with you versus for you.\nAI can help you pack, shop, and even prepare for a job interview\nYour chatbot gets better the more it learns from you over time. If you don't get the results you want with the first \nprompt, give it more information and keep asking. If you're creating a curriculum for a specific child or even using it \nto help you write a speech, ask it to \"interview\" you to get all of the information it needs to do the best job it can. In \nother words, help the tool help you.\nIt's a new way to think using your tech - and it actually works.\nArguing and negotiation\nMy family has a lot of \"spirited debates.\" These aren't contentious arguments by any stretch but rather \nconversations around topics we have a lot of feelings about. Like sunscreen.\nOn the family trip to Costa Rica, one of my relatives argued that \"child-safe sunscreen\" with zinc oxide is bad for \ntoddlers, full stop. My position was that it's better than a sunburn. Simple, right?\nClearly, you've not been in one of my family discussions.\nTo have a more productive conversation around this issue without getting mad about it, I needed a few specific \ntalking points to help get my point across without attacking, upsetting or alienating my family members. (I'm not \nalways good about that last part.)\nI used a ChatGPT plug-in tool called Negotiator to help create some compelling points in favor of sunscreen while \nnot getting too emotional around the debate.\nPRO TIP: This example might be a stretch for most people, but think of using this to help with negotiating a salary \nraise, work exit strategy, car purchase or something else you care about and need to advocate for.\nThe views and opinions expressed in this column are the author's and do not necessarily reflect those of USA \nTODAY.\nGraphic\n \nAs long as you know the limitations going in and incorporate a few pro tips, there are some super helpful ways we \ncan use artificial intelligence tools right now.\nKirill Kudryavtsev/AFP via Getty Images\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "New_York_Observer_Mar2024",
        "header": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap",
        "media": "New York Observer",
        "time": "March 7, 2024",
        "section": "",
        "length": "457 words",
        "byline": "Nhari Djan and Sissi Cao",
        "story_text": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap\nNew York Observer\nMarch 7, 2024 Thursday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 457 words\nByline: Nhari Djan and Sissi Cao\nBody\nMeta is in the final phase of rebuilding its A.I. recommendation models as part of the company's \"tech roadmap that \ngoes to 2026,\" meaning that a series of generative A.I. features are about to come to Meta's suite of social media \nproducts, Tom Alison, Meta's head of Facebook, said at the Morgan Stanley Technology, Media and \nTelecommunications conference yesterday (Mar. 6).\nLast year, inspired by an industrywide interest in generative A.I., Meta experimented with a new recommendation \nmodel in Reels, Facebook's short-form video sharing platform. The new model helped Facebook gain as much as \n10 percent in Reels watch time on the Facebook app, Alison said, proving that the model was \"learning from the \ndata much more efficiently than the previous generation.\"\n\"We've really focused on investing more in making sure that we can scale these models up with the right kind of \nhardware,\" Alison said onstage yesterday. \"Instead of just powering Reels, we're working on a project to power our \nentire video ecosystem with this single model.\"\nFor example, \"If you see something that you're into in Reels, and then you go back to the Feed, we can show you \nmore similar content,\" he explained. To date, Meta has used a separate model for each of its products. It's looking \nto build a single model for multiple products. \"If we get this right, not only will the recommendations be more \nengaging and more relevant, but we think the responsiveness of them can improve as well,\" Alison said.\nMeta is also experimenting integrating A.I. chatting features within Feed and Groups products. In Feed, for \ninstance, if a user sees a recommended post about Taylor Swift, they could perhaps \"easily just click a button and \nsay, 'Hey Meta AI, tell me more about what I'm seeing with Taylor Swift right now,'\" Alison said.\nHe illustrated with another example in Groups. \"If you are a home hobbyist baker, you're probably in a baking group \non Facebook, and you can go in and ask a question and say, Hey, how come my sourdough bread isn't rising \nproperly? There are people in the group that will come in and answer your question. But if for some reason they \ndon't, we've enabled meta A.I. to come in and answer your question in the comments,\" Alison said. \nAlison, 46, has been with Meta since 2010. He led the development of several Facebook products, including News \nFeed. He named head of Facebook in 2021 in the year Mark Zuckerberg changed the parent company's name to \nMeta.\nMeta is one of the largest buyers of Nvidia's graphics processing units, or GPUs, having spent billions of dollars on \nacquiring these chips essential in training A.I. models. Alison said the company has accumulated a massive \nstockpile of GPUs to power its ambitious generative A.I. efforts.\nLoad-Date: March 7, 2024\nHead of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Blocks Epic Games From Using iPhone Tools in Escalation of Feud",
        "media": "The New York Times",
        "time": "March 7, 2024",
        "section": "TECHNOLOGY",
        "length": "836 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple Blocks Epic Games From Using iPhone Tools in Escalation of Feud\nThe New York Times \nMarch 6, 2024 Wednesday 00:25 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 836 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: The move tests the European Union’s new tech competition law, which was designed to allow competing \napp stores.\nBody\nThe move tests the European Union’s new tech competition law, which was designed to allow competing app \nstores.\nWhen the European Union passed a 2022 law to loosen Apple’s grip on the app economy, Epic Games, the maker \nof Fortnite, began planning to launch a competing app store for developers.\nBut before that law could go into effect this week, Apple has blocked Epic’s European subsidiary from using iPhone \nsoftware tools, making it impossible for the game developer to create the Epic Games Store.\nIn correspondence from Apple to Epic Games, the tech giant said that Epic had shown in the past it was unwilling to \nfollow Apple’s rules to protect the App Store and that it couldn’t return to the Developer Program that supports it. \nApple also objected to Epic’s criticism of Apple’s plans to comply with Europe’s tech competition law.\nApple’s move is the latest salvo in a long-running battle with Epic. In 2020, Epic broke the App Store’s rules by \nencouraging customers to pay it directly for features in Fortnite. Apple threw Epic out of the App Store, and Epic \nsued Apple for violating antitrust laws by requiring developers to use its payment system.\nWith its rejection of Epic’s access to developer tools in Europe, Apple is testing the boundaries of the European \nUnion’s tech competition law. The Digital Markets Act, which takes effect Thursday, requires Apple to give app \nmakers alternatives for selling software to iPhone and iPad users, including the ability to use alternative payment \nsystems and competing app stores.\nAn Apple spokesman said in a statement that “Apple has the right to terminate” any of Epic’s games and that it had \ndone so because of Epic’s “egregious breach of its contractual obligations.”\nTim Sweeney, the chief executive of Epic, said his company had invested billions of dollars to create the Epic \nGames Store and would file a complaint to European regulators over Apple’s action.\n“We see Apple’s decision to block us from competing as a blatant effort to kneecap its leading competitor,” Mr. \nSweeney said, adding: “This isn’t just about Epic versus Apple. The D.M.A. is about ensuring consumers the benefit \nof competition, of better prices.”\nIn 2018, Epic Games launched a digital store to distribute games on PCs and other devices. The store currently \ntakes a 12 percent commission for every game it sells, which is less than the 30 percent Apple typically collects.\nApple Blocks Epic Games From Using iPhone Tools in Escalation of Feud\nEpic is the among the first app makers to complain that Apple is blocking competing app stores. But other \ndevelopers have criticized Apple’s plans to comply with the Digital Markets Act and called on E.U. regulators to \ninvestigate the tech giant.\nShould the European Commission, the European Union’s executive arm, open a formal investigation into \ncomplaints from Epic or other developers, it could set up a lengthy legal battle that might force Apple to change or \nrisk fines of up to 10 percent of its global annual revenue, which was nearly $400 billion last year.\nAn investigation would deepen the challenges confronting Apple over its App Store policies. On Monday, E.U. \nregulators fined Apple 1.8 billion euros ($1.95 billion) for thwarting competition among streaming music rivals. Last \nyear, South Korea’s telecommunications regulator said it might fine Apple $15.4 million for “unfair practices.”\nApple’s dispute with Epic’s plans to create a competing app store in Europe began last month. Epic wrote Apple \nsaying it planned to use its subsidiary in Sweden to bring the Epic Games Store and Fortnite to iPhones and iPads \nin Europe. Initially, Apple granted the subsidiary, Epic Games Sweden A.B., a developer account, but it later \nterminated the account.\nIn an email to Mr. Sweeney, which Epic Games posted on its website, Phil Schiller, who leads the App Store, \nquestioned Epic’s willingness to follow Apple’s rules. He said that Epic had deliberately broken Apple’s policies \nbefore filing its lawsuit in the United States and that Mr. Sweeney had called Apple’s plan to comply with Europe’s \ntech law “hot garbage” and a “horror show.”\n“Your colorful criticism of our D.M.A. compliance plan, coupled with Epic’s past practices of intentionally violating \ncontractual provisions with which it disagrees, strongly suggest that Epic Sweden does not plan to follow the rules,” \nMr. Schiller wrote.\nMr. Sweeney replied that Epic was “acting in good faith and will comply with all terms of current and future \nagreements with Apple.”\nA lawyer representing Apple later wrote Epic Games to tell it that its Sweden subsidiary’s account had been \nterminated. Mr. Sweeney said the correspondence was the totality of Epic’s exchange with Apple.\nPHOTOS: Epic Games, the maker of Fortnite, was planning to create its own app store. However, by not allowing \nEpic access to its iPhone software tools in Europe, Apple has made it impossible for the game developer to create \nthe Epic Games Store. (PHOTOGRAPHS BY FREDERIC J. BROWEN/AGENCE FRANCE-PRESSE — GETTY \nIMAGES; PHILIP PACHECO/GETTY IMAGES) This article appeared in print on page B5.\nLoad-Date: March 7, 2024"
    },
    {
        "file_name": "insurance_cover_better_Mar2024",
        "header": "How to use Bajaj Allianz General Insurance's Gen AI Bot to understand your",
        "media": "insurance cover better",
        "time": "March 7, 2024",
        "section": "WEALTH-NEWS",
        "length": "357 words",
        "byline": " ",
        "story_text": "How to use Bajaj Allianz General Insurance's Gen AI Bot to understand your \ninsurance cover better\nThe Economic Times\nMarch 7, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: WEALTH-NEWS\nLength: 357 words\nBody\nBajaj Allianz General Insurance has launched a Gen AI powered Bot called Insurance Samjho for its policyholders. \nThis next-generation AI technology bot is designed to simplify insurance complexities, empower customers with \nknowledge about their policies with easy-to-understand information, stated a press release issued by Bajaj Allianz \nGeneral Insurance.What information policyholder can getWhether it's understanding coverage details, comparing \npolicies, or clarifying specific terms and conditions, the \"Insurance Samjho\" Gen AI powered Bot offers \npersonalised assistance to policyholders, ensuring transparency and clarity, stated the press release. How to use \nInsurance SamjhoAs per the press release, this is what policyholders need to do to use the Gen AI bot. Customers \nneed to simply upload their policy documents (brochures, policy copies, or policy wordings) to the platform at \nhttps://www.bajajallianz.com/insurancesamjho/. The Gen AI powered Bot then acts as a virtual assistant, allowing \ncustomers to ask questions about their coverage, exclusions, and procedures or even ask for clarity on some \nspecific medical conditions. \nIn essence, it is similar to interacting with Chat GPT to ask questions and seek clarification on various aspects of \ntheir policies based on the document that has been uploaded. The bot provides clear, concise answers in a \nconversational style, ensuring complete transparency and easy comprehension.Tapan Singhel, MD & CEO, Bajaj \nAllianz General Insurance, emphasized the significance of this initiative, stating, \"It has been a perennial issue for \nthe insurance industry and worry for the citizens in terms of complexity of insurance terms, the jargon involved and \nunderstanding the fine print as well. With this platform, which is a bot powered by Gen AI, it is our endeavour to \nempower our citizens with the knowledge they need to make informed decisions by knowing more about insurance \nproducts across the industry and feel confident about their insurance coverage. This easy-to-use platform will keep \nlearning and improve over time, because of its AI capabilities.\" For Reprint Rights: timescontent.com\nLoad-Date: March 7, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Ex-Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm",
        "media": "The New York Times",
        "time": "March 7, 2024",
        "section": "Section A; Column 0; Foreign Desk; Pg. 8",
        "length": "967 words",
        "byline": "By Glenn Thrush and Nico Grant",
        "story_text": "Ex-Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm\nThe New York Times\nMarch 7, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; Foreign Desk; Pg. 8\nLength: 967 words\nByline: By Glenn Thrush and Nico Grant\nBody\nLinwei Ding, a Chinese national, was arrested in California and accused of uploading hundreds of files to the cloud.\nA Chinese citizen who recently quit his job as a software engineer for Google in California has been charged with \ntrying to transfer artificial intelligence technology to a Beijing-based company that paid him secretly, according to a \nfederal indictment unsealed on Wednesday. \n  Prosecutors accused Linwei Ding, who was part of the team that designs and maintains Google's vast A.I. \nsupercomputer data system, of stealing information about the ''architecture and functionality'' of the system, and of \npilfering software used to ''orchestrate'' supercomputers ''at the cutting edge of machine learning and A.I. \ntechnology.''\n  From May 2022 to May 2023, Mr. Ding, also known as Leon, uploaded 500 files, many containing trade secrets, \nfrom his Google-issued laptop to the cloud by using a multistep scheme that allowed him to ''evade immediate \ndetection,'' according to the U.S. attorney's office for the Northern District of California.\n  Mr. Ding was arrested on Wednesday morning at his home in Newark, Calif., not far from Google's sprawling main \ncampus in Mountain View, officials said.\n  Starting in June 2022, Mr. Ding was paid $14,800 per month -- plus a bonus and company stock -- by a China-\nbased technology company, without telling his supervisors at Google, according to the indictment. He is also \naccused of working with another company in China.\n  Mr. Ding openly sought funding for a new A.I. start-up company he had incorporated at an investor conference in \nBeijing in November, boasting that ''we have experience with Google's 10,000-card computational power platform; \nwe just need to replicate and upgrade it,'' prosecutors said in the indictment, which was unsealed in San Francisco \nfederal court.\n  ''The Justice Department will not tolerate the theft of artificial intelligence and other advanced technologies that \ncould put our national security at risk,'' said Attorney General Merrick B. Garland, who announced the indictment \nduring an appearance at an American Bar Association conference in San Francisco on Wednesday afternoon.\n  The charges underscore the high-stakes contest for primacy in artificial intelligence. While American companies \nhave developed most advances in generative A.I., China has made it a strategic priority to lead the growing field.\n  Tech industry insiders have estimated that China is at least a year behind the United States, but many Chinese \nstart-ups have tapped American technology to try to keep up, especially Meta's open-source large language model, \nEx- Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm\ncalled Llama. Generative A.I., which is behind ChatGPT and the wave of conversational chatbots, has quickly \nbecome one of the world's most coveted technologies.\n  In seconds, these types of tools can generate convincing text and images that could be used to boost productivity, \ncreate misinformation or provide amusement. Audio and video capabilities are not far behind. Google developed \nsome of the foundational breakthroughs that make these systems work. The company has said that its latest group \nof A.I. models, named Gemini, are among the most powerful available today.\n  But since ChatGPT's debut, Google has lost its status as a market leader and its stumbles have attracted \nattention. The company has been widely criticized for racial biases in its image generator, leading it to pause users' \nability to create images of people.\n  Accusations of intellectual property theft have been a major sticking point in U.S.-China relations for years. A \nChinese national was arrested in 2015 for selling some of IBM's source code to parties in China. In 2018, a former \nApple employee was apprehended as he tried to board a flight to Beijing with the company's autonomous-driving \ntrade secrets.\n  The same year, the Chinese firm Sinovel Wind Group was convicted of stealing wind turbine technology from a \nMassachusetts-based company, AMSC, which incurred more than $800 million in losses.\n  In October, Christopher A. Wray, the F.B.I. director, said that intellectual property theft from China was a danger to \nU.S. economic and national security, describing it as the ''defining threat of this generation.''\n  José Castañeda, a Google spokesman, said in a statement: ''We have strict safeguards to prevent the theft of our \nconfidential commercial information and trade secrets. After an investigation, we found that this employee stole \nnumerous documents, and we quickly referred the case to law enforcement. We are grateful to the F.B.I. for helping \nprotect our information and will continue cooperating with them closely.''\n  The indictment suggested that Mr. Ding had some help, saying that another Google employee swiped Mr. Ding's \nidentification card at a company office to help him conceal a trip to China.\n  Google, referring to Mr. Ding as a ''junior employee,'' initially said he had acted alone but later said that did not \nappear to be the case. It maintained that its security systems had worked as intended.\n  It was not immediately clear whether Mr. Ding has legal representation.\n  The government offered few details about the life of Mr. Ding, who began working for Google in early 2019 and \nquit suddenly in January -- after booking a one-way ticket to Beijing.\n  Mr. Ding listed a degree from the Dalian Institute of Technology in China in 2010, along with degrees from the \nUniversity of Southern California and Stanford, on a LinkedIn page that corresponded to his name and the details of \nemployment at Google.\n  The page lists stints at software semiconductor and health care companies over the past decade, along with \nawards he said he earned at Google, including the ''Perfy Award and Feats of Engineering.''\n  Kitty Bennett contributed reporting.Kitty Bennett contributed reporting.\nhttps://www.nytimes.com/2024/03/06/us/politics/google-engineer-china-ai-theft.html\nGraphic\n \nThis article appeared in print on page A8.               \nEx- Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm\nLoad-Date: March 7, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Ex-Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm",
        "media": "The New York Times",
        "time": "March 7, 2024",
        "section": "US; politics",
        "length": "963 words",
        "byline": "Glenn Thrush and Nico Grant Glenn Thrush covers the Department of Justice. He joined The Times in",
        "story_text": "Ex-Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm\nThe New York Times \nMarch 6, 2024 Wednesday 11:56 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 963 words\nByline: Glenn Thrush and Nico Grant Glenn Thrush covers the Department of Justice. He joined The Times in \n2017 after working for Politico, Newsday, Bloomberg News, The New York Daily News, The Birmingham Post-\nHerald and City Limits. Nico Grant is a technology reporter covering Google from San Francisco. Previously, he \nspent five years at Bloomberg News, where he focused on Google and cloud computing.\nHighlight: Linwei Ding, a Chinese national, was arrested in California and accused of uploading hundreds of files to \nthe cloud.\nBody\nLinwei Ding, a Chinese national, was arrested in California and accused of uploading hundreds of files to the cloud.\nA Chinese citizen who recently quit his job as a software engineer for Google in California has been charged with \ntrying to transfer artificial intelligence technology to a Beijing-based company that paid him secretly, according to a \nfederal indictment unsealed on Wednesday.\nProsecutors accused Linwei Ding, who was part of the team that designs and maintains Google’s vast A.I. \nsupercomputer data system, of stealing information about the “architecture and functionality” of the system, and of \npilfering software used to “orchestrate” supercomputers “at the cutting edge of machine learning and A.I. \ntechnology.”\nFrom May 2022 to May 2023, Mr. Ding, also known as Leon, uploaded 500 files, many containing trade secrets, \nfrom his Google-issued laptop to the cloud by using a multistep scheme that allowed him to “evade immediate \ndetection,” according to the U.S. attorney’s office for the Northern District of California.\nMr. Ding was arrested on Wednesday morning at his home in Newark, Calif., not far from Google’s sprawling main \ncampus in Mountain View, officials said.\nStarting in June 2022, Mr. Ding was paid $14,800 per month — plus a bonus and company stock — by a China-\nbased technology company, without telling his supervisors at Google, according to the indictment. He is also \naccused of working with another company in China.\nMr. Ding openly sought funding for a new A.I. start-up company he had incorporated at an investor conference in \nBeijing in November, boasting that “we have experience with Google’s 10,000-card computational power platform; \nwe just need to replicate and upgrade it,” prosecutors said in the indictment, which was unsealed in San Francisco \nfederal court.\n“The Justice Department will not tolerate the theft of artificial intelligence and other advanced technologies that \ncould put our national security at risk,” said Attorney General Merrick B. Garland, who announced the indictment \nduring an appearance at an American Bar Association conference in San Francisco on Wednesday afternoon.\nThe charges underscore the high-stakes contest for primacy in artificial intelligence. While American companies \nhave developed most advances in generative A.I., China has made it a strategic priority to lead the growing field.\nEx- Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm\nTech industry insiders have estimated that China is at least a year behind the United States, but many Chinese \nstart-ups have tapped American technology to try to keep up, especially Meta’s open-source large language model, \ncalled Llama. Generative A.I., which is behind ChatGPT and the wave of conversational chatbots, has quickly \nbecome one of the world’s most coveted technologies.\nIn seconds, these types of tools can generate convincing text and images that could be used to boost productivity, \ncreate misinformation or provide amusement. Audio and video capabilities are not far behind. Google developed \nsome of the foundational breakthroughs that make these systems work. The company has said that its latest group \nof A.I. models, named Gemini, are among the most powerful available today.\nBut since ChatGPT’s debut, Google has lost its status as a market leader and its stumbles have attracted attention. \nThe company has been widely criticized for racial biases in its image generator, leading it to pause users’ ability to \ncreate images of people.\nAccusations of intellectual property theft have been a major sticking point in U.S.-China relations for years. A \nChinese national was arrested in 2015 for selling some of IBM’s source code to parties in China. In 2018, a former \nApple employee was apprehended as he tried to board a flight to Beijing with the company’s autonomous-driving \ntrade secrets.\nThe same year, the Chinese firm Sinovel Wind Group was convicted of stealing wind turbine technology from a \nMassachusetts-based company, AMSC, which incurred more than $800 million in losses.\nIn October, Christopher A. Wray, the F.B.I. director, said that intellectual property theft from China was a danger to \nU.S. economic and national security, describing it as the “defining threat of this generation.”\nJosé Castañeda, a Google spokesman, said in a statement: “We have strict safeguards to prevent the theft of our \nconfidential commercial information and trade secrets. After an investigation, we found that this employee stole \nnumerous documents, and we quickly referred the case to law enforcement. We are grateful to the F.B.I. for helping \nprotect our information and will continue cooperating with them closely.”\nThe indictment suggested that Mr. Ding had some help, saying that another Google employee swiped Mr. Ding’s \nidentification card at a company office to help him conceal a trip to China.\nGoogle, referring to Mr. Ding as a “junior employee,” initially said he had acted alone but later said that did not \nappear to be the case. It maintained that its security systems had worked as intended.\nIt was not immediately clear whether Mr. Ding has legal representation.\nThe government offered few details about the life of Mr. Ding, who began working for Google in early 2019 and quit \nsuddenly in January — after booking a one-way ticket to Beijing.\nMr. Ding listed a degree from the Dalian Institute of Technology in China in 2010, along with degrees from the \nUniversity of Southern California and Stanford, on a LinkedIn page that corresponded to his name and the details of \nemployment at Google.\nThe page lists stints at software semiconductor and health care companies over the past decade, along with \nawards he said he earned at Google, including the “Perfy Award and Feats of Engineering.”\nKitty Bennett contributed reporting.\nKitty Bennett contributed reporting. \nThis article appeared in print on page A8.\nLoad-Date: March 7, 2024\nEx- Google Engineer Charged With Stealing A.I. Secrets for Chinese Firm"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Unlocking Targeted Funding for Startups",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "655 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "Unlocking Targeted Funding for Startups\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 655 words\nByline: Annapurna Roy & Suraksha P\nHighlight: AI Mission will help startups make in India and for the world, say tech investors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of artificial intelligence-based applications and models is a “good starting point” \nas it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372-crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. This will provide Indian companies with their own computing hardware — a scarce resource globally — \nallowing them to create more AI applications and arming the country to compete better with the likes of the US, \nChina and the UK which are ahead in the race to dominate the sunrise sector. \n“The government’s AI mission is incredibly exciting for India and its vibrant startup ecosystem. In-  vesting in 10,000 \nGPUs and making them available to researchers and innovators will make a huge difference as we aim to build \n(India) the AI application capital of the world,” Rajan Anandan, managing director, Peak XV Partners, told ET \nadding that it will provide critical building blocks that AI startups can leverage to “build in India, for India and for the \nworld”.  In addition to IndiaAI Innovation Centre for the development and deployment of indigenous Large \nMultimodal Models and domainspecific foundational models in critical sectors, the mission will also provide access \nto targeted funding for AI startups. India now has over 100 generative AI startups, however, the investment into the \nspace has been comparatively small.  Last year, Indian conglomerates such as the Tata Group and Reliance \nIndustries announced partnerships with top GPU maker Nvidia to obtain computing infrastructure to build their own \nAI applications. However, startups facing resource constraints have been petitioning the government to invest into \ncomputing infrastructure to ensure they also get access and do not lose out in the dynamic AI race. The Centre’s \nlatest move will enable these AI startups to create foundational models from  scratch for a variety of applications, for \nwhich they were earlier dependent on models from the likes of OpenAI and Meta.  Vishal Dhupar, managing \ndirector for South Asia at Nvidia, said that the government’s latest outlay creates a “highway” for innovation to \nhappen. “I’m so pleased that the digital transformation has taken place in the country. Now you can embed AI into \nit,” he said while speaking at an event in  the national capital on Friday. Dhupar added that this enables solutions to \nbe built for India and that solutions built here at population scale are applicable globally. “I'm hoping India’s \nadvantage is to migrate from general purpose compute to accelerated compute, and you will have sufficient \nhighway for this country to make a difference.” The GPUs will be made available in the next 18-24 months, said \nelectronics and IT secretary S Krish-  nan on the sidelines of an event on Friday. He added that the government will \ninvite bids from the industry under the mission and provide viability gap funding for this compute \ninfrastructure.PLAYING CATCHUPGlobally, countries like the UK, Saudi Arabia and the UAE have been shelling \nbig money to acquire AI chips to boost their countries’ companies.  Pointing out that the “market of GPUs is very \nUnlocking Targeted Funding for Startups\ndynamic with new technologies coming in and rendering existing technologies outdated,” Tanuj Bhojwani, head, \npeople+ai, an initiative by Infosys co-founder Nandan Nilekani’s EkStep Foundation, said “ the government should \nplay the role of investor and not (of) a purchaser or a customer.” “Merely going out into the market and purchasing \n10,000 GPUs may not do the trick, the government should think like an investor,” he added.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GPUs to Keep India in Sync Globally on AI Front: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "393 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "GPUs to Keep India in Sync Globally on AI Front: Experts\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 393 words\nByline: Annapurna Roy & Suraksha P\nHighlight: Access to compute infra under AI Mission will help startups make in India and for the world, say tech \ninvestors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of any artificial intelligence-based applications and models is a “good starting \npoint” as it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372 crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. \nThis will provide Indian companies with their own compute hardware — a scarce resource globally — allowing them \nto create more AI applications and arming the country to compete better with the likes of the US, China and the UK \nwhich are ahead in the race to dominate the sunrise sector. “The government’s AI mission is incredibly exciting for \nIndia and  its vibrant startup ecosystem. Investing in 10,000 GPUs and making them available to researchers and \ninnovators will make a huge difference as we aim to build (India) the AI application capital of the world,” Rajan \nAnandan, managing director, PeakXV Partners, told ET adding that it will provide critical building blocks that AI \nstartups can leverage to “build in India, for India and for the world”. In addition to IndiaAI Innovation Centre for the \ndevelopment and deployment of indigenous Large Multimodal Models and domain-specific foundational models in \ncritical sectors, the mission will also provide access to targeted funding for AI startups. India now has over 100 \ngenerative AI startups, however, the investment into the space has been comparatively small. The US saw nearly \n$250 billion private investments into AI startups between 2013 and 2022, while investments in India stood at just $8 \nbillion. Over the same period, China saw $95 billion of investments while for the UK, the number stood at $18 \nbillion, as per data from the AI Index 2023 Annual Report. Last year, Indian conglomerates such as the Tata Group \nand Reliance Industries announced partnerships with top GPU maker Nvidia to obtain compute to build their own \nAI. However, startups facing resource constraints have been petitioning the government to invest into compute to \nensure they also get access.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot",
        "media": "The New York Times",
        "time": "March 8, 2024",
        "section": "TECHNOLOGY",
        "length": "463 words",
        "byline": "Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other",
        "story_text": "A.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\nThe New York Times \nMarch 4, 2024 Monday 13:58 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 463 words\nByline: Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other \nemerging areas of technology.\nHighlight: Despite computer shortages, controversies and lawsuits, A.I. continues to improve at a rapid pace.\nBody\nDespite computer shortages, controversies and lawsuits, A.I. continues to improve at a rapid pace.\nThe high-profile A.I. start-up Anthropic released a new version of its Claude chatbot on Monday, saying it \noutperforms other leading chatbots on a range of standard benchmark tests, including systems from Google and \nOpenAI.\nDario Amodei, Anthropic’s chief executive and co-founder, said the new technology, called Claude 3 Opus, was \nparticularly useful when analyzing scientific data or generating computer code.\nAnthropic is among a small group of companies at the forefront of generative A.I., technology that instantly creates \ntext, images and sounds. Dr. Amodei and other Anthropic founders helped pioneer the technology while working as \nresearchers at OpenAI, the start-up that launched the generative A.I. boom in late 2022 with the release of the \nchatbot ChatGPT.\nChatbots like ChatGPT can answer questions, write term papers, generate small computer programs and more. \nThey may also generate false or misleading information, much as people do.\nWhen OpenAI released a new version of its technology called GPT-4 last spring, it was widely considered the most \npowerful chatbot technology used by both consumers and businesses. Google recently introduced a comparable \ntechnology, Gemini.\nBut the leading artificial intelligence companies have been distracted by one controversy after another. They say \nthe computer chips needed to build A.I. are in short supply. And they face countless lawsuits over the way they \ngather digital data, another ingredient essential to the creation of A.I. (The New York Times has sued Microsoft and \nOpenAI over use of copyrighted work.)\nStill, the technology continues to improve at a remarkable pace.\nAnthropic claims that its Claude 3 Opus technology outperforms both GPT-4 and Gemini in mathematical problem \nsolving, computer coding, general knowledge and other areas.\nClaude 3 Opus was available starting Monday to consumers who pay $20 per month for a subscription. A less \npowerful version, called Claude 3 Sonnet, is available for free.\nThe company allows businesses to build their own chatbots and other services using the Opus and Sonnet \ntechnologies.\nA.I. Start-Up Anthropic Challenges OpenAI and Google With New Chatbot\nBoth versions of the technology can respond to images as well as text. These can analyze a flowchart, for instance, \nor solve a math problem that includes diagrams and graphs.\nBut the technology cannot generate images. Google recently suspended Gemini’s ability to generate human faces \nafter it produced images showing people of color in German military uniforms from World War II.\nPHOTO: Dario Amodei, Anthropic’s chief executive. The company released a new version of its Claude chatbot on \nMonday. (PHOTOGRAPH BY MASSIMO BERRUTI FOR THE NEW YORK TIMES) This article appeared in print on \npage B4.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Unlocking Funding",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "756 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "Unlocking Funding\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 756 words\nByline: Annapurna Roy & Suraksha P\nHighlight: AI Mission will help startups make in India and for the world, say tech investors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of artificial intelligence-based applications and models is a “good starting point” \nas it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372-crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. This will provide Indian companies with their own computing hardware — a scarce resource globally — \nallowing them to create more AI applications and arming the country to compete better with the likes of the US, \nChina and the UK which are ahead in the race to dominate the sunrise sector. \n“The government’s AI mission is incredibly exciting for India and its vibrant startup ecosystem. In-  vesting in 10,000 \nGPUs and making them available to researchers and innovators will make a huge difference as we aim to build \n(India) the AI application capital of the world,” Rajan Anandan, managing director, Peak XV Partners, told ET \nadding that it will provide critical building blocks that AI startups can leverage to “build in India, for India and for the \nworld”.  In addition to IndiaAI Innovation Centre for the development and deployment of indigenous Large \nMultimodal Models and domain-specific foundational models in critical sectors, the mission will also provide access \nto targeted funding for AI startups. India now has over 100 generative AI startups, however, the investment into the \nspace has been comparatively small. The US saw nearly $250 billion private investments into AI startups between \n2013 and 2022, while investments in India stood at just $8 billion. Over the same period, China saw $95 billion of \ninvestments while for the UK, the number stood at $18 billion, as per data from the AI Index 2023 Annual Report. \nLast year, Indian conglomerates such as the Tata Group and Reliance Industries announced partnerships with top \nGPU maker Nvidia to obtain computing infrastructure to build their own AI applications. However,  startups facing \nresource constraints have been petitioning the government to invest into computing infrastructure to ensure they \nalso get access and do not lose out in the dynamic AI race. The Centre’s latest move will enable these AI startups \nto create foundational models from scratch for a variety of applications, for which they were earlier dependent on \nmodels from the likes of OpenAI and Meta.  Vishal Dhupar, managing director for South Asia at Nvidia, said that the \ngovernment’s latest outlay creates a “highway” for innovation to happen. “I’m so pleased that the digital \ntransformation has taken place in the country. Now you can embed AI into it,” he said while speaking at an event in \nthe national capital on Friday. Dhupar added that this enables solutions to be built for India and that solutions built \nhere at population scale are applicable globally. “I'm hoping India’s advantage is to migrate from general purpose \ncompute to accelerated compute, and you will have sufficient highway for this country to make a difference.” Nvidia \nstock has seen an unprecedented rally this year. Chip maker is close to edging out Apple, which is listed se-  cond \nin market cap table globally. It will provide Reliance Industries access to its most advanced Nvidia GH200 Grace \nUnlocking Funding\nHopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 provides massive \nmemory bandwidth. The GPUs will be made available in the next 18-24 months, said electronics and IT secretary S \nKrishnan on the sidelines of an event on Friday. He added that the government will invite bids from the industry \nunder the mission and provide viability gap funding for this compute infrastructure.   PLAYING CATCHUP  Globally, \ncountries like the UK, Saudi Arabia and the UAE have been shelling big money to acquire AI chips to boost their \ncountries' companies. For instance, the UK is building a national AI resource, as a part of which it would acquire \n5,000 Nvidia GPUs. Saudi Arabia, through the King Abdullah University of Science and Technology, reportedly \nbought 3,000 Nvidia GPUs worth $40,000 each.  This year, the UAE announced a $500 million investment to \nFalcon Foundation to develop open-source generative AI models and provide technology access to emerging \neconomies.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Unlocking Funding",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "755 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "Unlocking Funding\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 755 words\nByline: Annapurna Roy & Suraksha P\nHighlight: AI Mission will help startups make in India and for the world, say tech investors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of artificial intelligence-based applications and models is a “good starting point” \nas it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372-crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. This will provide Indian companies with their own computing hardware — a scarce resource globally — \nallowing them to create more AI applications and arming the country to compete better with the likes of the US, \nChina and the UK which are ahead in the race to dominate the sunrise sector. \n“The government’s AI mission is incredibly exciting for India and its vibrant startup ecosystem. In-  vesting in 10,000 \nGPUs and making them available to researchers and innovators will make a huge difference as we aim to build \n(India) the AI application capital of the world,” Rajan Anandan, managing director, Peak XV Partners, told ET \nadding that it will provide critical building blocks that AI startups can leverage to “build in India, for India and for the \nworld”. In addition to IndiaAI Innovation Centre for the development and deployment of indigenous Large \nMultimodal Models and domainspecific foundational models in critical sectors, the mission will also provide access \nto targeted funding for AI startups. India now has over 100 generative AI startups, however, the investment into the \nspace has been comparatively small. The US saw nearly $250 billion private investments into AI startups between \n2013 and 2022, while investments in India stood at just $8 billion. Over the same period, China saw $95 billion of \ninvestments while for the UK, the number stood at $18 billion, as per data from the AI Index 2023 Annual Report. \nLast year, Indian conglomerates such as the Tata Group and Reliance Industries announced partnerships with top \nGPU maker Nvidia to obtain computing infrastructure to build their own AI applications. However, startups facing \nresource constraints have been petitioning the government to invest into computing infrastructure to ensure they \nalso get access and do not lose out in the dynamic AI race. The Centre’s latest move will enable these AI startups \nto create foundational models from scratch for a variety of applications, for which they were earlier dependent on \nmodels from the likes of OpenAI and Meta. Vishal Dhupar, managing director for South Asia at Nvidia, said that the \ngovernment’s latest outlay creates a “highway” for innovation to happen. “I’m so pleased that the digital \ntransformation has taken place in the country. Now you can embed AI into it,” he said while speaking at an event in \nthe national capital on Friday. Dhupar added that this enables solutions to be built for India and that solutions built \nhere at population scale are applicable globally. “I'm hoping India’s advantage is to migrate from general purpose \ncompute to accelerated compute, and you will have sufficient highway for this country to make a difference.” Nvidia \nstock has seen an unprecedented rally this year. Chip maker is close to edging out Apple, which is listed second in \nmarket cap table globally. It will provide Reliance Industries access to its most advanced Nvidia GH200 Grace \nUnlocking Funding\nHopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 provides massive \nmemory bandwidth. The GPUs will be made available in the next 18-24 months, said electronics and IT secretary S \nKrishnan on the sidelines of an event on Friday. He added that the government will invite bids from the industry \nunder the mission and provide viability gap funding for this compute infrastructure.  PLAYING CATCH-UP Globally, \ncountries like the UK, Saudi Arabia and the UAE have been shelling big money to acquire AI chips to boost their \ncountries' companies. For instance, the UK is building a national AI resource, as a part of which it would acquire \n5,000 Nvidia GPUs. Saudi Arabia, through the King Abdullah University of Science and Technology, reportedly \nbought 3,000 Nvidia GPUs worth $40,000 each. This year, the UAE announced a $500 million investment to Falcon \nFoundation to develop open-source generative AI models and provide technology access to emerging economies.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "In age of AI, companies put focus on tech & soft skills and ‘internal mobility’",
        "media": "The Economic Times",
        "time": "March 8, 2024",
        "section": "JOBS",
        "length": "546 words",
        "byline": "Debleena Majumdar",
        "story_text": "In age of AI, companies put focus on tech & soft skills and ‘internal mobility’\nThe Economic Times\nMarch 8, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: JOBS\nLength: 546 words\nByline: Debleena Majumdar\nBody\nOrganisations are placing a lot of emphasis on improving the skillsets of employees as the nature of work is \nchanging. Companies are taking care to embed a culture of learning so that the process is continuous. According to \nLinkedIn’s recent Workplace Learning Report, 94% of companies that took part in the survey said it plans to \nenhance employees’ skills in 2024. The survey was conducted by Censuswide with a sample of about 4,323 hiring \nmanagers (middle management) aged 18-77 years in countries such as the UK, Ireland, France, Germany, Italy, \nSpain, the USA, India, Australia, Singapore, Japan, Indonesia, China, the Netherlands, Sweden, MENA and Brazil. \nThe data was collected between the middle of December and early January 2024. The key insights of the report \nwere that along with upskilling, aligning the learning programmes to business goals and creating a learning culture \nremain the focus areas for professions in the learning and development (L&D) industry. The underlying reasons are \nclear: in the face of ongoing AI and automation, 98% of the employers have felt the need for significant shifts in the \nskills of the employees. Meanwhile, about half of the hiring managers said they are prioritising internal mobility to \nenable better career advancement opportunities for employees. What does this mean in terms of skills?Apart from \ncore technology skills, the report said that 91% of the L&D professionals identify soft skills as critical. \nCommunication was the most in-demand skill across APAC countries, including in India. As with other studies, \nproblem-solving and critical thinking are other high-demand skills as people try to make sense of the current \ntransformational shifts in work. These are considered the most important in the era of AI.Clarifying this trend, \nRuchee Anand, Senior Director-Talent, Learning and Engagement Solutions, LinkedIn India, says, “Last year, we \nsaw a 21x surge in job postings mentioning ChatGPT or GPT on LinkedIn, reflecting the growing demand for tech \nskills as businesses explored AI. This year, we are seeing a pronounced shift towards skills — both technical and \nsoft skills — to thrive in the era of AI.”Further, Anand added, “With skills for jobs globally expected to change 68% \nby 2030, we are seeing a greater emphasis on learning both technical and soft skills with a majority of employers \nsurveyed agreeing that this balance will be critical for organisations to succeed in the age of AI.”Building a culture of \ncontinuous learningIn terms of specific actions, companies are looking at online training and development \nprogrammes (53%) as well as hands-on experimentation with generative AI tools (54%). This ongoing focus can \nalso help show outcomes. As many as 96% of L&D professionals in India said that they believe they can show \nbusiness value by helping employees gain skills to move into different internal roles; 48% of the hiring managers \nsaid that they believe “helping employees build the skills needed for the future of work” (38%) and “providing \ncompetitive salary and benefits” (31%) are key to retaining top talent. They also said that highlighting career \nadvancement opportunities (59%), and “increasing internal mobility” (51%) are crucial to attract top talent. For \nReprint Rights: timescontent.com\nLoad-Date: March 8, 2024\nIn age of AI, companies put focus on tech & soft skills and ‘internal mobility’"
    },
    {
        "file_name": "Middle_School_pupils_have_been_disciplined_in_the_incident._Mar2024",
        "header": "CITY & STATE; Students expelled over fake nude images; Five Beverly Vista",
        "media": "Middle School pupils have been disciplined in the incident.",
        "time": "March 9, 2024",
        "section": "CALIFORNIA; Metro Desk; Part B; Pg. 1",
        "length": "530 words",
        "byline": "Jon Healey",
        "story_text": "CITY & STATE; Students expelled over fake nude images; Five Beverly Vista \nMiddle School pupils have been disciplined in the incident.\nLos Angeles Times\nMarch 9, 2024 Saturday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: CALIFORNIA; Metro Desk; Part B; Pg. 1\nLength: 530 words\nByline: Jon Healey\nBody\nFive Beverly Hills eighth-graders have been expelled for their involvement in the creation and sharing of fake nude \npictures of their classmates.\nThe Beverly Hills Unified School District board of education voted at a special meeting Wednesday evening to \napprove stipulated agreements of expulsion with five students. According to a source close to the investigation, the \nexpelled students were attending Beverly Vista Middle School. Under a stipulated agreement, the students and their \nparents do not contest the punishment and no hearing was held.\nThe names of the students were not released, and the agreements are confidential. Typically, however, such \nagreements specify how long a student is expelled and what the terms are for their return to the district.\nAccording to Supt. Michael Bregy, the five students who were the focus of its investigation were the \"most \negregiously involved\" in the creation and sharing of the images, which superimposed pictures of real students' faces \nonto simulated nude bodies generated by artificial intelligence. The victims, the district said, were 16 eighth-grade \nstudents.\nShared through messaging apps, the images outraged parents and school officials, prompting Bregy to tell parents \nin a message last month that he was prepared to impose \"the most severe disciplinary actions allowed by state \nlaw.\" The students involved were identified and disciplined in less than 24 hours, but the district did not move to \nexpel them until it completed its investigation.\nThe Beverly Hills Police Department and the Los Angeles County district attorney's office are still investigating the \nincident, but no arrests have been made or charges brought. California's laws against possessing child \npornography and sharing nonconsensual nude pictures do not specifically apply to AI-generated images, which \nlegal experts say would pose a problem for prosecutors.\nThe fake nudes circulated briefly among Beverly Vista students in late February, school officials say. They haven't \nspecified how the images were made, other than to say it involved generative A.I.\nDozens of A.I.-powered apps are available online to \"undress\" someone in a photo, simulating what a person would \nlook like if they'd been nude when the shot was taken. Other A.I.-based tools allow you to \"face swap\" a targeted \nperson's face onto another person's body.\n\"This incident has spurred crucial discussions on the ethical use of technology, including AI, underscoring the \nimportance of vigilant and informed engagement within digital environments,\" Bregy said in a message to parents. \nCITY & STATE Students expelled over fake nude images Five Beverly Vista Middle School pupils have been \ndisciplined in the incident.\n\"Our district is steadfast in its commitment to enhancing education around digital citizenship, privacy, and safety for \nour students, staff, and parents which was immediately reemphasized at all schools.\"\nNo specific policy change has been announced in response to the incident, but the district had already prohibited \nstudents from using cellphones on campus.\nBregy said the images, reported to school officials Feb. 21, were contained within 24 hours.\n\"We recognize that kids are still learning and growing, and mistakes are part of this process,\" he said in the \nmessage. \"However, accountability is essential.\"\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "Store_Mar2024",
        "header": "Apple Reverses Course and Allows Epic Games to Start Competing App",
        "media": "Store",
        "time": "March 9, 2024",
        "section": "TECHNOLOGY",
        "length": "516 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple Reverses Course and Allows Epic Games to Start Competing App \nStore\nThe New York Times \nMarch 8, 2024 Friday 00:14 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 516 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: After an inquiry by European regulators, Epic Games said Apple would allow it to access the software \ntools necessary to develop a game store.\nBody\nAfter an inquiry by European regulators, Epic Games said Apple would allow it to access the software tools \nnecessary to develop a game store.\nDays after Epic Games, the maker of Fortnite, complained publicly that Apple had blocked it from starting a \ncompeting app store in Europe, the technology companies said Apple had reversed course and would allow Epic to \ngo ahead with its plan.\nThe reversal highlights the way that Apple is changing its operations to comply with a new European tech \ncompetition law. That law, the Digital Markets Act, which went into effect on Thursday, requires Apple to give app \nmakers alternatives for selling software to iPhone and iPad users, including the ability to use competing app stores \nand payment systems other than its own.\nBy opening up the iPhone to competing stores, European regulators hope that smartphone users across the region \nwill benefit from lower prices. Epic Games, which planned to start a competing app store, currently takes a 12 \npercent commission for every game it sells on personal computers and other platforms. The fee is less than half of \nthe 30 percent that Apple typically collects.\n“People ask: Why do you need another app store?” said Justin Kan, one of the founders of the video game \nstreaming service Twitch and the creator of Stash, an open payments platform for video game companies. “But \ncompetition generally creates lower prices. Ultimately, it’s probably good for Apple because it could grow the market \nof apps.”\nApple and Epic have been feuding over App Store commission for years. In 2020, Epic broke the App Store’s rules \nby encouraging customers to pay it directly for features in Fortnite. Apple threw Epic out of the App Store, and Epic \nsued Apple for violating antitrust law by requiring developers to use its payment system.\nThe feud was reignited in the wake of Europe’s competition law. Epic planned to start a competing app store called \nthe Epic Games Store through a subsidiary in Sweden. Initially, Apple granted the subsidiary, Epic Games Sweden \nA.B., a developer account so that it could access the software tools necessary for the release.\nBut Apple later terminated Epic’s account, saying that it couldn’t trust Epic to follow its rules. Apple also complained \nthat Tim Sweeney, Epic’s chief executive, had called Apple’s plan to comply with the new tech law “hot garbage.”\nApple Reverses Course and Allows Epic Games to Start Competing App Store\nOn Wednesday, Mr. Sweeney said that he had assured Apple that Epic would follow the rules. He also released \nemails where he made those assurances directly to Apple.\nAn Apple spokesman said Friday that Epic had committed to following its rules, including its policies in Europe.\nMr. Sweeney said that Apple changed its plan after a “swift inquiry” by European regulators. He called it “a big win \nfor European rule of law, for the European Commission, and for the freedom of developers worldwide to speak up.”\nPHOTO: Apple’s shift in its dispute with Epic Games highlights the company’s operations changes as it complies \nwith a new European technology law. (PHOTOGRAPH BY MICHAEL M. SANTIAGO/GETTY IMAGES) This article \nappeared in print on page B6.\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "GPU access to power up India’s AI play: experts",
        "media": "The Economic Times",
        "time": "March 9, 2024",
        "section": "TECH & INTERNET",
        "length": "1034 words",
        "byline": "Annapurna Roy and Suraksha P",
        "story_text": "GPU access to power up India’s AI play: experts\nThe Economic Times\nMarch 9, 2024 Saturday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1034 words\nByline: Annapurna Roy and Suraksha P\nBody\nIndia’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are deemed essential for \nthe creation of artificial intelligence-based applications and models is a “good starting point” as it strives to stay \napace with global leaders in the rapidly evolving area of AI innovation, top investors and technologists said.The Rs \n10,372-crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on a public-private partnership \nmodel. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-service. This will provide Indian \ncompanies with their own computing hardware — a scarce resource globally — allowing them to create more AI \napplications and arming the country to compete better with the likes of the US, China and the UK which are ahead \nin the race to dominate the sunrise sector.“The government’s AI mission is incredibly exciting for India and its \nvibrant startup ecosystem. \nInvesting in 10,000 GPUs and making them available to researchers and innovators will make a huge difference as \nwe aim to build (India) the AI application capital of the world,” Rajan Anandan, managing director, Peak XV \nPartners, told ET adding that it will provide critical building blocks that AI startups can leverage to “build in India, for \nIndia and for the world”.In addition to IndiaAI Innovation Centre for the development and deployment of indigenous \nLarge Multimodal Models and domain-specific foundational models in critical sectors, the mission will also provide \naccess to targeted funding for AI startups.India now has over 100 generative AI startups, however, the investment \ninto the space has been comparatively small. The US saw nearly $250 billion private investments into AI startups \nbetween 2013 and 2022, while investments in India stood at just $8 billion. Over the same period, China saw $95 \nbillion of investments while for the UK, the number stood at $18 billion, as per data from the AI Index 2023 Annual \nReport.Last year, Indian conglomerates such as the Tata Group and Reliance Industries announced partnerships \nwith top GPU maker Nvidia to obtain computing infrastructure to build their own AI applications. However, startups \nfacing resource constraints have been petitioning the government to invest into computing infrastructure to ensure \nthey also get access and do not lose out in the dynamic AI race.The Centre’s latest move will enable these AI \nstartups to create foundational models from scratch for a variety of applications, for which they were earlier \ndependent on models from the likes of OpenAI and Meta.Vishal Dhupar, managing director for South Asia at Nvidia, \nsaid that the government’s latest outlay creates a “highway” for innovation to happen. “I’m so pleased that the digital \ntransformation has taken place in the country. Now you can embed AI into it,” he said while speaking at an event in \nthe national capital on Friday.Dhupar added that this enables solutions to be built for India and that solutions built \nhere at population scale are applicable globally. “I'm hoping India’s advantage is to migrate from general purpose \ncompute to accelerated compute, and you will have sufficient highway for this country to make a difference.”Nvidia \nstock has seen an unprecedented rally this year, which has pushed its market cap beyond $2.3 trillion, making it the \nthird-largest company globally.It will provide Reliance Industries access to its most advanced Nvidia GH200 Grace \nHopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 provides massive \nmemory bandwidth.The GPUs will be made available in the next 18-24 months, said electronics and IT secretary S \nKrishnan on the sidelines of an event on Friday.He added that the government will invite bids from the industry \nunder the mission and provide viability gap funding for this compute infrastructure.Playing catchupGlobally, \nGPU access to power up India ’s AI play: experts\ncountries like the UK, Saudi Arabia and the UAE have been shelling big money to acquire AI chips to boost their \ncountries' companies. For instance, the UK is building a national AI resource, as a part of which it would acquire \n5,000 Nvidia GPUs. Saudi Arabia, through the King Abdullah University of Science and Technology, reportedly \nbought 3,000 Nvidia GPUs worth $40,000 each. This year, the UAE announced a $500 million investment to Falcon \nFoundation to develop open-source generative AI models and provide technology access to emerging \neconomies.Pointing out that the “market of GPUs is very dynamic with new technologies coming in and rendering \nexisting technologies outdated,” Tanuj Bhojwani, head, people+ai, an initiative by Infosys co-founder Nandan \nNilekani’s EkStep Foundation, said “ the government should play the role of investor and not (of) a purchaser or a \ncustomer.”“Merely going out into the market and purchasing 10,000 GPUs may not do the trick, the government \nshould think like an investor,” he added.People+ai has been working on a digital public infrastructure (DPI) for \ncreating a network of interoperable data centres in the country.Boost for startupsStartups are terming Thursday’s \nannouncement as ‘historic’ and said it could bring in a ‘transformative era’ for India’s AI landscape as it offers “ \naffordable compute”.“High-quality, well-organised data is the bedrock of all AI developments, and the mission will \nhelp harness India's vast data repository for the larger good of society, especially in fields like healthcare and \nagriculture,” said Kunal Bahl, co-founder of Snapdeal and Titan Capital.Others such as Gangandeep Reehal, chief \nexecutive of Minus Zero, said, “creating shared infrastructure for AI was a much-needed boost in this global AI race, \nsimilar to what UPI did for fintech.”Minus Zero is a Bengaluru-based AI startup that builds self-driving car \ntechnology. It is building foundational models for autonomous driving.Ankush Sabharwal, chief executive of Corover \nAI which built a large language model BharatGPT, said the initiative is “poised to revolutionise sectors such as \nhealthcare, education, agriculture, banking, travel and governance” as India aims to cultivate a robust and globally \ncompetitive AI ecosystem. For Reprint Rights: timescontent.com\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Goldman Sachs India to train over 1,000 non-engineers in AI",
        "media": "The Economic Times",
        "time": "March 9, 2024",
        "section": "TECH & INTERNET",
        "length": "566 words",
        "byline": "Beena Parmar",
        "story_text": "Goldman Sachs India to train over 1,000 non-engineers in AI\nThe Economic Times\nMarch 9, 2024 Saturday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 566 words\nByline: Beena Parmar\nBody\nAmerican investment bank Goldman Sachs has set up a facility in India to train both engineers and non-engineers \nin generative artificial intelligence (GenAI) to explore the usage of the technology in its businesses.Since 2006, \nGoldman Sachs has invested more than $7 billion in India. Starting off as a support function, the Indian operations \nhave now become the second largest for Goldman Sachs globally.“In 2024, we aim to train over 1,000 non-\nengineering business users across Bengaluru and Hyderabad offices in India … They include individuals across \noperations, controllers, treasury, sales, research and investment banking,” Gunjan Samtani, global chief operating \nofficer of engineering at Goldman Sachs, told ET.The school was piloted in mid-2023, under which the global \nfinancial services major trained employees across asset and wealth management, risk management, global banking \nand markets functions.It aims to have more than 4,000 employees trained in AI, said Samtani, who is also the \ncountry head for Goldman Sachs Services India.About two decades ago, it set up Goldman Sachs Services India in \nBengaluru as one of its global capability centres and now has over 8,500 employees working out of its Bengaluru \nand Hyderabad offices, representing about 18% of the total global headcount. The Hyderabad centre was \ninaugurated in October last year.Half of the 8,500 staffers in India are engineers, representing one-third of the \n12,000 engineers Goldman Sachs employs globally. \nWith the largest office presence outside of its headquarters in New York, India also has the highest percentage of \nengineers embedded into Goldman Sachs’ front-to-back businesses.“In the context of distribution of engineers \nacross Americas and India, in totality, I think they are on par with each other,” Samtani said, adding that the bank is \nmaking deliberate efforts to prepare its workforce for AI.This also comes at a time when most technology firms are \nupskilling and reskilling their employees, especially engineers, in order to improve productivity, efficiency as well as \nprepare for better AI use-cases and adapting them to new roles.By the end of the year, according to Samtani, all \nGoldman Sachs engineers in India, who are in roles that are software development centred, will be enabled on \nGenAI based co-pilots. There are about 3,200 engineers who are working in software development-related \nroles.Goldman Sachs has several hundred open roles over a spectrum of functions. Without giving a specific \nnumber, Samtani said: “There will be a tremendous focus in hiring individuals exposed to emerging technologies \nlike AI and cloud engineering. We have open roles in software development and quantitative finance, and \nadditionally in operations, controllers and compliance functions. On the business side, we have roles in our asset \nmanagement, wealth management, global banking and markets businesses.”In 2022 and 2023, the company hired \nan average of 2,000 employees annually in India at the two centres. Around 40% of these were in engineering \nfunctions.Currently, Goldman Sachs has more than 1,000 developers using GenAI for coding.“More than 100 ideas \nhave been identified across the firm, and we currently have about a dozen proofs of concept. Certain elements of \ninternal use cases are planned for roll-out to a broader population throughout 2024,” Samtani said. For Reprint \nRights: timescontent.com\nLoad-Date: March 9, 2024\nGoldman Sachs India to train over 1,000 non-engineers in AI"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Sam Altman Asserts Control of OpenAI as He Rejoins Its Board",
        "media": "The New York Times",
        "time": "March 9, 2024",
        "section": "TECHNOLOGY",
        "length": "1505 words",
        "byline": "Cade Metz, Tripp Mickle and Mike Isaac Cade Metz writes about artificial intelligence, driverless cars,",
        "story_text": "Sam Altman Asserts Control of OpenAI as He Rejoins Its Board\nThe New York Times \nMarch 8, 2024 Friday 23:08 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1505 words\nByline: Cade Metz, Tripp Mickle and Mike Isaac Cade Metz writes about artificial intelligence, driverless cars, \nrobotics, virtual reality and other emerging areas of technology. Tripp Mickle reports on Apple and Silicon Valley for \nThe Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and \npolitical challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and \nrobot taxis. Mike Isaac is a technology correspondent for The Times based in San Francisco. He regularly covers \nFacebook and Silicon Valley.\nHighlight: Mr. Altman, whose sudden firing and rehiring in the fall shocked Silicon Valley, was among several new \nadditions to the board announced on Friday.\nBody\nMr. Altman, whose sudden firing and rehiring in the fall shocked Silicon Valley, was among several new additions to \nthe board announced on Friday.\nThe conclusion of an investigation into the chaotic firing of Sam Altman from OpenAI more than three months ago \nrepresented a resounding victory for the high-profile chief executive as he moves to reassert control of the artificial \nintelligence company he helped to create.\nOpenAI, in a news conference on Friday, said that Mr. Altman, who returned to OpenAI just five days after he was \npushed out in November, did not do anything that justified his removal and would regain the one role at the \ncompany that still eluded him: a seat on the company’s board of directors.\nMr. Altman’s ouster stunned Silicon Valley and imperiled the future of one of the tech industry’s most influential \nstart-ups. It also called into question whether OpenAI — with or without Mr. Altman in charge — was ready to carry \nthe banner for the tech industry’s rabid focus on artificial intelligence.\nWhen he returned to OpenAI in November, Mr. Altman did not regain his board seat while agreeing to an \ninvestigation of his behavior and the board’s actions. Two members who voted for his removal agreed to step down; \ntheir replacements, from outside the company, oversaw the investigation by the law firm, WilmerHale. Bret Taylor, \nchairman of OpenAI’s board, said during the news conference that the highly anticipated report about the episode \nwas finished, but the company did not release the report.\nThe company said that the law firm’s report found that OpenAI’s board acted within its broad discretion to terminate \nMr. Altman, but also found that his conduct did not mandate removal.\n“The special committee recommended and the full board expressed their full confidence in Mr. Altman and Mr. \nBrockman,” Mr. Taylor said, referring to Greg Brockman, the company president who quit in protest after Mr. Altman \nwas removed. “We are excited and unanimous in our support for Sam and Greg.”\nOpenAI also moved to address concerns about a lack of diversity on the board by adding three women as directors: \nSue Desmond-Hellmann, the former chief executive of the Bill &amp; Melinda Gates Foundation; Nicole Seligman, \nthe former general counsel of Sony; and Fidji Simo, the chief executive of Instacart.\nSam Altman Asserts Control of OpenAI as He Rejoins Its Board\nMr. Taylor, who was one of the replacements named to OpenAI’s board in November, said the board would \ncontinue to expand.\nWith the report and the additions to the board, OpenAI’s leadership hoped to move past the controversy of Mr. \nAltman’s ouster. The incident raised myriad questions about his leadership and the San Francisco company’s \nunusual structure — a nonprofit board that oversees a for-profit company.\nBut because it has not released the report, OpenAI has left many questions unanswered about the company. Some \ninsiders have asked whether Mr. Altman had too much control over how the investigation was handled.\n“As we told the investigators, deception, manipulation, and resistance to thorough oversight should be \nunacceptable,” Helen Toner and Tasha McCauley, the two OpenAI board members who left late last year, said in a \nstatement. “We hope the new board does its job in governing OpenAI and holding it accountable to the mission.”\nMr. Taylor appeared alongside Mr. Altman at the news conference on Friday. After announcing the new board \nmembers, he said the review found that the previous board acted in good faith in removing Mr. Altman but did not \nanticipate the challenges that would arise from his dismissal.\n“The review determined the board’s decision did not arise from concern regarding product safety or security,” Mr. \nTaylor said. “It was simply a breakdown in trust between the board and Mr. Altman.”\nAfter Mr. Taylor completed his prepared remarks, Mr. Altman praised the resilience of the company and its partners \nduring and after his removal. “I am pleased this whole thing is over,” he said.\nOpenAI provided a six-paragraph summary of the report. It said that WilmerHale reviewed 30,000 documents and \nconducted dozens of interviews, including with OpenAI’s previous board members.\nIt found that the previous board was accurate in its rationale and public explanation for firing Mr. Altman for not \nbeing “consistently candid in his communications with the board.” It also said that the board didn’t anticipate that its \naction would destabilize the company.\nThe company said that WilmerHale gave oral briefings on the report, which will not be publicly released, to Mr. \nTaylor and Lawrence H. Summers, the former Treasury secretary who was also added to the board in November.\nMr. Taylor said OpenAI had made several changes meant to improve the way the company was run, including new \ngovernance guidelines for the board, a new conflict of interest policy and a whistle-blower hotline.\nOpenAI’s summary of the report did not provide insight into the concerns that the company’s senior leaders brought \nto the previous board about Mr. Altman. Before his dismissal, Ilya Sutskever, OpenAI’s chief scientist, and Mira \nMurati, OpenAI’s chief technology officer, expressed worries about Mr. Altman’s management style, including what \nwas characterized as his history of manipulative behavior, The New York Times has reported.\nDr. Sutskever, through a lawyer, has called those claims “false.” Ms. Murati said in a company Slack post on \nThursday that she shared the same feedback with the board that she had provided directly to Mr. Altman, but said \nshe never reached out to the board to share those concerns.\n“I am happy that the independent review has concluded and we can all move forward united,” Ms. Murati said on \nFriday in a post on X, formerly called Twitter.\nOpenAI is still being investigated by the Securities and Exchange Commission over the board’s actions and the \npossibility that Mr. Altman misled investors. Companies that hire outside law firms often turn over the report to \npublic investigators after completion. A spokeswoman for OpenAI’s board declined to say whether it would provide \nthe report to the S.E.C.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nSam Altman Asserts Control of OpenAI as He Rejoins Its Board\nOpenAI, which was valued at more than $80 billion in its latest financing round, sits at the forefront of generative \nA.I., technologies that can generate text, images and sounds. Many believe that generative A.I. could transform \nthe technology industry as thoroughly as the web browser did about three decades ago. Others worry that the \ntechnology could cause serious harm, helping to spread online disinformation, replacing countless jobs and maybe \neven threatening the future of humanity.\nAfter OpenAI released the online chatbot ChatGPT in late 2022, Mr. Altman became the face of the industry’s push \ntoward generative A.I. About a year later, the board unexpectedly dismissed him, saying it no longer had \nconfidence in his ability to run the company.\nThe board had shrunk to six people: three founders and three independent members. Along with the three \noutsiders, Dr. Sutskever, one of OpenAI’s founders, voted to remove Mr. Altman as chief executive and chairman of \nthe board, saying without providing specifics that he had not been “consistently candid in his communications.”\nMr. Brockman, another founder, resigned from the company in protest. Days later, Dr. Sutskever said he regretted \nhis decision to remove Mr. Altman and effectively stepped down from the board, leaving three independent \nmembers standing in opposition to Mr. Altman.\nOpenAI was founded as a nonprofit in 2015, before Mr. Altman created a for-profit subsidiary three years later and \nraised $1 billion from Microsoft. The board of the nonprofit, whose stated mission was to build A.I. for the benefit of \nhumanity, maintained complete control over the new subsidiary. Investors, including Microsoft, had no legal say in \nwho ran the company.\nIn an effort to resolve the turmoil and return Mr. Altman to the company, he and the board agreed to replace two \nmembers with Mr. Taylor, who is a former Salesforce executive. But Mr. Altman was not reinstated to the board. Mr. \nTaylor and Mr. Summers were charged with overseeing the investigation into Mr. Altman and his dismissal.\nMicrosoft, a close partner of OpenAI, has a board observer position, which is filled by Dee Templeton, the \ncompany’s vice president, technology and research partnerships. Microsoft declined on Friday to comment on the \nboard and report.\nThe new board faced criticism from corporate governance experts because of its lack of diversity. Mr. Taylor told \nThe Times in November that he would fill out the board by adding “qualified, diverse candidates” who embodied \n“the fullness of what this mission represents, which is going to span technology, A.I. safety policy.”\nKaren Weise contributed reporting.\nPHOTO: An investigation concluded that Sam Altman, a founder of OpenAI, did not do anything that justified his \nremoval in November. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) This article appeared in print on \npage A19.\nLoad-Date: March 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Altman Reasserts Control of OpenAI and Regains a Seat on Its Board",
        "media": "The New York Times",
        "time": "March 10, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 19",
        "length": "1483 words",
        "byline": "By Cade Metz, Tripp Mickle and Mike Isaac",
        "story_text": "Altman Reasserts Control of OpenAI and Regains a Seat on Its Board\nThe New York Times\nMarch 10, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 19\nLength: 1483 words\nByline: By Cade Metz, Tripp Mickle and Mike Isaac\nBody\nMr. Altman, whose sudden firing and rehiring in the fall shocked Silicon Valley, was among several new additions to \nthe board announced on Friday.\nThe conclusion of an investigation into the chaotic firing of Sam Altman from OpenAI more than three months ago \nrepresented a resounding victory for the high-profile chief executive as he moves to reassert control of the artificial \nintelligence company he helped to create. \n  OpenAI, in a news conference on Friday, said that Mr. Altman, who returned to OpenAI just five days after he was \npushed out in November, did not do anything that justified his removal and would regain the one role at the \ncompany that still eluded him: a seat on the company's board of directors.\n  Mr. Altman's ouster stunned Silicon Valley and imperiled the future of one of the tech industry's most influential \nstart-ups. It also called into question whether OpenAI -- with or without Mr. Altman in charge -- was ready to carry \nthe banner for the tech industry's rabid focus on artificial intelligence.\n  When he returned to OpenAI in November, Mr. Altman did not regain his board seat while agreeing to an \ninvestigation of his behavior and the board's actions. Two members who voted for his removal agreed to step down; \ntheir replacements, from outside the company, oversaw the investigation by the law firm, WilmerHale. Bret Taylor, \nchairman of OpenAI's board, said during the news conference that the highly anticipated report about the episode \nwas finished, but the company did not release the report.\n  The company said that the law firm's report found that OpenAI's board acted within its broad discretion to \nterminate Mr. Altman, but also found that his conduct did not mandate removal.\n  ''The special committee recommended and the full board expressed their full confidence in Mr. Altman and Mr. \nBrockman,'' Mr. Taylor said, referring to Greg Brockman, the company president who quit in protest after Mr. Altman \nwas removed. ''We are excited and unanimous in our support for Sam and Greg.''\n  OpenAI also moved to address concerns about a lack of diversity on the board by adding three women as \ndirectors: Sue Desmond-Hellmann, the former chief executive of the Bill & Melinda Gates Foundation; Nicole \nSeligman, the former general counsel of Sony; and Fidji Simo, the chief executive of Instacart.\n  Mr. Taylor, who was one of the replacements named to OpenAI's board in November, said the board would \ncontinue to expand.\nAltman Reasserts Control of OpenAI and Regains a Seat on Its Board\n  With the report and the additions to the board, OpenAI's leadership hoped to move past the controversy of Mr. \nAltman's ouster. The incident raised myriad questions about his leadership and the San Francisco company's \nunusual structure -- a nonprofit board that oversees a for-profit company.\n  But because it has not released the report, OpenAI has left many questions unanswered about the company. \nSome insiders have asked whether Mr. Altman had too much control over how the investigation was handled.\n  ''As we told the investigators, deception, manipulation, and resistance to thorough oversight should be \nunacceptable,'' Helen Toner and Tasha McCauley, the two OpenAI board members who left late last year, said in a \nstatement. ''We hope the new board does its job in governing OpenAI and holding it accountable to the mission.''\n  Mr. Taylor appeared alongside Mr. Altman at the news conference on Friday. After announcing the new board \nmembers, he said the review found that the previous board acted in good faith in removing Mr. Altman but did not \nanticipate the challenges that would arise from his dismissal.\n  ''The review determined the board's decision did not arise from concern regarding product safety or security,'' Mr. \nTaylor said. ''It was simply a breakdown in trust between the board and Mr. Altman.''\n  After Mr. Taylor completed his prepared remarks, Mr. Altman praised the resilience of the company and its \npartners during and after his removal. ''I am pleased this whole thing is over,'' he said.\n  OpenAI provided a six-paragraph summary of the report. It said that WilmerHale reviewed 30,000 documents and \nconducted dozens of interviews, including with OpenAI's previous board members.\n  It found that the previous board was accurate in its rationale and public explanation for firing Mr. Altman for not \nbeing ''consistently candid in his communications with the board.'' It also said that the board didn't anticipate that its \naction would destabilize the company.\n  The company said that WilmerHale gave oral briefings on the report, which will not be publicly released, to Mr. \nTaylor and Lawrence H. Summers, the former Treasury secretary who was also added to the board in November.\n  Mr. Taylor said OpenAI had made several changes meant to improve the way the company was run, including \nnew governance guidelines for the board, a new conflict of interest policy and a whistle-blower hotline.\n  OpenAI's summary of the report did not provide insight into the concerns that the company's senior leaders \nbrought to the previous board about Mr. Altman. Before his dismissal, Ilya Sutskever, OpenAI's chief scientist, and \nMira Murati, OpenAI's chief technology officer, expressed worries about Mr. Altman's management style, including \nwhat was characterized as his history of manipulative behavior, The New York Times has reported.\n  Dr. Sutskever, through a lawyer, has called those claims ''false.'' Ms. Murati said in a company Slack post on \nThursday that she shared the same feedback with the board that she had provided directly to Mr. Altman, but said \nshe never reached out to the board to share those concerns.\n  ''I am happy that the independent review has concluded and we can all move forward united,'' Ms. Murati said on \nFriday in a post on X, formerly called Twitter.\n  OpenAI is still being investigated by the Securities and Exchange Commission over the board's actions and the \npossibility that Mr. Altman misled investors. Companies that hire outside law firms often turn over the report to \npublic investigators after completion. A spokeswoman for OpenAI's board declined to say whether it would provide \nthe report to the S.E.C.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  OpenAI, which was valued at more than $80 billion in its latest financing round, sits at the forefront of generative \nA.I., technologies that can generate text, images and sounds. Many believe that generative A.I. could transform \nAltman Reasserts Control of OpenAI and Regains a Seat on Its Board\nthe technology industry as thoroughly as the web browser did about three decades ago. Others worry that the \ntechnology could cause serious harm, helping to spread online disinformation, replacing countless jobs and maybe \neven threatening the future of humanity.\n  After OpenAI released the online chatbot ChatGPT in late 2022, Mr. Altman became the face of the industry's \npush toward generative A.I. About a year later, the board unexpectedly dismissed him, saying it no longer had \nconfidence in his ability to run the company.\n  The board had shrunk to six people: three founders and three independent members. Along with the three \noutsiders, Dr. Sutskever, one of OpenAI's founders, voted to remove Mr. Altman as chief executive and chairman of \nthe board, saying without providing specifics that he had not been ''consistently candid in his communications.''\n  Mr. Brockman, another founder, resigned from the company in protest. Days later, Dr. Sutskever said he regretted \nhis decision to remove Mr. Altman and effectively stepped down from the board, leaving three independent \nmembers standing in opposition to Mr. Altman.\n  OpenAI was founded as a nonprofit in 2015, before Mr. Altman created a for-profit subsidiary three years later and \nraised $1 billion from Microsoft. The board of the nonprofit, whose stated mission was to build A.I. for the benefit of \nhumanity, maintained complete control over the new subsidiary. Investors, including Microsoft, had no legal say in \nwho ran the company.\n  In an effort to resolve the turmoil and return Mr. Altman to the company, he and the board agreed to replace two \nmembers with Mr. Taylor, who is a former Salesforce executive. But Mr. Altman was not reinstated to the board. Mr. \nTaylor and Mr. Summers were charged with overseeing the investigation into Mr. Altman and his dismissal.\n  Microsoft, a close partner of OpenAI, has a board observer position, which is filled by Dee Templeton, the \ncompany's vice president, technology and research partnerships. Microsoft declined on Friday to comment on the \nboard and report.\n  The new board faced criticism from corporate governance experts because of its lack of diversity. Mr. Taylor told \nThe Times in November that he would fill out the board by adding ''qualified, diverse candidates'' who embodied \n''the fullness of what this mission represents, which is going to span technology, A.I. safety policy.''\n  Karen Weise contributed reporting.\nhttps://www.nytimes.com/2024/03/08/technology/sam-altman-to-return-to-openais-board-of-directors.html\nGraphic\n \nPHOTO: An investigation concluded that Sam Altman, a founder of OpenAI, did not do anything that justified his \nremoval in November. (PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) This article appeared in print on \npage A19.               \nLoad-Date: March 10, 2024"
    },
    {
        "file_name": "HOPEFUL?'_Mar2024",
        "header": "ARTIFICIAL INTELLIGENCE IS HERE TO STAY - 'WHO'S ON TEAM",
        "media": "HOPEFUL?'",
        "time": "March 10, 2024",
        "section": "BUSINESS; Pg. E-3",
        "length": "628 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "ARTIFICIAL INTELLIGENCE IS HERE TO STAY - 'WHO'S ON TEAM \nHOPEFUL?'\nPittsburgh Post-Gazette\nMarch 10, 2024 Sunday\nEAST EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: BUSINESS; Pg. E-3\nLength: 628 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nPete Buttigieg has boring ideas for AI. But like many politicians, he's thinking practically.\nEarlier this year, on a visit to Pittsburgh that included a Q&A with college students at Carnegie Mellon University, \nthe U.S. transportation secretary dished on the Boeing blowout and drew hope from fatherhood before delving \nbriefly into CMU's signature technology: artificial intelligence.\nMr. Buttigieg admitted that his vision for the much-hyped computer tool wasn't exactly sexy.\nEmails made the list, along with other administrative tasks.\nIf applied to driverless cars, maybe cities could gain some space by eliminating parking spots, the former mayor of \nSouth Bend, Ind., mused.\nThat a chief Biden administration official would have such simple, utilitarian uses for AI - a technology already used \nby nearly every Fortune 500 company - shows just how quickly ChatGPT and its cousin products have been \nnormalized.\n\"Who's on team hopeful?\" Mr. Buttigieg asked the audience at CMU. More than half raised their hands.\n\"I hope you're right,\" he said.\nThe 2020 presidential candidate noted that his boss and former rival, Joe Biden, has endorsed AI.\nLast fall, under pressure to keep up with his European counterparts, Mr. Biden circulated one of the largest \nexecutive orders ever written, urging every federal department to explore the potential pitfalls and promise of \nartificial intelligence.\nPennsylvania Gov. Josh Shapiro, a rising star in the Democratic party, also has tried to be a leader in AI. Last fall, \nhe signed his own executive order, establishing a committee that chose OpenAI as its first commercial client.\nThrough a $108,000 pilot, Pennsylvania employees are to start using ChatGPT to speed up administrative tasks, \nmuch like Mayor Pete suggested.\nI've reported for the Post-Gazette on the makeup of this Pennsylvania AI committee. Nobody on it is an expert in AI. \nBut they don't see that as a problem. In interviews shortly after their promotion, the senior administration officials \nARTIFICIAL INTELLIGENCE IS HERE TO STAY - 'WHO'S ON TEAM HOPEFUL?'\nsaid very few people actually have expertise in generative AI - the latest iteration and the brains behind ChatGPT, \nwhich, if you've never tried it, is already smart enough to draft A+ English papers in a matter of minutes.\nPennsylvania, like many private companies, has said ChatGPT won't replace human workers.\nBut after a year of rapid introduction to companies as storied and set in their ways as PPG and U.S. Steel, the new \ntagline for ChatGPT and other generative AI tech seems to be: Get with the program, or fall behind.\nAnd that could be a big problem for parts of Western Pennsylvania that are still waiting for a far more basic \ntechnology: Wi-Fi.\nWhen Mr. Shapiro's digital strategy director Annie Newman came to Pittsburgh last fall for an AI conference at \nDuquesne University, she and other panelists noted that you can't start talking about AI with rural Pennsylvanians \nwithout first addressing the issue of broadband.\nThat technological gulf likely will widen unless intentional efforts are made to train people and help them adapt.\nBut it should be said: Training can be fun.\nWhen I first discovered ChatGPT in December 2022, I wrote poetry and movie scripts, casting my friends by \nfeeding the website character traits like \"lazy\" and \"insightful.\"\nAs our first year with ubiquitous AI took shape, we saw so much creativity from people messing around with the \nnew, free tool. Once it gained the ability to create images, the sharing only grew. Perhaps you saw some circulating \nthe internet. And yes, perhaps they freaked you out.\nBut at least there's more beyond the emails and administrative tasks. We're going to see far more uses for \ngenerative AI in 2024.\nHave an AI question? Contact tech reporter Evan Robinson-Johnson at ejohnson@post-gazette.com or on X \n@sightsonwheels.\nLoad-Date: March 10, 2024"
    },
    {
        "file_name": "New_York_Observer_Mar2024",
        "header": "SXSW: Google, J.Crew Execs Discuss Online Shopping In the Age of A.I.",
        "media": "New York Observer",
        "time": "March 11, 2024",
        "section": "",
        "length": "422 words",
        "byline": "Nhari Djan",
        "story_text": "SXSW: Google, J.Crew Execs Discuss Online Shopping In the Age of A.I.\nNew York Observer\nMarch 9, 2024 Saturday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 422 words\nByline: Nhari Djan\nBody\nArtificial intelligence (A.I.) is affecting every industry. In retail, A.I. means an increasingly personalized experience \nfor shoppers. Tech giants and traditional retail companies are using the technology to create as close of a shopping \nexperience online as a person can get in a store. At this year's SXSW, Lilian Rincon, Google (GOOGL)'s director of \nconsumer shopping, and Danielle Schmelkin, the chief intelligence officer at J.Crew, discussed how they aimed to \nachieve that for their respective companies. \nDuring a presentation yesterday (March 8), Rincon spoke about existing \"gaps\" in online shopping between \ncustomer satisfaction and the products they purchase. She cited data showing that as much as 60 percent of online \nshoppers return a purchase because it doesn't meet their expectation and more than half of shoppers \"don't feel \nrepresented when they go online.\"\nRincon demonstrated technology from Google's try-on feature, which uses A.I. to show how clothing would look on \nmodels of different shapes, sizes, skin tones and genders. For her, A.I. can be used to effectively show how clothes \nand fabric move and mold to the contours of different body types. The feature can also show the clothes look in \ndifferent poses. Merchants only need to take pictures of a clothing item on a flat surface, and Google's generative \nA.I. will then turn it into an image showing a person wearing the item. \nJ.Crew's Schmelkin pointed out that A.I. can help improve discoverability for shoppers. Oftentimes, a shopper can't \nfind the item that they're looking for because they are using a different or wrong set of search terms, according to \nthe intelligence officer. Attaching more attributes to the clothes will make them easier for customers to find. \n\"What we want to do is augment every one of our products with probably close to 90 attributes and synonyms,\" \nSchmelkin said. \"Because we're finding more and more people are getting a lot looser in how they're searching for \nthings, we want to make sure you can find what you're looking for, this helps us tremendously.\" \nThe two executives are also thinking about how Gen Z will shop with A.I. According to Rincon, the age group of 11-\n26 sees shopping as a form of entertainment. This demographic group also takes to visual searching, or searching \nwith their phone cameras, instead of typing in keywords.\n\"Ten years ago, a lot of it was text. Now we see lens actually being much more popular,\" Rincon observed. \"A lot of \nthe younger generation is actually searching with their camera.\"\nLoad-Date: March 11, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "ETtech Explainer: Nvidia hit with AI copyright lawsuit",
        "media": "The Economic Times",
        "time": "March 11, 2024",
        "section": "TECH BYTES",
        "length": "480 words",
        "byline": "Annapurna Roy",
        "story_text": "ETtech Explainer: Nvidia hit with AI copyright lawsuit\nThe Economic Times\nMarch 12, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH BYTES\nLength: 480 words\nByline: Annapurna Roy\nBody\nThree authors have filed a lawsuit against graphics processing unit (GPU) giant Nvidia for illegally training its \nartificial intelligence (AI) platform NeMo on their copyrighted works. This is another development in the growing \ntensions globally involving intellectual property right holders and companies that make AI models, resulting in \nsimilar lawsuits that saw entities such as Microsoft and OpenAI cross swords.Here's an explainer of what the Nvidia \nlawsuit says and what these concerns are.Who are the authors?Authors Brian Keene, Abdi Nazemian, and Stewart \nO’Nan proposed a class action lawsuit against Nvidia in a San Francisco federal court on Friday.Keene’s 2008 \nnovel ‘Ghost Walk’, Nazemian’s 2019 novel ‘Like a Love Story’, and O’Nan’s 2007 novella ‘Last Night at the \nLobster’ are the works allegedly used as data input for Nvidia’s AI platform NeMo, Reuters reported.Nvidia \ndescribes NeMo as a ‘toolkit’ for conversational AI and natural language processing. Users can leverage the \n‘building blocks’ the platform provides to efficiently create their own generative AI.Gen AI is built using large \nlanguage models which are trained on vast amounts of data. Major AI players like OpenAI have said that gen AI \nmodels do not infringe copyright as they are “transformative” in nature.\nETtech Explainer: Legal tussle between OpenAI and NYTWhat are the allegations?The authors argue that their \nbooks were included in a dataset of about 196,640 books used to train NeMo to simulate ordinary written \nlanguage.They were taken down in October for ‘reported copyright infringement’. The authors say that this proves \nNvidia admitted to the alleged violation.The lawsuit seeks damages from Nvidia, of an unspecified amount, for \npeople in the US whose works were used without permission to train NeMo in the last three years, Reuters \nreported.With the surge in demand for AI, the GPU-maker’s stocks have seen an unprecedented rally in recent \nweeks. It became the third-largest company in the world behind Microsoft and Apple, with its market capitalisation \ncrossing $2.3 trillion.Also read | Nvidia on cusp of overtaking Apple as second-most-valuable companyGrowing \nconcernsPreviously, ChatGPT-maker OpenAI and its major investor Microsoft have been sued by the New York \nTimes and several Pulitzer-winning authors for allegedly training their AI models on copyrighted material worth \nbillions of dollars.In India, ET reported on January 26 that news publishers are seeking changes to the Information \nTechnology Rules for protection against copyright infringement in the process of training AI models and ensuring \nfair compensation.Some companies have entered licensing deals to use data legitimately. For instance, Google in \nFebruary cut a $60 million per year deal with community forum website Reddit for real-time access to its data for AI \ntraining. For Reprint Rights: timescontent.com\nLoad-Date: March 11, 2024"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "How to address artificial intelligence in the workplace",
        "media": "USA Today",
        "time": "March 12, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "871 words",
        "byline": " ",
        "story_text": "How to address artificial intelligence in the workplace\nUSA Today\nMarch 12, 2024 Tuesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 871 words\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader's Guide to Work in an Age of Upheaval.\"\nQuestion: My job does not have a policy for the use of artificial intelligence. I started regularly using generative AI \nin my work but have yet to tell my boss. Should I let him know that I use ChatGPT for work? - Caleb\nAnswer: Absolutely. It's crucial to communicate with your boss about your use of generative AI tools like ChatGPT \nfor work, even if there isn't a formal AI policy in place at your workplace. Here are a few points to consider when \ndiscussing this with your boss:\nData security: Address the issue of data security upfront. Underscore that while generative AI is a valuable tool, \nyou are mindful of the sensitivity of the information it processes. Assure your boss you will refrain from entering \nproprietary or confidential information into ChatGPT and are willing to turn off chat history to uphold data security if \nrequested.\nMisinformation verification: Acknowledge the potential for discrepancies in the information provided by AI tools. \nEmphasize your understanding of the significance of verifying any information obtained via generative AI to ensure \naccuracy. This commitment to fact-checking will help maintain the reliability of the work you produce.\nOverreliance on AI: Address the concern of overreliance on generative AI tools. Acknowledge that while AI is a \npowerful aid in generating content, you are cautious to keep it from overshadowing your own authentic voice. Share \nyour approach to using AI as a starting point, incorporating your personal touch, and avoiding a copy-and-paste \nmentality.\nEthical considerations: Discuss the ethical considerations if you are using AI to influence decisions or products. \nHighlight your awareness of the importance of maintaining ethical standards in your work. Assure your boss you \napproach AI as a supplementary tool and that your decisions align with the company's ethical principles.\nSeek feedback: Express your willingness to receive feedback on your use of AI and inquire if there are specific \ntasks or areas where your boss would like you to apply this technology. This proactive approach demonstrates your \nopenness to collaboration and aligning AI usage with your company's objectives.\nUltimately, artificial intelligence should complement and elevate human intelligence and capability, not replace it. \nEnsuring your uniquely human intellect and intuition are involved in an operation aided by AI will deliver the best \npossible outcome. By addressing these considerations and having an open conversation with your boss, you not \nonly ensure transparency in your work but also contribute to the ongoing dialogue around AI usage in your \nHow to address artificial intelligence in the workplace\nworkplace. Your proactive approach could even help shape a future AI policy to suit your company's needs and \nvalues.\nI've never fared well in a group interview. Do you have any tips for the group interview I have coming up? - Tara\nNavigating group interviews can be challenging, but you can make a positive impact with proper preparation and \nstrategic approaches. Thorough preparation will boost your confidence during the interview.\nBegin with a comprehensive examination of the organization. Understand its values, mission and recent \nachievements. A sound understanding of the company will help you connect to its goals.\nCompile relevant examples from your experience, skills and education. Be ready to articulate how you've overcome \nchallenges in past positions. Practicing with friends or mentors who can provide constructive feedback will bolster \nyour confidence.\nDemonstrate strong networking skills by introducing yourself to group members before the interview begins. \nBuilding a rapport with interviewers and fellow candidates can help alleviate initial anxiety and create a positive \nimpression.\nGroup interviews often focus on teamwork and communication skills. Showcase your ability to collaborate by \nactively participating in group discussions. Emphasize instances where you successfully worked in a team, \nresolving challenges and achieving common goals.\nInvolve the group in your responses by connecting with what other participants have shared. Acknowledge and \nagree with their points when it makes sense. This demonstrates active listening skills and your ability to collaborate \nand build on others' ideas.\nTake note of what others are saying to avoid repetitive points. Look for opportunities to add a nuanced angle or \nexpand on ideas to move the discussion forward. This showcases your ability to think critically and build on existing \nideas.\nStay engaged throughout the group interview. Maintain eye contact, nod affirmatively, and use nonverbal cues to \nshow attentiveness. Avoid distractions and actively participate in group activities or discussions.\nShape your responses to align with the organizational objectives and job role. Have a clear understanding of the \nvalue you can bring to the company culture and the team. Remember to be authentic and distinct, allowing your \nunique qualities to shine.\nJohnny C. Taylor\nColumnist\nUSA TODAY\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Clock Ticks for TikTok; DealBook Newsletter",
        "media": "The New York Times",
        "time": "March 12, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1925 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "The Clock Ticks for TikTok; DealBook Newsletter\nThe New York Times \nMarch 12, 2024 Tuesday 08:17 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1925 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: Advertisers are sticking with the social media platform, even as the House prepares to vote on a bill to \nforce the company to cut its China ties this week.\nBody\nAdvertisers are sticking with the social media platform, even as the House prepares to vote on a bill to force the \ncompany to cut its China ties this week.\nAnother round in the TikTok fight \nThe warnings against TikTok aren’t letting up, with U.S. security officials saying China is using the platform to \nmeddle in elections and lawmakers calling the video app a global threat.\nThe sharp rhetoric isn’t new, but it raises a question for policymakers and business: Is the new push to force \nByteDance, the company’s Chinese owners, to divest a real step change or just political posturing?\nThe House is barreling toward a vote on Wednesday that would force ByteDance to sell. Representative Steve \nScalise, Republican of Louisiana and the majority leader, said yesterday that special measures would be used to \nspeed the process.\nA big worry is TikTok’s ability to push content. The Office of the Director of National Intelligence says that the \nChinese government has used the platform to promote pro-Chinese narratives and to influence American elections. \nBeijing could try to use TikTok to “sideline critics of China and magnify U.S. divisions” in this year’s presidential \nrace.\n(Worth noting: China has also used X and Meta’s platforms to disseminate its messages.)\nThe Clock Ticks for TikTok DealBook Newsletter\nCritics say TikTok’s response is proof it’s spreading misinformation. The app has 170 million users in the U.S. and \nsent push alerts to users over 18, telling them to urge lawmakers to “stop a TikTok ban.” Congressional offices have \nbeen inundated with calls and messages.\nBut the House committee on the Chinese Communist Party that’s behind the legislation accused TikTok of \ndeceiving Americans, saying the bill is not a ban but rather a proposal asking TikTok to sever ties with China and \nByteDance.\nExpect China to hit back. “It’s highly unlikely that Chinese leaders would permit ByteDance to divest from TikTok,” \nGabriel Wildau, a China risk analyst at Teneo, told DealBook. “And the leadership has plenty of legal tools available \nto block a sale, so the bill under discussion is effectively a ban.”\nBut don’t expect business to abandon TikTok. The app has been under threat since 2020, when Donald Trump \nsigned an executive order to force a divestment. (Trump has now changed his mind, adding to the confusion about \nwhether the bill will become law.)\nYet TikTok has become a crucial platform for brands trying to connect with younger consumers. Advertisers spent \nnearly $1.2 billion on TikTok in the fourth quarter of 2023, up 43 percent compared to the first quarter last year.\n“This is an issue that’s been there for years,” Martin Sorrell, a veteran advertising executive, told DealBook. “Until it \ngets resolved, one way or the other, I think advertisers will continue. They are not going to withdraw because of this \nlatest flurry.”\nHERE’S WHAT’S HAPPENING \nA federal judge delivers a labor victory for big franchisers. A rule issued by the National Labor Relations Board that \nwould hold companies like McDonald’s liable for the working conditions of franchisees’ employees was too broad, \nthe judge, based in the Eastern District of Texas, decided. The N.L.R.B. may appeal the decision.\nMeta sues a former executive, alleging the theft of confidential documents. The tech giant accused Dipinder Singh \nKhurana, most recently a vice president, of taking a “trove” of sensitive information when he went to an unidentified \nA.I. start-up, according to Bloomberg. At least eight Meta employees whose information was in the documents \nfollowed him to that company.\nThe Murdochs may team up with Jeff Zucker and Abu Dhabi for a British newspaper. News Corp. is in talks to \npartner with RedBird IMI, an investment firm led by Zucker, the former CNN chief, and backed by Emirati money, to \nbuy The Telegraph, Bloomberg reports. That could ease concerns among British lawmakers about a foreign power \ncontrolling one of the country’s most prominent publications.\nThe N.A.A.C.P. calls on Black student-athletes to reconsider attending Florida colleges. The advocacy group cited \nthe state’s policies banning the use of public money for diversity, equity and inclusion programs — leading to \nuniversities shutting their programs — as a reason to weigh going elsewhere. The campaign introduces a new area \nof conflict in the battle over D.E.I. programs.\nThe big inflation report \nTuesday’s Consumer Price Index report is expected to be another decisive one for Wall Street and Washington.\nThe S&amp;P 500 has taken a two-day break from its record run, as investors look for fresh signs of progress in the \nFed’s battle with inflation. Jay Powell, the central bank’s chair, said last week that central bank policymakers were \n“not far” from cutting interest rates — if new data justified such a move. President Biden is also hoping for an \nupbeat number to bolster perceptions of his economic record.\nHere’s what to watch: The report is expected to show that headline inflation held steady at 3.1 percent on an annual \nbasis. That’s well above the Fed’s 2 percent target. But economists expect to see a slowdown in “core” inflation, \nThe Clock Ticks for TikTok DealBook Newsletter\nwhich excludes volatile food and fuel prices. That would be welcome progress after last month’s surprisingly strong \nreading.\nThe bad news: Rising health care, insurance, and  “shelter” costs continue to blunt progress. “Core services \ninflation should remain sticky-high,” Stephen Juneau, a Bank of America economist, wrote in a note last week. \nAnother warning sign: The New York Fed’s monthly inflation survey yesterday showed that respondents saw prices \nclimbing during the next three to five years.\nAdding to the downbeat mood, Jamie Dimon, the C.E.O. of JPMorgan Chase, warned on Tuesday that a U.S. \nrecession wasn’t “off the table.”\nThe good news: Goods inflation, particularly for cars, clothing and household furnishings, has been falling for \nmonths. That’s expected to be borne out in Tuesday’s figures, too. And some parts of the country “are in a low \ninflation environment,” Paul Donovan, an economist at UBS, wrote to investors on Tuesday. “This is all consistent \nwith the Federal Reserve following inflation lower with a second quarter rate cut.”\nThe futures market on Tuesday was pricing in roughly three interest rate cuts this year, the first coming in June. \nThat’s in line with the Fed’s own forecast — but well off what markets had priced in at the start of the year.\nBiden bets on taxing big business\nWith his newly released budget proposal, President Biden has sharpened his political pitch for an election year: \ngoing populist by raising taxes on big businesses and the wealthy to pay for social programs. It has no chance of \nbecoming law — but it’s a reminder for corporate America of where it stands as Biden seeks another term.\nBiden called for raising $5 trillion in new taxes on companies and the rich, including:\n• Raising the corporate tax rate to 28 percent from 21 percent, where it was set in 2017;\n• Increasing the corporate minimum tax to 21 percent, up from the 15 percent set in 2022;\n• Quadrupling a levy on corporate stock buybacks to 4 percent and eliminating a tax break on purchases of \ncorporate jets;\n• Lifting the capital-gains rate for those who earn more than $400,000 to 39.6 percent, while closing the so-\ncalled carried interest loophole for hedge fund and private equity executives;\n• And imposing a 25 percent “billionaire tax” on those whose wealth exceeds $100 million. (Valuing people’s \nfortunes will be tricky and the Treasury Department hasn’t specified how it would do so.)\nBiden is trying to strike a delicate political balance. He wants to win over voters who are giving him low marks on \nthe economy, while painting Donald Trump as an advocate for tax breaks for the rich. (Republicans criticized the \nproposed budget as “another glaring reminder of this administration’s insatiable appetite for reckless spending and \nthe Democrats’ disregard for fiscal responsibility.”)\nBut Biden was also quick to rebut claims that he’s anti-business. “I’m a capitalist, man,” he said at a speech in New \nHampshire. “Make all the money you want. Just begin to pay your fair share in taxes.”\nThere are limits to the tax-the-rich approach, however. Neil Irwin of Axios writes that even though Biden’s budget \nproposal would reduce the federal deficit by $3 trillion, it would require some optimistic economic assumptions to \npull it off.\nCrypto is on a winning streak \nBitcoin is hovering around $72,000 on Tuesday, a rally that has helped mint a new crop of crypto billionaires. The \nbullish mood can be felt throughout the sector.\nThe Clock Ticks for TikTok DealBook Newsletter\nThe token has climbed by more than 50 percent since the S.E.C. approved the first Bitcoin exchange traded-funds \nin January, bringing a wave of mainstream investors into crypto trading. A raft of similar funds linked to Ethereum, \nanother popular digital currency, could get the green light by May.\nCoinbase is pushing the S.E.C. for more favorable treatment. The Nasdaq-listed cryptocurrency exchange’s stock \nhas surged alongside Bitcoin this year. Yesterday, Coinbase filed a lawsuit against the regulator, accusing it of \n“capricious” behavior. It says the agency has shirked its responsibility to write clear rules on how the industry should \noperate.\nTough tactics have worked before. Grayscale Investments, a digital asset manager, sued the S.E.C. last year after \nthe regulator denied its application for a Bitcoin exchange-traded fund. A panel of judges agreed that the agency \nacted arbitrarily, a ruling that paved the way for January’s approval of new Bitcoin funds.\nThe industry is also flexing its political muscles. Coinbase and others backed a network of well-funded super PACs \nthat some say helped fell crypto-skeptic Katie Porter, the Democratic representative from California, who lost her \nrace to be the party’s nominee for the Senate.\nThe sector is now looking at new targets to boost, or topple. “The crypto advocacy community is feeling pretty good \nright now,” said Kristin Smith, C.E.O. of the trade group Blockchain Association. “For the first time since Bitcoin was \ncreated 15 years ago, we have the tools in place, on the policy front and the political front.”\nThe sector got another shot in the arm yesterday when Travis Hill, the F.D.I.C.’s vice chair, called on regulators to \nease their restrictions on how banks handle customers’ digital assets.\nTHE SPEED READ \nDeals\n• Donald Trump reportedly asked Elon Musk last summer if he was interested in buying Truth Social, the former \npresident’s social media platform. (WaPo)\n• G/O Media agreed to sell Deadspin, the sports news website, to a European media company — and will lay \noff all existing employees. (NYT)\nArtificial intelligence\n• “How the A.I. That Drives ChatGPT Will Move Into the Physical World” (NYT)\n• The generative A.I. start-up Midjourney has barred employees of a rival, Stability AI, from using its service, \nblaming the other company for a service outage. (The Verge)\nBest of the rest\n• A new crop of media start-ups — including Semafor and Puck — is following a novel plan for survival: lots of \ndifferent revenue sources, narrow coverage areas and staying small. (NYT)\n• “One Day, Israeli Tech Founder Was Closing Deals. The Next, He Was Near Death on a Gaza Battlefield” \n(WSJ)\n• Why U.S. foreign policy is more dependent on corporate America — and vice versa — than ever before. \n(Foreign Affairs)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: TikTok users are lobbying Washington lawmakers to try to derail a bill that could ban the short video app \nin the U.S. (PHOTOGRAPH BY Ore Huiying for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: March 12, 2024\nThe Clock Ticks for TikTok DealBook Newsletter"
    },
    {
        "file_name": "CEO_Cristiano_Amon_Mar2024",
        "header": "India can play a key role in building hardy supply chain, says Qualcomm",
        "media": "CEO Cristiano Amon",
        "time": "March 12, 2024",
        "section": "ELECTRONICS",
        "length": "583 words",
        "byline": "Romit Guha and Himanshi Lohchab",
        "story_text": "India can play a key role in building hardy supply chain, says Qualcomm \nCEO Cristiano Amon\nThe Economic Times\nMarch 13, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ELECTRONICS\nLength: 583 words\nByline: Romit Guha and Himanshi Lohchab\nBody\nIndia can play a key role in building a resilient global electronics supply chain, said Cristiano Amon, chief executive \nof US chip giant Qualcomm Inc. In an interview with ET's Romit Guha and Himanshi Lohchab, Amon said the \ncountry has an opportunity to create large companies that serve both the domestic and global markets in areas \nsuch as semiconductor packaging and manufacturing. Edited excerpts: What are the opportunities for Qualcomm in \nIndia?There's an incredible opportunity with the transition to 5G. But it's not only 5G, but also the incredible \nopportunity that is developing with Gen AI and the opportunity to do Gen AI at the edge, not only at data centres, \nbut across many different industries.What's Qualcomm's investment plan for India?\nIndia is our largest R&D site outside San Diego. We have a presence in a number of sites - from Hyderabad, \nBengaluru, Chennai and Noida. The majority of our chips are designed in India, both hardware and software. With \nthe world looking for alternatives to make the overall electronic supply chain more resilient, we see that India has an \nimportant role to play, an opportunity to create over time, very large Indian companies serving not only the Indian \nmarket, but also global, whether it's smartphone industrial modules, whether it's semiconductor packaging, and \neventually semiconductor manufacturing.Have you tied up with the Tatas and/or any other partner for the chip \necosystem?We're the largest fabless company in the world. And if you're going to build the semiconductor supply \nchain, you need that long-term customer. Qualcomm is fabless, and because we don't have any manufacturing, we \nwant a diversified and resilient supply chain. Our role is, if India wants to build a strong semiconductor supply chain, \nfor assembly and semiconductors, we will be there to provide the scale and to support our partners.Anything more \nspecific about your talks with the Tatas?We have been in discussions. It's very natural, anybody who is going to be \nlooking into investing in semiconductors will have a conversation with Qualcomm... We can't wait to see India build \na semiconductor supply chain with technologies that are relevant to us.How is India's latest efforts to be a part of \nthe semiconductor supply chain different from its previous efforts?The opportunity for India to be successful in the \nsemiconductor supply chain is to also leverage the India scale. And it's not just about focussing on semiconductor \nmanufacturing. India also needs to be focused about generating demand. Because if you have demand for \nsemiconductors, you have the ability to build upon that scale, a very sustainable semiconductor supply chain. And \nthat's where I think we can play two roles. One role Qualcomm can play is if India has semiconductor manufacturing \ncapacity, assembly capacity, we can be a customer given our scale. But more exciting to us is the ability to work \nwith India to make phones in India, industrial modules in India, meaning connected cars. I think that is the big \nopportunity, and that's what makes it different from prior attempts to create a semiconductor industry.The \ngovernment expects India to be among the top five in the semiconductor global supply chain. Do you think it's a \nrealistic target?The current global environment is a unique opportunity for India. I think it's in the interest of many \ncompanies in the world to build resilience in the supply chain. That is the opportunity for India. For Reprint Rights: \ntimescontent.com\nIndia can play a key role in building hardy supply chain, says Qualcomm CEO Cristiano Amon\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "'confusion'_over_pic_with_kids,_but_it's_a_credibility_blow_for_a_family_in_crisis._Mar2024",
        "header": "Doctored photo is a major royal oops; Princess of Wales is sorry for",
        "media": "'confusion' over pic with kids, but it's a credibility blow for a family in crisis.",
        "time": "March 12, 2024",
        "section": "MAIN NEWS; Entertainment Desk; Part A; Pg. 1",
        "length": "1395 words",
        "byline": "Nardine Saad",
        "story_text": "Doctored photo is a major royal oops; Princess of Wales is sorry for \n'confusion' over pic with kids, but it's a credibility blow for a family in crisis.\nLos Angeles Times\nMarch 12, 2024 Tuesday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Entertainment Desk; Part A; Pg. 1\nLength: 1395 words\nByline: Nardine Saad\nBody\nCatherine, Princess of Wales, issued an apology Monday for distributing an image that had been manipulated, only \nheightening speculation about her health and whereabouts since she had surgery in January.\nKensington Palace had released the image of the former Kate Middleton and her children the day before, \napparently hoping to ease questions that have fueled worry as well as online sleuthing and conspiracy theories.\nBut her admission that the image had been doctored has only heightened controversy and raised serious questions \nabout the way the royal family has handled the princess' health.\n\"The palace clearly messed up. Full stop. You don't release a manipulated image with the world watching,\" said \nMike Ananny, co-director of the Center for Generative AI and Society and co-director of the Artificial Intelligence for \nMedia & Storytelling initiative at USC.\nIt breaks \"this myth that royals are showing us genuine trusted images,\" he added. \"This historically is a moment of \n'Can we trust images and public institutions?' being blown up.\"\nKensington Palace on Sunday released the Princess of Wales' first photo since her hospitalization for abdominal \nsurgery nearly two months ago, but the Associated Press and other news agencies retracted the image \"because it \nappeared to be manipulated.\" It is common practice for news outlets not to publish retouched photos. Getty, \nReuters and AFP also issued take-down notices that said the photo had been removed for editorial reasons. At that \npoint, however, the image had already been published on the front page of numerous British publications and \nonline.\nCatherine's photo distribution and news agencies pulling back the image fueled even more conjecture about the 42-\nyear-old royal. Instead of quelling rumors, her U.K. Mother's Day greeting resulted in a rare apology from the British \nroyal for the Photoshop fail, making a strange situation even more bizarre.\n\"Like many amateur photographers, I do occasionally experiment with editing. I wanted to express my apologies for \nany confusion the family photograph we shared yesterday caused. I hope everyone celebrating had a very happy \nMother's Day. C,\" the duchess said in a statement on Kensington Palace's account on the social media platform X.\nThe photo, said to have been taken in Windsor last week by her husband, Prince William, heir apparent to the \nBritish throne, featured Catherine seated in a chair outdoors surrounded by her children, Prince George, Princess \nCharlotte and Prince Louis. However, it was clear that it had been edited in certain areas, specifically around \nCharlotte's hands.\nDoctored photo is a major royal oops Princess of Wales is sorry for 'confusion' over pic with kids, but it's a \ncredibility blow for a family in crisis.\nThe Associated Press retracted the photo hours after publishing it.\n\"While there was no suggestion the photo was fake, AP retracted it because closer inspection revealed the source \nhad manipulated the image in a way that did not meet AP's photo standards. For instance, the photo shows an \ninconsistency in the alignment of Princess Charlotte's left hand,\" AP said. The Los Angeles Times also removed the \nimage from its website.\nInternet sleuths spotted more issues, including misalignment on a window in the background and a tile on the floor, \nas well as apparent inconsistencies around the family's attire. Naturally, the image and Catherine's apology evolved \ninto a viral meme, and others questioned a wide range of issues, including why the photo was posted in the first \nplace and why Catherine wasn't wearing her wedding ring.\n\"Shout-out to whoever is doing PR ... Because nothing says 'let's put the conspiracy theories to rest' quite like a \nvery badly photoshopped/ai generated photo,\" one user wrote in the comments section of the palace photo.\n\"I am struggling to believe that the most famous royal family in the world -- and the woman who would be queen -- \nfiddled around with photoshop and put out a family pic (designed to quash rumours about her whereabouts) without \nanyone in the ranks inspecting it. Nah. Not buying it,\" wrote another.\nCatherine's Mother's Day message came a week after she was captured in paparazzi photos making her first public \nouting since December and since undergoing abdominal surgery Jan. 16.\nThe senior royal was admitted to the London Clinic, Kensington Palace said, for a planned abdominal surgery and \nsuccessfully underwent the procedure. The palace added, however, that the princess was expected to be \nhospitalized for 10 to 14 days \"before returning home to continue her recovery.\" She would return to public duties \nafter Easter -- March 31 -- based on current medical advice, the palace added.\n\"The Princess of Wales appreciates the interest this statement will generate,\" Kensington Palace said. \"She hopes \nthat the public will understand her desire to maintain as much normality for her children as possible; and her wish \nthat her personal medical information remains private.\"\nDespite that, Catherine's \"disappearance\" has led to rampant gossip about the nature of her ailment and what she's \nbeen doing in her time out of public view.\nSuch questions have run wild in Reddit threads, in tabloids around the world and in mainstream news outlets, \nparticularly last month when William cited personal matters as his reason for missing the funeral of his godfather, \nKing Constantine II of Greece. Catherine's announcement about her break from royal duties was further \ncompounded by King Charles III's health issues, including Buckingham Palace's announcement that he was being \ntreated for an undisclosed form of cancer.\nLast week, a spokesman reiterated the palace's stance that there would be no \"running commentary\" provided on \nKate's health despite internet rumors.\nSunday's Mother's Day post appeared to present an apt way for the princess to break her silence, thanking British \nsubjects for their \"kind wishes and continued support over the last two months.\" But the accompanying image -- \nwith its many photo-editing red flags -- ignited anew the discourse about her welfare.\nThe palace has not further commented on the gaffe. Hours after the apology, Catherine was photographed leaving \nWindsor Castle with Prince William, People said, reporting that she was heading to a private appointment.\nCatherine's image was distributed amid a tenuous time -- for both the media and the royal family, which has been \nstruggling with discord and scandals.\nDoctored photo is a major royal oops Princess of Wales is sorry for 'confusion' over pic with kids, but it's a \ncredibility blow for a family in crisis.\n\"In a way, there was a no-win condition here for her. And if in fact she's dealing with illness, I can't imagine how \ndistressing this is on top of that. I do think expectations from the public have to change too,\" said Sarah T. Roberts, \nprofessor and director of the UCLA Center for Critical Internet Inquiry.\nRoberts said royal watchers have an insatiable appetite for content, which has been scant since Catherine's last \npublic appearance in December and offered in only piecemeal updates from the palace. Although she was not \nmeant to return to royal duties until after Easter, the palace likely would have faced criticism for any image it used or \nfor skipping her acknowledgment of Mother's Day.\n\"Pretty much any other move would've been better, but hindsight is 20/20,\" Roberts said. \"Kate Middleton and her \nhusband are youngish people, and they're aware of the internet and understand the way it works, and they should \nhave some better advice maybe around them too. If she was really out there doing the photo herself, that's a bigger \nproblem altogether. These people have media teams, engage in reputation management. It struck a wrong note.\"\nAlthough the editing flubs seem \"ridiculous or funny\"on the surface, Roberts said, they reflect a bigger \"crisis of \nveracity\" that the media has been dealing with for years.\n\"There is perhaps an unspoken expectation that maybe needs to be part of an open conversation about the level of \nintegrity that institutions like the British monarchy and others that want to be taken seriously need to have,\" Roberts \nsaid.\n\"They need to set the tone because there are so many competing outlets that don't have those standards. So if we \ncan't expect veracity from the sources ... they're really gonna impugn themselves reputationally to the public.\"\nAnanny added: \"This is royalty we're talking about, and royalty has always needed visibility and a publicness. It's a \nrequirement of royalty that they be visible and accessible. But social media complicates that because Instagram has \na veneer of informality and authenticity, but we also know it's not always real.\"\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2024",
        "header": "Sprouts of Hope in a Gloomy Media Landscape",
        "media": "The New York Times - International Edition",
        "time": "March 13, 2024",
        "section": "BUSINESS",
        "length": "1378 words",
        "byline": "Katie Robertson and Benjamin Mullin",
        "story_text": "Sprouts of Hope in a Gloomy Media Landscape\nThe New York Times - International Edition\nMarch 14, 2024 Thursday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1378 words\nByline: Katie Robertson and Benjamin Mullin\nBody\nABSTRACT\nA handful of digital start-ups are finding success - so far, at least - by learning lessons from their troubled \npredecessors.\nFULL TEXT\nThis year is looking grim for the news business.       \nFacing a set of harsh financial realities - resulting from a mix of news fatigue, an unsteady advertising market and a \nprecipitous fall in traffic from tech giants - many outlets have been forced to fold or make significant cuts in recent \nmonths.       \nBut there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success - at least for the moment - by taking the opposite approach of many predecessors, \nsuch as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize growth.       \nThe new class of news start-ups - Puck, Punchbowl News, The Ankler and Semafor are among the most prominent \n- have kept spending down and hired carefully. They are all centered on newsletters covering specific niches with \nbroad appeal. They have attracted top journalists by putting them at the heart of the enterprise, sometimes as part \nowners in the companies.       \n\"There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,\" said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. \"And I think that the entire industry has learned from that.\"       \nThese start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.       \nBut traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn't add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.       \nThe formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nSprouts of Hope in a Gloomy Media Landscape\nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.       \n\"What all of them have in common is this intense need to serve specific audiences rather than to serve everybody,\" \nsaid Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.       \nSome of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.       \nPunchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome \"the hometown newspaper of Capitol Hill in a lot of ways,\" said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.       \n\"What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,\" she said.       \nPunchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. Access \nto Punchbowl's policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the low \nfive-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings from \nthose websites.       \nMs. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl's finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.       \nThe Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood's unsparing gadfly, narrating the industry's unending chaos and skewering the \nactors, agents and executives responsible for creating it.       \nAnkler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, said \nJanice Min, the company's chief executive and founder, who previously helmed The Hollywood Reporter and Us \nWeekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a Hollywood \nnews digest.       \n\"If we want to make a Hollywood analogy, it's like these growing franchises are multiverses,\" Ms. Min said. \"People \nlike what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.\"       \nSemafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.       \nSemafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called for, \nMr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic outlook \nwas darkening.       \n\"The pandemic really marked the transition from the social media era to what we call the post-social media era,\" Mr. \nSmith said, noting that outlets must now focus on direct relationships with their audience.       \nFor Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.       \nSprouts of Hope in a Gloomy Media Landscape\nThe company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.       \nOf course, nothing in media lasts forever - particularly in the fast-changing digital world. So there's no guarantee \nthat the early success of these companies will translate into sustained growth.       \nMany of these start-ups are also taking a somewhat risky bet on talent.       \nAt Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who is \na definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on Russian \npolitics, are \"founding partners.\" In addition to a salary, they receive bonuses based on the number of people who \nsubscribe to their email newsletters and how many of them stick around. New employees also get a small \nownership stake in the company.       \nPuck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.       \nIf one or more of the star journalists leave the publication, would Puck's subscribers follow?       \nMr. Kelly said he didn't \"want to even contemplate a world\" in which one of Puck's journalists exited.       \n\"We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,\" Mr. Kelly said. \"And I really think that our model is actually becoming one of the \nmoats of our business.\" \nLoad-Date: March 13, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Elon Musk says AI will be smarter than any human next year",
        "media": "The Economic Times",
        "time": "March 13, 2024",
        "section": "TECH BYTES",
        "length": "270 words",
        "byline": " ",
        "story_text": "Elon Musk says AI will be smarter than any human next year\nThe Economic Times\nMarch 13, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH BYTES\nLength: 270 words\nBody\nElon Musk, who is involved in a legal tussle with ChatGPT maker OpenAI, has said artificial intelligence (AI) will \nlikely be smarter than any single human by next year.Reposting a clip from Joe Rogan’s podcast with American \ncomputer scientist Ray Kurzweil on when AI will achieve human-level intelligence, Musk said on social media site X \n(formerly Twitter) that “AI will probably be smarter than any single human next year.”“By 2029, AI is probably \nsmarter than all humans combined,” he added.The Tesla founder has taken Sam Altman-run OpenAI to court \nalleging a breach of contract as the company, which he helped found, had agreed not to commercialise any product \nthat its board considered artificial general intelligence (AGI).Musk appealed to the court to direct OpenAI to make its \nresearch and technology publicly available and prevent the use of its assets and cutting-edge generative AI \nmodels for the financial gains of software major and investor Microsoft or any individual.OpenAI has said it \n“categorically disagrees” with the lawsuit. Its chief strategy officer, Jason Kwon, said in a memo that OpenAI is \nindependent and competes directly with Microsoft, pushing back against Musk’s suggestion that the startup is a “de \nfacto subsidiary” of the software giant.Meanwhile, Musk on Monday said his AI startup xAI would open-source its \nChatGPT challenger \"Grok\" this week.Seeking an alternative to OpenAI and Google, Musk launched xAI last year \nto create what he said would be a “maximum truth-seeking AI.” In December, the startup rolled out Grok for \nPremium+ subscribers of X. For Reprint Rights: timescontent.com\nLoad-Date: March 13, 2024"
    },
    {
        "file_name": "your_doctor;_New_artificial_intelligence_tools_are_helping_doctors_Mar2024",
        "header": "New AI tools can record your medical appointment or draft a message from",
        "media": "your doctor; New artificial intelligence tools are helping doctors",
        "time": "March 13, 2024",
        "section": "NATION WORLD",
        "length": "1097 words",
        "byline": "CARLA K. JOHNSON",
        "story_text": "New AI tools can record your medical appointment or draft a message from \nyour doctor; New artificial intelligence tools are helping doctors \ncommunicate with their patients\nDayton Daily News (Ohio)\nMarch 13, 2024 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1097 words\nByline: CARLA K. JOHNSON\nBody\nDon't be surprised if your doctors start writing you overly friendly messages. They could be getting some help from \nartificial intelligence.\nNew AI tools are helping doctors communicate with their patients, some by answering messages and others by \ntaking notes during exams. It's been 15 months since OpenAI released ChatGPT. Already thousands of doctors are \nusing similar products based on large language models. One company says its tool works in 14 languages. \nAI saves doctors time and prevents burnout, enthusiasts say. It also shakes up the doctor-patient relationship, \nraising questions of trust, transparency, privacy and the future of human connection. \nA look at how new AI tools affect patients: \nIS MY DOCTOR USING AI? \nIn recent years, medical devices with machine learning have been doing things like reading mammograms, \ndiagnosing eye disease and detecting heart problems. What's new is generative AI's ability to respond to complex \ninstructions by predicting language. \nYour next check-up could be recorded by an AI-powered smartphone app that listens, documents and instantly \norganizes everything into a note you can read later. The tool also can mean more money for the doctor's employer \nbecause it won't forget details that legitimately could be billed to insurance. \nYour doctor should ask for your consent before using the tool. You might also see some new wording in the forms \nyou sign at the doctor's office. \nOther AI tools could be helping your doctor draft a message, but you might never know it. \n\"Your physician might tell you that they're using it, or they might not tell you,\" said Cait DesRoches, director of \nOpenNotes, a Boston-based group working for transparent communication between doctors and patients. Some \nhealth systems encourage disclosure, and some don't. \nDoctors or nurses must approve the AI-generated messages before sending them. In one Colorado health system, \nsuch messages contain a sentence disclosing they were automatically generated. But doctors can delete that line. \nNew AI tools can record your medical appointment or draft a message from your doctor New artificial \nintelligence tools are helping doctors communicate with thei....\n\"It sounded exactly like him. It was remarkable,\" said patient Tom Detner, 70, of Denver, who recently received an \nAI-generated message that began: \"Hello, Tom, I'm glad to hear that your neck pain is improving. It's important to \nlisten to your body.\" The message ended with \"Take care\" and a disclosure that it had been automatically \ngenerated and edited by his doctor. \nDetner said he was glad for the transparency. \"Full disclosure is very important,\" he said. \nWILL AI MAKE MISTAKES? \nLarge language models can misinterpret input or even fabricate inaccurate responses, an effect called hallucination. \nThe new tools have internal guardrails to try to prevent inaccuracies from reaching patients  or landing in electronic \nhealth records. \n\"You don't want those fake things entering the clinical notes,\" said Dr. Alistair Erskine, who leads digital innovations \nfor Georgia-based Emory Healthcare, where hundreds of doctors are using a product from Abridge to document \npatient visits. \nThe tool runs the doctor-patient conversation across several large language models and eliminates weird ideas, \nErskine said. \"It's a way of engineering out hallucinations.\" \nUltimately, \"the doctor is the most important guardrail,\" said Abridge CEO Dr. Shiv Rao. As doctors review AI-\ngenerated notes, they can click on any word and listen to the specific segment of the patient's visit to check \naccuracy. \nIn Buffalo, New York, a different AI tool misheard Dr. Lauren Bruckner when she told a teenage cancer patient it \nwas a good thing she didn't have an allergy to sulfa drugs. The AI-generated note said, \"Allergies: Sulfa.\" \nThe tool \"totally misunderstood the conversation,\" said Bruckner, chief medical information officer at Roswell Park \nComprehensive Cancer Center. \"That doesn't happen often, but clearly that's a problem.\" \nWHAT ABOUT THE HUMAN TOUCH? \nAI tools can be prompted to be friendly, empathetic and informative. \nBut they can get carried away. In Colorado, a patient with a runny nose was alarmed to learn from an AI-generated \nmessage that the problem could be a brain fluid leak. (It wasn't.) A nurse hadn't proofread carefully and mistakenly \nsent the message. \n\"At times, it's an astounding help and at times it's of no help at all,\" said Dr. C.T. Lin, who leads technology \ninnovations at Colorado-based UC Health, where about 250 doctors and staff use a Microsoft AI tool to write the \nfirst draft of messages to patients. The messages are delivered through Epic's patient portal. \nThe tool had to be taught about a new RSV vaccine because it was drafting messages saying there was no such \nthing. But with routine advice  like rest, ice, compression and elevation for an ankle sprain  \"it's beautiful for that,\" \nLinn said. \nAlso on the plus side, doctors using AI are no longer tied to their computers during medical appointments. They can \nmake eye contact with their patients because the AI tool records the exam. \nThe tool needs audible words, so doctors are learning to explain things aloud, said Dr. Robert Bart, chief medical \ninformation officer at Pittsburgh-based UPMC. A doctor might say: \"I am currently examining the right elbow. It is \nquite swollen. It feels like there's fluid in the right elbow.\" \nNew AI tools can record your medical appointment or draft a message from your doctor New artificial \nintelligence tools are helping doctors communicate with thei....\nTalking through the exam for the benefit of the AI tool can also help patients understand what's going on, Bart said. \n\"I've been in an examination where you hear the hemming and hawing while the physician is doing it. And I'm \nalways wondering, 'Well, what does that mean?'\" \nWHAT ABOUT PRIVACY? \nU.S. law requires health care systems to get assurances from business associates that they will safeguard \nprotected health information, and the companies could face investigation and fines from the Department of Health \nand Human Services if they mess up. \nDoctors interviewed for this article said they feel confident in the data security of the new products and that the \ninformation will not be sold. \nInformation shared with the new tools is used to improve them, so that could add to the risk of a health care data \nbreach. \nDr. Lance Owens is chief medical information officer at the University of Michigan Health-West, where 265 doctors, \nphysician assistants and nurse practitioners are using a Microsoft tool to document patient exams. He believes \npatient data is being protected. \n\"When they tell us that our data is safe and secure and segregated, we believe that,\" Owens said. \nThe Associated Press Health and Science Department receives support from the Howard Hughes Medical \nInstitute's Science and Educational Media Group. The AP is solely responsible for all content.\nGraphic\n \nIn this photo provided by University of Michigan Health-West, Dr. Lance Owens, chief medical information officer at \nthe university, demonstrates the use of an AI tool on a smartphone in Wyoming, Mich., on Sept. 9, 2021. The \nsoftware listens to a doctor-patient conversation, documents and organizes it to write a clinical note. (University of \nMichigan Health-West via AP)\nLoad-Date: March 13, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "InMobi nets 235 million active users on Glance lock screen",
        "media": "The Economic Times",
        "time": "March 14, 2024",
        "section": "ENTERTAINMENT",
        "length": "454 words",
        "byline": "Himanshi Lohchab",
        "story_text": "InMobi nets 235 million active users on Glance lock screen\nThe Economic Times\nMarch 15, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ENTERTAINMENT\nLength: 454 words\nByline: Himanshi Lohchab\nBody\nMobile marketing group InMobi has amassed 235 million active users on its lock screen platform Glance, which also \nhosts shopping-cum-entertainment video commerce platform Roposo and mobile gaming destination Nostra.Having \npartnered with leading mobile device makers including Samsung, Xiaomi, Oppo, Vivo, Motorola, Realme and Jio, \nthe company is on the path to appear on 1 billion lock screens by 2025 globally, chief business officer (CBO), \nVasuta Agarwal said.Backed by Google, Jio Platforms and SoftBank, the Bengaluru-based advertising and \nconsumer tech group has worked with 300+ brands across verticals and expanded operations in India, Indonesia, \nUS, Mexico, Brazil, Japan, and Thailand.Glance, which recently acquired Roposo and Nostra, is an unconsolidated \nsubsidiary of the InMobi group.“Nostra, the free-to-play gaming platform on Glance smart lock screen, has \nregistered over 82 million users, which is over one-fifth of India’s gaming population,” said Bikash Chaudhary, chief \nmarketing officer (CMO), Glance.“We are on track to introduce 600 new casual and hyper-casual games across 15 \ncategories on the platform as well as support the esports ecosystem with live tournaments,” Chaudhary \nadded.Glance is a pre-installed, customisable lock screen available in Android devices which delivers personalised \ncontent such as news, entertainment, sports, fashion and games. The Glance screen can also be disabled if users \nchoose to opt-out from the platform. \nOnly 10% content on Glance is promotional or advertising while the rest is pure content curation, the executives \nsaid.Besides the adtech business the company is also bullish on the consent management space as the Digital \nData Protection Act was enforced in India, CBO, Agarwal said.InMobi, last year, acquired the US-based consent \nmanagement platform Quantcast Choice which enables organisations to comply with global privacy regulations. \nThe executives declined to comment on Quantcast's India plans.CMO Chaudhary said that generative artificial \nintelligence is helping the company create more engaging content, do accurate language translations and curate \ncontent faster.On Thursday, Glance released its 2023 trends report, according to which, last year, the G20 World \nCup and Chandrayaan were among the trending topics with over 4 billion and 2 billion glances (views), respectively. \nReality TV show Bigg Boss Season 17 updates also generated 6 billion glances throughout the season, it said.As \nper its latest financials, InMobi’s revenue for year-ending March 2023 stood at Rs 589.57 crore, up 41% from Rs \n415.93 crore in previous year. Its profit after tax was Rs 113.2 crore for FY23, up from Rs 24.5 crore in FY22. For \nReprint Rights: timescontent.com\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Solo traveling basics: Expert advice for your first trip",
        "media": "USA Today Online",
        "time": "March 14, 2024",
        "section": "OCEANIA LATEST",
        "length": "1388 words",
        "byline": "Kathleen Wong, USA TODAY",
        "story_text": "Solo traveling basics: Expert advice for your first trip\nUSA Today Online\nMarch 12, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: OCEANIA LATEST\nLength: 1388 words\nByline: Kathleen Wong, USA TODAY\nBody\nBoarding the plane to head to another country alone is often an emotional experience – there’s the excitement, the \nanxiety, the anticipation.\nIt can also be totally nerve-wracking.\nWhen Angie Orth made the bold choice to leave her job and embark on a solo yearlong journey around the world in \n2011, her friends and family cautioned her about safety concerns. “Everyone was horrified,” the Florida native told \nUSA TODAY. “The fear was all I heard.”\nThe then New York City-based Orth kicked off her 12-country solo trip in Fiji before making her way to New \nZealand, Australia, and Southeast Asia. Then she trekked through Europe, including Greece, Spain and England, \nand stopped in Turkey and Egypt before ending in Kenya and South Africa.\nStay safe while traveling: Here are 17 CIA tips, advice to think like a spy on vacation\nIt wasn’t always smooth traveling. At times, Orth said she survived “by the skin of my teeth.” Orth was in Egypt \nduring the Arab Spring, got unbelievably sick in Thailand, and had a bike accident in Bali. She was also robbed of \n400 euros. “I was in Greece for a half an hour and had already been pickpocketed,” she said. \nStill, to Orth, the solo journey was invaluable. “It’s a confidence that I don't think there’s any other way to get that \nconfidence than by solo travel,” she said, referring to the problem-solving that inherently comes with navigating \ntravel on your own. Then there’s also the compassion you gain from meeting and experiencing other cultures. \nNow more than ever, more people are deciding to forgo travel companions and embark on their trips alone. Solo \nvacation package searches on Google shot up by more than 200% over the past 90 days as of Feb. 2.\nIncreased connectivity on our phones makes it easier to feel secure and social media shows more people – \nespecially women – traveling the world alone. \n“Women are not waiting for permission or their 401(k) to mature. If my husband doesn’t want to go, fine. Women \nare having more confidence,” said Orth, who is also the author of the upcoming book “Flirting with Disaster,” which \nchronicles her yearlong solo trip. \nHere’s everything you need to know about solo travel. \nHow to safely travel alone\nLink to Image\nSolo traveling basics: Expert advice for your first trip\nSafety is always top of mind when traveling, and it’s especially important for solo travelers who have to look out for \nthemselves. \n'It's like your local bestie':  This startup helps make solo travel as a woman feel safer\n“Isn’t it fun to meet a person in a hostel and say yes, let’s go hiking right now? That’s fun, but it’s risky,” Orth said. \n“It’s about balancing it out and researching ridiculously.” \n￿ Start your research by heading to the State Department website to see if there are any travel advisories for the \ndestination you’re interested in. These advisories are based on changing conditions and also inform you about the \nspecific region you’re visiting.\nFor the most direct updates, enroll in the agency’s Smart Traveler Enrollment Program (STEP), a free service that \nsends you the most up-to-date information on the destination. It can also help connect you to the nearest U.S. \nembassy and consulate if traveling and something happens.\n￿ One thing Orth always searches for is “the destination plus scams” to see what she has to look out for when in \nthat place. Many European cities are notorious for petty theft, like pickpocketing in popular tourist hotspots like the \nTrevi Fountain or public transportation.  \nWhen doing research, it may feel like an information overload. \"There is so much information now, you could read \n1,000 reviews and get so many sources of conflicting information,\" Orth added. \"It’s hard to wade through all that \nand find trusted sources.\"\n￿ To help sift through everything, Orth recommends reaching out to others who have traveled to your ideal \ndestination. She also recommended cleaning out your feed and only following travel content creators who “give you \nthe good and the bad.”\n“You don’t want the glossy, glossy, oh, it’s so magical because travel isn’t always so magical,” she said. \n￿ At your destination, you’ll also need at least a basic understanding of the language used there. “Translation plays \na big role in safety, just being aware of your surroundings,” said Craig Ewer, Google Communications Manager for \nSearch. \nBesides direct translation between 133 languages, the Google Translate app offers pronunciation help – “such a \nlifesaver,” according to Rose Yao, vice president of product management at Google. You can also snap a picture of \na menu and have it translated in real time. \nThe Google app also has a feature called Lens that allows users to search using a picture of something like a sign. \n“You’d be surprised at what you can Lens: menus, what is that building or what is that statue,” Yao said. You can \nalso capture a screenshot of your social media feed and then search for it on Google to incorporate it into your \ntravel plans.\nLink to Image\nStaying healthy on your travels\n￿ To safeguard yourself and others against preventable illnesses while exploring new places, look up any \nrecommended vaccinations for the countries you plan on visiting. The Centers for Disease Control and Prevention \nwebsite is a good starting point, with in-depth travel health notices and recommended vaccines and medicines \nposted. \nThe CDC website also offers travel advice on managing nonpreventable illnesses, like preventing bug bites to \nreduce the risk of contracting diseases like dengue or Zika.\nSolo traveling basics: Expert advice for your first trip\n￿ Typically, you’d want to give yourself at least a month before departing on your trip to get everything you need \nfrom your doctor. And if you don’t know who to go to, the CDC can help you find a clinic as well. \nOrth recommends having a doctor help you put together a medical kit with some necessities and medications, such \nas for food poisoning. “It’s helpful to have some things on hand so you’re not scrambling on a remote island and no \none knows what you’re talking about,” she said. \n￿ As you’re making the big purchases for your trip, don’t forget about travel insurance for the unexpected. Orth said \nshe never travels without this layer of protection. Travel insurance not only helped with her medical costs from her \nbike collision but also replaced her camera, which was smashed in the accident. She also recommends a service \ncalled MedJet, which offers worldwide security crisis and medical transportation assistance for its members.\nLearn more: Best travel insurance\nWhat are the most popular solo travel destinations?\nAccording to Google, the top-searched destinations for American solo travelers are: \n￿ London\n￿ Alaska\n￿ Hawaii\n￿ Puerto Rico\n￿ Italy\nTips for solo travelers\n￿ The Google app’s generative AI search allows you to “ask really detailed questions like you would ask a friend,” \nYao said. “Ask what’s off the beaten path, what’s not crowded. What’s a great time to visit the Louvre that’s not \nsuper crowded?” \n￿ For your first trip alone, it’s OK to start small and dip your toes in the solo travel pool. “Start in an easier \ndestination, something more familiar where you speak the language or you don't have to fly far away,” Orth said. “A \nlot of folks see ‘Eat, Pray, Love’ and travel content creators trekking in Borneo for it to count but it doesn’t.” \n￿ It won’t always be rainbows and butterflies, despite what you see on social media. Expect decision fatigue from \nhaving to make many micro-decisions, like if this taxi driver seems safe. “I think this probably hits women a lot \nharder than it hits men because we are never not thinking about our safety, and that’s if we’re going to Target in our \nhometown or hopping on a plane to a remote island,” Orth said. \n￿ Make an itinerary for yourself with at least one thing planned every day, so you don’t feel aimless but still have \nspace for flexibility, said Madison Pietrowski, U.S. brand director at GetYourGuide, a marketplace for travel \nexperiences, where each company listed is thoroughly vetted. It can be as casual as wanting to eat at a certain \nrestaurant for dinner or more intensive like a whole-day tour. (On that note, make sure to read the fine print and be \naware of cancellation policies for your excursions.)  \nKathleen Wong is a travel reporter for USA TODAY based in Hawaii. You can reach her at  kwong@usatoday.co m.\nThis article originally appeared on USA TODAY: Solo traveling basics: Expert advice for your first trip\nLoad-Date: March 14, 2024\nSolo traveling basics: Expert advice for your first trip"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Norman Zammitt, Californian Modernist, Had His Eye to the Sky; Critic’s Pick",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "ARTS; design",
        "length": "1036 words",
        "byline": "Jonathan Griffin",
        "story_text": "Norman Zammitt, Californian Modernist, Had His Eye to the Sky; Critic’s Pick\nThe New York Times \nMarch 14, 2024 Thursday 22:01 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: ARTS; design\nLength: 1036 words\nByline: Jonathan Griffin\nHighlight: The Light and Space artist who flew under the radar has his moment in the sun.\nBody\nThe Light and Space artist who flew under the radar has his moment in the sun.\nAesthetically, Los Angeles is mostly a mess. Unplanned, mismatched buildings sprout like fungus among the grid of \nits streets, whose orderly classicism is often disrupted by tectonically induced hills. Curbs crumble and sidewalks \ncrack beneath telegraph poles festooned with cables. Flamboyant succulents mingle with scrubby native plants.\nWhat aesthetic perfection Los Angeles offers is mainly in its skies. Breathtaking ombres of color ascend from the \nhorizon, even outside its “golden hour” — the famously lambent period before sunset — even without the haze that \namplifies these atmospheric special effects.\nIn the 1960s, many of this region’s most celebrated artists were inspired by the vault of the heavens, rather than the \ngritty realities on the streets beneath. They favored new media, technologies often developed by the local \naerospace industry. Traditional paint on canvas was often sidelined in favor of modern industrial materials such as \npoured resin, ground glass, lacquers and microfilm coatings.\nThe artist Norman Zammitt, a colorist who excelled as a painter, remains less well known than his peers in the Light \nand Space movement. (The artist died in 2007.) Finally, a survey exhibition of Zammitt’s art at the Palm Springs Art \nMuseum is taking visitors on a glorious tour through his chromatic investigations.\nBorn in 1931 in Toronto, Zammitt moved to Southern California as a teenager. In the 1960s, he experimented with \nmaking fashionably minimalist sculptures from acrylic resin and plexiglass, but hit his stride the following decade \nwith paintings on canvas in what became his signature style: horizontal bands of acrylic color, shifting incrementally \nthrough shades both sickly and sublime.\nThis exhibition, titled “Gradations” and curated by Sharrissa Iqbal, starts good and gets better. Between entrance \nwalls painted sunflower yellow, Zammitt’s panoramic painting “One,” from 1973, greets visitors. From a distance, \nthe painting seems mostly yellow too. But as you draw near, you’ll identify colors from inky black, along the bottom, \nrising through dioxazine purple, cerise, coral, orange, then five or six different tones of yellow, in widening bands. \nUp close, the painting, 16 feet wide, bathes you in radiant luminosity.\n“One” is Zammitt’s first large-scale iteration of what he would call his “Band Paintings.” Turn around in the gallery \nand you’ll see two more, both painted in 1975: “Green One” — which recalls the subaquatic rather than the aerial — \nand “Arctic Yellow.” As time went by, the bands became thinner, the colors became more subtly gradated, \nZammitt’s surfaces more pristine and his effects more ecstatic.\nZammitt applied himself to his work with a lab technician’s precision. According to a wall text, by the mid-1970s he’d \ndeveloped a “complex mathematical system” for mixing his colors, weighing out pigments according to curves on a \nNorman Zammitt, Californian Modernist, Had His Eye to the Sky Critic’s Pick\ngraph. When I asked, Iqbal was unable to fully elucidate this process, although she did reveal that during the 1980s \nZammitt began working with mathematicians at the California Institute of Technology who showed him how \ncomputers could help him develop more complex variables for his color charts. When desktop computers became \naffordable, he bought one and commissioned a custom program that enabled him to formulate gradations of colors.\nRunning down either side of the gallery are rows of smaller paintings, many just eight or nine inches wide, that \nseem to serve as studies for his larger works. Hanging near most of the mighty paintings are their mini-me \ncompanions. An exhibition of these small canvases — exquisite objects in themselves — recently opened at Karma \nin Los Angeles, and that gallery is credited, along with Zammitt’s estate, with supplying most of the works for this \nshow.\nThe sky wasn’t Zammitt’s only visual reference. One especially dazzling painting from 1976, “North Wall,” achieves \nholograph illusions of depth, its horizontal bands pulsating before our eyes. It brings to mind Mexican serape \nblankets, or Native American weavings. Though he seldom advertised it, Zammitt’s mother was from the Mohawk \nNation and the family spent time living on the Kahnawake Mohawk Territory, a First Nations reserve near Montreal \nbefore moving to California.\nIqbal conjectures that Zammitt’s Native American heritage may have led him to view abstraction as a path toward \nspiritual transcendence. The artist himself remained largely mute on the subject. An early laminated acrylic \nsculpture, its layers sandwiching optically dazzling layers of rainbow dots, is titled “Caugnawaga II” — an alternative \nspelling of the reserve where Zammitt once lived — but the piece itself bears no overt relevance to Mohawk culture.\nThe exhibition contains an unexpected plot twist: In the late 1980s, Zammitt’s razor-straight lines and flat color \ndisintegrated in what he called “Fractal” paintings. A spectacular example of this style is the latest work in the show: \n“Triptych XI,” painted in 1992. It is an extraordinarily complex painting, an interlocking jigsaw of jagged forms, \nperhaps inspired by a coastline or cloudscape, loosely painted in dusky shades that ascend into blackness.\nWhy is Zammitt emerging from relative obscurity only now, in this artistic moment of generative A.I. and arcana, \nsocial activism and breakfast-table still lifes? Perhaps Zammitt’s art strikes a chord because it transcends its \nhistorical period — and ours, too. Not only do his paintings look as fresh as they must have when new, but they lift \nus out of our vexed and messy present, connecting us with the eternal.\nNorman Zammitt: Gradations\nThrough Oct. 7, Palm Springs Art Museum, 101 Museum Drive, Palm Springs, Calif., psmuseum.org.\nPHOTOS: Top, “Triptych XI” (1992), part of the Norman Zammitt show “Gradations.” Center left: “One” (1973) in the \nforeground, and “North Wall” (1976), partially obscured in the background. Center right: “Caly-forny-ay” (1987). \nAbove, \nfrom \nleft: \n“Green \nOne” \n(1975); \nand \n“Caugnawaga \nII” \n(1966). \n(PHOTOGRAPHS \nBY \nRJ \nSÁNCHEZ/SOLSTREAM STUDIOS, VIA PALM SPRINGS ART MUSEUM; ESTATE OF NORMAN ZAMMITT AND \nKARMA) This article appeared in print on page C12.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Key OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "TECHNOLOGY",
        "length": "1418 words",
        "byline": "Mike Isaac, Tripp Mickle and Cade Metz Mike Isaac is a technology correspondent for The Times based in",
        "story_text": "Key OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nThe New York Times \nMarch 7, 2024 Thursday 18:17 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1418 words\nByline: Mike Isaac, Tripp Mickle and Cade Metz Mike Isaac is a technology correspondent for The Times based in \nSan Francisco. He regularly covers Facebook and Silicon Valley. Tripp Mickle reports on Apple and Silicon Valley \nfor The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues \nand political challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and \nrobot taxis. Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other emerging \nareas of technology.\nHighlight: Mira Murati, OpenAI’s chief technology officer, brought questions about Mr. Altman’s management to the \nboard last year before he was briefly ousted from the company, people familiar with the matter said.\nBody\nMira Murati, OpenAI’s chief technology officer, brought questions about Mr. Altman’s management to the board last \nyear before he was briefly ousted from the company, people familiar with the matter said.\nMore than three months after OpenAI’s board of directors briefly ousted Sam Altman, the chief executive of the \nhigh-profile artificial intelligence company, questions remain about exactly what led the board to make such a \ndramatic move.\nA report from an outside law firm, which is expected in the coming days, could shed more light on the board’s \ndecision as well as the chaotic five days before Mr. Altman returned to the company.\nBut as anticipation for the report grows, previously unreported details are emerging about the role that Mira Murati, \nOpenAI’s chief technology officer, played in the ouster of Mr. Altman.\nMs. Murati wrote a private memo to Mr. Altman raising questions about his management and also shared her \nconcerns with the board. That move helped to propel the board’s decision to force him out, according to people with \nknowledge of the board’s discussions who asked for anonymity because of the sensitive nature of a personnel \nissue.\nAround the same time, Ilya Sutskever, a co-founder and chief scientist of OpenAI, expressed similar worries, citing \nwhat he characterized as Mr. Altman’s history of manipulative behavior, the people said. Both executives described \na hot-and-cold relationship with Mr. Altman. Though it was not clear whether they offered specific examples, the \nexecutives said he sometimes created a toxic work environment by freezing out executives who did not support his \ndecisions, the people said.\nMs. Murati’s interactions with the board offer insight into problems festering at the senior levels of OpenAI, though \nboth executives publicly backed Mr. Altman’s return to the company.\nWilmerHale, the law firm conducting the investigation, is expected to wrap up the process imminently. The company \nis expected to announce a new board of directors at the same time, some of the people said. Several directors left \nthe board after Mr. Altman returned to the company in November.\nKey OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nHannah Wong, a spokeswoman for OpenAI, said in a statement that the company’s senior leadership team, led by \nMs. Murati during her time as interim chief executive, unanimously asked for Mr. Altman’s return, as did an open \nletter signed by 95 percent of OpenAI’s employees.\n“The strong support from his team underscores that he is an effective C.E.O. who is open to different points of view, \nwilling to solve complex challenges, and who demonstrates care for his team,” Ms. Wong said. “We look forward to \nfindings from the independent review versus unsubstantiated claims.”\nMr. Altman declined to comment. Mr. Sutskever’s lawyer, Alex Weingarten, said claims that he had approached the \nboard were “categorically false.”\nMarc H. Axelbaum, a lawyer for Ms. Murati, said in a statement: “The claims that she approached the board in an \neffort to get Mr. Altman fired last year or supported the board’s actions are flat wrong. She was perplexed at the \nboard’s decision then, but is not surprised that some former board members are now attempting to shift the blame \nto her.”\nIn a message to OpenAI employees after publication of this article, Ms. Murati said she and Mr. Altman “have a \nstrong and productive partnership and I have not been shy about sharing feedback with him directly.”\nShe added that she did not reach out to the board but “when individual board members reached out directly to me \nfor feedback about Sam, I provided it — all feedback Sam already knew,” and that did not mean she was \n“responsible for or supported the old board’s actions.”\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nSince November, OpenAI and its investors have scrambled to contain the fallout from the incident, which \nthreatened to upend one of the tech industry’s most important start-ups. OpenAI was valued at more than $80 \nbillion in its last financing round.\nMuch of the remaining 700-plus employees at OpenAI — many of whom threatened to quit when Mr. Altman was \nfired — hope to put the events in November behind them. (Some employees refer to that period as “The Blip.”)\nBut there are others who are hopeful that the WilmerHale investigation will provide a thorough accounting of the \nevents surrounding Mr. Altman’s dismissal. It is not clear if the full report or a synopsis of it will be released to the \npublic.\nAt the time of Mr. Altman’s firing, OpenAI’s six-person board included Dr. Sutskever; Helen Toner, an A.I. \nresearcher who works at a Georgetown University think tank; Adam D’Angelo, a former Facebook executive; Greg \nBrockman, a co-founder and president of the company; Tasha McCauley, an adjunct senior management scientist \nat the RAND Corporation; and Mr. Altman.\nAs a condition of Mr. Altman’s reinstatement, executives agreed to shuffle OpenAI’s board to include a more \ndiverse and independent set of directors. OpenAI’s six-person board was whittled down to an interim board of three: \nBret Taylor, a former Salesforce and Facebook executive, joined as a board chairman helping to appoint a new set \nof directors. Lawrence H. Summers, the former Treasury Secretary, also joined. Mr. D’Angelo remains on the \nboard.\nIn October, Ms. Murati approached some members of the board and expressed concerns about Mr. Altman’s \nleadership, the people said.\nShe described what some considered to be Mr. Altman’s playbook, which included manipulating executives to get \nwhat he wanted. First, Ms. Murati said Mr. Altman would tell people what they wanted to hear to charm them and \nsupport his decisions. If they did not go along with his plans or if it took too long for them to make a decision, he \nwould then try to undermine the credibility of people who challenged him, the people said.\nKey OpenAI Executive Played a Pivotal Role in Sam Altman’s Ouster\nMs. Murati told the board she had previously sent a private memo to Mr. Altman outlining some of her concerns with \nhis behavior and shared some details of the memo with the board, the people said.\nAround the same time in October, Dr. Sutskever approached members of the board and expressed similar issues \nabout Mr. Altman, the people said.\nSome members of the board were concerned that Ms. Murati and Dr. Sutskever would leave the company if Mr. \nAltman’s behavior was not addressed. They also grew concerned the company would see an exodus of talent if top \nlieutenants left.\nThere were other factors that went into the decision. Some members were concerned about the creation of the \nOpenAI Startup Fund, a venture fund started by Mr. Altman. Unlike a typical company investment fund, which is a \nlegal extension of the corporation, Mr. Altman held legal ownership for the OpenAI fund and raised money from \noutside limited partners. OpenAI said that the structure was temporary, and that Mr. Altman would not receive \nfinancial benefit from it.\nThe OpenAI fund used that money to invest in other artificial intelligence start-ups. Some members of the board \ngrew concerned that Mr. Altman used the fund to skirt accountability from OpenAI’s nonprofit governance structure. \nThey confronted Mr. Altman about his legal ownership and operational control over the fund last year.\nAxios has previously reported on Mr. Altman’s control of the OpenAI fund.\nMembers of the board began discussing their next steps after they were approached by Ms. Murati and Dr. \nSutskever. By mid-November, the board planned to name Ms. Murati as interim chief executive while conducting a \nsearch for a new C.E.O., the people said. The board ousted Mr. Altman on Nov. 17.\nIn the days after, Mr. Altman waged a public fight to regain his position, using a mix of public pressure and powerful \nallies in Silicon Valley to push for his reinstatement. Most of OpenAI’s 770 employees threatened to quit if he were \nnot reinstalled as chief executive. Ms. Murati and Dr. Sutskever quickly — and publicly — said they supported Mr. \nAltman’s return to the company. Dr. Sutskever has not returned to his regular duties at the company, some of the \npeople said.\nAfter five days of public back and forth, Mr. Altman returned to his job.\nPHOTOS: Mira Murati, OpenAI’s chief technology officer, had concerns about the management of Sam Altman, the \ncompany’s chief executive. The ouster of Mr. Altman, shown at a congressional hearing last year, created days of \nchaos at OpenAI. (PHOTOGRAPHS BY JIM WILSON/THE NEW YORK TIMES; HAIYUN JIANG/THE NEW YORK \nTIMES) This article appeared in print on page B1, B3.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In Silicon Valley, Venture Capital Meets a Generational Shift",
        "media": "The New York Times",
        "time": "March 14, 2024",
        "section": "TECHNOLOGY",
        "length": "1318 words",
        "byline": "Erin Griffith Erin Griffith covers tech companies, start-ups and the culture of Silicon Valley from San",
        "story_text": "In Silicon Valley, Venture Capital Meets a Generational Shift\nThe New York Times \nMarch 13, 2024 Wednesday 22:07 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1318 words\nByline: Erin Griffith Erin Griffith covers tech companies, start-ups and the culture of Silicon Valley from San \nFrancisco.\nHighlight: Big-name investors such as Reid Hoffman and Michael Moritz are pulling back, creating room for a new \ngeneration of tech power brokers.\nBody\nReid Hoffman, a founder of LinkedIn and a longtime venture capitalist, is no longer the public face of the venture \nfirm Greylock. Michael Moritz, a force at Sequoia Capital for 38 years, officially separated from the investment firm \nlast summer. And Jeff Jordan, a top investor at Andreessen Horowitz for 12 years, left in May.\nThey are among the most recognizable of a generation of Silicon Valley investors who are getting out of venture \ncapital at the end of a lucrative 15-year upswing for the industry.\nMany more are leaving. Investors at Tiger Global, Paradigm, Lightspeed Venture Partners, Emergence Capital and \nSpark Capital have all announced plans to step back. Foundry Group, a venture firm in Boulder, Colo., that has \nbacked 200 companies since 2006, said in January that it would not raise another fund.\nTaken together, the steady thrum of departures has created a sense that venture capital — a $1.1 trillion corner of \nfinance that invests in young, private companies, sometimes spawning enterprises like Apple, Google and Amazon \n— is in a moment of transition.\n“We’re at a tipping point,” said Alan Wink, a managing director of capital markets at EisnerAmper, which provides \nadvisory services to venture capital firms. While there have been waves of retirements in the past, he said, this one \nis more pronounced.\nThe turnover creates an opening for new investors to step up, potentially shifting who the power players are in \nSilicon Valley. That may also change the calculus for young companies as they decide which venture firms to seek \nmoney from.\nYet the latest generation of investors faces a start-up investment landscape that has become more challenging. \nFew venture capital funds are reaping the kinds of enormous windfalls — which come when start-ups go public or \nare bought — that can secure an investor’s reputation. That also makes it harder for venture firms to raise money, \nwith fund-raising by the industry falling 61 percent last year and some large firms cutting their targets.\nThe last generation of investors, including Mr. Moritz, 69; Mr. Hoffman, 56; John Doerr of Kleiner Perkins, 72; Jim \nBreyer of Accel, 62; and Bill Gurley of Benchmark, 57, rose to prominence by making bets on consumer internet \nstart-ups like Google, Facebook, Uber and Airbnb, which turned into behemoths.\nToday’s up-and-coming venture capitalists are waiting for their version of those winners. Some of the most highly \nvalued start-ups — such as OpenAI, the artificial intelligence company valued at $86 billion — are in no hurry to go \npublic or sell. And the frenzy around generative A.I. could take years to translate into big wins.\nIn Silicon Valley, Venture Capital Meets a Generational Shift\n“We’re in this period of reset, based on where the technology is and where it’s going,” said David York, an investor \nat Top Tier Capital, which invests in other venture capital firms. “These stars will emerge.”\nIndustry stalwarts like Vinod Khosla of Khosla Ventures, Marc Andreessen of Andreessen Horowitz and Peter Thiel \nof Founders Fund continue to write checks and wield influence. (All three firms have backed  OpenAI.)\nBut many others are stepping down as a 15-year winning streak that reaped billions in profit for the industry has \nrecently curdled into a downturn. Venture capital firms typically invest over 10-year fund cycles, and some aren’t \neager to sign up for another decade.\n“There’s a bull market element to it,” said Mike Volpi, 57, an investor at Index Ventures who recently said he would \nstep down from the firm’s next fund. Mr. Volpi’s decision was earlier reported by the newsletter Newcomer.\nMr. Wink of EisnerAmper said that in some cases, the investors that back venture capital funds were eager for fresh \nblood. The message, he said: Get out at the top.\n“Don’t be like a lot of professional athletes that sign that last contract and your performance on the field was \nnowhere near where it was in your glory days,” he added.\nFor years, venture capital could only grow, propelled by low interest rates that lured investors everywhere to take \nmore risk. Cheap cash, as well as the proliferation of smartphones and plentiful cloud storage, allowed many tech \nstart-ups to flourish, producing bumper returns for investors who bet on those companies over the last 15 years.\nInvestments in U.S. start-ups soared eightfold to $344 billion between 2012 and 2022, according to PitchBook, \nwhich tracks start-ups. Venture capital firms grew from tiny partnerships into enormous asset managers.\nThe largest venture firms, including Sequoia Capital and Andreessen Horowitz, now manage tens of billions of \ndollars of investments. They have expanded into more specialized funds focusing on assets like cryptocurrencies, \nopened offices in Europe and Asia and dabbled in new areas such as wealth management and public stocks.\nAndreessen Horowitz, Sequoia Capital, Bessemer Venture Partners, General Catalyst and others also became \nregistered investment advisers, which meant they could invest in more than just private companies. Venture capital \nwas briefly the hot job for ambitious young people in finance.\nThe expansions have contributed to decisions by some investors to step back. Mr. Volpi, who joined Index Ventures \nin 2009 after 14 years at Cisco, said he had gotten into venture capital for a change of pace from the corporate \nworld. He backed start-ups including the work messaging company Slack and the A.I. start-up Cohere.\nBut over the years, Index — and the overall venture industry — became bigger and more professionalized.\n“Maybe it’s for someone else to go fight that battle,” Mr. Volpi said.\nMany venture funds have also grown so large that owning a stake in a “unicorn,” or a start-up valued at $1 billion or \nmore, is no longer enough to reap the same profits as before.\n“If you want to return three times your fund, then a unicorn isn’t sufficient,” said Renata Quintini, an investor at \nRenegade Partners, a venture capital firm. “You need a decacorn,” she added, referring to a start-up worth $10 \nbillion or more.\nThe largest firms have migrated from providing their investors with profits from the traditional definition of venture \ncapital — very young, high risk companies with potential for outsize growth — to a more general idea of “tech \nexposure,” Ms. Quintini said.\nManu Kumar, a founder of the venture firm K9 Ventures, has felt the shift. Since 2009, he has written checks of \n$500,000 or less to invest in very young companies. Some of those investments, including Lyft and Twilio, went \npublic, while others sold to bigger tech companies like LinkedIn, Meta, Google and Twitter.\nIn Silicon Valley, Venture Capital Meets a Generational Shift\nBut starting last year, he said, the venture capital investors who would have provided the next round of funding to \nthe start-ups he backed began demanding to see more progress before investing. (Start-ups typically raise a series \nof increasingly large financings until they go public or sell.) And potential buyers were laying off employees and \ncutting costs, not acquiring start-ups.\n“Companies today only have one option,” Mr. Kumar said. “They have to build a real business.”\nIn October, Mr. Kumar told investors that the math on his investment strategy no longer worked and that he would \nnot raise a new venture fund. He plans to watch the market and revisit the option in a year.\n“I want to have conviction in what my strategy is going to be,” he said. “I don’t have that conviction at the moment.”\nPHOTOS: Clockwise, from top left, Jeff Jordan, Reid Hoffman, Bill Gurley and Michael Moritz. They are among top \ninvestors who have gotten out of the industry. (PHOTOGRAPHS BY SCOTT OLSON/GETTY IMAGES, CLARA \nMOKRI FOR THE NEW YORK TIMES, NOAH BERGER FOR THE NEW YORK TIMES, PETER EARL \nMCCOLLOUGH FOR THE NEW YORK TIMES) (B1); Industry stalwarts like Vinod Khosla of Khosla Ventures \ncontinue to write checks. But many others are stepping down after an industry downturn. (PHOTOGRAPH BY \nANASTASIIA SAPON FOR THE NEW YORK TIMES) (B3) This article appeared in print on page B1, B3.\nLoad-Date: March 14, 2024"
    },
    {
        "file_name": "|_Fact_check_Mar2024",
        "header": "Image of Donald Trump leading crowd down flag-lined street is AI-generated",
        "media": "| Fact check",
        "time": "March 15, 2024",
        "section": "",
        "length": "711 words",
        "byline": "Joedy McCreary, USA TODAY",
        "story_text": "Image of Donald Trump leading crowd down flag-lined street is AI-generated \n| Fact check\nUSA Today Online\nMarch 15, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 711 words\nByline: Joedy McCreary, USA TODAY\nBody\nThe claim: Image shows Trump leading large crowd down flag-lined street\nA March 6 Facebook post (direct link, archive link) appears to show a massive crowd of people following former \nPresident Donald Trump down a street lined with American flags.\n“America stands with Trump,” reads the text in the image.\nIt was shared more than 1,000 times in eight days. \nMore from the Fact-Check Team:How we pick and research claims | Email newsletter | Facebook page\nOur rating: Altered\nThe image was generated by artificial intelligence, according to two computer science experts and an AI-detection \ntool.\nAI-generated image ‘not consistent with the physical world’\nA version of the image was first posted to social media the day before Trump's April 2023 arraignment in New York \nand was shared by  Eric Trump. It circulated again 11 months later as the former president secured the presumptive \nRepublican presidential nomination by earning enough delegates in state caucuses and primary elections.\nThe original image is in crisper focus than the one posted to Facebook, and it includes a watermark in the lower-\nright corner that identifies the social media user who originally shared it. In the more recent version, Trump is the \nonly person in focus. It was cropped to remove the watermark but includes the logo of the pro-Trump apparel \nretailer that shared the image.\nFact check: Image of Donald Trump, Jeffrey Epstein on private jet is AI generated\n\"The images are definitely the output of generative AI,\" James O’Brien, a computer science professor at the \nUniversity of California, Berkeley, told USA TODAY in an email.\nThe original also contains several hallmarks of AI-generated images that are less prominent in the more recent \nversion, Walter Scheirer, an associate professor of computer science and engineering at the University of Notre \nDame, told USA TODAY in an email.\nMany of the people in the crowd – including a man in a beige hat behind the car on the left and another in a light \nblue shirt behind Trump’s right shoulder – have features that are “deformed in a highly unnatural way,” Scheirer \nImage of Donald Trump leading crowd down flag-lined street is AI-generated | Fact check\nsaid. Additionally, the stars on many of the flags are arranged in incorrect patterns, and several flags have the \nwrong number of stars.\n“Overall, the image is in a cartoon-style that is not consistent with the physical world, but is very popular on the \nInternet – especially for political image generation,” Scheirer said.\nUSA TODAY ran both versions of the image through the online AI detection tool Hive Moderation. It reports the \nhigh-resolution original version is 99.9% likely to be AI-generated – and is 99.9% likely to have been created with \nthe program Midjourney. For the version in the Facebook post, the likelihood that it is an AI creation drops to 85.8%, \nthe detection tool determined.\nThe version posted to Facebook “looks lower quality to me, perhaps due to compression and resizing,” Scheirer \nsaid. “That might have been intentional to obscure the visible artifacts, or an unintentional consequence of \nuploading the photo to a different platform with its own image-processing algorithms.”\nTrump has been at the center of several false claims involving AI-generated images. USA TODAY has fact-checked \nfabricated images of the former president dancing with a teenage girl, being arrested by law enforcement and \nposing for a mugshot.\nPolitiFact also debunked the claim, and Forbes in April 2023 also concluded that AI was used to create the original \nimage.\nOur fact-check sources:\n• Walter Scheirer, March 14, Email exchange with USA TODAY\n• James O’Brien, March 14, Email exchange with USA TODAY\n• Hive Moderation (Internet Archive), March 14, Trump Orig AI Detector\n• Hive Moderation (Internet Archive), March 14, Trump Facebook AI Detector\n• Smithsonian, accessed March 14, Facts about the United States Flag\nThank you for supporting our journalism. You can subscribe to our print edition, ad-free app or e-newspaper here.\nUSA TODAY is a verified signatory of the International Fact-Checking Network, which requires a demonstrated \ncommitment to nonpartisanship, fairness and transparency. Our fact-check work is supported in part by a grant from \nMeta.\nThis article originally appeared on USA TODAY: Image of Donald Trump leading crowd down flag-lined street is AI-\ngenerated | Fact check\nLoad-Date: March 15, 2024"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "Planning needed if you want to hit the road alone",
        "media": "USA Today",
        "time": "March 15, 2024",
        "section": "BUSINESS; Pg. B5",
        "length": "1349 words",
        "byline": "By, Kathleen Wong",
        "story_text": "Planning needed if you want to hit the road alone\nUSA Today\nMarch 15, 2024 Friday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B5\nLength: 1349 words\nByline: By, Kathleen Wong\nBody\nSafety is always top of mind when traveling, and it's especially important for solo travelers who have to look out for \nthemselves.\nBoarding the plane to head to another country alone is often an emotional experience - there's the excitement, the \nanxiety, the anticipation. It can also be totally nerve-wracking. When Angie Orth made the bold choice to leave her \njob and embark on a solo yearlong journey around the world in 2011, her friends and family cautioned her about \nsafety concerns. \"Everyone was horrified,\" the Florida native told USA TODAY. \"The fear was all I heard.\"\nThe then New York City-based Orth kicked off her 12-country solo trip in Fiji before making her way to New \nZealand, Australia, and Southeast Asia. Then she trekked through Europe, including Greece, Spain and England, \nand stopped in Turkey and Egypt before ending in Kenya and South Africa.\nIt wasn't always smooth traveling. At times, Orth said she survived \"by the skin of my teeth.\" Orth was in Egypt \nduring the Arab Spring, got unbelievably sick in Thailand, and had a bike accident in Bali. She was also robbed of \n400 euros. \"I was in Greece for a half an hour and had already been pickpocketed,\" she said.\nStill, to Orth, the solo journey was invaluable. \"It's a confidence that I don't think there's any other way to get that \nconfidence than by solo travel,\" she said, referring to the problem-solving that inherently comes with navigating \ntravel on your own. Then there's also the compassion you gain from meeting and experiencing other cultures.\nNow more than ever, more people are deciding to forgo travel companions and embark on their trips alone. Solo \nvacation package searches on Google shot up by more than 200% over the past 90 days as of Feb. 2.\nIncreased connectivity on our phones makes it easier to feel secure and social media shows more people - \nespecially women - traveling the world alone.\n\"Women are not waiting for permission or their 401(k) to mature. If my husband doesn't want to go, fine. Women \nare having more confidence,\" said Orth, who is also the author of the upcoming book \"Flirting with Disaster,\" which \nchronicles her yearlong solo trip.\nHere's everything you need to know about solo travel.\nHow to safely travel alone\nSafety is always top of mind when traveling, and it's especially important for solo travelers who have to look out for \nthemselves.\nPlanning needed if you want to hit the road alone\n\"Isn't it fun to meet a person in a hostel and say yes, let's go hiking right now? That's fun, but it's risky,\" Orth said. \n\"It's about balancing it out and researching ridiculously.\"\nStart your research by heading to the State Department website to see if there are any travel advisories for the \ndestination you're interested in. These advisories are based on changing conditions and also inform you about the \nspecific region you're visiting.\nFor the most direct updates, enroll in the agency's Smart Traveler Enrollment Program (STEP), a free service that \nsends you the most up-to-date information on the destination. It can also help connect you to the nearest U.S. \nembassy and consulate if traveling and something happens.\nOne thing Orth always searches for is \"the destination plus scams\" to see what she has to look out for when in that \nplace. Many European cities are notorious for petty theft, like pickpocketing in popular tourist hotspots like the Trevi \nFountain or public transportation.\nWhen doing research, it may feel like an information overload. \"There is so much information now, you could read \n1,000 reviews and get so many sources of conflicting information,\" Orth added. \"It's hard to wade through all that \nand find trusted sources.\"\nTo help sift through everything, Orth recommends reaching out to others who have traveled to your ideal \ndestination. She also recommended cleaning out your feed and only following travel content creators who \"give you \nthe good and the bad.\"\n\"You don't want the glossy, glossy, oh, it's so magical because travel isn't always so magical,\" she said.\nAt your destination, you'll also need at least a basic understanding of the language used there. \"Translation plays a \nbig role in safety, just being aware of your surroundings,\" said Craig Ewer, Google Communications Manager for \nSearch.\nBesides direct translation between 133 languages, the Google Translate app offers pronunciation help - \"such a \nlifesaver,\" according to Rose Yao, vice president of product management at Google. You can also snap a picture of \na menu and have it translated in real time.\nThe Google app also has a feature called Lens that allows users to search using a picture of something like a sign. \n\"You'd be surprised at what you can Lens: menus, what is that building or what is that statue,\" Yao said. You can \nalso capture a screenshot of your social media feed and then search for it on Google to incorporate it into your \ntravel plans.\nStaying healthy on your travels\nTo safeguard yourself and others against preventable illnesses while exploring new places, look up any \nrecommended vaccinations for the countries you plan on visiting. The Centers for Disease Control and Prevention \nwebsite is a good starting point, with in-depth travel health notices and recommended vaccines and medicines \nposted.\nThe CDC website also offers travel advice on managing nonpreventable illnesses, like preventing bug bites to \nreduce the risk of contracting diseases like dengue or Zika.\nTypically, you'd want to give yourself at least a month before departing on your trip to get everything you need from \nyour doctor. And if you don't know who to go to, the CDC can help you find a clinic as well.\nOrth recommends having a doctor help you put together a medical kit with some necessities and medications, such \nas for food poisoning. \"It's helpful to have some things on hand so you're not scrambling on a remote island and no \none knows what you're talking about,\" she said.\nPlanning needed if you want to hit the road alone\nAs you're making the big purchases for your trip, don't forget about travel insurance for the unexpected. Orth said \nshe never travels without this layer of protection. Travel insurance not only helped with her medical costs from her \nbike collision but also replaced her camera, which was smashed in the accident. She also recommends a service \ncalled MedJet, which offers worldwide security crisis and medical transportation assistance for its members.\nWhat are the most popular solo travel destinations?\nAccording to Google, the top-searched destinations for American solo travelers are:\nLondon\nAlaska\nHawaii\nPuerto Rico\nItaly\nTips for solo travelers\nThe Google app's generative AI search allows you to \"ask really detailed questions like you would ask a friend,\" \nYao said. \"Ask what's off the beaten path, what's not crowded. What's a great time to visit the Louvre that's not \nsuper crowded?\"\nFor your first trip alone, it's OK to start small and dip your toes in the solo travel pool. \"Start in an easier destination, \nsomething more familiar where you speak the language or you don't have to fly far away,\" Orth said. \"A lot of folks \nsee 'Eat, Pray, Love' and travel content creators trekking in Borneo for it to count but it doesn't.\"\nIt won't always be rainbows and butterflies, despite what you see on social media. Expect decision fatigue from \nhaving to make many micro-decisions, like if this taxi driver seems safe. \"I think this probably hits women a lot \nharder than it hits men because we are never not thinking about our safety, and that's if we're going to Target in our \nhometown or hopping on a plane to a remote island,\" Orth said.\nMake an itinerary for yourself with at least one thing planned every day, so you don't feel aimless but still have \nspace for flexibility, said Madison Pietrowski, U.S. brand director at GetYourGuide, a marketplace for travel \nexperiences, where each company listed is thoroughly vetted. It can be as casual as wanting to eat at a certain \nrestaurant for dinner or more intensive like a whole-day tour.\n(On that note, make sure to read the fine print and be aware of cancellation policies for your excursions.)\nSafety is always top of mind when traveling, and it's especially important for solo travelers who have to look out for \nthemselves.\nGraphic\n \nAngie Orth went on a year-long solo adventure in 2011, back when it was less mainstream.\nProvided by Angie Orth\nLoad-Date: March 15, 2024\nPlanning needed if you want to hit the road alone"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Modernist With His Eye to the Sky",
        "media": "The New York Times",
        "time": "March 15, 2024",
        "section": "Section C; Column 0; Movies, Performing Arts/Weekend Desk; Pg. 12; CRITIC'S PICK",
        "length": "972 words",
        "byline": "By Jonathan Griffin",
        "story_text": "Modernist With His Eye to the Sky\nThe New York Times\nMarch 15, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section C; Column 0; Movies, Performing Arts/Weekend Desk; Pg. 12; CRITIC'S PICK\nLength: 972 words\nByline: By Jonathan Griffin\nBody\nThe Light and Space artist who flew under the radar has his moment in the sun.\nAesthetically, Los Angeles is mostly a mess. Unplanned, mismatched buildings sprout like fungus among the grid of \nits streets, whose orderly classicism is often disrupted by tectonically induced hills. Curbs crumble and sidewalks \ncrack beneath telegraph poles festooned with cables. Flamboyant succulents mingle with scrubby native plants. \n  What aesthetic perfection Los Angeles offers is mainly in its skies. Breathtaking ombres of color ascend from the \nhorizon, even outside its ''golden hour'' -- the famously lambent period before sunset -- even without the haze that \namplifies these atmospheric special effects.\n  In the 1960s, many of this region's most celebrated artists were inspired by the vault of the heavens, rather than \nthe gritty realities on the streets beneath. They favored new media, technologies often developed by the local \naerospace industry. Traditional paint on canvas was often sidelined in favor of modern industrial materials such as \npoured resin, ground glass, lacquers and microfilm coatings.\n  The artist Norman Zammitt, a colorist who excelled as a painter, remains less well known than his peers in the \nLight and Space movement. (The artist died in 2007.) Finally, a survey exhibition of Zammitt's art at the Palm \nSprings Art Museum is taking visitors on a glorious tour through his chromatic investigations.\n  Born in 1931 in Toronto, Zammitt moved to Southern California as a teenager. In the 1960s, he experimented with \nmaking fashionably minimalist sculptures from acrylic resin and plexiglass, but hit his stride the following decade \nwith paintings on canvas in what became his signature style: horizontal bands of acrylic color, shifting incrementally \nthrough shades both sickly and sublime.\n  This exhibition, titled ''Gradations'' and curated by Sharrissa Iqbal, starts good and gets better. Between entrance \nwalls painted sunflower yellow, Zammitt's panoramic painting ''One,'' from 1973, greets visitors. From a distance, \nthe painting seems mostly yellow too. But as you draw near, you'll identify colors from inky black, along the bottom, \nrising through dioxazine purple, cerise, coral, orange, then five or six different tones of yellow, in widening bands. \nUp close, the painting, 16 feet wide, bathes you in radiant luminosity.\n  ''One'' is Zammitt's first large-scale iteration of what he would call his ''Band Paintings.'' Turn around in the gallery \nand you'll see two more, both painted in 1975: ''Green One'' -- which recalls the subaquatic rather than the aerial -- \nand ''Arctic Yellow.'' As time went by, the bands became thinner, the colors became more subtly gradated, \nZammitt's surfaces more pristine and his effects more ecstatic.\nModernist With His Eye to the Sky\n  Zammitt applied himself to his work with a lab technician's precision. According to a wall text, by the mid-1970s \nhe'd developed a ''complex mathematical system'' for mixing his colors, weighing out pigments according to curves \non a graph. When I asked, Iqbal was unable to fully elucidate this process, although she did reveal that during the \n1980s Zammitt began working with mathematicians at the California Institute of Technology who showed him how \ncomputers could help him develop more complex variables for his color charts. When desktop computers became \naffordable, he bought one and commissioned a custom program that enabled him to formulate gradations of colors.\n  Running down either side of the gallery are rows of smaller paintings, many just eight or nine inches wide, that \nseem to serve as studies for his larger works. Hanging near most of the mighty paintings are their mini-me \ncompanions. An exhibition of these small canvases -- exquisite objects in themselves -- recently opened at Karma \nin Los Angeles, and that gallery is credited, along with Zammitt's estate, with supplying most of the works for this \nshow.\n  The sky wasn't Zammitt's only visual reference. One especially dazzling painting from 1976, ''North Wall,'' \nachieves holograph illusions of depth, its horizontal bands pulsating before our eyes. It brings to mind Mexican \nserape blankets, or Native American weavings. Though he seldom advertised it, Zammitt's mother was from the \nMohawk Nation and the family spent time living on the Kahnawake Mohawk Territory, a First Nations reserve near \nMontreal before moving to California.\n  Iqbal conjectures that Zammitt's Native American heritage may have led him to view abstraction as a path toward \nspiritual transcendence. The artist himself remained largely mute on the subject. An early laminated acrylic \nsculpture, its layers sandwiching optically dazzling layers of rainbow dots, is titled ''Caugnawaga II'' -- an alternative \nspelling of the reserve where Zammitt once lived -- but the piece itself bears no overt relevance to Mohawk culture.\n  The exhibition contains an unexpected plot twist: In the late 1980s, Zammitt's razor-straight lines and flat color \ndisintegrated in what he called ''Fractal'' paintings. A spectacular example of this style is the latest work in the show: \n''Triptych XI,'' painted in 1992. It is an extraordinarily complex painting, an interlocking jigsaw of jagged forms, \nperhaps inspired by a coastline or cloudscape, loosely painted in dusky shades that ascend into blackness.\n  Why is Zammitt emerging from relative obscurity only now, in this artistic moment of generative A.I. and arcana, \nsocial activism and breakfast-table still lifes? Perhaps Zammitt's art strikes a chord because it transcends its \nhistorical period -- and ours, too. Not only do his paintings look as fresh as they must have when new, but they lift \nus out of our vexed and messy present, connecting us with the eternal.\n  Norman Zammitt: Gradations\n  Through Oct. 7, Palm Springs Art Museum, 101 Museum Drive, Palm Springs, Calif., psmuseum.org.\nhttps://www.nytimes.com/2024/03/14/arts/design/norman-zammitt-painter-palm-springs-california.html\nGraphic\n \nPHOTOS: Top, ''Triptych XI'' (1992), part of the Norman Zammitt show ''Gradations.'' Center left: ''One'' (1973) in \nthe foreground, and ''North Wall'' (1976), partially obscured in the background. Center right: ''Caly-forny-ay'' (1987). \nAbove, from left: ''Green One'' (1975)\nand ''Caugnawaga II'' (1966). (PHOTOGRAPHS BY RJ SÁNCHEZ/SOLSTREAM STUDIOS, VIA PALM SPRINGS \nART MUSEUM\n ESTATE OF NORMAN ZAMMITT AND KARMA) This article appeared in print on page C12.               \nModernist With His Eye to the Sky\nLoad-Date: March 15, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "PepsiCo leans on Indian tech talent to leverage GenAI",
        "media": "The Economic Times",
        "time": "March 15, 2024",
        "section": "TECH & INTERNET",
        "length": "474 words",
        "byline": " ",
        "story_text": "PepsiCo leans on Indian tech talent to leverage GenAI\nThe Economic Times\nMarch 15, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 474 words\nBody\nBeverages and snacks maker PepsiCo is betting big on generative artificial intelligence (GenAI), which is helping \nit develop and launch products faster, chief strategy and transformation officer Athina Kanioura told ET. The maker \nof Pepsi soft drink, Tropicana juices and Lays potato chips is also planning to expand its back-office operations in \nIndia and hire more employees, she said.GenAI has helped the company in areas of productivity, marketing, \ncustomer service and feedback to develop new products and launch those in the market faster, the executive \nsaid.The US-headquartered firm has firmed up plans to add a new capability centre in India this year and plans to \nhire more employees here. It currently has nearly 4,000 employees in its two capability centres, in Hyderabad and \nGurugram.“We are adding a third capability centre in India this year soon … and elevating a lot of our India \nleadership roles as well as global leadership, positioning a lot of talent out of India...India’s talent is being leveraged \nacross the globe,” Kanioura said.The Hyderabad centre, which employs around 3,000 employees, is focused on AI, \nprocess transformation and next generation technologies, while the Gurugram facility works on software \nengineering, she said.Leveraging GenAIThe company experimented with GenAI in its marketing campaigns, the \nPepsiCo executive said. \nWhile AI helped reduce the campaign cycle from 6-9 months to 3-4 months, GenAI has helped that shrink further. \n“Now, we are able to go to the market faster,” she said.Citing snack brand Cheetos as an example, Kanioura said \nthe company utilised GenAI to get the product its “perfect shape, perfect flavour”, with the relevant customer \nfeedback. This allowed the firm to sustain margins on the product while driving revenue.“The second penetration \nwith GenAI is in consumer segments which include expansion of the portfolio. Overall, the delta with this example \nwas up by 15%,” she said, adding that this could boost both revenue and profitability.For the industry, she expects \nGenAI to bring an incremental uplift of 10-15% in revenue, depending on the maturity of a company.PepsiCo wants \nto use Gen AI to give the company the ability to synthesise, analyse more data and find synergies with other \ncategories that consumers might want.In the US, the GenAI experiments have already resulted in the entry of a new \nproduct in the non-alcoholic space, Kanioura said.PepsiCo had appointed Jagrut Kotecha as its new India chief in \nJanuary. ET recently reported that PepsiCo’s snacks business has been facing intense competition and has been \nlosing volume and market share. The company wants to get those back.In India, PepsiCo employs about 2,400 \npeople along with 4,000 contractual workers at its four sales units and four manufacturing facilities. For Reprint \nRights: timescontent.com\nLoad-Date: March 15, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2024",
        "header": "In Silicon Valley, Venture Capital Meets a Generational Shift",
        "media": "The New York Times - International Edition",
        "time": "March 15, 2024",
        "section": "TECHNOLOGY",
        "length": "1281 words",
        "byline": "Erin Griffith",
        "story_text": "In Silicon Valley, Venture Capital Meets a Generational Shift\nThe New York Times - International Edition\nMarch 16, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1281 words\nByline: Erin Griffith\nDateline: SAN FRANCISCO \nBody\nABSTRACT\nBig-name investors such as Reid Hoffman and Michael Moritz are pulling back, creating room for a new generation \nof tech power brokers.\nFULL TEXT\nReid Hoffman, a founder of LinkedIn and a longtime venture capitalist, is no longer the public face of the venture \nfirm Greylock. Michael Moritz, a force at Sequoia Capital for 38 years, officially separated from the investment firm \nlast summer. And Jeff Jordan, a top investor at Andreessen Horowitz for 12 years, left in May.       \nThey are among the most recognizable of a generation of Silicon Valley investors who are getting out of venture \ncapital at the end of a lucrative 15-year upswing for the industry.       \nMany more are leaving. Investors at Tiger Global, Paradigm, Lightspeed Venture Partners, Emergence Capital and \nSpark Capital have all announced plans to step back. Foundry Group, a venture firm in Boulder, Colo., that has \nbacked 200 companies since 2006, said in January that it would not raise another fund.       \nTaken together, the steady thrum of departures has created a sense that venture capital - a $1.1 trillion corner of \nfinance that invests in young, private companies, sometimes spawning enterprises like Apple, Google and Amazon \n- is in a moment of transition.       \n\"We're at a tipping point,\" said Alan Wink, a managing director of capital markets at EisnerAmper, which provides \nadvisory services to venture capital firms. While there have been waves of retirements in the past, he said, this one \nis more pronounced.       \nThe turnover creates an opening for new investors to step up, potentially shifting who the power players are in \nSilicon Valley. That may also change the calculus for young companies as they decide which venture firms to seek \nmoney from.       \nYet the latest generation of investors faces a start-up investment landscape that has become more challenging. \nFew venture capital funds are reaping the kinds of enormous windfalls - which come when start-ups go public or are \nbought - that can secure an investor's reputation. That also makes it harder for venture firms to raise money, with \nfund-raising by the industry falling 61 percent last year and some large firms cutting their targets.       \nIn Silicon Valley, Venture Capital Meets a Generational Shift\nThe last generation of investors, including Mr. Moritz, 69; Mr. Hoffman, 56; John Doerr of Kleiner Perkins, 72; Jim \nBreyer of Accel, 62; and Bill Gurley of Benchmark, 57, rose to prominence by making bets on consumer internet \nstart-ups like Google, Facebook, Uber and Airbnb, which turned into behemoths.       \nToday's up-and-coming venture capitalists are waiting for their version of those winners. Some of the most highly \nvalued start-ups - such as OpenAI, the artificial intelligence company valued at $86 billion - are in no hurry to go \npublic or sell. And the frenzy around generative A.I. could take years to translate into big wins.       \n\"We're in this period of reset, based on where the technology is and where it's going,\" said David York, an investor \nat Top Tier Capital, which invests in other venture capital firms. \"These stars will emerge.\"       \nIndustry stalwarts like Vinod Khosla of Khosla Ventures, Marc Andreessen of Andreessen Horowitz and Peter Thiel \nof Founders Fund continue to write checks and wield influence. (All three firms have backed  OpenAI.)       \nBut many others are stepping down as a 15-year winning streak that reaped billions in profit for the industry has \nrecently curdled into a downturn. Venture capital firms typically invest over 10-year fund cycles, and some aren't \neager to sign up for another decade.       \n\"There's a bull market element to it,\" said Mike Volpi, 57, an investor at Index Ventures who recently said he would \nstep down from the firm's next fund. Mr. Volpi's decision was earlier reported by the newsletter Newcomer.       \nMr. Wink of EisnerAmper said that in some cases, the investors that back venture capital funds were eager for fresh \nblood. The message, he said: Get out at the top.       \n\"Don't be like a lot of professional athletes that sign that last contract and your performance on the field was \nnowhere near where it was in your glory days,\" he added.       \nFor years, venture capital could only grow, propelled by low interest rates that lured investors everywhere to take \nmore risk. Cheap cash, as well as the proliferation of smartphones and plentiful cloud storage, allowed many tech \nstart-ups to flourish, producing bumper returns for investors who bet on those companies over the last 15 years.       \nInvestments in U.S. start-ups soared eightfold to $344 billion between 2012 and 2022, according to PitchBook, \nwhich tracks start-ups. Venture capital firms grew from tiny partnerships into enormous asset managers.       \nThe largest venture firms, including Sequoia Capital and Andreessen Horowitz, now manage tens of billions of \ndollars of investments. They have expanded into more specialized funds focusing on assets like cryptocurrencies, \nopened offices in Europe and Asia and dabbled in new areas such as wealth management and public stocks.       \nAndreessen Horowitz, Sequoia Capital, Bessemer Venture Partners, General Catalyst and others also became \nregistered investment advisers, which meant they could invest in more than just private companies. Venture capital \nwas briefly the hot job for ambitious young people in finance.       \nThe expansions have contributed to decisions by some investors to step back. Mr. Volpi, who joined Index Ventures \nin 2009 after 14 years at Cisco, said he had gotten into venture capital for a change of pace from the corporate \nworld. He backed start-ups including the work messaging company Slack and the A.I. start-up Cohere.       \nBut over the years, Index - and the overall venture industry - became bigger and more professionalized.       \n\"Maybe it's for someone else to go fight that battle,\" Mr. Volpi said.       \nMany venture funds have also grown so large that owning a stake in a \"unicorn,\" or a start-up valued at $1 billion or \nmore, is no longer enough to reap the same profits as before.       \n\"If you want to return three times your fund, then a unicorn isn't sufficient,\" said Renata Quintini, an investor at \nRenegade Partners, a venture capital firm. \"You need a decacorn,\" she added, referring to a start-up worth $10 \nbillion or more.       \nIn Silicon Valley, Venture Capital Meets a Generational Shift\nThe largest firms have migrated from providing their investors with profits from the traditional definition of venture \ncapital - very young, high risk companies with potential for outsize growth - to a more general idea of \"tech \nexposure,\" Ms. Quintini said.       \nManu Kumar, a founder of the venture firm K9 Ventures, has felt the shift. Since 2009, he has written checks of \n$500,000 or less to invest in very young companies. Some of those investments, including Lyft and Twilio, went \npublic, while others sold to bigger tech companies like LinkedIn, Meta, Google and Twitter.       \nBut starting last year, he said, the venture capital investors who would have provided the next round of funding to \nthe start-ups he backed began demanding to see more progress before investing. (Start-ups typically raise a series \nof increasingly large financings until they go public or sell.) And potential buyers were laying off employees and \ncutting costs, not acquiring start-ups.       \n\"Companies today only have one option,\" Mr. Kumar said. \"They have to build a real business.\"       \nIn October, Mr. Kumar told investors that the math on his investment strategy no longer worked and that he would \nnot raise a new venture fund. He plans to watch the market and revisit the option in a year.       \n\"I want to have conviction in what my strategy is going to be,\" he said. \"I don't have that conviction at the moment.\" \nLoad-Date: March 15, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Venture Capital Is Seeing A Generational Adjustment",
        "media": "The New York Times",
        "time": "March 15, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1238 words",
        "byline": "By Erin Griffith",
        "story_text": "Venture Capital Is Seeing A Generational Adjustment\nThe New York Times\nMarch 15, 2024 Friday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1238 words\nByline: By Erin Griffith\nBody\nReid Hoffman, a founder of LinkedIn and a longtime venture capitalist, is no longer the public face of the venture \nfirm Greylock. Michael Moritz, a force at Sequoia Capital for 38 years, officially separated from the investment firm \nlast summer. And Jeff Jordan, a top investor at Andreessen Horowitz for 12 years, left in May.\nThey are among the most recognizable of a generation of Silicon Valley investors who are getting out of venture \ncapital at the end of a lucrative 15-year upswing for the industry. \n  Many more are leaving. Investors at Tiger Global, Paradigm, Lightspeed Venture Partners, Emergence Capital \nand Spark Capital have all announced plans to step back. Foundry Group, a venture firm in Boulder, Colo., that has \nbacked 200 companies since 2006, said in January that it would not raise another fund.\n  Taken together, the steady thrum of departures has created a sense that venture capital -- a $1.1 trillion corner of \nfinance that invests in young, private companies, sometimes spawning enterprises like Apple, Google and Amazon \n-- is in a moment of transition.\n  ''We're at a tipping point,'' said Alan Wink, a managing director of capital markets at EisnerAmper, which provides \nadvisory services to venture capital firms. While there have been waves of retirements in the past, he said, this one \nis more pronounced.\n  The turnover creates an opening for new investors to step up, potentially shifting who the power players are in \nSilicon Valley. That may also change the calculus for young companies as they decide which venture firms to seek \nmoney from.\n  Yet the latest generation of investors faces a start-up investment landscape that has become more challenging. \nFew venture capital funds are reaping the kinds of enormous windfalls -- which come when start-ups go public or \nare bought -- that can secure an investor's reputation. That also makes it harder for venture firms to raise money, \nwith fund-raising by the industry falling 61 percent last year and some large firms cutting their targets.\n  The last generation of investors, including Mr. Moritz, 69; Mr. Hoffman, 56; John Doerr of Kleiner Perkins, 72; Jim \nBreyer of Accel, 62; and Bill Gurley of Benchmark, 57, rose to prominence by making bets on consumer internet \nstart-ups like Google, Facebook, Uber and Airbnb, which turned into behemoths.\n  Today's up-and-coming venture capitalists are waiting for their version of those winners. Some of the most highly \nvalued start-ups -- such as OpenAI, the artificial intelligence company valued at $86 billion -- are in no hurry to go \npublic or sell. And the frenzy around generative A.I. could take years to translate into big wins.\nVenture Capital Is Seeing A Generational Adjustment\n  ''We're in this period of reset, based on where the technology is and where it's going,'' said David York, an investor \nat Top Tier Capital, which invests in other venture capital firms. ''These stars will emerge.''\n  Industry stalwarts like Vinod Khosla of Khosla Ventures, Marc Andreessen of Andreessen Horowitz and Peter \nThiel of Founders Fund continue to write checks and wield influence. (All three firms have backed  OpenAI.)\n  But many others are stepping down as a 15-year winning streak that reaped billions in profit for the industry has \nrecently curdled into a downturn. Venture capital firms typically invest over 10-year fund cycles, and some aren't \neager to sign up for another decade.\n  ''There's a bull market element to it,'' said Mike Volpi, 57, an investor at Index Ventures who recently said he would \nstep down from the firm's next fund. Mr. Volpi's decision was earlier reported by the newsletter Newcomer.\n  Mr. Wink of EisnerAmper said that in some cases, the investors that back venture capital funds were eager for \nfresh blood. The message, he said: Get out at the top.\n  ''Don't be like a lot of professional athletes that sign that last contract and your performance on the field was \nnowhere near where it was in your glory days,'' he added.\n  For years, venture capital could only grow, propelled by low interest rates that lured investors everywhere to take \nmore risk. Cheap cash, as well as the proliferation of smartphones and plentiful cloud storage, allowed many tech \nstart-ups to flourish, producing bumper returns for investors who bet on those companies over the last 15 years.\n  Investments in U.S. start-ups soared eightfold to $344 billion between 2012 and 2022, according to PitchBook, \nwhich tracks start-ups. Venture capital firms grew from tiny partnerships into enormous asset managers.\n  The largest venture firms, including Sequoia Capital and Andreessen Horowitz, now manage tens of billions of \ndollars of investments. They have expanded into more specialized funds focusing on assets like cryptocurrencies, \nopened offices in Europe and Asia and dabbled in new areas such as wealth management and public stocks.\n  Andreessen Horowitz, Sequoia Capital, Bessemer Venture Partners, General Catalyst and others also became \nregistered investment advisers, which meant they could invest in more than just private companies. Venture capital \nwas briefly the hot job for ambitious young people in finance.\n  The expansions have contributed to decisions by some investors to step back. Mr. Volpi, who joined Index \nVentures in 2009 after 14 years at Cisco, said he had gotten into venture capital for a change of pace from the \ncorporate world. He backed start-ups including the work messaging company Slack and the A.I. start-up Cohere.\n  But over the years, Index -- and the overall venture industry -- became bigger and more professionalized.\n  ''Maybe it's for someone else to go fight that battle,'' Mr. Volpi said.\n  Many venture funds have also grown so large that owning a stake in a ''unicorn,'' or a start-up valued at $1 billion \nor more, is no longer enough to reap the same profits as before.\n  ''If you want to return three times your fund, then a unicorn isn't sufficient,'' said Renata Quintini, an investor at \nRenegade Partners, a venture capital firm. ''You need a decacorn,'' she added, referring to a start-up worth $10 \nbillion or more.\n  The largest firms have migrated from providing their investors with profits from the traditional definition of venture \ncapital -- very young, high risk companies with potential for outsize growth -- to a more general idea of ''tech \nexposure,'' Ms. Quintini said.\n  Manu Kumar, a founder of the venture firm K9 Ventures, has felt the shift. Since 2009, he has written checks of \n$500,000 or less to invest in very young companies. Some of those investments, including Lyft and Twilio, went \npublic, while others sold to bigger tech companies like LinkedIn, Meta, Google and Twitter.\nVenture Capital Is Seeing A Generational Adjustment\n  But starting last year, he said, the venture capital investors who would have provided the next round of funding to \nthe start-ups he backed began demanding to see more progress before investing. (Start-ups typically raise a series \nof increasingly large financings until they go public or sell.) And potential buyers were laying off employees and \ncutting costs, not acquiring start-ups.\n  ''Companies today only have one option,'' Mr. Kumar said. ''They have to build a real business.''\n  In October, Mr. Kumar told investors that the math on his investment strategy no longer worked and that he would \nnot raise a new venture fund. He plans to watch the market and revisit the option in a year.\n  ''I want to have conviction in what my strategy is going to be,'' he said. ''I don't have that conviction at the \nmoment.''\nhttps://www.nytimes.com/2024/03/13/technology/venture-capital-silicon-valley-investors.html\nGraphic\n \nPHOTOS: Clockwise, from top left, Jeff Jordan, Reid Hoffman, Bill Gurley and Michael Moritz. They are among top \ninvestors who have gotten out of the industry. (PHOTOGRAPHS BY SCOTT OLSON/GETTY IMAGES, CLARA \nMOKRI FOR THE NEW YORK TIMES, NOAH BERGER FOR THE NEW YORK TIMES, PETER EARL \nMCCOLLOUGH FOR THE NEW YORK TIMES) (B1)\n Industry stalwarts like Vinod Khosla of Khosla Ventures continue to write checks. But many others are stepping \ndown after an industry downturn. (PHOTOGRAPH BY ANASTASIIA SAPON FOR THE NEW YORK TIMES) (B3) \nThis article appeared in print on page B1, B3.               \nLoad-Date: March 15, 2024"
    },
    {
        "file_name": "Agency_Mar2024",
        "header": "Homeland Security Is Embracing A.I. With Plans to Use Tool Across the",
        "media": "Agency",
        "time": "March 18, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "634 words",
        "byline": "By Cecilia Kang",
        "story_text": "Homeland Security Is Embracing A.I. With Plans to Use Tool Across the \nAgency\nThe New York Times\nMarch 18, 2024 Monday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 634 words\nByline: By Cecilia Kang\nBody\nThe Department of Homeland Security has seen the opportunities and risks of artificial intelligence firsthand. It \nfound a trafficking victim years later using an A.I. tool that conjured an image of the child a decade older. But it has \nalso been tricked into investigations by deep fake images created by A.I.\nNow, the department is becoming the first federal agency to embrace the technology with a plan to incorporate \ngenerative A.I. models across a wide range of divisions. In partnerships with OpenAI, Anthropic and Meta, it will \nlaunch pilot programs using chatbots and other tools to help combat drug and human trafficking crimes, train \nimmigration officials and prepare emergency management across the nation. \n  The rush to roll out the still unproven technology is part of a larger scramble to keep up with the changes brought \nabout by generative A.I., which can create hyper realistic images and videos and imitate human speech.\n  ''One cannot ignore it,'' Alejandro Mayorkas, secretary of the Department of Homeland Security, said in an \ninterview. ''And if one isn't forward-leaning in recognizing and being prepared to address its potential for good and \nits potential for harm, it will be too late and that's why we're moving quickly.''\n  The plan to incorporate generative A.I. throughout the agency is the latest demonstration of how new technology \nlike OpenAI's ChatGPT is forcing even the most staid industries to re-evaluate the way they conduct their work. \nStill, government agencies like the D.H.S. are likely to face some of the toughest scrutiny over the way they use the \ntechnology, which has set off rancorous debate because it has proved at times to be unreliable and discriminatory.\n  Those within the federal government have rushed to form plans following President Biden's executive order issued \nlate last year that mandates the creation of safety standards for A.I. and its adoption across the federal government.\n  The D.H.S., which employs 260,000 people, was created after the Sept. 11 terror attacks and is charged with \nprotecting Americans within the country's borders, including policing of human and drug trafficking, the protection of \ncritical infrastructure, disaster response and border patrol.\n  As part of its plan,  the agency plans to hire 50 A.I. experts to work on solutions to keep the nation's critical \ninfrastructure safe from A.I.-generated attacks and to combat the use of the technology to generate child sexual \nabuse material and create biological weapons.\n  In the pilot programs, on which it will spend $5 million, the agency will use A.I. models like ChatGPT to help \ninvestigations of child abuse materials, human and drug trafficking. It will also work with companies to comb through \nits troves of text-based data to find patterns to help investigators. For example, a detective who is looking for a \nHomeland Security Is Embracing A.I. With Plans to Use Tool Across the Agency\nsuspect driving a blue pickup truck will be able to search for the first time across homeland security investigations \nfor the same type of vehicle.\n  D.H.S. will use chatbots to train immigration officials who have worked with other employees and contractors \nposing as refugees and asylum seekers. The A.I. tools will enable officials to get more training with mock \ninterviews. The chatbots will also comb information about communities across the country to help them create \ndisaster relief plans.\n  The agency will report results of its pilot programs by the end of the year, said Eric Hysen, the department's chief \ninformation officer and head of A.I.\n  The agency picked OpenAI, Anthropic and Meta to experiment with a variety of tools and will use cloud providers \nMicrosoft, Google and Amazon in its pilot programs. ''We cannot do this alone,'' he said. ''We need to work with the \nprivate sector on helping define what is responsible use of a generative A.I..''\nhttps://www.nytimes.com/2024/03/18/business/homeland-security-artificial-intelligence.html\nGraphic\n \nThis article appeared in print on page B2.               \nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Dan Loeb Enters the Chip Wars; DealBook Newsletter",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1891 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Dan Loeb Enters the Chip Wars; DealBook Newsletter\nThe New York Times \nMarch 18, 2024 Monday 16:57 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1891 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The hedge fund mogul has been bankrolling a European patent fight against Intel, Dell, Amazon and \nother tech giants.\nBody\nThe hedge fund mogul has been bankrolling a European patent fight against Intel, Dell, Amazon and other tech \ngiants. \nA different kind of battle for Third Point\nA small computer chip design company, R2 Semiconductor, has been notching wins in a potentially big patent fight \nagainst Intel over the past few months — a dispute that could force Intel to stop selling several chip lines in Europe.\nBehind R2’s legal war is one of the biggest names in hedge funds, DealBook is first to report: Dan Loeb’s activist \nhedge fund Third Point, the company’s majority owner, is bankrolling the lawsuits, including two new ones against \nAmazon Web Services and Fujitsu that haven’t been previously reported.\nThe context: R2 sued Intel, as well as two customers, Hewlett Packard Enterprise and Dell, in Germany, alleging \nthat the chipmaker had infringed on a patent dealing with voltage regulation in semiconductors. (Intel is \nindemnifying H.P.E. and Dell.)\nA regional court in February issued injunctions against the sale of at least some Intel chips. And on March 8, a \nhigher court rejected Intel’s effort to halt the decision. Meanwhile, a trial in Britain over the patent is set to begin \nnext month.\nIntel says that the R2 patent applies to older generations of its chips. But R2 and Third Point told DealBook that it \nmay also apply to the current generation of Intel chips.\nDan Loeb Enters the Chip Wars DealBook Newsletter\nThird Point has made the fight possible. The firm first invested in R2 15 years ago, eventually amassing a 75 \npercent stake. Not only has it been paying for R2’s legal costs, but it also plans to put up the $79 million required to \nbe held in escrow while the court fights in Germany continue.\nLoeb’s firm could make a windfall if R2 wins royalty payments from Intel. But the financier told DealBook that he’s \nalso trying to help Dave Fisher, R2’s founder: He compared R2 to companies like Arm that earn royalties for their \ncutting-edge designs. “That opportunity was taken from Dave,” Loeb said. “We plan to correct that.”\nIntel isn’t giving up. It has dismissed R2 as “a shell company whose only business is litigation,” and noted that a \ndifferent R2 patent was invalidated in the U.S.\nLoeb told DealBook: “You wouldn’t be a very good patent troll if you spent 15 years of your life developing a patent, \ngiving up weekends, working day and night to develop something, in the hopes that it would be stolen, and then \nthink you’re going to go litigate it.”\nIntel, Dell and Fujitsu didn’t respond to requests for comment. Amazon Web Services and H.P.E. declined to \ncomment.\nWhat next? Germany’s patent court will make a final decision on the validity of R2’s claim in October. A victory \nthere could lead to a ban on affected Intel chips in Germany — just as the chipmaker is in the process of spending \nabout $33 billion to build a new plant there.\nR2 and Third Point also suggested that they may pursue claims in the 38 other members of the European Patent \nConvention.\nHERE’S WHAT’S HAPPENING \nApple is said to be in talks to team up with Google on artificial intelligence. The two are discussing a licensing deal \nthat would mean Google’s Gemini models power new features on the iPhone, according to Bloomberg; the two \nalready have a lucrative search deal. In other A.I. news: Elon Musk’s xAI released the raw computer code behind its \nGrok chatbot; and the Department for Homeland Security is the first federal agency to incorporate generative A.I. \nacross a range of divisions through partnerships with OpenAI, Anthropic and Meta.\nChina reports better-than-expected manufacturing growth. Beijing said on Monday that industrial output rose 7 \npercent in January and February from the same time a year ago. Analysts said the data suggested that the \ncountry’s struggling economy was stabilizing, even as consumer demand remains weak, as the government tries to \nhit an ambitious 5 percent annual growth target.\nIt’s a big week for central banks. The Bank of Japan, the Fed and the Bank of England are set to make interest-rate \npolicy decisions. The drama will start in Tokyo on Tuesday, as investors speculate that the B.O.J. will raise rates for \nthe first time since 2007. The Fed, meanwhile, is expected to keep rates flat on Wednesday but offer clues on \nwhether a June cut is in the cards.\nWhy Europe isn’t following the U.S. on TikTok \nThe backers and opponents of a bill that could ban TikTok in the U.S. have been out in force, making their cases \nahead of a potential Senate vote. One thing that’s missing: any hint that America’s allies are going to follow suit, \nnotably in Europe, which has historically come down hard on Big Tech.\nThe gap shows that many don’t think TikTok or China poses a similar threat, and also reveals a more expansive \nview of regulating social media that could worry the app’s U.S. rivals.\nSeveral countries have introduced limited TikTok bans. The European Union and others have prohibited state \nworkers from using the app on government devices. Canada said last week that it had started a national security \nreview into TikTok’s expansion plans there. But the governments haven’t typically told the public to avoid it.\nDan Loeb Enters the Chip Wars DealBook Newsletter\nEurope doesn’t see TikTok as much of a security threat. That means there’s less political will to rein it in, said Max \nSchrems, an Austrian lawyer who has hounded U.S. social networks on their handling of user data. One reason: the \napp’s relatively small reach. The vast majority of user data flows to American tech companies, he said. “TikTok is \nreally pretty much for teenagers, and that’s about it,” Schrems told DealBook, saying Europeans are more likely to \nuse WhatsApp or Instagram.\nE.U. data-protection and market rules cover the gamut of social media rather than individual apps. Regulators are \nalready using them: Last month, the bloc opened an investigation centered on TikTok’s addictive algorithm. “There \nare certainly things setting TikTok apart from others, but still, many of the risks being discussed about TikTok apply \nto other platforms as well,” Julian Jaursch, a tech policy expert at the think tank Stiftung Neue Verantwortung, told \nDealBook. (Some in the U.S. are pushing for a similarly broad approach.)\nEurope is also split on China — a far cry from Washington, where there’s bipartisan consensus that China is a \nthreat. E.U. countries with strong trade links to China are keen to maintain ties. “This makes it very difficult for \nBrussels to reach the consensus needed to take tough measures singling out either China itself or leading Chinese \ncompanies,” Max von Thun of the Open Markets Institute, a competition policy think tank, told DealBook.\nIf the bill becomes law, that may change.\nInside Trump’s fund-raising rush\nDonald Trump is ahead of President Biden in many polls, but he’s badly behind in cash. The Biden campaign \ndisclosed on Sunday that it had $155 million in cash on hand, dwarfing what the Trump camp and the Republican \nNational Committee probably have.\nThat has added urgency to the former president’s fund-raising efforts, The Times reports, including courting deep-\npocketed backers.\nTrump’s legal fights are weighing on his campaign. He has been tapping his campaign to fund his defense in a half-\ndozen battles in federal and state courts. The costs are rising: He recently posted a $91.6 million bond in the E. \nJean Carroll defamation case, and must post a $450 million bond in the New York civil fraud case against his \nbusinesses.\nIn a sign of the campaign’s financial straits, at least two donors who made seven-figure pledges to Trump have \nbeen asked for millions more.\nThe former president is hitting up potential donors, including at private dinners at Mar-a-Lago in Florida. He has \nalso created a new joint fund-raising account with the R.N.C. (which is now co-led by his daughter-in-law) and state \nparties to raise significant sums.\nOne potential point of leverage: The 2017 tax cuts that he signed into law are set to expire in 2025, and Biden has \nsaid he won’t extend them for the nation’s highest earners.\nThose whom he has talked to recently include: Larry Ellison, the Oracle co-founder; Pepe Fanjul, the sugar \nmagnate; John Paulson, the hedge fund manager; Steve Wynn, the casino mogul; Woody Johnson, the owner of \nthe New York Jets; Jeff Yass, a billionaire investor in TikTok’s parent company; and Elon Musk (though he has said \nhe won’t give to either Biden or Trump).\n• In other election news: Robert Kennedy Jr. is likely to pick Nicole Shanahan, an entrepreneur who paid for a \nSuper Bowl ad promoting his independent presidential run (and the ex-wife of the Google co-founder \nSergey Brin) as his running mate. And Trump economic advisers have reportedly presented him with three \ncandidates for Fed chair: Kevin Warsh, Kevin Hassett and Arthur Laffer.\nYour thoughts on “capital requirements” \nDan Loeb Enters the Chip Wars DealBook Newsletter\nIn response to Andrew’s question last week, DealBook readers had plenty to say about the debate over whether \nincreasing banks’ capital requirements could avert the next crisis. Here’s a sample of the responses:\n• Sanford M. Brown, a financial services lawyer, is concerned that higher capital requirements could affect \nrecruitment: “As banking becomes less attractive to investors, it will become less attractive to employees, \nand I’m not sure we want one of the most important drivers of the American economy to be less attractive \nto the best and brightest that our country has to offer.”\n• Carter Dougherty, the communications director at Americans for Financial Reform (and a former reporter for \nThe Times), has fewer qualms about that: “With executive compensation linked to bank share prices, you \nrealize the incredibly self-interested case that the bank lobby makes against more equity/capital: it lowers \nbanker compensation.”\n• Chris Kotowski, a Wall Street analyst, says the debate elides important nuances: “You need to look at dozens \nof different ratios and exposures to get a handle on asset quality, liquidity and market risk, but capital boils \ndown to a single number, and that is why both politicians and regulators always like to pull the ‘C’ lever. \nThey can say, ‘Hey, it used to be 6% now it’s 12%. See, we’ve done something.’”\nTHE SPEED READ \nDeals\n• Joann, the embattled arts-and-crafts retailer, filed for bankruptcy protection; the chain will be owned by its \ncreditors after reorganizing its debt. (Bloomberg)\n• As Nelson Peltz presses his activist campaign against Disney, his investment firm has reportedly suffered \nfrom investors’ withdrawal requests and tension over the growing role of his son Matt. (NYT, WSJ)\nPolicy\n• Jared Kushner’s plan to invest in developments in Serbia and Albania follows earlier interest in the region by \nhis father-in-law, the presidential candidate Donald Trump. (NYT)\n• The White House is preparing to crack down sharply on auto emissions, in part to help bolster sales of electric \nvehicles. (Bloomberg)\nBest of the rest\n• “ESPN Boss Jimmy Pitaro’s Chaotic Race to Remake the Sports Giant” (WSJ)\n• Abu Dhabi’s latest efforts to become a global hub for finance include promising admissions for traders’ \nchildren to top-rated schools and helping hedge fund executives get into elite country clubs. (Bloomberg)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Dan Loeb is best known for taking on corporate boards, but the hedge fund mogul is now deep in a patent \nfight against Intel. (PHOTOGRAPH BY Brendan McDermid/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Realtors’ Big Defeat",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "BRIEFING",
        "length": "1847 words",
        "byline": "David Leonhardt David Leonhardt runs The Morning, The Times&amp;#8217;s flagship daily newsletter.",
        "story_text": "The Realtors’ Big Defeat\nThe New York Times \nMarch 18, 2024 Monday 06:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BRIEFING\nLength: 1847 words\nByline: David Leonhardt David Leonhardt runs The Morning, The Times&amp;#8217;s flagship daily newsletter. \nSince joining The Times in 1999, he has been an economics columnist, opinion columnist, head of the Washington \nbureau and founding editor of the Upshot section, among other roles.\nHighlight: A settlement in the real estate industry is a case study of a central flaw in free-market economic theory.\nBody\nA settlement in the real estate industry is a case study of a central flaw in free-market economic theory. \nFree-market economic theory suggests that the American real estate market should not have been able to exist as \nit has for decades.\nAmericans have long paid unusually high commissions to real estate agents. The typical commission in the U.S. \nhas been almost 6 percent, compared with 4.5 percent in Germany, 2.5 percent in Australia and 1.3 percent in \nBritain. As a recent headline in The Wall Street Journal put it, “Almost no one pays a 6 percent real-estate \ncommission — except Americans.”\nIf housing operated as an efficient economic market should, competition would have solved this problem. Some real \nestate brokers, recognizing the chance to win business by charging lower commissions, would have done so. Other \nbrokers would have had to reduce their own commissions or lose customers. Eventually, commissions would have \nsettled in a reasonable place, high enough for agents to make a profit but in line with the rest of the world.\nThat didn’t happen. Instead, an average home sale in the U.S. has cost between $5,000 and $15,000 more than it \nwould have without the inflated commissions. This money has been akin to a tax, collected by real estate agents \ninstead of the government.\nThe situation finally seems to be ending, though. On Friday, the National Association of Realtors, the industry group \nthat has enforced the rules that led to the 6 percent commission, agreed to change its behavior as part of an \nagreement to settle several lawsuits.\nThe settlement is important in its own right. Americans now spend about $100 billion a year on commissions. That \nnumber will probably decline by between $20 billion and $50 billion, Steve Brobeck, the former head of the \nConsumer Federation of America, told my colleague Debra Kamin.\nThere is also a broader significance to the settlement. It’s a case study of a central flaw in free-market economic \ntheory. That theory suggests that capitalist competition can almost always protect consumers from businesses that \ncharge too much.\nTo be clear, competition is indeed a powerful force that frequently makes both consumers and businesses better \noff. That’s why capitalist economies have such a better record than communist or socialist economies. Just look at \nSouth Korea and North Korea. (Are you familiar with the satellite images that compare the two Koreas at night?) Or \nconsider the recent economic struggles of Venezuela.\nThe Realtors’ Big Defeat\nMarket competition, however, isn’t the panacea that free-market advocates claim. Sometimes, businesses can \namass enough economic power to squash competition — as real estate brokers did.\nPower meets power\nDecades ago, the National Association of Realtors set the standard commission at 6 percent, to be split between an \nagent representing the seller and an agent representing the buyer. If a home seller tried to negotiate, an agent \nwould often issue a veiled threat: You won’t find a good seller’s agent to work with you, and buyers’ agents won’t \nshow your house to clients.\nJoanne Cleaver, for instance, tried to negotiate with agents when selling her house last year in Mint Hill, N.C., a \nsuburb of Charlotte. “They laughed at me,” Cleaver told The Times.\nThe Realtors’ hardball tactics succeeded because they operate much of the network that’s crucial to the housing \nmarket, such as the database of listings. They could keep out agents who would have competed on price.\nThe solution to this concentration of economic power often requires political power — namely, antitrust enforcement \nby the government. After years of refusing to change their tactics, the Realtors’ agreed to a settlement now because \nthey were vulnerable to government action.\nA turning point was a federal trial last year in Kansas City. The jury found that the Realtors’ association and several \nlarge members had conspired to keep commissions high and ordered them to pay at least $1.8 billion to home \nsellers in the Midwest. The verdict quickly led to more than a dozen other lawsuits. The Justice Department has \nalso been investigating the Realtors.\nThe new trustbusters\nThat investigation is part of Washington’s new focus on the problems with concentrated economic power.\nSince the 1980s, antitrust enforcement has been unfashionable in the U.S. Free-market economic theory has been \nascendant instead. But the results of this laissez-faire era have been disappointing for most Americans. Businesses \nhave grown larger, and corporate profits have surged. Incomes and wealth for most Americans have grown only \nslowly.\nIn response, both liberals and conservatives have recently shown an interest in antitrust (as I described in a recent \nnewsletter). The Biden administration has embarked on a competition agenda to reduce credit card fees, drug \nprices and more. The administration has become more aggressive about challenging mergers, too. Some \nRepublicans also worry that big business has become too powerful.\nThis new movement remains in its early stages, and it’s too soon to know how successful it will be. But the real \nestate settlement looks like the movement’s biggest victory yet.\nFor more: The Times explains how the process of selling a home may change.\nTHE LATEST NEWS\nRussia\n• Vladimir Putin won another six-year term. The election was the least transparent in recent Russian history.\n• Before he died, the opposition leader Aleksei Navalny called on his supporters to go to the polls at midday \nyesterday to protest. Many did.\n• Putin spoke about Navalny publicly for the first time since his death, which Putin described as an “unfortunate \nincident.”\n• Many Russians support Putin, but it’s not clear what they would do if they had real alternatives. Read Paul \nSonne’s analysis.\nThe Realtors’ Big Defeat\n• Here are other takeaways from the vote.\nIsrael-Hamas War\n• Israel said it was conducting a military operation in Gaza’s largest hospital, Al-Shifa, because Hamas had \nreturned there.\n• Benjamin Netanyahu told CNN that Senator Chuck Schumer’s call for elections in Israel after the war was \ninappropriate. “We’re not a banana republic,” Netanyahu said.\nMore International News\n• American sailors and pilots are fighting the Houthis in the Red Sea. See onboard their aircraft carrier, the \nDwight D. Eisenhower.\n• Niger’s junta ordered American troops to leave the country, revoking its military cooperation deal with the U.S.\n• Gambian lawmakers will decide whether to overturn a ban on female genital cutting. Experts said such a \nmove would undo decades of work.\n• In the Philippines, people can make around twice the nation’s minimum wage playing crypto-earning games at \ninternet cafes.\n• In Serbia, Jared Kushner plans to build a luxury hotel and apartment complex. Donald Trump was interested \nin the site more than a decade ago.\nA.I.\n• Elon Musk released the computer code behind his version of an A.I. chatbot, Grok. He has argued that such \nimportant technology shouldn’t be controlled solely by tech giants.\n• Homeland Security will be the first federal agency to incorporate generative A.I. in its work, including to help \ncombat drug and human trafficking.\nEducation\n• School closures did not significantly stop the spread of Covid and caused long-term academic harm for \nchildren, experts say.\n• Migration to New York is affecting school enrollment. A fight over space between two schools highlights the \nproblem.\nOther Big Stories\n• Few smartphones, some beer: In the Hudson Valley, members of the Bruderhof — a 1920s Christian pacifist \nmovement — limit exposure to the outside world.\n• Chicago started to evict some migrants from shelters. Officials said more than 2,000 people would be \nremoved by the end of April.\n• In an interview with The Times, former Justice Stephen Breyer discussed Dobbs, originalism and the decline \nof trust in the court.\nOpinions\nSci-fi-like solutions to climate change, such as blocking the sun, are becoming normalized. Before we trust them, \nwe need to learn more, Jeremy Freeman writes.\nThe army reservist who committed a mass shooting in Maine had brain damage. The U.S. needs to protect its \nsoldiers from injuries to protect its civilians, Daniel S. Johnson writes.\nGail Collins and Bret Stephens discuss TikTok and Mike Pence.\nThe Realtors’ Big Defeat\nHere is a column by David French on Trump Republicans’ about-face over TikTok.\nMORNING READS\nCollection: People recently browsed and bought attire owned by Barbara Walters, the trailblazing TV news anchor.\nRaunchy Christians: A surprising number of evangelicals are rejecting modesty and turning toward the risqué.\nChasing powder: At the Alta resort in Utah, anyone over 80 skis free.\nRelationships: Many young people are tired of dating apps.\nMetropolitan Diary: When the city stopped talking.\nLives Lived: Margaret Grade was a neuropsychologist who made a sharp career pivot and opened a cozy, eclectic \nCalifornia inn that served farmers as well as film stars. She died at 72.\nSPORTS\nMarch Madness: UConn, last year’s champion, was named the No. 1 overall seed in the men’s N.C.A.A. \ntournament. In the women’s bracket, undefeated South Carolina is No. 1.\nWomen’s bracket: Iowa is a No. 1 seed, but experts say it has a particularly tough draw. Caitlin Clark’s squad may \nhave to face L.S.U., which beat her team in last year’s championship, to reach the Final Four.\nGo deeper: The Athletic broke down strengths and weaknesses for all 68 teams in the men’s field and the women’s \nfield.\nJoin our pool: We’ve made groups on ESPN’s Tournament Challenge for readers of The Morning to compete with \none another. Here are links for the men’s and women’s tournaments. The winners will receive a Times-themed \nprize. (After you’ve completed your brackets, let us know with this Google form so we can contact you if you win.)\nARTS AND IDEAS\nBig Irish energy: Irish actors have starred in some of the biggest movies of the past year — including \n“Oppenheimer” and “Saltburn.” In doing so, Paul Mescal, Andrew Scott, Cillian Murphy and Barry Keoghan have \nushered in a moment for Irish crushes. TikTok is now full of videos analyzing why, as one said, “Irish men just hit \ndifferent.” Read more about the internet’s latest infatuation.\nMore on culture\n• Decades ago, two men stole a Vermeer and three Rembrandts in the largest art theft in history. Today, the \nframes still hang empty.\n• Paul Simon, the singer and songwriter, invited a filmmaker to capture the making of his album “Seven \nPsalms.” Simon struggled on camera because he was losing his hearing.\nTHE MORNING RECOMMENDS …\nPan-sear chicken with a garlicky, lemony anchovy sauce.\nScore these deals at REI.\nLimit your exposure to forever chemicals.\nTake our news quiz.\nGAMES\nThe Realtors’ Big Defeat\nHere is today’s Spelling Bee. Yesterday’s pangrams were nonapology and polygonal.\nAnd here are today’s Mini Crossword, Wordle, Sudoku and Connections.\nThanks for spending part of your morning with The Times. See you tomorrow. — David\nP.S. On the inaugural episode of the podcast “The Liberal Patriot with Ruy Teixeira,” David Leonhardt talked about \nthe 2024 campaign and more.\nSign up here to get this newsletter in your inbox. Reach our team at themorning@nytimes.com.\nPHOTO:  (PHOTOGRAPH BY Tony Cenicola/The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Blinken Warns of Disinformation Threat to Democracies",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "WORLD; asia",
        "length": "819 words",
        "byline": "Michael Crowley Michael Crowley covers the State Department and U.S. foreign policy for The Times. He",
        "story_text": "Blinken Warns of Disinformation Threat to Democracies\nThe New York Times \nMarch 18, 2024 Monday 23:00 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: WORLD; asia\nLength: 819 words\nByline: Michael Crowley Michael Crowley covers the State Department and U.S. foreign policy for The Times. He \nhas reported from nearly three dozen countries and often travels with the secretary of state.\nHighlight: At an international forum, the secretary of state said artificial intelligence’s ability to disrupt the global \nflow of information could prove politically perilous during a year of elections.\nBody\nAt an international forum, the secretary of state said artificial intelligence’s ability to disrupt the global flow of \ninformation could prove politically perilous during a year of elections.\nSecretary of State Antony J. Blinken warned on Monday that a malicious “flood” of disinformation was threatening \nthe world’s democracies, fueled in part by the swift rise of artificial intelligence, which he says sows “suspicion, \ncynicism and instability” around the globe.\nMr. Blinken spoke in Seoul at the Summit for Democracy, a global gathering organized by the Biden administration, \nwhich has made countering the authoritarian models of nations like Russia and China a top priority.\nMr. Blinken, who as a young man worked briefly as a journalist, said that changes to the international flow of \ninformation may be “the most profound” that he has experienced in his career, and that anti-democratic forces were \nexploiting those changes.\n“Our competitors and adversaries are using disinformation to exploit fissures within our democracies,” he said.\nHe noted that countries totaling nearly half of the world’s population, including India, will hold elections this year \nunder the threat of manipulated information. He did not mention the United States’ presidential election in \nNovember, which many analysts say could be influenced by foreign-directed information campaigns like the one \nRussia waged in 2016.\nThe U.S. promotes “digital and media literacy” programs abroad to help news consumers judge the reliability of \ncontent, Mr. Blinken said. But he cautioned that American adversaries were clever about laundering their \npropaganda and disinformation. China, for instance, has purchased cable television providers in Africa and then \nexcluded international news channels from subscription packages, he said.\nAnd increasingly powerful generative A.I. programs, Mr. Blinken said, can “fool even the most sophisticated news \nconsumers.”\nThe State Department has urged social media platforms to take more action, including by clearly labeling A.I.-\ngenerated content. Meta, the parent company of Facebook, announced such a plan last month for content posted \non Facebook and Instagram.\nBlinken Warns of Disinformation Threat to Democracies\nBut experts at the conference said the challenge was enormous. Speaking on the subject later in the day, Oliver \nDowden, the deputy prime minister of Britain, cited the example of an A.I.-generated image of Pope Francis in a \npuffer jacket that drew wide attention last year.\nMr. Dowden said that even though he understood that the image was fake, he retains a mental association between \nthe pope and puffer jackets. Such images “influence your perceptions” subconsciously, he said.\nMr. Blinken spoke days after a new report commissioned by the State Department and released last week warned \nthat artificial intelligence presents the world with “catastrophic risks.” The report said that an A.I. system “capable of \nsuperhuman persuasion” could undermine the democratic process.\nIt also cited an unnamed prominent A.I. researcher’s concern that “the model’s potential persuasive capabilities \ncould ‘break democracy’ if they were ever leveraged in areas such as election interference or voter manipulation.”\nMr. Blinken discussed the threat of commercial spyware, which he said several governments had used to monitor \nand intimidate journalists and political activists. He said that six countries — Finland, Germany, Ireland, Japan, \nPoland and South Korea — were joining a U.S.-led coalition to ensure that commercial spyware “is deployed \nconsistent with universal human rights and basic freedoms.”\nPresident Biden issued an executive order a year ago barring the U.S. government from using commercial spyware, \nthough not similar tools built by U.S. intelligence agencies.\nThis week’s Summit for Democracy is the third installment of a forum started in 2021 by Mr. Biden, who said during \nhis State of the Union address this month that “freedom and democracy are under attack both at home and \noverseas.” The meetings are intended to help other nations promote best civil society practices and defend against \npolitical sabotage.\nMr. Blinken’s visit to Seoul occurred as North Korea conducted its latest test launch of several short-range ballistic \nmissiles. The launches came days after joint U.S.-South Korean military exercises that North Korea denounced as \nprovocative.\nMr. Blinken did not mention the launches in his public remarks, although the State Department condemned them.\nMatthew Miller, a department spokesman, also said in a statement that Mr. Blinken and the South Korean foreign \nminister, Cho Tae-yul, discussed “Pyongyang’s military support for Russia’s war against Ukraine” and North Korea’s \n“increasingly aggressive rhetoric and activities.”\nPHOTO: Secretary of State Antony J. Blinken spoke Monday in Seoul at the Summit for Democracy. \n(PHOTOGRAPH BY ANTHONY WALLACE/AGENCE FRANCE-PRESSE — GETTY IMAGES) This article \nappeared in print on page A4.\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "India's compute infrastructure deficit hinders AI potential: Nvidia executive",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "TECH & INTERNET",
        "length": "462 words",
        "byline": "Annapurna Roy",
        "story_text": "India's compute infrastructure deficit hinders AI potential: Nvidia executive\nThe Economic Times\nMarch 19, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 462 words\nByline: Annapurna Roy\nBody\nIndia has under 2% of the world’s $1 trillion worth of compute infrastructure, which is several times less than \ncountries like the US and China which together have nearly 60%, a top Nvidia executive said on Monday. At the \nsame time, there is an opportunity for India to become the ‘AI (artificial intelligence) factory of the world' as more \nand more infrastructure becomes available in the country.“If we can basically build the infrastructure in accelerated \ncomputing quickly and faster, research will happen, innovation will happen, and more importantly, you will add $1 \ntrillion to the economy,” said Vishal Dhupar, managing director for South Asia at global processing unit (GPU) \nmaking giant Nvidia.Speaking at the Startup Mahakumbh in the national capital, Dhupar highlighted that India \ncontributes only about 2% of the world’s AI research, and that the paucity of compute infrastructure is the key \ndeterminant.“There's a direct correlation to that,” Dhupar said. “Indians who contribute to the research but are not \nbased in India are contributing 12% of AI research, because there's infrastructure available there. \nI think that itself signals why infrastructure is really, really important.”While the US and China each earmark about \n4% of their GDP towards research through infrastructure, India spends only a percent, he noted.The government’s \nrecent announcement regarding the India AI Mission, where it will invest in 10,000 GPUs to make compute more \naccessible, is a ‘great start’, Dhupar said.“But more importantly than that, the Indian business houses have figured \nout that now, computing is not about data centres, but converting data centres into compute units that will produce \nintelligence. In other words, it's becoming factories.”This gives India the opportunity to go from being the ‘back \noffice of the world’ to ‘the office of the world’.Codifying Indic languages and culture in large language models (LLM) \nis also a ‘mammoth opportunity’ for India, Dhupar said.Vision and good research are important for India to fulfil its \nAI ambitions, and for the latter, adequate infrastructure availability is ‘in progress’, Dhupar said, pointing to Nvidia’s \nrecent partnership with data centre company Yotta Data Services to bring 16,000 GPUs to India.“We're going to \nalso work with more business houses to bring it (compute infrastructure) here and cater for the sensitivities of this \ncountry, helping you to innovate and build here so that you can maximise the disruption that is needed in our \ncountry and hopefully add the trillion dollars,” he added.Dhupar said that the Nvidia Inception programme for \nstartups has over 1,600 Indian startups in its fold, of which over 400 are AI startups and 60 are generative AI \nstartups. For Reprint Rights: timescontent.com\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Startup Mahakumbh: deeptech, data, AI take centrestage on day 2",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "STARTUPS",
        "length": "474 words",
        "byline": " ",
        "story_text": "Startup Mahakumbh: deeptech, data, AI take centrestage on day 2\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 474 words\nBody\nFrom deeptech to digital public infrastructure, from data to artificial intelligence, and the ‘India way’ – the second \nday of the three-day Startup Mahakumbh in the national capital discussed it all.India is possibly the world leader in \nAI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud India, said at the \nevent.“India is leading the world in adoption of generative AI, which is also helping to solve real world problems in \nareas like financial inclusion, health-related problems and agriculture,” Kumar said, adding that Indian companies \nhave bold ambition.For instance, Indian deeptech companies are working on large language models (LLM) for \nIndia, building at a population scale, and these can be exported globally, he added.India is maturing into a large \neconomy at a time when we are becoming data rich, noted Umakanth Soni, chairman of AI Foundry, a venture \nstudio for AI startups. As the foundational technology of AI depends on data, India can develop the ‘India way’ \nrather than the US or China way, by looking at data as an asset, he added.Infosys co-founder and president, \nInfosys Science Foundation, Kris Gopalakrishnan highlighted that India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage for business.“This will \ncompletely transform the way digitisation happens in the country, which I believe is a better way than the way it has \ndeveloped in the west, where you have a few players owning the whole thing – owning the application, owning the \ndata, owning the services,” he said.Gopalakrishnan said that India’s new way of doing things is enabled by the \ngovernment, by philanthropic and non-government organisations creating open-source protocols and code, and \nentrepreneurs who develop applications on top of that.After the success of the Unified Payments Interface (UPI) \nand the Open Network for Digital Commerce (ONDC), India will see DPI like the health stack bringing hospitals and \ninsurers together, and the digital lending platform empowering farmers and eventually MSMEs for near-\ninstantaneous credit access, Gopalakrishnan pointed out.The Government eMarketplace (GeM) will by next month \nenable easy loan access on the GeM Sahay app, which is built on another DPI, the Open Credit Enablement \nNetwork (OCEN), GeM officials said at the event.“The single biggest thing we have on our side is the timing,” said \nZetwerks CEO Amrit Acharya, adding that in a China+1 geopolitical scenario along with the government’s ‘make in \nIndia’ policy, the world, especially markets like the US, are increasingly looking at India.The emotional argument is \nin India’s favour at the moment, and if companies get the economics right, the demand can be infinite, he said. \nFor Reprint Rights: timescontent.com\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "ETtech Explainer: All you wanted to know about Nvidia’s Blackwell AI chip",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "TECH & INTERNET",
        "length": "599 words",
        "byline": "Ajay Rag",
        "story_text": "ETtech Explainer: All you wanted to know about Nvidia’s Blackwell AI chip\nThe Economic Times\nMarch 19, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 599 words\nByline: Ajay Rag\nBody\nNvidia Corporation, the world's largest manufacturer of artificial intelligence (AI) chips, unveiled a new generation of \nsoftware—Blackwell—during its annual GPU technology conference (GTC) in San Jose, California. This is seen as \na significant step to reinforce Nvidia's position as a market leader and the go-to destination for companies \ndeveloping generative AI large language models (LLMs).What is the name of Nvidia's new generation of chips, and \nwhy is it important?The new generation of AI graphics processors is called Blackwell B200 GPU, with the first \nsuperchip named GB200, which pairs two B200 GPUs with a Grace CPU, set to be shipped later this year. Nvidia \nhighlighted that Blackwell chips enable organisations to develop and operate real-time generative AI on trillion-\nparameter large language models while reducing costs and energy consumption by up to 25 times compared to its \npredecessor.What is Blackwell’s predecessor and how powerful is Blackwell compared to it?\nThe previous generation of AI models, including those trained on chips like the H100, was based on Nvidia's \nHopper architecture, which was introduced in 2022. The Blackwell-based processors, such as the GB200, offer a \nsubstantial performance boost, providing 20 petaflops from its 208 billion transistors compared to the 4 petaflops of \nthe H100. This enhanced processing power allows AI companies to train larger and more complex models.How \nmuch does a Blackwell chip cost?Nvidia has not disclosed the pricing for the new GB200 chip or the systems it will \nbe used in. However, the previous-generation H100 chip based on Hopper architecture costs between $25,000 and \n$40,000.Which major companies are interested in adopting Blackwell?Nvidia expects customers like Amazon Web \nServices, Dell Technologies, Google, Meta, Microsoft, OpenAI, Oracle, Tesla, and xAI to integrate Blackwell into \ntheir AI and cloud computing offerings.What are Nvidia executives saying about Blackwell?Jensen Huang, Nvidia's \nfounder and CEO, during the conference, emphasised the transformative potential of generative AI powered by \nBlackwell, calling it the engine for a new industrial revolution. He highlighted Nvidia's collaboration with leading \ncompanies to leverage AI's potential across industries.What other offerings did Nvidia announce alongside \nBlackwell?Nvidia also introduced a new product called NIM (Nvidia Inference Microservice) as part of its Nvidia \nenterprise software subscription. NIM simplifies the use of older Nvidia GPUs for inference tasks, enabling \ncompanies to leverage their existing GPU infrastructure for AI software, including model training and inference.How \nhas Nvidia's growth been impacted by the ChatGPT boom?Nvidia’s shares have surged 240% over the past 12 \nmonths, making it the U.S. stock market's third most valuable company, behind only Microsoft and Apple. It \ndominates the data centre AI chip market, capturing roughly an 80% share last year.Who are Nvidia’s \ncompetitors?Nvidia faces strong competition from rivals like Intel and AMD who introduced new products to the \nmarket last year. In December, Intel unveiled a series of AI chips, including Gaudi3, a GPU intended to compete \nwith Nvidia and AMD's offerings. Also, Intel showcased new Core Ultra processors for Windows laptops and \ncomputers, as well as fifth-generation Xeon server chips, both incorporating neural processing units for more \nefficient AI programme execution. AMD also launched its MI300 data centre GPU accelerator family in December \n2023, further intensifying competition with Nvidia. For Reprint Rights: timescontent.com\nETtech Explainer: All you wanted to know about Nvidia ’s Blackwell AI chip\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Investors Shrug Off Nvidia’s ‘A.I. Woodstock’; DealBook Newsletter",
        "media": "The New York Times",
        "time": "March 19, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1965 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Investors Shrug Off Nvidia’s ‘A.I. Woodstock’; DealBook Newsletter\nThe New York Times \nMarch 19, 2024 Tuesday 08:21 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1965 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The chipmaker unveiled a new high-speed processor at its developer conference to power an “industrial \nrevolution,” but its sky-high valuation is coming under scrutiny.\nBody\nThe chipmaker unveiled a new high-speed processor at its developer conference to power an “industrial revolution,” \nbut its sky-high valuation is coming under scrutiny.\nAre investors buying Nvidia’s latest A.I. vision? \nNvidia’s stock has soared more than fivefold since ChatGPT debuted in November 2022, a rally that has vaulted the \nchipmaker into the trillion-dollar market cap club on the back of investor fervor for artificial intelligence — and the \nhigh-end processors that power these models.\nBut shares in Nvidia are down in premarket trading on Tuesday after investors gave the first day of the company’s \nannual developer conference (known as “A.I. Woodstock”) a tough grade. That’s even after the semiconductor \ncompany introduced its latest chip, which is capable of running increasingly complex computing models.\nBig money is expected to continue flowing into A.I. Nvidia and its peers (and their shareholders) have been the first \nto profit from this investment shift. But during a two-hour keynote speech on Monday, Jensen Huang, Nvidia’s \nC.E.O., painted a vision of A.I. turbocharging computing power, leading to a boom in robotics, autonomous \ntransport, concierge-style retail and drugs discovery.\nThe new chip, Blackwell, will be “the engine to power this new industrial revolution,” he said. To underscore that, \nNvidia recruited more than 100 customers — including from Amazon and the U.S. Army — to show off how they’re \nusing the company’s hardware in their businesses.\nInvestors Shrug Off Nvidia’s ‘A.I. Woodstock’ DealBook Newsletter\n“One hundred trillion dollars of the world’s industries are represented in this room today,” Huang said to cheers from \nthe packed SAP Center in San Jose, Calif. (Huang said that the event was no rock concert, before making a joking \nreference to Taylor Swift, who has performed there.)\nOne big new customer is the Novo Nordisk Foundation, a top shareholder in the highly profitable Ozempic weight-\nloss drugmaker. The foundation and the Export and Investment Fund of Denmark announced that they would invest \nabout $100 million in a new supercomputer powered by Nvidia chips and software.\nMads Krogsgaard Thomsen, the foundation’s C.E.O., told DealBook that the computer would be the most powerful \nof its kind in Europe, and would tackle “some of the world’s biggest challenges” in health care, climate science and \nthe green transition.\nThat may include drug discovery: While it took researchers over a decade to come up with the class of drugs that \nincludes Novo Nordisk’s Ozempic and Wegovy, advanced technology could take years off that process, Thomsen \nsaid. “The performance of generative A.I. is lifting the whole pharmaceutical science to a new level,” he said.\nSome on Wall Street urge caution about the A.I. boom. While many analysts see Nvidia sales growing robustly over \nthe next two years on the strength of demand for its chips, others wonder if its sky-high valuation is justified.\n“Companies with high valuations often struggle to grow into their multiples regardless of realized growth rates,” \nanalysts at Goldman Sachs wrote in an investor note ahead of Monday’s event.\nHERE’S WHAT’S HAPPENING \nUnilever plans to spin off its ice cream unit. The move to separate out the division, which includes the Ben &amp; \nJerry’s brand, is meant to streamline the consumer products giant’s operations and restart growth. It will also entail \ncutting 7,500 jobs. Shares in Unilever were up nearly 4 percent in London trading on the news.\nDisney and Bob Iger win key support in their fight against Nelson Peltz. Glass Lewis, an influential proxy advisory \nfirm, recommended that shareholders back the entertainment company’s slate of director nominees. And the \nfilmmaker George Lucas, Disney’s biggest individual shareholder, also said that he was voting for Iger and the \ncompany’s other nominees.\nJustice Department officials will reportedly brief senators on TikTok. The closed-door sessions, scheduled for \nTuesday and Wednesday according to Bloomberg, come as some lawmakers try to force the video app to separate \nfrom its Chinese parent, ByteDance. Lisa Monaco, the deputy attorney general, backs the legislation, citing national \nsecurity concerns.\nThe Supreme Court appears wary of limiting government contact with social media platforms. Justices questioned \narguments by Louisiana and Missouri that federal efforts to persuade tech companies not to publish information \n(without the use of coercion) represent an infringement of the First Amendment. The states and five individuals \nsued after Biden administration officials urged platforms to take down content related to coronavirus vaccines and \nelection fraud.\nThe Trump business empire is at risk \nDonald Trump has been busy courting potential donors (perhaps including people who had been critics like the \nfinancier Nelson Peltz) to refill his campaign coffers, and Monday helped show why: His lawyers said in a court filing \nthat he hadn’t been able to secure a $454 million bond for a civil fraud case in New York.\nThe former president still has options, including help from wealthy supporters or a favorable decision from an \nappeals court. But otherwise, he risks losing prized assets — or having to take longshot moves like seeking \nbankruptcy protection.\nInvestors Shrug Off Nvidia’s ‘A.I. Woodstock’ DealBook Newsletter\nNo one appears willing to provide an appellate bond of that size, Trump’s lawyers disclosed. They said that they \nhad reached out to 30 companies, including Chubb and Warren Buffett’s Berkshire Hathaway, but none were willing \nto accept property as collateral.\nThat’s an issue because while Trump boasts of being a billionaire, a vast majority of his wealth is tied up in real \nestate holdings. He has already probably pledged over $100 million in liquid assets, like cash and easy-to-sell \nsecurities, to cover a bond in a defamation case against E. Jean Carroll.\nThe clock is ticking. Attorney General Letitia James of New York has set March 25 as the deadline for Trump to \npost a bond. She could give him more time, or an appeals court could intervene.\nIf neither happens, James could start seizing Trump’s bank accounts or, in a bigger blow to his identity, some of his \nproperties. Among the most likely targets is Trump Tower, the building most closely associated with his public \nimage. (That said, The Wall Street Journal notes that the process of seizing the real estate would not be \nimmediate.)\nThere’s also a nuclear option, according to The Times: putting some of the Trump company’s entities into Chapter \n11, which would automatically halt the judgment against them.\nBut Trump, who lived through a painful bankruptcy case in the 1990s, would most likely balk at that. And a \nbankruptcy filing could trigger defaults in his companies’ loans, setting off more litigation.\nJapan Inc. gets a boost of confidence \nThe Bank of Japan ended eight years of negative interest rates this morning. Markets barely moved on the well-\nflagged decision. But it’s a symbolically important policy change nonetheless, and reflects changes to the Japanese \neconomy.\nThe bank lifted its prime lending rate to between 0 and 0.1 percent, up from minus 0.1 percent and its first increase \nsince 2007. It also reversed other global financial crisis-era policies that include: abandoning its yield curve control, \nwhich it has used to cap the yield on 10-year government bonds at no more than 1 percent; and it will no longer buy \nexchange-traded funds.\nJapan has been on a roll as investors worried about China look elsewhere. The Nikkei 225 stock index hit a record \nhigh last month, surpassing a level it last reached in 1989. And Japanese workers just secured their biggest pay \nrise in more than 30 years, suggesting that the bank is confident it has turned a corner on deflation.\nBig-name investors like Warren Buffett are bullish. The Berkshire Hathaway chief bet big on Japan during the \ncoronavirus pandemic, investing billions in the country’s five big trading houses, and has doubled down on that \nstrategy. Corporate governance reforms by the Tokyo Stock Exchange also appear to be attracting investors.\nThe latest changes aren’t likely to reverse some big outflows though. The country’s investors have spent about $3 \ntrillion in global bond markets and yen trades as they looked for better returns abroad.\nThe country still faces huge structural challenges. “Japan’s big structural challenges — aging, population decline, \nsluggish consumption, high public debt and low economic growth rates — remain the same,” The Financial Times’s \nRobin Harding notes.\nGensler sets his sights on ‘A.I. washing’ \nGary Gensler, the S.E.C. chairman, has been trying for years to stop companies from using buzz words to mislead \ninvestors, including cracking down on false claims about crypto and on greenwashing, or passing investments off as \nmore environmentally focused than they are. Now, he has a new target: “A.I. washing.”\nThe S.E.C. fined two investment firms for exaggerating their A.I. abilities. The agency said on Monday that Delphia \nand Global Predictions had made “false and misleading statements” about using the tech in their forecasts. The \nInvestors Shrug Off Nvidia’s ‘A.I. Woodstock’ DealBook Newsletter\nfirms settled with the S.E.C. and agreed to pay a total of $400,000 in penalties without admitting or denying the \nfindings.\n“A.I. is the most transformative technology of our time,” Gensler said, adding, that “when new technologies come \nalong, we’ve also seen time and again false claims to investors by those purporting to use those new technologies.”\nCompanies are eager to harness A.I.’s buzz. Money is pouring into A.I. companies, with start-ups raising about $27 \nbillion last year according to PitchBook, and A.I.-related stocks are soaring. More than 40 percent of S&amp;P \ncompanies mentioned the tech in their most recent earnings reports, with growing interest in how organizations are \ndeploying it.\nGensler has been warning against A.I. washing for months. “Don’t do it,” he said in December. “One shouldn’t \ngreenwash, and one shouldn’t AI wash.” The S.E.C. issued an alert to investors about A.I. fraud in January.\nThe fines could be just the start of a wider clampdown. “Today’s enforcement actions should serve notice to the \ninvestment industry,” Gurbir Grewal, the S.E.C.’s enforcement chief, said on Monday. He also said that the agency \nwas looking into other ways companies may be abusing A.I., including to manipulate markets.\nTHE SPEED READ \nDeals\n• Abu Dhabi has reportedly offered to buy out U.S. investors’ stakes in funds managed by the Hong Kong-\nbased private equity firm PAG, as Gulf funds look to capitalize from Western financiers pulling back from \nChina. (FT)\n• Selena Gomez is said to be weighing the sale of her cosmetics company, which has been valued at $2 billion. \n(Bloomberg)\nRevolving door\n• Stephanie Cohen, one of the most senior executives at Goldman Sachs, is reportedly leaving the Wall Street \nbank to become chief strategy officer at Cloudflare, a cloud services provider. (WSJ)\n• Chris Lehane, a member of the Clinton White House and a former policy chief at Airbnb, is reportedly near a \ndeal to join OpenAI in a senior role. (The Information)\nBest of the rest\n• The insurer UnitedHealth Group said it had paid out more than $2 billion to help health care companies \naffected by a cyberattack at one of its subsidiaries. (CNBC)\n• More than $2.7 billion worth of legal bets on basketball are expected during March Madness, according to \nestimates, as the sports betting industry continues to grow. (Axios)\n• An award named after Ruth Bader Ginsburg has been called off after the former Supreme Court justice’s \nfamily objected to this year’s winners, who include Elon Musk and Rupert Murdoch. (WaPo)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Jensen Huang, Nvidia’s C.E.O., unveiled the company’s latest A.I. chip yesterday as it hopes to build on \nits dominance in the sector. (PHOTOGRAPH BY Justin Sullivan/Getty Images FOR THE NEW YORK TIMES)\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In Latest A.I. War Escalation, Elon Musk Releases Chatbot Code",
        "media": "The New York Times",
        "time": "March 19, 2024",
        "section": "TECHNOLOGY",
        "length": "775 words",
        "byline": "Kate Conger and Cade Metz Kate Conger is a technology reporter based in San Francisco. She can be",
        "story_text": "In Latest A.I. War Escalation, Elon Musk Releases Chatbot Code\nThe New York Times \nMarch 17, 2024 Sunday 00:03 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 775 words\nByline: Kate Conger and Cade Metz Kate Conger is a technology reporter based in San Francisco. She can be \nreached at , kate.conger@nytimes.com,  Cade Metz writes about artificial intelligence, driverless cars, robotics, \nvirtual reality and other emerging areas of technology.\nHighlight: Mr. Musk’s move to open up the code behind Grok is the latest volley in a war to win the A.I. battle, after \na suit against OpenAI on the same topic.\nBody\nMr. Musk’s move to open up the code behind Grok is the latest volley in a war to win the A.I. battle, after a suit \nagainst OpenAI on the same topic.\nElon Musk released the raw computer code behind his version of an artificial intelligence chatbot on Sunday, an \nescalation by one of the world’s richest men in a battle to control the future of A.I.\nGrok, which is designed to give snarky replies styled after the science-fiction novel “The Hitchhiker’s Guide to the \nGalaxy,” is a product from xAI, the company Mr. Musk founded last year. While xAI is an independent entity from X, \nits technology has been integrated into the social media platform and is trained on users’ posts. Users who \nsubscribe to X’s premium features can ask Grok questions and receive responses.\nBy opening the code up for everyone to view and use — known as open sourcing — Mr. Musk waded further into a \nheated debate in the A.I. world over whether doing so could help make the technology safer, or simply open it up to \nmisuse.\nMr. Musk, a self-proclaimed proponent of open sourcing, did the same with X’s recommendation algorithm last year, \nbut he has not updated it since.\n“Still work to do, but this platform is already by far the most transparent &amp; truth-seeking (not a high bar tbh),” \nMr. Musk posted on Sunday in response to a comment on open sourcing X’s recommendation algorithm. \nThe move to open-source chatbot code is the latest volley between Mr. Musk and ChatGPT’s creator, OpenAI, \nwhich the mercurial billionaire sued recently over breaking its promise to do the same. Mr. Musk, who was a \nfounder and helped fund OpenAI before departing several years later, has argued such an important technology \nshould not be controlled solely by tech giants like Google and Microsoft, which is a close partner of OpenAI.\nOpenAI has said it will seek to dismiss the suit.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nThe controversy over open sourcing generative A.I. — which can create realistic images and videos and recreate \nhumanlike text responses — has roiled the tech world over the past year after the explosion in the popularity of the \ntechnology. Silicon Valley is deeply divided over whether the coding underlying A.I. should be publicly available, \nIn Latest A.I. War Escalation, Elon Musk Releases Chatbot Code\nwith some engineers arguing that the powerful technology must be guarded against interlopers while others insist \nthat the benefits of transparency outweigh the harms.\nBy publishing his A.I. code, Mr. Musk planted himself firmly in the latter camp, a decision that could enable him to \nleapfrog competitors who have had a head start in developing the technology.\nThe publication of the code will allow other companies and independent software developers to modify and reuse it \nas they build their own chatbots and other A.I. systems. Meta, the parent company of both Facebook and \nInstagram, has also open sourced its A.I. technology, called LLaMA. Google and a prominent French start-up, \nMistral, have also done some open sourcing.\nLast year, Mr. Musk — who also owns X and SpaceX, and is chief executive officer of Tesla — formed xAI, stating \nits mission was to “understand reality.” In November, he said investors in his $44 billion take-private deal for X \nwould own a 25 percent stake in xAI.\nMr. Musk has said that no topic should be off-limits for chatbots, criticizing companies that steer their technology to \navoid controversy as “woke.”\n“If an AI is programmed to push for diversity at all costs, as Google Gemini was, then it will do whatever it can to \ncause that outcome, potentially even killing people,” Mr. Musk said in a post on Friday.\nBut at least some of the posturing around open sourcing is closely tied to business interests. Because OpenAI is \nthe market leader, offering the most powerful and arguably the most popular chatbot, it has little reason to open \nsource its code.\nMr. Musk and xAI, on the other hand, are working to catch up and could help level the playing field by open \nsourcing their code and inviting others to improve the technology.\nSubbarao Kambhampati, a professor of computer science at Arizona State University, has argued that open \nsourcing today’s A.I. technology is the safest approach. But he added that companies like xAI and Meta were not \nnecessarily open-sourcing the technology for that reason.\n“Elon Musk and Yann LeCun are not the best messengers for this argument,” he said, referencing Meta’s chief A.I. \nscientist.\nPHOTO: Premium subscribers on X can ask Grok, an A.I.-powered chatbot, questions and receive responses. \n(PHOTOGRAPH BY DADO RUVIC/REUTERS) This article appeared in print on page B1, B3.\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Cognizant, Nvidia tap generative AI to boost drug discoveries",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "TECH & INTERNET",
        "length": "553 words",
        "byline": "Beena Parmar",
        "story_text": "Cognizant, Nvidia tap generative AI to boost drug discoveries\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 553 words\nByline: Beena Parmar\nBody\nGlobal IT services and consulting major Cognizant is tapping generative AI (gen AI) technology along with the \nNvidia BioNeMo platform to help improve productivity of drug discoveries and speed up its market reach pushing \ngrowth in its health sciences vertical.“By leveraging gen AI technologies, clinical researchers can rapidly sift \nthrough extensive datasets, more accurately predict interactions between drug compounds and create new, viable \ndrug development pathways,” Cognizant said in a statement.Amid high costs, long development cycles and high \nrate of failure, traditional drug discovery methodologies in the life sciences industry are process intensive and \nrequire the analysis of vast repositories of scientific literature and clinical data for relevant insights.\"More than any \nother technological breakthrough in recent decades, generative AI has the potential to revolutionize the way new \ndrugs are researched, developed and brought to market, making the creation of lifesaving discoveries faster, \nsmarter and more accessible to all,\" said Anna Elango, EVP, Cognizant's Core Technologies & Insights.Cognizant \nsaid it aims to give clients access to a suite of model-making services, including pretrained models, cutting-edge \nframeworks, and APIs, that offers clients the quickest path to train and customize enterprise models using their \nproprietary data. The offering is intended to enable this with reduced manual intervention for data analysis, and \nwithout the need to write elaborate code and build or maintain infrastructure.\"Generative AI will drive the next wave \nof enterprise productivity gains across industries, enabled by the Nvidia AI Enterprise software platform. \nUsing Nvidia BioNeMo, Cognizant will help provide its life sciences clients with advanced, secure and reliable AI \nservices to drive improved outcomes with custom drug discovery applications,\" said Alvin DaCosta, VP, Global \nConsulting Partner Organization, Nvidia.The US headquartered firm counts health sciences as its largest vertical, \nwhich surpassed BFSI (banking, financial services and insurance) with revenue at $1,396 million for the quarter \neven as the growth dipped by 2.1% year-on-year (YoY) and 2.7% on a constant currency (CC) basis while BFSI \ndecelerated by 5.8% YoY and 6.6% CC terms. Cognizant reported a 1.7% drop YoY and 2.4% in CC in total \nrevenues at $4,758 million for the October to December period. Cognizant is also understood to have hired Mohd \nHaque from Wipro, where he headed the healthcare services vertical, for which there is an ongoing legal \nemployment case.Cognizant's life sciences offerings support more than 120 global manufacturing lines and more \nthan 18 million patients with medical device company products, the firm said.Beyond healthcare, Cognizant further \nintends to pursue additional applications with Nvidia in manufacturing and automotive engineering, where gen AI \nhas the potential to enhance productivity, optimize costs and quicken market innovation.Cognizant intends to \nestablish an Nvidia AI Center of Excellence this year to further innovate with Nvidia technologies, including the \nNvidia Metropolis, Nvidia Omniverse and Nvidia AI Enterprise platforms, for the benefit of clients across industries \naround the world, the company statement added. For Reprint Rights: timescontent.com\nLoad-Date: March 19, 2024\nCognizant, Nvidia tap generative AI to boost drug discoveries"
    },
    {
        "file_name": "Essay_Mar2024",
        "header": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest",
        "media": "Essay",
        "time": "March 19, 2024",
        "section": "OPINION",
        "length": "1145 words",
        "byline": "Graciela Mochkofsky",
        "story_text": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest \nEssay\nThe New York Times \nMarch 18, 2024 Monday 11:58 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1145 words\nByline: Graciela Mochkofsky\nHighlight: We need mission-driven, imaginative news leaders who are not bound by the models of the past.\nBody\nMany uncertainties haunt the field of journalism today — among them, how we can reach our audience, build public \ntrust in our work, and who is going to pay for it all. But one thing is certain: as complicated and dark as the world \nlooks today, it would be much worse if journalists were not there to report on it.\nResearch shows that towns that have lost sources of local news tend to suffer from lower voter turnout, less civic \nengagement and more government corruption. Journalists are essential just as nurses and firefighters and doctors \nare essential.\nAnd to continue to have journalists, we need to make their journalism education free.\nThis might sound counterintuitive given the state of the industry. Shrinking revenue and decreasing subscription \nfigures have led to a record number of newsroom jobs lost. Much of the local news industry has fallen into the \nhands of hedge funds focused on squeezing the last drops of revenue out of operations by decimating them. \nBillionaires who appeared as saviors just a few years ago have grown tired of losing money on the media \norganizations they bought. Public trust in the value of news is at historical lows, while a growing percentage of \npeople are avoiding the news altogether.\nGenerative artificial intelligence, which is on the verge of reshaping almost everything around us, is bringing yet \nanother technological disruption to the industry. Against this grim backdrop, authoritarian leaders are increasingly \ntargeting journalists as political enemies both at home and abroad.\nAnd yet there are still tens of thousands of jobs in news media in America, with exceptional journalism being \nproduced every day. Some major organizations have even found ways to thrive in the digital age. Prominent \nfoundation leaders have started an effort to pour hundreds of millions of philanthropic dollars into local journalism, \nand a movement has formed to push for federal and local legislation to direct public funding to news. An initiative to \nreplant local news has founded dozens of nonprofit newsrooms in cities around the country. And a small but \ngrowing number of organizations are redefining the way news agendas are set, focusing on rebuilding public trust \nwithin small communities.\nNo matter how the news industry evolves, we will continue to need journalists. Successful business models for \nmedia are necessary, but the most crucial element for strong, independent journalism is the people who make it. \nGiven the present stakes in the industry, our society and the world, we need mission-driven, imaginative news \nleaders who are not bound by the models of the past, who have the motivation and freedom to reimagine the field, \nand the empathy and commitment to serve the public interest, undaunted by attacks and threats.\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nWe must also move beyond the lack of economic and demographic diversity that has long been a problem in the \nindustry. News has too often been reported by predominantly middle-class, white, male journalists, resulting in \ncoverage that has repeatedly missed the issues that are most important to the people receiving the news, \ncontributing to the public’s lack of trust in the media.\nIn a resource-starved industry, few newsrooms can offer the type of mentoring, guidance and time that it takes to \nshape a great journalist. This is now primarily the responsibility of journalism schools. It is the civic duty of these \nschools to find and train reporters and news leaders, instill in them an ethical foundation, help develop their critical \nthinking skills, allow them to try and fail in a safe environment, open doors and provide a support network. \n(Journalism schools should also contribute research in a variety of areas, from the impact of A.I. to new business \nmodels to identifying and responding to emerging threats.)\nBut the cost of a journalism education has become an insurmountable barrier for exactly the kind of people we need \nthe most. And those who, with great effort, manage to overcome that barrier, carry a weight that could limit their \nprofessional options.\nReporters burdened with debt are less likely to take professional risks and more likely to abandon the field. \nAccording to the Bureau of Labor Statistics, the median reporter salary in America is less than $56,000 a year, or \nabout $27 per hour. In low-income areas, where news deserts are more prevalent, annual salaries can be as low as \n$20,000. A Wall Street Journal report about the debt-to-income ratio of alumni of 16 journalism masters programs \nfound that many graduates leave with debts that exceed their postgraduate income.\nAs the dean of the Craig Newmark Graduate School of Journalism at the City University of New York, I can tell you \nthat half measures won’t solve this quandary. My school was founded in 2006 as a public alternative to elite \njournalism schools in the city and it remains one of the most affordable in the nation.\nOur in-state students pay about a quarter of the cost of an equivalent degree from top-tier schools with which we \nsuccessfully compete. This year alone, 90 percent of our students are on scholarships, and a record 25 percent are \nattending tuition-free. We also waived the $75 application fee this admission cycle and saw an increase of more \nthan 40 percent in our applicant pool.\nThanks to these policies, we have succeeded where the media industry keeps failing. Over 50 percent of our \nstudents are people of color and from underserved communities. Many couldn’t have attended our school if we \nhadn’t offered significant scholarship support. But that’s not enough. Though we rank as one of the journalism \nschools with higher-medium-income and lower-median-debt alumni, our students still don’t graduate fully debt-free.\nThis is why this year, we began a campaign to go fully tuition-free by 2027. While other schools might face different \nfinancial challenges, we hope that many more will follow us.\nWe need journalists whose only obligations are to the facts and the society they serve, not to lenders; who are \nconcerned with the public interest, not with interest rates; who can make risky decisions and take the difficult path if \nthat’s what the mission requires, free of financial burden. Journalism schools can help achieve that. In tough times, \nit is natural to mourn the past or lament the present, but what we really need is bold action.\nGraciela Mochkofsky is the dean at CUNY’s Craig Newmark Graduate School of Journalism. She is the author, \nmost recently, of “The Prophet of the Andes: An Unlikely Journey to the Promised Land.”\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nPHOTO:  (PHOTOGRAPH BY Pat Thomas FOR THE NEW YORK TIMES)\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Musk Opens A.I. Bot Code To Everyone",
        "media": "The New York Times",
        "time": "March 19, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "752 words",
        "byline": "By Kate Conger and Cade Metz",
        "story_text": "Musk Opens A.I. Bot Code To Everyone\nThe New York Times\nMarch 19, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 752 words\nByline: By Kate Conger and Cade Metz\nBody\nMr. Musk's move to open up the code behind Grok is the latest volley in a war to win the A.I. battle, after a suit \nagainst OpenAI on the same topic.\nElon Musk released the raw computer code behind his version of an artificial intelligence chatbot on Sunday, an \nescalation by one of the world's richest men in a battle to control the future of A.I. \n  Grok, which is designed to give snarky replies styled after the science-fiction novel ''The Hitchhiker's Guide to the \nGalaxy,'' is a product from xAI, the company Mr. Musk founded last year. While xAI is an independent entity from X, \nits technology has been integrated into the social media platform and is trained on users' posts. Users who \nsubscribe to X's premium features can ask Grok questions and receive responses.\n  By opening the code up for everyone to view and use -- known as open sourcing -- Mr. Musk waded further into a \nheated debate in the A.I. world over whether doing so could help make the technology safer, or simply open it up to \nmisuse.\n  Mr. Musk, a self-proclaimed proponent of open sourcing, did the same with X's recommendation algorithm last \nyear, but he has not updated it since.\n  ''Still work to do, but this platform is already by far the most transparent & truth-seeking (not a high bar tbh),'' Mr. \nMusk posted on Sunday in response to a comment on open sourcing X's recommendation algorithm. \n  The move to open-source chatbot code is the latest volley between Mr. Musk and ChatGPT's creator, OpenAI, \nwhich the mercurial billionaire sued recently over breaking its promise to do the same. Mr. Musk, who was a \nfounder and helped fund OpenAI before departing several years later, has argued such an important technology \nshould not be controlled solely by tech giants like Google and Microsoft, which is a close partner of OpenAI.\n  OpenAI has said it will seek to dismiss the suit.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  The controversy over open sourcing generative A.I. -- which can create realistic images and videos and recreate \nhumanlike text responses -- has roiled the tech world over the past year after the explosion in the popularity of the \ntechnology. Silicon Valley is deeply divided over whether the coding underlying A.I. should be publicly available, \nwith some engineers arguing that the powerful technology must be guarded against interlopers while others insist \nthat the benefits of transparency outweigh the harms.\nMusk Opens A.I. Bot Code To Everyone\n  By publishing his A.I. code, Mr. Musk planted himself firmly in the latter camp, a decision that could enable him to \nleapfrog competitors who have had a head start in developing the technology.\n  The publication of the code will allow other companies and independent software developers to modify and reuse \nit as they build their own chatbots and other A.I. systems. Meta, the parent company of both Facebook and \nInstagram, has also open sourced its A.I. technology, called LLaMA. Google and a prominent French start-up, \nMistral, have also done some open sourcing.\n  Last year, Mr. Musk -- who also owns X and SpaceX, and is chief executive officer of Tesla -- formed xAI, stating \nits mission was to ''understand reality.'' In November, he said investors in his $44 billion take-private deal for X \nwould own a 25 percent stake in xAI.\n  Mr. Musk has said that no topic should be off-limits for chatbots, criticizing companies that steer their technology to \navoid controversy as ''woke.''\n  ''If an AI is programmed to push for diversity at all costs, as Google Gemini was, then it will do whatever it can to \ncause that outcome, potentially even killing people,'' Mr. Musk said in a post on Friday.\n  But at least some of the posturing around open sourcing is closely tied to business interests. Because OpenAI is \nthe market leader, offering the most powerful and arguably the most popular chatbot, it has little reason to open \nsource its code.\n  Mr. Musk and xAI, on the other hand, are working to catch up and could help level the playing field by open \nsourcing their code and inviting others to improve the technology.\n  Subbarao Kambhampati, a professor of computer science at Arizona State University, has argued that open \nsourcing today's A.I. technology is the safest approach. But he added that companies like xAI and Meta were not \nnecessarily open-sourcing the technology for that reason.\n  ''Elon Musk and Yann LeCun are not the best messengers for this argument,'' he said, referencing Meta's chief \nA.I. scientist.\nhttps://www.nytimes.com/2024/03/17/technology/chatbot-xai-code-musk.html\nGraphic\n \nPHOTO: Premium subscribers on X can ask Grok, an A.I.-powered chatbot, questions and receive responses. \n(PHOTOGRAPH BY DADO RUVIC/REUTERS) This article appeared in print on page B1, B3.               \nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A 'Flood' of Disinformation Poses a Threat, Blinken Says",
        "media": "The New York Times",
        "time": "March 19, 2024",
        "section": "Section A; Column 0; Foreign Desk; Pg. 4",
        "length": "795 words",
        "byline": "By Michael Crowley",
        "story_text": "A 'Flood' of Disinformation Poses a Threat, Blinken Says\nThe New York Times\nMarch 19, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; Foreign Desk; Pg. 4\nLength: 795 words\nByline: By Michael Crowley\nBody\nAt an international forum, the secretary of state said artificial intelligence's ability to disrupt the global flow of \ninformation could prove politically perilous during a year of elections.\nSecretary of State Antony J. Blinken warned on Monday that a malicious ''flood'' of disinformation was threatening \nthe world's democracies, fueled in part by the swift rise of artificial intelligence, which he says sows ''suspicion, \ncynicism and instability'' around the globe. \n  Mr. Blinken spoke in Seoul at the Summit for Democracy, a global gathering organized by the Biden \nadministration, which has made countering the authoritarian models of nations like Russia and China a top priority.\n  Mr. Blinken, who as a young man worked briefly as a journalist, said that changes to the international flow of \ninformation may be ''the most profound'' that he has experienced in his career, and that anti-democratic forces were \nexploiting those changes.\n  ''Our competitors and adversaries are using disinformation to exploit fissures within our democracies,'' he said.\n  He noted that countries totaling nearly half of the world's population, including India, will hold elections this year \nunder the threat of manipulated information. He did not mention the United States' presidential election in \nNovember, which many analysts say could be influenced by foreign-directed information campaigns like the one \nRussia waged in 2016.\n  The U.S. promotes ''digital and media literacy'' programs abroad to help news consumers judge the reliability of \ncontent, Mr. Blinken said. But he cautioned that American adversaries were clever about laundering their \npropaganda and disinformation. China, for instance, has purchased cable television providers in Africa and then \nexcluded international news channels from subscription packages, he said.\n  And increasingly powerful generative A.I. programs, Mr. Blinken said, can ''fool even the most sophisticated news \nconsumers.''\n  The State Department has urged social media platforms to take more action, including by clearly labeling A.I.-\ngenerated content. Meta, the parent company of Facebook, announced such a plan last month for content posted \non Facebook and Instagram.\n  But experts at the conference said the challenge was enormous. Speaking on the subject later in the day, Oliver \nDowden, the deputy prime minister of Britain, cited the example of an A.I.-generated image of Pope Francis in a \npuffer jacket that drew wide attention last year.\nA 'Flood' of Disinformation Poses a Threat, Blinken Says\n  Mr. Dowden said that even though he understood that the image was fake, he retains a mental association \nbetween the pope and puffer jackets. Such images ''influence your perceptions'' subconsciously, he said.\n  Mr. Blinken spoke days after a new report commissioned by the State Department and released last week warned \nthat artificial intelligence presents the world with ''catastrophic risks.'' The report said that an A.I. system ''capable of \nsuperhuman persuasion'' could undermine the democratic process.\n  It also cited an unnamed prominent A.I. researcher's concern that ''the model's potential persuasive capabilities \ncould 'break democracy' if they were ever leveraged in areas such as election interference or voter manipulation.''\n  Mr. Blinken discussed the threat of commercial spyware, which he said several governments had used to monitor \nand intimidate journalists and political activists. He said that six countries -- Finland, Germany, Ireland, Japan, \nPoland and South Korea -- were joining a U.S.-led coalition to ensure that commercial spyware ''is deployed \nconsistent with universal human rights and basic freedoms.''\n  President Biden issued an executive order a year ago barring the U.S. government from using commercial \nspyware, though not similar tools built by U.S. intelligence agencies.\n  This week's Summit for Democracy is the third installment of a forum started in 2021 by Mr. Biden, who said \nduring his State of the Union address this month that ''freedom and democracy are under attack both at home and \noverseas.'' The meetings are intended to help other nations promote best civil society practices and defend against \npolitical sabotage.\n  Mr. Blinken's visit to Seoul occurred as North Korea conducted its latest test launch of several short-range ballistic \nmissiles. The launches came days after joint U.S.-South Korean military exercises that North Korea denounced as \nprovocative.\n  Mr. Blinken did not mention the launches in his public remarks, although the State Department condemned them.\n  Matthew Miller, a department spokesman, also said in a statement that Mr. Blinken and the South Korean foreign \nminister, Cho Tae-yul, discussed ''Pyongyang's military support for Russia's war against Ukraine'' and North Korea's \n''increasingly aggressive rhetoric and activities.''\nhttps://www.nytimes.com/2024/03/18/world/asia/blinken-artificial-intelligence-threat.html\nGraphic\n \nPHOTO: Secretary of State Antony J. Blinken spoke Monday in Seoul at the Summit for Democracy. \n(PHOTOGRAPH BY ANTHONY WALLACE/AGENCE FRANCE-PRESSE -- GETTY IMAGES) This article \nappeared in print on page A4.               \nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "India-based leaders steer the wheels of global tech",
        "media": "The Economic Times",
        "time": "March 20, 2024",
        "section": "TECH & INTERNET",
        "length": "722 words",
        "byline": "Beena Parmar and Annapurna Roy",
        "story_text": "India-based leaders steer the wheels of global tech\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 722 words\nByline: Beena Parmar and Annapurna Roy\nBody\nIndia is no more just the back office or the cost centre of the global tech industry; it is increasingly becoming a \ncountry where global leadership of multinationals are based, with teams reporting to them from across the \nglobe.Technology and banking giants such as IBM, Accenture, SAP and Goldman Sachs among others have \nseveral new reporting and controlling positions based out of India, industry experts said.As more international \ncompanies widen their operations here, especially with the expansion of global capability centres (GCCs), this trend \nwill only strengthen, they said.Global snack and beverage maker PepsiCo is also firming up plans to elevate several \nsenior executives based out of India, which will see reporting from global teams, people aware of the development \nsaid.For Accenture, at least five senior global positions are now in India including its chief strategy officer Bhaskar \nGhosh.IBM has recently appointed Sudheesh Kairali, the architect of watsonx.data (IBM’s artificial intelligence and \ndata platform), to lead the data and AI team at IBM based out of Kochi.SAP has Dharani Karthikeyan heading the \nengineering for analytics from Bengaluru.“Dharani is the global engineering lead for our analytics products, and \nshe’s based here in Bangalore,” SAP CTO Juergen Muller said. “There are teams in Germany reporting into \nDharani, there are teams in Canada reporting into Dharani… So, there’s no artificial ceiling where you can only get \nto a certain level and then that’s the end unfortunately… Many senior leaders for the company are actually based in \nBengaluru,” he told ET.Viswanathan KS, vice president (industry initiatives) at industry body Nasscom, said, “There \nis increasingly more trust built in India over the past five years with the leadership roles focused beyond mere \ndelivery and back-office functions. \nThis aids the parent organisations to leverage more from India.”New types of roles including chief customer officer, \ndiscovery officer, etc are being created here, he said. “There is higher confidence, more stature and increased \nownership of end-to-end responsibilities and strategic advisory positions developed from here,” Viswanathan \nadded.Other global roles in India at Accenture include Senthil Ramani, global lead for data & AI, Kaushal Mody, \nchief assets and solutions officer, and Arundhati Chakraborty, global lead – delivery and business transformation \noperations, in Bengaluru, besides Mahesh Zurale, global lead for advanced technology centres global network and \nlead for advanced technology centres in India, based out of Pune.“A significant portion of our clients are coming to \nIndia right now… The numbers are in double, triple digits,” said Ramani, who moved from Singapore to Bengaluru \nover two years ago. “And then the supply part is here… India to us is like the nucleus, so ability to go out to the \nmarket and come back here to constantly match the demand supply (talent). And to keep the friction as less as \npossible between demand-supply (talent) and that’s my job,” he said.According to Dinesh Nirmal, senior vice \npresident for products at IBM Software, the technical talents here like Kairali can help create multiple new talented \npeople to create more innovations and India has that technology advantage.“I would say generative AI, data and \nsecurity are the three areas we’ll see a lot of new talent coming out from here,” he said.Goldman Sachs’ global chief \noperating officer of engineering Gunjan Samtani is based out of Bengaluru.Last year, the US investment banking \ngiant promoted its largest ever batch of around 32 executives across Mumbai, Bengaluru and Hyderabad to \nmanaging director roles.“We promoted the biggest MD class here… There are many global functions or leaders \nwith global responsibilities that are anchored out of here,” Samtani told ET in an interaction recently. “In many ways, \nIndia -based leaders steer the wheels of global tech\nthe state of maturity has led to the nature of roles, the kind of people that we look for these roles and lastly, the \ninversion of responsibility in these roles, to not just be in support of global teams, but you are the global leader,” he \nsaid.Industry body Nasscom has projected about 5,000 global digital leadership roles present in the country in 2022 \nto grow four-fold to 20,000 by 2030 with the rise of GCCs in the country. For Reprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Group_Mar2024",
        "header": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone",
        "media": "Group",
        "time": "March 20, 2024",
        "section": "STARTUPS",
        "length": "500 words",
        "byline": "Javed Farooqui",
        "story_text": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone \nGroup\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 500 words\nByline: Javed Farooqui\nBody\nPocket FM, a leading audio entertainment platform, has raised $103 million in Series D funding led by Lightspeed \nwith participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to $196.5 \nmillion.The new funding will strengthen Pocket FM's push into the U.S. market and also support global expansion \nas the company plans to expand into Europe and LATAM markets in 2024.The company will continue to strengthen \nits exclusive content library and create a strong IP playbook by providing the writer community with a stage to share \ntheir unique and unheard stories.The company said it has exceeded $150 million in annualised revenue run rate \n(ARR) worldwide, with revenue growing at 57% quarter-over-quarter (QoQ).Its revenue has surpassed $100 million \nin ARR in the U.S. market. It launched in the US in Q4 of 2022. US audiences spend over 135 minutes daily. \nThe platform has approximately 10 million registered users in the U.S.Pocket FM has put up an AI-led strategy for \nautomation, content curation, production, and distribution. The company plans to leverage generative AI to scale \nits entertainment content offerings and build AI-powered personalised recommendations that enhance the overall \nuser experience. “We identified an unexplored space in the entertainment industry driven by an increasing demand \nfor audio fiction and crafted a playbook to address this opportunity across every key market,\" said Rohan Nayak, \nCEO and co-founder of Pocket FM.\"Our robust content library of audio series and strong consumption behaviour on \nthe platform are shaping the future of entertainment. Our focus remains on tapping into unique and exclusive stories \nto solidify our leadership in this emerging category and create a strong IP playbook. This latest funding validates \nour vision and the possibilities we bring to disrupt the industry.”“What sets Pocket FM apart is its vision to set up a \nsustainable and profitable business, backed by its unique pricing strategy. It emerges as a great reference for the \nentertainment landscape with its capability to demonstrate strong unit economics. They are not just building a new \ncategory but democratising the entertainment landscape with a tech-driven approach,” said Harsha Kumar, Partner \nat Lightspeed.Since launching in 2018, Pocket FM has been driving serialised audio storytelling and has \nestablished itself as the leader in personalised audio entertainment.With over 100,000+ hours of content, including \n2,000+ exclusive audio series and more than 400,000 episodes across genres and languages, the platform has \ncultivated a loyal audience and established itself as a driving force in the entertainment category. The company has \nsurpassed $150 million in ARR and is growing at 57% QoQ.It has clocked over 20 million transactions in 2023. \nGlobally, listeners spend an average of over 115 minutes per day. In 2023 alone, the platform witnessed over 75 \nbillion minutes of streaming worldwide. For Reprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Group_Mar2024",
        "header": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone",
        "media": "Group",
        "time": "March 20, 2024",
        "section": "ENTERTAINMENT",
        "length": "500 words",
        "byline": "Javed Farooqui",
        "story_text": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone \nGroup\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ENTERTAINMENT\nLength: 500 words\nByline: Javed Farooqui\nBody\nPocket FM, a leading audio entertainment platform, has raised $103 million in Series D funding led by Lightspeed \nwith participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to $196.5 \nmillion.The new funding will strengthen Pocket FM's push into the U.S. market and also support global expansion \nas the company plans to expand into Europe and LATAM markets in 2024.The company will continue to strengthen \nits exclusive content library and create a strong IP playbook by providing the writer community with a stage to share \ntheir unique and unheard stories.The company said it has exceeded $150 million in annualised revenue run rate \n(ARR) worldwide, with revenue growing at 57% quarter-over-quarter (QoQ).Its revenue has surpassed $100 million \nin ARR in the U.S. market. It launched in the US in Q4 of 2022. US audiences spend over 135 minutes daily. \nThe platform has approximately 10 million registered users in the U.S.Pocket FM has put up an AI-led strategy for \nautomation, content curation, production, and distribution. The company plans to leverage generative AI to scale \nits entertainment content offerings and build AI-powered personalised recommendations that enhance the overall \nuser experience. “We identified an unexplored space in the entertainment industry driven by an increasing demand \nfor audio fiction and crafted a playbook to address this opportunity across every key market,\" said Rohan Nayak, \nCEO and co-founder of Pocket FM.\"Our robust content library of audio series and strong consumption behaviour on \nthe platform are shaping the future of entertainment. Our focus remains on tapping into unique and exclusive stories \nto solidify our leadership in this emerging category and create a strong IP playbook. This latest funding validates \nour vision and the possibilities we bring to disrupt the industry.”“What sets Pocket FM apart is its vision to set up a \nsustainable and profitable business, backed by its unique pricing strategy. It emerges as a great reference for the \nentertainment landscape with its capability to demonstrate strong unit economics. They are not just building a new \ncategory but democratising the entertainment landscape with a tech-driven approach,” said Harsha Kumar, Partner \nat Lightspeed.Since launching in 2018, Pocket FM has been driving serialised audio storytelling and has \nestablished itself as the leader in personalised audio entertainment.With over 100,000+ hours of content, including \n2,000+ exclusive audio series and more than 400,000 episodes across genres and languages, the platform has \ncultivated a loyal audience and established itself as a driving force in the entertainment category. The company has \nsurpassed $150 million in ARR and is growing at 57% QoQ.It has clocked over 20 million transactions in 2023. \nGlobally, listeners spend an average of over 115 minutes per day. In 2023 alone, the platform witnessed over 75 \nbillion minutes of streaming worldwide. For Reprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Group_Mar2024",
        "header": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone",
        "media": "Group",
        "time": "March 20, 2024",
        "section": "FUNDING",
        "length": "500 words",
        "byline": "Javed Farooqui",
        "story_text": "Pocket FM raises $103 mn in Series D round from Lightspeed, Stepstone \nGroup\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 500 words\nByline: Javed Farooqui\nBody\nPocket FM, a leading audio entertainment platform, has raised $103 million in Series D funding led by Lightspeed \nwith participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to $196.5 \nmillion.The new funding will strengthen Pocket FM's push into the U.S. market and also support global expansion \nas the company plans to expand into Europe and LATAM markets in 2024.The company will continue to strengthen \nits exclusive content library and create a strong IP playbook by providing the writer community with a stage to share \ntheir unique and unheard stories.The company said it has exceeded $150 million in annualised revenue run rate \n(ARR) worldwide, with revenue growing at 57% quarter-over-quarter (QoQ).Its revenue has surpassed $100 million \nin ARR in the U.S. market. It launched in the US in Q4 of 2022. US audiences spend over 135 minutes daily. \nThe platform has approximately 10 million registered users in the U.S.Pocket FM has put up an AI-led strategy for \nautomation, content curation, production, and distribution. The company plans to leverage generative AI to scale \nits entertainment content offerings and build AI-powered personalised recommendations that enhance the overall \nuser experience. “We identified an unexplored space in the entertainment industry driven by an increasing demand \nfor audio fiction and crafted a playbook to address this opportunity across every key market,\" said Rohan Nayak, \nCEO and co-founder of Pocket FM.\"Our robust content library of audio series and strong consumption behaviour on \nthe platform are shaping the future of entertainment. Our focus remains on tapping into unique and exclusive stories \nto solidify our leadership in this emerging category and create a strong IP playbook. This latest funding validates \nour vision and the possibilities we bring to disrupt the industry.”“What sets Pocket FM apart is its vision to set up a \nsustainable and profitable business, backed by its unique pricing strategy. It emerges as a great reference for the \nentertainment landscape with its capability to demonstrate strong unit economics. They are not just building a new \ncategory but democratising the entertainment landscape with a tech-driven approach,” said Harsha Kumar, Partner \nat Lightspeed.Since launching in 2018, Pocket FM has been driving serialised audio storytelling and has \nestablished itself as the leader in personalised audio entertainment.With over 100,000+ hours of content, including \n2,000+ exclusive audio series and more than 400,000 episodes across genres and languages, the platform has \ncultivated a loyal audience and established itself as a driving force in the entertainment category. The company has \nsurpassed $150 million in ARR and is growing at 57% QoQ.It has clocked over 20 million transactions in 2023. \nGlobally, listeners spend an average of over 115 minutes per day. In 2023 alone, the platform witnessed over 75 \nbillion minutes of streaming worldwide. For Reprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "The new AI disruption tool: Devin(e) or Devil for software engineers?",
        "media": "The Economic Times",
        "time": "March 20, 2024",
        "section": "COMPANY",
        "length": "1019 words",
        "byline": " ",
        "story_text": "The new AI disruption tool: Devin(e) or Devil for software engineers?\nThe Economic Times\nMarch 21, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANY\nLength: 1019 words\nBody\nWhile explosive growth in artificial intelligence (AI) is augmenting capacities in several sectors, there are also \nconcerns over how it can affect humans. Firms have invested heavily in AI, leaving economists striving to \nunderstand the impact on the labour market and driving fears among the wider public for the future of their jobs. \nThe rapid adoption of AI so far is creating and not destroying jobs, especially for the young and highly-skilled, but \ncould reduce wages, research published last year by the European Central Bank has shown.After ChatGPT made \nwaves all over the world for its surprising generative AI capacity, a US-based company called Cognition has \nannounced the launch of a new AI tool called Devin which it claims to be the world's first fully autonomous AI \nsoftware engineer which can write code with command prompts. It has triggered fears among the software \ncommunity about its possible impact on tech jobs.What is Devin and what it doesAs per Cognition, Devin is a \ntireless, skilled teammate, equally ready to build alongside you or independently complete tasks for you to review. \nWith Devin, engineers can focus on more interesting problems and engineering teams can strive for more ambitious \ngoals.Devin can plan and execute complex engineering tasks requiring thousands of decisions. It can recall \nrelevant context at every step, learn over time, and fix mistakes.Cognition has equipped Devin with common \ndeveloper tools including the shell, code editor, and browser within a sandboxed compute environment — \neverything a human would need to do their work. Devin has the ability to actively collaborate with the user. It reports \non its progress in real time, accepts feedback, and works together with the user through design choices as needed. \nDevin can learn how to use unfamiliar technologies; build and deploy apps end-to-end; autonomously find and fix \nbugs in codebases; and train and finetune its own AI models.Devin correctly resolves 13.86% of the issues end-to-\nend, far exceeding the previous state-of-the-art of 1.96%. Even when given the exact files to edit, the best previous \nmodels can only resolve 4.80% of issues. Cognition tried giving Devin real jobs on Upwork and it could do those \ntoo. At present, Devin AI is in the beta testing phase and available to select users in limited access and that too by \nrequest. You can request Devin AI access by filling out a form available on their official website.How will Devin \nimpact software jobs? Devin's capabilities have raised concerns over its impact on software jobs. Will it prove to be \na job-killer as much of AI is being seen, or a blessing for techies who will benefit from it? Cognition presents Devin \nas a smart assistant that makes the job of software engineers easier and thus allows them to focus on higher-level \nskills. Software programming was getting impacted with generative AI tools like GitHub Copilot, but Cognition’s \nDevin has taken this to another level, Jaspreet Bindra, MD & founder of The Tech Whisperer, has told TOI. “It has \nseemingly groundbreaking capabilities in transforming software development. It can handle some development \nprojects independently, from writing code to fixing bugs and executing tasks, therefore mimicking a full-fledged AI \nworker rather than just a coding assistant,” he said.Its reported effectiveness in software engineering, Jaspreet \nsays, is notable because it can rapidly learn and utilise new technologies, build applications from scratch, identify \nand rectify bugs, contribute to production repositories, and autonomously train AI models. “This ability to handle \ncomplexity is creating a nervous and excited buzz amongst the fraternity,” he says.However, Devin is being seen \nmostly as an assistant rather than a competitor. Abhimanyu Saxena, co-founder of Scaler & InterviewBit, has told \nTOI that software engineers need to see these tools as enablers and quickly build expertise in using them efficiently \nrather than seeing them as competitors. “It is most likely to be a developer companion and may also enable a lot of \nnon-technical people to easily build applications,\" he says.Coding, Devin's core capability, is just one part of \nThe new AI disruption tool: Devin(e) or Devil for software engineers?\nsoftware development, and that's why it can't replace software engineers. Heena Kothari, senior director of \nengineering and product development at Exotel, has told TOI that Devin represents a big shift in how software is \nmade, and that software development isn’t just about writing code or testing it anymore. “While coding is important, \nthere’s a lot more to it, like planning how the software will work, making sure it fits with other software, and \nunderstanding how it’s used in different ways.”For large enterprise software, Heena says, coding only comprises \n40% of the whole software development process. “The rest involves designing the software, making it work with \nother software, and understanding how people will use it. That’s why Devin could be really helpful for simpler or \nmedium-complexity software projects. It could let engineers focus on solving bigger problems instead of spending \ntoo much time on routine tasks.”Despite its amazing capabilities, Devin may not pose any threat to techies at \npresent but development of generative AI will remain a cause of concern on the jobs front in various sectors, \nthough AI has in fact led to creation of more jobs. The research published by the European Central Bank, cited \nearlier in this article, is in contrast to previous technology waves, when computerisation decreased the relative \nshare of employment of medium-skilled workers. In a sample of 16 European countries, the employment share of \nsectors exposed to AI increased, with low and medium-skill jobs largely unaffected and highly-skilled positions \ngetting the biggest boost, a Research Bulletin published by the ECB said.However, the research says, these results \ndo not amount to an acquittal. \"AI-enabled technologies continue to be developed and adopted. Most of their impact \non employment and wages - and therefore on growth and equality - has yet to be seen.\"(With inputs from TOI) For \nReprint Rights: timescontent.com\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi:From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi: From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of Startup Mahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi:From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "Mahakumbh_Mar2024",
        "header": "Deeptech and AI Take Centre Stage on Second Day of the Startup",
        "media": "Mahakumbh",
        "time": "March 20, 2024",
        "section": "STARTUPS & TECH",
        "length": "226 words",
        "byline": "Our Bureau",
        "story_text": "Deeptech and AI Take Centre Stage on Second Day of the Startup \nMahakumbh\nEconomic Times (E-Paper Edition)\nMarch 20, 2024 Wednesday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 226 words\nByline: Our Bureau\nHighlight: Spotlight on Indian firms solving real-world problems at population scale\nBody\nNew Delhi:From deeptech to digital public infrastructure (DPI), from data to artificial intelligence, and the ‘India way’ \n— the second day of the three-day Startup Mahakumbh in the national capital discussed it all. India is possibly the \nworld leader in AI-first startups today, Amit Kumar, director and head of digital natives business at Google Cloud \nIndia, said. “India is leading the world in adoption of generative AI, which is also helping to solve real world \nproblems in areas like financial inclusion, health-related problems and agriculture,” he said. Kumar said Indian \ncompanies have bold ambition. For instance, Indian deeptech companies  are working on large language models \n(LLM) for India, building at a population scale, and these can be exported globally, he added. Umakanth Soni, \nchairman of AI Foundry, a venture studio for AI startups, said India is maturing into a large economy at a time when \nthe country is becoming data rich. As the foundational technology of AI depends on data, India  can develop the \n‘India way’ rather than the US or China way, by looking at data as an asset, he added.  Kris Gopalakrishnan, \nInfosys cofounder and Infosys Science Foundation president, said India’s unique digital public infrastructure will \ntransform digitisation in the country and presents an opportunity for startups to leverage it for business.\nLoad-Date: March 20, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "The Department of Homeland Security Is Embracing A.I.",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "BUSINESS",
        "length": "636 words",
        "byline": "Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C.",
        "story_text": "The Department of Homeland Security Is Embracing A.I.\nThe New York Times \nMarch 18, 2024 Monday 22:34 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 636 words\nByline: Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C. \nShe has written about technology for over two decades.\nHighlight: The agency will be the first in the federal government to roll out a comprehensive plan to integrate the \ntechnology into a variety of uses, from fighting crime to helping disaster survivors.\nBody\nThe Department of Homeland Security has seen the opportunities and risks of artificial intelligence firsthand. It \nfound a trafficking victim years later using an A.I. tool that conjured an image of the child a decade older. But it has \nalso been tricked into investigations by deep fake images created by A.I.\nNow, the department is becoming the first federal agency to embrace the technology with a plan to incorporate \ngenerative A.I. models across a wide range of divisions. In partnerships with OpenAI, Anthropic and Meta, it will \nlaunch pilot programs using chatbots and other tools to help combat drug and human trafficking crimes, train \nimmigration officials and prepare emergency management across the nation.\nThe rush to roll out the still unproven technology is part of a larger scramble to keep up with the changes brought \nabout by generative A.I., which can create hyper realistic images and videos and imitate human speech.\n“One cannot ignore it,” Alejandro Mayorkas, secretary of the Department of Homeland Security, said in an interview. \n“And if one isn’t forward-leaning in recognizing and being prepared to address its potential for good and its potential \nfor harm, it will be too late and that’s why we’re moving quickly.”\nThe plan to incorporate generative A.I. throughout the agency is the latest demonstration of how new technology \nlike OpenAI’s ChatGPT is forcing even the most staid industries to re-evaluate the way they conduct their work. \nStill, government agencies like the D.H.S. are likely to face some of the toughest scrutiny over the way they use the \ntechnology, which has set off rancorous debate because it has proved at times to be unreliable and discriminatory.\nThose within the federal government have rushed to form plans following President Biden’s executive order issued \nlate last year that mandates the creation of safety standards for A.I. and its adoption across the federal government.\nThe D.H.S., which employs 260,000 people, was created after the Sept. 11 terror attacks and is charged with \nprotecting Americans within the country’s borders, including policing of human and drug trafficking, the protection of \ncritical infrastructure, disaster response and border patrol.\nAs part of its plan,  the agency plans to hire 50 A.I. experts to work on solutions to keep the nation’s critical \ninfrastructure safe from A.I.-generated attacks and to combat the use of the technology to generate child sexual \nabuse material and create biological weapons.\nIn the pilot programs, on which it will spend $5 million, the agency will use A.I. models like ChatGPT to help \ninvestigations of child abuse materials, human and drug trafficking. It will also work with companies to comb through \nits troves of text-based data to find patterns to help investigators. For example, a detective who is looking for a \nThe Department of Homeland Security Is Embracing A.I.\nsuspect driving a blue pickup truck will be able to search for the first time across homeland security investigations \nfor the same type of vehicle.\nD.H.S. will use chatbots to train immigration officials who have worked with other employees and contractors posing \nas refugees and asylum seekers. The A.I. tools will enable officials to get more training with mock interviews. The \nchatbots will also comb information about communities across the country to help them create disaster relief plans.\nThe agency will report results of its pilot programs by the end of the year, said Eric Hysen, the department’s chief \ninformation officer and head of A.I.\nThe agency picked OpenAI, Anthropic and Meta to experiment with a variety of tools and will use cloud providers \nMicrosoft, Google and Amazon in its pilot programs. “We cannot do this alone,” he said. “We need to work with the \nprivate sector on helping define what is responsible use of a generative A.I.”\nThis article appeared in print on page B2.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nBangalore Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai: Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, with revenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai:Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, with  revenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai: Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, withrevenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 21, 2024",
        "section": "STARTUPS & TECH",
        "length": "276 words",
        "byline": "Our Bureau",
        "story_text": "Pocket FM Nets $103m in Series-D Raise from Lightspeed, Others\nEconomic Times (E-Paper Edition)\nMarch 21, 2024 Thursday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 276 words\nByline: Our Bureau\nHighlight: Funds to strengthen platform’s US push and global expansion\nBody\nMumbai: Pocket FM, a leading audio entertainment platform, has raised $103 million in Series-D funding led by \nLightspeed with participation from Stepstone Group. The latest round brings Pocket FM’s total funding to date to \n$196.5 million. Pocket FM CEO Rohan Nayak said that the funding will strengthen Pocket FM's push into the US. \nmarket and also support global expansion into Europe and LATAM markets in 2024. He said the funds will also be \nused to expand the content catalogue and for generative AI initiatives that the company is undertaking. The \ncompany said it has exceeded $150 million in annualised revenue run rate (ARR) worldwide, with revenue growing \nat 57% quarterover-quarter (QoQ). Its revenue has surpassed $100 million in ARR in the US market. It launched in \nthe US in Q4 of 2022. US audiences spend over 135 minutes daily. The platform has approximately 10 million \nregistered users in the US. “We had zero revenue in 2022, and we have jumped to $150 million in ARR by the end \nof 2023. Out of which, $100 million of ARR is just in the US. We have seen significant traction in multiple markets \nglobally,” Nayak added. The Pocket FM CEO also said that the platform's success has proven that audio series is a \nnew entertainment category globally. “Pocket FM wants to be the largest audio series platform in the world. This \nalso validates that we can build global consumer products from India for the world,” he stated. Pocket FM, he said, \nhas done 20 million transactions since last year. “Audio entertainment as a category will be just as big as movies \nand TV shows, going by the transactions we have received in the last two years,” he noted.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "TECHNOLOGY",
        "length": "843 words",
        "byline": "Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times",
        "story_text": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nThe New York Times \nMarch 19, 2024 Tuesday 22:32 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 843 words\nByline: Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nNico Grant is a technology reporter covering Google from San Francisco. Previously, he spent five years at \nBloomberg News, where he focused on Google and cloud computing. Brian X. Chen is the lead consumer \ntechnology writer for The Times. He reviews products and writes Tech Fix, a column about the social implications of \nthe tech we use.\nHighlight: A partnership would extend the long relationship between the companies that has helped deliver \neverything from maps to search on Apple’s devices.\nBody\nA partnership would extend the long relationship between the companies that has helped deliver everything from \nmaps to search on Apple’s devices.\nApple is in discussions with Google about using the search giant’s generative artificial intelligence model called \nGemini for its next iPhone, as the company races to embrace a technology that has upended the tech industry.\nThe talks are preliminary and the exact scope of a potential deal hasn’t been defined, three people with knowledge \nof the discussions said. Apple has also held discussions with other A.I. companies, one of these people said, as it \nlooks to tap into the power of a large language model capable of analyzing vast amounts of data and generating \ntext on its own.\nTim Cook, Apple’s chief executive, has promised investors that the company will introduce new generative A.I. \ncapabilities this year. The company’s smartphone rivals, Samsung and Google, have already added Gemini to their \nnewest devices to edit videos and summarize audio recordings.\nApple and Google declined to comment. Bloomberg reported earlier on their talks.\nAn Apple-Google deal on generative A.I. would extend one of technology’s most longstanding partnerships. Since \nApple introduced the iPhone in 2007, Google has been a critical contributor to the device’s success. It initially \nprovided Google Maps for navigation and the default search engine on the iPhone’s Safari browser, now a lucrative \nagreement for which Google pays Apple more than $18 billion a year. \nGoogle’s discussions to provide generative A.I. capabilities for the iPhone would be the latest example of its filling \na gap in Apple’s products. Apple’s effort to develop its own large language model, the technology behind chatbots \nlike ChatGPT and Gemini, has been running behind, two people familiar with its development said.\nApple’s delay in releasing an A.I. product has been costly. After a decade-long run as the world’s most valuable \npublic company, it was dethroned this year by Microsoft, which has aggressively pursued A.I. The technology has \nbeen heralded for its potential to disrupt businesses and create trillions of dollars in economic value.\nApple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nDespite its delays, Apple has the potential to be a big player in A.I. The company has more than two billion devices \nactively in use, making it an attractive partner for Google and others. Its reputation for protecting customers’ private \ninformation could also be helpful in a future where A.I. services help manage people’s calendars or health data.\nA deal could bring the Gemini model to iPhones around the world, giving Google access to a massive user base \nand making generative A.I. even more mainstream. Virtually overnight, Google could have more consumers using \nits A.I. than its chief rival, OpenAI, which makes ChatGPT — making a pact with Apple a tantalizing prospect.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nApple’s selecting Google as an A.I. supplier would be a crucial vote of confidence in the search giant after a number \nof setbacks to its A.I. ambitions. The company’s first A.I. chatbot, Bard, debuted to middling reviews last March and \nstruggled to attract as many users as ChatGPT.\nIn February, Google debuted a new chatbot, Gemini. The chatbot ran into problems last month when users found \nthat its image generator produced illustrations of historical figures that were not racially accurate and refused in \nmost instances to generate images of white people, leading to accusations of bias. Google disabled the ability to \ncreate images of people and vowed to fix the problem.\nIn a note on Tuesday, a Bernstein Research analyst, Toni Sacconaghi, called an Apple-Google deal a “win-win,” \ngiving Apple generative A.I. for iPhones and validating Google’s work on Gemini. He also said Apple didn’t have to \nown an A.I. model on iPhones to profit from it and could instead take a commission from Google, which currently \ncharges $19.99 per month for its Gemini Advanced app.\nCompanies haven’t yet cashed in on generative A.I. The costs associated with running large language models in \nthe cloud are staggering, and consumers and business customers are only starting to pay for the emerging \ntechnology. But they are optimistic that profits will increase as the capabilities of A.I. systems improve and the costs \ndecline for building the data centers to power the systems.\nA new deal between Apple and Google could draw scrutiny from U.S. regulators. The Justice Department is in the \nfinal stages of a lawsuit against Google for harming competition by paying Apple to be the default search engine on \nthe iPhone and other services. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict this year.\nPHOTO: A deal to provide A.I. capabilities for the iPhone would be the latest example of Google filling a gap in \nApple’s products. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES) This article \nappeared in print on page B5.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Intel Receives $8.5 Billion in Grants to Build Chip Plants",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "1210 words",
        "byline": "By Zolan Kanno-Youngs, Madeleine Ngo and Don Clark",
        "story_text": "Intel Receives $8.5 Billion in Grants to Build Chip Plants\nThe New York Times\nMarch 21, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 1210 words\nByline: By Zolan Kanno-Youngs, Madeleine Ngo and Don Clark\nBody\nThe award, announced by President Biden at a plant in Arizona, is the biggest the government has made under a \nnew program that aims to rebuild the nation's semiconductor manufacturing industry.\nPresident Biden on Wednesday awarded $8.5 billion in grants to Intel, a major investment to bolster the nation's \nsemiconductor production, during a tour of battleground states meant to sell his economic agenda. \n  Speaking from the Intel campus in Chandler, Ariz., Mr. Biden said the award would support thousands of new \nmanufacturing jobs, including ones that do not require a college degree.\n  ''It's going to transform the semiconductor industry,'' Mr. Biden said. ''Where the hell is it written saying that we're \nnot going to be the manufacturing capital of the world again?''\n  The award, which will go to the construction and expansion of Intel facilities around the United States, is the \nbiggest the federal government has made with funding from the CHIPS Act, which lawmakers passed in 2022 to \nhelp re-establish the United States as a leader in semiconductor manufacturing.\n  The Biden administration, equipped with $39 billion in subsidies to distribute, is spearheading an ambitious effort \nto ramp up production of the tiny chips that power everything from smartphones to computers and cars. The effort is \nat the center of Mr. Biden's goal to reduce America's reliance on foreign countries: Although semiconductors were \ninvented in the United States, only about 10 percent of the world's chips are made domestically.\n  ''Nearly all manufacturing of leading-edge chips across the entire industry moved overseas to Asia years ago,'' Mr. \nBiden said. ''That's why today's investment is such a big deal: We will enable advanced semiconductor \nmanufacturing to make a comeback here in America.''\n  In addition to the grants, the federal government is planning to award Intel up to $11 billion in loans on what the \ncompany characterized as generous terms. Intel is also expected to claim federal tax credits that could cover 25 \npercent of the expense of its U.S. expansion projects, which are expected to cost more than $100 billion over five \nyears.\n  The grants are intended to help fund the company's construction plans in Arizona, Ohio, New Mexico and Oregon. \nThe projects are expected to create more than 10,000 manufacturing jobs and roughly 20,000 construction jobs, \naccording to Biden administration officials.\n  Commerce Secretary Gina Raimondo, whose department is overseeing the distribution of the grants, said the \naward would help ramp up the country's production of the most advanced semiconductors, which are used in \nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nartificial intelligence, smartphones, supercomputers and the most sensitive military hardware. The United States \ncurrently produces none.\n  Ms. Raimondo said the Intel award would be the single largest grant to a chipmaker under the new program. The \ninvestment will help put the United States on track to produce roughly 20 percent of the world's leading-edge chips \nby the end of the decade, she said.\n  ''This investment will enable Intel to produce leading edge, the most sophisticated chips in the world that will power \nour economic and national security,'' Ms. Raimondo said at the Intel campus on Wednesday.\n  In Arizona, the money will help fund Intel's recent construction of two advanced plants and the modernization of \nanother facility. The money will also help establish an entirely new site near Columbus, Ohio, starting with two \nfactories, in its first move to a new U.S. region in more than 40 years.\n  In Rio Rancho, N.M., Intel will use the federal funds to transform two plants into advanced packaging facilities, \nwhere chips are assembled together to enhance performance and reduce costs. The company will also expand and \nmodernize an innovation hub in Hillsboro, Ore., which is expected to further the company's technological leadership \nand development of new innovations.\n  Mr. Biden and his Democratic allies view the semiconductor investments as a key way to try to turn around \nperceptions of the economy among voters in battleground states like Arizona.\n  ''We have not been talking to folks about the issues that President Biden has been delivering on, and that's what \nwe are determined to do,'' Yolanda Bejarano, the Arizona Democratic Party chairwoman, said on Tuesday, adding \nthat Democrats would need to talk more about the effects of the semiconductor investments.\n  Although Intel will have to meet certain milestones before the money is distributed, senior Biden administration \nofficials said they expected the funds to start flowing to the company by the end of this year.\n  Patrick Gelsinger, Intel's chief executive, told reporters in a briefing on Tuesday evening that the government \nincentives represented a proud moment for his company and a major achievement for politicians of both parties. \nThough satisfied with the incentives earmarked for Intel, he said officials might need to invest more in the industry \nto reverse decades of shifting investment from the United States to countries in Asia.\n  ''It doesn't get fixed in one three- to five-year program,'' Mr. Gelsinger said. ''I do think we'll need at least a CHIPS \n2 to finish that job.''\n  Intel is the fourth company to receive a federal award under the new program, and brings the total announced \ngrants to more than $10 billion. The first three grants -- to GlobalFoundries, Microchip Technology and BAE \nSystems -- were to makers of legacy chips, which are created with older production processes but are still used in \nmany products like cars and dishwashers.\n  Biden administration officials are expected to announce more awards in the coming months to other major \nchipmakers, including the Taiwan Semiconductor Manufacturing Company, Samsung and Micron Technology. \nThose companies have also made major investments in new or expanded semiconductor manufacturing plants in \nthe United States in recent years.\n  The United States' dependence on Asia for its chips has become even more pronounced with the rise of artificial \nintelligence. Nearly all chips used to power the latest generative A.I. services were manufactured in Taiwan by \nT.S.M.C., though designed by the Silicon Valley company Nvidia.\n  Intel has been trying to change that by developing new manufacturing technology, beginning to build chips \ndesigned by other companies and lobbying heavily for the legislation. The investment in Intel is intended to help \nenable U.S. companies to lead in the A.I. industry by ensuring there is a domestic supply of advanced chips.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\n  About $50 million of federal funding will be set aside for Intel to spend on training and developing ''a new \ngeneration of workers for the semiconductor industry,'' Mr. Biden said. Many semiconductor companies and \nindustry groups have voiced concerns about potential shortages of technicians, engineers and other workers to fill \nall of the positions that will be created once the facilities are constructed.\n  In total, private companies have announced more than $240 billion in semiconductor and electronic manufacturing \ninvestments since Mr. Biden took office, according to administration officials. Some chipmakers, however, have run \ninto obstacles while trying to expand their domestic manufacturing capacity, resulting in delays.\nhttps://www.nytimes.com/2024/03/20/us/politics/chips-act-grant-intel.html\nGraphic\n \nPHOTO: An Intel semiconductor factory under construction in 2021 outside Phoenix. The award announced \nWednesday was the biggest so far under a new program that aims to rebuild the industry. (PHOTOGRAPH BY \nPHILIP CHEUNG FOR THE NEW YORK TIMES) This article appeared in print on page B4.               \nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Intel Receives $8.5 Billion in Grants to Build Chip Plants",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "US; politics",
        "length": "1247 words",
        "byline": "Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House",
        "story_text": "Intel Receives $8.5 Billion in Grants to Build Chip Plants\nThe New York Times \nMarch 20, 2024 Wednesday 12:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 1247 words\nByline: Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House \ncorrespondent, covering President Biden and his administration. Madeleine Ngo covers U.S. economic policy and \nhow it affects people across the country.\nHighlight: The award, announced by President Biden at a plant in Arizona, is the biggest the government has \nmade under a new program that aims to rebuild the nation’s semiconductor manufacturing industry.\nBody\nThe award, announced by President Biden at a plant in Arizona, is the biggest the government has made under a \nnew program that aims to rebuild the nation’s semiconductor manufacturing industry.\nPresident Biden on Wednesday awarded $8.5 billion in grants to Intel, a major investment to bolster the nation’s \nsemiconductor production, during a tour of battleground states meant to sell his economic agenda.\nSpeaking from the Intel campus in Chandler, Ariz., Mr. Biden said the award would support thousands of new \nmanufacturing jobs, including ones that do not require a college degree.\n“It’s going to transform the semiconductor industry,” Mr. Biden said. “Where the hell is it written saying that we’re \nnot going to be the manufacturing capital of the world again?”\nThe award, which will go to the construction and expansion of Intel facilities around the United States, is the biggest \nthe federal government has made with funding from the CHIPS Act, which lawmakers passed in 2022 to help re-\nestablish the United States as a leader in semiconductor manufacturing.\nThe Biden administration, equipped with $39 billion in subsidies to distribute, is spearheading an ambitious effort to \nramp up production of the tiny chips that power everything from smartphones to computers and cars. The effort is at \nthe center of Mr. Biden’s goal to reduce America’s reliance on foreign countries: Although semiconductors were \ninvented in the United States, only about 10 percent of the world’s chips are made domestically.\n“Nearly all manufacturing of leading-edge chips across the entire industry moved overseas to Asia years ago,” Mr. \nBiden said. “That’s why today’s investment is such a big deal: We will enable advanced semiconductor \nmanufacturing to make a comeback here in America.”\nIn addition to the grants, the federal government is planning to award Intel up to $11 billion in loans on what the \ncompany characterized as generous terms. Intel is also expected to claim federal tax credits that could cover 25 \npercent of the expense of its U.S. expansion projects, which are expected to cost more than $100 billion over five \nyears.\nThe grants are intended to help fund the company’s construction plans in Arizona, Ohio, New Mexico and Oregon. \nThe projects are expected to create more than 10,000 manufacturing jobs and roughly 20,000 construction jobs, \naccording to Biden administration officials.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nCommerce Secretary Gina Raimondo, whose department is overseeing the distribution of the grants, said the \naward would help ramp up the country’s production of the most advanced semiconductors, which are used in \nartificial intelligence, smartphones, supercomputers and the most sensitive military hardware. The United States \ncurrently produces none.\nMs. Raimondo said the Intel award would be the single largest grant to a chipmaker under the new program. The \ninvestment will help put the United States on track to produce roughly 20 percent of the world’s leading-edge chips \nby the end of the decade, she said.\n“This investment will enable Intel to produce leading edge, the most sophisticated chips in the world that will power \nour economic and national security,” Ms. Raimondo said at the Intel campus on Wednesday.\nIn Arizona, the money will help fund Intel’s recent construction of two advanced plants and the modernization of \nanother facility. The money will also help establish an entirely new site near Columbus, Ohio, starting with two \nfactories, in its first move to a new U.S. region in more than 40 years.\nIn Rio Rancho, N.M., Intel will use the federal funds to transform two plants into advanced packaging facilities, \nwhere chips are assembled together to enhance performance and reduce costs. The company will also expand and \nmodernize an innovation hub in Hillsboro, Ore., which is expected to further the company’s technological leadership \nand development of new innovations.\nMr. Biden and his Democratic allies view the semiconductor investments as a key way to try to turn around \nperceptions of the economy among voters in battleground states like Arizona.\n“We have not been talking to folks about the issues that President Biden has been delivering on, and that’s what we \nare determined to do,” Yolanda Bejarano, the Arizona Democratic Party chairwoman, said on Tuesday, adding that \nDemocrats would need to talk more about the effects of the semiconductor investments.\nAlthough Intel will have to meet certain milestones before the money is distributed, senior Biden administration \nofficials said they expected the funds to start flowing to the company by the end of this year.\nPatrick Gelsinger, Intel’s chief executive, told reporters in a briefing on Tuesday evening that the government \nincentives represented a proud moment for his company and a major achievement for politicians of both parties. \nThough satisfied with the incentives earmarked for Intel, he said officials might need to invest more in the industry \nto reverse decades of shifting investment from the United States to countries in Asia.\n“It doesn’t get fixed in one three- to five-year program,” Mr. Gelsinger said. “I do think we’ll need at least a CHIPS 2 \nto finish that job.”\nIntel is the fourth company to receive a federal award under the new program, and brings the total announced \ngrants to more than $10 billion. The first three grants — to GlobalFoundries, Microchip Technology and BAE \nSystems — were to makers of legacy chips, which are created with older production processes but are still used in \nmany products like cars and dishwashers.\nBiden administration officials are expected to announce more awards in the coming months to other major \nchipmakers, including the Taiwan Semiconductor Manufacturing Company, Samsung and Micron Technology. \nThose companies have also made major investments in new or expanded semiconductor manufacturing plants in \nthe United States in recent years.\nThe United States’ dependence on Asia for its chips has become even more pronounced with the rise of artificial \nintelligence. Nearly all chips used to power the latest generative A.I. services were manufactured in Taiwan by \nT.S.M.C., though designed by the Silicon Valley company Nvidia.\nIntel has been trying to change that by developing new manufacturing technology, beginning to build chips \ndesigned by other companies and lobbying heavily for the legislation. The investment in Intel is intended to help \nenable U.S. companies to lead in the A.I. industry by ensuring there is a domestic supply of advanced chips.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nAbout $50 million of federal funding will be set aside for Intel to spend on training and developing “a new generation \nof workers for the semiconductor industry,” Mr. Biden said. Many semiconductor companies and industry groups \nhave voiced concerns about potential shortages of technicians, engineers and other workers to fill all of the \npositions that will be created once the facilities are constructed.\nIn total, private companies have announced more than $240 billion in semiconductor and electronic manufacturing \ninvestments since Mr. Biden took office, according to administration officials. Some chipmakers, however, have run \ninto obstacles while trying to expand their domestic manufacturing capacity, resulting in delays.\nPHOTO: An Intel semiconductor factory under construction in 2021 outside Phoenix. The award announced \nWednesday was the biggest so far under a new program that aims to rebuild the industry. (PHOTOGRAPH BY \nPHILIP CHEUNG FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "opportunities_may_be_ahead._'We're_in_an_almost_gold_rush.'_Mar2024",
        "header": "AI a job killer -- and a job creator; Tech sector has been roiled by layoffs, but",
        "media": "opportunities may be ahead. 'We're in an almost gold rush.'",
        "time": "March 21, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1733 words",
        "byline": "Samantha Masunaga, Don Lee",
        "story_text": "AI a job killer -- and a job creator; Tech sector has been roiled by layoffs, but \nopportunities may be ahead. 'We're in an almost gold rush.'\nLos Angeles Times\nMarch 21, 2024 Thursday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1733 words\nByline: Samantha Masunaga, Don Lee\nBody\nFor the thousands of tech workers recently laid off in California and across the country, the future may not be as \nbleak as it looks right now: Many are likely to retrain fairly quickly for new jobs in the burgeoning field of artificial \nintelligence.\nThe massive rounds of layoffs at tech giants and many smaller companies were largely the result of stricter investor \ndemands -- what managers saw as over-hiring during the pandemic and a stock market that rewarded those \npersonnel cuts.\nBut the industry also was clearing the way to focus on AI, which is expected to revolutionize computer-related \ntechnology and work in the years ahead -- even as it displaces jobs, previously handled by humans, in areas as \nvaried as coding and background acting.\nNot only is AI taking over more standard computer programming once done entirely by humans, it is also starting to \nspur waves of new applications -- and with them, jobs, both tech and non-tech, in a wide range of industries, \nincluding in Southern California.\n\"What we're seeing is a lot of tech companies are actually monetizing the AI solution,\" said Jenn Longnion, the Los \nAngeles-based founder of See & Free Consulting, which helps businesses grow sustainably. \"They've had AI for a \nvery long time. But they're finding ways now to monetize that and actually promote that and sell that as a solution to \nother businesses. ... Every industry is now having those conversations.\"\nJob postings in the U.S. that specifically mention AI, though still a tiny fraction of all openings, were up by 13% in \nFebruary from a year ago, even as software development was off more than 30%, according to the employment \nwebsite Indeed.\nSilicon Valley, where most of the AI action is today, figures to lead the way. In February, 9% of companies in the \nBay Area said they already use AI, compared with a little more than 5% in the U.S. as a whole, according to the \nU.S. Census Bureau.\nThe share of L.A.-area companies wasn't significantly higher than the national average, but about 8% of firms in the \nSouthland said they expected to adopt AI in the next six months. In Silicon Beach, which has emerged as a home \nfor companies focusing on AI and augmented reality, firms are hiring for hundreds of AI-related jobs, including \ncontent writers and software developers who will train the technology.\nAI a job killer -- and a job creator Tech sector has been roiled by layoffs, but opportunities may be ahead. \n'We're in an almost gold rush.'\nTom Case, a founder at Atticus Growth Partners, a tech recruiting firm in San Francisco, said the proliferation of AI \nentrepreneurs and startups translates into more jobs. In the last few years, companies have been hiring primarily for \nresearch labs, he said, but the industry is beginning to move from AI models to getting them into production.\n\"We're in an almost gold rush where everybody's building an AI company model,\" he said. \"Very little AI is deployed \nin production. ... At the moment, it feels like the dawn of job creation.\"\nAfter pivoting her startup from business operations software to customer service ticketing through AI, Sophie Wyne \nsaw interest surge.\n\"I actually have never seen this amount of interest before for a product,\" said Wyne, founder and chief executive of \nAriglad in San Francisco. \"It's really just combining two things which people are really caring about. One is AI -- I \nthink everyone's really interested in how can that actually help my day-to-day in reality and not be so abstract. And \nthe other side is, I just hate updating my knowledge base.\"\nAmong the hundreds of AI startups looking for talent is Quest Labs, a Bay Area firm co-founded by Debparna \nPratiher. The 27-year-old previously worked as a product manager at Nvidia, the highly publicized Silicon Valley \nsupplier of chips used in gaming and other high-performance computing, particularly AI.\nPratiher is an alumnus of UC Davis and Carnegie Mellon University. Her firm, with seed money from Techstars and \nAfore Capital, has a staff of about 20. The business has been moving quickly to build data sets for ecommerce as \nGoogle has started to phase out third-party cookies, which track and learn what users are doing online. \"If cookies \nare gone, you're blind to consumers,\" Pratiher said.\nShe said she's had difficulty finding qualified data scientists and other AI engineers with deep experience in \nmachine learning.\n\"For all the AI hype and interest, buyers need to adopt the technology, and for that, they need better data,\" Pratiher \nsaid.\nFor those recently laid off, getting up to speed on Python, the popular programming language, and other in-demand \nAI skills isn't as daunting as one might think. Some skills, such as learning programming languages and databases \nto build AI models, might take a matter of weeks for IT workers.\nEven those with little or no experience in tech have been able to pivot.\nShakil Kamran attended a Salesforce conference in 2017, set on trying to break into tech and transition out of his \nretail management career, which regularly involved 60-hour weeks and left little time to spend with his son.\nHe took courses through Trailhead, San Francisco-based Salesforce's online learning platform, increased his skills \nand began seeing AI as the future. Today, Kamran, 37, is a Salesforce consultant and focuses on helping \norganizations use AI to help their business grow.\n\"AI is going to help us. It's going to assist us in growing and becoming more effective and efficient,\" said Kamran, \nwho lives in Connecticut. \"It's going to supercharge our lives.\"\nOthers are following Kamran's lead. Trailhead expanded its AI curriculum last year to include 43 \"badges\" that are \nearned by completing courses. So far, users have tallied more than 1.1 million badges, said Ann Weeby, senior vice \npresident of Trailhead.\n\"We're seeing employees from every level, in every type of business ... jump in and start learning, because they \nwant to apply generative AI to their business yesterday,\" Weeby said.\nFor their part, many universities are pivoting to incorporate AI in courses on computer science and other disciplines.\nAI a job killer -- and a job creator Tech sector has been roiled by layoffs, but opportunities may be ahead. \n'We're in an almost gold rush.'\n\"It's not a death knell,\" said Charles Lee Isbell Jr., who studied at MIT's AI Lab and recently became provost at the \nUniversity of Wisconsin in Madison.\nIsbell is pushing for classroom emphasis on AI data-driven simulations and so-called deep learning, which uses \nmultiple layers of what are called \"artificial neural networks\" -- complex algorithms designed to mimic the human \nbrain to generate new data.\n\"Coding and programming aren't going away,\" he said.\nTech layoffs have slowed from last year's frenetic pace, but they remain substantial. More than 28,000 job cuts by \ntech firms nationwide were announced in the first two months of this year, according to Challenger, Gray & \nChristmas, an outplacement and research firm.\nOnly a few hundred of those layoffs were explicitly attributed to AI, but thousands more cuts in tech and other \nindustries were said to be the result of \"updating or incorporating new technology,\" Challenger said. It noted that \nsome of that may be companies overhauling budgets and staffing to make room for AI work.\nAlthough AI may not be directly responsible for most of the tech sector's job cuts, companies are realizing that \ngreater utilization of AI could mean they don't have to rehire for some positions, or that they can transition parts of \nthose jobs over to the new technology, said Longnion of See & Free Consulting.\nBackground actors expressed fears during last summer's strike that AI technology would be used to replace their \njobs. Their new contract secured rules to guard against that.\nData from Layoffs.fyi show that a growing number of layoffs have hit software developers, also known as coders, \nwho -- after decades of disrupting other industries and other workers' jobs with their programs -- now find \nthemselves victims of tech disruption.\nIn recent months, hundreds of coders and other IT specialists have been let go by tech giants Google, Meta and \nApple, as well as many smaller industry-focused digital platforms and cloud services, including Toast (restaurants), \nFlexport (logistics) and Block (financial services).\nMany of the layoffs have come in the Bay Area, putting a pause to two decades of growth at California's computer-\nsystems design firms and related services. Most of the cuts probably reflect a pullback after excessive pandemic-\ndriven hiring, due in part to ecommerce and remote work.\nBut the correction may be ending soon, as new tech jobs come into view and workers adjust.\nAyanna Howard, a robotics expert and dean of the engineering college at Ohio State University, said it wasn't long \nago that coding was all the rage, and people were flocking to computer boot camps. She remembers how hard it \nonce was for people to create a website. Now, with AI tools, you can build one within minutes by simply putting in \nblocks of information, she noted.\nAI can also do coding on back-end servers, the side responsible for storing and organizing data, including security.\nBut Howard said not all is lost for even low-level coders. \"If you're trained to learn, you can evolve,\" she said, just as \nthose who began by using Pascal and BASIC learned to program in Assembly and Python, used for many machine \nlearning and AI solutions.\nOthers are emphasizing the inimitable human touch that AI could never replace. Since Alissa Marr was laid off last \nmonth from an early-stage AI startup, the product designer has mostly focused on building her business acumen \nand strategic problem-solving ability rather than just retooling her software skills.\nAI a job killer -- and a job creator Tech sector has been roiled by layoffs, but opportunities may be ahead. \n'We're in an almost gold rush.'\n\"Those kinds of things are not something an AI can do,\" said Marr, 39, who lives in Providence, R.I. \"You need to \nhave a human with expertise and knowledge about the customer and the business problem. There needs to be \nsomeone pulling the strings, because it can't just be automated by AI and just go out as is.\"\nAI may ultimately lead to a smaller tech workforce, said Howard of Ohio State. But there will also be AI-augmented \njobs, as well as new jobs. One position in high demand is prompt engineer, who designs prompts and other \nprocesses to get optimal performance from generative AI tools, whether text or images.\nA company buying AI conversational programs such as ChatGPT (from OpenAI) or Gemini (from Google) will still \nneed engineers to refine and customize the tools to replicate human-like dialogue.\n\"We don't necessarily know what it is that we need,\" Howard said. \"But they will come out, and when they do, it'll be \nlike, 'Oh, guess what? It's another field.' \"\nGraphic\n \nPHOTO: (no caption)  PHOTOGRAPHER:Jim Cooke Los Angeles Times; photos via Getty Images PHOTO: \nALISSA MARR, above, was laid off. Consultant Jenn Longnion, top, sees the sector evolving.  \nPHOTOGRAPHER:Michael Owen Baker PHOTO: ALISSA MARR, above, was laid off. Consultant Jenn Longnion, \ntop, sees the sector evolving.  PHOTOGRAPHER:Sean Hayes \nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Sprouts of Hope in a Gloomy Media Landscape",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "BUSINESS; media",
        "length": "1358 words",
        "byline": "Katie Robertson and Benjamin Mullin Katie Robertson covers the media industry for The Times. Email: ,",
        "story_text": "Sprouts of Hope in a Gloomy Media Landscape\nThe New York Times \nMarch 12, 2024 Tuesday 22:11 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1358 words\nByline: Katie Robertson and Benjamin Mullin Katie Robertson covers the media industry for The Times. Email: , \nkatie.robertson@nytimes.com,  Benjamin Mullin reports on the major companies behind news and entertainment. \nContact Ben securely on Signal at +1 530-961-3223 or email at , benjamin.mullin@nytimes.com\nHighlight: A handful of digital start-ups are finding success — so far, at least — by learning lessons from their \ntroubled predecessors.\nBody\nThis year is looking grim for the news business.\nFacing a set of harsh financial realities — resulting from a mix of news fatigue, an unsteady advertising market and \na precipitous fall in traffic from tech giants — many outlets have been forced to fold or make significant cuts in \nrecent months.\nBut there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success — at least for the moment — by taking the opposite approach of many \npredecessors, such as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize \ngrowth.\nThe new class of news start-ups — Puck, Punchbowl News, The Ankler and Semafor are among the most \nprominent — have kept spending down and hired carefully. They are all centered on newsletters covering specific \nniches with broad appeal. They have attracted top journalists by putting them at the heart of the enterprise, \nsometimes as part owners in the companies.\n“There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,” said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. “And I think that the entire industry has learned from that.”\nThese start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.\nBut traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn’t add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.\nThe formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.\nSprouts of Hope in a Gloomy Media Landscape\n“What all of them have in common is this intense need to serve specific audiences rather than to serve everybody,” \nsaid Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.\nSome of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.\nPunchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome “the hometown newspaper of Capitol Hill in a lot of ways,” said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.\n“What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,” she said.\nPunchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. Access \nto Punchbowl’s policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the low \nfive-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings from \nthose websites.\nMs. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl’s finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.\nThe Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood’s unsparing gadfly, narrating the industry’s unending chaos and skewering the \nactors, agents and executives responsible for creating it.\nAnkler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, said \nJanice Min, the company’s chief executive and founder, who previously helmed The Hollywood Reporter and Us \nWeekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a Hollywood \nnews digest.\n“If we want to make a Hollywood analogy, it’s like these growing franchises are multiverses,” Ms. Min said. “People \nlike what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.”\nSemafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.\nSemafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called for, \nMr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic outlook \nwas darkening.\n“The pandemic really marked the transition from the social media era to what we call the post-social media era,” Mr. \nSmith said, noting that outlets must now focus on direct relationships with their audience.\nFor Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.\nSprouts of Hope in a Gloomy Media Landscape\nThe company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.\nOf course, nothing in media lasts forever — particularly in the fast-changing digital world. So there’s no guarantee \nthat the early success of these companies will translate into sustained growth.\nMany of these start-ups are also taking a somewhat risky bet on talent.\nAt Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who is \na definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on Russian \npolitics, are “founding partners.” In addition to a salary, they receive bonuses based on the number of people who \nsubscribe to their email newsletters and how many of them stick around. New employees also get a small \nownership stake in the company.\nPuck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.\nIf one or more of the star journalists leave the publication, would Puck’s subscribers follow?\nMr. Kelly said he didn’t “want to even contemplate a world” in which one of Puck’s journalists exited.\n“We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,” Mr. Kelly said. “And I really think that our model is actually becoming one of the \nmoats of our business.”\nPHOTO: Punchbowl News has become “the hometown newspaper of Capitol Hill in a lot of ways,” its chief \nexecutive said. (PHOTOGRAPH BY CHIP SOMODEVILLA/GETTY IMAGES) (B3) This article appeared in print on \npage B1, B3.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Keeps Losing Patent Cases. Its Solution: Rewrite the Rules.",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "TECHNOLOGY",
        "length": "1425 words",
        "byline": "Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco.",
        "story_text": "Apple Keeps Losing Patent Cases. Its Solution: Rewrite the Rules.\nThe New York Times \nMarch 19, 2024 Tuesday 09:56 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1425 words\nByline: Tripp Mickle Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. \nHis focus on Apple includes product launches, manufacturing issues and political challenges. He also writes about \ntrends across the tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: After losing two complaints before the U.S. International Trade Commission, Apple has stepped up its \nlobbying to change the agency’s practices.\nBody\nAfter losing two complaints before the U.S. International Trade Commission, Apple has stepped up its lobbying to \nchange the agency’s practices.\nOver the past decade, some of Apple’s biggest regulatory headaches have come from a little-known federal agency \ncalled the U.S. International Trade Commission. The agency’s patent judges have found Apple guilty of \nappropriating innovations in smartphones, semiconductors and smartwatches. And recently, they forced Apple to \nremove a health feature from Apple Watches.\nNow the tech giant is pushing back. While it defends itself from patent complaints before the I.T.C., Apple has \nbegun lobbying lawmakers to help rewrite the agency’s rules.\nThe company has been campaigning across Washington for legislation that would make some patent owners \nineligible to bring complaints before the I.T.C. It has sought to influence the language of committee reports that \ncould affect how the agency levels punishments. And it has added to its lobbying might by enlisting one of the \nagency’s former commissioners.\nThe lobbying effort comes as Apple is enmeshed in a multiyear legal battle with two U.S. medical device makers \nover technology in the Apple Watch. The companies, AliveCor and Masimo, filed complaints in the I.T.C. against \nApple in 2021 for appropriating innovations they had developed to measure the heart’s electrical activity and \npeople’s blood oxygen levels.\nAfter losing both cases, Apple this year removed the technology to measure blood oxygen in its watches, which \ninfringed on Masimo’s patent. It is appealing the I.T.C.’s decision. A similar punishment is on hold as court \nproceedings continue related to the I.T.C.’s finding that Apple infringed on AliveCor’s innovations with the Apple \nWatch’s electrocardiogram feature.\nApple is trying to blunt the agency’s signature power. Unlike traditional patent courts, where juries or judges \ntypically issue fines, the I.T.C.’s judges can discipline a company that violates a patent by banning imports of the \ninfringing product.\nBecause Apple makes all its signature devices overseas, a block on the import of its devices would be perilous to \nthe company. To avoid that penalty in the future, the company says, it wants the agency to put the public interest of \na product ahead of a ban. The company is betting that the court would then give more credence to Apple’s \nApple Keeps Losing Patent Cases. Its Solution: Rewrite the Rules.\nargument that Americans would be harmed by an import ban because they would lose access to the \ncommunication and health features in iPhones and Apple Watches.\nAn Apple spokeswoman said the existing law requires that the I.T.C. consider how the public interest could be \naffected before ordering an import ban. But it said public data showed that the agency had made public-interest \nevaluations in only one-fifth of cases it had heard since 2010. As a result, its lobbyists have been talking with White \nHouse and congressional leaders about the I.T.C., as well as other issues such as privacy and domestic \nmanufacturing.\nAdam Mossoff, a patent law expert and a professor at George Mason University, said Apple was misinterpreting the \nlaw, which requires the I.T.C. to block a product if it finds that it infringes on a patent. An import ban is supposed to \nbe overruled only if there’s a proven threat to health or safety, he said. Blocking sales of an Apple device wouldn’t \nqualify as harmful.\n“The problem with their lobbying is that they’re trying to neuter a well-functioning court by closing its doors to \nAmericans who have had their rights infringed,” he said.\nWhen Congress set up what became the I.T.C. in 1916, it wanted to protect American innovation by allowing the \nU.S. government to ban the import of products with stolen technology. But as manufacturing moved overseas, the \nfederal agency’s court system became a forum for disputes between U.S. companies.\nThe I.T.C.’s judges, who are appointed by the commission, hold hearings with different standards for patent \ndisputes than those that govern District Court cases. The cases are fast and compressed and can culminate with \nthe judge’s punishing a patent abuser by blocking its products.\nBefore a ban is put into effect, a company that’s found guilty can appeal to the White House for a reprieve. But it’s \nrare for an administration, which oversees the agency, to go against a judge’s recommendation.\nApple has become the pre-eminent example of how the I.T.C. can be used. Because the company manufactures \nalmost all its products overseas, the judges who have found it guilty of infringing on patents in smartphones, \nsemiconductors and smartwatches say it should be punished by blocking the import of iPhones, iPads and Apple \nWatches.\nApple has largely escaped the import bans. In 2013, the Obama administration vetoed the I.T.C.’s plan to block \niPhone imports after the agency determined that Apple had infringed on one of Samsung’s smartphone patents. In \n2019, Apple agreed to pay Qualcomm a royalty for some wireless technology patents, heading off an I.T.C. ruling \nthat could have blocked iPhone sales. And after losing the Masimo case, Apple agreed to remove the infringing \nhealth feature to dodge an Apple Watch ban.\nFor years, Apple avoided the kind of lobbying that was customary for a large corporation. It kept a small office in \nWashington staffed by just a few people and employed only one lobbying firm, two people familiar with the \ncompany’s practices said. But as regulatory challenges to its business have risen, its policy team has swelled to \ninclude dozens of people and 11 lobbying firms.\nIn the face of the patent complaints from AliveCor and Masimo, Apple’s team in Washington gave priority to \nlobbying to change the I.T.C. In 2022, it began working with the ITC Modernization Alliance, a loose-knit coalition of \ncompanies that includes Samsung, Intel, Dell, Google, Verizon and Comcast. The group worked with members of \nCongress as it wrote the Advancing America’s Interest Act in 2019 and supported its reintroduction in 2023.\nThe bill’s backers — Representatives David Schweikert, a Republican from Arizona, and Donald S. Beyer Jr., a \nDemocrat from Virginia — have promoted it as a way to curb abuse of the I.T.C. by patent trolls. It would prohibit \npatent holders from suing unless they manufactured a product that used the patented technology or had licensed \nthe technology to someone else already.\nApple Keeps Losing Patent Cases. Its Solution: Rewrite the Rules.\nAliveCor and Masimo are medical companies that have focused on selling products to health care providers and \nconsumers more than licensing innovations to consumer technology companies like Apple.\nLast year, Apple’s lobbyists filed three reports disclosing that it had campaigned on behalf of the bill, according to \nOpen Secrets, a campaign finance research nonprofit. It also added to its lobbying ranks by hiring Deanna Tanner \nOkun, a former I.T.C. chair who works for the law firm Polsinelli. (The hiring was previously reported by Politico.)\nThe lobbying campaign coincided with an effort to argue in Washington that an I.T.C. ban on Apple Watch imports \nwould deprive people of a device that was crucial to their health, two people familiar with the lobbying said.\nIn addition to lobbying directly on legislation, Apple worked with a member of Congress to put language on Page 97 \nof a committee report for the 2024 Appropriations Bill, said Representative Ken Buck, a Republican from Colorado. \nThe language would require the I.T.C. to review how it determined the value to the public of a product before \nsuggesting a ban and to report to Congress on that process.\n“To me, this went around the legitimate process,” said Mr. Buck, who is leaving Congress this month. He told \nRepresentative Thomas Massie, a Republican from Kentucky who is on the Rules Committee, that he had 10 votes \nand would block the bill unless the language was removed. Mr. Massie’s office confirmed that the language had \nbeen removed at Mr. Buck’s request but declined to comment further.\nAn Apple spokeswoman disagreed with Mr. Buck’s claims that its lobbying circumvented the legitimate legislative \nprocess. She said its public federal lobbying reports detailed how it worked on issues important for its products and \ncustomers.\nThe spokeswoman also pointed to the Senate’s passage of a committee report with a sentence expressing its \nsupport of the I.T.C.’s doing thorough analysis of the public health implications of a product ban before issuing one, \nwhich is what Apple wants in the future.\nPHOTO: Representative Ken Buck of Colorado has called Apple’s lobbying a run around the legislative process. \n(B3) This article appeared in print on page B1, B3.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "TECHNOLOGY",
        "length": "1761 words",
        "byline": "David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in",
        "story_text": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly\nThe New York Times \nMarch 21, 2024 Thursday 08:18 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1761 words\nByline: David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in \n2019. Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on \nApple includes product launches, manufacturing issues and political challenges. He also writes about trends across \nthe tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: The lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, \nwhich have fueled its growth into a nearly $3 trillion public company.\nBody\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $3 trillion public company.\nThe federal government’s aggressive crackdown on Big Tech expanded on Thursday to include an antitrust lawsuit \nby the Justice Department against Apple, one of the world’s best-known and most valuable companies.\nThe department joined 16 states and the District of Columbia to file a significant challenge to the reach and \ninfluence of Apple, arguing in an 88-page lawsuit that the company had violated antitrust laws with practices that \nwere intended to keep customers reliant on their iPhones and less likely to switch to a competing device. The tech \ngiant prevented other companies from offering applications that compete with Apple products like its digital wallet, \nwhich could diminish the value of the iPhone, and hurts consumers and smaller companies that compete with it, the \ngovernment said.\nThe Justice Department’s lawsuit is seeking to put an end to those practices. The government even has the right to \nask for a breakup of the Silicon Valley icon.\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $2.75 trillion public company that was for years the most valuable on the planet. It \ntakes direct aim at the iPhone, Apple’s most popular device and most powerful business, and attacks the way the \ncompany has turned the billions of smartphones it has sold since 2007 into the centerpiece of its empire.\nBy tightly controlling the user experience on iPhones and other devices, Apple has created what critics call an \nuneven playing field, where it grants its own products and services access to core features that it denies rivals. \nOver the years, it has limited finance companies’ access to the phone’s payment chip and Bluetooth trackers from \ntapping into its location-service feature. It’s also easier for users to connect Apple products, like smartwatches and \nlaptops, to the iPhone than to those made by other manufacturers.\n“Each step in Apple’s course of conduct built and reinforced the moat around its smartphone monopoly,” the \ngovernment said in the lawsuit, which was filed in the U.S. District Court for the District of New Jersey. It added that \nthe company’s practices resulted in “higher prices and less innovation.”\nApple says these practices make its iPhones more secure than other smartphones. But app developers and rival \ndevice makers say Apple uses its power to crush competition.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\n“This lawsuit threatens who we are and the principles that set Apple products apart in fiercely competitive markets,” \nan Apple spokeswoman said. “If successful, it would hinder our ability to create the kind of technology people \nexpect from Apple — where hardware, software, and services intersect. It would also set a dangerous precedent, \nempowering government to take a heavy hand in designing people’s technology.”\nApple is the latest company the federal government has tried to rein in under a wave of antitrust pressure in recent \nyears from both the Justice Department and the Federal Trade Commission, to which the Biden administration has \nappointed heads sharply focused on changing the laws to fit the modern era. Google, Meta and Amazon are all \nfacing similar suits, and companies from Kroger to JetBlue Airways have faced greater scrutiny of potential \nacquisitions and expansion.\nThe lawsuit asks the court to stop Apple from engaging in current practices, including blocking cloud-streaming \napps, undermining messaging across smartphone operating systems and preventing the creation of digital wallet \nalternatives.\nThe Justice Department has the right under the law to ask for structural changes to Apple’s business — including a \nbreakup, said an agency official, who spoke on condition of anonymity. The official declined to identify what \nadditional action the agency could request in this case but any demands would be tied to how a court rules on the \nquestion of whether — and how — Apple broke the law.\nIt’s unclear what implications the suit — which is likely to drag out years before any type of resolution — would have \nfor consumers. Apple plans to file a motion to dismiss the case in the next 60 days. In its filing, the company plans \nto emphasize that competition laws permit it to adopt policies or designs that its competitors oppose, particularly \nwhen those designs would make using an iPhone a better experience.\nApple has effectively fought off other antitrust challenges. In a lawsuit over its App Store policies that Epic Games, \nthe maker of Fortnite, brought in 2020, Apple persuaded the judge that customers could easily switch between its \niPhone operating system and Google’s Android system. It has presented data showing that the reason few \ncustomers change phones is their loyalty to the iPhone.\nIt also has defended its business practices in the past by highlighting how the App Store, which it opened in 2008, \ncreated millions of new businesses. Over the past decade, the number of paid app makers has increased by 374 \npercent to 5.2 million, which Apple has said is a testament to a flourishing marketplace.\nEvery modern-day tech giant has faced a major federal antitrust challenge. The Justice Department is also pursuing \na case against Google’s search business and another focused on Google’s hold over advertising technology. The \nFederal Trade Commission filed a lawsuit accusing Meta, which owns Facebook, of thwarting competition when it \nbought Instagram and WhatsApp and another accusing Amazon of abusing its power over online retail. The F.T.C. \nalso tried unsuccessfully to block Microsoft from acquiring Activision Blizzard, the video game publisher.\nThe lawsuits reflect a push by the regulators to apply greater scrutiny to the companies’ roles as gatekeepers to \ncommerce and communications. In 2019, under President Donald J. Trump, the agencies opened antitrust inquiries \ninto Google, Meta, Amazon and Apple. The Biden administration has put even more energy behind the effort, \nappointing critics of the tech giants to lead both the F.T.C. and the antitrust division of the Department of Justice.\nIn Europe, regulators recently punished Apple for preventing music streaming competitors from communicating with \nusers about promotions and options to upgrade their subscriptions, levying a 1.8 billion-euro fine. App makers have \nalso appealed to the European Commission, the European Union’s executive arm, to investigate claims that Apple \nis violating a new law requiring it to open iPhones to third-party app stores.\nIn South Korea and the Netherlands, the company is facing potential fines over the fees it charges app developers \nto use alternative payment processors. Other countries, including Britain, Australia and Japan, are considering rules \nthat would undercut Apple’s grip on the app economy.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\nThe Justice Department, which began its investigation into Apple in 2019, chose to build a broader and more \nambitious case than any other regulator has brought against the company. Rather than narrowly focus on the App \nStore, as European regulators have, it focused on Apple’s entire ecosystem of products and services.\nThe lawsuit filed Thursday focuses on a group of practices that the government said Apple had used to shore up its \ndominance.\nThe company “undermines” the ability of iPhone users to message with owners of other types of smartphones, like \nthose running the Android operating system, the government said. That divide — epitomized by the green bubbles \nthat show an Android owner’s messages — sent a signal that other smartphones were lower quality than the \niPhone, according to the lawsuit.\nApple has similarly made it difficult for the iPhone to work with smartwatches other than its own Apple Watch, the \ngovernment argued. Once an iPhone user owns an Apple Watch, it becomes far more costly for them to ditch the \nphone.\nThe government also said Apple had tried to maintain its monopoly by not allowing other companies to build their \nown digital wallets. Apple Wallet is the only app on the iPhone that can use the chip, known as the NFC, that allows \na phone to tap-to-pay at checkout. Though Apple encourages banks and credit card companies to allow their \nproducts to work inside Apple Wallet, it blocks them from getting access to the chip and creating their own wallets \nas alternatives for customers.\nThe government said that Apple refuses to allow game streaming apps that could make the iPhone a less valuable \npiece of hardware or offer “super apps” that let users perform a variety of activities from one application.\nThe government’s complaint uses similar arguments to the claims it made against Microsoft decades ago, in a \nseminal lawsuit that argued the company was tying its web browser to the Windows operating system, said Colin \nKass, an antitrust lawyer at Proskauer Rose. He added that the most compelling allegation — and the one that \nbrings it closest to the Microsoft case — is that Apple could be contractually preventing rivals from developing apps \nthat work with other app providers, as “super apps” could.\nOther legal experts noted that companies are legally allowed to favor their own products and services, so the \ngovernment will have to explain why that is a problem with Apple.\n“This case is about technology,” Mr. Kass said. “Can the antitrust laws force a company to redesign its product to \nmake it more compatible with competitors’ products?”\nApple has defended itself against other antitrust challenges by arguing that its policies are critical to make its \ndevices private and secure. In its defense against Epic Games, it argued that restraining the distribution of apps \nallowed it to protect the iPhone from malware and fraud. The practice benefited customers and made the iPhone \nmore attractive than competing devices with Android’s operating system.\nThe government will try to show that the effect of Apple’s policies was to hurt consumers, not help them.\n“Competition makes devices more private and more secure,” said Jonathan Kanter, assistant attorney general of \nthe Justice Department’s antitrust division. “In many instances, Apple’s conduct has made its ecosystem less \nprivate and less secure.”\nPHOTO: Tim Cook, Apple’s chief executive. Wildly popular devices and services have turned Apple into a nearly \n$2.75 trillion public company, and it tightly controls the user experience on iPhones and other products. \n(PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (A20) This article appeared in print on page A1, A20.\nLoad-Date: March 22, 2024\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Talking to Google About A.I. for iPhone",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "810 words",
        "byline": "By Tripp Mickle, Nico Grant and Brian X. Chen",
        "story_text": "Apple Talking to Google About A.I. for iPhone\nThe New York Times\nMarch 20, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 810 words\nByline: By Tripp Mickle, Nico Grant and Brian X. Chen\nBody\nA partnership would extend the long relationship between the companies that has helped deliver everything from \nmaps to search on Apple's devices.\nApple is in discussions with Google about using the search giant's generative artificial intelligence model called \nGemini for its next iPhone, as the company races to embrace a technology that has upended the tech industry. \n  The talks are preliminary and the exact scope of a potential deal hasn't been defined, three people with knowledge \nof the discussions said. Apple has also held discussions with other A.I. companies, one of these people said, as it \nlooks to tap into the power of a large language model capable of analyzing vast amounts of data and generating \ntext on its own.\n  Tim Cook, Apple's chief executive, has promised investors that the company will introduce new generative A.I. \ncapabilities this year. The company's smartphone rivals, Samsung and Google, have already added Gemini to their \nnewest devices to edit videos and summarize audio recordings.\n  Apple and Google declined to comment. Bloomberg reported earlier on their talks.\n  An Apple-Google deal on generative A.I. would extend one of technology's most longstanding partnerships. Since \nApple introduced the iPhone in 2007, Google has been a critical contributor to the device's success. It initially \nprovided Google Maps for navigation and the default search engine on the iPhone's Safari browser, now a lucrative \nagreement for which Google pays Apple more than $18 billion a year. \n  Google's discussions to provide generative A.I. capabilities for the iPhone would be the latest example of its filling \na gap in Apple's products. Apple's effort to develop its own large language model, the technology behind chatbots \nlike ChatGPT and Gemini, has been running behind, two people familiar with its development said.\n  Apple's delay in releasing an A.I. product has been costly. After a decade-long run as the world's most valuable \npublic company, it was dethroned this year by Microsoft, which has aggressively pursued A.I. The technology has \nbeen heralded for its potential to disrupt businesses and create trillions of dollars in economic value.\n  Despite its delays, Apple has the potential to be a big player in A.I. The company has more than two billion \ndevices actively in use, making it an attractive partner for Google and others. Its reputation for protecting customers' \nprivate information could also be helpful in a future where A.I. services help manage people's calendars or health \ndata.\nApple Talking to Google About A.I. for iPhone\n  A deal could bring the Gemini model to iPhones around the world, giving Google access to a massive user base \nand making generative A.I. even more mainstream. Virtually overnight, Google could have more consumers using \nits A.I. than its chief rival, OpenAI, which makes ChatGPT -- making a pact with Apple a tantalizing prospect.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  Apple's selecting Google as an A.I. supplier would be a crucial vote of confidence in the search giant after a \nnumber of setbacks to its A.I. ambitions. The company's first A.I. chatbot, Bard, debuted to middling reviews last \nMarch and struggled to attract as many users as ChatGPT.\n  In February, Google debuted a new chatbot, Gemini. The chatbot ran into problems last month when users found \nthat its image generator produced illustrations of historical figures that were not racially accurate and refused in \nmost instances to generate images of white people, leading to accusations of bias. Google disabled the ability to \ncreate images of people and vowed to fix the problem.\n  In a note on Tuesday, a Bernstein Research analyst, Toni Sacconaghi, called an Apple-Google deal a ''win-win,'' \ngiving Apple generative A.I. for iPhones and validating Google's work on Gemini. He also said Apple didn't have to \nown an A.I. model on iPhones to profit from it and could instead take a commission from Google, which currently \ncharges $19.99 per month for its Gemini Advanced app.\n  Companies haven't yet cashed in on generative A.I. The costs associated with running large language models in \nthe cloud are staggering, and consumers and business customers are only starting to pay for the emerging \ntechnology. But they are optimistic that profits will increase as the capabilities of A.I. systems improve and the costs \ndecline for building the data centers to power the systems.\n  A new deal between Apple and Google could draw scrutiny from U.S. regulators. The Justice Department is in the \nfinal stages of a lawsuit against Google for harming competition by paying Apple to be the default search engine on \nthe iPhone and other services. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict this year.\nGraphic\n \nPHOTO: A deal to provide A.I. capabilities for the iPhone would be the latest example of Google filling a gap in \nApple's products. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES) This article \nappeared in print on page B5.               \nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "especially_in_communities_of_color._The_state_must_step_in._Mar2024",
        "header": "Preventing a voter disinformation crisis; AI is turbocharging disinformation,",
        "media": "especially in communities of color. The state must step in.",
        "time": "March 22, 2024",
        "section": "MAIN NEWS; Opinion Desk; Part A; Pg. 1",
        "length": "852 words",
        "byline": "Bill Wong, Mindy Romero, Bill Wong is a campaign strategist and the author of \"Better to Win: Hardball",
        "story_text": "Preventing a voter disinformation crisis; AI is turbocharging disinformation, \nespecially in communities of color. The state must step in.\nLos Angeles Times\nMarch 22, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Opinion Desk; Part A; Pg. 1\nLength: 852 words\nByline: Bill Wong, Mindy Romero, Bill Wong is a campaign strategist and the author of \"Better to Win: Hardball \nLessons in Leadership, Influence, & the Craft of Politics.\" Mindy Romero is a political sociologist and the director of \nthe Center for Inclusive Democracy at the USC Price School of Public Policy.\nBody\nAs the general election campaign begins in earnest, we can expect disinformation attacks to target voters, \nespecially in communities of color. This has happened before: In 2016, for example, Russia's disinformation \nprograms zeroed in on Black Americans, creating Instagram and Twitter accounts that masqueraded as Black \nvoices and producing fake news websites such as blacktivist.info, blacktolive.org and blacksoul.us.\nAdvances in technology will make these efforts harder to recognize. Envision those same fake accounts and \nwebsites featuring hyper-realistic videos and images intended to sow racial division and mislead people about their \nvoting rights. With the advent of generative artificial intelligence, that is possible at little to no cost, turbocharging \nthe kind of disinformation that has always targeted communities of color.\nIt's a problem for candidates, election offices and voter outreach groups in the months ahead. But voters \nthemselves will ultimately have to figure out what is real news or fake news, authentic or AI-generated.\nFor immigrants and communities of color -- who often face language barriers, distrust democratic systems and lack \ntechnology access -- the challenge is likely to be more significant. Across the nation, and especially in states such \nas California with large communities of immigrants and people with limited knowledge of English, the government \nneeds to help these groups identify and avoid disinformation,\nAsian Americans and Latinos are particularly vulnerable. About two-thirds of the Asian American and Pacific \nIslander population are immigrants, and a Pew Research Center report states that \"[86%] of Asian immigrants 5 \nand older say they speak a language other than English at home.\" The same dynamics hold true for Latinos: Only \n38% of the U.S. foreign-born Latino population reports being proficient in English.\nTargeting non-English-speaking communities has several advantages for those who would spread disinformation. \nThese groups are often cut off from mainstream news sources that have the greatest resources to debunk \ndeepfakes and other disinformation, preferring online engagement in their native languages, where moderation and \nfact-checking are less prevalent.\nForty-six percent of Latinos in the U.S. use WhatsApp, while many Asian Americans prefer WeChat. Wired \nmagazine reported that the platform \"is used by millions of Chinese Americans and people with friends, family, or \nbusiness in China, including as a political organizing tool.\"\nPreventing a voter disinformation crisis AI is turbocharging disinformation, especially in communities of color. \nThe state must step in.\nDisinformation aimed at immigrant communities is poorly understood and difficult to track and counteract, yet it is \ngetting easier and easier to create. In the past, producing false content in non-English languages required intensive \nwork from humans and was often low in quality. Now, AI tools can create hard-to-track, in-language disinformation \nat lightning speed and without the vulnerabilities and scaling problems posed by human limitations. Despite this, \nmuch research on misinformation and disinformation concentrates on English-language uses.\nAttempts to target communities of color and non-English speakers with disinformation are aided by many \nimmigrants' heavy reliance on their mobile phones for internet access. Mobile user interfaces are particularly \nvulnerable to disinformation because many desktop design and branding elements are minimized in favor of content \non smaller screens. With 13% of Latinos and 12% of African Americans dependent on mobile devices for \nbroadband access, in contrast to 4% of white smartphone owners, they are more likely to receive -- and share -- \nfalse information.\nSocial media companies' past efforts to counter voter disinformation have fallen short. Meta's February \nannouncement that it would flag AI-generated images on Facebook, Instagram and Threads is a positive but minor \nstep toward stemming AI-generated disinformation, especially for ethnic and immigrant communities who may know \nlittle about its effects. Clearly, a stronger government response is needed.\nThe California Initiative for Technology and Democracy, or CITED, where we serve on the board of directors, will \nsoon unveil a legislative package that would require broader transparency for generative AI content, making sure \nusers of social media know what video, audio and images were made by AI tools. The bills would also require \nlabeling of AI-assisted political disinformation on social media, prohibit campaign ads close to an election from \nusing the technology and restrict anonymous trolls and bots.\nIn addition, CITED plans to hold a series of community forums around California with partner organizations rooted \nin their regions. The groups will speak directly to leaders in communities of color, labor leaders, local elected \nofficials and other trusted messengers about the dangers of false AI-generated information likely to be circulating \nthis election season.\nThe hope is that this information will be relayed at the community level, making voters in the state more aware and \nskeptical of false or misleading content, building trust in the election process, election results and our democracy.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "Essay_Mar2024",
        "header": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest",
        "media": "Essay",
        "time": "March 22, 2024",
        "section": "OPINION",
        "length": "1174 words",
        "byline": "Graciela Mochkofsky",
        "story_text": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest \nEssay\nThe New York Times - International Edition\nMarch 23, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: OPINION\nLength: 1174 words\nByline: Graciela Mochkofsky\nBody\nABSTRACT\nWe need mission-driven, imaginative news leaders who are not bound by the models of the past.\nFULL TEXT\nMany uncertainties haunt the field of journalism today - among them, how we can reach our audience, build public \ntrust in our work, and who is going to pay for it all. But one thing is certain: as complicated and dark as the world \nlooks today, it would be much worse if journalists were not there to report on it.       \nResearch shows that towns that have lost sources of local news tend to suffer from lower voter turnout, less civic \nengagement and more government corruption. Journalists are essential just as nurses and firefighters and doctors \nare essential.       \nAnd to continue to have journalists, we need to make their journalism education free.       \nThis might sound counterintuitive given the state of the industry. Shrinking revenue and decreasing subscription \nfigures have led to a record number of newsroom jobs lost. Much of the local news industry has fallen into the \nhands of hedge funds focused on squeezing the last drops of revenue out of operations by decimating them. \nBillionaires who appeared as saviors just a few years ago have grown tired of losing money on the media \norganizations they bought. Public trust in the value of news is at historical lows, while a growing percentage of \npeople are avoiding the news altogether.       \nGenerative artificial intelligence, which is on the verge of reshaping almost everything around us, is bringing yet \nanother technological disruption to the industry. Against this grim backdrop, authoritarian leaders are increasingly \ntargeting journalists as political enemies both at home and abroad.       \nAnd yet there are still tens of thousands of jobs in news media in America, with exceptional journalism being \nproduced every day. Some major organizations have even found ways to thrive in the digital age. Prominent \nfoundation leaders have started an effort to pour hundreds of millions of philanthropic dollars into local journalism, \nand a movement has formed to push for federal and local legislation to direct public funding to news. An initiative to \nreplant local news has founded dozens of nonprofit newsrooms in cities around the country. And a small but \ngrowing number of organizations are redefining the way news agendas are set, focusing on rebuilding public trust \nwithin small communities.       \nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nNo matter how the news industry evolves, we will continue to need journalists. Successful business models for \nmedia are necessary, but the most crucial element for strong, independent journalism is the people who make it. \nGiven the present stakes in the industry, our society and the world, we need mission-driven, imaginative news \nleaders who are not bound by the models of the past, who have the motivation and freedom to reimagine the field, \nand the empathy and commitment to serve the public interest, undaunted by attacks and threats.       \nWe must also move beyond the lack of economic and demographic diversity that has long been a problem in the \nindustry. News has too often been reported by predominantly middle-class, white, male journalists, resulting in \ncoverage that has repeatedly missed the issues that are most important to the people receiving the news, \ncontributing to the public's lack of trust in the media.       \nIn a resource-starved industry, few newsrooms can offer the type of mentoring, guidance and time that it takes to \nshape a great journalist. This is now primarily the responsibility of journalism schools. It is the civic duty of these \nschools to find and train reporters and news leaders, instill in them an ethical foundation, help develop their critical \nthinking skills, allow them to try and fail in a safe environment, open doors and provide a support network. \n(Journalism schools should also contribute research in a variety of areas, from the impact of A.I. to new business \nmodels to identifying and responding to emerging threats.)       \nBut the cost of a journalism education has become an insurmountable barrier for exactly the kind of people we need \nthe most. And those who, with great effort, manage to overcome that barrier, carry a weight that could limit their \nprofessional options.       \nReporters burdened with debt are less likely to take professional risks and more likely to abandon the field. \nAccording to the Bureau of Labor Statistics, the median reporter salary in America is less than $56,000 a year, or \nabout $27 per hour. In low-income areas, where news deserts are more prevalent, annual salaries can be as low as \n$20,000. A Wall Street Journal report about the debt-to-income ratio of alumni of 16 journalism masters programs \nfound that many graduates leave with debts that exceed their postgraduate income.       \nAs the dean of the Craig Newmark Graduate School of Journalism at the City University of New York, I can tell you \nthat half measures won't solve this quandary. My school was founded in 2006 as a public alternative to elite \njournalism schools in the city and it remains one of the most affordable in the nation.       \nOur in-state students pay about a quarter of the cost of an equivalent degree from top-tier schools with which we \nsuccessfully compete. This year alone, 90 percent of our students are on scholarships, and a record 25 percent are \nattending tuition-free. We also waived the $75 application fee this admission cycle and saw an increase of more \nthan 40 percent in our applicant pool.       \nThanks to these policies, we have succeeded where the media industry keeps failing. Over 50 percent of our \nstudents are people of color and from underserved communities. Many couldn't have attended our school if we \nhadn't offered significant scholarship support. But that's not enough. Though we rank as one of the journalism \nschools with higher-medium-income and lower-median-debt alumni, our students still don't graduate fully debt-free.       \nThis is why this year, we began a campaign to go fully tuition-free by 2027. While other schools might face different \nfinancial challenges, we hope that many more will follow us.       \nWe need journalists whose only obligations are to the facts and the society they serve, not to lenders; who are \nconcerned with the public interest, not with interest rates; who can make risky decisions and take the difficult path if \nthat's what the mission requires, free of financial burden. Journalism schools can help achieve that. In tough times, \nit is natural to mourn the past or lament the present, but what we really need is bold action.       \nGraciela Mochkofsky is the dean at CUNY's Craig Newmark Graduate School of Journalism. She is the author, \nmost recently, of \"The Prophet of the Andes: An Unlikely Journey to the Promised Land.\"       \nThe Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com.\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "Section ; Column 0; Business/Financial Desk",
        "length": "1090 words",
        "byline": "By Paul Mozur and Cade Metz",
        "story_text": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent\nThe New York Times\nMarch 22, 2024 Friday\nThe New York Times on the Web\nCopyright 2024 The New York Times Company\nSection: Section ; Column 0; Business/Financial Desk\nLength: 1090 words\nByline: By Paul Mozur and Cade Metz\nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.\nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead. \n  New research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world's top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.\n  The findings show a jump for China, which produced about one-third of the world's top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022's Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.\n  The talent imbalance has been building for the better part of a decade. During much of the 2010s, the United \nStates benefited as large numbers of China's top minds moved to American universities to complete doctoral \ndegrees. A majority of them stayed in the United States. But the research shows that trend has also begun to turn, \nwith growing numbers of Chinese researchers staying in China.\n  What happens in the next few years could be critical as China and the United States jockey for primacy in A.I. -- a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation -- turning the \nresearchers into one of the most geopolitically important groups in the world.\n  Generative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China's researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.\n  (The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\n  China has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.\n  ''A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that's come to dominate the American A.I. industry at the moment,'' he said.\n  While the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.\n  Researchers originally from China now make up 38 percent of the top A.I. researchers working in the United \nStates, with Americans making up 37 percent, according to the research. Three years earlier, those from China \nmade up 27 percent of top talent working in the United States, compared with 31 percent from the United States.\n  ''The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,'' said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.\n  He added that the data seemed to show the United States was still attractive. ''We're the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,'' he said.\n  Pieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.\n  ''It's just a natural state of affairs,'' he said.\n  In the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.\n  Despite bans introduced by the Trump administration that prohibit entry to the United States for students from \nsome military-linked universities in China and a relative slowdown in the flow of Chinese students into the country \nduring Covid, the research showed large numbers of the most promising A.I. minds continued coming to the United \nStates to study.\n  But this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology -- including critical microchip architecture -- to a Beijing-based company that paid him in secret, \naccording to a federal indictment.\n  The substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.\n  ''Chinese scholars are almost leading the way in the A.I. field,'' said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are ''shooting themselves in the foot.''\n  The track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.\n  For now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world's top talent, down from about 59 percent three years ago, according to the research.\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nhttps://www.nytimes.com/2024/03/22/technology/in-one-key-ai-metric-china-pulls-ahead-of-the-us-talent.html\nGraphic\n \nPHOTO: The World Artificial Intelligence Conference in Shanghai in July 2023. China has invested heavily in A.I. \neducation. (PHOTOGRAPH BY Agence France-Presse -- Getty Images FOR THE NEW YORK TIMES)               \nLoad-Date: March 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Finding Sprouts of Hope In a Gloomy Media Era",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1336 words",
        "byline": "By Katie Robertson and Benjamin Mullin",
        "story_text": "Finding Sprouts of Hope In a Gloomy Media Era\nThe New York Times\nMarch 23, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1336 words\nByline: By Katie Robertson and Benjamin Mullin\nBody\nThis year is looking grim for the news business.\nFacing a set of harsh financial realities -- resulting from a mix of news fatigue, an unsteady advertising market and a \nprecipitous fall in traffic from tech giants -- many outlets have been forced to fold or make significant cuts in recent \nmonths. \n  But there are some signs of hope. A small cohort of for-profit digital media companies that sprang up during the \npandemic have found success -- at least for the moment -- by taking the opposite approach of many predecessors, \nsuch as BuzzFeed and Vice, which fatefully relied on huge amounts of investor money to prioritize growth.\n  The new class of news start-ups -- Puck, Punchbowl News, The Ankler and Semafor are among the most \nprominent -- have kept spending down and hired carefully. They are all centered on newsletters covering specific \nniches with broad appeal. They have attracted top journalists by putting them at the heart of the enterprise, \nsometimes as part owners in the companies.\n  ''There was possibly a mismatch 10 or 15 years ago between funding structures and media companies,'' said Jon \nKelly, the co-founder and editor in chief of Puck, whose 14 reporters write about topics including politics, finance \nand media. ''And I think that the entire industry has learned from that.''\n  These start-ups exemplify a shift in the conventional wisdom about how to make money in digital publishing. A \ndecade or so ago, many venture capitalists and top media executives thought the then-rising class of digital start-\nups might eventually dominate the industry. The big influx of investor money was put toward chasing the biggest \naudience possible.\n  But traffic from social media giants like Facebook and Twitter dropped, and the economics of digital ads didn't add \nup. Predictions of supplanting traditional TV networks or sprawling print empires never came to pass. The most \nrecent outlet to try this playbook, The Messenger, folded in January, fewer than nine months after it launched.\n  The formula embraced by the new start-ups is instead sustainable growth built on a mix of revenue sources, \nincluding ads, paid subscriptions and sponsored events. Instead of trying to reach everybody on the internet, they \nhave kept more narrow lanes of coverage and targeted high-income readers, following a path more similar to the \n10-year-old tech website The Information or the politics outlet Politico.\n  ''What all of them have in common is this intense need to serve specific audiences rather than to serve \neverybody,'' said Jacob Cohen Donnelly, the founder of A Media Operator, a newsletter about the media business.\nFinding Sprouts of Hope In a Gloomy Media Era\n  Some of the other new companies finding early traction include publications on the newsletter platform Substack, \nsuch as The Free Press and The Bulwark, which have attracted tens of thousands of paid subscribers. Several \nworker-owned publications, like Defector and Hell Gate, are showing promise. And some older digital outlets, like \nVox Media, have survived by expanding into businesses such as podcasting, and cutting costs.\n  Punchbowl News, started in 2021 by three former Politico reporters, aggressively covers Congress and has \nbecome ''the hometown newspaper of Capitol Hill in a lot of ways,'' said Anna Palmer, a founder and the chief \nexecutive. Now with 30 employees, Punchbowl publishes three newsletters a day and has added coverage of the \nfinancial services industry. It is looking to expand into other policy areas.\n  ''What we have really focused on is not being something that people might find interesting, but that they actually \nneed to be able to do their job,'' she said.\n  Punchbowl offers its morning newsletter for free, while a subscription to its other newsletters is $350 a year. \nAccess to Punchbowl's policy reporting starts at $1,200 a year. The model is akin to Politico Pro (which starts at the \nlow five-figures per year), Axios Pro ($599 a year) and The Information Pro ($999 a year), the premium offerings \nfrom those websites.\n  Ms. Palmer said Punchbowl had been profitable since its first year and generated $20 million in revenue in 2023, \nthough she declined to discuss subscription figures. A person with knowledge of Punchbowl's finances said that in \nthe first two months of this year, the company had already booked 90 percent of its annual newsletter sponsorship \ngoal.\n  The Ankler, a paid newsletter focused on Hollywood, is anchored by Richard Rushfield, an entertainment journalist \nwho has emerged as Hollywood's unsparing gadfly, narrating the industry's unending chaos and skewering the \nactors, agents and executives responsible for creating it.\n  Ankler Media has raised $1.3 million at a valuation of $20 million and has been profitable for more than a year, \nsaid Janice Min, the company's chief executive and founder, who previously helmed The Hollywood Reporter and \nUs Weekly. The Ankler now has seven employees and publishes several newsletters, including Wake Up, a \nHollywood news digest.\n  ''If we want to make a Hollywood analogy, it's like these growing franchises are multiverses,'' Ms. Min said. \n''People like what we do and see our newsletters as an extension of the voice that might have drawn them in in the \nbeginning.''\n  Semafor is the largest of the group, with about 75 employees and ambitions to provide global news. But the \ncompany is charting a careful path, said Justin Smith, one of the founders and its chief executive.\n  Semafor launched in late 2022, with 30 to 40 percent fewer employees than its original business plan had called \nfor, Mr. Smith said. The company decided to start smaller as interest rates were creeping up and the economic \noutlook was darkening.\n  ''The pandemic really marked the transition from the social media era to what we call the post-social media era,'' \nMr. Smith said, noting that outlets must now focus on direct relationships with their audience.\n  For Semafor, that has meant committing to newsletters centered on a handful of topics, as well as the geographic \nareas of the United States and sub-Saharan Africa. Semafor now has more than 650,000 unpaid newsletter \nsubscriptions, according to a spokeswoman. The outlet is hiring for an editor in the Middle East and plans to add a \nnewsletter focused on the region.\n  The company generates revenue from advertising and events, and has a sponsorship deal with Microsoft for a \nglobal elections tracker and a news feed aided by generative artificial intelligence. Mr. Smith declined to share \nspecific financial figures for the company but said it had a couple of profitable months in the last six months of 2023.\nFinding Sprouts of Hope In a Gloomy Media Era\n  Of course, nothing in media lasts forever -- particularly in the fast-changing digital world. So there's no guarantee \nthat the early success of these companies will translate into sustained growth.\n  Many of these start-ups are also taking a somewhat risky bet on talent.\n  At Puck, the start-up that covers topics including entertainment and finance, early hires such as Matt Belloni, who \nis a definitive chronicler of modern Hollywood, and Julia Ioffe, who has established herself as a must-read on \nRussian politics, are ''founding partners.'' In addition to a salary, they receive bonuses based on the number of \npeople who subscribe to their email newsletters and how many of them stick around. New employees also get a \nsmall ownership stake in the company.\n  Puck, which has about 40 employees, now has roughly 40,000 paid subscribers. Shortly after the company \nlaunched, Mr. Belloni accounted for about 30 percent of paid subscribers, according to a person with knowledge of \nthe figures.\n  If one or more of the star journalists leave the publication, would Puck's subscribers follow?\n  Mr. Kelly said he didn't ''want to even contemplate a world'' in which one of Puck's journalists exited.\n  ''We made a promise to everyone: You will do the best work of your career here, and we will find a way to make \nsure that you are valued for it,'' Mr. Kelly said. ''And I really think that our model is actually becoming one of the \nmoats of our business.''\nhttps://www.nytimes.com/2024/03/12/business/media/digital-media-new-startups-business-model.html\nGraphic\n \nPHOTO: Punchbowl News has become ''the hometown newspaper of Capitol Hill in a lot of ways,'' its chief \nexecutive said. (PHOTOGRAPH BY CHIP SOMODEVILLA/GETTY IMAGES) (B3) This article appeared in print on \npage B1, B3.               \nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "China Rises As Producer Of Talent In A.I. Field",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1090 words",
        "byline": "By Paul Mozur and Cade Metz",
        "story_text": "China Rises As Producer Of Talent In A.I. Field\nThe New York Times\nMarch 23, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1090 words\nByline: By Paul Mozur and Cade Metz\nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.\nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead. \n  New research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world's top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.\n  The findings show a jump for China, which produced about one-third of the world's top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022's Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.\n  The talent imbalance has been building for the better part of a decade. During much of the 2010s, the United \nStates benefited as large numbers of China's top minds moved to American universities to complete doctoral \ndegrees. A majority of them stayed in the United States. But the research shows that trend has also begun to turn, \nwith growing numbers of Chinese researchers staying in China.\n  What happens in the next few years could be critical as China and the United States jockey for primacy in A.I. -- a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation -- turning the \nresearchers into one of the most geopolitically important groups in the world.\n  Generative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China's researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.\n  (The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)\nChina Rises As Producer Of Talent In A.I. Field\n  China has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.\n  ''A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that's come to dominate the American A.I. industry at the moment,'' he said.\n  While the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.\n  Researchers originally from China now make up 38 percent of the top A.I. researchers working in the United \nStates, with Americans making up 37 percent, according to the research. Three years earlier, those from China \nmade up 27 percent of top talent working in the United States, compared with 31 percent from the United States.\n  ''The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,'' said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.\n  He added that the data seemed to show the United States was still attractive. ''We're the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,'' he said.\n  Pieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.\n  ''It's just a natural state of affairs,'' he said.\n  In the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.\n  Despite bans introduced by the Trump administration that prohibit entry to the United States for students from \nsome military-linked universities in China and a relative slowdown in the flow of Chinese students into the country \nduring Covid, the research showed large numbers of the most promising A.I. minds continued coming to the United \nStates to study.\n  But this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology -- including critical microchip architecture -- to a Beijing-based company that paid him in secret, \naccording to a federal indictment.\n  The substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.\n  ''Chinese scholars are almost leading the way in the A.I. field,'' said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are ''shooting themselves in the foot.''\n  The track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.\n  For now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world's top talent, down from about 59 percent three years ago, according to the research.\nChina Rises As Producer Of Talent In A.I. Field\nhttps://www.nytimes.com/2024/03/22/technology/china-ai-talent.html\nGraphic\n \nPHOTO: A camera using artificial intelligence at a coal mine in Heze, China. Beijing has invested heavily in A.I. \neducation. (PHOTOGRAPH BY MARK R CRISTINO/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in \nprint on page B1, B4.               \nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "TECHNOLOGY",
        "length": "1119 words",
        "byline": "Paul Mozur and Cade Metz Paul Mozur is the global technology correspondent for The Times, based in",
        "story_text": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent\nThe New York Times \nMarch 22, 2024 Friday 12:28 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1119 words\nByline: Paul Mozur and Cade Metz Paul Mozur is the global technology correspondent for The Times, based in \nTaipei. Previously he wrote about technology and politics in Asia from Hong Kong, Shanghai and Seoul. Cade Metz \nwrites about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.\nHighlight: China has produced a huge number of top A.I. engineers in recent years. New research shows that, by \nsome measures, it has already eclipsed the United States.\nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.\nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead.\nNew research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world’s top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.\nThe findings show a jump for China, which produced about one-third of the world’s top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022’s Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.\nThe talent imbalance has been building for the better part of a decade. During much of the 2010s, the United States \nbenefited as large numbers of China’s top minds moved to American universities to complete doctoral degrees. A \nmajority of them stayed in the United States. But the research shows that trend has also begun to turn, with growing \nnumbers of Chinese researchers staying in China.\nWhat happens in the next few years could be critical as China and the United States jockey for primacy in A.I. — a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation — turning the \nresearchers into one of the most geopolitically important groups in the world.\nGenerative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China’s researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.\n(The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nChina has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.\n“A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that’s come to dominate the American A.I. industry at the moment,” he said.\nWhile the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.\nResearchers originally from China now make up 38 percent of the top A.I. researchers working in the United States, \nwith Americans making up 37 percent, according to the research. Three years earlier, those from China made up 27 \npercent of top talent working in the United States, compared with 31 percent from the United States.\n“The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,” said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.\nHe added that the data seemed to show the United States was still attractive. “We’re the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,” he said.\nPieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.\n“It’s just a natural state of affairs,” he said.\nIn the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.\nDespite bans introduced by the Trump administration that prohibit entry to the United States for students from some \nmilitary-linked universities in China and a relative slowdown in the flow of Chinese students into the country during \nCovid, the research showed large numbers of the most promising A.I. minds continued coming to the United States \nto study.\nBut this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology — including critical microchip architecture — to a Beijing-based company that paid him in secret, \naccording to a federal indictment.\nThe substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.\n“Chinese scholars are almost leading the way in the A.I. field,” said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are “shooting themselves in the foot.”\nThe track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.\nFor now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world’s top talent, down from about 59 percent three years ago, according to the research.\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nPHOTO: A camera using artificial intelligence at a coal mine in Heze, China. Beijing has invested heavily in A.I. \neducation. (PHOTOGRAPH BY MARK R CRISTINO/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in \nprint on page B1, B4.\nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Mar2024",
        "header": "LOTS OF TALK BUT LITTLE ACTION ON AI BILLS IN PA. LEGISLATURE",
        "media": "Pittsburgh Post-Gazette",
        "time": "March 24, 2024",
        "section": "LOCAL; Pg. C-3",
        "length": "731 words",
        "byline": "Ford Turner Pittsburgh Post-Gazette",
        "story_text": "LOTS OF TALK BUT LITTLE ACTION ON AI BILLS IN PA. LEGISLATURE\nPittsburgh Post-Gazette\nMarch 24, 2024 Sunday\nTWO STAR EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: LOCAL; Pg. C-3\nLength: 731 words\nByline: Ford Turner Pittsburgh Post-Gazette\nBody\nHARRISBURG - With the state House and Senate back in action simultaneously last week for the first time in \nmonths, there is considerable talk but little action on bills that could stymie harmful uses of artificial intelligence, or \nAI.\nThe bills involve concerns like visual \"deepfakes,\" the use of AI in child porn and consumer awareness that AI has \nbeen used in making products. A growing number of states are passing bills on AI, and Pennsylvania lawmakers \nhave introduced at least nine bills this session involving AI, but none has gained significant traction.\nOpinions on the lack of progress vary.\nRepublican Tracy Pennycuick, of Montgomery County, who heads a Senate Committee that is likely to consider \nsome of the bills, said lawmakers are being cautious. Any AI bill that moves forward should be a \"good quality \nproduct\" that will not have to be revised in the near future, she said.\nBut Sen. Lisa Boscola, D-Northampton, thinks many lawmakers are more concerned with election posturing than \npushing forward bills that likely will have bipartisan support. Ms. Boscola said families have concerns about AI, and \nlegislation intended to improve its use will pass both chambers.\n\"AI should be one of the areas where Democrats and Republicans get together and do something,\" Ms. Boscola \nsaid.\nAt least one estimate has projected the generative AI market will grow to $1.3 trillion within a decade. A high-profile \nexample of AI lawmaking came March 13, when the European Union gave approval to an AI law for the 27-nation \nbloc. It bans various uses including police scanning of faces in public using AI-powered remove \"biometric \nidentification\" systems, except for serious crime like kidnapping or terrorism.\nGrace Gedye, an AI policy analyst for Consumer Reports, said a lot of lawmakers are introducing bills across the \ncountry. \"The sense of activity is promising,\" she said.\nThe lag in making laws for AI that is already in use, Ms. Gedye said, brings to mind the lag that followed the surge \nin collection of personal data by internet companies. \"It took years to get states to start passing privacy legislation,\" \nshe said.\nMs. Gedye said AI companies are lobbying state lawmakers, both openly and behind closed doors. Their \narguments, she said, sometimes include statements that proposed laws \"might kill the industry\" or that the \nproposed laws require things that are technically impossible.\nLOTS OF TALK BUT LITTLE ACTION ON AI BILLS IN PA. LEGISLATURE\nSuch pushback, she said, must be taken with a grain of salt. \"Those claims should be given due diligence at least \nby people who don't have a monied interest,\" Ms. Gedye said.\nA spokesperson for the Pennsylvania District Attorneys Association, Berks County District Attorney John Adams, \nsaid the association supports a pair of bills that would add the phrase \"artificially generated child sexual abuse \nmaterial\" to state law's definitions of child pornography. One was referred to House committee in October, and the \nother - recently introduced by Ms. Boscola - was referred to a Senate committee last month.\n\"This is another example of our laws not keeping up with technology,\" Mr. Adams said. \"Historically, we have seen \nthat it takes too long for our legislators to act on technology, and changes in technology.\"\nState Rep. Chris Pielli, D-Chester and sponsor of the bill awaiting consideration by the House Judiciary Committee, \nsaid its point is to provide complete clarity in an AI-related child porn case so \"we have a tight statute to prosecute \nwith.\"\nAsked about the multi-month wait for action, Mr. Pielli said, \"It is difficult for me to understand why there is \nhesitation.\" One sentiment he has heard, he said, is the bill is the sort that is \"creating new crimes\" while another is \nthat an uninformed juvenile experimenting with an AI program might be unfairly implicated.\nMr. Pielli said he is working on tweaks to his bill with other lawmakers.\nMs. Boscola's bill is similar to Mr. Pielli's, but it also includes a section that allows for lawsuits to be filed against AI \nchild sex abuse image creators by parents of minors.\nAnother bill sponsored by Mr. Pielli would require disclosure to consumers that AI has been used to create a \nproduct. That bill has been awaiting action in the House Consumer Protection, Technology and Utilities Committee \nsince August.\n\"If it is AI, it has got to say 'AI,' \" Mr. Pielli said. \"People need to know what they are looking at, and whether it is real \nor not.\"\nGraphic\n \nPHOTO: Pittsburgh Post-Gazette: The dome on the Pennsylvania State Capitol Building in Harrisburg.\nPHOTO: Ford Turner/Post-Gazette: Sen. Lisa Boscola, D-Northampton: \"AI should be one of the areas where \nDemocrats and Republicans get together and do something.\"\nPHOTO: Ford Turner/Post-Gazette: Sen. Lisa Boscola, D-Northampton: \"AI should be one of the areas where \nDemocrats and Republicans get together and do something.\"\nLoad-Date: March 24, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "E.U. Takes Aim at Alphabet, Apple and Meta in Wide-Ranging Investigations",
        "media": "The New York Times",
        "time": "March 25, 2024",
        "section": "BUSINESS",
        "length": "1020 words",
        "byline": "Adam Satariano and Tripp Mickle Adam Satariano is a technology correspondent based in Europe, where",
        "story_text": "E.U. Takes Aim at Alphabet, Apple and Meta in Wide-Ranging Investigations\nThe New York Times \nMarch 25, 2024 Monday 22:36 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1020 words\nByline: Adam Satariano and Tripp Mickle Adam Satariano is a technology correspondent based in Europe, where \nhis work focuses on digital policy and the intersection of technology and world affairs. Tripp Mickle reports on Apple \nand Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes product launches, \nmanufacturing issues and political challenges. He also writes about trends across the tech industry, including \nlayoffs, generative A.I. and robot taxis.\nHighlight: The inquiries signal the bloc’s intention to tightly enforce sweeping new competition rules that took effect \nthis month.\nBody\nThe inquiries signal the bloc’s intention to tightly enforce sweeping new competition rules that took effect this \nmonth.\nAlphabet, Apple and Meta were told by European Union regulators on Monday that they were under investigation \nfor a range of potential violations of the region’s new competition law.\nThe inquiries are the first that regulators have announced since the Digital Markets Act took effect on March 7, and \nthey signal the bloc’s intention to tightly enforce the sweeping competition rules. The law requires Alphabet, Apple, \nMeta and other tech giants to open up their platforms so smaller rivals can have more access to their users, \npotentially affecting app stores, messaging services, internet search, social media and online shopping.\nThe investigations in Brussels add to the regulatory scrutiny facing the largest tech companies and show growing \nalignment between the United States and Europe on the need to crack down on the firms for anticompetitive \nbehavior.\nLast week in Washington, the Justice Department sued Apple for breaking antitrust laws with practices that were \nintended to keep customers reliant on their iPhones and less likely to switch to a competing device. Amazon, \nGoogle and Meta are also facing federal antitrust lawsuits.\nE.U. investigators said they wanted to study whether Apple and Alphabet, the parent company of Google, were \nunfairly favoring their own app stores to box out rivals, particularly restrictions that limit how app developers can \ncommunicate with customers about sales and other offers. Google is also being investigated over the display of \nsearch results in Europe, while Meta will be questioned about a new ad-free subscription service and the use of \ndata for selling advertising.\nThe European Commission, the European Union’s executive arm, can fine the companies up to 10 percent of their \nglobal revenue, which for each runs into the hundreds of billions of dollars annually. The commission has 12 \nmonths to complete its investigations.\nThe companies had already announced a number of changes to their products, services and business practices to \ntry to comply with the Digital Markets Act. But in announcing the investigations on Monday, regulators said their \nchanges did not go far enough.\nE.U. Takes Aim at Alphabet , Apple and Meta in Wide-Ranging Investigations\n“Certain compliance measures fail to achieve their objectives and fall short of expectations,” said Margrethe \nVestager, the European Commission’s executive vice president, who announced the investigations at a news \nconference in Brussels. Compliance with the law, she said, “is something that we take very seriously.”\nThe investigations announced on Monday intensify a yearslong campaign by European regulators to loosen the grip \nof the biggest tech companies on the digital economy. This month, Ms. Vestager announced a 1.85 billion-euro ($2 \nbillion) fine against Apple for unfair business practices related to the App Store. Amazon, Google and Meta have \nalso been subject to E.U. investigations.\nIn an interview last month, Ms. Vestager said the United States and the European Union were more closely aligned \nnow on the need to regulate the tech sector than a few years ago when she was accused of unfairly targeting \nAmerican firms. She said European regulators communicated with counterparts in Washington to “share notes.”\n“I don’t think the cooperation has been better for a very long time,” she said.\nThe Digital Markets Act, first passed in 2022, was intended to give European regulators more authority to force the \ntech giants to change their business practices without the drawn-out process of filing traditional antitrust lawsuits, \nwhich can take years to resolve. A key aspect of the law is that the companies cannot favor their own services over \nsimilar products offered by rivals.\nAs part of the investigations, Alphabet, Apple and Meta will now be required to disclose more information to \nregulators about their business practices. The companies said they had made changes to comply with the new \nrules.\nAmong the changes, Apple announced in January that developers would have new ways to reach customers in the \nEuropean Union, including allowing outside app stores to be available on iPhones and iPads for the first time. \nGoogle also made changes to its products, including how it displays search results for flights, hotels and shopping \nservices.\nMeta created a new subscription service that allows E.U. users to pay €13 per month if they want to use Facebook \nand Instagram without advertisements. Regulators said the policy essentially forces users to either pay a fee or \nagree to have their personal data used to target advertising.\n“The commission is concerned that the binary choice imposed by Meta’s ‘pay or consent’ model may not provide a \nreal alternative in case users do not consent,” the commission said in a statement.\nA spokesman for Meta said it would “continue to engage constructively with the commission.” Apple said it had \n“demonstrated flexibility and responsiveness to the European Commission and developers, listening and \nincorporating their feedback.” Oliver Bethell, the director of competition at Google, said the company would \n“continue to defend our approach in the coming months.”\nMany in the tech industry have wondered how aggressively E.U. regulators would enforce the new competition law. \nIn Brussels, the tech companies have been participating in workshops about how the rules would be carried out. At \nthe same time, many app developers, competitors and consumer groups have complained to regulators that the \nchanges made by the companies so far were insufficient.\n“Today’s opening of investigations into Meta, Google and Apple is a sure sign that the commission means business \nin enforcing the Digital Markets Act,” said Monique Goyens, director general of the European Consumer \nOrganization, a group in Brussels that has been critical of the tech industry.\nOn Monday, regulators also said they were gathering information about Amazon’s compliance with the Digital \nMarkets Act. Regulators said the company might be favoring its own branded products in its online store, in \nviolation of the law.\nThis article appeared in print on page B1, B3.\nE.U. Takes Aim at Alphabet , Apple and Meta in Wide-Ranging Investigations\nLoad-Date: March 25, 2024"
    },
    {
        "file_name": "time_soon_Mar2024",
        "header": "Can ChatGPT do my taxes? Chatbots won't replace human expertise any",
        "media": "time soon",
        "time": "March 25, 2024",
        "section": "",
        "length": "1446 words",
        "byline": "Jennifer Jolly",
        "story_text": "Can ChatGPT do my taxes? Chatbots won't replace human expertise any \ntime soon\nUSA Today Online\nMarch 23, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 1446 words\nByline: Jennifer Jolly\nBody\nAs the clock ticks toward the tax filing deadline, some people might be desperate enough to turn to a bevy of new \nAI chatbots to do it all for them.\nOne word of advice: Don’t. \nThere’s a reason we warn kids not to use ChatGPT to write an essay or finish their history homework. And the bot \nis  especially bad at math. Add in the intricate and often ambiguous realm of tax laws that vary by state, and it could \nbe a recipe for disaster − or even worse − an audit. \nThis question of whether it’s a good idea to use generative AI for tax help comes at a time when the nation’s most \npopular tax preparation companies, Intuit’s TurboTax and H&R Block, launched generative AI “assistants.” \nSo far, reviews of “Intuit Assist,” specifically in Turbo Tax’s DIY “Self-Help” section, and H&R Block’s “AI Tax \nAssist,” which is part of their paid packages, underscore why this sort of AI won’t replace human expertise any time \nsoon. \nNot that they’re meant to, Turbo Tax spokeswoman Karen Nolan said on a Zoom call. And it’s important taxpayers \nunderstand that. \nHow can generative AI help with my taxes?\nIntuit Director of Design Jim Fell and Nolan walked me through some of the most common ways people can − and \ncannot − use the new tool. \n\"Our AI is a digital front door to simple help flagging missing information or inconsistencies while also providing \naccess to expert help from a human being,\" Nolan explained as Fell showed me specific use-cases on screen. \nThe main ways the AI chatbot pops up right now are to flag an accuracy check, such as missed information or \npotential “clumsy-thumb” typos. It also offers deeper, more detailed explanations of finished returns and can quickly \ntranslate between languages for filers who might be overwhelmed trying to figure everything out in English. \nThat last part is the most impressive bit of AI magic that’s easy to see firsthand. The rest of the machine learning \ntools run mainly in the background and have for years. Nolan says it has been checking for tax return accuracy, \ncutting down on repetitive tasks, and helping find obscure deductions for nearly a decade.\nLink to Image\nDoes H&R Block have a new AI tax tool?\nCan ChatGPT do my taxes? Chatbots won't replace human expertise any time soon\nH&R Block’s new “AI Tax Assist” is a more prominent part of its website and similar to what many of us have played \naround with using ChatGPT, Copilot or Gemini. \nLike Turbo Tax’s Intuit Assist, it’s best to use H&R Block’s AI Tax Assist more for a simple query or as a failsafe for \ncommon mistakes. For instance, it does well defining tax terms and explaining something you might not understand \n(such as the simplest, most easy-to-understand terms in the filing process). \nIs AI just bad at math? \nRemember when I said that AI doesn’t do “facts” very well? It’s abundantly clear that you can’t ask ChatGPT or any \nother AI conversation bot a critical or confusing tax question and trust its answers. \nThat's largely because different AI assistants are trained on different types of information, kind of like if you raised a \nchild without ever teaching her what colors are called, then asked her what color an apple is. She might try to come \nup with an answer, but without being taught, a guess is as good as you’re going to get. \nIn the case of Intuit Assist, the company says the bot was trained on current tax code as well as the company’s own \nvast data trove based on its tax prep experience. That information, combined with whatever it learns from your own \ntax documents along the way, forms its knowledge base and dictates the answers you receive when asking it a \nquestion. \nH&R Block’s AI Tax Assist works in a similar way, and the company says it used its own archive of tax laws, with a \nfew tweaks here and there from their own accountants, tax law experts and the like. \nNeither of these bots is trained from information scraped from the internet, which is reassuring, but that doesn’t \nprevent them from falling victim to AI accuracy issues. All versions of consumer AI currently have a “hallucination” \nproblem. They often spit out information that sounds “right” but is out of date, inaccurate or just plain made up.\nSpring cleaning for your finances:  12 money moves to make right now\nHere’s how not to use AI to do your taxes\nIn some early reviews of Intuit Assist and AI Tax Assist, a fellow technology columnist asked the tax chatbots a slew \nof much more specific and nuanced hypothetical questions, and it didn’t go well. \nBoth company’s bots responded with vague, misleading or just wrong answers, specifically when his questions \nwere around cryptocurrencies, multi-state returns and other uncommon filing situations. \nFor example, when asked a question about where a college student should file taxes when they go to school out of \nstate, the journalist reported that TurboTax’s bot provided “irrelevant advice” and H&R Block’s AI assistant \nerroneously suggested the student would have to file in both states. The truth is, the person would have to file only \nin a state where they earned income, but neither AI helper nailed the answer. \nThese situations reveal the limitations of artificial intelligence, but those specific shortcomings aren’t necessarily \napplicable across the board, spokespeople from both companies say. \n“If Turbo Tax is powering the AI, you can trust it,” Nolan said. “We don’t expect our customers to try to manipulate it \nthe way (that journalist did). That wouldn’t really happen if you’re doing your taxes.”\nWhen I asked Nolan about the trouble people might have turning to an AI chatbot in the Self Help section \nspecifically, she explained, “If you have questions like that, a DIY product is probably not what you need.” \nNolan also reiterated that in the hypothetical instance it gives you bad advice, the company's system would flag that \nbefore it allowed you to finish and file. \nCan ChatGPT do my taxes? Chatbots won't replace human expertise any time soon\n“AI won’t file your taxes for you, even if you’re using our mobile app and not speaking with a human. AI is not filing \nyour actual return. We will absolutely capture inaccuracies before anything gets to the IRS,” Nolan said. \nBe sure to read the fine print\nTurbo Tax identifies its AI chatbot as a Beta version product, which mean it's still working out the kinks. It has \nseveral disclaimers in the fine print that warn people advice might not be spot-on. Same with H&R Block. \n“Gen-AI for the industry is still in its infancy,” Nolan said. “You won’t see us using AI to do math. We have other \nthings doing the math.\" \nTo TurboTax’s credit, the Intuit Assist bot did help me along the way, even if the standard checks and issue alerts \nwould have accomplished the same thing, albeit a bit later in the process. But the most important thing about these \nAI tax bots is that they’re designed to get better over time. Fast-forward a few years, and both tax assistants will \nprobably be miles better than they are today, and they learn as they go. \nBig business and taxes: Major companies haven't paid federal income tax in 5 years. How could that be?\nChild tax credit: How much is the child tax credit for 2023? Here's what you need to know about qualifying.\nYour tax return: Here are all the ways to check the status of your 2023 tax return\nACA and taxes: Your ACA plan's advance premium tax credit may affect your refund or how much you owe.\nWill we use AI to do our taxes in the future? \nFuture versions of these tax-minded assistants will be smarter and more robust than the versions we have today. \nThat’s the promise of generative AI, and we’ll all grow to expect it as artificial intelligence gradually takes over \nmore of our daily tasks. \nYou know those prescription drug commercials on TV? It’s kind of like that right now. Here’s this amazing new tool \nthat can save you time, give you “more confidence” and maybe even save you money. But the list of potential \nproblems using it without guardrails on something as crucial as your taxes comes with a list of potential “side \neffects” so long it makes you laugh out loud. \nFortunately, humans at TurboTax and H&R Block are still running the show, and they both guarantee the accuracy \nof your tax return, regardless of whether you use the available AI features. If you get audited, they’ll give you advice \nand guide you along the way, but additional safeguards like TurboTax’s Audit Defense or H&R Block’s Peace of \nMind Extended Service Plan, where the companies actually deal with the IRS on your behalf, still cost extra. \nJennifer Jolly is an Emmy Award-winning consumer tech columnist and on-air correspondent. The views and \nopinions expressed in this column are the author's and do not necessarily reflect those of USA TODAY. Contact her \nat J J@Techish.co m. \nThis article originally appeared on USA TODAY: Can ChatGPT do my taxes? Chatbots won't replace human \nexpertise any time soon\nLoad-Date: March 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2024",
        "header": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent",
        "media": "The New York Times - International Edition",
        "time": "March 25, 2024",
        "section": "TECHNOLOGY",
        "length": "1106 words",
        "byline": "Paul Mozur and Cade Metz",
        "story_text": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent\nThe New York Times - International Edition\nMarch 26, 2024 Tuesday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1106 words\nByline: Paul Mozur and Cade Metz\nDateline: TAIPEI, Taiwan \nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.       \nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead.       \nNew research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world's top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.       \nThe findings show a jump for China, which produced about one-third of the world's top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022's Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.       \nThe talent imbalance has been building for the better part of a decade. During much of the 2010s, the United States \nbenefited as large numbers of China's top minds moved to American universities to complete doctoral degrees. A \nmajority of them stayed in the United States. But the research shows that trend has also begun to turn, with growing \nnumbers of Chinese researchers staying in China.       \nWhat happens in the next few years could be critical as China and the United States jockey for primacy in A.I. - a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation - turning the \nresearchers into one of the most geopolitically important groups in the world.       \nGenerative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China's researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.       \n(The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)       \nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nChina has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.       \n\"A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that's come to dominate the American A.I. industry at the moment,\" he said.       \nWhile the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.       \nResearchers originally from China now make up 38 percent of the top A.I. researchers working in the United States, \nwith Americans making up 37 percent, according to the research. Three years earlier, those from China made up 27 \npercent of top talent working in the United States, compared with 31 percent from the United States.       \n\"The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,\" said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.       \nHe added that the data seemed to show the United States was still attractive. \"We're the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,\" he said.       \nPieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.       \n\"It's just a natural state of affairs,\" he said.       \nIn the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.       \nDespite bans introduced by the Trump administration that prohibit entry to the United States for students from some \nmilitary-linked universities in China and a relative slowdown in the flow of Chinese students into the country during \nCovid, the research showed large numbers of the most promising A.I. minds continued coming to the United States \nto study.       \nBut this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology - including critical microchip architecture - to a Beijing-based company that paid him in secret, according \nto a federal indictment.       \nThe substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.       \n\"Chinese scholars are almost leading the way in the A.I. field,\" said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are \"shooting themselves in the foot.\"       \nThe track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.       \nFor now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world's top talent, down from about 59 percent three years ago, according to the research. \nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nLoad-Date: March 25, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Is Coming for the Past, Too; Guest Essay",
        "media": "The New York Times",
        "time": "March 26, 2024",
        "section": "OPINION",
        "length": "1352 words",
        "byline": "Jacob N. Shapiro and Chris Mattmann",
        "story_text": "A.I. Is Coming for the Past, Too; Guest Essay\nThe New York Times \nJanuary 28, 2024 Sunday 13:17 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1352 words\nByline: Jacob N. Shapiro and Chris Mattmann\nHighlight: In our focus on protecting the present and future from A.I., we have forgotten about the urgent need to \nprotect the past.\nBody\nWe don’t have to imagine a world where deepfakes can so believably imitate the voices of politicians that they can \nbe used to gin up scandals that could sway elections. It’s already here. Fortunately, there are numerous reasons for \noptimism about society’s ability to identify fake media and maintain a shared understanding of current events.\nWhile we have reason to believe the future may be safe, we worry that the past is not.\nHistory can be a powerful tool for manipulation and malfeasance. The same generative A.I. that can fake current \nevents can also fake past ones. While new content may be secured through built-in systems, there is a world of \ncontent out there that has not been watermarked, which is done by adding imperceptible information to a digital file \nso that its provenance can be traced. Once watermarking at creation becomes widespread and people adapt to \ndistrust content that is not watermarked, then everything produced before that point in time can be much more \neasily called into question.\nAnd this will create a treasure trove of opportunities for backstopping false claims with generated documents, from \nphotos placing historical figures in compromising situations, to altering individual stories in historical newspapers, to \nchanging names on deeds of title. While all of these techniques have been used before, countering them is much \nharder when the cost of creating near-perfect fakes has been radically reduced.\nThis forecast is based on history. There are many examples of how economic and political powers manipulated the \nhistorical record to their own ends. Stalin purged disloyal comrades from history by executing them and then \naltering photographic records to make it appear as if they never existed. Slovenia, on becoming an independent \ncountry in 1992, erased over 18,000 people from the registry of residents — mainly members of the Roma minority \nand other ethnic non-Slovenes. In many cases, the government destroyed their physical records, leading to their \nloss of homes, pensions and access to other services, according to a 2003 report by the Council of Europe \nCommissioner for Human Rights.\nFalse documents are a key part of many efforts to rewrite the historical record. The infamous Protocols of the \nElders of Zion, first published in a Russian newspaper in 1903, purported to be meeting minutes from a Jewish \nconspiracy to control the world. First discredited in August 1921 as a forgery plagiarized from multiple unrelated \nsources, the Protocols featured prominently in Nazi propaganda and have long been used to justify antisemitic \nviolence, including a citation in Article 32 of Hamas’s 1988 founding covenant.\nIn 1924 the Zinoviev Letter, said to be a secret communiqué from the head of the Communist International in \nMoscow to the Communist Party of Great Britain to mobilize support for normalizing relations with the Soviet Union, \nwas published by The Daily Mail four days before a general election. The resulting scandal may have cost Labour \nA.I. Is Coming for the Past, Too Guest Essay\nthe election. The letter’s origin has never been proved, but its authenticity was questioned at the time, and an \nofficial investigation in the 1990s concluded that it was most likely the work of White Russians — a conservative \npolitical faction led at the time by Russian émigrés opposed to the Communist government.\nDecades later Operation Infektion, a Soviet disinformation campaign, used forged documents to spread the idea \nthat the United States had invented H.I.V., the virus that causes AIDS, as a biological weapon. And in 2004 CBS \nNews withdrew a controversial story because it could not authenticate the documents, which were later \ndiscredited as forgeries, that called into question the earlier service by George W. Bush, then the president, in the \nTexas Air National Guard. As it becomes easier to generate historical disinformation and as the sheer volume of \ndigital fakes explodes, the opportunity will become available to reshape history or at least to call our current \nunderstanding of it into question.\nThe prospects of political actors using generative A.I. to effectively reshape history — not to mention fraudsters \ncreating spurious legal documents and transaction records — are frightening. Fortunately, a path forward has been \nlaid by the same companies that created the risk.\nIn indexing a large share of the world’s digital media to train their models, the A.I. companies have effectively \ncreated systems and databases that will soon contain all of humankind’s digitally recorded content or at least a \nmeaningful approximation of it. They could start work today to record watermarked versions of these primary \ndocuments, which include newspaper archives and a wide range of other sources, so that subsequent forgeries are \ninstantly detectable.\nSuch work faces some barriers. Google’s digital libraries’ effort to scan millions of the world’s library books and \nmake them readily accessible online ran into intellectual property limits, rendering the historical archive unworkable \nfor its intended purpose of making these texts searchable by anyone with an internet connection. Those same \nintellectual property concerns are causing creators and companies to fret about both the training data provided to \ngenerative A.I. and its implications when used to generate content.\nGiven this freighted history, including Google’s failed investment in its digital libraries project, who will step up and \npay for a similar massive effort that would create immutable versions of historical data? Both government and \nindustry have strong incentives to do so, and many of the intellectual property concerns around providing a \nsearchable online archive do not apply to creating watermarked and time-stamped versions of documents, because \nthose versions need not be made publicly available to serve their purpose. One can compare a claimed document \nto the recorded archive by using a mathematical transformation of the document known as a hash, the same \ntechnique the Global Internet Forum to Counter Terrorism uses to help companies screen for known terrorist \ncontent.\nAside from creating an important public good and protecting citizens from the dangers posed by manipulation of \nhistorical narratives, creating verified records of historical documents can be valuable for the large A.I. companies. \nNew research suggests that when A.I. models are trained on A.I.-generated data, their performance quickly \ndegrades. Thus separating what is actually part of the historical record from newly created “facts” may be critical.\nPreserving the past will also mean preserving the training data, the associated tools that operate on it and even the \nenvironment that the tools were run in. Vint Cerf, an early internet pioneer, has called this type of record “digital \nvellum,” and we need it to secure the information environment.\nSuch a vellum will be a powerful tool. It can help companies to build better models by enabling them to analyze \nwhat data to include to get the best content and help regulators to audit bias and harmful content in the models. \nTech giants are already conducting similar efforts to record the new content their models are creating — in part \nbecause they need to train their models on human-generated text and the data produced after the adoption of large \nlanguage models may be tainted with generated content.\nThe time has come to extend this effort back in time as well, before our politics, too, become severely distorted by \ngenerated history.\nA.I. Is Coming for the Past, Too Guest Essay\nJacob N. Shapiro is a professor of politics and international affairs at Princeton University and the managing \ndirector of the Empirical Studies of Conflict Project. Chris Mattmann is an adjunct research professor at the \nUniversity of Southern California and the director of its Information Retrieval and Data Science Group.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, X and Threads.\nThis article appeared in print on page A21.\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "Than_Ever;_Guest_Essay_Mar2024",
        "header": "When Your Technical Skills Are Eclipsed, Your Humanity Will Matter More",
        "media": "Than Ever; Guest Essay",
        "time": "March 26, 2024",
        "section": "OPINION",
        "length": "1281 words",
        "byline": "Aneesh Raman and Maria Flynn",
        "story_text": "When Your Technical Skills Are Eclipsed, Your Humanity Will Matter More \nThan Ever; Guest Essay\nThe New York Times \nFebruary 14, 2024 Wednesday 13:32 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1281 words\nByline: Aneesh Raman and Maria Flynn\nHighlight: The rise of A.I. will make soft skills even more important.\nBody\nThere have been just a handful of moments over the centuries when we have experienced a huge shift in the skills \nour economy values most. We are entering one such moment now. Technical and data skills that have been highly \nsought after for decades appear to be among the most exposed to advances in artificial intelligence. But other skills, \nparticularly the people skills that we have long undervalued as soft, will very likely remain the most durable. That is \na hopeful sign that A.I. could usher in a world of work that is anchored more, not less, around human ability.\nA moment like this compels us to think differently about how we are training our workers, especially the heavy \npremium we have placed on skills like coding and data analysis that continue to reshape the fields of higher \neducation and worker training. The early signals of what A.I. can do should compel us to think differently about \nourselves as a species. Our abilities to effectively communicate, develop empathy and think critically have allowed \nhumans to collaborate, innovate and adapt for millenniums. Those skills are ones we all possess and can improve, \nyet they have never been properly valued in our economy or prioritized in our education and training. That needs to \nchange.\nIn today’s knowledge economy, many students are focused on gaining technical skills because those skills are seen \nas the most competitive when it comes to getting a good job. And for good reason. For decades, we have viewed \nthose jobs as future-proof, given the growth of technology companies and the fact that engineering majors land the \nhighest-paying jobs.\nThe number of students seeking four-year degrees in computer science and information technology shot up 41 \npercent between the spring of 2018 and the spring of 2023, while the number of humanities majors plummeted. \nWorkers who didn’t go to college and those who needed additional skills and wanted to take advantage of a \nlucrative job boom flocked to dozens of coding boot camps and online technical programs.\nNow comes the realization of the power of generative A.I., with its vast capabilities in skills like writing, \nprogramming and translation. (Microsoft, which owns LinkedIn, is a major investor in the technology.) LinkedIn \nresearchers recently looked at which skills any given job requires and then identified over 500 likely to be affected \nby generative A.I. technologies. They then estimated that 96 percent of a software engineer’s current skills — \nmainly proficiency in programming languages — can eventually be replicated by A.I. Skills associated with jobs like \nlegal associates and finance officers will also be highly exposed.\nIn fact, given the broad impact A.I. is set to have, it is quite likely to affect all of our work to some degree or another.\nWe believe there will be engineers in the future, but they will most likely spend less time coding and more time on \ntasks like collaboration and communication. We also believe that there will be new categories of jobs that emerge \nWhen Your Technical Skills Are Eclipsed, Your Humanity Will Matter More Than Ever Guest Essay\nas a result of A.I.’s capabilities — just like we’ve seen in past moments of technological advancement — and that \nthose jobs will probably be anchored increasingly around people skills.\nCircling around this research is the big question emerging across so many conversations about A.I. and work, \nnamely: What are our core capabilities as humans?\nIf we answer that question from a place of fear about what’s left for people in the age of A.I., we can end up \nconceding a diminished view of human capability. Instead, it’s critical for us all to start from a place that imagines \nwhat’s possible for humans in the age of A.I. When you do that, you find yourself focusing quickly on people skills \nthat allow us to collaborate and innovate in ways technology can amplify but never replace. And you find yourself — \nwhatever the role or career stage you’re in — with agency to better manage this moment of historic change.\nCommunication is already the most in-demand skill across jobs on LinkedIn today. Even experts in A.I. are \nobserving that the skills we need to work well with A.I. systems, such as prompting, are similar to the skills we need \nto communicate and reason effectively with other people.\nOver 70 percent of executives surveyed by LinkedIn last year said soft skills were more important to their \norganizations than highly technical A.I. skills. And a recent Jobs for the Future survey found that 78 percent of the \n10 top-employing occupations classified uniquely human skills and tasks as “important” or “very important.” These \nare skills like building interpersonal relationships, negotiating between parties and guiding and motivating teams.\nNow is the time for leaders, across sectors, to develop new ways for students to learn that are more directly, and \nmore dynamically, tied to where our economy is going, not where it has been. Critically, that involves bringing the \nsame level of rigor to training around people skills that we have brought to technical skills.\nColleges and universities have a critical role to play. Over the past few decades, we have seen a prioritization of \nscience and engineering, often at the expense of the humanities. That calibration will need to be reconsidered.\nThose not pursuing a four-year degree should look for those training providers that have long emphasized people \nskills and are invested in social capital development.\nEmployers will need to be educators not just around A.I. tools but also on people skills and people-to-people \ncollaboration. Major employers like Walmart and American Airlines are already exploring ways to put A.I. in the \nhands of employees so they can spend less time on routine tasks and more time on personal engagement with \ncustomers.\nUltimately, for our society, this comes down to whether we believe in the potential of humans with as much \nconviction as we believe in the potential of A.I. If we do, it is entirely possible to build a world of work that not only is \nmore human but also is a place where all people are valued for the unique skills they have, enabling us to deliver \nnew levels of human achievement across so many areas that affect all of our lives, from health care to \ntransportation to education. Along the way, we could meaningfully increase equity in our economy, in part by \naddressing the persistent gender gap that exists when we undervalue skills that women bring to work at a higher \npercentage than men.\nAlmost anticipating this moment a few years ago, Minouche Shafik, who is now the president of Columbia \nUniversity, said: “In the past, jobs were about muscles. Now they’re about brains, but in the future, they’ll be about \nthe heart.”\nThe knowledge economy that we have lived in for decades emerged out of a goods economy that we lived in for \nmillenniums, fueled by agriculture and manufacturing. Today the knowledge economy is giving way to a relationship \neconomy, in which people skills and social abilities are going to become even more core to success than ever \nbefore. That possibility is not just cause for new thinking when it comes to work force training. It is also cause for \ngreater imagination when it comes to what is possible for us as humans not simply as individuals and organizations \nbut as a species.\nWhen Your Technical Skills Are Eclipsed, Your Humanity Will Matter More Than Ever Guest Essay\nAneesh Raman is a vice president and work force expert at LinkedIn. Maria Flynn is the president of Jobs for the \nFuture.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, X and Threads.\nPHOTO:  (PHOTOGRAPH BY Kate Dehler FOR THE NEW YORK TIMES)\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "AI can flag some tax mistakes but won't do heavy lifting",
        "media": "USA Today",
        "time": "March 26, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "1318 words",
        "byline": "By, Jennifer Jolly, Special to USA TODAY",
        "story_text": "AI can flag some tax mistakes but won't do heavy lifting\nUSA Today\nMarch 26, 2024 Tuesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 1318 words\nByline: By, Jennifer Jolly, Special to USA TODAY\nBody\nAs the clock ticks toward the tax filing deadline, some people might be desperate enough to turn to a bevy of new \nAI chatbots to do it all for them.\nOne word of advice: Don't.\nThere's a reason we warn kids not to use ChatGPT to write an essay or finish their history homework. And the bot \nis especially bad at math. Add in the intricate and often ambiguous realm of tax laws that vary by state, and it could \nbe a recipe for disaster   or even worse   an audit.\nThis question of whether it's a good idea to use generative AI for tax help comes at a time when the nation's most \npopular tax preparation companies, Intuit's TurboTax and H&R Block, launched generative AI \"assistants.\"\nSo far, reviews of \"Intuit Assist,\" specifically in Turbo Tax's DIY \"Self-Help\" section, and H&R Block's \"AI Tax \nAssist,\" which is part of their paid packages, underscore why this sort of AI won't replace human expertise any time \nsoon.\nNot that they're meant to, Turbo Tax spokeswoman Karen Nolan said on a Zoom call. And it's important taxpayers \nunderstand that.\nHow can generative AI\nhelp with my taxes?\nIntuit Director of Design Jim Fell and Nolan walked me through some of the most common ways people can   and \ncannot   use the new tool.\n\"Our AI is a digital front door to simple help flagging missing information or inconsistencies while also providing \naccess to expert help from a human being,\" Nolan explained as Fell showed me specific use-cases on screen.\nThe main ways the AI chatbot pops up right now are to flag an accuracy check, such as missed information or \npotential \"clumsy-thumb\" typos. It also offers deeper, more detailed explanations of finished returns and can quickly \ntranslate between languages for filers who might be overwhelmed trying to figure everything out in English.\nThat last part is the most impressive bit of AI magic that's easy to see firsthand. The rest of the machine learning \ntools run mainly in the background and have for years. Nolan says it has been checking for tax return accuracy, \ncutting down on repetitive tasks, and helping find obscure deductions for nearly a decade.\nAI can flag some tax mistakes but won't do heavy lifting\nDoes H&R Block have\na new AI tax tool?\nH&R Block's new \"AI Tax Assist\" is a more prominent part of its website and similar to what many of us have played \naround with using ChatGPT, Copilot or Gemini.\nLike Turbo Tax's Intuit Assist, it's best to use H&R Block's AI Tax Assist more for a simple query or as a fail-safe for \ncommon mistakes. For instance, it does well defining tax terms and explaining something you might not understand \n(such as the simplest, most easy-to-understand terms in the filing process).\nIs AI just bad at math?\nRemember when I said that AI doesn't do \"facts\" very well? It's abundantly clear that you can't ask ChatGPT or any \nother AI conversation bot a critical or confusing tax question and trust its answers.\nThat's largely because different AI assistants are trained on different types of information, kind of like if you raised a \nchild without ever teaching her what colors are called, then asked her what color an apple is. She might try to come \nup with an answer, but without being taught, a guess is as good as you're going to get.\nIn the case of Intuit Assist, the company says the bot was trained on current tax code as well as the company's own \nvast data trove based on its tax prep experience. That information, combined with whatever it learns from your own \ntax documents along the way, forms its knowledge base and dictates the answers you receive when asking it a \nquestion.\nH&R Block's AI Tax Assist works in a similar way, and the company says it used its own archive of tax laws, with a \nfew tweaks here and there from their own accountants, tax law experts and the like.\nNeither of these bots is trained from information scraped from the internet, which is reassuring, but that doesn't \nprevent them from falling victim to AI accuracy issues. All versions of consumer AI currently have a \"hallucination\" \nproblem. They often spit out information that sounds \"right\" but is out of date, inaccurate or just plain made up.\nHere's how not to use\nAI to do your taxes\nIn some early reviews of Intuit Assist and AI Tax Assist, a fellow technology columnist asked the tax chatbots a slew \nof much more specific and nuanced hypothetical questions, and it didn't go well.\nBoth company's bots responded with vague, misleading or just wrong answers, specifically when his questions \nwere around cryptocurrencies, multistate returns and other uncommon filing situations.\nFor example, when asked a question about where a college student should file taxes when they go to school out of \nstate, the journalist reported that TurboTax's bot provided \"irrelevant advice\" and H&R Block's AI assistant \nerroneously suggested the student would have to file in both states. The truth is, the person would have to file only \nin a state where they earned income, but neither AI helper nailed the answer.\nThese situations reveal the limitations of artificial intelligence, but those specific shortcomings aren't necessarily \napplicable across the board, spokespeople from both companies say.\n\"If Turbo Tax is powering the AI, you can trust it,\" Nolan said. \"We don't expect our customers to try to manipulate it \nthe way (that journalist did). That wouldn't really happen if you're doing your taxes.\"\nWhen I asked Nolan about the trouble people might have turning to an AI chatbot in the Self Help section \nspecifically, she explained, \"If you have questions like that, a DIY product is probably not what you need.\"\nAI can flag some tax mistakes but won't do heavy lifting\nNolan also reiterated that in the hypothetical instance it gives you bad advice, the company's system would flag that \nbefore it allowed you to finish and file. \"AI won't file your taxes for you, even if you're using our mobile app and not \nspeaking with a human. AI is not filing your actual return. We will absolutely capture inaccuracies before anything \ngets to the IRS,\" Nolan said.\nBe sure to read the fine print\nTurbo Tax identifies its AI chatbot as a Beta version product, which mean it's still working out the kinks. It has \nseveral disclaimers in the fine print that warn people advice might not be spot-on. Same with H&R Block.\nTo TurboTax's credit, the Intuit Assist bot did help me along the way, even if the standard checks and issue alerts \nwould have accomplished the same thing, albeit a bit later in the process. But the most important thing about these \nAI tax bots is that they're designed to get better over time. Fast-forward a few years, and both tax assistants will \nprobably be miles better than they are today, and they learn as they go.\nWill we use AI to do\nour taxes in the future?\nFuture versions of these tax-minded assistants will be smarter and more robust than the versions we have today. \nThat's the promise of generative AI, and we'll all grow to expect it as artificial intelligence gradually takes over more \nof our daily tasks.\nYou know those prescription drug commercials on TV? It's kind of like that right now. Here's this amazing new tool \nthat can save you time, give you \"more confidence\" and maybe even save you money. But the list of potential \nproblems using it without guardrails on something as crucial as your taxes comes with a list of potential \"side \neffects\" so long it makes you laugh out loud.\nFortunately, humans at TurboTax and H&R Block are still running the show, and they both guarantee the accuracy \nof your tax return, regardless of whether you use the available AI features. If you get audited, they'll give you advice \nand guide you along the way, but additional safeguards like TurboTax's Audit Defense or H&R Block's Peace of \nMind Extended Service Plan, where the companies actually deal with the IRS on your behalf, still cost extra.\nJennifer Jolly is an Emmy Award-winning consumer tech columnist and on-air correspondent. The views and \nopinions expressed in this column are the author's and do not necessarily reflect those of USA TODAY. Contact her \nat JJ@Techish.com .\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "'additive_to_humanity';_Aidan_Gomez_can_take_some_credit_for_the_'T'_at_the_Mar2024",
        "header": "Tired of AI doomsday tropes, Cohere CEO says his goal is technology that's",
        "media": "'additive to humanity'; Aidan Gomez can take some credit for the 'T' at the",
        "time": "March 26, 2024",
        "section": "NATION WORLD",
        "length": "988 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Tired of AI doomsday tropes, Cohere CEO says his goal is technology that's \n'additive to humanity'; Aidan Gomez can take some credit for the 'T' at the \nend of ChatGPT\nDayton Daily News (Ohio)\nMarch 25, 2024 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 988 words\nByline: MATT O'BRIEN\nBody\nAidan Gomez can take some credit for the 'T' at the end of ChatGPT. He was part of a group of Google engineers \nwho first introduced a new artificial intelligence model called a transformer.\nThat helped set a foundation for today's generative AI boom that ChatGPT-maker OpenAI and others built upon. \nGomez, one of eight co-authors of Google's 2017 paper, was a 20-year-old intern at the time. \nHe's now the CEO and co-founder of Cohere, a Toronto-based startup competing with other leading AI companies \nin supplying large language models and the chatbots they power to big businesses and organizations. \nGomez spoke about the future of generative AI with The Associated Press. The interview has been edited for \nlength and clarity. \nQ: What's a transformer? \nA: A transformer is an architecture of a neural network -- the structure to the computation that happens inside of the \nmodel. The reason that transformers are special relative to their peers -- other competing architectures, other ways \nof structuring neural networks -- is essentially that they scale very well. They can be trained across not just \nthousands, but tens of thousands of chips. They can be trained extremely quickly. They use many different \noperations that these GPUs (graphics chips) are tailored for. Compared to what existed before the transformer, they \ndo that processing faster and more efficiently. \nQ: How important are they to what you're doing at Cohere? \nA: Massively important. We use the transformer architecture as does everyone else in building large language \nmodels. For Cohere, a huge focus is scalability and production readiness for enterprises. Some of the other models \nthat we compete against are huge and super inefficient. You can't actually put that into production, because as \nsoon as you're faced with real users, costs blow up and the economics break. \nQ: What's a specific example of how a customer is using a Cohere model? \nA: I have a favorite example in the health care space. It stems from the surprising fact that 40% of a doctor's \nworking day is spent writing patient notes. So what if we could have doctors attach a little passive listening device to \nfollow along with them throughout the day, between their patient visits, listening into the conversation and pre-\npopulating those notes so that instead of having to write it from scratch, there's a first draft in there. They can read \nthrough it and just make edits. Suddenly, the capacity of doctors boosts by a massive proportion. \nTired of AI doomsday tropes, Cohere CEO says his goal is technology that's 'additive to humanity' Aidan \nGomez can take some credit for the 'T' at the end of Cha....\nQ: How do you address customer concerns about AI language models being prone to 'hallucinations' (errors) and \nbias? \nA: Customers are always concerned about hallucinations and bias. It leads to a bad product experience. So it's \nsomething we focus on heavily. For hallucinations, we have a core focus on RAG, which is retrieval-augmented \ngeneration. We just released a new model called Command R which is targeted explicitly at RAG. It lets you \nconnect the model to private sources of trusted knowledge. That might be your organization's internal documents or \na specific employee's emails. You're giving the model access to information that it just otherwise hasn't seen out in \nthe web when it was learning. What's important is that it also allows you to fact check the model, because now \ninstead of just text in, text out, the model is actually making reference to documents. It can cite back to where it got \nthat information. You can check its work and gain a lot more confidence working with the tool. It reduces \nhallucination massively. \nQ: What are the biggest public misconceptions about generative AI? \nA: The fear that certain individuals and organizations espouse about this technology being a terminator, an \nexistential risk. Those are stories humanity has been telling itself for decades. Technology coming and taking over \nand displacing us, rendering us subservient. They're very deeply embedded in the public's cultural brain stem. It's a \nvery salient narrative. It's easier to capture people's imagination and fear when you tell them that. So we pay a lot of \nattention to it because it's so gripping as a story. But the reality is I think this technology is going to be profoundly \ngood. A lot of the arguments for how it might go bad, those of us developing the technology are very aware of and \nworking to mitigate those risks. We all want this to go well. We all want the technology to be additive to humanity, \nnot a threat to it. \nQ: Not only OpenAI but a number of major technology companies are now explicitly saying they're trying to build \nartificial general intelligence (a term for broadly better-than-human AI). Is AGI part of your mission? \nA: No, I don't see it as part of my mission. For me, AGI isn't the end goal. The end goal is profound positive impact \nfor the world with this technology. It's a very general technology. It's reasoning, it's intelligence. So it applies all over \nthe place. And we want to make sure it's the most effective form of the technology it possibly can be, as early as it \npossibly can be. It's not some pseudo-religious pursuit of AGI, which we don't even really know the definition of. \nQ: What's coming next? \nA: I think everyone should keep their eyes on tool use and more agent-like behavior. Models that you can present \nthem for the first time with a tool you've built. Maybe it's a software program or an API (application programming \ninterface). And you can say, 'Hey model, I just built this. Here's what it does. Here's how you interact with it. This is \npart of your toolkit of stuff you can do.' That general principle of being able to give a model a tool it's never seen \nbefore and it can adopt it effectively, I think is going to be very powerful. In order to do a lot of stuff, you need \naccess to external tools. The current status quo is models can just write (text) characters back at you. If you give \nthem access to tools, they can actually take action out in the real world on your behalf.\nGraphic\n \n(AP Illustration/Peter Hamlin)\nLoad-Date: March 26, 2024\nTired of AI doomsday tropes, Cohere CEO says his goal is technology that's 'additive to humanity' Aidan \nGomez can take some credit for the 'T' at the end of Cha...."
    },
    {
        "file_name": "Narayen_Mar2024",
        "header": "Adobe collaborating to develop industry standards on GenAI: CEO Shantanu",
        "media": "Narayen",
        "time": "March 26, 2024",
        "section": "TECH & INTERNET",
        "length": "397 words",
        "byline": "Ishaan Gera",
        "story_text": "Adobe collaborating to develop industry standards on GenAI: CEO Shantanu \nNarayen\nThe Economic Times\nMarch 27, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 397 words\nByline: Ishaan Gera\nBody\nAdobe is collaborating with other companies, especially those working with generative artificial intelligence to \ndevelop broad industry standards, Adobe CEO Shantanu Narayen said Tuesday at the launch of its genAI-enabled \napplication called GenStudio for marketers. “Responsible innovation cannot be an afterthought. We are working to \ncombat misinformation by advocating for content credentials as an industry standard to establish trust in digit \ncontent,” Narayen, who is also chairman and president of the company, noted. \nGenStudio builds on Adobe’s generative artificial intelligence model released last year to plan, create, manage \nand measure campaigns. The company launched Firefly, its image generation model in March 2023, which it \npointed out will also be scaled up to video, audio and 3D model generation.The brand, known for its suite of apps in \nthe workspace, had previewed GenStudio last year in September. “Generative AI enables a fundamental shift in \nthe relationship between brands and their customers, creating a transformative moment for business leaders to \ndrive profitable growth while delivering new digital experiences,” said Anil Chakravarthy, president, Digital \nExperience Business, Adobe. Adobe is integrating generative AI programme with its customer experience platform \nto deliver personalisation at scale, the company noted.“We need to be bringing generative AI out of the playground \nand into the workspace,” said David Wadhwani, senior VP, Adobe's Digital Media business.Adding more \ncapabilities to its existing genAI model, the company announced Structure Reference for its Firefly model, which it \nsaid will help apply the structure and design of an existing image to new generated content.“A new capability in \nAdobe Firefly, Adobe’s family of creative generative AI models for safe commercial use, called Structure Reference \nbrings users a new level of creative control,” it said.The programme can already use a specific style of an image \nand apply it to other images.Adobe Experience Platform AI Assistant, which can help answer technical questions, \nautomate tasks and simulate outcomes, was released as well. It unveiled programmes within its experience \nplatform, used primarily by brands, to map customer journeys more efficiently. (The reporter is in the US to cover \nAdobe Summit 2024 at the invitation of Adobe.) For Reprint Rights: timescontent.com\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Mar2024",
        "header": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS",
        "media": "Pittsburgh Post-Gazette",
        "time": "March 26, 2024",
        "section": "ASECTION; Pg. A-1",
        "length": "1363 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\nPittsburgh Post-Gazette\nMarch 26, 2024 Tuesday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 1363 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nArtificial intelligence is making its way into medical offices throughout Pennsylvania, including those in Pittsburgh, \nwith the tantalizing promise of fewer administrative headaches for doctors and better care for patients.\nThe transition could be bumpy: Among obstacles to widespread adoption of tech that instantly taps vast stores of \ninformation will be doctors' resistance to change how they've practiced medicine, experts say. For patients, the \nselling point could be more eye contact and better communication during office visits, if doctors aren't tied up with a \ncomputer screen, typing notes into a medical record.\nBut that's just the start.\nGoogle, Microsoft and Nvidia are among the tech giants plowing money into medicine. For the 12 months ending \nJuly 30, 2023, the Food and Drug Administration approved 171 AI or machine learning devices for use in medicine, \na number that was expected to increase 30% for the year compared to 2022.\nNearly 700 AI-like devices have been approved by the FDA since 1995.\nUp for grabs is a market expected to reach $51.3 billion by 2030 from just $2.9 billion in 2022, according to India-\nbased market research firm Insights 10.\nIn the coming weeks, artificial intelligence will be introduced at the 14-hospital Allegheny Health Network - first with \nthe goal of chipping away at the administrative workload of doctors, nurses and others, and later to take on some \nfar less mundane tasks including monitoring high-risk patients.\nAHN rival UPMC has also been adding AI tools in the clinician's office, with the same early goal of freeing doctors \nfrom medical record documentation through what's called \"ambient listening.\"\nWith patients' permission, AI software will \"listen\" to the physician-patient conversation in the office, then organize \nthe notes into the written medical record. The doctor's role will be reduced to simply editing the software's notes for \nfinal entry.\nAnd other, more ambitious, ways to tap the capabilities of artificial intelligence will find their way into the local health \ncare workforce soon.\nAHN's 22,000 employees will soon get access to Google's Vertex AI Search and Sidekick software that can, for \ninstance, draft letters to health insurers on behalf of patients who need specialty medications, medical equipment or \nother care that's not standard in their insurance benefits. The program will be \"trained\" on internal Highmark Health \ndata rather than publicly available information sources, like ChatGPT and similar tools.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"It's paradoxical, but AI is going to humanize health care,\" said Ashis Barad, a pediatrician and AHN chief digital \nand information officer. \"It will not replace anybody.\"\nFord, Seagate, Wayfair and Lowe's are among other corporate users of Vertex AI, a cloud-based platform Google \ndeveloped in 2021, according to San Francisco online newspaper TechCrunch. Mayo Clinic and HCA Healthcare, \nwhich operates more than 2,000 hospitals in the U.S. and Britain, are also Google AI customers.\nHighmark and UPMC have long been rivals, so it isn't surprising the two Pittsburgh health care giants have chosen \ndifferent paths to the world of artificial intelligence.\nUPMC has partnered with Google rival Microsoft, subsidiary Nuance Communications and Pittsburgh startup \nAbridge AI Inc. to allow doctors and other care providers to use Nuance's DAX Copilot ambient listening software to \norganize and write patient exam narratives for medical records.\nPrivately held Abridge was founded in 2018 and automates clinical notes. The startup has offices in Lawrenceville \nand elsewhere.\nMicrosoft acquired Nuance for $19.7 billion in 2021. Microsoft is also a major investor in OpenAI, the for-profit arm \nof the San Francisco company founded in 2021 that created all the buzz a year later around generative AI models \nlike ChatGPT.\n\"Operational efficiency has the potential of being greatly aided by AI,\" said Robert Bart, a UPMC pediatric intensivist \nand system chief medical information officer. \"It can listen, then create the document for the workflow, creating a \nmuch more natural, caring interaction to occur between the doctor and patient.\"\nFiguring out what AI can do\nThroughout the U.S., the industry is going big for artificial intelligence, with academic medical centers tapping AI's \nvast reserves of information to do things like better identify pre-diabetes, perform retinal exams for early signs of \ndisease and detect an array of cancers as well or better than humans.\nEventually, doctors at both AHN and UPMC envision a far bigger role for AI than the initial documentation tasks, \nwith some of the possibilities growing out of evolving partnerships between Epic Systems and AI vendors. Both \nhealth systems use the Verona, Wis., company's services to store patient medical records.\nTasks that artificial intelligence tools could pick up include writing patient progress notes, responding to emailed \nquestions from patients and suggesting medical coding, which is the basis of billing.\nDr. Bart envisions the day when such a tool might note a change in the seriousness of a medical problem based on \nthe doctor's conversation with the patient, alert the physician that a certain prescription drug is not covered by the \npatient's health insurance or even suggest a diagnosis.\n\"AI is not going to replace who I am as a physician, but I believe physicians who adopt AI will be better prepared to \ndeliver high-quality care into their practice,\" Dr. Bart said.\nSeparately, AHN is preparing to introduce a smart patient room and a digital nursing program at its Forbes Hospital \nin the coming weeks.\nA 47-bed unit of the Monroeville hospital is being equipped with monitors that will allow a seasoned nurse at a North \nShore office - or even at home - to brief new patients in a live chat on what to expect during their stay and also \nprovide discharge instructions before they go home.\nPermission from the patient will be required. A doorbell chime will mark the start of the session.\nAdmissions' briefings typically take 45 minutes and discharge instructions last 20-30 minutes, Forbes Hospital Chief \nNursing Officer Lynn Kosar said. That's time that floor nurses could be spending instead with patients, she said.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"These things really help our nursing staff focus more on patients, getting them their meds, making sure patients \nare getting the best care we can,\" Ms. Kosar said. \"Nurses see the value in it. They're really excited.\"\nAHN nurses spend two hours of every typical 12-hour shift recording test results and other information in patient \nmedical records, according to an internal study, Dr. Barad said. Only 45% of their time is spent on direct patient \ncare, compromising the reason many nurses choose the vocation.\nPartnering with Orlando, Fla.-based care.ai, a company specializing in virtual medical care systems, AHN is \npreparing for the day when AI will monitor hospital patients with dementia or who risk falling because of dizziness or \nother issues. Today, these patients may require someone to be in the room with them at all times, but AHN \nanticipates high-risk patients could eventually be monitored remotely by AI and sensors on their bed.\nStarting at Forbes, smart patient rooms are slated to be rolled out throughout AHN's hospital system.\nChange is hard\nA 2023 survey by the American Medical Association found that 65% of more than 1,000 doctors surveyed saw \nadvantages to what the medical organization called \"augmented intelligence.\" But doctors also worried about data \nprivacy issues and legal liability for AI-generated medical errors.\nFor some doctors, change is just hard, AHN's Dr. Barad said, especially older physicians who've been practicing for \nyears. It's his job to make the case for embracing AI to the health system's medical staff.\nDr. Barad was reminded of a 2014 study at the University of Bristol that found most ants instinctively turn left when \nentering unfamiliar places.\nPart of the reason may be in seeking strength in numbers since other ants exhibit similar behavior, an analogy that \ncan be extended to seasoned doctors, he said.\n\"It's easier to go through the inefficiencies they know,\" Dr. Barad said. \"I'm the left-turn guy. My job is empathy.\"\nKris B. Mamula: kmamula@post-gazette.com\nGraphic\n \nPHOTO: care.ai: Orlando, Fla.-based care.ai is partnering with Allegheny Health Network in installing cameras and \nscreens in patient rooms to allow remote nurses to talk with patients. The video link is expected to allow floor \nnurses to spend more time with patients.\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Your doctor might not be listening to you. AI can help change that.",
        "media": "USA Today Online",
        "time": "March 27, 2024",
        "section": "",
        "length": "1196 words",
        "byline": "Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry",
        "story_text": "Your doctor might not be listening to you. AI can help change that.\nUSA Today Online\nMarch 27, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 1196 words\nByline: Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry\nBody\nAre you tired of feeling like just another number at the doctor’s office? As current and future members of the \nphysician workforce, we believe that well-regulated artificial intelligence presents an opportunity to tackle burnout \nwithin the medical workforce and restore patient-centered care.\nFrom 2021 through 2022, about 71,300 physicians left their clinical jobs, exacerbating staffing shortages. Even \nmore troubling, the Association of American Medical Colleges projects a shortage of up to 124,000 physicians by \n2034. \nA major factor driving this shortage is the overwhelming and increasing administrative burden associated with care \ndelivery. These burdens leave physicians, who train to connect with their patients face-to-face, spending more time \nwith their eyes glued to their electronic health records. \nDr. Christine Sinsky, a vice president at the American Medical Association, explains, “Physicians don't leave their \ncareers. They are leaving their inbox.”\nLink to Image\n'The doctor is not really listening to me'\nIt's not just doctors feeling the strain, either. When a doctor spends half their time typing away at their computer, it \nis no surprise that patients feel neglected. Many patients resent the resulting decline in face-to-face time with their \ndoctors, frustrated as they slip through the cracks of what many increasingly describe as a corporatized health care \nsystem. \nOne of us, Victor Agbafe, learned this firsthand from his frustrated neighbor who after an encounter with his primary \ncare provider told him, “The doctor is not really listening to me – they’re too focused on their pre-set agenda.” \nYes, urgent care is convenient.  But seeing your doctor may save your life.\nAnd it's not just a one-off complaint. \nA study from the Mayo Clinic showed that doctors often interrupt their patients within just 11 seconds of them \ntalking. The patients in the study who did voice concerns about the history and physical aspects of their patient \nencounter cited being interrupted a few seconds into their encounter as their chief complaint.\nFortunately, this is exactly where generative AI can make a remarkable difference. AI tools can reduce the \nphysician’s administrative workload, freeing up more time to spend with patients. \nOpinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to \nyour device through the USA TODAY app. Don't have the app? Download it for free from your app store.\nYour doctor might not be listening to you. AI can help change that.\nHow AI can help doctors treat patients better\nFor example, in Tennessee, Dr. Matthew Hitchcock is using an AI tool that drafts his medical notes, turning two \nhours of typing at home into just 20 minutes of editing. \nBy delegating time-consuming tasks to AI, physicians can focus on verifying the accuracy of medical notes and, \nmore important, on directly engaging with patients.\nThink back to Victor’s neighbor, whose appointments were depersonalized by doctors typing notes into electronic \nmedical records, dividing their attention between their screens and patients. With AI-assisted appointments, doctors \ncan spend their limited time forming genuine connections with patients and asking important follow-up questions. \nLink to Image\nMinimizing keyboard clicking and computer screen barriers creates more space for doctors and patients to build the \ntrust and mutual understanding necessary to maximize the doctor-patient relationship. This shows the positive \npotential of AI making inroads in health care: It can enhance rather than replace human connection.\nBeyond easing administrative tasks, AI's integration into health care can benefit diagnostics and treatment planning \n– particularly through the integration of retrieval-augmented generation techniques (RAG), which enhance the \naccuracy and reliability of AI models.\nAmerica needs diverse medical workforce: Racial disparities in health care cost lives. Medical school needs \nrace-conscious admissions.\nImagine the models as standard GPS systems, which navigate using preloaded maps based on vast collections of \nold data. The models generate outputs that mirror natural language, much like a GPS guides you based on existing \nroad layouts. \nIn this scenario, RAG is like upgrading your GPS to include real-time traffic updates. RAG enhances the AI models \nby integrating current, relevant information from external sources, just as a GPS with real-time updates optimizes \nroutes.\nThis approach ensures that physicians have access to the latest medical evidence, reducing the risk of outdated or \nincorrect diagnoses. \nLink to Image\nFor instance, when a physician evaluates a patient, RAG-enabled AI systems can sift through vast databases of \nmedical literature and clinical guidelines in real time. They can offer additional diagnoses or remind physicians of \nrare conditions, ensuring a more thorough consideration of all possibilities. They can even flag potentially \ndangerous drug interactions that might be overlooked in a busy clinical setting, protecting vulnerable populations \nlike older patients.\nAs health care evolves from volume-based to value-based care and we increasingly integrate population health \nwithin the context of the individual patient, AI will remain a valuable tool. It enables our doctors, nurses and other \nclinical providers to tailor insights gleaned from large-scale population data to the individual needs of each patient. \nEven so, let us be clear: AI will not and should not replace our doctors. Medicine is both an art and a science that \nrequires human intuition and judgment that AI cannot replicate.\nLink to Image\nIt is crucial to strike a balance with how to use AI with medical trainees who will form the backbone of our future \nhealth care workforce. We have to integrate AI into medical education while still ensuring students develop \nYour doctor might not be listening to you. AI can help change that.\nfoundational skills such as developing an initial diagnostic and treatment course that are essential to the practice of \nmedicine. \nWe want to bring doctors and patients closer. If implemented responsibly, AI promises to help return medicine to its \nhumanistic roots.\nRotimi Kukoyi is a Public Voices Fellow of The OpEd Project and The National Black Child Development Institute. \nHe is a sophomore Morehead-Cain Scholar at the University of North Carolina at Chapel Hill, where he studies \nhealth policy and management, biology and chemistry.\nVictor Agbafe is an MD/JD student at the University of Michigan Medical School and Yale Law School, where he is \na research fellow at the Solomon Center for Health Law and Policy.\nDr. Joan Perry is a pediatrician and the chairwoman of the department of pediatrics at Lenoir Memorial Hospital in \nKinston, North Carolina. She is also an adjunct assistant clinical professor of pediatrics at East Coastal University \n(ECU) and the University of North Carolina School of Medicine, and a former member of the North Carolina 7th \nCongressional District Advisory Committee on Medical and Health Affairs.\nYou can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on \nTwitter @usatodayopinion and in our daily Opinion newsletter.\nThis article originally appeared on USA TODAY: Your doctor might not be listening to you. AI can help change that.\nLoad-Date: March 27, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Image of hands for sale as meat in grocery store is AI-generated | Fact check",
        "media": "USA Today Online",
        "time": "March 27, 2024",
        "section": "AGRICULTURE NEWS",
        "length": "491 words",
        "byline": "Nate Trela, USA TODAY",
        "story_text": "Image of hands for sale as meat in grocery store is AI-generated | Fact check\nUSA Today Online\nMarch 27, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: AGRICULTURE NEWS\nLength: 491 words\nByline: Nate Trela, USA TODAY\nBody\nThe claim: Image shows human hands for sale as meat\nA March 21 Facebook post (direct link, archive link) shows what appears to be marbled red meat in the shape of \nhuman hands for sale in a grocery store.\n“Human Meat On The Market!” the post reads.\nThe post was shared more than 6,000 times in six days.\nMore from the Fact-Check Team:How we pick and research claims | Email newsletter | Facebook page\nOur rating: Altered\nThe image was digitally created and includes elements consistent with AI-generated imagery, three experts told \nUSA TODAY.\nTelltale signs of AI generation throughout image\nThree experts speaking to USA TODAY independently highlighted two elements in the image that indicated it was \ngenerated with AI.\nThe most obvious was the number of fingers on the hands. Several hands in the image have fewer than five fingers. \nAI struggles to put the correct number of fingers on images, said Michelle Johnson, a journalism professor emerita \nat Boston University.\nThe other unanimously recognized tell was the nonsensical labels on the packages in the image. Walter Scheirer, \nan engineering professor at Notre Dame whose area of research includes visual recognition, called the labels “the \ngibberish output of a generative AI algorithm.”\n“While such algorithms can do a good job rendering photorealistic scenes, they have trouble with readable text \nsynthesis,” he said in an email to USA TODAY. “Further, the labels are also distorted and fuzzy in places, which \nwouldn’t be the case if the text was printed in the physical world.”\nFact check: Image of Donald Trump leading crowd down flag-lined street is AI-generated\nBritt Paris, an assistant professor of library and information science at Rutgers, noted that beyond the issues with \ntext and hands, the lighting is unrealistic in the image.\nImage of hands for sale as meat in grocery store is AI-generated | Fact check\n“There are many weird streaks of light and reflections at various depths, seemingly reflecting off of many different \nplanes of varying depth between the ‘hands’ and the camera,” she wrote in an email.\nThe Facebook post contains the earliest version of the image USA TODAY could find after using multiple reverse \nimage search engines, and the user is identified as a “digital creator.” \nUSA TODAY reached out to the social media user who shared the claim for comment but did not immediately \nreceive a response.\nOur fact-check sources:\nBritt Paris, March 26, Email exchange with USA TODAY\nWalter Scheirer, March 26, Email exchange with USA TODAY\nMichelle Johnson, March 26, Email exchange with USA TODAY\nThank you for supporting our journalism. You can subscribe to our print edition, ad-free app or e-newspaper here.\nUSA TODAY is a verified signatory of the International Fact-Checking Network, which requires a demonstrated \ncommitment to nonpartisanship, fairness and transparency. Our fact-check work is supported in part by a grant from \nMeta.\nThis article originally appeared on USA TODAY: Image of hands for sale as meat in grocery store is AI-generated | \nFact check\nLoad-Date: March 27, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Amazon Adds $2.75 Billion to Its Stake in the A.I. Start-Up Anthropic",
        "media": "The New York Times",
        "time": "March 27, 2024",
        "section": "TECHNOLOGY",
        "length": "657 words",
        "byline": "Karen Weise Karen Weise writes about technology and is based in Seattle. Her coverage focuses on",
        "story_text": "Amazon Adds $2.75 Billion to Its Stake in the A.I. Start-Up Anthropic\nThe New York Times \nMarch 27, 2024 Wednesday 23:17 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 657 words\nByline: Karen Weise Karen Weise writes about technology and is based in Seattle. Her coverage focuses on \nAmazon and Microsoft, two of the most powerful companies in America.\nHighlight: The latest investment brings Amazon’s total stake in the San Francisco company to $4 billion.\nBody\nThe latest investment brings Amazon’s total stake in the San Francisco company to $4 billion.\nAmazon said on Wednesday that it had added $2.75 billion to its investment in Anthropic, a start-up that competes \nwith companies like OpenAI and Google in the race to build cutting-edge A.I. systems.\nSix months ago, Amazon invested $1.25 billion in Anthropic, making the San Francisco start-up Amazon’s most \nimportant A.I. partner. Amazon said at the time that it had the option to bring its total investment to $4 billion. It had \nuntil the end of March to do so, according to financial filings.\nStill, the additional investment shows the enormous resources that tech companies are pouring into A.I. and is \nindicative of how much financial support Anthropic needs to keep pace with its peers.\n“We believe our strategic collaboration with Anthropic will further improve our customers’ experiences, and look \nforward to what’s next,” Swami Sivasubramanian, an Amazon executive, said in a blog post announcing the \ninvestment.\nWhile Anthropic gets closer to Amazon, it has shed a bulk of the holdings of a controversial investor. Last week, a \nfederal judge granted approval for the bankrupt cryptocurrency exchange FTX to sell its stake in Anthropic. In 2021, \nFTX invested $500 million in the A.I. start-up, making up a stake of about 8 percent.\nThe value of that investment has since ballooned. Anthropic’s valuation tripled to $15 billion in just a year, The New \nYork Times reported in February.\nAnthropic was started in 2021 by a group of researchers from OpenAI, the company that created the ChatGPT \nchatbot. At the time, many of those researchers were concerned about OpenAI’s growing closer to Microsoft in a \npartnership eventually worth $13 billion.\nAnthropic has steadily raised funds because developing the foundational systems for generative A.I. requires deep \npockets, both to hire staff and to secure computing power.\nThe Amazon investment in Anthropic is not just a simple equity stake. Like Microsoft’s investment in OpenAI, it \nincludes gaining access to A.I. systems and commitments to provide computing power. But it stops short of the \nhigh-value acquisitions that could trigger an antitrust review. The Federal Trade Commission has begun an inquiry \nto see if these kinds of large A.I. deals hamper competition. (The Times has sued OpenAI and Microsoft for \ncopyright infringement of news content related to A.I. systems.)\nAmazon Adds $2.75 Billion to Its Stake in the A.I. Start-Up Anthropic\nIn a key part of the partnership, Anthropic agreed to build its A.I. using specialized computer chips designed by \nAmazon. Amazon has said it hopes Anthropic will help its efforts to meet the cutting-edge demands of A.I. as well \nas collaborate on designs of specialized chips.\nAmazon also gets an early shot at making Anthropic’s A.I. models available to customers of its cloud computing \nservice, and this month announced that it would provide access to the most powerful Anthropic models, known as \nClaude 3.\nThe bankruptcy estate of FTX agreed to sell about two-thirds of its shares in the start-up for $884 million. The \nmajority of the stake went to ATIC Third International Investment, a firm linked to a sovereign wealth fund in the \nUnited Arab Emirates.\nOther buyers included the quantitative trading firm Jane Street and the Ford Foundation, a philanthropic group. \nDarren Walker, the foundation’s president, said in an interview that he viewed Anthropic as an important competitor \nto OpenAI.\n“The fact that Anthropic has emerged and will be a strong competitor is a good thing for the markets, and it’s a good \nthing for the public and the public interest,” Mr. Walker said.\nDavid Yaffe-Bellany contributed reporting from New York.\nDavid Yaffe-Bellany contributed reporting from New York. \nPHOTO: Anthropic’s Claude A.I. chatbox. Anthropic competes with companies like OpenAI and Google in the race \nto build cutting-edge A.I. systems. (PHOTOGRAPH BY JACKIE MOLLOY FOR THE NEW YORK TIMES) This \narticle appeared in print on page B4.\nLoad-Date: March 27, 2024"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Mar2024",
        "header": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS",
        "media": "Pittsburgh Post-Gazette",
        "time": "March 27, 2024",
        "section": "ASECTION; Pg. A-1",
        "length": "1363 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\nPittsburgh Post-Gazette\nMarch 26, 2024 Tuesday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 1363 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nArtificial intelligence is making its way into medical offices throughout Pennsylvania, including those in Pittsburgh, \nwith the tantalizing promise of fewer administrative headaches for doctors and better care for patients.\nThe transition could be bumpy: Among obstacles to widespread adoption of tech that instantly taps vast stores of \ninformation will be doctors' resistance to change how they've practiced medicine, experts say. For patients, the \nselling point could be more eye contact and better communication during office visits, if doctors aren't tied up with a \ncomputer screen, typing notes into a medical record.\nBut that's just the start.\nGoogle, Microsoft and Nvidia are among the tech giants plowing money into medicine. For the 12 months ending \nJuly 30, 2023, the Food and Drug Administration approved 171 AI or machine learning devices for use in medicine, \na number that was expected to increase 30% for the year compared to 2022.\nNearly 700 AI-like devices have been approved by the FDA since 1995.\nUp for grabs is a market expected to reach $51.3 billion by 2030 from just $2.9 billion in 2022, according to India-\nbased market research firm Insights 10.\nIn the coming weeks, artificial intelligence will be introduced at the 14-hospital Allegheny Health Network - first with \nthe goal of chipping away at the administrative workload of doctors, nurses and others, and later to take on some \nfar less mundane tasks including monitoring high-risk patients.\nAHN rival UPMC has also been adding AI tools in the clinician's office, with the same early goal of freeing doctors \nfrom medical record documentation through what's called \"ambient listening.\"\nWith patients' permission, AI software will \"listen\" to the physician-patient conversation in the office, then organize \nthe notes into the written medical record. The doctor's role will be reduced to simply editing the software's notes for \nfinal entry.\nAnd other, more ambitious, ways to tap the capabilities of artificial intelligence will find their way into the local health \ncare workforce soon.\nAHN's 22,000 employees will soon get access to Google's Vertex AI Search and Sidekick software that can, for \ninstance, draft letters to health insurers on behalf of patients who need specialty medications, medical equipment or \nother care that's not standard in their insurance benefits. The program will be \"trained\" on internal Highmark Health \ndata rather than publicly available information sources, like ChatGPT and similar tools.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"It's paradoxical, but AI is going to humanize health care,\" said Ashis Barad, a pediatrician and AHN chief digital \nand information officer. \"It will not replace anybody.\"\nFord, Seagate, Wayfair and Lowe's are among other corporate users of Vertex AI, a cloud-based platform Google \ndeveloped in 2021, according to San Francisco online newspaper TechCrunch. Mayo Clinic and HCA Healthcare, \nwhich operates more than 2,000 hospitals in the U.S. and Britain, are also Google AI customers.\nHighmark and UPMC have long been rivals, so it isn't surprising the two Pittsburgh health care giants have chosen \ndifferent paths to the world of artificial intelligence.\nUPMC has partnered with Google rival Microsoft, subsidiary Nuance Communications and Pittsburgh startup \nAbridge AI Inc. to allow doctors and other care providers to use Nuance's DAX Copilot ambient listening software to \norganize and write patient exam narratives for medical records.\nPrivately held Abridge was founded in 2018 and automates clinical notes. The startup has offices in Lawrenceville \nand elsewhere.\nMicrosoft acquired Nuance for $19.7 billion in 2021. Microsoft is also a major investor in OpenAI, the for-profit arm \nof the San Francisco company founded in 2021 that created all the buzz a year later around generative AI models \nlike ChatGPT.\n\"Operational efficiency has the potential of being greatly aided by AI,\" said Robert Bart, a UPMC pediatric intensivist \nand system chief medical information officer. \"It can listen, then create the document for the workflow, creating a \nmuch more natural, caring interaction to occur between the doctor and patient.\"\nFiguring out what AI can do\nThroughout the U.S., the industry is going big for artificial intelligence, with academic medical centers tapping AI's \nvast reserves of information to do things like better identify pre-diabetes, perform retinal exams for early signs of \ndisease and detect an array of cancers as well or better than humans.\nEventually, doctors at both AHN and UPMC envision a far bigger role for AI than the initial documentation tasks, \nwith some of the possibilities growing out of evolving partnerships between Epic Systems and AI vendors. Both \nhealth systems use the Verona, Wis., company's services to store patient medical records.\nTasks that artificial intelligence tools could pick up include writing patient progress notes, responding to emailed \nquestions from patients and suggesting medical coding, which is the basis of billing.\nDr. Bart envisions the day when such a tool might note a change in the seriousness of a medical problem based on \nthe doctor's conversation with the patient, alert the physician that a certain prescription drug is not covered by the \npatient's health insurance or even suggest a diagnosis.\n\"AI is not going to replace who I am as a physician, but I believe physicians who adopt AI will be better prepared to \ndeliver high-quality care into their practice,\" Dr. Bart said.\nSeparately, AHN is preparing to introduce a smart patient room and a digital nursing program at its Forbes Hospital \nin the coming weeks.\nA 47-bed unit of the Monroeville hospital is being equipped with monitors that will allow a seasoned nurse at a North \nShore office - or even at home - to brief new patients in a live chat on what to expect during their stay and also \nprovide discharge instructions before they go home.\nPermission from the patient will be required. A doorbell chime will mark the start of the session.\nAdmissions' briefings typically take 45 minutes and discharge instructions last 20-30 minutes, Forbes Hospital Chief \nNursing Officer Lynn Kosar said. That's time that floor nurses could be spending instead with patients, she said.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"These things really help our nursing staff focus more on patients, getting them their meds, making sure patients \nare getting the best care we can,\" Ms. Kosar said. \"Nurses see the value in it. They're really excited.\"\nAHN nurses spend two hours of every typical 12-hour shift recording test results and other information in patient \nmedical records, according to an internal study, Dr. Barad said. Only 45% of their time is spent on direct patient \ncare, compromising the reason many nurses choose the vocation.\nPartnering with Orlando, Fla.-based care.ai, a company specializing in virtual medical care systems, AHN is \npreparing for the day when AI will monitor hospital patients with dementia or who risk falling because of dizziness or \nother issues. Today, these patients may require someone to be in the room with them at all times, but AHN \nanticipates high-risk patients could eventually be monitored remotely by AI and sensors on their bed.\nStarting at Forbes, smart patient rooms are slated to be rolled out throughout AHN's hospital system.\nChange is hard\nA 2023 survey by the American Medical Association found that 65% of more than 1,000 doctors surveyed saw \nadvantages to what the medical organization called \"augmented intelligence.\" But doctors also worried about data \nprivacy issues and legal liability for AI-generated medical errors.\nFor some doctors, change is just hard, AHN's Dr. Barad said, especially older physicians who've been practicing for \nyears. It's his job to make the case for embracing AI to the health system's medical staff.\nDr. Barad was reminded of a 2014 study at the University of Bristol that found most ants instinctively turn left when \nentering unfamiliar places.\nPart of the reason may be in seeking strength in numbers since other ants exhibit similar behavior, an analogy that \ncan be extended to seasoned doctors, he said.\n\"It's easier to go through the inefficiencies they know,\" Dr. Barad said. \"I'm the left-turn guy. My job is empathy.\"\nKris B. Mamula: kmamula@post-gazette.com\nGraphic\n \nPHOTO: care.ai: Orlando, Fla.-based care.ai is partnering with Allegheny Health Network in installing cameras and \nscreens in patient rooms to allow remote nurses to talk with patients. The video link is expected to allow floor \nnurses to spend more time with patients.\nLoad-Date: March 27, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Leaders Lobby Congress as China Tensions Rise",
        "media": "The New York Times",
        "time": "March 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "810 words",
        "byline": "By Cecilia Kang",
        "story_text": "A.I. Leaders Lobby Congress as China Tensions Rise\nThe New York Times\nMarch 28, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 810 words\nByline: By Cecilia Kang\nBody\nIn recent weeks, American lawmakers have moved to ban the Chinese-owned app TikTok. President Biden \nreinforced his commitment to overcome China's rise in tech. And the Chinese government added chips from Intel \nand AMD to a blacklist of imports.\nNow, as the tech and economic cold war between the United States and China accelerates, Silicon Valley's leaders \nare capitalizing on the strife with a lobbying push for their interests in another promising field of technology: artificial \nintelligence. \n  On May 1, more than 100 tech chiefs and investors, including Alex Karp, the head of the defense contractor \nPalantir, and Roelof Botha, the managing partner of the venture capital firm Sequoia Capital, will come to \nWashington for a daylong conference and private dinner focused on drumming up more hawkishness toward \nChina's progress in A.I.\n  Dozens of lawmakers, including Speaker Mike Johnson, Republican of Louisiana, will also attend the event, the \nHill & Valley Forum, which will include fireside chats and keynote discussions with members of a new House A.I. \ntask force.\n  Tech executives plan to use the event to directly lobby against A.I. regulations that they consider onerous, as well \nas ask for more government spending on the technology and research to support its development. They also plan \nto ask to relax immigration restrictions to bring more A.I. experts to the United States.\n  The event highlights an unusual area of agreement between Washington and Silicon Valley, which have long \nclashed on topics like data privacy, children's online protections and even China.\n  ''At the end of the day, whether you are in industry or government, or whatever side of the aisle you are on, we \nplay for team America,'' said Representative Jay Obernolte of California, the Republican chair of the House A.I. \nTask Force, who will give opening remarks at the conference.\n  After the rise over the past year of generative A.I. -- technology that has the potential to fundamentally shift \nproductivity, innovation and employment trends -- lobbying on the topic has exploded. Last year, more than 450 \ncompanies, nonprofits, universities and trade groups reported lobbying on A.I., more than double the number of \norganizations in the previous year, according to OpenSecrets, a nonprofit research group. Palantir more than \ndoubled its spending on lobbying last year to $5 million, its highest level on record.\nA.I. Leaders Lobby Congress as China Tensions Rise\n  As tech leaders capitalize on anti-China fervor in Washington, civil society groups and academics warn that \ndebates over competition for tech leadership could hurt efforts to regulate potential harms, such as the risks that \nsome A.I. tools could kill jobs, spread disinformation, and disrupt elections.\n  ''The dynamics of this U.S. v. China race has profound implications because on the other side of slowing down \nChina is minimal friction and regulation for U.S. companies,'' said Amba Kak, who is the executive director of the AI \nNow Institute, a research firm, and a former senior adviser on A.I. to the Federal Trade Commission.\n  A.I. experts say China lags the United States in generative A.I. by at least a year and may be falling further \nbehind, although a new study suggests that it is ahead in the talent.\n  May's event is being organized by Jacob Helberg, a senior adviser to Palantir and a member of the U.S.-China \nEconomic and Security Review Commission, which reports to Congress on national security threats posed by \nChina. He expanded this year's forum from the first gathering he organized last year, which was a private dinner \nfocused largely on the threat of TikTok, which is owned by Beijing-based ByteDance.\n  In addition to A.I., lawmakers speaking at the event in the Capitol will push for the Senate to pass legislation to \nban TikTok, and Tom Mueller, a founding employee of SpaceX, will speak about the space race between the United \nStates and China. Attendees will include Senator Mike Rounds, Republican of South Dakota and the ranking \nmember of the Armed Services Committee, and Representative Ritchie Torres, a New York Democrat on the House \nSelect Committee on the Chinese Communist Party.\n  ''Tech companies can't be neutral any more,'' Mr. Helberg said, adding that he recuses himself from any work \ninvolving contracts on the U.S.-China Economic and Security Review Commission that could give Palantir an \nadvantage.\n  Venture capitalists attending the event have dozens of A.I. investments. Sequoia has invested in more than 70 A.I. \nstartups. Khosla Ventures, a $15 billion venture firm, has several investments, including in OpenAI, the company \nbehind the ChatGPT chatbot.\n  ''It's become even more obvious, even more critical, that we treat China as an adversary,'' said Vinod Khosla, the \nhead of Khosla Ventures who will speak at the forum. ''What I'm worrying about is Western values versus a different \nset of values in China.''\nhttps://www.nytimes.com/2024/03/27/technology/ai-lobby-china.html\nGraphic\n \nPHOTOS: Clockwise from top left: Jacob Helberg, a member of the U.S.-China Economic and Security Review \nCommission\nHouse Speaker Mike Johnson\nand Representative Ritchie Torres, a Democrat on the House Select Committee on the Chinese Communist Party. \n(PHOTOGRAPHS BY JASON ANDREW FOR THE NEW YORK TIMES\nHAIYUN JIANG FOR THE NEW YORK TIMES\n AMIR HAMJA/THE NEW YORK TIMES) This article appeared in print on page B4.               \nLoad-Date: March 28, 2024\nA.I. Leaders Lobby Congress as China Tensions Rise"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Amazon Adds $2.7 Billion To Stake in A.I. Start-Up",
        "media": "The New York Times",
        "time": "March 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "622 words",
        "byline": "By Karen Weise",
        "story_text": "Amazon Adds $2.7 Billion To Stake in A.I. Start-Up\nThe New York Times\nMarch 28, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 622 words\nByline: By Karen Weise\nBody\nThe latest investment brings Amazon's total stake in the San Francisco company to $4 billion.\nAmazon said on Wednesday that it had added $2.75 billion to its investment in Anthropic, a start-up that competes \nwith companies like OpenAI and Google in the race to build cutting-edge A.I. systems. \n  Six months ago, Amazon invested $1.25 billion in Anthropic, making the San Francisco start-up Amazon's most \nimportant A.I. partner. Amazon said at the time that it had the option to bring its total investment to $4 billion. It had \nuntil the end of March to do so, according to financial filings.\n  Still, the additional investment shows the enormous resources that tech companies are pouring into A.I. and is \nindicative of how much financial support Anthropic needs to keep pace with its peers.\n  ''We believe our strategic collaboration with Anthropic will further improve our customers' experiences, and look \nforward to what's next,'' Swami Sivasubramanian, an Amazon executive, said in a blog post announcing the \ninvestment.\n  While Anthropic gets closer to Amazon, it has shed a bulk of the holdings of a controversial investor. Last week, a \nfederal judge granted approval for the bankrupt cryptocurrency exchange FTX to sell its stake in Anthropic. In 2021, \nFTX invested $500 million in the A.I. start-up, making up a stake of about 8 percent.\n  The value of that investment has since ballooned. Anthropic's valuation tripled to $15 billion in just a year, The \nNew York Times reported in February.\n  Anthropic was started in 2021 by a group of researchers from OpenAI, the company that created the ChatGPT \nchatbot. At the time, many of those researchers were concerned about OpenAI's growing closer to Microsoft in a \npartnership eventually worth $13 billion.\n  Anthropic has steadily raised funds because developing the foundational systems for generative A.I. requires \ndeep pockets, both to hire staff and to secure computing power.\n  The Amazon investment in Anthropic is not just a simple equity stake. Like Microsoft's investment in OpenAI, it \nincludes gaining access to A.I. systems and commitments to provide computing power. But it stops short of the \nhigh-value acquisitions that could trigger an antitrust review. The Federal Trade Commission has begun an inquiry \nto see if these kinds of large A.I. deals hamper competition. (The Times has sued OpenAI and Microsoft for \ncopyright infringement of news content related to A.I. systems.)\nAmazon Adds $2.7 Billion To Stake in A.I. Start-Up\n  In a key part of the partnership, Anthropic agreed to build its A.I. using specialized computer chips designed by \nAmazon. Amazon has said it hopes Anthropic will help its efforts to meet the cutting-edge demands of A.I. as well \nas collaborate on designs of specialized chips.\n  Amazon also gets an early shot at making Anthropic's A.I. models available to customers of its cloud computing \nservice, and this month announced that it would provide access to the most powerful Anthropic models, known as \nClaude 3.\n  The bankruptcy estate of FTX agreed to sell about two-thirds of its shares in the start-up for $884 million. The \nmajority of the stake went to ATIC Third International Investment, a firm linked to a sovereign wealth fund in the \nUnited Arab Emirates.\n  Other buyers included the quantitative trading firm Jane Street and the Ford Foundation, a philanthropic group. \nDarren Walker, the foundation's president, said in an interview that he viewed Anthropic as an important competitor \nto OpenAI.\n  ''The fact that Anthropic has emerged and will be a strong competitor is a good thing for the markets, and it's a \ngood thing for the public and the public interest,'' Mr. Walker said.\n  David Yaffe-Bellany contributed reporting from New York.David Yaffe-Bellany contributed reporting from New \nYork.\nhttps://www.nytimes.com/2024/03/27/technology/amazon-anthropic-ai.html\nGraphic\n \nPHOTO: Anthropic's Claude A.I. chatbox. Anthropic competes with companies like OpenAI and Google in the race \nto build cutting-edge A.I. systems. (PHOTOGRAPH BY JACKIE MOLLOY FOR THE NEW YORK TIMES) This \narticle appeared in print on page B4.               \nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "How artificial intelligence can help doctors treat you better",
        "media": "USA Today",
        "time": "March 28, 2024",
        "section": "OPINION; Pg. A7",
        "length": "1038 words",
        "byline": "By, Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry, Opinion contributors",
        "story_text": "How artificial intelligence can help doctors treat you better\nUSA Today\nMarch 28, 2024 Thursday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: OPINION; Pg. A7\nLength: 1038 words\nByline: By, Rotimi Kukoyi, Victor Agbafe and Dr. Joan Perry, Opinion contributors\nBody\nAre you tired of feeling like just another number at the doctor's office? As current and future members of the \nphysician workforce, we believe that well-regulated artificial intelligence presents an opportunity to tackle burnout \nwithin the medical workforce and restore patient-centered care.\nFrom 2021 through 2022, about 71,300 physicians left their clinical jobs, exacerbating staffing shortages.\nEven more troubling, the Association of American Medical Colleges projects a shortage of up to 124,000 physicians \nby 2034.\nA major factor driving this shortage is the overwhelming and increasing administrative burden associated with care \ndelivery.\nThese burdens leave physicians, who train to connect with their patients face-to-face, spending more time with their \neyes glued to their electronic health records.\nAs Dr. Christine Sinsky, a vice president at the American Medical Association, explains the problem, \"Physicians \ndon't leave their careers. They are leaving their inbox.\"\nIt's not just doctors feeling the strain, either. When a doctor spends half their time typing away at their computer, it \nis no surprise that patients feel neglected.\nMany patients resent the resulting decline in face-to-face time with their doctors, frustrated as they slip through the \ncracks of what many increasingly describe as a corporatized health care system.\nOne of us, Victor Agbafe, learned this firsthand from his frustrated neighbor who after an encounter with his primary \ncare provider told him, \"The doctor is not really listening to me - they're too focused on their pre-set agenda.\"\nAnd this is not just a one-off complaint. A study from the Mayo Clinic showed that doctors often interrupt their \npatients within just 11 seconds of them talking. The patients in the study who did voice concerns about the history \nand physical aspects of their patient encounter cited being interrupted a few seconds into their encounter as their \nchief complaint.\nFortunately, this is exactly where generative artificial intelligence can make a remarkable difference. AI tools can \nreduce the physician's administrative workload, freeing up more time to spend with patients.\nFor example, in Tennessee, Dr. Matthew Hitchcock is using an AI tool that drafts his medical notes, turning \ntwohours of typing at home into just 20 minutes of editing.\nHow artificial intelligence can help doctors treat you better\nBy delegating time-consuming tasks to AI, physicians can focus on verifying the accuracy of medical notes and, \nmore important, on directly engaging with patients.\nThink back to Victor's neighbor, whose appointments were depersonalized by doctors typing notes into electronic \nmedical records, dividing their attention between their screens and patients. With AI-assisted appointments, doctors \ncan spend their limited time forming genuine connections with patients and asking important follow-up questions.\nMinimizing keyboard clicking and computer screen barriers creates more space for doctors and patients to build the \ntrust and mutual understanding necessary to maximize the doctor-patient relationship.\nThis shows the positive potential of AI making inroads in health care: It can enhance rather than replace human \nconnection.\nBeyond easing administrative tasks, AI's integration into health care can benefit diagnostics and treatment planning \n- particularly through the integration of retrieval-augmented generation techniques (RAG), which enhance the \naccuracy and reliability of AI models.\nImagine the models as standard GPS systems, which navigate using preloaded maps based on vast collections of \nold data. The models generate outputs that mirror natural language, much like a GPS guides you based on existing \nroad layouts.\nReducing the risk of outdated\nor incorrect diagnoses\nIn this scenario, RAG is like upgrading your GPS to include real-time traffic updates. RAG enhances the AI models \nby integrating current, relevant information from external sources, just as a GPS with real-time updates optimizes \nroutes.\nThis approach ensures that physicians have access to the latest medical evidence, reducing the risk of outdated or \nincorrect diagnoses.\nFor instance, when a physician evaluates a patient, RAG-enabled AI systems can sift through vast databases of \nmedical literature and clinical guidelines in real time.\nThey can offer additional diagnoses or remind physicians of rare conditions, ensuring a more thorough \nconsideration of all possibilities.\nThey can even flag potentially dangerous drug interactions that might be overlooked in a busy clinical setting, \nprotecting vulnerable populations like older patients.\nAs health care evolves from volume-based to value-based care and we increasingly integrate population health \nwithin the context of the individual patient, artificial intelligence will remain a valuable tool. It enables our doctors, \nnurses and other clinical providers to tailor insights gleaned from large-scale population data to the individual needs \nof each patient.\nAI should not replace doctors\nEven so, let us be clear: AI will not and should not replace our doctors. Medicine is both an art and a science that \nrequires human intuition and judgment that AI cannot replicate.\nIt is crucial to strike a balance with how to use AI with medical trainees who will form the backbone of our future \nhealth care workforce. We have to integrate AI into medical education while still ensuring students develop \nfoundational skills such as developing an initial diagnostic and treatment course that are essential to the practice of \nmedicine.\nHow artificial intelligence can help doctors treat you better\nWe want to bring doctors and patients closer.\nIf implemented responsibly, AI promises to help return medicine to its humanistic roots.\nRotimi Kukoyi is a Public Voices Fellow of The OpEd Project and The National Black Child Development Institute. \nHe is a sophomore Morehead-Cain Scholar at the University of North Carolina at Chapel Hill.\nVictor Agbafe is an MD/JD student at the University of Michigan Medical School and Yale Law School, where he is \na research fellow at the Solomon Center for Health Law and Policy.\nDr. Joan Perry is  the chairwoman of the department of pediatrics at Lenoir Memorial Hospital in Kinston, North \nCarolina. She is also an adjunct assistant clinical professor  at East Coastal University  and the University of North \nCarolina School of Medicine.\nGraphic\n \nA major factor of burnout and shortage in the medical workforce\nis the overwhelming and increasing administrative burden.\ncarenas1/Getty Images\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "AI-led security startup SydeLabs raises $2.5 million in seed funding round",
        "media": "The Economic Times",
        "time": "March 28, 2024",
        "section": "FUNDING",
        "length": "409 words",
        "byline": "Tarush Bhalla",
        "story_text": "AI-led security startup SydeLabs raises $2.5 million in seed funding round\nThe Economic Times\nMarch 28, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 409 words\nByline: Tarush Bhalla\nBody\nArtificial intelligence (AI)-led risk management solutions provider, SydeLabs on Thursday said it has raised $2.5 \nmillion as a part of its seed round of funding led by RTP Global.The round also saw participation from early-stage \ninvestment firm Picus Capital along with marquee angel investors including Cred founder Kunal Shah and Mobile \nPremier League founder Sai Srinivas Kiran among others.SydeLabs said it will use the funds for research and \ndevelopment (R&D) and to build on its existing product portfolio. Founded by Ruchir Patwa and Ankita Kumari in \n2023, SydeLabs helps enterprises and core AI companies identify vulnerabilities in their generative AI models and \napplications before they go into final production. It currently has two products as part of its offerings including Syde \nBox, which helps detection of vulnerabilities in AI models, and Syde Guard, a real-time firewall that tracks security \nvulnerabilities after AI applications are deployed.“Most enterprises use one of the open-source foundational models \nout there and then build the context of their enterprises on top of it (to launch AI applications),” Kumari told ET. \n“However, open models are actually not tuned for safety and security and inherit some of these vulnerabilities, \nwhich can later seep into an enterprises’ AI applications. SydeLabs helps detect these vulnerabilities early on \nduring the production cycle,” she added.With both of its products in beta, San Francisco-based SydeLabs currently \nworks with over 10 enterprises across India and the US. Its tech team is based in Bengaluru.Within four months of \nlaunch, the company’s products have been deployed across 50 AI applications, and has tracked over 10,000 \nvulnerabilities.Without disclosing names, Kumari said SydeLabs is currently working with clients in domains of \necommerce, travel and financial services, as well as companies in India which are building large foundational AI \nmodels.It charges customers on a per scan and consumption basis.The company plans to hit $1 million in annual \nrecurring revenue (ARR) by the end of 2024, Kumari said.It will look to forge partnerships with large language \nmodel (LLM) operation providers to distribute its product and bolster its go-to-market strategy, she added. \nSydeLabs is also working on tools which will help enterprises with achieving compliance for their AI applications \nacross geographies, tuned to local rules and policies. For Reprint Rights: timescontent.com\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Has China Lost Its Taste for the iPhone?",
        "media": "The New York Times",
        "time": "March 28, 2024",
        "section": "BUSINESS",
        "length": "1410 words",
        "byline": "Meaghan Tobin, Alexandra Stevenson and Tripp Mickle Meaghan Tobin is a technology correspondent for",
        "story_text": "Has China Lost Its Taste for the iPhone?\nThe New York Times \nMarch 25, 2024 Monday 13:09 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1410 words\nByline: Meaghan Tobin, Alexandra Stevenson and Tripp Mickle Meaghan Tobin is a technology correspondent for \nThe Times based in Taipei, covering business and tech stories in Asia with a focus on China. Alexandra Stevenson \nis the Shanghai bureau chief for The Times, reporting on China&amp;#8217;s economy and society. Tripp Mickle \nreports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple includes \nproduct launches, manufacturing issues and political challenges. He also writes about trends across the tech \nindustry, including layoffs, generative A.I. and robot taxis.\nHighlight: Apple has deep ties in the country, its second-largest market. But there are signs that Chinese \nconsumers are becoming a harder sell.\nBody\nApple has deep ties in the country, its second-largest market. But there are signs that Chinese consumers are \nbecoming a harder sell.\nFor years, Apple dominated the market for high-end smartphones in China. No other company made a device that \ncould compete with the iPhone’s performance — or its position as a status object in the eyes of wealthy, \ncosmopolitan shoppers.\nBut evidence is mounting that, for many in China, the iPhone no longer holds the appeal it used to. During the first \nsix weeks of the year, historically a peak season for Chinese shoppers to spring for a new phone, iPhone sales fell \n24 percent from a year earlier, according to Counterpoint Research, which analyzes the smartphone market.\nMeanwhile, sales for one of Apple’s longstanding Chinese rivals, Huawei, surged 64 percent.\nIt’s a challenging time for Apple. Analysts say its latest product, a $3,500 virtual reality headset released in \nFebruary, is still years away from gaining mainstream appeal. This month, Apple has taken two regulatory hits: a \nEuropean Union fine of nearly $2 billion for anticompetitive music streaming practices and a U.S. government \nlawsuit claiming Apple violated antitrust laws.\nFor a decade, China has been the iPhone’s most important market after the United States and accounted for \nroughly 20 percent of Apple’s sales. Now the company’s grip on China could be dislodged by a series of factors: a \nslowdown in consumer spending, growing pressure from Beijing for people to shun devices made by U.S. \ncompanies and the resurgence of national champion Huawei.\n“The golden time for Apple in China is over,” said Linda Sui, a senior director at TechInsights, a market research \nfirm. One of the biggest reasons is the rising tension between the United States and China over trade and \ntechnology, Ms. Sui said. Without a significant lessening of geopolitical stress, it will be difficult for Apple to retain its \nposition.\n“It’s not just about consumers,” Ms. Sui said. “It’s about the big picture, the two superpowers competing with each \nother — that’s a fundamental thing behind the whole shift.”\nHas China Lost Its Taste for the iPhone?\nFew American companies have more to lose from these heightened tensions than Apple, whose newest handset, \nthe iPhone 15, went on sale in September. It is the first iPhone line to feature a titanium frame and include an action \nbutton that can be programmed to take photos or turn on the flashlight.\n“Five years ago, Apple had really strong branding in China — people would bring tents to wait through the whole \nnight outside the Apple Store for the next product launch,” said Lucas Zhong, a Shanghai-based analyst at Canalys, \na market research firm. “The iPhone 15 launch wasn’t nearly as popular.”\nSix months later, Apple has plastered billboards across cities like Shanghai, reminding residents they can still buy \nan iPhone 15 nearby. Similar promotions helped the iPhone account for four of the six top-selling smartphones in \nChina in the final three months of last year, the company said during a call with Wall Street analysts. But the \nprominent advertising did not persuade Jason Li, 22, to visit the Apple Store on Nanjing East Road, in the heart of \nShanghai’s shopping district, when he needed to replace his iPhone 13 Pro Max.\nInstead, Mr. Li went to the Huawei flagship store directly across the street, where he contemplated the Mate 60 Pro.\n“I don’t want to use iOS anymore,” he said, referring to the iPhone’s operating system. “It’s a bit stale.”\nApple declined to comment.\nFor some in China, buying a phone has become a political statement. Debates over whether using an iPhone is \ndisrespectful to Chinese tech companies or akin to handing personal data over to the U.S. government have \nerupted online. Last year, employees at some Chinese government agencies reported being told not to use iPhones \nfor work.\nThese directives surfaced less than two weeks after Huawei unveiled the Mate 60 Pro, a smartphone equipped with \nthe company’s own operating system and a computer chip more advanced than had previously been made in \nChina.\nHuawei released the device in the final days of a trip to China by Gina M. Raimondo, the U.S. commerce secretary. \nChinese commentators and state media heralded it as a triumph for Huawei in the face of Washington’s attempts to \nrestrict the company from developing just such technology.\nThe Mate 60 Pro was an immediate sensation. Its boost to Huawei’s sales carried over into the first six weeks of \nthis year, when the company claimed the second-largest share of the smartphone market, up to 17 percent from 9 \npercent a year earlier, according to data from Counterpoint.\n“Today, holding the Mate 60 series gives people a feeling like they had many years ago if someone saw them \nholding an iPhone on the street,” said Ivan Lam, a senior analyst at Counterpoint Research in Hong Kong. This is \nespecially true for people over 35, the age group that buys the most smartphones, he said.\nChina’s smartphone market is divided up by a number of companies. The domestic brands Vivo, Oppo and Xiaomi \njostle with Apple and Huawei for the largest pieces.\nApple started selling iPhones in China in 2009. The last time it was losing ground to Huawei, in 2019, the Trump \nadministration inadvertently extended Apple a lifeline by restricting U.S. technology firms from dealing with Huawei. \nGoogle, which makes the Android operating system, and several semiconductor companies cut off their support of \nthe Chinese smartphone maker.\nAs Huawei struggled, Apple rebounded. In 2022, its share of phones sold in China rose to 22 percent, from 9 \npercent in 2019, according to Counterpoint. Apple reported record revenue of $74 billion from the region during its \nfiscal year ending in September 2022.\nBut the restrictions also forced Huawei to develop its own wireless chip and operating system, resulting in the \ntechnology behind the Mate 60 Pro. The operating system has been a draw for Chinese shoppers, and many of \nHas China Lost Its Taste for the iPhone?\nChina’s biggest tech companies have made apps exclusively for it, further walling off users from platforms used \noutside China.\nHuawei’s innovation has made Apple’s latest models appear stodgy by comparison. And as China’s economy has \nstruggled to rebound from the Covid pandemic, many consumers are hesitant to spend on what feels like an \nincremental upgrade. The owners of about 125 million out of 215 million iPhones in China have not upgraded to \nnewer devices in the last three years, according to Daniel Ives, an Apple analyst at Wedbush Securities.\nApple has responded to the challenges in China. Its chief executive, Tim Cook, has traveled to the country and \nvisited Apple’s suppliers. Last week, he attended the splashy opening of an Apple Store near Shanghai’s Jing’an \nTemple — the company’s eighth store in Shanghai and 57th in China — to a crowd of Apple fans. The company \nalso said it was expanding its research and development labs in Shanghai. \nBut for some shoppers, Apple’s efforts have been overshadowed by Washington’s approach to the company’s \nChinese rival.\nWhile waiting at the Genius Bar for help with his ailing iPhone 12 at the Apple Store on Nanjing East Road in \nShanghai, Chi Miaomiao, 38, said he had recently bought Huawei’s Mate 60 Pro as his second phone. He was \ndrawn to Huawei after its chief financial officer, Meng Wanzhou, was arrested by the Canadian authorities in 2018 \nat the request of the United States, which accused her of misleading banks about Huawei’s business in Iran. Ms. \nMeng’s detention set off a flood of support in China, where many saw her as a hostage.\n“Huawei is our own brand, and because of this political incident, I think we Chinese should be united,” Mr. Chi said.\nUpstairs on the Apple sales floor, Li Bin, 23, and two friends debated the latest iPhone models. Huawei and Apple \nwere nearly comparable in quality, Mr. Li said, and though he thought the iPhone was slightly better, it was also \nmore expensive.\n“I may switch to an iPhone,” Mr. Li said, “when I get richer in the future.”\nLi You and Zixu Wang contributed research.\nLi You and Zixu Wang contributed research. \nPHOTOS: A transit station in Shanghai this month. While iPhone sales in China fell 24 percent early this year, sales \nby the domestic giant Huawei rose 64 percent. (B1); Lining up to buy the iPhone 15 in Shanghai in September. Six \nmonths later, billboards plastered across the city remind residents that the phone is for sale. (PHOTOGRAPHS BY \nQILAI SHEN FOR THE NEW YORK TIMES) (B5) This article appeared in print on page B1, B5.\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "significant?_Mar2024",
        "header": "ETtech Explainer: Why is Amazon’s $4-billion investment in Anthropic",
        "media": "significant?",
        "time": "March 28, 2024",
        "section": "TECH & INTERNET",
        "length": "664 words",
        "byline": "Gaurab Dasgupta",
        "story_text": "ETtech Explainer: Why is Amazon’s $4-billion investment in Anthropic \nsignificant?\nThe Economic Times\nMarch 28, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 664 words\nByline: Gaurab Dasgupta\nBody\nTech giant Amazon announced its $2.75 billion investment in artificial intelligence startup Anthropic on Wednesday, \ntaking its total investment in the firm to $4 billion. “We believe our strategic collaboration with Anthropic will further \nimprove our customers’ experiences, and look forward to what’s next,” Swami Sivasubramanian, a senior Amazon \nofficial said in a blog post announcing the investment.This investment underscores the trend of big tech companies \npiggybacking on upcoming startups to advance their AI ambitions, particularly around generative artificial \nintelligence. Microsoft has ChatGPT; now Amazon has Anthropic. ETtech looks at this emerging trend in the AI \nsector and how Amazon’s latest investment heats up the overall AI ecosystem. First, tell us more about this \ndealThe investment comes six months after Amazon invested $1.25 billion in Anthropic, making the San Francisco-\nbased startup Amazon’s most important AI partner.But the investment in Anthropic is not just a simple equity stake \nfor Amazon. Like Microsoft’s investment in OpenAI, it includes getting access to AI systems and commitments to \nprovide computing power. However, it stops short of the high-value acquisitions that could trigger an antitrust \nreview. How does Amazon benefit from this deal?\nAccording to a New York Times report, Anthropic has agreed to build its AI using specialised computer chips \ndesigned by Amazon. The Seattle-based company has said it hopes Anthropic will help its efforts to meet the \ncutting-edge demands of AI and collaborate on designs of these specialised chips.Amazon also gets an early shot \nat making Anthropic’s AI models available to customers of its cloud computing service, and this month announced \naccess to the most powerful Anthropic model, known as Claude 3.What are the AI plans of other Big Tech \ncompanies?When it comes to execution, Microsoft leads the pack after placing an early bet of $10 billion on Sam \nAltman’s OpenAI. The latter’s conversational chatbot ChatGPT, running on the large language model GPT-4, has \ncreated a new era of AI, where investments are pouring in from all directions. Interestingly, the first-mover \nadvantage should have been with Google since it acquired London-based artificial intelligence company DeepMind \nfor over $500 million in 2014. But that has not been the case because it has not succeeded in exploiting its \ninvestment in terms of speed and scale, post the acquisition. Google also has its conversational chatbot Gemini \n(earlier known as Bard), which the tech giant is trying to integrate into its ecosystem. However, the pick-up has \nbeen relatively slower, with multiple glitches impeding its rapid adoption.According to a report in tech publication \nThe Information, Facebook-parent Meta is planning to release the newest version of its artificial-intelligence large \nlanguage model Llama 3 in July which would give better responses to contentious questions posed by usersBut \nwhere is Apple in this race?This is the question that everyone is asking, including shareholders of the Cupertino-\nbased tech giant. Apple plans to disclose more about its plans to put generative artificial intelligence to use later \nthis year, CEO Tim Cook said during the company's annual shareholder meeting last month.Cook said the iPhone \nmaker sees “incredible breakthrough potential for generative AI, which is why we're currently investing significantly \nin this area. We believe that will unlock transformative opportunities for users when it comes to productivity, \nproblem solving and more.”Apple announced its annual developer conference WWDC on June 10 this year, and \nmany expect the company to finally announce its AI offerings. Apple might push for AI integration into its upcoming \nETtech Explainer: Why is Amazon ’s $4-billion investment in Anthropic significant?\niOS, iPadOS, macOS and other platforms that have been confirmed to be showcased during the \nconference.Meanwhile, reports suggest that Apple is in talks with both Google and OpenAI to power its iPhone AI \nfeatures. For Reprint Rights: timescontent.com\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "people's_safety_or_rights;_U.S._federal_agencies_must_show_that_their_artificial_Mar2024",
        "header": "VP Harris says US agencies must show their AI tools aren't harming",
        "media": "people's safety or rights; U.S. federal agencies must show that their artificial",
        "time": "March 28, 2024",
        "section": "NATION WORLD",
        "length": "527 words",
        "byline": "MATT O'BRIEN",
        "story_text": "VP Harris says US agencies must show their AI tools aren't harming \npeople's safety or rights; U.S. federal agencies must show that their artificial \nintelligence tools aren't harming the public, or stop using them, under new \nrules unveiled by the White House\nDayton Daily News (Ohio)\nMarch 28, 2024 Thursday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 527 words\nByline: MATT O'BRIEN\nBody\nU.S. federal agencies must show that their artificial intelligence tools aren't harming the public, or stop using them, \nunder new rules unveiled by the White House on Thursday.\n\"When government agencies use AI tools, we will now require them to verify that those tools do not endanger the \nrights and safety of the American people,\" Vice President Kamala Harris told reporters ahead of the announcement. \nEach agency by December must have a set of concrete safeguards that guide everything from facial recognition \nscreenings at airports to AI tools that help control the electric grid or determine mortgages and home insurance. \nThe new policy directive being issued to agency heads Thursday by the White House's Office of Management and \nBudget is part of the more sweeping AI executive order signed by President Joe Biden in October. \nWhile Biden's broader order also attempts to safeguard the more advanced commercial AI systems made by \nleading technology companies, such as those powering generative AI chatbots, Thursday's directive will also affect \nAI tools that government agencies have been using for years to help with decisions about immigration, housing, \nchild welfare and a range of other services. \nAs an example, Harris said, \"If the Veterans Administration wants to use AI in VA hospitals to help doctors diagnose \npatients, they would first have to demonstrate that AI does not produce racially biased diagnoses.\" \nAgencies that can't apply the safeguards \"must cease using the AI system, unless agency leadership justifies why \ndoing so would increase risks to safety or rights overall or would create an unacceptable impediment to critical \nagency operations,\" according to a White House announcement. \nThe new policy also calls for two other \"binding requirements,\" Harris said. One is that federal agencies must hire a \nchief AI officer with the \"experience, expertise and authority\" to oversee all of the AI technologies used by that \nagency, she said. The other is that each year, agencies must make public an inventory of their AI systems that \nincludes an assessment of the risks they might pose. \nSome rules exempt intelligence agencies and the Department of Defense, which is having a separate debate about \nthe use of autonomous weapons. \nVP Harris says US agencies must show their AI tools aren't harming people's safety or rights U.S. federal \nagencies must show that their artificial intelligence ....\nShalanda Young, the director of the Office of Management and Budget, said the new requirements are also meant \nto strengthen positive uses of AI by the U.S. government. \n\"When used and overseen responsibly, AI can help agencies to reduce wait times for critical government services, \nimprove accuracy and expand access to essential public services,\" Young said. \nThe new oversight was applauded Thursday by civil rights groups, some of which have spent years pushing federal \nand local law enforcement agencies to curb the use of face recognition technology tied to wrongful arrests of Black \nmen. \nA September report by the U.S. Government Accountability Office reviewing seven federal law enforcement \nagencies, including the FBI, found that they cumulatively conducted more than 60,000 searches using face-\nscanning technology without first requiring sufficient staff training on how it works and how to interpret results.\nGraphic\n \nVice President Kamala Harris delivers a speech on healthcare at an event in Raleigh, N.C., Tuesday, March 26, \n2024. (AP Photo/Matt Kelley)\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Leaders Press Advantage With Congress as China Tensions Rise",
        "media": "The New York Times",
        "time": "March 29, 2024",
        "section": "TECHNOLOGY",
        "length": "873 words",
        "byline": "Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C.",
        "story_text": "A.I. Leaders Press Advantage With Congress as China Tensions Rise\nThe New York Times \nMarch 27, 2024 Wednesday 09:10 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 873 words\nByline: Cecilia Kang Cecilia Kang reports on technology and regulatory policy and is based in Washington D.C. \nShe has written about technology for over two decades.\nHighlight: Silicon Valley chiefs are swarming the Capitol to try to sway lawmakers on the dangers of falling behind \nin the artificial intelligence race.\nBody\nIn recent weeks, American lawmakers have moved to ban the Chinese-owned app TikTok. President Biden \nreinforced his commitment to overcome China’s rise in tech. And the Chinese government added chips from Intel \nand AMD to a blacklist of imports.\nNow, as the tech and economic cold war between the United States and China accelerates, Silicon Valley’s leaders \nare capitalizing on the strife with a lobbying push for their interests in another promising field of technology: artificial \nintelligence.\nOn May 1, more than 100 tech chiefs and investors, including Alex Karp, the head of the defense contractor \nPalantir, and Roelof Botha, the managing partner of the venture capital firm Sequoia Capital, will come to \nWashington for a daylong conference and private dinner focused on drumming up more hawkishness toward \nChina’s progress in A.I.\nDozens of lawmakers, including Speaker Mike Johnson, Republican of Louisiana, will also attend the event, the Hill \n&amp; Valley Forum, which will include fireside chats and keynote discussions with members of a new House A.I. \ntask force.\nTech executives plan to use the event to directly lobby against A.I. regulations that they consider onerous, as well \nas ask for more government spending on the technology and research to support its development. They also plan \nto ask to relax immigration restrictions to bring more A.I. experts to the United States.\nThe event highlights an unusual area of agreement between Washington and Silicon Valley, which have long \nclashed on topics like data privacy, children’s online protections and even China.\n“At the end of the day, whether you are in industry or government, or whatever side of the aisle you are on, we play \nfor team America,” said Representative Jay Obernolte of California, the Republican chair of the House A.I. Task \nForce, who will give opening remarks at the conference.\nAfter the rise over the past year of generative A.I. — technology that has the potential to fundamentally shift \nproductivity, innovation and employment trends — lobbying on the topic has exploded. Last year, more than 450 \ncompanies, nonprofits, universities and trade groups reported lobbying on A.I., more than double the number of \norganizations in the previous year, according to OpenSecrets, a nonprofit research group. Palantir more than \ndoubled its spending on lobbying last year to $5 million, its highest level on record.\nA.I. Leaders Press Advantage With Congress as China Tensions Rise\nAs tech leaders capitalize on anti-China fervor in Washington, civil society groups and academics warn that debates \nover competition for tech leadership could hurt efforts to regulate potential harms, such as the risks that some A.I. \ntools could kill jobs, spread disinformation, and disrupt elections.\n“The dynamics of this U.S. v. China race has profound implications because on the other side of slowing down \nChina is minimal friction and regulation for U.S. companies,” said Amba Kak, who is the executive director of the AI \nNow Institute, a research firm, and a former senior adviser on A.I. to the Federal Trade Commission.\nA.I. experts say China lags the United States in generative A.I. by at least a year and may be falling further behind, \nalthough a new study suggests that it is ahead in the talent.\nMay’s event is being organized by Jacob Helberg, a senior adviser to Palantir and a member of the U.S.-China \nEconomic and Security Review Commission, which reports to Congress on national security threats posed by \nChina. He expanded this year’s forum from the first gathering he organized last year, which was a private dinner \nfocused largely on the threat of TikTok, which is owned by Beijing-based ByteDance.\nIn addition to A.I., lawmakers speaking at the event in the Capitol will push for the Senate to pass legislation to ban \nTikTok, and Tom Mueller, a founding employee of SpaceX, will speak about the space race between the United \nStates and China. Attendees will include Senator Mike Rounds, Republican of South Dakota and the ranking \nmember of the Armed Services Committee, and Representative Ritchie Torres, a New York Democrat on the House \nSelect Committee on the Chinese Communist Party.\n“Tech companies can’t be neutral any more,” Mr. Helberg said, adding that he recuses himself from any work \ninvolving contracts on the U.S.-China Economic and Security Review Commission that could give Palantir an \nadvantage.\nVenture capitalists attending the event have dozens of A.I. investments. Sequoia has invested in more than 70 A.I. \nstartups. Khosla Ventures, a $15 billion venture firm, has several investments, including in OpenAI, the company \nbehind the ChatGPT chatbot.\n“It’s become even more obvious, even more critical, that we treat China as an adversary,” said Vinod Khosla, the \nhead of Khosla Ventures who will speak at the forum. “What I’m worrying about is Western values versus a different \nset of values in China.”\nPHOTOS: Clockwise from top left: Jacob Helberg, a member of the U.S.-China Economic and Security Review \nCommission; House Speaker Mike Johnson; and Representative Ritchie Torres, a Democrat on the House Select \nCommittee on the Chinese Communist Party. (PHOTOGRAPHS BY JASON ANDREW FOR THE NEW YORK \nTIMES; HAIYUN JIANG FOR THE NEW YORK TIMES; AMIR HAMJA/THE NEW YORK TIMES) This article \nappeared in print on page B4.\nLoad-Date: March 29, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 30, 2024",
        "section": "ECONOMY & COMPANIES",
        "length": "377 words",
        "byline": "Ishaan.Gera@timesgroup.com",
        "story_text": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation\nEconomic Times (E-Paper Edition)\nMarch 30, 2024 Saturday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY & COMPANIES\nLength: 377 words\nByline: Ishaan.Gera@timesgroup.com\nBody\nLas Vegas: India needs a regulator for artificial intelligence (AI), but it also needs to balance innovation and \nregulation, Prativa Mohapatra, managing director of Adobe India told ET. “We have long advocated for a risk-based \napproach to AI regulation. It is important to regulate high-risk AI for the safety of everyone, and it is equally \nimportant to allow innovation to flourish by allowing low-risk AI tools to be deployed quickly and without excessive \ncompliance regulations,” Mohapatra said in an interview on the sidelines of the Adobe Summit 2024. The company \nhas also been collaborating with other companies to create industry standards for establishing trust. \nLast year, Adobe announced the release of its generative AI model called Firefly, which focuses on generating \nimages and text. At this year’s conference, the company announced the integration of its AI tool with other \nmarketing applications and the expansion of Firefly to audio, video and 3D modelling. Mohapatra said India will be \nan essential market for the company. “India is on a very positive trajectory. It's part of Adobe's global strategy of \ninternational expansion,” she said, adding that the company has witnessed double-digit growth here. “India is a \nmarket that we are very focused on, and the growth is good.  We are calling India a hypergrowth market.” Adobe \ncounts banking and financial services, and aviation among its biggest clients in India but also sees scope for \nexpansion. “I think companies' digital transformation journeys have just started,” Mohapatra said, pointing out that \nAdobe is looking to aid many other businesses, especially small and medium enterprises. However, she said the \ncompany is more cautious about its approach than during the Covid years. “Three years back, during Covid, many \nSMEs went to our commerce platform. Everybody wanted to sell digitally. But now they're going more cautiously \ninto commerce and analytics,” Mohapatra said. Mohapatra lauded the government’s effort to ensure skilling begins \nfrom a young age, but said it is important to see how this can be embedded in the curriculum and how engineering \ncolleges and others adapt to new skill requirements. (The reporter is in the US to cover Adobe Summit 2024 at the \ninvitation of Adobe)\nLoad-Date: March 30, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 30, 2024",
        "section": "ECONOMY & COMPANIES",
        "length": "377 words",
        "byline": "Ishaan.Gera@timesgroup.com",
        "story_text": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation\nEconomic Times (E-Paper Edition)\nMarch 30, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY & COMPANIES\nLength: 377 words\nByline: Ishaan.Gera@timesgroup.com\nBody\nLas Vegas: India needs a regulator for artificial intelligence (AI), but it also needs to balance innovation and \nregulation, Prativa Mohapatra, managing director of Adobe India told ET. “We have long advocated for a risk-based \napproach to AI regulation. It is important to regulate high-risk AI for the safety of everyone, and it is equally \nimportant to allow innovation to flourish by allowing low-risk AI tools to be deployed quickly and without excessive \ncompliance regulations,” Mohapatra said in an interview on the sidelines of the Adobe Summit 2024. The company \nhas also been collaborating with other companies to create industry standards for establishing trust. \nLast year, Adobe announced the release of its generative AI model called Firefly, which focuses on generating \nimages and text. At this year’s conference, the company announced the integration of its AI tool with other \nmarketing applications and the expansion of Firefly to audio, video and 3D modelling. Mohapatra said India will be \nan essential market for the company. “India is on a very positive trajectory. It's part of Adobe's global strategy of \ninternational expansion,” she said, adding that the company has witnessed double-digit growth here. “India is a \nmarket that we are very focused on, and the growth is good.  We are calling India a hypergrowth market.” Adobe \ncounts banking and financial services, and aviation among its biggest clients in India but also sees scope for \nexpansion. “I think companies' digital transformation journeys have just started,” Mohapatra said, pointing out that \nAdobe is looking to aid many other businesses, especially small and medium enterprises. However, she said the \ncompany is more cautious about its approach than during the Covid years. “Three years back, during Covid, many \nSMEs went to our commerce platform. Everybody wanted to sell digitally. But now they're going more cautiously \ninto commerce and analytics,” Mohapatra said. Mohapatra lauded the government’s effort to ensure skilling begins \nfrom a young age, but said it is important to see how this can be embedded in the curriculum and how engineering \ncolleges and others adapt to new skill requirements. (The reporter is in the US to cover Adobe Summit 2024 at the \ninvitation of Adobe)\nLoad-Date: March 30, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "US evaluating risks related to adoption of AI tools by federal agencies",
        "media": "The Economic Times",
        "time": "March 30, 2024",
        "section": "TECH & INTERNET",
        "length": "426 words",
        "byline": " ",
        "story_text": "US evaluating risks related to adoption of AI tools by federal agencies\nThe Economic Times\nMarch 31, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 426 words\nBody\nIn the latest move to curb the expansive reach of artificial intelligence (AI) tools, the US House of Representatives \nbanned congressional staffers from using Microsoft's Copilot generative AI assistant. According to a report in \nAxios, the application is seen as a threat in terms of data leakage. “The Microsoft Copilot application has been \ndeemed by the Office of Cybersecurity to be a risk to users due to the threat of leaking House data to non-House \napproved cloud services,” said Catherine Szpindor, the House chief administrative officer.Policymakers in the US \nhave been looking at potential risks in the adoption of AI tools by federal agencies and the adequacy of safeguards \nto protect individual privacy and ensure fair treatment.“We recognise government users have higher security \nrequirements for data. That's why we announced a roadmap of Microsoft AI tools, like Copilot, that meet federal \ngovernment security and compliance requirements that we intend to deliver later this year,\" a Microsoft \nspokesperson told Reuters.Last year, two senators from the Democratic and Republican parties introduced \nlegislation to ban the use of AI that creates content falsely depicting candidates in political advertisements to \ninfluence federal elections. The US is set to go to polls later this year. Kamala Harris’ diktatMeanwhile, US vice \npresident Kamala Harris said federal agencies must show that their artificial intelligence tools aren't harming the \npublic, or stop using them. \n\"When government agencies use AI tools, we will now require them to verify that those tools do not endanger the \nrights and safety of the American people,\" she told reporters.Earlier, on Thursday, the White House said it is \nrequiring federal agencies using AI to adopt “concrete safeguards” by December 1 to protect Americans' rights and \nensure safety as the government expands AI use in a wide range of applications.Each agency must have a set of \nconcrete safeguards that guide everything from facial recognition screenings at airports to AI tools that help control \nthe electric grid or determine mortgages and home insurance.Thursday's directive will also affect AI tools that \ngovernment agencies have been using for years to help with decisions about immigration, housing, child welfare, \nand a range of other services.As an example, Harris said, \"If the Veterans Administration wants to use AI in VA \nhospitals to help doctors diagnose patients, they would first have to demonstrate that AI does not produce racially \nbiased diagnoses.\" For Reprint Rights: timescontent.com\nLoad-Date: March 30, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "How India's rising gaming ecosystem is bringing investment opportunities",
        "media": "The Economic Times",
        "time": "March 30, 2024",
        "section": "SMALLBIZ-TECHNOLOGY",
        "length": "995 words",
        "byline": " ",
        "story_text": "How India's rising gaming ecosystem is bringing investment opportunities\nThe Economic Times\nMarch 30, 2024 Saturday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: SMALLBIZ-TECHNOLOGY\nLength: 995 words\nBody\nThe global gaming industry is currently at an inflexion point, having evolved to a worth of $184 billion through \ndecades of technological advancements, distribution enhancements, and innovative business models. With the \nadvent of cutting-edge technologies such as Gen AI, cloud gaming, 5G, and XR, the industry is growing rapidly.In \ntandem with this global trend, India's gaming ecosystem is also witnessing remarkable growth. In 2023, it reached \n500 million active gamers, with 200 million ready to invest in enhancing their experiences. This equates to over 50% \nof smartphone users playing games, a substantial portion of whom are willing to make in-game \npurchases.However, despite its success, the gaming sector still needs to exhibit more within the ecosystem in \nterms of domestic studios, AI infrastructure, and gamification tools. \nThese gaps present untapped opportunities for new-age companies. Following a comprehensive analysis of gaming \ntrends worldwide, Eximius Ventures has identified specific areas with potential for emerging companies from India \nto capitalise on.Domestic StudiosThe Indian gaming landscape is witnessing significant growth, yet the content \navailable often feels disconnected from the local sociocultural context. However, the boom in Indian gamers has \nattracted foreign developers to establish studios in the country, paving the way for veterans from these studios to \npotentially create gaming experiences that resonate more with Indian audiences.Currently, out of the top 10 highest \nrevenue-generating games in India, only one, Teen Patti, is developed by an Indian studio, signalling the potential \nfor local studios to adopt global best practices and succeed in the Indian market. Additionally, there's a noticeable \nshift in Indian gamer preferences, with casual and hyper-casual games dominating the market, while mid-core and \nhardcore games are gaining traction, boasting higher ARPPUs.As India continues to export its culture and content \nacross various mediums, gaming emerges as the next frontier. With globally acclaimed Indian titles like Raji - An \nAncient Epic, Asura, and Rainswept setting precedents, Indian studios are poised for further success on the global \nstage. Moreover, the buoyant period in Indian cinema, with movies like Dangal, Secret Superstar, and Baahubali 2 \nenjoying widespread acceptance, opens doors for developers to not only cater to the Indian market but also expand \ntheir reach internationally.Publisher EcosystemAs the developer ecosystem in India strengthens, there is also a \ngrowing need for a greater presence of domestic publishers, similar to ecosystems in the USA and China, where \ndomestic publishers dominate customer spending. Despite India's substantial developer community, Indian \npublishers command only 6% of the local mobile market, indicating the necessity for stronger domestic \npublishing.The global publisher market has witnessed significant outcomes, with players like Voodoo (France), Say \nGames (Cyprus), and Lion Studios (USA), with Rollic (Istanbul) building a thriving outcome. Additionally, while the \nmajority of the market is focused on casual and hyper-casual games, there are opportunities for mid-core and \nhardcore games, particularly for Indian publishers with specialised knowledge.Notable Indian examples such as \nGlance and Jio Games have shown impressive growth, albeit with a focus on generic platforms. This suggests the \npotential for specialisation within specific sectors, signalling opportunities for further growth and diversification in the \nIndian gaming industry.InfrastructureThe rapid technology growth in game development has exacerbated the \nresource demands, widening the gap between large studios and smaller developers. Despite this gap, the advent of \ngenerative AI promises to be a better playing field.Indie studios, operating with limited resources, demonstrate \nagility in game development. Nearly half complete prototyping within a month, and 62% finalise development within \na year. To sustain this, they leverage technology, especially AI, to streamline development and enhance user-\nHow India 's rising gaming ecosystem is bringing investment opportunities\ngenerated content (UGC) and live operations.UGC emerged as a key gaming trend, driving major developers to \nintegrate engaging mechanics for viral growth. The fusion of UGC and AI is expected to produce tools that expedite \ndevelopment, simplify UGC creation, and streamline game lifecycle management, offering significant innovation \nopportunities in areas like world creation, AI behaviour mapping, live operations, creator tools, and AI-driven user \nacquisition.Gamification Gamification integrates traditional game design elements into non-gaming platforms to \nenhance user experience, significantly improving user retention and engagement.The global gamification market is \ngrowing rapidly, with a 27.4% CAGR expected from 2020 to 2025. Currently, 70% of Global 2000 businesses have \nadopted gamification. In retail, it has led to a 700% increase in customer acquisitions and can boost user \nengagement by 48% and customer retention by 22%. Additionally, implementing gamification in sales processes \nresults in a 25.3% increase in sales conversion.As consumer-facing brands like Amazon, Flipkart, and Starbucks \nutilise gamification to enhance their operations, there's a growing trend among new-age companies across Fintech, \nCommerce, and Health to develop similar solutions. This presents an opportunity for companies to assist in creating \nthese platforms and capitalise on the expanding gamification market.In conclusion, emerging trends like publisher \necosystem, infrastructure development, and gamification offer fertile ground for investment in the gaming industry. \nWith India's burgeoning gaming market and global trends gaining momentum, investments in these areas can pave \nthe way for sustained growth and enduring success in the dynamic realm of online media & gaming.The writer is \nFounder and Managing Partner, Eximius Ventures. For Reprint Rights: timescontent.com\nLoad-Date: March 30, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I.-Generated Garbage Is Polluting Our Culture",
        "media": "The New York Times",
        "time": "March 31, 2024",
        "section": "Section SR; Column 0; Sunday Review Desk; Pg. 10; GUEST ESSAY",
        "length": "1619 words",
        "byline": "By Erik Hoel",
        "story_text": "A.I.-Generated Garbage Is Polluting Our Culture\nThe New York Times\nMarch 31, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section SR; Column 0; Sunday Review Desk; Pg. 10; GUEST ESSAY\nLength: 1619 words\nByline: By Erik Hoel\nBody\nIncreasingly, mounds of synthetic A.I.-generated outputs drift across our feeds and our searches. The stakes go far \nbeyond what's on our screens. The entire culture is becoming affected by A.I.'s runoff, an insidious creep into our \nmost important institutions. \n  Consider science. Right after the blockbuster release of GPT-4, the latest artificial intelligence model from OpenAI \nand one of the most advanced in existence, the language of scientific research began to mutate. Especially within \nthe field of A.I. itself.\n  A study published this month examined scientists' peer reviews -- researchers' official pronouncements on others' \nwork that form the bedrock of scientific progress -- across a number of high-profile and prestigious scientific \nconferences studying A.I. At one such conference, those peer reviews used the word ''meticulous'' more than 34 \ntimes as often as reviews did the previous year. Use of ''commendable'' was around 10 times as frequent, and \n''intricate,'' 11 times. Other major conferences showed similar patterns.\n  Such phrasings are, of course, some of the favorite buzzwords of modern large language models like ChatGPT. In \nother words, significant numbers of researchers at A.I. conferences were caught handing their peer review of \nothers' work over to A.I. -- or, at minimum, writing them with lots of A.I. assistance. And the closer to the deadline \nthe submitted reviews were received, the more A.I. usage was found in them.\n  If this makes you uncomfortable -- especially given A.I.'s current unreliability -- or if you think that maybe it \nshouldn't be A.I.s reviewing science but the scientists themselves, those feelings highlight the paradox at the core \nof this technology: It's unclear what the ethical line is between scam and regular usage. Some A.I.-generated \nscams are easy to identify, like the medical journal paper featuring a cartoon rat sporting enormous genitalia. Many \nothers are more insidious, like the mislabeled and hallucinated regulatory pathway described in that same paper -- \na paper that was peer reviewed as well (perhaps, one might speculate, by another A.I.?).\n  What about when A.I. is used in one of its intended ways -- to assist with writing? Recently, there was an uproar \nwhen it became obvious that simple searches of scientific databases returned phrases like ''As an A.I. language \nmodel'' in places where authors relying on A.I. had forgotten to cover their tracks. If the same authors had simply \ndeleted those accidental watermarks, would their use of A.I. to write their papers have been fine?\n  What's going on in science is a microcosm of a much bigger problem. Post on social media? Any viral post on X \nnow almost certainly includes A.I.-generated replies, from summaries of the original post to reactions written in \nChatGPT's bland Wikipedia-voice, all to farm for follows. Instagram is filling up with A.I.-generated models, Spotify \nwith A.I.-generated songs. Publish a book? Soon after, on Amazon there will often appear A.I.-generated \n''workbooks'' for sale that supposedly accompany your book (which are incorrect in their content; I know because \nA.I.-Generated Garbage Is Polluting Our Culture\nthis happened to me). Top Google search results are now often A.I.-generated images or articles. Major media \noutlets like Sports Illustrated have been creating A.I.-generated articles attributed to equally fake author profiles. \nMarketers who sell search engine optimization methods openly brag about using A.I. to create thousands of \nspammed articles to steal traffic from competitors.\n  Then there is the growing use of generative A.I. to scale the creation of cheap synthetic videos for children on \nYouTube. Some example outputs are Lovecraftian horrors, like music videos about parrots in which the birds have \neyes within eyes, beaks within beaks, morphing unfathomably while singing in an artificial voice, ''The parrot in the \ntree says hello, hello!'' The narratives make no sense, characters appear and disappear randomly, and basic facts \nlike the names of shapes are wrong. After I identified a number of such suspicious channels on my newsletter, The \nIntrinsic Perspective, Wired found evidence of generative A.I. use in the production pipelines of some accounts \nwith hundreds of thousands or even millions of subscribers.\n  As a neuroscientist, this worries me. Isn't it possible that human culture contains within it cognitive micronutrients -\n- things like cohesive sentences, narrations and character continuity -- that developing brains need? Einstein \nsupposedly said: ''If you want your children to be intelligent, read them fairy tales. If you want them to be very \nintelligent, read them more fairy tales.'' But what happens when a toddler is consuming mostly A.I.-generated \ndream-slop? We find ourselves in the midst of a vast developmental experiment.\n  There's so much synthetic garbage on the internet now that A.I. companies and researchers are themselves \nworried, not about the health of the culture, but about what's going to happen with their models. As A.I. capabilities \nramped up in 2022, I wrote on the risk of culture's becoming so inundated with A.I. creations that when future A.I.s \nare trained, the previous A.I. output will leak into the training set, leading to a future of copies of copies of copies, as \ncontent became ever more stereotyped and predictable. In 2023 researchers introduced a technical term for how \nthis risk affected A.I. training: model collapse. In a way, we and these companies are in the same boat, paddling \nthrough the same sludge streaming into our cultural ocean.\n  With that unpleasant analogy in mind, it's worth looking to what is arguably the clearest historical analogy for our \ncurrent situation: the environmental movement and climate change. For just as companies and individuals were \ndriven to pollute by the inexorable economics of it, so, too, is A.I.'s cultural pollution driven by a rational decision to \nfill the internet's voracious appetite for content as cheaply as possible. While environmental problems are nowhere \nnear solved, there has been undeniable progress that has kept our cities mostly free of smog and our lakes mostly \nfree of sewage. How?\n  Before any specific policy solution was the acknowledgment that environmental pollution was a problem in need of \noutside legislation. Influential to this view was a perspective developed in 1968 by Garrett Hardin, a biologist and \necologist. Dr. Hardin emphasized that the problem of pollution was driven by people acting in their own interest, and \nthat therefore ''we are locked into a system of 'fouling our own nest,' so long as we behave only as independent, \nrational, free-enterprisers.'' He summed up the problem as a ''tragedy of the commons.'' This framing was \ninstrumental for the environmental movement, which would come to rely on government regulation to do what \ncompanies alone could or would not.\n  Once again we find ourselves enacting a tragedy of the commons: short-term economic self-interest encourages \nusing cheap A.I. content to maximize clicks and views, which in turn pollutes our culture and even weakens our \ngrasp on reality. And so far, major A.I. companies are refusing to pursue advanced ways to identify A.I.'s handiwork \n-- which they could do by adding subtle statistical patterns hidden in word use or in the pixels of images.\n  A common justification for inaction is that human editors can always fiddle around with whatever patterns are \nimplemented if they know enough. Yet many of the issues we're experiencing are not caused by motivated and \ntechnically skilled malicious actors; they're caused mostly by regular users' not adhering to a line of ethical use so \nfine as to be nigh nonexistent. Most would be uninterested in advanced countermeasures to statistical patterns \nenforced into outputs that should, ideally, mark them as A.I.-generated.\nA.I.-Generated Garbage Is Polluting Our Culture\n  That's why the independent researchers were able to detect A.I. outputs in the peer review system with \nsurprisingly high accuracy: They actually tried. Similarly, right now teachers across the nation have created home-\nbrewed output-side detection methods, like adding in hidden requests for patterns of word use to essay prompts \nthat appear only when copy-pasted.\n  In particular, A.I. companies appear opposed to any patterns baked into their output that can improve A.I.-\ndetection efforts to reasonable levels, perhaps because they fear that enforcing such patterns might interfere with \nthe model's performance by constraining its outputs too much -- although there is no current evidence this is a risk. \nDespite public pledges to develop more advanced watermarking, it's increasingly clear that the companies are \ndragging their feet because it goes against the A.I. industry's bottom line to have detectable products.\n  To deal with this corporate refusal to act we need the equivalent of a Clean Air Act: a Clean Internet Act. Perhaps \nthe simplest solution would be to legislatively force advanced watermarking intrinsic to generated outputs, like \npatterns not easily removable. Just as the 20th century required extensive interventions to protect the shared \nenvironment, the 21st century is going to require extensive interventions to protect a different, but equally critical, \ncommon resource, one we haven't noticed up until now since it was never under threat: our shared human culture.\n  Erik Hoel is a neuroscientist, a novelist and the author of The Intrinsic Perspective newsletter.\n  The Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com\n  Follow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nhttps://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html\nGraphic\n \nThis article appeared in print on page SR10.               \nLoad-Date: March 31, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Life at Guantánamo Bay",
        "media": "The New York Times",
        "time": "March 31, 2024",
        "section": "BRIEFING",
        "length": "1945 words",
        "byline": "Desiree Ibekwe Desiree Ibekwe is a writer for The Morning newsletter, based in London.",
        "story_text": "Life at Guantánamo Bay\nThe New York Times \nMarch 31, 2024 Sunday 18:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BRIEFING\nLength: 1945 words\nByline: Desiree Ibekwe Desiree Ibekwe is a writer for The Morning newsletter, based in London.\nHighlight: Inside a new season of “Serial.”\nBody\nInside a new season of “Serial.”\nAround 780 people have been detained at the prison at Guantánamo Bay since it opened in January 2002. Thirty \nmen remain there today, many of whom have not been charged.\nThe podcast “Serial,” which debuted in 2014 with the story of a questionable murder conviction, has dedicated its \nnew season to Guantánamo. Over nine episodes, it tells the story of the prison through a personal lens, by way of \nconversations with people who worked or were detained there.\nI spoke with the hosts, Sarah Koenig and Dana Chivvis, about the show. \nDesiree: There’s an interesting political story to be told about Guantánamo, but why did you decide to tell this story \nthrough the people who lived through it?\nSarah: The government threw all of these normal people on Guantánamo, and they had to sort out how on earth \nare we supposed to behave in here, how are we supposed to make sense of this? So over the course of 20 years, \nyou saw this thing, which was kind of like a terrible spasm in the national response to 9/11, harden into something \nthat was trying to justify and sustain itself. I think that’s what we were interested in: Who were those people who are \nhaving to make decisions, who are having to survive a thing not of their own making, and what did that look like and \nwhat did that feel like?\nIn the reporting of the podcast, did anything upend your preconceived notions or surprise you about Guantánamo?\nDana: The people who work in Guantánamo for the military rotate in and out about every nine months, but the \nprisoners have been there, so very quickly the prisoners learned how the prison operated better than the guard \nforce did. I heard a lot of stories about prisoners who would correct the guards and be like, “No, no, you need to \ngive me 10 squares of toilet paper,” or “You’re not handcuffing me right. Let me show you how to do it.”\nAnd I think the thing that surprised me the most as I started digging into it was that we were told by the Bush \nadministration that these are the worst of the worst, these are the people who did 9/11. As it turned out, they were \nnot, and the people who worked in Guantánamo — and a lot of people in the Bush administration — knew that from \nwithin months of the first prisoners’ arriving. There wasn’t a tremendous amount of screening going on. It was really \nlike an overflow room for the war in Afghanistan. And the prisoners who are there, and were there, have now been \ndipped in this toxic paint of this place forever.\nOne thing that struck me was that while things at Guantánamo were scary and unsettling, it was also a really \nsurreal place.\nLife at Guantánamo Bay\nSarah: I think the thing that a lot of people either don’t know or forget is that it’s just a naval base. Like a normal \nnaval base, it has sandwich shops and a coffee shop and a school and a chapel. It’s just when you first visit there, \nyou’re not psychically ready to see that. But by the third time I went, I wasn’t even noticing that stuff. Once, I was \nthere with these young people from various N.G.O.s who were there to observe the court, and one guy goes, “I got \na coffee this morning, and then this woman told me to ‘have a nice day,’ and I was like, What are you talking about? \nHow can I have a nice day?” And I was like, “Oh, you’re a newcomer. You’ll get over that.”\nHow have you seen Guantánamo evolve?\nSarah: When I was first reporting on it in the early 2000s, there were hundreds of prisoners there, and it felt very \nactive and very violent and very scary and very shocking. And in 2015, I think there were 122 people. It wasn’t like \nthe bad wasn’t still happening, but it had dug in for the long term. These people just live here now, and the court is \nchugging along. It felt very like an institution.\nTo me it feels like it’s in its last throes, and it’s sort of falling apart. But it’s interesting — I spoke to an attorney who \nhas been working there for more than a decade on the same case, and he was like, “Every time you come, you \nthink this thing is about to fall apart, and I’m here to tell you: You have no idea whether it’s falling apart.”\nListen to the first two episodes of the season here.\nFor more\n• Sarah and Dana spoke with Times Insider about the making of the show.\n• Photography is largely forbidden at Guantánamo. Carol Rosenberg, who reports on the prison for The Times, \nexplains what you can learn from a single image.\nTHE LATEST NEWS\nMiddle East\n• Benjamin Netanyahu’s cabinet is divided about whether ultra-Orthodox Jews should be required to join the \nIsraeli Army.\n• Negotiations on a cease-fire in the war in Gaza are expected to resume today in Cairo, according to an \nEgyptian state-owned TV channel.\n• Airdrops play a prominent role in efforts to deliver food and supplies to Gaza. A Times photographer observed \none aboard a Jordanian Air Force plane. See the images.\n• U.S.-led airstrikes against the Houthi militia and inflation have raised concerns about a new humanitarian \ncrisis in Yemen.\nMore International News\n• Ukrainian brigades are running their own marketing campaigns outside the official mobilization system to \nattract recruits.\n• The death in Spain of a Russian defector has raised fears that Russia’s European spy networks continue to \noperate despite attempts to dismantle them.\n• The police in Peru raided President Dina Boluarte’s home and the presidential palace in search of Rolex \nwatches as part of an “unlawful enrichment” investigation.\n• Protests by farmers in Europe have emboldened a far right that thrives on grievances.\n• See images from Reuters of Christians around the world celebrating Holy Week.\nOther Big Stories\nLife at Guantánamo Bay\n• A woman in Texas who was falsely charged with murder after using an abortion pill has filed a lawsuit against \nthe local prosecutor’s office and its leaders.\n• Thousands gathered on Long Island for the funeral of a New York City police officer who was shot to death in \nthe line of duty. His killing has become a political flashpoint.\n• Chance Perdomo, an actor known for his roles in the series “Gen V” and “Chilling Adventures of Sabrina,” \ndied on Friday at 27.\nTHE SUNDAY DEBATE\nWill the collapse of Francis Scott Key Bridge hurt the Port of Baltimore?\nYes. The bridge’s destruction has cut off one of the busiest ports in the country. “The biggest generator of who \nknows how many millions of sticky dollars over the centuries, dollars that stuck right here, is at a standstill,” Will \nEnglund writes for The Washington Post.\nNo. The problems won’t be as severe as people think. “Given the hard lessons learned during the past decade, \nsignificant price shocks or product shortages are unlikely,” Tinglong Dai writes for The Baltimore Banner.\nFROM OPINION\nVladimir Putin will use the attack on a concert hall near Moscow to escalate his campaign in Ukraine, Hanna Notte \nargues.\nGenerative A.I. loves buzzwords. As the technology spreads, it will pollute our language, Erik Hoel writes.\nThe science writer Ed Yong deepened his connection to animals through birding.\nHere are columns by Nicholas Kristof on the benefits of marriage and Ross Douthat on the future of American \nreligion.\nMORNING READS\nJane Goodall: The activist celebrated her upcoming 90th birthday with 90 dogs.\nDoomscrolling? Try ringing a doorbell for fish instead.\nMystery: Old newspaper stories helped researchers find a 19th-century shipwreck in Lake Michigan.\nPoints: Credit card companies are changing the fees they charge merchants. That may affect travel rewards.\nVows: He expresses himself through art, she through math. They have found ways to merge work with love.\nLives Lived: Robert Moskowitz was a painter who was inspired by the New York City skyline. His work took on new \nmeaning after 9/11. Moskowitz died at 88.\nTHE NEW YORK TIMES MAGAZINE\n• The chef José Andrés is famous for his food and for his humanitarian work. See behind the scenes at \nZaytinya, where he still approves every dish on the menu.\n• Screenland: Why does every Southern accent in a movie sound so bad\n• A writer recommends turning on a classic rock radio station in your car.\nTALK | FROM THE MAGAZINE\nLife at Guantánamo Bay\nI’ll be part of a new Q. and A. franchise, The Interview, that’s launching in late April. Before then, I’m sharing some \nof my favorite past interviews. This one, from 2022, is with the stand-up comedian Jerrod Carmichael, who was \nthen dealing with the familial fallout of having publicly come out as gay in his HBO special “Rothaniel.”\nYou’re trying hard to tell the truth these days, but aside from what’s going on with your family, does committing to \nhonesty present problems in your day-to-day life? It’s not easy to be fully honest with everyone.\nOh, people get mad at you. I don’t like that but I know that’s a part of telling the truth — the reaction isn’t consistent. \nI used to lie to keep a consistent reaction, which was all about Like me, like me, like me. I told the truth about who I \nam and now there’s a rift with my mom. I was lying because it was more pleasant.\nFor other people.\nFor other people! And thus for me. I don’t like not talking to my mom. But it’s a byproduct of being honest. That’s the \npart of coming out, the relationship with my mom, that I don’t like. It was a truth I was afraid to say because of that \none relationship. But it’s who I am.\nWhat did you feel inside when you delivered material that conveyed one thing about who you were when the truth \nwas another?\nI don’t know, man. I don’t know because I wouldn’t have called myself gay. I could not accept that. That’s why it’s \nimportant for me to say it now. There are certain phrases that have no substitute. Like “I’m gay” or telling someone \n“I’m sorry.” But people can live in cognitive dissonance. I did.\nRead more of the interview here.\nBOOKS\nKing of King’s: “Carrie,” Stephen King’s debut novel, was published 50 years ago next month. The Times Book \nReview’s editor, Gilbert Cruz, offers a guide to the author’s essential books.\nBorrowed titles: Many modern book names allude to other works of literature. A.O. Scott explores our habit of \ndressing up new writing in secondhand words.\nOur editors’ picks: “The Morningside,” a book about a version of New York in climate collapse, and seven other \nbooks.\nTimes best sellers: Percival Everett’s book “Erasure” was adapted into the Oscar-winning movie “American Fiction.” \nHis latest release, “James,” a reimagining of Mark Twain’s “Adventures of Huckleberry Finn,” is new on the \nhardcover fiction list.\nTHE MORNING RECOMMENDS …\nCool down with a good fan.\nLook good in the best cheap sunglasses.\nSpend 36 hours in Mumbai, India.\nRead “Where Rivers Part,” a memoir by Kao Kalia Yang.\nTHE WEEK AHEAD\nWhat to Watch For\n• Today is Easter.\n• Connecticut, New York, Rhode Island and Wisconsin hold primaries on Tuesday. \nLife at Guantánamo Bay\n• Donald Trump has until Thursday to post a $175 million bond in his New York civil fraud case, after an \nappeals court lowered the amount and gave him more time.\nMeal Plan\nIn her Five Weeknight Dishes newsletter, Emily Weinstein encourages you to make rice bowls for dinner. Try out \nEric Kim’s extremely delicious and extremely simple bacon and egg don. Or whip up a salmon and rice bowl, which \ncomes together in one pot.\nNOW TIME TO PLAY\nHere is today’s Spelling Bee. Yesterday’s pangram was jackpot.\nCan you put eight historical events — including the chicken, the egg and the reign of Louis XIV — in chronological \norder? Take this week’s Flashback quiz.\nAnd here are today’s Mini Crossword, Wordle, Sudoku and Connections.\nThanks for spending part of your weekend with The Times.\nSign up here to get this newsletter in your inbox. Reach our team at themorning@nytimes.com.\nPHOTO: The Camp Justice sign at Guantanamo Bay sits next to the military commissions expeditionary legal \ncomplex. (PHOTOGRAPH BY Marisa Schwartz Taylor/The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: March 31, 2024"
    }
]