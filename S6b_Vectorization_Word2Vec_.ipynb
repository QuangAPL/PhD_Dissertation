{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Vectorization with Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0 -0.171622  0.108064 -0.004670  0.135769 -0.061985  0.033696 -0.083035   \n",
      "1 -0.173188  0.108872 -0.011226  0.149500 -0.060411  0.030855 -0.087352   \n",
      "2 -0.161672  0.112374 -0.004053  0.143581 -0.054326  0.036501 -0.091227   \n",
      "3 -0.164241  0.099705  0.003212  0.147389 -0.054037  0.040446 -0.089972   \n",
      "4 -0.173503  0.111899 -0.009761  0.142923 -0.061620  0.028136 -0.087772   \n",
      "\n",
      "        7         8         9    ...       290       291       292       293  \\\n",
      "0 -0.044343 -0.053279  0.027136  ...  0.072206 -0.002153 -0.096771  0.076867   \n",
      "1 -0.038299 -0.051793  0.017950  ...  0.070757 -0.018967 -0.095223  0.087860   \n",
      "2 -0.033716 -0.058064  0.023707  ...  0.076147 -0.021281 -0.104619  0.087541   \n",
      "3 -0.038930 -0.050870  0.019841  ...  0.076469 -0.026876 -0.090544  0.083582   \n",
      "4 -0.043422 -0.054692  0.019189  ...  0.071873 -0.011160 -0.101913  0.088150   \n",
      "\n",
      "        294       295       296       297       298       299  \n",
      "0 -0.035954 -0.157954 -0.096791 -0.029140 -0.118637  0.144923  \n",
      "1 -0.024788 -0.153044 -0.094819 -0.026300 -0.111151  0.148181  \n",
      "2 -0.021475 -0.149235 -0.096759 -0.020485 -0.118954  0.143590  \n",
      "3 -0.020577 -0.139066 -0.087549 -0.018857 -0.119284  0.145713  \n",
      "4 -0.027522 -0.160419 -0.103203 -0.027260 -0.109165  0.148344  \n",
      "\n",
      "[5 rows x 300 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def word2vec_data(input_file_path, output_file_path, embedding_model_path):\n",
    "    # Load pre-trained Word2Vec model\n",
    "    word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(embedding_model_path, binary=True)\n",
    "    \n",
    "    # Load tokenized data from input file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Initialize an empty list to store embeddings\n",
    "    embeddings = []\n",
    "    \n",
    "    # Iterate through each tokenized document\n",
    "    for doc in data:\n",
    "        # Remove non-relevant tokens\n",
    "        doc = [token for token in doc if token in word2vec_model.key_to_index]\n",
    "        # Initialize an empty list to store embeddings for tokens in the document\n",
    "        doc_embeddings = []\n",
    "        # Iterate through tokens in the document\n",
    "        for token in doc:\n",
    "            # Retrieve word embedding for the token\n",
    "            embedding = word2vec_model[token]\n",
    "            doc_embeddings.append(embedding)\n",
    "        # Calculate the mean embedding for the document\n",
    "        if doc_embeddings:\n",
    "            mean_embedding = np.mean(doc_embeddings, axis=0)\n",
    "            embeddings.append(mean_embedding)\n",
    "        else:\n",
    "            # If no embeddings found for the document, use zeros\n",
    "            embeddings.append(np.zeros(word2vec_model.vector_size))\n",
    "    \n",
    "    # Convert embeddings to DataFrame\n",
    "    embeddings_df = pd.DataFrame(embeddings)\n",
    "    \n",
    "    # Print first few rows of the DataFrame\n",
    "    print(embeddings_df.head())\n",
    "    \n",
    "    # Save embeddings to CSV file\n",
    "    embeddings_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Example usage:\n",
    "input_file_path = \"tokenized_300.json\"\n",
    "output_file_path = \"word2vec_vectorized_300.csv\"\n",
    "embedding_model_path = \"/Users/QuangAP/gensim/GoogleNews-vectors-negative300.bin\"\n",
    "word2vec_data(input_file_path, output_file_path, embedding_model_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
