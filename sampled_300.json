[
    {
        "file_name": "The_Economic_Times_Aug2023",
        "header": "Amazon to offer fulfilment infrastructure to sellers outside its platform",
        "media": "The Economic Times",
        "time": "August 31, 2023",
        "section": "TECH & INTERNET",
        "length": "468 words",
        "byline": "Annapurna Roy",
        "story_text": "Amazon to offer fulfilment infrastructure to sellers outside its platform\nThe Economic Times\nSeptember 1, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 468 words\nByline: Annapurna Roy\nBody\nAmazon on Thursday announced the launch of a new product, Multichannel Fulfilment, which will enable sellers to \nrun their online businesses by accessing its fulfilment infrastructure, even if they are not on the e-commerce \nplatform. \"Very excited to announce this product called Multichannel Fulfilment. And what that does is it allows \nsmall businesses, direct-to-consumer brands, to take advantage of our fulfilments infrastructure, and they don't \nhave to worry about where their inventory is, what does their fulfilment looks like, irrespective of whether they are \nselling on Amazon or off Amazon. \nSo no matter where you are a digital seller, you can run your operations using the Amazon fulfilment infrastructure,\" \nsaid Amit Agarwal, senior vice president, emerging markets at Amazon, speaking at the Amazon Smbhav Summit \nin the national capital on Thursday.Amazon is also leveraging generative artificial intelligence (genAI) in their \nbusiness, rolling out Sahai, a genAI-driven virtual assistant to help small businesses navigate their online \noperations. \"In the spirit of future technologies...we are very excited to announce a generative AI solution for small \nbusinesses. This is a first-of-its-kind generative AI solution that we are launching in India for small businesses. It's \ncalled Sahai - it's a play on 'help' and 'AI'\", Agarwal said.With the tagline 'making sellers' life easy', Sahai will help \nsellers on Amazon clarify their queries, list products, generate product attributes, analyse trends in their sales, and \nso on.Commenting on the role that genAI technology will play for Amazon going forward, Russell Grandinetti, senior \nvice president, international consumer, said, \"In the next ten years, there won't be any aspect of our business that \nwon't be transformed in some meaningful way by this.\"Into its tenth year in India, the tech giant further announced \nthat it had signed a memorandum of understanding (MoU) with the Indian Postal Service to create a \"first-of-its-\nkind, seamlessly integrated\" cross-border logistics solution that will expand the opportunity of global selling for \nbusinesses. This will make more 'real' the vision of local products reaching customers in New York, Agarwal said. \nThis came as Amazon pledged to hit $8 billion in cumulative exportsfrom India in 2023, to bolster the Indian \ngovernment's goal of $20 billion in exports by 2025.It is also partnering with the Indian Railways to make use of the \nfreight corridors, which will enable sellers to sell to customers across India in a faster and more efficient way.\"I'm \nvery enthusiastic about the next ten years, and I think we're just getting started,\" said Grandinetti, adding that \nAmazon will be part of India's transformation as it becomes the world's third-largest economy. For Reprint Rights: \ntimescontent.com\nLoad-Date: August 31, 2023"
    },
    {
        "file_name": "you_need_to_know_Dec2023",
        "header": "The New York Times is suing OpenAI over copyright breaches, here's what",
        "media": "you need to know",
        "time": "December 27, 2023",
        "section": "TECH LATEST, TECH LATEST, TECH LATEST & IP AND PATENTS NEWS",
        "length": "431 words",
        "byline": "James Powel, USA TODAY",
        "story_text": "The New York Times is suing OpenAI over copyright breaches, here's what \nyou need to know\nUSA Today Online\nDecember 27, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST, TECH LATEST, TECH LATEST & IP AND PATENTS NEWS\nLength: 431 words\nByline: James Powel, USA TODAY\nBody\nThe New York Times has filed a civil lawsuit against OpenAI and Microsoft in Federal District Court in Manhattan \nWednesday, claiming that the technology companies used the newspaper's content to train its artificial intelligence, \nbreaching copyright protections.\nThe Times does not ask for a specific dollar amount but says that the lawsuit, \"seeks to hold them (the defendants) \nresponsible for the billions of dollars in statutory and actual damages that they owe for the unlawful copying and use \nof The Times’s uniquely valuable works.\"\nNeither company has responded to the lawsuit publicly. USA Today has reached out to both Microsoft and OpenAI \nand will update this story if we receive a response.\nThe lawsuit comes at a pivotal moment for artificial intelligence as the technology has proliferated in recent years.\n\"The future of generative AI models requires vast amounts of training data, determining what data is protected and \nwhat data may fall under fair use is 'the' question,\" Shelly Palmer, CEO at The Palmer Group, a tech strategy \nadvisory group, said in his \"Think About This\" newsletter Wednesday.\nWhat is OpenAI?\nOpenAI is an artificial intelligence company that was founded in 2015 and has recently faced a power struggle \nwithin the company centered around co-founder and CEO Sam Altman. \nThe company is best known for its generative artificial intelligence chat-bot, ChatGPT, that was launched in \nNovember of 2022.\nData too open: FTC opens investigation into ChatGPT company OpenAI over inaccuracies, data protection\nOthers who have sued over copyright infringement\nComedian Sarah Siverman and two others sued OpenAI and Meta, Facebook's parent company, claiming that, \n\"their copyrighted materials were ingested and used to train ChatGPT.\"\nA collection of authors, including Jonathan Franzen and George R.R. Martin, also sued OpenAI this year alleging \nthat the company ingested their work to train its artificial intelligence. \nGetty Images sued Stability AI in February claiming that the company committed, \"brazen infringement of Getty \nImages’ intellectual property on a staggering scale,\" to train its technology.\nThe New York Times is suing OpenAI over copyright breaches, here's what you need to know\nAI and other media outlets\nEarlier this year The Associated Press signed an agreement with OpenAI to license news stories. \nAxel Springer, the company that owns POLITICO and Business Insider, signed a similar agreement with OpenAI \nthat allows ChatGPT to provide summaries of articles from the company's properties.\nRead the lawsuit\nThis article originally appeared on USA TODAY: The New York Times is suing OpenAI over copyright breaches, \nhere's what you need to know\nLoad-Date: December 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "OpenAI Completes Deal That Values the Company at $80 Billion",
        "media": "The New York Times",
        "time": "February 18, 2024",
        "section": "TECHNOLOGY",
        "length": "540 words",
        "byline": "Cade Metz and Tripp Mickle Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual",
        "story_text": "OpenAI Completes Deal That Values the Company at $80 Billion\nThe New York Times \nFebruary 16, 2024 Friday 22:46 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 540 words\nByline: Cade Metz and Tripp Mickle Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual \nreality and other emerging areas of technology. Tripp Mickle reports on Apple and Silicon Valley for The Times and \nis based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot \ntaxis.&amp;#160;\nHighlight: The A.I. start-up’s valuation tripled in less than 10 months.\nBody\nThe A.I. start-up’s valuation tripled in less than 10 months.\nOpenAI has completed a deal that values the San Francisco artificial intelligence company at $80 billion or more, \nnearly tripling its valuation in less than 10 months, according to three people with knowledge of the deal.\nThe company would sell existing shares in a so-called tender offer led by the venture firm Thrive Capital, the people \nsaid. The deal lets employees cash out their shares in the company, rather than a traditional funding round that \nwould raise money for business operations.\nOpenAI, which declined to comment, is now one of the world’s most valuable tech start-ups, behind ByteDance and \nSpaceX, according to figures from the data tracker CB Insights.\nThe deal is another example of the Silicon Valley deal-making machine pumping money into a handful of \ncompanies that specialize in generative A.I. — technology that can generate text, sounds and images on its own. \nThe funding boom kicked off early last year, after OpenAI captured the public’s imagination with the release of the \nonline chatbot ChatGPT.\n(The New York Times sued OpenAI and its partner, Microsoft, in December, claiming copyright infringement of \nnews content related to A.I. systems.)\nThe deal comes at a critical time for OpenAI, providing it with an important vote of confidence after a year of \ncontroversy. In November, the company’s board fired Sam Altman, its chief executive, because it lost confidence in \nhis leadership. The dismissal ignited a week of chaos and threw the company’s future into doubt, as employees \nthreatened to resign in solidarity with Mr. Altman. Ultimately, he was reinstated and several board members \nresigned.\nIn an attempt to resolve last year’s turmoil, OpenAI hired the law firm WilmerHale to review the board’s actions and \nMr. Altman’s leadership. WilmerHale is expected to finish its report on the episode early this year.\nThe company agreed to a similar deal early last year. The venture-capital firms Thrive Capital, Sequoia Capital, \nAndreessen Horowitz and K2 Global agreed to buy OpenAI shares in a tender offer, valuing the company at around \n$29 billion.\nOpenAI Completes Deal That Values the Company at $80 Billion\nThrive declined to comment.\nInvestors are eager to pour money into A.I. companies. Last January, Microsoft invested $10 billion in OpenAI, \nbringing its total investment in the San Francisco start-up to $13 billion.\nSince then, Anthropic, an OpenAI rival, has raised $6 billion from Google and Amazon. Cohere, a start-up founded \nby former Google researchers, raised $270 million, bringing its total funding to more than $440 million, and \nInflection AI, founded by a former Google executive, also raised a $1.3 billion round, bringing its total to $1.5 billion.\nOpenAI appeared to be close to finalizing its latest deal in November, when Mr. Altman was unexpectedly fired. In \nthe week that followed, the potential deal loomed over Mr. Altman’s efforts to negotiate his way back into the \ncompany. Before he was reinstated, over 700 of the company’s 770 employees signed a petition calling for his \nreinstatement.\nPHOTO: OpenAI had been close to finalizing a deal in the fall when Sam Altman, its chief executive, was fired. \n(PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) This article appeared in print on page B2.\nLoad-Date: February 18, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "'Cognizant Clocks 100+ Gen AI-Engagements'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 8, 2023",
        "section": "COMPANIES",
        "length": "165 words",
        "byline": "Sai.Ishwar@timesgroup.com",
        "story_text": "'Cognizant Clocks 100+ Gen AI-Engagements'\nEconomic Times (E-Paper Edition)\nAugust 8, 2023 Tuesday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 165 words\nByline: Sai.Ishwar@timesgroup.com\nBody\nBengaluru:Cognizant has said it has bagged more than 100 active early client engagements focussed on cognitive \nand generative AI in a bid to become market leader in the technology.  The New Jersey-based firm said it has \nalready produced more than 3,000 ideas in the generative AI domain and has “hundreds” of projects using AI \nservices within the context of IT services delivery, showed an internal note from chief executive Ravi Kumar S to \nemployees. “We are designing generative AI offerings in conjunction with our partners for industry-specific \nsolutions, cross-industry use cases and productivity enablement under themes like transforming code processes, \nimproving the customer and employee experience, product innovations, software and coding, and knowledge \nmanagement, to name a few,” the note reviewed by ET said. This comes as the NASDAQ-listed firm, during its \nearnings call last week, announced investing about $1 billion over the next three years to build generative AI \ncapabilities.\nLoad-Date: August 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Real Solutions to Reduce Plastics Pollution",
        "media": "The New York Times",
        "time": "June 6, 2023",
        "section": "Section A; Column 0; Editorial Desk; Pg. 23; LETTERS",
        "length": "1173 words",
        "byline": " ",
        "story_text": "Real Solutions to Reduce Plastics Pollution\nThe New York Times\nJune 6, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Editorial Desk; Pg. 23; LETTERS\nLength: 1173 words\nBody\nTo the Editor: \n  Re ''To Keep Plastic Out of Oceans, Start With Rivers,'' by Boyan Slat (Opinion guest essay, May 28):\n  When your bathtub is overflowing, what is the first thing you do? Find a mop or turn off the faucet?\n  Unfortunately, Mr. Slat's projects for in-the-water plastic collection are mops. Big, expensive, technical mops, but \nstill mops.\n  Meanwhile, the plastic pollution tap remains wide open. Plastic production is estimated to triple in the next three \ndecades.\n  Only 9 percent of all the plastic waste ever produced since the start of this industry has been recycled. Also, a \nlarge portion of ocean plastic sinks and is out of the reach of surface mops. So the mop strategy has been tried. It \nhas failed.\n  The effective solution, evident in the history of other antipollution campaigns, is to stop the problem at the source. \nThat's why California, Canada, Chile, France and indeed the European Union have passed laws mandating \nreductions in single-use plastic production.\n  Sadly, Mr. Slat's plastic cleanup strategy distracts consumers, policymakers and philanthropists from the real \nsolution, which is winning tough anti-single-use plastic pollution policies at the national and international levels.\n  Andrew SharplessWashingtonThe writer is C.E.O. of Oceana, an international advocacy organization dedicated to \nocean conservation.\n  To the Editor:\n  As the second of five negotiation sessions for a global plastics treaty has just come to a close, we cannot afford to \n''prepare for a future in which humanity uses more plastic, not less,'' as Boyan Slat proposes.\n  A decade ago, when Mr. Slat started the Ocean Cleanup, people were mistakenly focused on plastic pollution as \nan ocean ''litter'' issue. But we now know that toxic plastics and the particles they shed pollute Earth's air, land and \nwaters, as well as plants, animals and our bodies.\n  Plastics warm the climate. They pollute during extraction and refining of their fossil fuel ingredients, and during \ntheir manufacturing, transportation, storage, use and disposal. Plastics' pollution disproportionately harms low-\nincome and rural neighborhoods, as well as Black, Indigenous and other people of color communities.\nReal Solutions to Reduce Plastics Pollution\n  An effective global plastics treaty will recognize plastic's full costs, drastically reduce industries' plastic production, \nand implement the plastic-free reuse, refill, repair and share systems we need to eliminate wastefulness -- rather \nthan enabling the problem to grow worse by distracting us with false solutions like cleanups and recycling. \n  Erica CirinoWashingtonThe writer is communications manager for Plastic Pollution Coalition and the author of \n''Thicker Than Water: The Quest for Solutions to the Plastic Crisis.''\n  Trump's MAGA Army\n  To the Editor:\n  Re ''Trump Wants to Party Like It's 1776,'' by Michelle Cottle (Opinion, June 5):\n  This has nothing to do with America, and everything to do with Donald Trump. He needs his flock to come to his \naid as he is unable to fight for himself while he tries to hold off the criminal charges being leveled against him.\n  The big, tough guy will use his MAGA army to fight his fight for him. He will use American sentimentalism as his \ntool as he lies his way to ousting our democracy and installing himself as our monarch in chief.\n  There are so many Americans willing to fly the Trump flag alongside the American flag, it is truly alarming.\n  Bob BascelliSeaford, N.Y.\n  How the West Helped Erdogan Win\n  To the Editor:\n  Re ''Turkey's Election Is a Warning About Trump'' (column, May 31):\n  While Bret Stephens is right to point out how President Recep Tayyip Erdogan of Turkey leveraged nationalism to \nwin re-election and what it might mean for Donald Trump, he did not highlight how Western leaders allowed this \nunlikely victory to happen despite Turkish economic conditions.\n  For more than 20 years, U.S. presidents from both political parties have turned a blind eye to Mr. Erdogan's rising \nauthoritarianism and egregious behavior by not holding him accountable and turning to Ankara's role in NATO as a \ngeopolitical trade-off. This type of transactional diplomacy is not only dangerous but also gives cover to despots like \nMr. Erdogan who feel that they can say and do whatever they want with impunity.\n  In many ways, Mr. Erdogan's victory says more about us than about him. We have only ourselves to blame.\n  Stephan PechdimaldjiSan Ramon, Calif.\n  Canned Music on Broadway\n  To the Editor:\n  Re ''Broadway Musicians Object to David Byrne's 'Here Lies Love''' (Arts, June 1):\n  It isn't only Broadway musicians who should object to the injection of all recorded music on a Broadway stage. \nPeople who come to Broadway expect something more than they could experience in some local production.\n  Theater is a living art. Audiences want to see and hear live actors and live musicians. Asking folks to spend \nhundreds of dollars to hear canned music doesn't cut it. Broadway's brand is first class. Canned music is not.\n  I have another reason to support the musicians' union: Before I was a first-night critic, I was a performer. Often our \nonly rehearsal breaks came because of union support.\n  Leida SnowNew YorkThe writer is a former critic at WINS-AM.\nReal Solutions to Reduce Plastics Pollution\n  A.I.'s Existential Threat\n  To the Editor:\n  Re ''A.I. Poses 'Risk of Extinction,' Tech Leaders Warn'' (front page, May 31):\n  The more than 350 leaders in artificial intelligence aren't the only people scared to death by this fast-evolving \ntechnology.\n  Two-thirds of American adults believe that generative A.I. poses a threat to humanity, according to a national poll \nwe conducted. Additionally, more than four in five agree that it would be simple for someone to abuse the \ntechnology to do harm. A majority also believes that regulation is warranted.\n  Business is clearly enamored by A.I.'s power, but across all income and education levels, society worries that this \nnew marvel may be the atomic bomb of the 21st century.\n  Will JohnsonChicagoThe writer is the C.E.O. of the Harris Poll.\n  A Social Media Upside\n  To the Editor:\n  Re ''Advisory Says Teens Face Risk on Social Sites'' (front page, May 24):\n  While I agree with the sentiment in the article about the surgeon general's warning that social media may harm \nchildren and adolescents, I wonder why there is not more of an emphasis on what we can do than what we \nshouldn't do with social media.\n  As an aging millennial, I know that social media is here to stay. What if we invested in promoting content that \nimproves, not harms, users' lives instead?\n  A wealth of research shows that engaging in art education builds strength across the life span and in the very \nworkings of our brains. As the pandemic proved true for many, including me, social media is a robust art and arts \neducation platform, from YouTube tutorials to communities of artists on Facebook to TikTok's short-form content \nteaching techniques.\n  Young people deserve the time and space to engage in the visual learning of art education, which can very well \nbegin with the social media we fear.\n  Lindsey Frances JonesNew York\nhttps://www.nytimes.com/2023/06/05/opinion/letters/plastics-pollution.html\nGraphic\n \nThis article appeared in print on page A23.               \nLoad-Date: June 6, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Pressed by Biden, Big Tech Agrees to A.I. Rules",
        "media": "The New York Times",
        "time": "July 22, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "1344 words",
        "byline": "By Michael D. Shear, Cecilia Kang and David E. Sanger",
        "story_text": "Pressed by Biden, Big Tech Agrees to A.I. Rules\nThe New York Times\nJuly 22, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 1344 words\nByline: By Michael D. Shear, Cecilia Kang and David E. Sanger\nBody\nAmazon, Google and Meta are among the companies that announced the guidelines as they race to outdo each \nother with versions of artificial intelligence.\nSeven leading A.I. companies in the United States have agreed to voluntary safeguards on the technology's \ndevelopment, the White House announced on Friday, pledging to manage the risks of the new tools even as they \ncompete over the potential of artificial intelligence. \n  The seven companies -- Amazon, Anthropic, Google, Inflection, Meta, Microsoft and OpenAI -- formally made their \ncommitment to new standards for safety, security and trust at a meeting with President Biden at the White House \non Friday afternoon.\n  ''We must be cleareyed and vigilant about the threats emerging from emerging technologies that can pose -- don't \nhave to but can pose -- to our democracy and our values,'' Mr. Biden said in brief remarks from the Roosevelt Room \nat the White House.\n  ''This is a serious responsibility; we have to get it right,'' he said, flanked by the executives from the companies. \n''And there's enormous, enormous potential upside as well.''\n  The announcement comes as the companies are racing to outdo each other with versions of A.I. that offer \npowerful new ways to create text, photos, music and video without human input. But the technological leaps have \nprompted fears about the spread of disinformation and dire warnings of a ''risk of extinction'' as artificial intelligence \nbecomes more sophisticated and humanlike.\n  The voluntary safeguards are only an early, tentative step as Washington and governments across the world seek \nto put in place legal and regulatory frameworks for the development of artificial intelligence. The agreements include \ntesting products for security risks and using watermarks to make sure consumers can spot A.I.-generated material.\n  But lawmakers have struggled to regulate social media and other technologies in ways that keep up with the \nrapidly evolving technology.\n  The White House offered no details of a forthcoming presidential executive order that aims to deal with another \nproblem: how to control the ability of China and other competitors to get ahold of the new artificial intelligence \nprograms, or the components used to develop them.\n  The order is expected to involve new restrictions on advanced semiconductors and restrictions on the export of the \nlarge language models. Those are hard to secure -- much of the software can fit, compressed, on a thumb drive.\nPressed by Biden, Big Tech Agrees to A.I. Rules\n  An executive order could provoke more opposition from the industry than Friday's voluntary commitments, which \nexperts said were already reflected in the practices of the companies involved. The promises will not restrain the \nplans of the A.I. companies nor hinder the development of their technologies. And as voluntary commitments, they \nwill not be enforced by government regulators.\n  ''We are pleased to make these voluntary commitments alongside others in the sector,'' Nick Clegg, the president \nof global affairs at Meta, the parent company of Facebook, said in a statement. ''They are an important first step in \nensuring responsible guardrails are established for A.I. and they create a model for other governments to follow.''\n  As part of the safeguards, the companies agreed to security testing, in part by independent experts; research on \nbias and privacy concerns; information sharing about risks with governments and other organizations; development \nof tools to fight societal challenges like climate change; and transparency measures to identify A.I.-generated \nmaterial.\n  In a statement announcing the agreements, the Biden administration said the companies must ensure that \n''innovation doesn't come at the expense of Americans' rights and safety.''\n  ''Companies that are developing these emerging technologies have a responsibility to ensure their products are \nsafe,'' the administration said in a statement.\n  Brad Smith, the president of Microsoft and one of the executives attending the White House meeting, said his \ncompany endorsed the voluntary safeguards.\n  ''By moving quickly, the White House's commitments create a foundation to help ensure the promise of A.I. stays \nahead of its risks,'' Mr. Smith said.\n  Anna Makanju, the vice president of global affairs at OpenAI, described the announcement as ''part of our ongoing \ncollaboration with governments, civil society organizations and others around the world to advance AI governance.''\n  For the companies, the standards described Friday serve two purposes: as an effort to forestall, or shape, \nlegislative and regulatory moves with self-policing, and a signal that they are dealing with the new technology \nthoughtfully and proactively.\n  But the rules on which they agreed are largely the lowest common denominator, and can be interpreted by every \ncompany differently. For example, the firms committed to strict cybersecurity measures around the data used to \nmake the language models on which generative A.I. programs are developed. But there is no specificity about \nwhat that means, and the companies would have an interest in protecting their intellectual property anyway.\n  And even the most careful companies are vulnerable. Microsoft, one of the firms attending the White House event \nwith Mr. Biden, scrambled last week to counter a Chinese government-organized hack on the private emails of \nAmerican officials who were dealing with China. It now appears that China stole, or somehow obtained, a ''private \nkey'' held by Microsoft that is the key to authenticating emails -- one of the company's most closely guarded pieces \nof code.\n  Given such risks, the agreement is unlikely to slow the efforts to pass legislation and impose regulation on the \nemerging technology.\n  Paul Barrett, the deputy director of the Stern Center for Business and Human Rights at New York University, said \nthat more needed to be done to protect against the dangers that artificial intelligence posed to society.\n  ''The voluntary commitments announced today are not enforceable, which is why it's vital that Congress, together \nwith the White House, promptly crafts legislation requiring transparency, privacy protections, and stepped-up \nresearch on the wide range of risks posed by generative A.I.,'' Mr. Barrett said in a statement.\n  European regulators are poised to adopt A.I. laws later this year, which has prompted many of the companies to \nencourage U.S. regulations. Several lawmakers have introduced bills that include licensing for A.I. companies to \nPressed by Biden, Big Tech Agrees to A.I. Rules\nrelease their technologies, the creation of a federal agency to oversee the industry, and data privacy requirements. \nBut members of Congress are far from agreement on rules.\n  Lawmakers have been grappling with how to address the ascent of A.I. technology, with some focused on risks to \nconsumers and others acutely concerned about falling behind adversaries, particularly China, in the race for \ndominance in the field.\n  This week, the House committee on competition with China sent bipartisan letters to U.S.-based venture capital \nfirms, demanding a reckoning over investments they had made in Chinese A.I. and semiconductor companies. For \nmonths, a variety of House and Senate panels have been questioning the A.I. industry's most influential \nentrepreneurs and critics to determine what sort of legislative guardrails and incentives Congress ought to be \nexploring.\n  Many of those witnesses, including Sam Altman of OpenAI, have implored lawmakers to regulate the A.I. industry, \npointing out the potential for the new technology to cause undue harm. But that regulation has been slow to get \nunderway in Congress, where many lawmakers still struggle to grasp what exactly A.I. technology is.\n  In an attempt to improve lawmakers' understanding, Senator Chuck Schumer, Democrat of New York and the \nmajority leader, began a series of sessions this summer to hear from government officials and experts about the \nmerits and dangers of artificial intelligence across a number of fields.\n  Karoun Demirjian contributed reporting from Washington.Karoun Demirjian contributed reporting from Washington.\nhttps://www.nytimes.com/2023/07/21/us/politics/ai-regulation-biden.html\nGraphic\n \nPHOTOS: ''This is a serious responsibility,'' President Biden said on Friday. (A1)\n President Biden met with executives of A.I. companies, including leaders of Microsoft and Google, on Friday. The \nWhite House said they must ensure their products are safe. (PHOTOGRAPHS BY KENNY HOLSTON/THE NEW \nYORK TIMES) (A13) This article appeared in print on page A1, A13.               \nLoad-Date: July 22, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "In A.I. Race, Microsoft and Google Choose Speed Over Caution",
        "media": "The New York Times",
        "time": "June 28, 2023",
        "section": "TECHNOLOGY",
        "length": "1766 words",
        "byline": "Nico Grant and Karen Weise",
        "story_text": "In A.I. Race, Microsoft and Google Choose Speed Over Caution\nThe New York Times \nApril 7, 2023 Friday 18:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1766 words\nByline: Nico Grant and Karen Weise\nHighlight: Technology companies were once leery of what some artificial intelligence could do. Now the priority is \nwinning control of the industry’s next big thing.\nBody\nTechnology companies were once leery of what some artificial intelligence could do. Now the priority is winning \ncontrol of the industry’s next big thing.\nIn March, two Google employees, whose jobs are to review the company’s artificial intelligence products, tried to \nstop Google from launching an A.I. chatbot. They believed it generated inaccurate and dangerous statements.\nTen months earlier, similar concerns were raised at Microsoft by ethicists and other employees. They wrote in \nseveral documents that the A.I. technology behind a planned chatbot could flood Facebook groups with \ndisinformation, degrade critical thinking and erode the factual foundation of modern society.\nThe companies released their chatbots anyway. Microsoft was first, with a splashy event in February to reveal an \nA.I. chatbot woven into its Bing search engine. Google followed about six weeks later with its own chatbot, Bard.\nThe aggressive moves by the normally risk-averse companies were driven by a race to control what could be the \ntech industry’s next big thing — generative A.I., the powerful new technology that fuels those chatbots.\nThat competition took on a frantic tone in November when OpenAI, a San Francisco start-up working with Microsoft, \nreleased ChatGPT, a chatbot that has captured the public imagination and now has an estimated 100 million \nmonthly users.\nThe surprising success of ChatGPT has led to a willingness at Microsoft and Google to take greater risks with their \nethical guidelines set up over the years to ensure their technology does not cause societal problems, according to \n15 current and former employees and internal documents from the companies.\nThe urgency to build with the new A.I. was crystallized in an internal email sent last month by Sam Schillace, a \ntechnology executive at Microsoft. He wrote in the email, which was viewed by The New York Times, that it was an \n“absolutely fatal error in this moment to worry about things that can be fixed later.”\nWhen the tech industry is suddenly shifting toward a new kind of technology, the first company to introduce a \nproduct “is the long-term winner just because they got started first,” he wrote. “Sometimes the difference is \nmeasured in weeks.”\nLast week, tension between the industry’s worriers and risk-takers played out publicly as more than 1,000 \nresearchers and industry leaders, including Elon Musk and Apple’s co-founder Steve Wozniak, called for a six-\nmonth pause in the development of powerful A.I. technology. In a public letter, they said it presented “profound risks \nto society and humanity.”\nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nRegulators are already threatening to intervene. The European Union proposed legislation to regulate A.I., and Italy \ntemporarily banned ChatGPT last week. In the United States, President Biden on Tuesday became the latest official \nto question the safety of A.I.\n“Tech companies have a responsibility to make sure their products are safe before making them public,” he said at \nthe White House. When asked if A.I. was dangerous, he said: “It remains to be seen. Could be.”\nThe issues being raised now were once the kinds of concerns that prompted some companies to sit on new \ntechnology. They had learned that prematurely releasing A.I. could be embarrassing. Seven years ago, for \nexample, Microsoft quickly pulled a chatbot called Tay after users nudged it to generate racist responses.\nResearchers say Microsoft and Google are taking risks by releasing technology that even its developers don’t \nentirely understand. But the companies said that they had limited the scope of the initial release of their new \nchatbots, and that they had built sophisticated filtering systems to weed out hate speech and content that could \ncause obvious harm.\nNatasha Crampton, Microsoft’s chief responsible A.I. officer, said in an interview that six years of work around A.I. \nand ethics at Microsoft had allowed the company to “move nimbly and thoughtfully.” She added that “our \ncommitment to responsible A.I. remains steadfast.”\nGoogle released Bard after years of internal dissent over whether generative A.I.’s benefits outweighed the risks. It \nannounced Meena, a similar chatbot, in 2020. But that system was deemed too risky to release, three people with \nknowledge of the process said. Those concerns were reported earlier by The Wall Street Journal.\nLater in 2020, Google blocked its top ethical A.I. researchers, Timnit Gebru and Margaret Mitchell, from publishing a \npaper warning that so-called large language models used in the new A.I. systems, which are trained to recognize \npatterns from vast amounts of data, could spew abusive or discriminatory language. The researchers were pushed \nout after Dr. Gebru criticized the company’s diversity efforts and Dr. Mitchell was accused of violating its code of \nconduct after she saved some work emails to a personal Google Drive account.\nDr. Mitchell said she had tried to help Google release products responsibly and avoid regulation, but instead “they \nreally shot themselves in the foot.”\nBrian Gabriel, a Google spokesman, said in a statement that “we continue to make responsible A.I. a top priority, \nusing our A.I. principles and internal governance structures to responsibly share A.I. advances with our users.”\nConcerns over larger models persisted. In January 2022, Google refused to allow another researcher, El Mahdi El \nMhamdi, to publish a critical paper.\nDr. El Mhamdi, a part-time employee and university professor, used mathematical theorems to warn that the \nbiggest A.I. models are more vulnerable to cybersecurity attacks and present unusual privacy risks because they’ve \nprobably had access to private data stored in various locations around the internet.\nThough an executive presentation later warned of similar A.I. privacy violations, Google reviewers asked Dr. El \nMhamdi for substantial changes. He refused and released the paper through École Polytechnique.\nHe resigned from Google this year, citing in part “research censorship.” He said modern A.I.’s risks “highly \nexceeded” the benefits. “It’s premature deployment,” he added.\nAfter ChatGPT’s release, Kent Walker, Google’s top lawyer, met with research and safety executives on the \ncompany’s powerful Advanced Technology Review Council. He told them that Sundar Pichai, Google’s chief \nexecutive, was pushing hard to release Google’s A.I.\nJen Gennai, the director of Google’s Responsible Innovation group, attended that meeting. She recalled what Mr. \nWalker had said to her own staff.\nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nThe meeting was “Kent talking at the A.T.R.C. execs, telling them, ‘This is the company priority,’” Ms. Gennai said \nin a recording that was reviewed by The Times. “‘What are your concerns? Let’s get in line.’”\nMr. Walker told attendees to fast-track A.I. projects, though some executives said they would maintain safety \nstandards, Ms. Gennai said.\nHer team had already documented concerns with chatbots: They could produce false information, hurt users who \nbecome emotionally attached to them and enable “tech-facilitated violence” through mass harassment online.\nIn March, two reviewers from Ms. Gennai’s team submitted their risk evaluation of Bard. They recommended \nblocking its imminent release, two people familiar with the process said. Despite safeguards, they believed the \nchatbot was not ready.\nMs. Gennai changed that document. She took out the recommendation and downplayed the severity of Bard’s risks, \nthe people said.\nMs. Gennai said in an email to The Times that because Bard was an experiment, reviewers were not supposed to \nweigh in on whether to proceed. She said she “corrected inaccurate assumptions, and actually added more risks \nand harms that needed consideration.”\nGoogle said it had released Bard as a limited experiment because of those debates, and Ms. Gennai said \ncontinuing training, guardrails and disclaimers made the chatbot safer.\nGoogle released Bard to some users on March 21. The company said it would soon integrate generative A.I. into \nits search engine.\nSatya Nadella, Microsoft’s chief executive, made a bet on generative A.I. in 2019 when Microsoft invested $1 \nbillion in OpenAI. After deciding the technology was ready over the summer, Mr. Nadella pushed every Microsoft \nproduct team to adopt A.I.\nMicrosoft had policies developed by its Office of Responsible A.I., a team run by Ms. Crampton, but the guidelines \nwere not consistently enforced or followed, said five current and former employees.\nDespite having a “transparency” principle, ethics experts working on the chatbot were not given answers about what \ndata OpenAI used to develop its systems, according to three people involved in the work. Some argued that \nintegrating chatbots into a search engine was a particularly bad idea, given how it sometimes served up untrue \ndetails, a person with direct knowledge of the conversations said.\nMs. Crampton said experts across Microsoft worked on Bing, and key people had access to the training data. The \ncompany worked to make the chatbot more accurate by linking it to Bing search results, she added.\nIn the fall, Microsoft started breaking up what had been one of its largest technology ethics teams. The group, \nEthics and Society, trained and consulted company product leaders to design and build responsibly. In October, \nmost of its members were spun off to other groups, according to four people familiar with the team.\nThe remaining few joined daily meetings with the Bing team, racing to launch the chatbot. John Montgomery, an A.I. \nexecutive, told them in a December email that their work remained vital and that more teams “will also need our \nhelp.”\nAfter the A.I.-powered Bing was introduced, the ethics team documented lingering concerns. Users could become \ntoo dependent on the tool. Inaccurate answers could mislead users. People could believe the chatbot, which uses \nan “I” and emojis, was human.\nIn mid-March, the team was laid off, an action that was first reported by the tech newsletter Platformer. But Ms. \nCrampton said hundreds of employees were still working on ethics efforts.\nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nMicrosoft has released new products every week, a frantic pace to fulfill plans that Mr. Nadella set in motion in the \nsummer when he previewed OpenAI’s newest model.\nHe asked the chatbot to translate the Persian poet Rumi into Urdu, and then write it out in English characters. “It \nworked like a charm,” he said in a February interview. “Then I said, ‘God, this thing.’”\nAudio produced by Parin Behrooz.\nMike Isaac contributed reporting. Susan C. Beachy contributed research.\nAudio produced by Parin Behrooz. Mike Isaac contributed reporting. Susan C. Beachy contributed research. \nThis article appeared in print on page A1, A11.\nLoad-Date: June 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "OpenAI’s Chief Scientist and Co-Founder Is Leaving the Company",
        "media": "The New York Times",
        "time": "May 14, 2024",
        "section": "TECHNOLOGY",
        "length": "957 words",
        "byline": "Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other",
        "story_text": "OpenAI’s Chief Scientist and Co-Founder Is Leaving the Company\nThe New York Times \nMay 14, 2024 Tuesday 23:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 957 words\nByline: Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other \nemerging areas of technology.\nHighlight: In November, Ilya Sutskever joined three other OpenAI board members to force out Sam Altman, the \nchief executive, before saying he regretted the move.\nBody\nIn November, Ilya Sutskever joined three other OpenAI board members to force out Sam Altman, the chief \nexecutive, before saying he regretted the move.\nIlya Sutskever, the OpenAI co-founder and chief scientist who in November joined three other board members to \nforce out Sam Altman, the company’s high-profile chief executive, before saying he regretted the move, is leaving \nthe San Francisco A.I. company.\nDr. Sutskever’s departure, which the company announced in a blog post on Tuesday, closes another chapter in a \nstory that stunned Silicon Valley and that raised questions about whether Mr. Altman and his company were \nprepared to lead the tech industry into the age of artificial intelligence.\nAfter returning to OpenAI just five days after he was ousted, Mr. Altman reasserted his control and continued its \npush toward increasingly powerful technologies that worried some of his critics. Dr. Sutskever remained an OpenAI \nemployee, but he never returned to work.\n“This is an emotional day for all of us,” Mr. Altman said in an interview. “OpenAI would not exist without him and \ncertainly was shaped by him.”\nIn a statement, Dr. Sutskever said: “I have made the decision to leave OpenAI. The company’s trajectory has been \nnothing short of miraculous, and I’m confident that OpenAI will build A.G.I. that is both safe and beneficial.” A.G.I., \nor artificial general intelligence, is an as-yet-unbuilt technology that can do anything the brain can do.\nDr. Sutskever, 38, added that he was starting a new project, but did not elaborate.\nA key OpenAI researcher, Jakub Pachocki, will replace Dr. Sutskever as chief scientist at the company, which is \nvalued at more than $80 billion, according to a recent fund-raising deal.\nOn Monday, OpenAI unveiled a new version of its ChatGPT chatbot that can receive and respond to voice \ncommands, images and videos, joining tech giants like Google and Apple in a race toward a new kind of talking \ndigital assistant.\nFounded in 2015 by Mr. Altman, Elon Musk and several young researchers, including Dr. Sutskever, OpenAI has \nlong been at the forefront of A.I. research. Dr. Sutskever’s involvement provided the company with instant \ncredibility. As a graduate student at the University of Toronto, he had been part of an A.I. breakthrough involving \nneural networks — the technology that has driven the field’s progress over the last decade.\nOpenAI ’s Chief Scientist and Co-Founder Is Leaving the Company\nIn late 2022, OpenAI wowed the world with the release of ChatGPT, an online chatbot that could answer questions, \nwrite poetry, generate computer code and chat a lot like people. The tech industry quickly embraced what is called \ngenerative artificial intelligence — technologies that can generate text, images and other media on their own.\nThe result of more than a decade of research inside companies like OpenAI and Google, generative A.I. is poised \nto remake everything from email programs to internet search engines and digital assistants.\nMr. Altman became a spokesman for the shift toward generative A.I., testifying before Congress and meeting with \nlawmakers, regulators and investors around the world. In November, OpenAI’s board of directors unexpectedly \nousted him, saying he could no longer be trusted with the company’s plan to eventually create artificial general \nintelligence.\nThe OpenAI board had six people: three founders and three independent members. Dr. Sutskever voted with the \nthree outsiders to remove Mr. Altman as chief executive and chairman of the board, saying — without providing \nspecifics — that Mr. Altman had not been “consistently candid in his communications.”\nGreg Brockman, OpenAI’s president and another co-founder, resigned from the company in protest. So did Dr. \nPachocki.\nDays later, as hundreds of OpenAI employees threatened to quit, Dr. Sutskever said he regretted his decision to \nremove Mr. Altman and effectively stepped down from the board, leaving three independent members in opposition \nto Mr. Altman.\nMr. Altman returned as chief executive after he and the board agreed to replace two members with Bret Taylor, a \nformer Salesforce executive, and Lawrence Summers, a former U.S. Treasury secretary. Mr. Altman regained his \nboard seat several months later, as the board expanded to seven people.\nLast year, Dr. Sutskever helped create a Super Alignment team inside OpenAI to explore ways of ensuring that \nfuture versions of the technology would not do harm. Like others in the field, he had grown increasingly concerned \nthat A.I. could become dangerous and perhaps even destroy humanity.\nJan Leike, who ran the Super Alignment team alongside Dr. Sutskever, has also resigned from OpenAI. His role will \nbe taken by John Schulman, another company co-founder.\nIn the weeks leading up to Mr. Altman’s ouster, Dr. Pachocki, who helped oversee the creation of GPT-4, the \ntechnology at the heart of ChatGPT, was promoted to director of research at the company. After occupying a \nposition below Dr. Sutskever, he was elevated to a position alongside him, two people familiar with the moves said.\nAfter Mr. Altman was reinstated, Dr. Sutskever did not return to work. Mr. Altman indicated that he was hoping to \nnegotiate his return, but ultimately that was not possible.\nDr. Pachocki has effectively served as chief scientist since November. After Dr. Sutskever recruited him and others \nto join OpenAI, he was among the key researchers on several of the company’s most important projects, including, \nmost notably, GPT-4.\n“I am grateful to Ilya,” Dr. Pachocki said in an interview. “We have different and in many ways complementary styles \nof leadership.”\nMr. Altman said he talked with Dr. Sutskever on Tuesday. “He has pushed us — and will continue to push us — to, \nas he says, feel the A.G.I.,” Mr. Altman said.\nThis article appeared in print on page B6.\nLoad-Date: May 14, 2024\nOpenAI ’s Chief Scientist and Co-Founder Is Leaving the Company"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "PROFESSORS USE ORAL EXAMS TO FOIL AI CHEATS",
        "media": "Wall Street Journal Abstracts",
        "time": "June 3, 2023",
        "section": "A; Pg. 3",
        "length": "35 words",
        "byline": "DOUGLAS BELKIN",
        "story_text": "PROFESSORS USE ORAL EXAMS TO FOIL AI CHEATS\nWall Street Journal Abstracts\nJune 2, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 3\nLength: 35 words\nByline: DOUGLAS BELKIN\nBody\nABSTRACT\nProfessors around world are experimenting with oral exams to improve teaching and learning and discourage \ncheating, particularly as generative-artificial-intelligence systems like ChatGPT become popular (M)\nLoad-Date: June 3, 2023"
    },
    {
        "file_name": "The_Economic_Times_Feb2024",
        "header": "Sharp companies leverage data to build out healthcare LLMs",
        "media": "The Economic Times",
        "time": "February 15, 2024",
        "section": "TECH & INTERNET",
        "length": "560 words",
        "byline": "Suraksha P",
        "story_text": "Sharp companies leverage data to build out healthcare LLMs\nThe Economic Times\nFebruary 15, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 560 words\nByline: Suraksha P\nBody\nCompanies are leveraging healthcare data – hospital enterprise data and publicly available clinical trial data – to \ncreate large language models (LLMs) for hospitals and other enterprise clients.Firms such as Samsung Electronics' \nHarman and healthcare firm Vizzy have found this to be a viable revenue model as they have discovered ways to \nmonetise this data, said industry executives.Seetha Mahalaxmi Healthcare last year imported 256 graphics \nprocessing units (GPUs) to build BharatGPT, an indigenous generative artificial intelligence (AI) platform. Its \nCEO Vishnu Vardhan has co-founded another healthcare company Vizzy Inc, which has signed agreements with \ntwo hospital chains in India to build an LLM, called VizzyGPT, with hospital enterprise data. The hospitals will be \ncharged for the use of the LLM.Harman late last year launched a private LLM, known as HealthGPT. \nIt leverages generative AI to help healthcare professionals, researchers and institutions in advanced patient care, \nmedical research and decision-making.“We’re launching VizzyGPT soon and have imported the H100 GPUs on \nwhich you can build foundational language models. We’ve also secured an additional 1,000 GPUs from another \ncompany and are building an LLM for healthcare specifically, which will be implemented both in India and the US,” \nVardhan told ET.VizzyGPT, a multimodal model will be used to automate hospital processes, both clinical and non-\nclinical. It will be able to understand text, images, and audio and video files too, and will help automate the process \nof understanding X-rays and magnetic resonance imaging (MRI) scans.“If a doctor is doing an endoscopy, the LLM \nneeds to understand a video file, and have clinical knowledge too,” said Vardhan, who is an orthopaedic and \nballistic trauma surgeon.While Harman’s HealthGPT helps accelerate drug discovery and development by \nextracting insights from clinical trial data, one of the key challenges that people in the clinical field face is staying \nupdated in their respective medical specialties.There can be promising results from a clinical trial which a clinician is \nunaware of.Harman sourced data of publicly available clinical trials hosted on the website (clinicaltrials.gov) of the \nUS National Library of Medicine. It holds registrations from around 444,000 trials from 221 countries.As clinical trials \nprogress, the investigators or the pharma companies are expected to periodically report their results, Jai Ganesh, \nchief product officer, digital transformation solutions, Harman, told ET.To begin with, the company collected clinical \ntrial data from government sources for three medical conditions – breast cancer, immune diseases and heart \ndiseases.HealthGPT is not intended for usage by the public but by doctors, clinicians and regulators. “We are doing \na pilot with some of the customers and are also in discussion with global pharmaceutical companies. There are one \nor two external enterprise trial users of this solution who have used it for about a month now,” Ganesh said.The \ncompany is in talks with clinical research organisations and pharmaceutical companies involved in clinical trials. \nDepending on the number of users and data, the company will have a licensing fee-based structure for HealthGPT, \napart from which the model can be used with a subscription fee. For Reprint Rights: timescontent.com\nLoad-Date: February 15, 2024\nSharp companies leverage data to build out healthcare LLMs"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Oct2023",
        "header": "LINKEDIN TESTS AI FOR SECURITY QUESTIONS",
        "media": "Wall Street Journal Abstracts",
        "time": "October 27, 2023",
        "section": "B; Pg. 5",
        "length": "35 words",
        "byline": "CATHERINE STUPP",
        "story_text": "LINKEDIN TESTS AI FOR SECURITY QUESTIONS\nWall Street Journal Abstracts\nOctober 26, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 5\nLength: 35 words\nByline: CATHERINE STUPP\nBody\nABSTRACT\nMicrosoft’s LinkedIn professional networking platform is testing how generative artificial intelligence can help \nemployees and outside suppliers get quick answers about cybersecurity policies; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: October 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "Turning an Algorithm Into an Art Student",
        "media": "The New York Times",
        "time": "October 1, 2023",
        "section": "Section AR; Column 0; Arts and Leisure Desk; Pg. 10",
        "length": "1326 words",
        "byline": "By Zachary Small",
        "story_text": "Turning an Algorithm Into an Art Student\nThe New York Times\nOctober 1, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section AR; Column 0; Arts and Leisure Desk; Pg. 10\nLength: 1326 words\nByline: By Zachary Small\nBody\nOf the many young artists David Salle has mentored, none were ever as challenging as his latest student, who \ncannot hold a paintbrush or a conversation.\n''The mountain looks too airbrushed,'' Salle informed the algorithm that lives inside his iPad. The landscape painting \nit had produced, based on hundreds of his own artworks, was typically generic, lacking in depth. But the next one \nsucceeded, depicting a valley stream with expressionistic wisps and a sense of volume. \n  ''The way it has rendered water looks more deliberate,'' Salle, 70, said. ''But it's funny to call something deliberate \nwhen it has no consciousness, isn't it?''\n  For nearly a year, the painter -- known for edgy images appropriated from art history and popular culture, as well \nas juxtapositions of voluptuous nudes and ham sandwiches -- has attempted to defy conventional thinking about \ngenerative artificial intelligence by testing an A.I. program's capacity to become a sophisticated creator of art.\n  The partnership has grown through weekly meetings with two technologists, Danika Laszuk and Grant Davis, who \ntailored a text-to-image model to Salle's requirements, relying on descriptive prompts that generated images in the \nartist's style. The New York Times observed three of their work sessions, tracking the algorithm's progress over \nseveral months as it adopted more of Salle's techniques and abandoned the bland photorealism that often limits \nother generative programs.\n  ''We are sending the machine to art school,'' Salle quipped, before expounding on the principles of light, shadow, \ndepth and volume that good painting requires. The algorithm wouldn't need eyes to achieve greatness, but it would \nneed to hone the robotic equivalent of intuition to spark inspiration and fool a gallerist.\n  And first, it would have to learn to mimic his style.\n  The experiment was a mutually beneficial arrangement. Laszuk runs a program called E.A.T__WORKS, for the \nventure capital firm Betaworks, that pairs artists and engineers on projects where her company might earn a \npercentage of the profits. Davis is building Wand, an A.I. platform for artists that promises to help them streamline \ntheir operations with faster imaging through text prompts and sketching. Salle was something like a guinea pig for \nWand, teaching its program how to paint while developing his own series of digital images.\n  With permission from Ben Lerner, a friend of Salle's, the group has been feeding bits of poetry from his new book, \n''The Lights,'' to evoke more fantastical images of cities growing within organic cells, and patterns of interlocking \nbarbules. Prompts also have been sourced from another friend, the writer Sarah French.\nTurning an Algorithm Into an Art Student\n  ''Our process starts with very imaginative prompts,'' Davis said. ''And we generate lots of images before selecting \nthe ones we like. Then David starts drawing on top of them. The process can repeat itself like that until he's \nsatisfied.''\n  Salle is one of the first traditional artists to embed on the front lines of artificial intelligence. He, in turn, was trained \nby the conceptualist John Baldessari at the California Institute of the Arts in the 1970s and has a style that absorbs \na diverse set of influences, from the Italian painter Giorgio de Chirico to the New Yorker cartoonist Peter Arno.\n  The results have sometimes been described as memories that barely hold together, and as attempts to ascribe \nsignificance to the foggy afterimages of art history. He is often grouped with the appropriation artists of the 1980s, \nincluding Richard Prince and Cindy Sherman, who have questioned the primacy of authorship in contemporary \nculture. He has also juxtaposed photography with painting.\n  ''Every major artist is an amalgamation or synthesis of diverse sympathies and influences,'' Salle wrote in his 2018 \nbook ''How to See'' about making and viewing art. He recalled asking the painter Alex Katz to make a list of his own \ninfluences; Katz said the list started with Jackson Pollock and ended with ''the guy who made Nefertiti.''\n  On another page of his art treatise, Salle delivered a grand theory of creativity: ''Form is the raw material, and style \nis the forge.''\n  Artificial intelligence has a limitless vault of forms, thanks to the billions of online images it studies through a \nprocess called diffusion, in which the algorithm learns the structure of an image -- and then learns to create \nvariations. Its knowledge is then stored in the parameters of the model, which is translated to the A.I. through a \nshort sequence of numbers known as ''latent space.''\n  But learning artistic style requires going beyond simple pattern recognition. Experts say that increased \nmatchmaking improves accuracy but also stymies the machine's ability to produce the unexpected. A balance must \nbe struck.\n  The algorithm's ''training'' to become the next David Salle started with a diffusion model to develop a general \nunderstanding of visual images based on hundreds of the artist's paintings. Davis, the engineer, then introduced \ndozens of detailed snapshots of Salle's paintings to the program so it would learn to ''think like a painter.''\n  Some of the first experiments were underwhelming: blobby landscapes, figures drawn without brush strokes, flat \nabstraction. But the critiques that Salle offered did improve the machine's intelligence enough to surprise the artist.\n  ''As a painter you only have time to create a painting, but each painting contains within it all the paintings you don't \nhave time to make,'' Salle said. ''A.I. is a great tool because it allows me to see thousands of combinations; things \nthat I would manually sift through in years are made with 5,000 versions in an hour.''\n  Salle isn't the first artist to assume the role of mad scientist, pushing against the limits of his own mortality with a \nmachine capable of publishing a series of posthumous ''new'' works long after his death.\n  But he is also not someone to rest on his laurels. These experiments have come at a moment of great change in \nthe artist's career, which has spanned nearly 50 years. This year he left Skarstedt Gallery, which represented him \nfor nearly a decade, to join the dealer Barbara Gladstone. This fall, he has a solo exhibition in Seoul filled with \npaintings in a more graphic style from his ''Tree of Life'' series -- influenced by Arno, the cartoonist -- which Salle \nhas described as ''little dramas.''\n  Some of those pictures hung on the walls of his studio during summer, when he met with the technologists behind \nhis algorithm. The branches of his ''Tree of Life'' resembled the image of brain synapses -- summoning the \npsychological dramas of the characters' lives onto the canvas foreground.\n  The algorithm has become another pathway into his own psychology. The experiment has Salle wrestling with the \ndefinition of art and the nature of authorship.\nTurning an Algorithm Into an Art Student\n  What will become of his own identity, as the algorithm continues to produce more Salle paintings than he could \never imagine? Some days, it seems like the algorithm is an assistant. Other days, it's like a child. When asked if the \nA.I. would replace him entirely one day, the artist shrugged. ''Well,'' he said, ''that's the future.''Zachary Small spent \nfive months observing David Salle's experiments with artificial intelligence, including at the painter's studio in \nBrooklyn.Produced by Lucky Benson, Alicia DeSantis, Barbara Graustark, Gabriel Gianordoli, Andrew LaVallee and \nTala Safie. A.I.-generated images: Grant Davis and David Salle. Additional images: David Salle/VAGA at Artists \nRights Society (ARS), NY, via Gladstone Gallery, NY; Edward Hopper, ''Nighthawks,'' 1942, via The Art Institute of \nChicago; Giorgio de Chirico, ''Ariadne,'' 1913, Artists Rights Society (ARS), NY/SIAE, Rome, via The Metropolitan \nMuseum of Art, NY; Gian Lorenzo, ''Ecstasy of Saint Teresa,'' 1653, Alessandra Tarantino/Associated Press; David \nSalle/VAGA at Artists Rights Society (ARS), NY, via Gladstone Gallery, NY.\nhttps://www.nytimes.com/interactive/2023/09/22/arts/design/david-salle-ai.html\nLoad-Date: October 1, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 20, 2023",
        "section": "STARTUPS & TECH",
        "length": "214 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "In Global AI Season, AMD's Su Sees Big Opening in Data Centres\nEconomic Times (E-Paper Edition)\nJune 15, 2023 Thursday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 214 words\nByline: Suraksha.P@timesgroup.com\nHighlight: AI key driver of silicon consumption for the foreseeable future: AMD CEO\nBody\nSan Francisco: California-based multinational semiconductor company Advanced Micro Devices (AMD) said \nartificial intelligence (AI) will be the key driver of silicon consumption for the foreseeable future but the largest \nopportunity is in data centre currently.  AMD also revealed new details about MI300 chip on Tuesday. MI300 is \nAMD's most advanced graphics processing unit (GPU) that is believed to be a strong challenge to Nvidia whose \nchips dominate the AI computing market with over 80% market share. “The generative AI large language models \nhave paved the landscape. The need for more compute is growing exponentially. Be it training or inference, large \nmodels give you better accuracy. There's atremendous experimentation and development that is coming across the \nindustry. At the centre of this are GPUs. GPUs are enabling generative AI,” AMD chief executive Lisa Su said. She \nwas speaking at the AMD Data Centre and AI Technology Premiere on Tuesday. The company's fourth  generation \nEPYC processors are cloud-native central processing units (CPUs) that enable data centres to run demanding, \nscalable services and enterprise applications on shared cloud infrastructure. (The author is in San Francisco for \nAMD Data Center and AI Technology Premiere at the invitation of AMD.)\nLoad-Date: June 20, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "BUSINESS",
        "length": "1135 words",
        "byline": "Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is",
        "story_text": "Apple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nThe New York Times \nMarch 4, 2024 Monday 12:48 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1135 words\nByline: Tripp Mickle and Adam Satariano Tripp Mickle reports on Apple and Silicon Valley for The Times and is \nbased in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nAdam Satariano is a technology correspondent based in Europe, where his work focuses on digital policy and the \nintersection of technology and world affairs.\nHighlight: Apple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nBody\nApple said it would appeal the penalty, the latest in a series of regulatory setbacks for the tech giant.\nApple on Monday was fined 1.8 billion euros ($1.95 billion) by European Union regulators for thwarting competition \namong music streaming rivals, a severe punishment levied against the tech giant in a long-simmering battle over \nthe powerful role it plays as gatekeeper of the App Store.\nThe penalty, announced by the E.U. antitrust regulator, is the culmination of a five-year investigation set in motion \nby one of its biggest rivals, Spotify. Regulators said Apple illegally used its App Store dominance to box out rivals.\n“For a decade, Apple abused its dominant position in the market for the distribution of music streaming apps \nthrough the App Store,” said Margrethe Vestager, the European Commission executive vice president who \noversees competition policy.\n“From now on,” she said in a news conference, “Apple will have to allow music streaming developers to \ncommunicate freely with their own users.” The size of the fine, she added, “reflects both Apple’s financial power and \nthe harm that Apple’s conduct inflicted on millions of European users.”\nThe action by the European Commission, the E.U. executive branch, is the latest in a series of regulations and \npenalties to target the App Store. Most of the disputes are because Apple requires that apps use its in-app payment \nservice for sales. It takes as much as a 30 percent commission on each transaction, a fee that many developers \nsay is excessive.\nRegulators in the Netherlands and South Korea have passed laws or orders to force Apple to allow alternative \npayment services, but Apple has largely disregarded the regulators’ challenges. In those countries  it is allowing \nalternatives but charging a 27 percent commission, a solution that regulators in the countries are contesting.\nApple said it would appeal the ruling. “While we respect the European Commission, the facts simply don’t support \nthis decision,” Apple said in a statement on Monday.\nIn a briefing last month, Apple said that European regulators had been searching for a legal theory for the case for \nnearly a decade, in fits and starts. Apple challenged the idea that Spotify users haven’t been able to subscribe to \nmusic services through other means, saying that Spotify has added more than 100 million subscribers outside its \napp over the past eight years.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\nApple also accused Spotify of being a monopolist because it has more than a 50 percent share of Europe’s music \nstreaming business. It said that Spotify has benefited from the software tools that Apple provides, as well as more \nthan 119 billion downloads and updates of its app. It’s done so while not paying Apple any money in commissions.\n“Fundamentally, their complaint is about trying to get limitless access to all of Apple’s tools without paying anything \nfor the value Apple provides,” a spokesman said in a statement.\nSpotify, in a statement, said Monday’s penalty “sends a powerful message — no company, not even a monopoly \nlike Apple, can wield power abusively to control how other companies interact with their customers.” \nThe penalty reinforces the European Union’s position as the world’s most aggressive regulator of the tech sector. In \nrecent years, the bloc has passed laws on data privacy, industry competition, content moderation of online content \nand artificial intelligence. Antitrust regulators have meanwhile investigated or fined Google, Amazon, Microsoft and \nMeta.\nThe fine is the most severe penalty against Apple since 2016, when the European Commission ordered the \ncompany to turn over €13 billion for unpaid taxes to Ireland. In a sign of how long the appeal process can drag out, \nthat case is still winding its way through E.U. courts.\nIn 2022, the 27-nation bloc largely sided with developers in writing the Digital Markets Act that requires Apple to \nopen the iPhone to competing app stores and allow app makers to directly accept payments. The rules go into \neffect Thursday.\nIn its latest quarter, Apple reported revenue of about $120 billion and a net profit of $34 billion.\nLast month, Apple said that it would comply with the new law by giving developers three options. They could stick \nwith the status quo App Store system and continue paying up to a 30 percent commission of sales. Or they could \naccept alternative payments and reduce their commission to 17 percent, while taking on a new charge of 50 euro \ncents on every download above one million. Finally, they could avoid Apple’s commission and distribute through \ncompeting stores, while still paying Apple’s download fee.\nUnder Apple’s plan, Spotify and other apps would be able to tell customers in their app about cheaper subscription \nprices online. \nApple’s proposal for the App Store in Europe has sparked an outcry from developers large and small, who say that \nit fails to abide by both the letter and spirit of the law.\nApple has said that its plan complies with the law, while minimizing the risk iPhone users encounter malware, spam \nor fraud.\nSpotify has been one of Apple’s most vocal critics. For years, the music streaming service has complained that the \nApp Store’s in-app payment system and 30 percent commission has put it at a disadvantage to Apple Music, which \ncan sell subscriptions directly without a similar fee.\nThe rules have also hampered Spotify’s efforts to expand its business into audiobooks and other services. Instead \nof charging for a book in the app, it has tried to avoid Apple’s fees by directing customers outside the app to pay, a \nprocess that it has called cumbersome and difficult.\nApple says that Spotify’s decision to link to its website means that it doesn’t pay for many of the services that \nbenefit the music streaming service, including software tools and hardware improvements like advanced media \nplayback. It also complained that Spotify met with European regulators more than 60 times during the course of the \ninvestigation.\nDaniel Ek, Spotify’s chief executive, has complained for years about the slow pace of Europe’s investigation. \nThroughout the process, he pointed out ways that Apple’s control over the App Store disadvantaged competitors.\nApple Fined $2 Billion by E.U. for Using App Store to Thwart Competition\n“Without policymakers taking action, nothing will change,” Mr. Ek wrote in 2022 on X, the site formerly known as \nTwitter. “I can’t be the only one who sees the absurdity.”\nMonika Pronczuk contributed reporting from Brussels.\nMonika Pronczuk contributed reporting from Brussels. \nPHOTOS: The Digital Markets Act requires Apple to open the iPhone to competing app stores and allow direct \npayments. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES); Apple “abused its \ndominant position in the market,” said Margrethe Vestager, an executive vice president. (PHOTOGRAPH BY \nOLIVIER HOSLET/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in print on page B1, B4.\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "A.I. Debate Lands in Once-Sleepy Office",
        "media": "The New York Times",
        "time": "February 5, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1348 words",
        "byline": "By Cecilia Kang",
        "story_text": "A.I. Debate Lands in Once-Sleepy Office\nThe New York Times\nFebruary 5, 2024 Monday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1348 words\nByline: By Cecilia Kang\nBody\nThe office is reviewing how centuries-old laws should apply to artificial intelligence technology, with both content \ncreators and tech giants arguing their cases.\nFor decades, the Copyright Office has been a small and sleepy office within the Library of Congress. Each year, the \nagency's 450 employees register roughly half a million copyrights, the ownership rights for creative works, based on \na two-centuries-old law. \n  In recent months, however, the office has suddenly found itself in the spotlight. Lobbyists for Microsoft, Google, \nand the music and news industries have asked to meet with Shira Perlmutter, the register of copyrights, and her \nstaff. Thousands of artists, musicians and tech executives have written to the agency, and hundreds have asked to \nspeak at listening sessions hosted by the office.\n  The attention stems from a first-of-its-kind review of copyright law that the Copyright Office is conducting in the \nage of artificial intelligence. The technology -- which feeds off creative content -- has upended traditional norms \naround copyright, which gives owners of books, movies and music the exclusive ability to distribute and copy their \nworks.\n  The agency plans to put out three reports this year revealing its position on copyright law in relation to A.I. The \nreports are set to be hugely consequential, weighing heavily in courts as well as with lawmakers and regulators.\n  ''We are now finding ourselves the subject of a lot of attention from the broader general public, so it is a very \nexciting and challenging time,'' Ms. Perlmutter said.\n  The Copyright Office's review has thrust it into the middle of a high-stakes clash between the tech and media \nindustries over the value of intellectual property to train new A.I. models that are likely to ingest copyrighted books, \nnews articles, songs, art and essays to generate writing or images. Since the 1790s, copyright law has protected \nworks so an author or artist ''may reap the fruits of his or her intellectual creativity,'' the Copyright Office declares on \nits website.\n  That law is now a topic of hot debate. Authors, artists, media companies and others say the A.I. models are \ninfringing on their copyrights. Tech companies say that they aren't replicating the materials and that they consume \ndata that is publicly available on the internet, practices that are fair use and within the bounds of the law. The fight \nhas led to lawsuits, including one by The New York Times against the ChatGPT creator OpenAI and Microsoft. And \ncopyright owners are pushing for officials to rein in the tech companies.\nA.I. Debate Lands in Once-Sleepy Office\n  ''What the Copyright Office is doing is a big deal because there are important principles of law and lots and lots of \nmoney involved,'' said Rebecca Tushnet, a professor of copyright and intellectual property law at Harvard Law \nSchool. ''At the end of the day, the issue is not whether these models will exist. It's who will get paid.''\n  Congress created the Copyright Office in 1870 to register licenses for books, maps, essays and other creative \nworks and store those works for the use of lawmakers at the Library of Congress. The first registration was given to \nthe ''Philadelphia Spelling Book,'' a children's language book.\n  When Ms. Perlmutter, a veteran copyright official and former intellectual property lawyer for Time Warner, was \nappointed to lead the Copyright Office in late 2020, she promised to bring the office into the modern era by focusing \non big tech trends. She took inspiration from previous leaders, who dealt with technological innovations including \nthe camera, records, Xerox machines, the internet and streaming music, all of which required the office to weigh in \non how copyright would apply and advise Congress on proposed updates to the law.\n  Right away, A.I. became a hot topic. Stephen Thaler, a computer scientist, tried to register an A.I.-generated art \npiece for a copyright by submitting an application on the Copyright Office's website. In 2019, the office rejected his \nfirst attempt to register the piece, a pixelated scene of train tracks running through a tunnel overgrown with brush \nand flowers called ''A Recent Entrance to Paradise.'' In February 2022, Ms. Perlmutter declined his second attempt \nto register the piece on the same grounds: Copyrights were given only to original works created by humans.\n  The decision -- a first on an A.I.-produced work -- set an important precedent. Artists and lawmakers flooded Ms. \nPerlmutter's office with emails and phone calls asking her to also intervene in the way A.I. companies were using \ncopyrighted material to train their systems.\n  In August, she opened the formal review of A.I. and copyright law. The office said it would examine whether the \nuse of intellectual property to train A.I. models violated the law and would look more deeply into whether machine-\ngenerated works could be eligible for copyright protections. The office said it would also review how A.I. tools were \ncreating content that used the names, images and likenesses of individuals without their consent or compensation.\n  ''The attention on A.I. is intense,'' Ms. Perlmutter said in an interview. ''The current generative A.I. systems raise a \nlot of complicated copyright issues -- some have called them existential -- that really require us to start grappling \nwith fundamental questions about the nature and value of human creativity.''\n  The interest in the office's review was overwhelming. The office solicited public comments on the topic and \nreceived more than 10,000 responses on a form on its website. A typical policy review gets no more than 20 \ncomments, the office said.\n  Tech companies argued in comments on the website that the way their models ingested creative content was \ninnovative and legal. The venture capital firm Andreessen Horowitz, which has several investments in A.I. start-ups, \nwarned in its comments that any slowdown for A.I. companies in consuming content ''would upset at least a \ndecade's worth of investment-backed expectations that were premised on the current understanding of the scope of \ncopyright protection in this country.''\n  OpenAI, Microsoft, Meta (Facebook's parent) and Google are currently relying on a 2015 court decision in a case \nfiled by the Authors Guild.\n  The guild sued Google in 2005 for scanning books to use in excerpts in its search engine results and to share with \nlibraries. A court ruled that Google had not violated copyright law. It said that the scanning of entire books was \npermissible because Google didn't make the full book available and that it was ''transformative'' use of copyrighted \nmaterial. Google relied on an exemption to copyright law known as ''fair use'' that allows limited replication of \ncopyrighted material for things like criticism, parody or other transformational uses.\n  Google, Meta and the A.I. start-up Anthropic all echoed arguments from that case in their comments to the \nCopyright Office, including that A.I. copies the information to analyze data, not repurpose it for creative works.\nA.I. Debate Lands in Once-Sleepy Office\n  Authors, musicians and the media industry argued that by taking their content without permission or licensing \npayments, the A.I. companies were robbing them of their livelihoods.\n  ''The absence of consent and compensation in this process is theft,'' Justine Bateman, the ''Family Ties'' actress \nand author, wrote in comments to the Copyright Office.\n  News Corp, which publishes The Wall Street Journal and The New York Post, implored the office to ''not lose sight \nof this simple truth: Protecting content creators is one of copyright law's core missions.'' (The Times also submitted \na comment.)\n  Ms. Perlmutter said she and a staff of about two dozen copyright lawyers were going through each comment filed \nto the office.\n  Still, the office may not offer clear-cut views that will satisfy either the tech companies or creative people.\n  ''As technology gets more and more sophisticated, the challenges are exponentially more difficult and the risks \nand rewards are exponentially greater,'' Ms. Perlmutter said. \n  Audio produced by Sarah Diamond.Audio produced by Sarah Diamond.\nhttps://www.nytimes.com/2024/01/25/technology/ai-copyright-office-law.html\nGraphic\n \nPHOTOS: Shira Perlmutter's agency will grapple with the ''value of human creativity.'' (B1)\n Lobbyists for Microsoft, Google, and the music and news industries have sought meetings with the Copyright \nOffice. (PHOTOGRAPHS BY JARED SOARES FOR THE NEW YORK TIMES) (B3) This article appeared in print \non page B1, B3.               \nLoad-Date: February 5, 2024"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "ETtech Explainer: Here are nations at the forefront of GenAI innovation",
        "media": "The Economic Times",
        "time": "December 27, 2023",
        "section": "TECH & INTERNET",
        "length": "663 words",
        "byline": "Himanshi Lohchab",
        "story_text": "ETtech Explainer: Here are nations at the forefront of GenAI innovation\nThe Economic Times\nDecember 27, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 663 words\nByline: Himanshi Lohchab\nBody\nIt’s not just the US which is leading the race for releasing generative AI large language models (LLMs). \nOrganisations across China, Korea, Singapore, Japan, France, India and the UAE have built LLMs trained on their \nnative languages, outperforming several performance benchmarks set by OpenAI’s ChatGPT, Meta’s LlaMa, \nGoogle’s Gemini, and several other popularly known models.According to data science community platform \nHugging Face, there has been a rapid influx of new LLMs, with hundreds being announced every week. Today, its \nrepository hosts 450,706 open-source language models and serves over 1 million model downloads a day. ET \ncurates an explainer on how different geographies are contributing to GenAI innovation.ChinaChina is in a neck-\nand-neck competition with its geopolitical rival US in terms of the number of models it releases. According to \nBeijing’s ministry of science and technology, Chinese organisations released 2 LLMs compared with 11 in the US in \n2020. In 2021, this figure was 30 each for both countries. \nAnd, in 2023 China released 28 LLMs against the US’ 37.Some of China’s popular releases include DeepSeek, a \n67 billion parameter model trained on English and Chinese.E-commerce giant Alibaba Group Holding’s research \nunit Damo Academy launched the Southeast Asia LLM (SeaLLM) trained on Vietnamese, Indonesian, Thai, Malay, \nKhmer, Lao, Tagalog, and Burmese data sets.Alibaba’s small language 7-billion parameter model Qwen-VL, is a \nmultimodal tool that can comprehend images, texts, and bounding boxes in prompts.Another Chinese startup called \n01.AI became a unicorn in less than eight months since its inception after it released the Yi-34B model trained on \n34 billion parameters.SingaporeSingapore also took a similar initiative as China. It anchored the SEA-LION \n(Southeast Asian Languages In One Network) family of LLMs that are pre-trained for the Southeast Asian (SEA) \nregion. Currently, SEA-LION has two SLMs in 3-billion and 7-billion parameters.Following this initiative, Singapore’s \ntelecom and media regulator IMDA, its ministry of science and other agencies announced a sum of SGD $70 million \n($52.3 million) to be invested on multimodal AI research.Singaporean startup WIZ.AI also released its 13 billion \nparameter LLM tailored for Bahasa Indonesia.KoreaNaver Corp., South Korea’s online giant, debuted in the LLM \nspace with launch of its humongous 204-billion parameter LLM HyperCLOVA X trained with news articles published \nover the past five decades and blog data accumulated over nine years.Korean startup Upstage built Solar LLM, \nwhich has been lately ranked among top LLMs on Hugging Face’s leaderboard for open-source LLMs.KT Corp., \nSouth Korea’s number two mobile carrier, has also joined hands with Thailand’s Jasmine Group to together create \nan LLM for Thai language.UAEThe Technology Innovation Institute, an Emirati research centre in Abu Dhabi, \nreleased the Falcon 180B, after unveiling Noor last year, which was the world's first Arabic model.UAE also came \nout with Jais, a 13-billion parameter model, trained on an Arabic and English dataset on Condor Galaxy, one of the \nlargest cloud AI supercomputers in the world.IndiaIndian tech majors and startups are also in the fray for AI \ninnovation. Conversational AI startup Corover.ai recently launched BharatGPT, a 7 billion parameter model trained \nin 14 Indian languages across text, voice, and video interactions.Sarvam AI also released the first open-source \nHindi language model called OpenHathi-Hi-0.1 built on Meta’s LlaMa 2-7B model.Mobility unicorn Ola dropped the \nKrutrim LLM which can comprehend 22 Indian languages and can form responses in 10 languages.IT services \nleader Tech Mahindra is also working on ‘Project Indus’, an LLM trained in Hindi and 37 Indic \nETtech Explainer: Here are nations at the forefront of GenAI innovation\ndialects.OthersBesides these, Japan’s Rakuten and France's Mistral have also forayed into the LLM race with \nmodels trained in Japanese and European languages respectively. For Reprint Rights: timescontent.com\nLoad-Date: December 27, 2023"
    },
    {
        "file_name": "go_hand-in-hand?_Aug2023",
        "header": "Zoom's updated TOS prompted concerns about AI and privacy. Can the two",
        "media": "go hand-in-hand?",
        "time": "August 14, 2023",
        "section": "TECH LATEST",
        "length": "1582 words",
        "byline": "Mary Walrath-Holdridge, USA TODAY",
        "story_text": "Zoom's updated TOS prompted concerns about AI and privacy. Can the two \ngo hand-in-hand?\nUSA Today Online\nAugust 11, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST\nLength: 1582 words\nByline: Mary Walrath-Holdridge, USA TODAY\nBody\nIt's been a bit of a rough PR week for video meeting and chat platform Zoom. The app, which became synonymous \nwith remote working during the pandemic, received a few sideways glances when it announced plans to bring \nworkers back into the office.\nThen, thanks to a post on blog StackDiary, users on X, formerly Twitter, caught wind of what appeared to be a \nchange to Zoom's terms of service (TOS), which would seemingly allow the platform to feed user \"content\" to AI \nprograms in training almost indiscriminately. \nZoom calls workers back to office: Even Zoom wants its workers back in the office: 'A hybrid approach'\nSection 10.4 of Zoom’s TOS, specifically, raised red flags for many users, reading in part:\n\"You agree to grant and hereby grant Zoom a perpetual, worldwide, non-exclusive, royalty-free, sublicensable, and \ntransferable license and all other rights required or necessary to redistribute, publish, import, access, use, store, \ntransmit, review, disclose, preserve, extract, modify, reproduce, share, use, display, copy, distribute, translate, \ntranscribe, create derivative works, and process Customer Content and to perform all acts with respect to the \nCustomer Content .... for the purpose of product and service development, marketing, analytics, quality assurance, \nmachine learning, artificial intelligence, training, testing, improvement of the Services, Software, or Zoom’s other \nproducts, services, and software, or any combination thereof.\"\nWith the abundance of conversation around artificial intelligence and the role it should or should not play circulating \neverywhere lately, the words \"machine learning,\" \"artificial intelligence,\" \"training,\" and \"testing\" rang in the ears of \nusers. \nX, along with other social media platforms, quickly lit up with proclamations of banning Zoom from company use \nand the cancelling of memberships.\nZoom responds to outcry over changes to its terms of service\nSoon after, Zoom put out a company blog clarifying the clause, adding in bold lettering: \"For AI, we do not use \naudio, video, or chat content for training our models without customer consent.\"\nCancelling the Bellingcat pro Zoom account, and we'll migrate all our webinars /trainings to a new platform right \naway. https://t.co/g9wiseVXmX\n— Aric Toler (@AricToler)\nZoom's updated TOS prompted concerns about AI and privacy. Can the two go hand-in-hand?\nAugust 7, 2023\nThe post also clarified what AI services Zoom was hoping to train, which include Zoom IQ Meeting Summary and \nZoom IQ Team Chat Compose, tools that generate meeting summaries and compose chats. The features are \ncurrently available on a free-trial basis and require account owners to enable the features, according to the post. \n\"When you choose to enable Zoom IQ Meeting Summary or Zoom IQ Team Chat Compose, you will also be \npresented with a transparent consent process for training our AI models using your customer content. Your content \nis used solely to improve the performance and accuracy of these AI services. And even if you chose to share your \ndata, it will not be used for training of any third-party models,\" the blog reads. \nA Zoom spokesperson told USA TODAY in a statement that: \"Zoom customers decide whether to enable \ngenerative AI features, and separately whether to share customer content with Zoom for product improvement \npurposes. We’ve updated our terms of service to further confirm that we will not use audio, video, or chat customer \ncontent to train our artificial intelligence models without your consent.”\nThe company updated their TOS yet again on Friday, noting in an edited blog post: \"Following feedback, Zoom \nmade the decision to update its Terms of Service to reflect Zoom does not use any of your audio, video, chat, \nscreen sharing, attachments or other communications like customer content (such as poll results, whiteboard and \nreactions) to train Zoom’s or third-party artificial intelligence models.\"\nI want to set the record straight……https://t.co/iuCcCzgfP7\n— Eric S. Yuan (he / him / his) (@ericsyuan)\nAugust 9, 2023\nWhile Zoom was the unfortunate subject of public discourse this time around, International Association of Privacy \nProfessionals Washington, D.C. Managing Director Cobun Zweifel-Keegan told USA TODAY that people, \nbusinesses and regulators can expect to continue grappling with the use of AI. \n\"Every now and then, we seem to get a lot of interest in some company's terms of service and how it's raised, often \nthey're very similar to each other. If you look at other companies, they will have a lot of the same language that was \nan issue here,\" Zweifel-Keegan shared.\n\"Companies are always updating their terms of service because of new products and services that they're \noffering...but yes, also, I think we're going to start seeing AI being explicitly described in terms of service more \noften.\"\nZweifel-Keegan said that terms of service exist, on a large scale, to protect the company. Because anything a user \n\"creates,\" including the use of text, voice and image, then automatically belongs to the user thanks to copyright law, \na platform seeking to make any copy of user-created \"content\" to store and otherwise use is opening itself up to \nliability. This is why we see the long, and at times aggressive sounding, walls of text we must click \"agree\" to before \nusing a service. \nAt the same time, companies are still subject to privacy policy, which usually exists separately from but in tandem \nwith TOS agreements. The purpose of a privacy policy, Zweifel-Keegan said, is to explain the commitments that the \ncompany is making around personal information and often to limit the company's ability to collect information for \npurposes that go beyond delivering the agreed upon service. \n\"Terms of service and privacy policies are both legally binding instruments that companies write and publish on \ntheir websites. They have very different purposes,\" he said. \"So, reading one without looking at the other can \nsometimes lead to kind of frightening and maybe overly dramatic reads on what exactly is happening.\"\nAI models need real-world information to improve\nZoom's updated TOS prompted concerns about AI and privacy. Can the two go hand-in-hand?\nIn the case of Zoom, concerns were focused on the potential to use video, audio and other \"customer content\" for \ntraining models and training algorithms, said Zweifel-Keegan. This, he said, gets to the core of policy and general \nconversation around AI today: what should be allowed to us for training new models?\n\"We have debates around should publicly available information, which is what was used primarily to train, to \neducate [AI], should that be used? Should that be allowed?\" he said.\n\"Should you have to seek out consent and find all the pieces of information individually before you can train those \ntypes of models, should people know before they've shared their information that it's going to be used to train a \nmodel?\"\nHe said that models like Zoom can be especially tricky, as the decisions in this care are up to the primary holder of \nthe account. Meaning, if you're in a call and the host has consented to the use of AI, you have the choice of asking \nthem to rescind that consent or leave the call if you don't want to take part in it. \nHow to handle a data breach: Got a data breach alert? Don't ignore it. Here's how to protect your information.\nZweifel-Keegan said that different companies will likely determine different means of using consumer content and \ndata to train AI and provide different possibilities for opting-out. Ultimately, these models need real-world \ninformation in order to improve.\nEven after systems are launched, they require continued training in order to make them better and more useful. At \nthe same time, they need to be monitored for privacy, fairness and bias, accuracy and other concerns. \nBut one thing is for sure: it's not going away anytime soon. \nThose concerned with the use of their content can take a few steps to double-check they understand what they're \ngetting in to before clicking accept, however. \nWhere to go to better understand what you're agreeing to\n\"I think most companies have gotten much better over the years at explaining their privacy practices in plain \nlanguage,\" said Zweifel-Keegan.\n\"So, in addition to privacy policies, which are just as arduous as terms of service, usually many companies have \nlayered privacy notices, privacy centers where you can go to better understand and to more quickly understand how \nthey're collecting types of information, using and sharing it with people and any choices that you might have to \nexercise over that.\"\nHe pointed out the many blogs Zoom has available on their website which explain in clearer, simpler terms what is \ninside of their TOS and privacy policies, something many other companies have as well. In an increasing number of \nstates, consumers also have the ability to request an overview for the information a company has on them and ask \nfor its deletion.  \nAnd, he reassured, companies are beholden to statements made in these policies, meaning consumers are \nprotected by authorities like the Federal Trade Commission if any claims, like the ability to opt-out of certain data \ncollection, turn out to be false. \n\"AI is part of every policy conversation right now,\" said Zweifel-Keegan. \"I think one of the takeaways for companies \nin this is that it is really important to be straightforward with your users and provide as much clarity as possible \nabout terms of service changes to help make sure that customers understand what you are doing and what you're \nnot doing.\"\nThis article originally appeared on USA TODAY: Zoom's updated TOS prompted concerns about AI and privacy. \nCan the two go hand-in-hand?\nZoom's updated TOS prompted concerns about AI and privacy. Can the two go hand-in-hand?\nLoad-Date: August 14, 2023"
    },
    {
        "file_name": "strike_for_protection_against_artificial_intelligence_Jul2023",
        "header": "Netflix posts $900,000 AI job listing as Hollywood actors, writers continue to",
        "media": "strike for protection against artificial intelligence",
        "time": "July 26, 2023",
        "section": "TECH AND GADGETS",
        "length": "350 words",
        "byline": " ",
        "story_text": "Netflix posts $900,000 AI job listing as Hollywood actors, writers continue to \nstrike for protection against artificial intelligence\nThe Economic Times\nJuly 27, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 350 words\nBody\nSeems like Hollywood's fight against artificial intelligence (AI) will be a long one as streaming giant Netflix has listed \na high-paying AI job with an annual salary of up to $900,000. This posting comes at a time when Hollywood actors \nand writers have been on strike demanding fair compensation and safeguards for their digital likenesses in the face \nof AI advancements. The job opening by Netflix is for a Machine Learning/AI Product Manager. They will be \nresponsible for enhancing Netflix's machine-learning platform (MLP) and leveraging AI to \"create great content\" \nrather than solely relying on AI for recommending shows and movies. \nThat's not the company's only AI-heavy job posting promising a giant payday. In another job listing, the streaming \ngiant has sought a technical director for generative AI at its gaming studio, further emphasising the company's \ncommitment to integrating AI across its business sectors. Meanwhile, reports state that the striking actors, \nrepresented by the Screen Actors Guild-American Federation of Television and Radio Artists (SAG-AFTRA), have \nrejected a proposal from the Alliance of Motion Picture and Television Producers (AMPTP). It aims to pay actors a \none-time fee for scanning their likenesses to be used as AI-generated CGI in perpetuity. According to The Intercept, \nSAG-AFTRA raised concerns that this proposal would grant studios ownership and control over their digital images \nwithout adequate compensation or consent. Similarly, writers represented by the Writers Guild of America (WGA) \nhave also been on strike since May, demanding better labour protections against AI-generated content. They are \nasking for regulations that prevent AI programs like ChatGPT from being credited as screenplay writers. The \nstriking unions have expressed concerns that AI advancements in Hollywood may lead to actors being replaced by \nAI-generated characters and writers' jobs being at risk. The fear of AI potentially infringing on creative rights and \ncompensation has escalated as the use of deepfakes and CGI continues to evolve. For Reprint Rights: \ntimescontent.com\nLoad-Date: July 26, 2023"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "The S.E.C.’s Chief Is Worried About A.I.; DealBook Newsletter",
        "media": "The New York Times",
        "time": "August 7, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1903 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni",
        "story_text": "The S.E.C.’s Chief Is Worried About A.I.; DealBook Newsletter\nThe New York Times \nAugust 7, 2023 Monday 07:57 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1903 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced and Ephrat Livni\nHighlight: Gary Gensler, who has studied the consequences of artificial intelligence for years, said that the \ntechnology could lead to future financial crises.\nBody\nGary Gensler, who has studied the consequences of artificial intelligence for years, said that the technology could \nlead to future financial crises.\nA financial regulator issues a warning on A.I. \nGary Gensler, the chairman of the S.E.C., has been studying the potential consequences of artificial intelligence for \nyears. The recent proliferation of generative A.I. tools like ChatGPT has demonstrated that the technology is set to \ntransform business and society.\nMr. Gensler outlined some of his biggest concerns in an interview with DealBook’s Ephrat Livni.\nA.I. could be the next big systemic risk to the financial system. In 2020, Mr. Gensler co-wrote a paper about deep \nlearning and financial stability. It concluded that just a few A.I. companies will build the foundational models that \nunderpin the tech tools that lots of businesses will come to rely on, based on how network and platform effects have \nbenefited tech giants in the past.\nMr. Gensler expects that the United States will most likely end up with two or three foundational A.I. models. This \nwill deepen interconnections across the economic system, making a financial crash more likely because when one \nmodel or data set becomes central, it increases “herding” behavior, meaning that everyone will rely on the same \ninformation and respond similarly.\n“This technology will be the center of future crises, future financial crises,” Mr. Gensler said. “It has to do with this \npowerful set of economics around scale and networks.”\nA.I. models may put companies’ interests ahead of investors’. The meme stock frenzy driven by social media and \nthe rise of retail trading on apps highlighted the power of nudges and predictive algorithms. But are companies that \nuse A.I. to study investor behavior or recommend trades prioritizing user interests when they act on that \ninformation?\nThe S.E.C. last month proposed a rule that would require platforms to eliminate conflicts of interest in their \ntechnology. “You’re not supposed to put the adviser ahead of the investor, you’re not supposed to put the broker \nahead of the investor,” Mr. Gensler said. “And so we put out a specific proposal about addressing those conflicts \nthat could be embedded in the models.”\nWho is responsible if generative A.I. gives faulty financial advice? “Investment advisers under the law have a \nfiduciary duty, a duty of care, and a duty of loyalty to their clients,” Mr. Gensler said. “And whether you’re using an \nalgorithm, you have that same duty of care.”\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nPrecisely who is legally liable for A.I. is a matter of debate among policymakers. But Mr. Gensler says it’s fair to ask \nthe companies to create mechanisms that are safe and that anyone who uses a chatbot is not delegating \nresponsibility to the tech. “There are humans that build the models that set up parameters,” he said.\nHERE’S WHAT’S HAPPENING \n“Barbie” is a billion-dollar phenomenon. Warner Bros. said that the movie had reached the $1 billion mark faster \nthan any other in its history. The feat may help further dispel the notion that women-focused movies are limited in \ntheir appeal, with “Barbie” having outperformed bigger-budget blockbusters like the latest “Indiana Jones” and \n“Mission: Impossible” sequels.\nSaudi Aramco reports a 38 percent drop in quarterly profit. The state-controlled oil giant earned $30 billion in the \nsecond quarter, sharply lower than in the same period last year, driven partly by declining global crude prices. \nRiyadh is trying to counteract that by prolonging a production cut of a million barrels per day through September, a \nmove that the kingdom said could be “extended or extended and deepened” as necessary.\nThe U.A.W. makes a bold opening bid in talks with big automakers. The United Auto Workers has asked for \nconcessions including a 40 percent wage increase and guarantees that workers hired at new electric-vehicle battery \nplants would be covered by the union’s national contracts. Behind its demands are high profits at Ford, General \nMotors and Stellantis — and the risk of job cuts amid a switch to E.V. production.\nWarren Buffett’s Berkshire Hathaway reports a rise in earnings. The conglomerate benefited from improving \nperformance at its Geico insurance arm and strong performance in stocks it holds, principally Apple, as it reported \nnearly $36 billion in net income and $10 billion in operating earnings. Berkshire’s cash holdings are now about $147 \nbillion, near a record, raising questions about what Mr. Buffett will do with that war chest.\nU.S. researchers duplicate a nuclear fusion feat. Scientists at the federal Lawrence Livermore National Laboratory \nsaid they had again managed to achieve net gain in a fusion reaction — meaning that it yielded more energy than it \nconsumed — but managed to get even more power out this time. The results are an advancement in a process that \nresearchers hope will produce clean and cheap energy, though it could be decades away.\nA bankruptcy that could cost taxpayers millions\nThe trucking giant Yellow finally filed for bankruptcy protection overnight, nearly two weeks after shutting its doors \nand three years after receiving a $700 million loan from the federal government during the pandemic. The shutdown \nmeans the loss of 30,000 jobs and could shake up the business of moving goods around the United States — as \nwell as raise questions about how much money taxpayers will lose.\nYellow has struggled for years. A final blow came when the company, formerly known as YRC, was unable to strike \na deal with the Teamsters union, which represents its drivers, on a new contract.\nYellow has accused the Teamsters of blocking a restructuring effort that, the company argued, would have helped it \navoid Chapter 11. The union “knowingly and intentionally triggered a death spiral for Yellow,” Matthew Doheny, the \ncompany’s chief restructuring officer, wrote in a court filing.\nA Teamsters spokesman told The Wall Street Journal that the union had been giving wage and pension \nconcessions for years: “Yellow couldn’t manage itself, and it wasn’t up to Teamsters to do it for them,” the \nrepresentative said.\nYellow’s deal-making didn’t help. The company embarked on an acquisition spree after the 2008 financial crisis, \nand experts said it failed to integrate those businesses. The deals also contributed to an onerous debt load that \ntotaled about $1.5 billion as of March. The company has twice had to reorganize its finances to avoid default.\n“Yellow was struggling to keep its head above water and survive,” Jack Atkins, an analyst at Stephens, told The \nTimes.\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nTaxpayers could be on the hook for losses. In 2020, Yellow took out a pandemic relief loan from the federal \ngovernment. That move has since been questioned, with House Democrats writing in a report last year that the \nTrump administration had provided the rescue package over objections from Defense Department officials.\nThe company has repaid just $230 of the principal on the loan, which comes due next year. The government \nacquired a 30 percent stake in Yellow via the deal, and could end up assuming or trying to sell off much of the \ncompany’s fleet of trucks and terminals — though how much it will recover is unclear.\n‘Do we need another rate increase?’ \nJohn Williams, the president of the New York Fed, expects interest rates to start coming down next year as efforts \nby the central bank to cool the economy near their peak.\nMr. Williams’s comments suggest that slowing inflation could prompt a shift in Fed policy amid hopes that the \neconomy is heading for a soft landing and avoiding a recession. From his conversation with The Times’s Jeanna \nSmialek:\nGiven what I see today, from the perspective of the data that we have, I think — it’s not about having to tighten \nmonetary policy a lot. To me, the debate is really about: Do we need to do another rate increase? Or not?\nI think we’re pretty close to what a peak rate would be, and the question will really be — once we have a good \nunderstanding of that, how long will we need to keep policy in a restrictive stance, and what does that mean.\n“Exact date is still in flux. I’m getting an MRI of my neck &amp; upper back tomorrow. May require surgery before \nthe fight can happen.”\n— Elon Musk, responding to questions about when he would stage a cage fight with the Meta C.E.O. Mark \nZuckerberg. The tech moguls have traded barbs recently; Musk posted his message after Zuckerberg said his rival \nhadn’t responded to his suggestion of holding the match on Aug. 26.\nThe week ahead\nA key reading on inflation and Disney’s latest earnings will be top of mind for investors this week. Here’s what to \nwatch.\nToday: The online homework help company Chegg — whose stock plunged in May after its C.E.O. warned that \nChatGPT threatened its business model — is set to report earnings.\nTomorrow: UPS and Restaurant Brands, the owner of Burger King, will report. The Japanese tech investor \nSoftBank will also disclose results; it may announce a profit after five quarters of losses.\nWednesday: Disney reports, and analysts are sure to press its C.E.O., Bob Iger, on an array of topics, including: \nefforts to find a strategic partner for ESPN; whether he intends to sell the company’s legacy TV businesses like \nABC; any improvements on streaming numbers; and his outlook on Hollywood, given the writers’ and actors’ \nstrikes.\nAlso, China reports inflation data for July. Economists are worried that the country may slip into deflation.\nThursday: U.S. Consumer Price Index data for July is due. Economists forecast a 3.3 percent rise in headline \ninflation from the same time a year ago, up only slightly from the 3 percent increase reported in June. That would be \nthe smallest monthly price rise in two years; the measure will be closely watched by Fed officials ahead of their next \nrate-setting meeting in September.\nAlso, the Chinese tech giant Alibaba reports, and Virgin Galactic will launch its second commercial flight to the edge \nof space.\nThe S.E.C.’s Chief Is Worried About A.I. DealBook Newsletter\nFriday: The University of Michigan publishes preliminary data for its Consumer Sentiment Index; the measure has \nbeen showing steady rises in recent months as the economy improves.\nTHE SPEED READ \nDeals\n• Saudi Arabia’s sovereign wealth fund, the Public Investment Fund, lost $15.6 billion last year, as investments \nin SoftBank’s Vision Fund and other tech ventures soured. (Bloomberg)\n• Private equity firms are reportedly offering incentives including discounts on management fees to prospective \ninvestors, as many struggle to raise new funds. (FT)\nPolicy\n• Republican voters appear less interested in fighting “woke” corporations than many candidates for the 2024 \nG.O.P. presidential nomination are. (NYT)\n• A federal judge allowed the Justice Department’s antitrust lawsuit against Google to proceed, but limited the \nscope of the case. (WaPo, NYT)\n• The Carlyle co-founder David Rubenstein offered a creative, if unlikely, proposal to resolve voter concerns \nabout Donald Trump’s and President Biden’s candidacies. (Puck)\nBest of the rest\n• “Big Oil’s Talent Crisis: High Salaries Are No Longer Enough” (WSJ)\n• The ordeal of a woman who was wrongly arrested on robbery charges while eight months pregnant illustrates \nthe dangers of police use of facial recognition software to identify criminals. (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Gary Gensler, the head of the S.E.C., sees A.I. as a transformational technology. (PHOTOGRAPH BY \nLeah Millis/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "CREDIT?_Sep2023",
        "header": "CHATGPT HELPED YOU BRAINSTORM IDEAS. SHOULD YOU GIVE IT",
        "media": "CREDIT?",
        "time": "September 12, 2023",
        "section": "R; Pg. 6",
        "length": "42 words",
        "byline": "DEMETRIA GALLEGOS",
        "story_text": "CHATGPT HELPED YOU BRAINSTORM IDEAS. SHOULD YOU GIVE IT \nCREDIT?\nWall Street Journal Abstracts\nSeptember 11, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: R; Pg. 6\nLength: 42 words\nByline: DEMETRIA GALLEGOS\nBody\nABSTRACT\nDemetria Gallegos article in Journal Report — Workplace Technology looks at reader responses to question of \nwhether generative artificial intelligence deserves to be singled out for credit when worker uses it to brainstorm \nideas; drawing; photo (M)\nGraphic\n \nCombination\nLoad-Date: September 12, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "AI SPENDING WILL CLOUD SEMICONDUCTOR SLOWDOWN",
        "media": "Wall Street Journal Abstracts",
        "time": "May 17, 2023",
        "section": "B; Pg. 12",
        "length": "45 words",
        "byline": "DAN GALLAGHER",
        "story_text": "AI SPENDING WILL CLOUD SEMICONDUCTOR SLOWDOWN\nWall Street Journal Abstracts\nMay 16, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 12\nLength: 45 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column notes Google and Microsoft have said Nvidia chips are critical for their \ngenerative-artificial-intelligence projects; predicts heavy expenditures for chips plus business slowdowns will \nmean cuts elsewhere; graph; photo (M)\nGraphic\n \nCombination\nLoad-Date: May 17, 2023"
    },
    {
        "file_name": "Alternatives_Dec2023",
        "header": "SaaS startup Kapture raises $4 million funding from PE firm India",
        "media": "Alternatives",
        "time": "December 19, 2023",
        "section": "FUNDING",
        "length": "309 words",
        "byline": " ",
        "story_text": "SaaS startup Kapture raises $4 million funding from PE firm India \nAlternatives\nThe Economic Times\nDecember 19, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 309 words\nBody\nKapture CX, a customer support platform for enterprises, has raised $4 million from India Alternatives, a private \nequity fund. The Bengaluru-based startup has been expanding on-ground operations in five countries: the US, the \nUAE, Indonesia, Saudi Arabia and India.The company last raised funds in July—a $4 million roundled by venture \ncapital firm Cactus Venture Partners (CVP). The latest infusion will be used to push Kapture’s generative artificial \nintelligence (Gen AI) capabilities and strengthen its footprint across India as well as global markets, the company \nsaid in a statement.Having crossed a 1,000 customers from 19 countries, the company is planning to add 100 more \nemployees next year, the statement added.“We are experiencing tailwinds across the large and global enterprise \nsegment that has made us capitalise on Gen AI capabilities. We are confident that a value added and relationship \noriented partner like India Alternatives will help us bolster our position as a leading SaaS player across India and \nglobal markets,” Vikas Garg, cofounder of Kapture CX said. The company was founded by Garg, Sheshgiri Kamath \nand Pearl Tewari in 2014.India Alternatives Investment Advisors is a mid-market, domestic private equity firm. \nPrivate equity firms have played an active part in startup funding this year. Earlier this month, ChrysCapital acquired \na 75% stake in ProHance Analytics,a Bengaluru-based business-to-business software-as-a-service platform \noffering workforce analytics and operations enablement.“Kapture is well positioned to capitalise on this opportunity \ndue to Shesh (Kamath) and Vikas’ excellent leadership, customer orientation and ability to leverage Gen AI \ncapabilities to provide a customised solution at scale,” said Shivani Bhasin, founder and chief executive of India \nAlternatives. \nFor Reprint Rights: timescontent.com\nLoad-Date: December 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Oct2023",
        "header": "Does Pixel 8's A.I.-Based Editing Cross a Line?",
        "media": "The New York Times",
        "time": "October 12, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 8; TECH FIX",
        "length": "1074 words",
        "byline": "By Brian X. Chen",
        "story_text": "Does Pixel 8's A.I.-Based Editing Cross a Line?\nThe New York Times\nOctober 12, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 8; TECH FIX\nLength: 1074 words\nByline: By Brian X. Chen\nBody\nGoogle's new $700 Pixel 8 lets you use artificial intelligence to add or remove elements from your images. It's not \nclear we really need this.\nSmartphone cameras became extremely powerful over the last five years. Their leap in quality was largely driven by \nadvancements in computational photography, a technology that uses algorithms, artificial intelligence and sensors \nto produce sharp, lifelike pictures. Now we all can shoot stunning images that rival the work of professionals. \n  So what's next? I hate to say it: faker photos.\n  Google, which has long been an industry leader in smartphone photography, will on Thursday start shipping the \nPixel 8, a $700 handset with a suite of A.I.-powered photo-editing tools. The phone software does much more than \nadjust the sharpness and brightness of a photo -- it uses A.I. to generate imagery or to remove elements to give you \nexactly the photo you want.\n  Imagine, for instance, a photo in which a person's shoulder is cut off. With Google's software, you can now tap the \nMagic Editor button and scoot that person over in the frame. From there, the software will use A.I. to produce the \nrest of that person's shoulder.\n  Or consider a picture you shot of a friend in front of a historical monument, but the background is crowded with \nother tourists. Using the same editing tool, you can select the photo bombers and hit the Erase button. In seconds, \nthe strangers will vanish -- and Google's software will automatically generate imagery to fill in the background.\n  Google has integrated these new A.I. editing tools into Google Photos, its free photo album app for Android \ndevices and iPhones, which has more than one billion users. The company said the Pixel 8 was the first device with \nthe A.I. editor, which means the same tools could soon arrive for other devices.\n  Google's A.I. photo editor is part of a wave of generative A.I., which became popular in the last year after the \nrelease of the ChatGPT chatbot, which produces text in response to prompts. Image-based generative A.I. tools \nlike DALL-E, Midjourney and Adobe Firefly also let people create pictures by simply typing in a prompt, such as ''a \ncat sleeping on a windowsill.''\n  Yet the Pixel 8 is a turning point. It is the first mainstream phone to bake generative A.I. directly into the photo \ncreation process at no extra cost, pushing smartphone photography into an era when people will increasingly have \nto question whether what they see in their images is real -- including photos from loved ones.\n  (Apple's iPhone camera can add some artificial effects, such as a ''stage light'' that brightens a subject and blacks \nout the background, but it stops short of generating fake imagery.)\nDoes Pixel 8's A.I.-Based Editing Cross a Line?\n  ''This is a really big moment that's going to change a lot of things about imagery,'' said Ren Ng, a computer \nscience professor at the University of California, Berkeley, who teaches courses on computational photography. ''As \nwe go boldly forth into this future, a photo is no longer a visual fact.''\n  To test whether this is a good thing, I shot and edited dozens of photos with the Pixel 8. I was impressed, creeped \nout and skeptical that I would want to keep generating fake photos. Here's what I found.\n  Picture Imperfect\n  Continuing my tradition when testing many smartphone cameras, I used the Pixel 8 to snap photos of my dogs -- \nMax, a corgi, and Mochi, a brown Labrador -- and then applied the A.I.\n  The results were hit and miss.\n  In one photo of Max sitting on a large rock, I wanted to remove a citation form from a police officer for letting my \ndogs run off leash without a permit in an off-leash dog park. (Who has ever heard of such a thing?) In the Google \nPhotos app, I tapped the Magic Editor button and traced an outline around the piece of paper.\n  The software did a remarkable job. It replaced the maddening piece of bureaucracy with the rock slab and some \npine needles.\n  In another photo, where Mochi is standing near Max and the right side of her butt is cut off in the frame, I tried \nscooting her to the left. The Pixel 8 did OK moving her, but the right side of Mochi's computer-generated behind \nwas blurry and her left paw was cut off.\n  Then came the most jarring result. In a photo of a pizza restaurant where Mochi's face was cut off in the frame, I \ntried moving her over to test if the A.I. could generate the rest of her head. I didn't expect the software to perfectly \nreproduce her grizzled mug, but the A.I. produced something nightmarish, a half-demi-god hellhound with a pair of \nhooves sprouting from her legs.\n  Google includes a Regenerate button for when you are unhappy with the results, which I tried. But it yielded \nequally off-putting results each time.\n  In the same photo, I tried highlighting and deleting the strangers in the background. This worked well but felt \nunsettling, like watching the ''snap'' scene in ''Avengers: Infinity War,'' when half the universe's population \ndisappeared.\n  It is early days, and Google expects people to run into imperfections. ''This feature is in early stages and won't \nalways get it right,'' the company said in a statement. ''We're looking for feedback to continually improve our \nmodels.'' \n  To use or not to use\n  Here's my feedback: I don't think these A.I. editing tools should be featured so prominently in the photos app of a \nflagship smartphone, especially in their imperfect state.\n  And even when the technology matures, there are broader questions -- such as the ethical issues of artificial \nimages -- to consider and navigate.\n  Editing photos for clarity and brightness improves an image without altering its substance. But artificially adding \nelements to a photo crosses a threshold, rendering an image a fake. Using these A.I. tools to produce and share \nphotos could contribute to the spread of fake media online when misinformation is already rampant and it's hard to \nknow what to trust.\n  Dr. Ng, the computer science professor, said it was up to us to decide how to use generative photo technology \nresponsibly, especially now that it has arrived on smartphones. He has set his own limits.\nDoes Pixel 8's A.I.-Based Editing Cross a Line?\n  ''Anything that touches authenticity to me, as a photographer, would be very problematic,'' he said.\n  As for myself, I would use these A.I. photo tools to remove visual distractions, like the photo bomber ruining an \notherwise great picture, from photos shared among family. But even then, I would use these tools sparingly, and I \nwould not publish the fakery online.\nhttps://www.nytimes.com/2023/10/11/technology/personaltech/google-pixel8-photos.html\nGraphic\n \nPHOTOS: Using Pixel 8's A.I.-enabled photo editor, the citation on the rock to the right of the dog and the citation's \nshadow were removed and the background filled in to look like rock surface. This article appeared in print on page \nB8.               \nLoad-Date: October 12, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Cognizant gets its mojo back under new CEO’s watch",
        "media": "The Economic Times",
        "time": "January 9, 2024",
        "section": "ITES",
        "length": "1035 words",
        "byline": "Beena Parmar and Romita Majumdar",
        "story_text": "Cognizant gets its mojo back under new CEO’s watch\nThe Economic Times\nJanuary 9, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 1035 words\nByline: Beena Parmar and Romita Majumdar\nBody\nAs former Infosys President Ravi Kumar S completes one year as CEO of IT services and consulting major \nCognizant Technology Solutions Corp this month, experts and insiders ET gave a thumbs up to the new chief of the \n$19.4 billion dollar company has steered Cognizant into getting back its old “mojo”.Kumar, 49, is a \"people's \nperson\" who is winning back competitiveness on large deals, is getting major talent back to CTS, has rationalised \nthe company with real-estate as well as headcount consolidation. However, results in terms of actual revenue \ngrowth and profits are yet to show in a tough market situation where tech spending has dwindled. It is also yet to be \nseen how CTS under Kumar navigates lawsuits and warnings by Wipro and Infosys over poaching of senior \nleadership. Four of the experts ET spoke to, unanimously agreed that Kumar’s working style is much closer to the \nold Cognizant way and his management approach is different from his predecessor Brian Humphries, who led the \nfirm for four years after being coming from outside of the traditional IT services space.Kumar, joined the US-\nheadquartered firm as its fifth CEO since it was founded in Chennai in 1994 as a unit of Dun & Bradstreet. \nTaking the hotseat at Cognizant on 16 January, 2023, Kumar came in at a time when Cognizant was struggling to \nremain relevant as a key services partner, unable to close large deals, facing high attrition amid unfavourable \nmacro factors that have impacted the IT industry.“While it’s still relatively early days, Ravi has helped bring \nCognizant back into a host of client conversations and boost the firm’s large deal pipeline. Several clients are \nencouraged with the rapid progress Ravi has made and are willing to entertain what Cognizant has to offer with his \ngo-forward plans,” said Phil Fersht, founder and CEO of HfS Research.Peter Bendor-Samuel, CEO of IT research \nfirm Everest Group, said, “He has matched his competitors in fully funding the big deal team, however, the results \nare not particularly spectacular… Most of these moves have been simple execution moves and not big strategic \nchanges.”Cognizant did not respond to ET’s queries seeking comments for this piece.HitsIn Q3 (July to \nSeptember), Cognizant reported a record trailing 12-month deal bookings growth of $26.9 billion, up 16% year-over-\nyear (y-o-y), and a book-to-bill of 1.4x. Approximately 30% of these were large deals and three were over $100 \nmillion each.The Nasdaq-listed software services exporter said its operating margin of 15.5% exceeded its \nexpectations, mostly benefitting from its (NextGen) program, announced in Q2 aimed at savings worth $400 million. \nFurther, Cognizant is training and reskilling its employees and also committed about $1 billion in its generative AI \ncapabilities over the next three years.The firm also claims to have hit a historic high in its annual client Net \nPromoter Score survey, that measures customer loyalty.On the topline, Cognizant achieved 0.5% positive revenue \ngrowth in a difficult market condition where 60% of the larger competitors reported negative revenue growth, \naccording to Gaurav Vasu, CEO & Founder of UnearthInsight, an IT market intelligence firm.Vasu adds that Kumar \nhad “razor sharp focus on execution of NextGen program and sustaining margins at or over 14.2% in line with \nlarger peers while competitors with new CEOs & leadership changes have struggled to sustain margins… In fact, \nTech Mahindra, Wipro, etc are witnessing dip in margins.”For Q4 (Oct-Dec), Cognizant expects revenue between \n$4.69 billion and $4.82 billion, a y-o-y decline of 3.1% to 0.3% or dip of 4% to 1.2% in constant currency, with \ninorganic contribution of approximately 100 basis points (bps) (1%). In Q3, acquisitions contributed to 110 bps (1.1 \nper cent) to the revenue.Since Kumar took charge, the IT firm announced two acquisitions in 2023, Mobica in \nCognizant gets its mojo back under new CEO’s watch\nJanuary and Thirdera in December.For 30-year old Cognizant, India market doesn’t generate revenue but is a \ndelivery centre, focused on growing in Tier-II/III cities over last two years. This approach has aligned with its office \nspace optimisation plans as selling real estate in tier-I cities has acted as both retention and margin improvement \nlevers for the company.MissesWhile a lot of Kumar’s efforts are working, the CEO has his share of troubles.As part \nof the rationalisation plans, in May last year Cognizant let go 3,500 employees or 1% of its workforce. Nevertheless, \nCognizant has bucked the hiring trends with headcount increasing by 1000 employees from Q2 at 346,600. It also \naggressively expanded its senior leadership, which has irked its domestic rivals, especially Wipro and Infosys, from \nwhich Cognizant hired about 15-20 senior executives including for the vice president and president level \nroles.Wipro has filed lawsuits against at least two of its employees including Cognizant’s current chief financial \nofficer Jatin Dalal (former Wipro CFO) who joined in December. Meanwhile, Infosys has alleged Cognizant of using \n“unethical poaching tactics” in a communication likely directed at Kumar.In November, to an ET query in the post-\nresults concall, Kumar exclaimed that Cognizant is “a magnet for talent”. “Now, leadership and talent in the market \nis confident to join Cognizant and the cycle is back for us to hire the talent we want to,” he said.According to \nUnearthinsight’s Vasu, Kumar will have to remain focused on growth in North America/Emerging Markets and avoid \nhiring legal battles with competitors or compliance battles with authorities in both US/India as they “can derail both \nrevenue and margin focus in the short-run”.Amid a tough environment, Kumar will also have his task at hand to \neffectively integrate the acquisitions that saw investments worth around $2.2 billion since FY21.In a confluence of a \n“period of uncertainty and period of change”, as Kumar called the current macro environment after the Q3 results, \nhe still has promises to deliver. “It remains unclear if this level of performance will return Cognizant to the heady \ndays when it was setting the world on fire, and disrupting the tech Services market place. We will have to see,” \nBender-Samuel said. For Reprint Rights: timescontent.com\nLoad-Date: January 9, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Oct2023",
        "header": "MONEY PROS SHARE THEIR TOP PICKS — DAN NILES",
        "media": "Wall Street Journal Abstracts",
        "time": "October 27, 2023",
        "section": "S; Pg. 4",
        "length": "35 words",
        "byline": "DAN NILES",
        "story_text": "MONEY PROS SHARE THEIR TOP PICKS — DAN NILES\nWall Street Journal Abstracts\nOctober 25, 2023 Wednesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: S; Pg. 4\nLength: 35 words\nByline: DAN NILES\nBody\nABSTRACT\nSatori Fund founder Dan Niles article in Barron’s — Guide to Wealth suggests investor with $100,000 windfall could \ninvest in Oracle, which has opportunity in generative artificial intelligence and cloud (S)\nLoad-Date: October 27, 2023"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "Startups write a $1.5-billion twist in winter’s tale",
        "media": "The Economic Times",
        "time": "December 27, 2023",
        "section": "FUNDING",
        "length": "827 words",
        "byline": "Ajay Rag and Pranav Mukul",
        "story_text": "Startups write a $1.5-billion twist in winter’s tale\nThe Economic Times\nDecember 27, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 827 words\nByline: Ajay Rag and Pranav Mukul\nBody\nDecember has turned out to be the busiest month of 2023 for risk capital investors, who have announced more than \n$1.5 billion funding till Tuesday. However, most industry watchers would be cautious about terming it the end of the \nfunding winter.This month’s funding now tops January’s $1.4-billion raise, which was the highest for the year so far, \ndata compiled until December 26 by Tracxn showed.However, despite the last-month sprint, funding in India’s \nstartups in 2023 remained at a seven-year low of $8.8 billion. Notably, the monthly funding counter had also not \ncrossed the billion-dollar mark since March this year.Late-stage DealsIn March, deals worth $1.1 billion were \nannounced.Investors said the latest data pertain to deals that closed a few months ago, as the formal \nannouncement comes with a lag.According to the data, over 85% of the fund flows came into late-stage deals \nduring December, bucking the broader trend of a slowdown in growth- and late-stage funding.The surge is, thus, \nattributed to a few large deals, including the $600-million fund infusion in ecommerce marketplace Flipkart by US-\nbased retail major Walmart, as part of the Bengaluru-based firm’s $1-billion round that is yet to close. \nET was the first to report this development on December 21.Other big-ticket transactions announced during the \nmonth included business-to-business ecommerce marketplace Udaan’s $340-million fundraise, led by UK savings \nand investment firm M&G Prudential. A significant portion of Udaan’s deal was conversion of its existing debt into \nequity, with the fresh capital coming in from M&G Prudential comprising a relatively smaller part. Warehouse \nautomation startup GreyOrange’s $135-million round led by Anthelion Capital capped off the deals beyond $100 \nmillion in size.December’s commitment was nearly double November’s approximately $800 million, and 15% higher \nthan the $1.3 billion recorded in the last month of 2022.The data include primary and secondary deals, in addition to \nmoney raised through debt and convertible instruments.“Closures have taken a lot longer than in the past decade. \nSome of these are announcements and closures (after) months of work,” said Karthik Reddy, cofounder and \npartner, Blume Ventures, an early-stage venture capital firm. “What’s interesting is that a booming IPO (initial public \noffering) market has given more tech IPOs the courage to list quickly and that the trickle-down effect of liquidity and \nvalue establishment gives more comparables around true valuations and increases secondary flows more \naggressively.”ET earlier reported how extensive investor due diligence had lengthened deal closure timelines this \nyear, from the explosive pace of growth in 2021 and early 2022. This coincided with a number of corporate \ngovernance cases in the Indian startup ecosystem.On whether there could be a sustained recovery in funding, \nReddy said some of the secondary flow and impetus “automatically increases growth stage flow.”Also read | \nFunding in Indian startups sinks to $7 billion, lowest since 2017Data DecodedIn December, while late-stage deals \nled in terms of commitment size, early-stage investors were the most active by the number of deals \nannounced.Mumbai-based investor We Founder Circle announced six deals during the month, followed by \nLightspeed Venture Partners and 3one4 Capital at five and three deals, respectively. There were 11 deals in the \n$10-100 million range, including raises by startups such as Exponent Energy, Sarvam AI and VideoVerse.While \ntech companies led the pack by the quantum of funds raised, aided by the larger deal sizes, consumer brands —\nincluding beauty and personal care brand Nat Habit, cloud kitchen Biryani By Kilo, dry fruits specialist Farmley, \napparel brand Snitch and  direct-to-consumer mattress brand The Sleep Company— also raised funds from the \nStartups write a $1.5-billion twist in winter’s tale\nlikes of Premji Invest, Alpha Wave, DSG Consumer Partners, Bertelsmann India Investments and SWC Global.This \npoints to a trend of consumer brands increasingly raising venture money at a time when larger tech companies are \nwitnessing a cooling down of growth metrics amid high valuations.Ashish Sharma, managing partner at venture \ndebt firm Innoven Capital, said he expects the funding environment to remain sluggish going into 2024, and that \nenterprise and fintech, in terms of sectors, would continue to attract the bulk of the financing.“Investors have also \nshown increased interest in emerging sectors such as generative AI, deeptech and cleantech, which will see more \naction in 2024,” he said. “Some of the Covid darlings — such as edtech, digital media, gaming and web3 — are \nseeing less investor interest due to slowing growth, struggles with some large players, and some regulatory \nchallenges.”Shashank Randev, founder at early-stage investment firm 100x.vc, told ET that enterprise, consumer \ntech and healthtech “with sustainability at the core, will be movers” next year. For Reprint Rights: timescontent.com\nLoad-Date: December 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Jan2024",
        "header": "An Artist in Residence on A.I.'s Territory",
        "media": "The New York Times - International Edition",
        "time": "January 4, 2024",
        "section": "TECHNOLOGY",
        "length": "1543 words",
        "byline": "Leslie Katz",
        "story_text": "An Artist in Residence on A.I.'s Territory\nThe New York Times - International Edition\nJanuary 5, 2024 Friday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1543 words\nByline: Leslie Katz\nDateline: SAN FRANCISCO \nBody\nABSTRACT\nAlexander Reben is taking his tech-savvy perspective to OpenAI, a company that some in the art world believe is a \nthreat to their future.\nFULL TEXT\nAt a reception for OpenAI's first developer conference in San Francisco last month, a crowd mingled, wine in hand, \nas withering criticism of art created with artificial intelligence flashed on a blue wall at the front of the room. \"I've \nseen more engaging art from a malfunctioning printer,\" one critic jabbed. \"The fine-art equivalent of elevator music,\" \nhuffed another. \"Inoffensive, unmemorable and terminally dull.\"       \nIt might seem an odd strategy for OpenAI, the company behind widely used generative A.I. tools like ChatGPT and \nDALL-E, to promote scorn of A.I. art, until you catch the twist: A.I. itself wrote the criticism. Alexander Reben, the \nM.I.T.-educated artist behind the presentation, combined his own custom code with GPT-4, a version of the large \nlanguage model that powers the ChatGPT online chatbot.       \nNext month, Mr. Reben, 38, will become OpenAI's first artist in residence. He steps in as generative A.I. advances \nat a head-spinning rate, with artists and writers trying to make sense of the possibilities and shifting implications. \nSome regard artificial intelligence as a powerful and innovative tool that can steer them in weird and wonderful \ndirections. Others express outrage that A.I. is scraping their work from the internet to train systems without \npermission, compensation or credit.       \nIn late November, a group of visual artists filed an amended copyright lawsuit against Stability AI, Midjourney and \nother makers of A.I. tools after a federal judge dismissed parts of the original complaint, which accused the \ncompanies of misusing the artists' creations to train generative A.I systems. Mr. Reben said he couldn't speak to \nthe specifics of A.I. and the law, \"but like with any new creative technology, the law needs to catch up to the \nunpredictable future.\"       \n(The New York Times sued OpenAI and Microsoft for copyright infringement on Wednesday.)       \nTech companies including Google, Autodesk and Microsoft have welcomed artists in residence. And for the last \nseveral years, artists have tested products like GPT and the DALL-E image generator, offering insight into the tools' \ncreative potential before their public release. But the OpenAI residency, which is giving Mr. Reben a front-row view \nof the company's work, is a first for the start-up that is at the center of the debate over art and A.I.       \nAn Artist in Residence on A.I.'s Territory\n\"Alex is one of the first people we share our new models with,\" said Natalie Summers, a spokeswoman for OpenAI.       \nSam Altman, OpenAI's chief executive, has long acknowledged that the technologies created by his company will \nchange the nature of art. But he insists that no matter how good the technology gets, artists - human artists - will \nalways matter.       \n\"There was a real moment of fear where people asked, 'Is this a tool we have built or a creature we have built?'\" he \nsaid last month during an appearance in front of more than 300 artists and art lovers packed into an abandoned \nwarehouse in downtown Oakland, Calif. \"People now view these things as a new set of tools.\"       \nAfter the digital artist Android Jones said at the event that many artists were still very angry over the rise of A.I. \nimage generators and the way it reduced the value of their own art, Mr. Altman said people would always seek art \ncreated by other people.       \n\"There is clearly going to be more competition,\" he said. \"But, awash in a sea of A.I.-generated art, that desire for \nhuman connection will go up, not down.\"       \nGe Wang, an associate director of Stanford's Institute for Human-Centered Artificial Intelligence and an associate \nprofessor of music and computer science at the school's Center for Computer Research in Music and Acoustics, \nwonders how receptive OpenAI will be to considering the tough questions about A.I.'s impact on art. What's the \nright balance between machine output and human curation? Will the instantaneous results produced by the likes of \nDALL-E discourage people from developing the kinds of skills that require study and time?       \n\"Asking these questions is kind of bad for business, and OpenAI is a business,\" Dr. Wang said. \"You might have a \nwonderful artist there in residence asking questions. Are you willing to receive them?\"       \nNonetheless, Dr. Wang - who is also a musician and designed two music-making apps, Ocarina and Magic Piano, \nfor Apple's iPhone - said he was heartened that Mr. Reben was open to engaging with the questions about A.I.'s \nimpact on the art community.       \nMr. Reben said that as a technologist who had studied the impact of innovations like photography and recorded \nmusic on creativity, \"I usually stay on the cautiously optimistic side.\"       \n\"But like any other technology of the past, there are both sides to the coin,\" he added.       \nThe New York native moved to Berkeley, Calif., a decade ago to become director of technology and research at \nStochastic Labs, an incubator for creative scientists and engineers that is housed in a three-story 19th-century \nVictorian. Mr. Reben's highly conceptual art lines the walls of the main hallway and fills work spaces packed with \nprinters, headphones, cables, capacitors, soldering supplies, and other bits and bobs.       \nOn a rainy Thursday, Mr. Reben relaxed on a couch at Stochastic after a meeting at OpenAI to continue working \nout details of what he'll do during the residency, which will last three months.       \n\"If I come out of it and make my art better, or even come up with some new questions or new directions to present \nto the world, that would be very valuable,\" said Mr. Reben, who researched human-machine symbiosis as a \ngraduate student at the M.I.T. Media Lab, an interdisciplinary research center.       \nThe residency overlaps with Mr. Reben's first major retrospective, titled \"AI Am I?\" and on display through April at \nSacramento's Crocker Art Museum. DALL-E and other image generators like Midjourney and Stability AI's Stable \nDiffusion have captivated the internet by allowing anyone to instantly retrieve custom visual imagery simply by \ntyping a few words into a box. But while much A.I.-generated art exists as pixels, Mr. Reben often manifests \nphysical structures from ideas he hones with the help of artificial intelligence.       \n\"I like a lot of absurdity and humor in my work, even if the underpinning question is serious,\" Mr. Reben said.       \nAn Artist in Residence on A.I.'s Territory\nOne sculpture at the exhibit presents six toilet plungers queued up like a bizarre police lineup. A.I.-generated text \non the wall placard explains that the work represents all that remains of the Plungers, an apocryphal '70s art \ncollective. Its fake artists adhered to \"plungism,\" a fictional philosophy \"wherein the mind of an artist is in a state of \nflux and able to be influenced by all things, even plungers.\"       \nPlungism arose from Mr. Reben's extensive back and forth with GPT-3: He'd enter a prompt (an input aimed at \nproducing a desired response), and then tinker with his favorite responses, sometimes feeding the edited language \nback to the A.I. until he landed on just the right wording.       \nThen there's \"Dreams of the Cheese-Faced Gentleman,\" which depicts a man whose face could be mistaken for a \nwheel of Swiss cheese. Mr. Reben worked with GPT-4 to find the right prompts to craft a compelling description of a \npainting, then fed the curated text into an image generator. He's not a painter himself, so he commissioned one to \nmake the artwork.       \nA large language model capable of ingesting both images and text then studied the painting and described it in \nlanguage that would fit in at any museum. \"The combination of psychedelic surrealism and whimsicality lends the \npainting an air of playfulness, challenging the viewer to engage with the work's complex layers of meaning,\" the wall \nlabel reads.       \nJanisy Lagrue, the A.I.-imagined name for the real-life painter who produced the oil on canvas, explained: \"I use \ncheese because it is so perfect a symbol of the American dream. Cheese is a commodity, not a food. It is totally \nartificial, and it is delicious.\"       \nThe exhibit provokes more questions than answers, a reflection of Mr. Reben's belief that as machines produce \nbetter outputs, humans need to ask better questions - about bias and ownership, among other things.       \n\"Given how young this creative tool is, much still needs to be solved, and confronting these problems falls on the \nshoulders of everyone involved, from its developers to its users,\" Mr. Reben said. \"The more people thinking about \nthese questions the better.\"       \nMr. Reben doesn't profess to speak for all artists as OpenAI's first artist in residence. But he does understand their \nconcerns. Artists and writers worry that A.I. could steal their jobs, but Dr. Wang of Stanford said the nervousness \nextended beyond the possibility of lost livelihood.       \nThe fear is \"not only are we going to be replaced as artists, it's that we'll be replaced by something far more \ngeneric, far less interesting,\" he said. \"Maybe generic is enough to make a ton of money.\"       \nCade Metz contributed reporting.       \nCade Metz contributed reporting. \nLoad-Date: January 4, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Jul2023",
        "header": "A Blessing and a Boogeyman: Advertisers Warily Embrace A.I.",
        "media": "The New York Times - International Edition",
        "time": "July 19, 2023",
        "section": "BUSINESS",
        "length": "1290 words",
        "byline": "Tiffany Hsu and Yiwen Lu",
        "story_text": "A Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\nThe New York Times - International Edition\nJuly 20, 2023 Thursday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1290 words\nByline: Tiffany Hsu and Yiwen Lu\nBody\nMany ads are easier to make with the fast-improving technology. It also poses a threat to an industry already in flux.       \nThe advertising industry is in a love-hate relationship with artificial intelligence.       \nIn the past few months, the technology has made ads easier to generate and track. It is writing marketing emails \nwith subject lines and delivery times tailored to specific subscribers. It gave an optician the means to set a fashion \nshoot on an alien planet and helped Denmark's tourism bureau animate famous tourist sites. Heinz turned to it to \ngenerate recognizable images of its ketchup bottle, then paired them with the symphonic theme that charts human \nevolution in the film \"2001: A Space Odyssey.\"       \nA.I., however, has also plunged the marketing world into a crisis. Much has been made about the technology's \npotential to limit the need for human workers in fields such as law and financial services. Advertising, already \nracked by inflation and other economic pressures as well as a talent drain due to layoffs and increased automation, \nis especially at risk of an overhaul-by-A.I., marketing executives said.       \nThe conflicting attitudes suffused a co-working space in downtown San Francisco where more than 200 people \ngathered last week for an \"A.I. for marketers\" event. Copywriters expressed worry and skepticism about chatbots \ncapable of writing ad campaigns, while start-up founders pitched A.I. tools for automating the creative process.       \n\"It really doesn't matter if you are fearful or not: The tools are here, so what do we do?\" said Jackson Beaman, \nwhose AI User Group organized the event. \"We could stand here and not do anything, or we can learn how to apply \nthem.\"       \nMachine learning, a subset of artificial intelligence that uses data and algorithms to imitate how humans learn, has \nquietly powered advertising for years. Madison Avenue has used it to target specific audiences, sell and buy ad \nspace, offer user support, create logos and streamline its operations. (One ad agency has a specialized A.I. tool \ncalled the Big Lebotski to help clients compose ad copy and boost their profile on search engines).       \nEnthusiasm came gradually. In 2017, when the advertising group Publicis introduced Marcel, an A.I. business \nassistant, its peers responded with what it described as \"outrage, jest and negativity.\"       \nAt last month's Cannes Lions International Festival of Creativity, the glittering apex of the advertising industry \ncalendar, Publicis got its \"I told you so\" moment. Around the festival, where the agenda was stuffed with panels \nabout A.I.'s being \"unleashed\" and affecting the \"future of creativity,\" the company plastered artificially generated \nposters that mocked the original reactions to Marcel.       \n\"Is it OK to talk about A.I. at Cannes now?\" the ads joked.       \nA Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\nThe answer is clear. The industry has wanted to discuss little else since late last year, when OpenAI released its \nChatGPT chatbot and set off a global arms race around generative artificial intelligence.       \nMcDonald's asked the chatbot to name the most iconic burger in the world and splashed the answer - the Big Mac - \nacross videos and billboards, drawing A.I.-generated retorts from fast food rivals. Coca-Cola recruited digital artists \nto generate 120,000 riffs on its brand imagery, including its curved bottle and swoopy logo, using an A.I. platform \nbuilt in part by OpenAI.       \nThe surge of A.I. experimentation has brought to the fore a host of legal and logistical challenges, including the \nneed to protect reputations and avoid misleading consumers.       \nA recent campaign from Virgin Voyages allowed users to prompt a digital avatar of Jennifer Lopez to issue \ncustomized video invitations to a cruise, including the names of potential guests. But, to prevent Ms. Lopez from \nappearing to use inappropriate language, the avatar could say only names from a preapproved list and otherwise \ndefaulted to terms like \"friend\" and \"sailor.\"       \n\"It's still in the early stages - there were challenges to get the models right, to get the look right, to get the sound \nright - and there are very much humans in the loop throughout,\" said Brian Yamada, the chief innovation officer of \nVMLY&R, the agency that produced the campaign for Virgin.       \nElaborate interactive campaigns like Virgin's make up a minority of advertising; 30-second video clips and \ncaptioned images, often with variations lightly adjusted for different demographics, are much more common. In \nrecent months, several large tech companies, including Meta, Google and Adobe, have announced artificial \nintelligence tools to handle that sort of work.       \nMajor advertising companies say the technology could streamline a bloated business model. The ad group WPP is \nworking with the chip maker Nvidia on an A.I. platform that could, for example, allow car companies to easily \nincorporate footage of a vehicle into scenes customized for local markets without laboriously filming different \ncommercials around the world.       \nTo many of the people who work on such commercials, A.I.'s advance feels like looming obsolescence, especially \nin the face of several years of slowing growth and a shift in advertising budgets from television and other legacy \nmedia to programmatic ads and social platforms. The media agency GroupM predicted last month that artificial \nintelligence was likely to influence at least half of all advertising revenue by the end of 2023.       \n\"There's little doubt that the future of creativity and A.I. will be increasingly intertwined,\" said Philippe Krakowsky, \nthe chief executive of the Interpublic Group of Companies, an ad giant.       \nIPG, which was hiring chief A.I. officers and similar executives years before ChatGPT's debut, now hopes to use \nthe technology to deliver highly personalized experiences.       \n\"That said, we need to apply a very high level of diligence and discipline, and collaborate across industries, to \nmitigate bias, misinformation and security risk in order for the pace of advancement to be sustained,\" Mr. \nKrakowsky added.       \nA.I.'s ability to copy and deceive, which has already found widespread public expression in political marketing from \nGov. Ron DeSantis of Florida and others, has alarmed many advertising executives. They are also concerned \nabout intellectual property issues and the direction and speed of A.I. development. Several ad agencies joined \norganizations such as the Coalition for Content Provenance and Authenticity, which wants to trace content from its \norigins, and the Partnership on AI, which aims to keep the technology ethically sound.       \nAmid the doom and gloom, the agency Wunderman Thompson decided this spring to take A.I. down a peg.       \nIn an Australian campaign for Kit Kat candy bars, the agency used text and image generators from OpenAI to \ncreate intentionally awkward ads with the tagline \"AI made this ad so we could have a break.\" In one, warped \nA Blessing and a Boogeyman: Advertisers Warily Embrace A.I.\nfigures chomped on blurry chocolate bars over a script narrated in a mechanical monotone: \"Someone hands them \na Kit Kat bar. They take a bite.\"       \nThe campaign would be trickier to pull off now, in part because the fast-improving technology has erased many of \nthe flaws present just a few months ago, said Annabelle Barnum, the general manager for Wunderman Thompson \nin Australia. Still, she said, humans will always be key to the advertising process.       \n\"Creativity comes from real human insight - A.I. is always going to struggle with that because it relies purely on data \nto make decisions,\" she said. \"So while it can enhance the process, ultimately it will never be able to take away \nanything that creators can really do because that humanistic element is required.\" \nLoad-Date: July 19, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Discussions on Chip Fabrication Scaling, Manufacturing Investments",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 8, 2023",
        "section": "FRONT PAGE",
        "length": "783 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Discussions on Chip Fabrication Scaling, Manufacturing Investments\nEconomic Times (E-Paper Edition)\nSeptember 8, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 783 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Plan to expand workforce in India, focus on upskilling, says Huang\nBody\nCEO MEETS IISC , IIT RESEARCHERS\nBengaluru: Nvidia, the world's pre-eminent maker of hardware and software for artificial intelligence tools, envisions \nexporting AI products from its Indian arm, CEO and cofounder of the $27-billion firm, Jensen Huang told \nresearchers at India's top technology institutes this week, according to the people present at the interaction. India is \nevolving into a “front end” nation in the world of technology, the 60-year-old technocrat told his audience during his \nongoing visit in the country, which included a meeting with Prime Minister Narendra Modi on September 4.  The \nAmerican chipmaker, which is riding on a trillion-dollar valuation led by the boom in generative Artificial \nIntelligence (AI), expects to leverage the vast data generated by India's $1.4 billion population to build AI products \nthat can be exported from the country. Huang, who co-founded the Santa Clara-based technology giant in 1993, \nmet researchers from the Indian Institute of Science's (IISc) department of computational and data sciences (CDS), \nIndian Institute of Technology (IIT) Madras and IIT Bombay on September 4 during the course of his week-long \nvisit. Sashikumar Ganesan, associate professor and chair of CDS at IISc, Bengaluru, told ET that the discussions at \nthe HPC and AI Research Leaders Meet revolved around leaders in artificial intelligence (AI) and highperformance \ncomputing (HPC), which is Nvidia's primary business domain. \nHuang communicated plans to expand Nvidia's workforce in India and focus on upskilling. “Although we may lack \nthe ecosystem to collect all data, once acquired, all AI and machine learning systems for the world can be trained \non it. This is one of the reasons why technology companies invest heavily in India,” Ganesan said. Discussions \nduring the meeting encompassed India's potential to lead AI research, chip fabrication scaling, and investments in \nmanufacturing. TRILLION-DOLLAR CLUB Nvidia manufactures semiconductor chips that are integral to the \nfunctioning of AI-products built by the likes of Microsoft-backed OpenAI such as ChatGPT. As it rode the surging AI \nwave in 2023, Nvidia saw a record rise in demand for its chips, which are now at an all-time high. Nvidia reported a \nrevenue of $13.51 billion for the second quarter ended July 30, 2023, up 101% from a year ago. Its stock recently \nhit an all-time high after a surge of 315%. The company reached a market value of more than a trillion dollars in \nMay this year, joining the likes of Microsoft, Apple and Amazon. Following Microsoft's $10 billion investment into the \nSam Altman founded-OpenAI earlier this year, Google announced an aggressive follow-up through its own AI tool \nBard. Huang was keen to understand the nuances of high-perfor-  mance computing in India, its applications, and \nNvidia's role. Ajay Kumar Sood, a distinguished honorary professor of Physics at IISc and the principal scientific \nadvisor to the Indian government, was also among the attendees. INDIA FOCUS Nvidia began its operations in \nIndia in 2004 in Bengaluru and has four engineering development centres located in Gurugram, Hyderabad, Pune \nand Bengaluru with a workforce of 3,800 individuals in India. More than 320,000 India-based developers are part of \nNvidia's developer programme. Huang was updated on the research activities of CDS at IISc. “We're integrating \nmachine learning with computational science. Huang was curious about this intersection,” Ganesan said. He added \nDiscussions on Chip Fabrication Scaling, Manufacturing Investments\nthat Huang highlighted the importance of using data generated from the scientific community instead of synthetic \nmethods in AI systems. Other topics covered during the meeting included an India-focused cloud initiative and the \nNational Supercomputing Mission (NSM).  NSM aims to equip India with advanced supercomputing infrastructure, \naddressing the computational needs of various sectors.  “An upgraded version, NSM 2.0, will further enhance our \ncomputing capabilities,” said Ganesan. Huang has visited India several times over the past few years. The last \nmeeting held between Prime Minister Modi and Huang was five years ago in New Delhi.  Following the meeting \nearlier this week, PM Modi had posted on X, “Had an excellent meeting with Mr Jensen Huang, the CEO of \n@nvidia. We talked at length about the rich potential India offers in the world of AI.  Mr Jensen Huang was \nappreciative of the strides India has made in this sector and was equally upbeat about the talented youth of India.” \nThis comes at a time when technology executives, startup founders and venture capital chiefs are petitioning the \ngovernment to invest in developing India's AI compute-infrastructure.  FOR FULL REPORT, GO TO \nwww.economictimes.com\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Dec2022",
        "header": "The 2022 Good Tech Awards; The Shift",
        "media": "The New York Times - International Edition",
        "time": "December 30, 2022",
        "section": "TECHNOLOGY",
        "length": "1490 words",
        "byline": "Kevin Roose",
        "story_text": "The 2022 Good Tech Awards; The Shift\nThe New York Times - International Edition\nDecember 31, 2022 Saturday\nCopyright 2022 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1490 words\nByline: Kevin Roose\nBody\nABSTRACT\nNuclear fusion, generative A.I., bee tracking and more. There's a lot to like.\nFULL TEXT\nThe year 2022, in the tech world, was one of big leaps and even bigger pratfalls.       \nThe falls included some of the industry's most recognizable names. Sam Bankman-Fried began the year as the \nbiggest celebrity in crypto, with a net worth of more than $20 billion, and ends it as a disgraced pariah who is facing \ncriminal fraud charges. Elon Musk began 2022 as the world's richest man, with a thriving electric car company and \na name synonymous with success; he ends it more than $100 billion poorer, as the bitter and beleaguered owner of \na social media company that seems to be ruining his life.       \nThe tech industry struggled, too, with harsh macroeconomic conditions, including high inflation and rising interest \nrates. As the sector's decade of hypergrowth came to an end, start-ups died, tech giants cut perks and laid off \nworkers, and investors' dreams of a new, crypto-fied internet known as \"web3\" faded into oblivion.       \nBut focusing exclusively on what went wrong risks missing the many noble, clever and socially valuable tech \nprojects that made progress this year.       \nFor several years now, I've highlighted these kinds of projects in my annual Good Tech Awards column. These \naren't necessarily technologies that I'm sure will improve the world, while causing no problems whatsoever. They're \ntools that I believe could improve the world, or help address thorny societal challenges. Some of them could also go \nquite badly, if they're mismanaged or co-opted in harmful ways.       \nThere were many to choose from this year. Here's what made the final cut.       \nTo OpenAI and the makers of Midjourney and Stable Diffusion, for proving that A.I. can create\nThe splashiest tech breakthrough of the year, by a significant margin, was the boom in \"generative A.I.\" - a term for \nthe new type of artificial intelligence apps, trained on vast amounts of data, that can create new media objects out \nof thin air.       \nThis year, A.I. image generators like DALL-E 2, Stable Diffusion and Midjourney dazzled users (including me) with \ntheir creations and set off a Cambrian explosion of new, ultracapable A.I. tools. In recent weeks, ChatGPT, a text-\ngenerating A.I. built by OpenAI, became a viral sensation (and every teacher's worst nightmare) when it started \ncranking out term papers, original poetry and working snippets of code.       \nThe 2022 Good Tech Awards The Shift\nSome credit for the generative A.I. boom should go to Google, which created much of the foundational technology. \nBut this year, Google (which has kept most of its A.I. experiments private, to its recent chagrin) got one-upped by \nOpenAI, as well as the makers of Midjourney and Stable Diffusion, all of which released public-facing products that \nallowed millions of people to experience generative A.I. for themselves.       \nThe ultimate effects of generative A.I. are still unknown. Some people argue that these apps will destroy millions of \njobs, while others argue that they'll be a boon to human creativity. But whether you're an A.I. optimist or pessimist, \nthis year's advances mean that we are no longer debating theoretical costs and benefits - the tools have arrived, \nand we now get to decide how to use them.       \nTo Ethereum developers, for pulling off the merge\nI know, I know. Putting a crypto project in a \"good tech\" list in 2022 feels like putting credit default swaps in a \"cool \nfinancial innovations\" list in 2008.       \nBut while the crypto industry took a nosedive this year - wiping out trillions of dollars in value and leaving many \ninvestors empty-handed - there was at least one bright spot. In September, Ethereum, the network behind the \nsecond most valuable cryptocurrency after Bitcoin, completed what was known as \"the merge\" - a hulking, years-in-\nthe-making project to switch Ethereum from an energy-guzzling form of blockchain known as \"proof of work\" to a \nmuch greener form of blockchain known as \"proof of stake.\"       \nThe switch, which crypto developers compared to trying to swap a plane's engine in midair, was a smashing \nsuccess, and cut the energy required to power Ethereum by more than 99 percent. (It didn't, however, boost the \nprice of the cryptocurrency, Ether, which ended the year down nearly 70 percent.)       \nTo Living Carbon, Twelve and BeeHero, for turning tech on the climate crisis\nWhile 2022 was a horrible year for start-up fund-raising in general, it was a great year for climate tech start-ups, \nwhich raised billions of dollars to bring climate-friendly technologies to market.       \nThere are too many promising climate tech start-ups to name - and, to be honest, I don't know enough about \nclimate science to tell which ones stand the best chance of succeeding - but a few that caught my eye this year \nwere Living Carbon, Twelve and BeeHero.       \nLiving Carbon, a three-year-old California start-up, is genetically engineering trees and other plants to capture and \nstore more carbon from the atmosphere. These G.M.O. supertrees, the company claims, grow bigger and faster \nthan normal trees and can survive in soil with metal concentrations that would be toxic to other plants.       \nTwelve, which is based in Berkeley, Calif., is using a novel electrochemical process to turn carbon dioxide into \nindustrial products as varied as sunglasses and jet fuel. The company raised a $130 million funding round this year \nand struck deals with companies like Mercedes-Benz and Procter & Gamble.       \nBeeHero, which was started in Israel in 2017, is using new technology to address problems facing one of the most \nimportant parts of our global food supply: bees. Bees pollinate more than one-third of all crops, but they are dying \noff at alarming rates, setting off fears of a food shortage. To tackle this, BeeHero developed a \"precision pollination \nplatform\" - basically, a bee-tracking sensor system that allows for industrial beekeepers to monitor the health and \nproductivity of their hives in real time. The company raised a $42 million Series B (Series Bee?) round this year \nfrom investors including General Mills.       \nTo the National Ignition Facility, Commonwealth Fusion Systems and Helion, for keeping the fusion dream \nalive\nNuclear fusion, an emissions-free form of energy generation that has long been viewed as the \"holy grail of energy,\" \ntook a few important steps toward reality this year.       \nThe 2022 Good Tech Awards The Shift\nThe biggest fusion news of the year came just a few weeks ago when scientists at the National Ignition Facility at \nLawrence Livermore National Laboratory in California crossed a major threshold known as \"ignition,\" creating a \nfusion reaction that generated more energy than it took to produce. That breakthrough was hailed by officials \nincluding Jennifer M. Granholm, the secretary of energy, who called it a \"landmark achievement.\"       \nMany start-ups have also been plugging away on fusion. One, Helion Energy, has raised hundreds of millions of \ndollars from well-known investors including Sam Altman, Dustin Moskovitz and Peter Thiel to create affordable, \nmass-market fusion technology. Helion says it plans to create energy with its next fusion reactor, Polaris, by 2024. \nAnother company, Commonwealth Fusion Systems, which was spun out of the Massachusetts Institute of \nTechnology in 2018, is using an array of powerful magnets to power its prototype fusion machine outside Boston, \nand plans to have it up and running by 2025.       \nExperts have cautioned that despite the latest breakthroughs, affordable fusion power may not be widely available \nfor years. But this year, both the public and private sectors offered a glimpse of a fusion-powered future.       \nTo Locket, for making photo-sharing fun again\nIf 2022 was the year when social media died, it was also the year when start-ups began trying to recapture what \nhad made social media fun in the first place.       \nOne app I've loved using this year is Locket. It's a very simple premise - a widget that is installed on your \nsmartphone's home screen, creating a kind of digital photo frame that your closest friends and loved ones can \nupload photos to.       \nLocket was created by Matt Moss, a young developer who wanted a way to send photos to his long-distance \ngirlfriend; this year, the app quickly grew to millions of users, raised a major funding round and won an Apple \ncultural impact award. There are no filters, preening influencers, data-harvesting schemes or algorithmic feeds on \nLocket - it's just an easy, no-frills way to share photos with your loved ones.       \nMy wife and I started using Locket this year to share photos of our kid, in a way that wouldn't require us digging \nthrough text chains or huge photo albums to find them later on. It's not the tech product I've used most often, or the \none I think will create the most net good for society. But it's fun, uncomplicated and respectful of its users - three \nqualities to which more tech products should aspire. \nLoad-Date: December 30, 2022"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Can A.I. Invent?",
        "media": "The New York Times",
        "time": "July 17, 2023",
        "section": "TECHNOLOGY",
        "length": "1229 words",
        "byline": "Steve Lohr",
        "story_text": "Can A.I. Invent?\nThe New York Times \nJuly 15, 2023 Saturday 23:41 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1229 words\nByline: Steve Lohr\nHighlight: A group of legal experts are pressing patent agencies, courts and policymakers to address the question \nas generative A.I. seems on the brink of invading another uniquely human endeavor.\nBody\nA group of legal experts are pressing patent agencies, courts and policymakers to address the question as \ngenerative A.I. seems on the brink of invading another uniquely human endeavor.\nGenerative artificial intelligence, the technology engine powering the popular ChatGPT chatbot, seems to have a \nlimitless bag of tricks. It can produce on command everything from recipes and vacation plans to computer code \nand molecules for new drugs.\nBut can A.I. invent?\nLegal scholars, patent authorities and even Congress have been pondering that question. The people who answer \n“yes,” a small but growing number, are fighting a decidedly uphill battle in challenging the deep-seated belief that \nonly a human can invent.\nInvention evokes images of giants like Thomas Edison and eureka moments — “the flash of creative genius,” as the \nSupreme Court justice William O. Douglas once put it.\nBut this is far more than a philosophical debate about human versus machine intelligence. The role, and legal \nstatus, of A.I. in invention also have implications for the future path of innovation and global competitiveness, \nexperts say.\nThe U.S. Patent and Trademark Office has hosted two public meetings this year billed as A.I. Inventorship Listening \nSessions.\nLast month, the Senate held a hearing on A.I. and patents. The witnesses included representatives of big \ntechnology and pharmaceutical companies. Next to them at the witness table was Dr. Ryan Abbott, a professor at \nthe University of Surrey School of Law in England, who founded the Artificial Inventor Project, a group of intellectual \nproperty lawyers and an A.I. scientist.\nThe project has filed pro bono test cases in the United States and more than a dozen other countries seeking legal \nprotection for A.I.-generated inventions.\n“This is about getting the incentives right for a new technological era,” said Dr. Abbott, who is also a physician and \nteaches at the David Geffen School of Medicine at the University of California, Los Angeles.\nRapidly advancing A.I., Dr. Abbott contends, is very different from a traditional tool used in inventions — say, a \npencil or a microscope. Generative A.I. is also a new breed of computer program. It is not confined to doing things \nCan A.I. Invent?\nit is specifically programmed to do, he said, but produces unscripted results, as if creatively “stepping into the shoes \nof a person.”\nA central goal of Dr. Abbott’s project is to provoke and promote discussion about artificial intelligence and invention. \nWithout patent protection, he said, A.I. innovations will be hidden in the murky realm of trade secrets rather than \ndisclosed in a public filing, slowing progress in the field.\nThe Artificial Inventor Project, said Mark Lemley, a professor at the Stanford Law School, “has made us confront \nthis hard problem and exposed the cracks in the system.”\nBut patent arbiters generally agree on one thing: An inventor has to be human, at least under current standards.\nThe project has experienced mixed results so far with patent authorities around the world. South Africa granted it a \npatent for a heat-diffusing drink container that was generated by A.I., and most countries, including China, have not \nyet made a determination. In the United States, Australia and Taiwan, its claims have been turned down.\nAfter the U.S. patent office rejected the project’s patent application — a decision upheld in a federal appeals court \n— Lawrence Lessig, a professor at the Harvard Law School, joined a brief filed this year with the Supreme Court.\nIn support of the project’s patent claim, Mr. Lessig and his co-authors wrote that the federal appeals court’s ruling \n“deprives an entire class of important and potentially lifesaving patentable inventions of any protections” and \n“jeopardizes billions in current and future investments” by undermining the incentive that patent protection would \nprovide.\nThe Supreme Court declined to hear the case.\nMany patents list several inventors, and company employees are frequently named while the patent’s owner is their \nemployer. That suggests a middle ground for A.I. systems as a co-inventor, credited and fully disclosed — a partner \nrather than a solo creator.\n“That may end up being where we land, but that’s a pretty big line to cross,” said Senator Chris Coons, the \nchairman of the Judiciary subcommittee on intellectual property.\nIf granting A.I. inventor status is a stretch today, stronger intellectual property protection for the fast-evolving \ntechnology is not.\nMr. Coons, a Delaware Democrat, and Senator Thom Tillis, a North Carolina Republican, introduced a bill last \nmonth to clarify what kinds of innovations are eligible for patents. It is intended as a legislative fix to the uncertainty \nraised by a series of Supreme Court decisions. Patents on artificial intelligence, along with medical diagnostics and \nbiotechnology, would most likely become easier to obtain, legal experts say.\nThe bill is not about artificial intelligence specifically, but it “recognizes the direction of travel relative to A.I.” toward \nstronger patent protection, said David Kappos, a former director of the patent office and a partner at Cravath, \nSwaine &amp; Moore.\nAt the Senate hearing, Dr. Abbott made the case for A.I. invention, helped by an odd-looking drink container he held \nup and described. It was created by an A.I. system trained on general knowledge. It had no training in container \ndesign, and it was not asked to make one.\nThe A.I. was built to combine simple ideas and concepts into more complex ones and identify when one had a \npositive outcome, a process repeated again and again. The resulting design was fed into a 3-D printer. The \ncontainer employs fractal geometry to improve heat transfer, a kind of anti-Thermos. It could, for example, be used \nto quickly make iced tea, boiled, steeped and refrigerated.\nThe container is easy to hold, difficult to drink from and not headed for commercial production yet. But it is certainly \nnovel, and it is entirely the creation of an A.I. system without human control.\nCan A.I. Invent?\nThe A.I. system was created by Stephen Thaler, who has conducted artificial intelligence research and \ndevelopment for decades, at McDonnell Douglas and later on his own. Dr. Abbott’s study of the A.I. field led him to \nDr. Thaler, who agreed to use his technology to generate a demonstration invention or two for the Artificial Inventor \nProject.\nDr. Thaler’s patented system has some ingredients similar to those in generative A.I. models like ChatGPT, and \nothers that are not. He describes his system as having the machine equivalent of feelings. It becomes digitally \nexcited, producing a surge of simulated neurotransmitters, when it recognizes useful ideas, setting off “a ripening \nprocess, and the most salient ideas survive.”\nDr. Thaler said the ability to recognize and react in that way amounted to sentience, and his generative A.I. system \nis called DABUS, for Device for the Autonomous Bootstrapping of Unified Sentience.\nHe regards the reluctance of patent authorities to recognize his system as an inventor as discrimination against a \ncreation-capable machine. “It’s speciesism to me,” he said.\nBut Dr. Abbott said, “That’s totally irrelevant to the legal question.”\nAnd that question will surely become more pressing in time. “There is a universal consensus that A.I. will only get \nbetter at this sort of thing,” Dr. Abbott said.\nThis article appeared in print on page B1, B4.\nLoad-Date: July 17, 2023"
    },
    {
        "file_name": "TESTED_IN_AMAZON_WAREHOUSES_Oct2023",
        "header": "CMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS'; HUMANOID BOTS",
        "media": "TESTED IN AMAZON WAREHOUSES",
        "time": "October 30, 2023",
        "section": "ASECTION; Pg. A-1",
        "length": "988 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "CMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS'; HUMANOID BOTS \nTESTED IN AMAZON WAREHOUSES\nPittsburgh Post-Gazette\nOctober 30, 2023 Monday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 988 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nAmazon's new factory workers don't complain about long hours or poor working conditions.\nBuilt by Carnegie Mellon University alumni, the Agility Robotics humanoids, called Digit, can pick up packages and \nwalk around warehouses on their own two legs. They're part of a push by the online shopping giant to make \ndeliveries more efficient.\n\"New robotic solutions ... will support workplace safety and help Amazon deliver to customers faster,\" the company \nsaid in a recent blog post.\nAmazon led the charge toward warehouse automation with the purchase of Kiva Systems in 2012. It now deploys \n750,000 wheeled mobile robots across its warehouse network.\nBut Digit would be the company's first on two feet.\nThe 5-foot, 9-inch bots were designed around Occupational Safety and Health Administration standards and built to \nmove like humans so that they can work in existing factories, said Agility CEO Damion Shelton. To recharge, the \nrobots initially sat in bays that resembled airport massage chairs.\n\"Now, because of where the battery pack is, it actually clicks back into the charge dock,\" Mr. Shelton said. \"I really \nloved the airport massage chair model, but you know, engineering realities taking precedence.\"\nBoth Amazon and Agility say robots won't replace human jobs. Digit is designed to work alongside humans and \nreplace the most mundane tasks, freeing up people to do more thought-heavy tasks.\n\"Despite the logistics industry pushing out a non-trivial amount of robots in the past 10 years, not only has there not \nbeen any job loss associated with it, the number of unfilled jobs has actually increased,\" Mr. Shelton said.\nAgility plans to make 10,000 Digit units each year. Amazon is currently using the bots in a testing capacity but sees \n\"a big opportunity to scale.\"\nMr. Shelton started Agility in 2015 alongside Chief Technology Officer Jonathan Hurst. They met as CMU graduate \nstudents in the early 2000s.\n\"The whole train that ultimately led to what became Digit has its roots back to Jonathan being in grad school at \nCMU,\" said Mr. Shelton, who remembers helping Mr. Hurst with his computer science homework as the student \nhelped him with his mechanical work.\nCMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS' HUMANOID BOTS TESTED IN AMAZON \nWAREHOUSES\nMr. Hurst went on to create Oregon State University's first robotics lab. Mr. Shelton taught at the University of \nPittsburgh before leaving the conceptual world of academia to build real-world products, first at threeRivers 3D and \nnow at Agility.\nTheir synergy led to the first commercially available bipedal robot, Cassie, in 2017. Three years later, Agility started \nselling Digit to Ford.\nSimilar humanoids have been developed by Boston Dynamics and Tesla, but neither have found broad commercial \nuse. New founders like Brett Adcock, of electric aviation company Archer, are now getting bipedal robots up on two \nlegs in under a year.\nMr. Shelton said the various companies don't necessarily learn from each other's approach.\n\"We're comfortable, frankly, with our own tech,\" he said.\nBut together, the buzz they create can be helpful.\n\"This is such a large market, it's not like any individual company is going to dominate 100% of it,\" Mr. Shelton said. \n\"Agility is obviously the first to market, and we're quite confident with where we are. But we're also happy that \nthere's more broad interest in this space.\"\nAgility is headquartered in Corvallis, Ore., but Mr. Shelton and a team of about 45 employees work from its second-\nlargest office in Pittsburgh. The company received development funding last year from Amazon's $1 billion \nIndustrial Innovation Fund.\nAmazon also backed a CMU team in 2015 that built the four-legged \"CHIMP\" robot, which could drive, climb stairs \nand operate power tools - all facets of a competition sponsored by the Defense Advanced Research Projects \nAgency.\nMr. Hurst led a team at Oregon State University that also responded to the challenge, building the ostrich-like \nATRIAS, a direct predecessor to Cassie.\nStill, years later, Mr. Shelton said humanoids remain an \"unmet gap for automation.\"\n\"The main argument for robots that are about the size and shape of a person is not so much that they're cool - \nalthough they are - but rather that our world is set up around us,\" he said.\nThere is still a ways to go before Digit finds its way outside of warehouses, where safety would be a significant \nconcern.\nThe robots are fully autonomous and even walk themselves back to charging stations when it's time to refuel. But \nthey are trained on a limited world of smooth floors and standard-sized bins.\nPittsburgh's sidewalks would pose an entirely different challenge, Mr. Shelton said.\n\"It is literally possible to have a CAD model of every single plastic bin in the entire world,\" he said. \"Whereas in \nPittsburgh, God knows what database you'd have to have.\n\"The reality is the robots are not self-aware, they're not even using large language models right now,\" he said, \nreferring to the building blocks of generative AI tools like ChatGPT.\nChris Atkeson, a CMU robotics professor known for creating the inflatable technology that inspired Disney's \"Big \nHero 6\" movie, said Agility's recent success is part of a broader upswing in robotics development that is blossoming \nnationwide and in Pittsburgh.\nCMU ALUMS HAVE ROLE IN 'ROBOTIC SOLUTIONS' HUMANOID BOTS TESTED IN AMAZON \nWAREHOUSES\n\"There is a lot of work going on at CMU and at local companies, given that there is a big overlap between \ndeveloping brains for autonomous cars and for humanoids,\" he said, noting that Tesla loves to highlight the \nsynergy.\nThe university's work on humanoid bodies currently focuses on hands, skin, control and superhuman sensing, Mr. \nAtkeson said.\nAs for Agility's plans beyond Amazon, Mr. Shelton said they are launching a partnership program that will allow \nlarge manufacturing and logistics companies to purchase a Digit workforce.\nDown the road, Agility is considering an hourly subscription model to help small and midsize companies that are \ntypically more impacted by workforce shortages.\nEvan Robinson-Johnson: ejohnson@post-gazette.com or @sightsonwheels\nGraphic\n \nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed by Agility Robotics, a team \nled by Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently \nusing the bots in a testing capacity but sees \"a big opportunity to scale.\"\nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed Agility Robotics, a team led \nby Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently using \nthe bots in a testing capacity but sees \"a big opportunity to scale.\"\nPHOTO: Courtesy of Amazon: Amazon is testing a new walking humanoid developed Agility Robotics, a team led \nby Carnegie Mellon University alumni. Agility plans to make 10,000 Digit units each year. Amazon is currently using \nthe bots in a testing capacity but sees \"a big opportunity to scale.\"\nLoad-Date: October 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Investors Bail on Boeing Following Max 9 Grounding; DealBook Newsletter",
        "media": "The New York Times",
        "time": "January 8, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1824 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Investors Bail on Boeing Following Max 9 Grounding; DealBook Newsletter\nThe New York Times \nJanuary 8, 2024 Monday 07:50 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1824 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni &lt;p&gt;Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is \na co-anchor of CNBC&amp;#8217;s &#34;Squawk Box&#34; and the author of &amp;#8220;Too Big to \nFail.&amp;#8221; He is also a co-creator of the Showtime drama series &#34;Billions.&#34;&lt;/p&gt; &lt;p&gt;Ravi \nMattu is the managing editor of DealBook, based in London. He joined The New York Times in 2022 from the \nFinancial Times, where he held a number of senior roles in Hong Kong and London.&lt;/p&gt; &lt;p&gt;Bernhard \nWarner is a senior editor for DealBook, a newsletter from The Times, covering business trends, the economy and \nthe markets.&lt;/p&gt; &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on \nbusiness and how workplaces are changing.&lt;/p&gt; &lt;p&gt;Michael de la Merced joined The Times as a reporter \nin 2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry.&lt;/p&gt; &lt;p&gt;Lauren Hirsch joined The Times from CNBC in 2020, \ncovering deals and the biggest stories on Wall Street.&lt;/p&gt; &lt;p&gt;Ephrat Livni reports from Washington on \nthe intersection of business and policy for DealBook. Previously, she was a senior reporter at Quartz, covering law \nand politics, and has practiced law in the public and private sectors.&amp;#160;&amp;#160;&lt;/p&gt;\nHighlight: The jet maker’s share price fell sharply in premarket trading on Monday after hundreds of flights were \ncanceled and safety inspections resumed.\nBody\nThe jet maker’s share price fell sharply in premarket trading on Monday after hundreds of flights were canceled and \nsafety inspections resumed.  \nGrounded \nInvestors are bailing on Boeing and one of its biggest suppliers this morning after a harrowing malfunction at 16,000 \nfeet this weekend in which a door panel sheared off a new 737 Max 9 airliner in midflight.\nAir safety officials have ordered the grounding of the Max 9, one of Boeing’s best-selling models, and airlines \naround the world have canceled hundreds of flights as they await instructions from regulators in the U.S. and \nelsewhere.\nThe latest update: The N.T.S.B. said yesterday that the piece of fuselage that fell off the plane was found in a \nbackyard in Portland, Ore. \nShares in Boeing fell nearly 9 percent, and Spirit Aerosystems, which makes the Max 9’s door panel, or “plug,” sank \nin premarket trading. Stock in Boeing, a major defense contractor, had risen sharply since war broke out in October \nbetween Israel and Hamas. But its shares remain well below the levels they hit in early 2019 on huge buzz around \nthe fuel-efficient Max.\nThe latest mishap could deal a blow to Boeing’s turnaround plan, as well as its reputation. Nobody was injured \naboard Friday night’s Alaska Airlines flight. But it’s the latest in a series of safety lapses before and since two \ndeadly crashes involving Indonesia’s Lion Air and Ethiopian Airlines in 2018 and 2019. The crashes, of different \nInvestors Bail on Boeing Following Max 9 Grounding DealBook Newsletter\nversions of the Max, were linked to a malfunctioning computer system that overrode pilots’ commands. The planes \nwere grounded worldwide for nearly two years after the accidents.\nDeliveries of the 737 were delayed after Boeing found problems with the work Spirit did on the planes last year. \nBoeing’s wide-body Dreamliner was also held up while the company worked to address F.A.A. safety concerns. \n“The issue is what’s going on at Boeing,” John Goglia, an aviation safety consultant and airplane crash investigator, \ntold The Times.\nDavid Calhoun, Boeing’s C.E.O., hoped 2024 would be a comeback year. Instead, the company has canceled a \nleadership retreat, Bloomberg reported, and was working over the weekend with the F.A.A. to supply its airline \ncustomers with instructions on how to inspect their planes. Boeing is set to hold a companywide meeting tomorrow, \nat which Calhoun has said he will reinforce its focus on safety.\nQuestions are also swirling around Alaska Airlines. The company had halted flying that plane long distances over \nwater following concerns about a pressurization indicator.\nHERE’S WHAT’S HAPPENING \nCongressional leaders reach a government spending deal. The agreement caps top-line spending at roughly $1.66 \ntrillion, in line with President Biden’s deal last year with Kevin McCarthy, the former House speaker. But it’s unclear \nif there are enough votes to win over conservatives and avert a partial government shutdown in less than two \nweeks.\n“Oppenheimer” and “Succession” win big at the Golden Globe Awards. The film about the father of the atomic bomb \nwon five awards, making it the favorite for the Oscars, while “Succession” took top honors for a television series, \nwinning four. It’s too early to declare whether the award show’s broadcaster, CBS, or its organizers, Penske Media \nand the investor Todd Boehly, came out ahead.\nA commercial spacecraft heads for the moon. A Vulcan rocket blasted off this morning, bearing a robotic lander \n(and the remains of Gene Roddenberry, the “Star Trek” creator). The spacecraft, built by a joint venture between \nBoeing and Lockheed Martin, is the first of several launches planned this year, as an array of companies hope to \nerode SpaceX’s dominance of the space launch industry.\nA radio and podcast giant files for bankruptcy protection. Audacy, the U.S.’s biggest radio company, which owns \nWFAN Sports Radio and New York’s 1010 WINS, filed for Chapter 11 in Texas this weekend to cut its debt. The \ncompany has been hard hit by an advertising downturn.\nA widening conflict between Ackman and Business Insider \nBill Ackman’s fight against elite universities has broadened in unexpected ways: The parent company of Business \nInsider, the publication that last week accused his wife of plagiarism, said it was reviewing its journalists’ reporting \nin light of that coverage.\nAnd Ackman, who loudly called for the ouster of Claudine Gay as Harvard’s president, escalated his campaign \nagainst his wife’s alma mater, M.I.T. — including both its senior leaders and its faculty.\nThe media giant Axel Springer said it would examine Business Insider’s processes, after Ackman criticized articles \nthat said his wife, Neri Oxman, a former M.I.T. professor, plagiarized other scholars in her 2010 dissertation. While \nOxman apologized for any academic infractions and said she was requesting corrections, Ackman questioned the \nmotivations behind the coverage.\nThough Springer is known for taking a hands-off approach to its media holdings, which also include Politico and \nGermany’s Die Welt and Bild, the publisher said it wanted to “ensure that our standards as well as our journalistic \nvalues have been upheld.” (Semafor reported that some Springer executives worried that the coverage of Oxman, \nwho was born and raised in Israel, could be seen as antisemitic and anti-Zionist.)\nInvestors Bail on Boeing Following Max 9 Grounding DealBook Newsletter\nBusiness Insider defended itself. The outlet’s global editor in chief, Nicholas Carlson, wrote in an internal memo that \nhe stood by the publication’s coverage. It was motivated by “truth and accountability,” he said.\nMeanwhile, Ackman has called for examining M.I.T. faculty’s papers for plagiarism, using artificial intelligence tools \nto review their work. He also suggested that similar efforts should be undertaken at other universities and at \nBusiness Insider.\nThe demand continues his campaign against Sally Kornbluth, the M.I.T. president, who critics say has failed to \nsufficiently combat antisemitism on campus. (She also testified at the same Congressional hearing last month that \nhelped seal the fates of Gay and Liz Magill, the University of Pennsylvania’s now-former president.)\n• In other university news: Several schools have hired high-powered communications firms like SKDK, \nPrecision and FGS Global to advise them on navigating the antisemitism controversy.\nNew reports of Musk drug use raise questions about behavior\nElon Musk made waves in 2018 when he smoked marijuana during an interview on Joe Rogan’s podcast, with \nfootage of him holding a joint quickly becoming fodder for discussions about the billionaire’s behavior and internet \nmemes.\nMusk didn’t break any laws, since recreational marijuana in California, where the show was taped, is legal. But a \nWall Street Journal report accusing him of consuming other substances, including some that are illegal, has \nreignited debate about his behavior.\nDirectors of Tesla and SpaceX have discussed Musk’s actions, including the consumption of ketamine (for which he \nhas said he has a prescription), LSD and psychedelic mushrooms, according to The Journal. One Tesla board \nmember, Linda Johnson Rice, became so frustrated by the issue that she chose not to seek re-election in 2019, the \nreport added.\nWhy it matters, according to The Journal:\nIllegal drug use would likely be a violation of federal policies that could jeopardize SpaceX’s billions of dollars in \ngovernment contracts. Musk is intrinsic to the value of his companies, potentially putting at risk around $1 trillion in \nassets held by investors, tens of thousands of jobs and big parts of the U.S. space program. …\nIn addition to violating federal contracts, any kind of illegal drug use would break company policies at both SpaceX \nand Tesla, and would raise questions about Musk’s executive role at the publicly traded Tesla, where the board has \na duty to shareholders to oversee management.\nElon Musk rebutted the report, posting on his X social network that after he smoked on Rogan’s show, he agreed to \nthree years of random drug testing at NASA’s request. “Not even trace quantities were found of any drugs or \nalcohol,” he wrote.\nHe later added that the media “will stop at nothing to destroy X.”\nInvestors don’t seem bothered. Shares in Tesla were down only slightly in premarket trading.\n“It’s like having the best bows and arrows in the age of gunpowder.” \n— Mike Madrid, an anti-Trump Republican strategist, on Nikki Haley’s surge in fund-raising from deep-pocketed \nbackers. Supporters of the former South Carolina governor include the investor Stanley Druckenmiller and the \nmetals magnate Andy Sabin (and the Democratic tech entrepreneur Reid Hoffman), but Haley continues to trail \nDonald Trump in Republican primary polls by double digits.\nThe week ahead \nInvestors Bail on Boeing Following Max 9 Grounding DealBook Newsletter\nThere’s plenty on the calendar this week to keep Wall Street occupied, including earnings from JPMorgan Chase \nand the latest inflation report. Here’s what to watch.\nTomorrow: The grocery chain Albertsons reports third-quarter results.\nThursday: The December Consumer Price Index report is expected to show that headline inflation ticked up last \nmonth while “core” inflation, which excludes food and fuel, cooled slightly. A more favorable reading could make \nmarkets more volatile, as Wall Street has already begun to dial back expectations for a first-quarter Fed rate cut as \ninflation concerns continue.\nFast Retailing, the parent company of Uniqlo, reports quarterly earnings.\nFriday: It’s an earnings bonanza. On deck are Bank of America, Bank of New York Mellon, BlackRock, Delta Air \nLines, JPMorgan Chase, UnitedHealth Group and Wells Fargo.\nSaturday: Taiwan holds a pivotal presidential election, as Beijing increases pressure on the self-governing island to \nunify.\nTHE SPEED READ \nDeals\n• Berkshire Hathaway settled a lawsuit over the valuation of Pilot Travel Centers, the truck-stop chain that \nWarren Buffett’s conglomerate bought control of from the Haslam family. (CNBC)\n• The proposed $14.1 billion sale of U.S. Steel to Japan’s Nippon Steel is testing President Biden’s efforts to \nincrease domestic industrial production. (NYT)\n• “Wall Street Doubles Down on Bonds” (WSJ)\nArtificial intelligence\n• Nvidia retooled some of its A.I.-focused chips to comply with limits on Chinese exports, but tech giants there \nare ignoring those semiconductors. (WSJ)\n• Some generative A.I. services can now produce near-perfect replicas of trademarked characters with simple \nprompts like “videogame Italian.” (Business Insider)\nBest of the rest\n• Nearly 20 percent of U.S. office space sat vacant as of Dec. 31, a four-decade high. (WSJ)\n• How the oil mogul Howard Hamm is trying to change young people’s minds about the fossil-fuel industry. (FT)\n• Why Elon Musk is failing in his effort to get MrBeast, the superstar YouTube creator, to produce content for his \nX social network. (WSJ)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Part of a Boeing 737 Max 9 operated by Alaska Airlines fell off in midair. (PHOTOGRAPH BY Craig \nMitchelldyer/Associated Press FOR THE NEW YORK TIMES)\nLoad-Date: January 8, 2024"
    },
    {
        "file_name": "The_Economic_Times_Feb2024",
        "header": "Accenture spots about 10% revenue upswing via GenAI",
        "media": "The Economic Times",
        "time": "February 26, 2024",
        "section": "ITES",
        "length": "647 words",
        "byline": "Beena Parmar and Surabhi Agarwal",
        "story_text": "Accenture spots about 10% revenue upswing via GenAI\nThe Economic Times\nFebruary 26, 2024 Monday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 647 words\nByline: Beena Parmar and Surabhi Agarwal\nBody\nAccenture has started to see a potential revenue upswing of about 10% with the use of generative artificial \nintelligence (GenAI) in some important business units, a top executive of the American technology services \ncompany told ET.Its clients across key sectors, which include banking and insurance, consumer goods, retail and \nsoftware and platforms, are beginning to see potential increase in revenues through their integration with GenAI, \nSenthil Ramani, global lead – data and AI at Accenture, said in an exclusive interview.“Early results from the \ninsurance industry indicate a revenue increase of up to 10% is possible, if companies reinvent the entire workflow of \nunderwriting,” Ramani said.Based on learnings from 700 client projects, companies that build a strong foundation of \nAI by adopting and scaling it now will be better positioned to reinvent, compete and achieve new levels of \nperformance, he said.Also read | Accenture opens genAI studio in BengaluruThe professional services giant is also \nseeing promise with highest demand in the consumer industry with the hyper personalisation that is helping \n“change context to relevance in terms of net revenue”.Life sciences and software and platforms, too, stand to \nbenefit from GenAI.“The velocity with which this tech is moving, it’s so fast that it’s yet to be completely proven in \nsome like the clinical and drug discovery process,” Ramani said. “But there is a lot of promise and hope… Even a \nsix-month acceleration of AI and GenAI into that will mean a lot from a revenue perspective.”The overall impact \nheavily varies across the 19 industries tracked by the company, he said.Accenture, which has committed an \ninvestment of $3 billion in AI, has already signed a total of $450 million worth of GenAI deals in the first quarter of \nFY24 ended November. \nThis is a 50% pump up in the pipeline from $300 million in the last six months of FY23.Also read | Eye on GenAI, \nIndian IT companies seek opportunities to build and expandAccording to Ramani, GenAI has been a catalyst in \ndriving a lot of this in businesses.The economics of GenAI, he said, is going to get normalised because it will start \nto become consumer tech from being engineer tech.“Engineer tech is when it actually is expensive and you’ve got \nto spend on it. But consumer tech is when you and I can use it on our phones... And that’s definitely starting to \nhappen,” he said.In a bid to become an AI-first company, Accenture has also doubled its headcount in data and AI \nto 40,000 globally.“So far, we have trained 600,000 employees globally on the fundamentals of AI. This year, we \nwill train 250,000 of our people globally on the fundamentals of generative AI. We have already mapped over \n30,000 people globally to new and emerging roles in data and AI,” Ramani said.Over 20,000 of these people are in \nIndia and the country will play a significant role in Accenture’s journey towards becoming a AI first company, he \nadded.The company has made six acquisitions in the data and AI space in financial year 2023 and in financial year \n2024 so far.Accenture is tracking over 1,020 foundational models in the GenAI space today and Ramani suggests \nthat organisations must focus on their core competencies to drive those up the value chain.Speaking of AI models \nand partnerships to use AI, he said, “Some cases will just need prompting, some cases will need fine-tuning. In \nsome cases, you can even do something called pre-training to effectively train the model.”Ramani said the learning \ncomponent is going to be important.“This is an alarming statistic that less than 5% of organisations globally are \nspending on reskilling of people and educating them on GenAI, so 95% of people in organisations need to do that \nAccenture spots about 10% revenue upswing via GenAI\nfar more… The best learned folks are going to be the fastest on this because the technology is moving so fast,” he \nsaid. For Reprint Rights: timescontent.com\nLoad-Date: February 26, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "GPUs to Keep India in Sync Globally on AI Front: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 8, 2024",
        "section": "FRONT PAGE",
        "length": "393 words",
        "byline": "Annapurna Roy & Suraksha P",
        "story_text": "GPUs to Keep India in Sync Globally on AI Front: Experts\nEconomic Times (E-Paper Edition)\nMarch 9, 2024 Saturday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 393 words\nByline: Annapurna Roy & Suraksha P\nHighlight: Access to compute infra under AI Mission will help startups make in India and for the world, say tech \ninvestors\nBody\n‘GOOD STARTING POINT’ TO BOOST INNOVATION\nNew Delhi | Bengaluru: India’s ambitious plan to enable access to 10,000 graphic processing units (GPUs) that are \ndeemed essential for the creation of any artificial intelligence-based applications and models is a “good starting \npoint” as it strives to stay apace with global leaders in the rapidly evolving area of AI innovation, top investors and \ntechnologists said. The Rs 10,372 crore Artificial Intelligence (AI) Mission, announced on Thursday, will operate on \na public-private partnership model. It will extend GPUs as a digital public infrastructure that can offer AI-as-a-\nservice. \nThis will provide Indian companies with their own compute hardware — a scarce resource globally — allowing them \nto create more AI applications and arming the country to compete better with the likes of the US, China and the UK \nwhich are ahead in the race to dominate the sunrise sector. “The government’s AI mission is incredibly exciting for \nIndia and  its vibrant startup ecosystem. Investing in 10,000 GPUs and making them available to researchers and \ninnovators will make a huge difference as we aim to build (India) the AI application capital of the world,” Rajan \nAnandan, managing director, PeakXV Partners, told ET adding that it will provide critical building blocks that AI \nstartups can leverage to “build in India, for India and for the world”. In addition to IndiaAI Innovation Centre for the \ndevelopment and deployment of indigenous Large Multimodal Models and domain-specific foundational models in \ncritical sectors, the mission will also provide access to targeted funding for AI startups. India now has over 100 \ngenerative AI startups, however, the investment into the space has been comparatively small. The US saw nearly \n$250 billion private investments into AI startups between 2013 and 2022, while investments in India stood at just $8 \nbillion. Over the same period, China saw $95 billion of investments while for the UK, the number stood at $18 \nbillion, as per data from the AI Index 2023 Annual Report. Last year, Indian conglomerates such as the Tata Group \nand Reliance Industries announced partnerships with top GPU maker Nvidia to obtain compute to build their own \nAI. However, startups facing resource constraints have been petitioning the government to invest into compute to \nensure they also get access.\nLoad-Date: March 8, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Feb2023",
        "header": "HOW CHATGPT WILL BECOME USEFUL",
        "media": "Wall Street Journal Abstracts",
        "time": "February 28, 2023",
        "section": "A; Pg. 15",
        "length": "29 words",
        "byline": "ANDY KESSLER",
        "story_text": "HOW CHATGPT WILL BECOME USEFUL\nWall Street Journal Abstracts\nFebruary 27, 2023 Monday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 15\nLength: 29 words\nByline: ANDY KESSLER\nBody\nABSTRACT\nAndy Kessler Inside View column contends kinks will be worked out of generative artificial intelligence systems \nsuch as ChatGPT and it will find its uses in range of areas\nLoad-Date: February 28, 2023"
    },
    {
        "file_name": "NOTICE;_VOTE_SET_FOR_THURSDAY_ON_WHAT_ACTION_TO_TAKE_Oct2023",
        "header": "ALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT",
        "media": "NOTICE; VOTE SET FOR THURSDAY ON WHAT ACTION TO TAKE",
        "time": "October 31, 2023",
        "section": "BUSINESS; Pg. A-12",
        "length": "743 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "ALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT \nNOTICE; VOTE SET FOR THURSDAY ON WHAT ACTION TO TAKE\nPittsburgh Post-Gazette\nOctober 31, 2023 Tuesday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: BUSINESS; Pg. A-12\nLength: 743 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nUnionized Allegheny General Hospital nurses are scheduled to vote Thursday on whether to continue negotiating \nfor a new labor agreement or issue a 10-day notice of a walkout.\nThe vote turns up the heat on contract talks for some 1,200 registered nurses who are members of SEIU \nHealthcare Pennsylvania. A three-year contract for the nurses expired Oct. 13 and the nurses on Oct. 18 authorized \ntheir bargaining committee to call a strike as talks continued.\nA strike would be a first at the Allegheny Health Network hospital, the flagship institution in a 14-hospital system. \nThe vote will follow multiple labor rallies in Pittsburgh since June that have drawn wide support from Democratic \nelected officials, from Mayor Ed Gainey to members of the state General Assembly. Whether the union can turn that \nsupport into contract gains - which include a demand for a 31% increase in the starting wage for new nurses to $40 \nan hour - is yet to be seen.\nThe challenge for AHN corporate parent Highmark Inc. will be to restrain rising costs at a time of flat reimbursement \nfrom government and other health insurers, while attracting and retaining talent when there are not enough nurses \nin the job market to fill openings. Virtually every hospital in the U.S., including those in AHN, has had to use high-\ncost temporary staffing nurses to fill shifts.\nSEIU officials were not available for comment Monday; AHN spokesman Dan Laurent said only that talks were \ncontinuing.\nInformation about the bargaining was provided by two people familiar with the negotiations but who were not \nauthorized to discuss them publicly.\nThe labor tensions are rising at Allegheny General even as the hospital makes plans to lighten the administrative \nworkload of nurses and doctors.\nFor AGH nurses, entering medical information into the hospital's electronic health record systems eats up fully half \nof the workday, according to an internal time study, and that leads to frustration and job discontent, said Ashis \nBarad, AHN chief digital officer.\n\"Why do we have our nursing staff doing data entry?\" Dr. Barad said. \"There is a world where we give back almost \n50% of their time.\"\nALLEGHENY GENERAL HOSPITAL NURSES WEIGH A 10-DAY WALKOUT NOTICE VOTE SET FOR \nTHURSDAY ON WHAT ACTION TO TAKE\nIn recent weeks, enhancements to the hospital's Epic Systems medical recordkeeping system have made it faster \nfor nurses to enter information by automatically populating fields for the regular patient assessments that nurses \nperform.\nAnd in January, AHN Forbes Hospital in Monroeville will begin piloting a 47-bed telehealth feature that will allow a \nnurse in Allegheny Center to greet newly admitted patients and give discharge instructions to patients who are \ngoing home, allowing hospital nurses to increase their time caring for patients.\nWithin two years, the digital nurse will be rolled out to every AHN hospital.\n\"You want to be able to focus directly on your patients and not be taken away for administrative tasks,\" said Rachel \nUrosek, a registered nurse for 10 years and director of clinical information and digital health at AHN. \"Nurses want \nto spend time with their patients and do what's best for their patients.\"\nFor doctors, the administrative burden is not much lighter than for nurses: For every hour doctors spend with a \npatient, they spend another two hours with documentation, according to the American Medical Association's \npresident, Jesse M. Ehrenfeld.\n\"There is an insidious crisis going on in medicine today that is having a profound impact on our ability to care for \npatients and yet isn't receiving the attention it deserves,\" Dr. Ehrenfeld said during a speech Wednesday in \nWashington, D.C. \"This crisis is physician burnout.\"\nReducing the chore of medical documentation is among the top priorities for Highmark's new Google software \nplatform, which is called Vertex Search AI, according to Richard Clark, chief analytics officer at Highmark.\nAmong potential uses of the generative artificial intelligence platform in the doctor's office is ambient listening, \nwhich would provide input on treatment decisions based on massive searches of medical records and health \ninformation - in real time.\nGenerative AI in medicine, which is being tested at AHN, has been compared to the advent of penicillin, but much \nwork needs to be done before it's routinely used in clinical practice, ensuring that AI answers are sound, Dr. Barad \nsaid.\n\"Oh my god, this is huge, I want to go fast. But we have to do it responsibly,\" he said. \"The art of what's possible is \nway further ahead of how do we do this responsibly.\"\nGraphic\n \nPHOTO: Tim Robbibaro/For the Post-Gazette: Unionized nurses at Allegheny General Hospital on the North Side \nare set to vote Thursday on whether to issue a walkout notice or continue to negotiate in an effort to reach a new \nlabor agreement.\nPHOTO: Sebastian Foltz/Post-Gazette: Allegheny Health Network physical therapist Lauren Wilkerson updates a \npatient file at West Penn Hospital in Bloomfield.\nLoad-Date: October 31, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I.'s Existential Threat",
        "media": "The New York Times",
        "time": "June 6, 2023",
        "section": "Section A; Column 0; Editorial Desk; Pg. 23; LETTERS",
        "length": "130 words",
        "byline": " ",
        "story_text": "A.I.'s Existential Threat\nThe New York Times\nJune 6, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Editorial Desk; Pg. 23; LETTERS\nLength: 130 words\nBody\nSummary summary summary\nTo the Editor: \n  Re ''A.I. Poses 'Risk of Extinction,' Tech Leaders Warn'' (front page, May 31):\n  The more than 350 leaders in artificial intelligence aren't the only people scared to death by this fast-evolving \ntechnology.\n  Two-thirds of American adults believe that generative A.I. poses a threat to humanity, according to a national poll \nwe conducted. Additionally, more than four in five agree that it would be simple for someone to abuse the \ntechnology to do harm. A majority also believes that regulation is warranted.\n  Business is clearly enamored by A.I.'s power, but across all income and education levels, society worries that this \nnew marvel may be the atomic bomb of the 21st century.\n  Will JohnsonChicagoThe writer is the C.E.O. of the Harris Poll.\nhttps://www.nytimes.com/2023/06/05/opinion/letters/ais-existential-threat.html\nGraphic\n \nThis article appeared in print on page A23.               \nLoad-Date: June 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jul2023",
        "header": "GOOGLE’S AI CHATBOT AIMS TO GO GLOBAL",
        "media": "Wall Street Journal Abstracts",
        "time": "July 15, 2023",
        "section": "B; Pg. 4",
        "length": "34 words",
        "byline": "SAM SCHECHNER, MILES KRUPPA",
        "story_text": "GOOGLE’S AI CHATBOT AIMS TO GO GLOBAL\nWall Street Journal Abstracts\nJuly 14, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 34 words\nByline: SAM SCHECHNER, MILES KRUPPA\nBody\nABSTRACT\nGoogle’s ChatGPT rival Bard has rolled out new version of its chatbot in 43 languages, part of its effort to keep up \nin high-stakes race to commercialize generative artificial intelligence; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: July 15, 2023"
    },
    {
        "file_name": "The_Economic_Times_Oct2023",
        "header": "India fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora",
        "media": "The Economic Times",
        "time": "October 30, 2023",
        "section": "TECH & INTERNET",
        "length": "1151 words",
        "byline": "Dia Rekhi and Surabhi Agarwal",
        "story_text": "India fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora\nThe Economic Times\nOctober 30, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1151 words\nByline: Dia Rekhi and Surabhi Agarwal\nBody\nAmid the widespread weakness in technology stocks worldwide, American cybersecurity provider Palo Alto \nNetworks has emerged as a dark horse with its stock rallying 72%, so far, this year, and 288% in the last five years-\nwowing Wall Street-as it broke into the S & P 500 Index in June 2023. Chief executive officer Nikesh Arora who has \nled the transformation of the firewall-focused network security vendor into today’s diversified cybersecurity provider \nsays that in the last five to seven years, cyber-attacks have gone from being a hobby to a profession, this is \ntriggering sustained demand for cyber-security products globally. The Santa Clara-based company, which reported \nrevenues of $6.9 billion in FY 2023 aims to close FY 24 with revenues of around $8.20 billion. In a virtual interview \nwith ET, the 55-year old Arora said that India, apart from being a huge talent hub, is also emerging as a large \nmarket for technology services. Edited Excerpts:Palo Alto has managed to outgrow the market at a time when there \nis a widespread slump in demand for technology services, how is it bucking the trend ?The macro industry trends \nfor cybersecurity have been more favourable than other sub-sectors of technology. \nThere is also the geopolitical situation. Our growth is also differentiated by the fact that five years ago we were one \nof six or eight companies of our size. Today, we're the largest cybersecurity company, we've outstripped our \ncompetitors. When I joined (in 2018) we identified cloud and AI as the overarching new technology trend for the \ncoming decade. So, we designed our portfolio, bought 15 companies, spent $4 billion. We pivoted our whole \nbusiness to be at the bleeding edge of innovation in cybersecurity. That was unique in cybersecurity, most \ncompanies would capture the trend of the moment, figure the business and then as the trend shifted, a new \ncybersecurity company was born. Historically, the stalwarts of cybersecurity have been companies like McAfee or \nSymantec or Juniper who have given way to others as trends changed. Palo Alto’s success is a combination of both \na strong long-term secular trend in favour of cybersecurity but also some of the strategic choices we made as a \ncompany. How significant is India to Palo Alto’s global operations? In the last five years, India has been the fastest \ngrowing office of Palo Alto. We have a large presence in Europe, a large R&D presence in Israel because of the \nroots of our company. For some reason, there's a lot of cybersecurity companies born in Israel and many also have \na strong R&D presence in India. So, that ended up actually being our initial footprint in India.It is now one of our \nlargest growth markets and I see no reason for that to stop because it has a highly qualified talent pool. We've seen \na huge explosion of talent and honestly it's not just the economic imperative, it is the talent imperative. We need \naccess to large pools of talent - people who are well trained who understand technology. In addition, in the last ten \nyears India has also become a large technology market internally. The explosion in unicorns, the explosion in \ntechnology applications for the local market, have driven the need for technology and for cybersecurity. So it's not \njust a R&D market for us, it's also an important focus market. The relevance of India will continue to grow as it goes \nthrough its technological adoption curve. The innovation we've seen in UPI, which is (unique) in the world, look at \nwhat (Reliance) Jio was able to do in terms of democratising bandwidth. India is going to continue to grow in \nprominence as a cybersecurity market and we're delighted.What are the factors driving growth for the cybersecurity \nat large? In our industry parlance, we call it the attack surface, which is the different places you can get attacked. \nSo, the attack surface continues to amplify, given the connectedness of everything. Cars are connected so I can \nIndia fastest-growing office for Palo Alto in last five years: CEO Nikesh Arora\nattack your car. Mobile phones are connected so I can attack your mobile phone. Your mobile phone is used for \naccessing your bank accounts, used for paying your electricity bill or applying for a driver's license. Every one of \nthose tasks can now be intercepted and attacked. The attack surface is growing exponentially, which has been a \ndirect driver of demand for cybersecurity. This is going to be a growth business for a long time.Which sectors are \nparticularly vulnerable from a cyber-risk perspective?Some sectors are more sensitive. For example, almost every \ncountry and government system are ( at risk) in the case of geopolitical tension. (Attackers) want to get into their \ndefense and military systems. Financial services are always a big target. During the Covid-19 pandemic, there were \na lot of attacks on medical companies trying to figure out how to get the IP that is associated with the vaccine or \nhow to figure out supplies. Generally, where medical systems are involved, you want to have protection because \nyou don't want a cyber-attack when a sophisticated piece of medical machinery is being used to save lives. Every \nsector has its share of cyber concerns. With Generative AI, how do you see the cybersecurity landscape \nchanging? Any contingency measures that you've put in place? We've tried to use our LLM for Generative AI to \nsee if it can generate malware or can generate attacks. And we've discovered that with a little bit of engineering, we \ncan actually get LLMs to start generating malware. This is early days, but we've seen their malware is mostly sort of \na clone of what we've seen in the past because its uses a generative model. But when we combine generative AI \nwith reinforcement learning, you can start to iterate a model where you can start breaking through defences. So we \nhave a Generative AI Lab, we're generating malware, generating attacks, to see how generative AI produces \nattacks so we can try and build antidotes. So it's going to be a continued arms race, both between the bad guys and \nthe good guys to try and see how to nullify the impact of AI.At a time when companies are looking at operational \nefficiency and cutting costs, is it hard to convince them to invest in cybersecurity? It used to be the case where it \nwas hard in the past. But the global activity we're seeing from a cyber risk perspective has put the onus on boards \nto ensure their companies are digitally secured. Very rarely do we see cyber budgets being cut. It's a hard product \nto sell but I don't really feel that in the current decade, we are seeing an awareness problem or a problem around \nthe need for it. Most recently with the current global macroeconomic conditions, the interest rates have gone up. \nPeople are even more cautious in terms of how much budget they have across the board. But I don't think \ncybersecurity is disproportionately impacted in fact I think it is disproportionately protected.  For Reprint Rights: \ntimescontent.com\nLoad-Date: October 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Our 2023-24 Student Contest Calendar; Contests",
        "media": "The New York Times",
        "time": "May 2, 2024",
        "section": "LEARNING",
        "length": "2112 words",
        "byline": "The Learning Network",
        "story_text": "Our 2023-24 Student Contest Calendar; Contests\nThe New York Times \nJuly 13, 2023 Thursday 08:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 2112 words\nByline: The Learning Network\nHighlight: Here are 10 challenges to help us celebrate our 25th anniversary — including one open to both teachers \nand teenagers.\nBody\nHere are 10 challenges to help us celebrate our 25th anniversary — including one open to both teachers and \nteenagers.\nOur annual Contest Calendar is probably the single most powerful thing we publish all year. Teachers tell us they \nplan their classes around our challenges, and tens of thousands of teenagers across the globe participate by \ncreating narratives, profiles, opinion pieces and reviews, podcasts, videos, illustrations and photo essays. \nFor us, these contests are an honor and a joy to host. We love learning from young people — about what moves \nthem and makes them mad, what intrigues and confuses and delights and defines them.\nEvery summer, we tinker with our offerings to keep them fresh, and we’ve made some significant changes this time \naround.\nTo start, in August, The Learning Network will celebrate its 25th anniversary, and we’re marking it by running our \nfirst-ever challenge that is open to our full audience, both teachers and teenagers. We hope together you’ll help us \ntell a rich story about what it’s like to be in high school in 2023.\nLike educators all over, we’ve been spurred by the advent of generative artificial intelligence to make creative \ntweaks to our offerings. This year, we’re putting more emphasis on the parts of the composing process that are, \nwell, human. A glance at the 10 descriptions below might show you that elements like voice, point of view, \nreflection, making connections and building community are more central than ever. We’ve invented new contests \nand updated old ones, and we’ll be emphasizing process as well as product throughout. We also have a full writing \ncurriculum to help support this work. \nIf you need a little encouragement to participate, we recommend two pieces. Students might start with “‘I Was \nEnough’: How I Stopped Trying to Sound Smart and Found My Genuine Writing Voice,” by a teenager who reflects \non how our competitions helped her grow. If you are a teacher, our reader-submitted 10 Reasons to Send Student \nWork Out Into the World might be compelling — especially, perhaps, reason number 10.\nTo download a PDF version of this contest calendar, click here. Questions? Scroll to the bottom of this post to learn \nmore, write to us at LNFeedback@nytimes.com or post a comment here. \nWhat High School Is Like in 2023: A Multimedia Challenge for Teachers and Teens\nWhat can you show or tell us that might help explain what it’s like to be an educator or a student in a secondary \nschool right now?\nOur 2023-24 Student Contest Calendar Contests\nWe’re inviting you to contribute to a collective portrait of what it means to be in high school today, told by those \nliving it.\nAll who work in any capacity in a secondary school, or are students over 13 in one, are invited to document, reflect \nand express themselves on any aspect, big or small, of their experience there. We want to know what’s hard, but \nwe also want to know where and how you find meaning and joy.\nAs with our original Coming of Age contest — the blueprint for this effort — you can submit writing or images, audio \nor video. You can send us artifacts, such as photos from your camera roll, or create something new. And you can \nwork alone or in a group, with others your age or across ages, roles and even schools. Each submission must be \naccompanied by a short artist’s statement.\nHere are the contest rules and submission form, and here are 15 questions and a step-by-step guide that can help \nyou brainstorm ideas. \nUpdate, Jan. 4: Winners have been announced!\nMy Tiny Memoir: Our 100-Word Personal Narrative Contest\nCan you tell a meaningful and interesting true story from your life in just 100 words? That’s the challenge we posed \nto teenagers last fall with our 100-Word Personal Narrative Contest, a storytelling form popularized by Modern \nLove’s Tiny Love Stories. The answer, we discovered, was a resounding yes, so we’re bringing it back for Year 2.\nHere are this year’s rules and guidelines. For more inspiration, read the work of last year’s winners, or follow this \nstep-by-step guide for participating. \nUpdate, Jan. 17: Winners have been announced!\nTeenagers as Critics: Our Review Contest\nReview a book, movie, restaurant, album, theatrical production, video game, dance, TV show or art exhibition, with \nadvice from New York Times critics to help.\nThis year’s rules and guidelines follow last year’s with one big change: Anything you choose to review must have \ndebuted this year. (That means not that you watched a movie, read a book or heard an album for the first time this \nyear, but that the work premiered in 2023.)\nTo see how it’s done, take a look at the work of last year’s winners and visit our related step-by-step guide for \nwriting a review. \nUpdate Feb. 8: Winners have been announced!\nThinking Made Visible: Our One-Pager Challenge\nWe’re once again ending the fall semester with an invitation that we hope is accessible and fun for students across \nthe curriculum: Make a one-pager in response to any article, video, graph, photo essay or podcast published in The \nNew York Times in 2023 (or early 2024).\nHere are the rules and guidelines. Let our step-by-step guide walk you through the process, and the work of these \nwinners inspire you. \nTo help you find content you will enjoy, we have also curated a collection of free links to over 75 pieces about \nyoung people published across sections of NYTimes.com this fall.\nUpdate, March 7: Winners have been announced!\nHow to … : An Informational Writing Contest\nOur 2023-24 Student Contest Calendar Contests\nFollowing the example of the long-running Tip column from The New York Times Magazine, write a short \ndescription of how to do (almost) any task in 400 words or fewer.\nAs long as your topic is appropriate for a family newspaper, you can explain whatever you like, including tasks that \nTip has already taken on. But you must find, interview and quote one expert on the subject throughout your piece.\nHere are the rules and guidelines. Our step-by-step guide will walk you through the process, and our writing prompt \ncan help you come up with an original topic.\nUpdate, April 2: Winners have been announced!\nWhere We Are: Photo Essays About Community\nInspired by the immersive New York Times series Where We Are, which focuses on young people and the spaces \nwhere they create community, we invite students to work alone or with others to make photo essays about the \ncommunities that interest them.\nYou can document any kind of offline community you like and feature people of any age. Then tell us about it by \nsending six to eight images with captions and a short introduction. \nHere are the rules and guidelines. Our step-by-step guide will walk you through the process, and our writing prompt \ncan help you come up with an original topic.\nPlaying With Words: Our Vocabulary Video Contest\nProduce a 15-second video about the meaning of one of our recent Words of the Day.\nHere are the rules and guidelines, which are the same as last year’s except for one detail: You can work only with \nwords published in our W.O.T.D. column between June 1, 2023, and Feb. 28, 2024.\nFor inspiration, take a look at the work of past winners.\nOpen Letters: Our New Opinion Writing Contest\nOur Student Editorial Contest ran for a decade, and we received truly extraordinary work, but it’s time for a refresh. \nThis year, we’re asking you to draw on the same skills and passions to make your case, but this time in the form of \nan open letter.\nAn open letter is a published letter of protest or appeal usually addressed to an individual, group or institution but \nintended for the general public. Think of the many “Dear Taylor Swift” open letters you can find online and on social \nmedia: Sure, they’re addressed to Ms. Swift, but they’re really a way for the writer to share opinions and feelings on \nfeminism, or ticket sales, or the music industry, or … the list goes on.\nAs you might already know if you’ve read Martin Luther King’s famous Letter From Birmingham Jail, an open letter \nis a literary device. Though it seems on the surface to be intended for just one individual or group, and therefore \nusually reads like a personal letter (and can make readers feel they are somehow “listening in” on private thoughts), \nit is really a persuasive essay addressed to the public. This recent letter signed by over 1,000 tech leaders about \nthe dangers of A.I., this funny 2020 letter addressed to Harry and Meghan, and this video letter from young Asian-\nAmericans to their families about Black Lives Matter are all examples of the tradition.\nNow we’re inviting you to try it yourself. Write your own open letter, in 460 words or fewer, to anyone you like on \nany issue you care about, as long as it is also appropriate and meaningful for a general Times audience.\nHere are the rules and guidelines, as well as a step-by-step guide and a related writing prompt to help you get \nstarted.\nLive! Audio Stories: Our Podcast Contest\nOur 2023-24 Student Contest Calendar Contests\nMake an original podcast of five minutes or less that informs or entertains listeners.\nHere are this year’s rules and guidelines. For inspiration, listen to the work of past winners and visit the related \nwriting unit.\nUpdated! Voice and Choice: Our Summer Reading Contest\nUpdated, April 18: As we have for 14 years now, we’ll be asking you to tell us what got your attention in The Times \nand why. But this year, each week students can enter as they always have by submitting a short written response \n— or they can make a video up to 90 seconds long.\nHere are this year’s rules and guidelines. For inspiration, listen to the work of past winners and visit the related \nwriting unit.\nOur Conversation Challenge for Weekly Current Events\nWe invite students to react to the news via our daily writing prompts, and each week, we publish a selection of their \ncomments in a roundup for the world to read. We will also give a shout-out to new schools that join the \nconversation.\nA Few More Details About Our Contests\nWhy do we run so many contests? We believe in student voice. We want young people to be active content \ncreators, not just consumers. And we’re proud to offer places where they can create for an authentic audience of \nstudents, teachers, parents and other readers from around the world.\nHere are more details:\n• The work students send us is always considered by our staff and other experts, including Times journalists, as \nwell as educators from partner organizations or professional practitioners in a related field. Judging for our \ncontests is blind. That means we see only the entries themselves, not student names or schools, when we \nmake our decisions.\n• Winners get their work published on The Learning Network. Some may also be featured in a special section of \nthe print New York Times.\n• Anyone who submits to our contests retains the copyright for the work, even after we publish it.\n• About two months after each contest closes, we’ll announce the winners, runners-up and honorable mentions. \nWe usually celebrate dozens of students each time.\n• On the day each contest begins, we will add a link here, on this page, to the contest announcement so \nstudents and teachers can submit entries. All contests except Summer Reading begin and end on \nWednesdays.\n• Students can enter as many contests as they want, but they can submit only one entry per contest. Our \nSummer Reading Contest, however, offers a fresh opportunity to submit each week for 10 weeks.\n• Students’ entries must be original and fundamentally their own. An entry must not be published elsewhere at \nthe time of submission, including in a school newspaper, on a radio station’s website or in a literary \nmagazine.\n• All of our contests are open to students around the world ages 13 to 19 who are in middle school or high \nschool, except “What High School is Like in 2023,” which is open only to secondary students. College \nstudents cannot submit entries. However, high school students (including high school postgraduate \nstudents) who are taking one or more college classes can participate. Students attending their first year of \na two-year CEGEP in Quebec can also participate. In addition, students ages 19 or under who have \ncompleted high school but are taking a gap year or are otherwise not enrolled in college can participate. \nOur 2023-24 Student Contest Calendar Contests\nNote: The children and stepchildren of New York Times employees are not eligible to enter these contests, \nnor are students who live in the same household as those employees.\nWant to make sure you never miss a contest announcement? Sign up for our free weekly newsletter, or follow us on \nTwitter and Facebook.\nWe can’t wait to see what you’ll create this year!\nPHOTO: Winners from our Coming of Age in 2022 Contest. We’ll be running a new version of this challenge, open \nto both teachers and teenagers, in the fall. (PHOTOGRAPH BY From left to right, Shashank Salgam, Allyson Kim \nand Gigi Greene FOR THE NEW YORK TIMES)\nLoad-Date: May 2, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "The A.I. Election, Bitcoin’s Wall Street Debut and TikTok’s Doodad Era",
        "media": "The New York Times",
        "time": "April 16, 2024",
        "section": "PODCASTS",
        "length": "260 words",
        "byline": "Kevin Roose, Casey Newton, David Yaffe-Bellany, Davis Land, Rachel Cohn, Jen Poyant, Alyssa Moxley,",
        "story_text": "The A.I. Election, Bitcoin’s Wall Street Debut and TikTok’s Doodad Era\nThe New York Times \nJanuary 19, 2024 Friday 09:10 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 260 words\nByline: Kevin Roose, Casey Newton, David Yaffe-Bellany, Davis Land, Rachel Cohn, Jen Poyant, Alyssa Moxley, \nElisheba Ittoop, Marion Lozano, Rowan Niemisto and Dan Powell Kevin Roose is a Times technology columnist \nand a host of the podcast \"Hard Fork.\" David Yaffe-Bellany writes about the crypto industry from San Francisco. He \ncan be reached at , davidyb@nytimes.com\nHighlight: “Two truly terrible ways to make money this week.”\nBody\nListen and follow ‘Hard Fork’\nApple | Spotify | Amazon | YouTube\nOpenAI has released its plan to fight disinformation in elections in 2024, but will its policies be consequential \ncompared to those of other generative A.I. companies? Then, a watershed moment had crypto fans celebrating for \nthe first time in maybe more than a year. And finally, what one writer’s attempt to sell a used mechanical pencil on \nTikTok says about how the platform is changing.\nToday’s guests:\n• David Yaffe-Bellany covers the crypto industry for The New York Times\n• John Herrman covers technology for New York Magazine\nAdditional Reading:\n• How OpenAI is approaching 2024 worldwide elections\n• $4 Billion of New Bitcoin Funds Change Hands in First Trading Day\n• What I Learned Selling a Used Pencil on TikTok Shop\nCredits\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land and Rachel Cohn. The \nshow is edited by Jen Poyant. Engineering by Alyssa Moxley and original music by Dan Powell, Elisheba Ittoop, \nMarion Lozano, Sophia Lanman and Rowan Niemisto Fact-checking by Caitlin Love.\nSpecial thanks to Paula Szuchman, Pui-Wing Tam, Nell Gallogly, Kate LoPresti and Jeffrey Miranda.\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land and Rachel Cohn. The \nshow is edited by Jen Poyant. Engineering by Alyssa Moxley and original music by Dan Powell, Elisheba Ittoop, \nMarion Lozano, Sophia Lanman and Rowan Niemisto Fact-checking by Caitlin Love. Special thanks to Paula \nSzuchman, Pui-Wing Tam, Nell Gallogly, Kate LoPresti and Jeffrey Miranda. \nLoad-Date: April 16, 2024\nThe A.I. Election, Bitcoin’s Wall Street Debut and TikTok’s Doodad Era"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "Talent AI-volution: Can AI adoption dent India's tech edge?",
        "media": "The Economic Times",
        "time": "April 21, 2024",
        "section": "TECH & INTERNET",
        "length": "1830 words",
        "byline": "Annapurna Roy and Beena Parmar",
        "story_text": "Talent AI-volution: Can AI adoption dent India's tech edge?\nThe Economic Times\nApril 21, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1830 words\nByline: Annapurna Roy and Beena Parmar\nBody\nIndia is known as the world’s tech backbone. Not without reason. The $250-billion Indian software services industry, \naside from the mammoth GCC industry, caters to the biggest global companies of the world. The sheer breadth and \ndepth of talent burnishes India’s allure — and makes it the automatic destination for solving complex service \nindustry problems.However, recent advances in generative AI are raising doubts about whether India will continue \nto have its edge given the inevitability of automation that AI will spawn.The market size of generative AI in \ncustomer services sector was valued at $308.4 million in 2022 and is expected to cross $2,897.57 million by 2032, \ngrowing at a CAGR of 25.11% over this period, according to Precedence Research.To slash costs, most \norganisations in India are looking at cutting their marketing and customer experience budgets, as per a 2023 Adobe \nstudy. About 42% have already done so, and 37% will in the next 12 months, it said.In fact, 59% of brands are \ninstead seeking to drive efficiencies in these areas by deploying gen AI.In February, Jensen Huang, CEO of AI chip \nmaking giant Nvidia, said that with the arrival of AI, the future of coding as a career is dead. \nIn a January blog, Kristalina Georgieva, MD, IMF, wrote that AI will affect almost 40% of jobs around the world, \nreplacing some and complementing others. “It doesn’t take a rocket scientist to conclude that a million of the seven \nmillion Indian employees supporting routine-based testing and coding work could be eliminated in the next couple of \nyears,” said Phil Fersht, CEO and chief analyst, HFS Research, in what is an objective assessment on the fate of \njobs repetitive in structure and content.In India, market trends suggest that more than 16 million working employees \nwill need reskilling and upskilling due to AI’s influence by 2027, according to HR services firm TeamLease \nDigital.Huang’s words seemed even more ominous with the recent launch of Devin, “the world’s first fully \nautonomous AI software engineer”, developed by US startup Cognition. Devin’s capabilities achieved a 13.86% \naccuracy on the SWEBench benchmark, which assesses AI models on software engineering tasks, far \noutperforming the capabilities of the next best model, Claude 2 at 4.8%.The bot can practically be a collaborative \nco-worker. “Devin reports on its progress in real time, accepts feedback and works together with you through design \nchoices as needed,” Cognition said in a blog post. Devin now even has an Indian counterpart — Devika — an AI \ncreated by Mufeed VH of Lyminal and Stition.AI.Crowd thinningET had reported on March 14 that the IT industry \nwas set to miss its staff doubling target of 10 million employees by 2030. It will reach only about seven million by \nthe end of the decade, Teamlease Digital estimated. This slowing in pace of headcount addition is in large part due \nto AI, experts said.Fersht said that Indian support services could lose a million positions over the next couple of \nyears, as LLMs rapidly change how routine IT testing and coding work are delivered. “For 25 years, Indian IT \nservices have profitedfrom each of these technological shifts, as enterprises groped for bread-and-butter IT support \nto fix bad code, test portfolios of legacy apps, maintain creaking infrastructures and generally keep the IT wheels on \nglobal 2000 corporations hellbent on sustaining archaic business operating models that have barely changed since \nWorld War II… Many enterprise clients are crying out for help, but their partners are struggling to win their hearts. \nIt’s now time for India’s leaders to rethink how their firms operate and address gen AI,” Fersht said.“Tech roles are \nactually very, very susceptible to getting displaced by gen AI,” said Alpana Dutta, a partner at EY India. \n“Organisations are not going bold because there are considerations of ethics, data sanctity, etc. But from a first \nTalent AI-volution: Can AI adoption dent India 's tech edge?\nprinciples perspective, roles like software developer, code generator, optimisation, QA testing, integration testing, \nload testing, blockchain engineers, network administrator — all of these are very good candidates for getting \nautomated.”“Just being a plain Jane customer service person or just being a coder may not be enough,” Dutta \nsaid,adding that these skills have to transform. Ganesh Natarajan, former CEO of Zensar Technologies and \nfounderof digital transformation solutions company 5F World, had told ET that traditional roles like coding, \ntestingand maintenance, which make up about 60% of IT jobs, are being ‘taken over’ and ‘cannibalised’ byAI and \ncould drop precipitously to just 15%. He added that while automation and gen AI can be usedas an augmenting \nand enabling force too, in these areas it was essentially an autonomous force.“The fact of the matter is that the \ngrowth of manpower will not be linked to the growth of revenue. That is very clear,” Natarajan said. “We will soon be \ndealing with a very heterogeneous workforce, where there will be people andthere will be lots of robots and \nAI.”GCCs outdo pureplaysOver the past few quarters, when the IT headcount scenario has been bleak, continued \nhiring by Global Capability Centres was seen as a bright spot. But Natarajan contends that even there, once the \nlarge GCCs are fully populated over the next few years, it will meet the same fate with extensive leveraging of \ntechnology.According to Arvind Thakur, former vice-chairman and MD of NIIT Technologies, now a board member \nat NIIT University, the IT industry is at an inflection point, with a larger shift underway from labour arbitrage to AI-\ndriven tech arbitrage, he said. “If we look at the earlier practices of off-shoring, near-shoring, DevOps — all the \nthings the industry was doing were driving around 30% productivity and 5-10% continuous improvement. But we are \nnow going to move to the next S-curve of growth with AI driven decision making. So, new approaches like RPA \n(robotic process automation), low code/no code, process mining, machine learning, Gen AI — these things are \nnowgoing to become centre stage.  And you start seeing additional 50 -70% productivity happening in the workforce \ngoing forward,” Thakur said. While the industry understands the need for reskilling, some executives are also \nringing alarm bells about the need for specialised learning paths, citing that as few as five% of organisations \nglobally are spending on reskilling workers on gen AI.Fersht highlighted that the winners will be the partners who \ncan quickly understand what needs to be done to fix and scale the data without charging the world, yet with the \nability to work fast and smart. “When you look at the deep institutional relationships the likes of Cognizant, HCL, \nInfosys, TCS, etc have with their clients, many of whom are into fourth or even fifthgeneration contracts, surely \nthese firms have a tremendous opportunity to convince enterprise leaders to take a risk with them to make the \npainful changes necessary to capitalise on genAI tech,” he added. “India’s leaders must stop viewing gen AI as \nmerely the next shiny tech tool, as opposed to what it really is: A truly disruptive technological evolution that will \nfundamentally change business models and radically change how we invest in technology solutions and services. \nAll they need to do is look at the flourishing ecosystem of startups covering all angles of AI and industry solutions \nand embrace some of the entrepreneurial culture that once made them successful,” Fersht added.Other side of the \ndebate Having said all that, however, many industry leaders remain optimistic about the situation. Speaking at \nNasscom Technolog y and Leadership Forum (NTLF) about the impact on talent demand due to the use of A I, TCS \nCEO K Krithivasan said that it will only increase demand for new skills rather than reduce talent requirement. “While \nAI can improve productivity during production cycles, there will be a higher need for critical skills to addressthe \nstages of requirement gathering or even post-production use cases. So, we assume that AI adoption will not reduce \nthe number of people required,” he said, adding that skills in critical thinking, strategic planning and output \nvalidation for a superior user experience need to be included as part of the next generation of trainingmodels for \nemployees. Vineet Nayar, former CEO, HCL Technologies, said, “Repetitive work like coding, testing and service \nmanagement can be done with significantly smaller teams. However, it is also true that customers have no choice \nbut to double down on investments in AI to transform their own business, thus you would see a very high demand \nfor AI savvy skills.Overall impact of AI will be a significant increase in spending on technology by customers — thus \nmore demand for skills and more output from each person.”He cautioned, however, that “If you are an employee in \nIT — it’s time to reskill today as the day after tomorrow may be too late.”One window to the nextExperts point to \nother silver linings too. EY’s Dutt pointed out that new roles like AI trainer, AI ethics specialist, AI UX designer etc, \nare emerging, and “these are roles that you can morph into if you have a strong base in some ofthe older roles”, \nshe said, adding that India has been fast in adopting some of the AI-related skills.Moreover, while certain skills may \nbecome redundant in the IT services or ITeS setup, they may remain very relevant for other industries. “You could \nsee people with certain skills in the IT industry being not so relevant, but still relevant for some of our core sector \nindustries because they are way behind in their digital and automation journey. You will also see some from these \nindustries into other core manufacturing, production type of industry because they are also trying to significantly \nelevate their digital journey. What is average skill in the IT industry could become a very valuable and premium skill \nTalent AI-volution: Can AI adoption dent India 's tech edge?\ngiven the maturity of digital and tech in some of these other oldworld industries,” Dutt said.International tailwinds \nmay help India along as well. For instance, Rajnil Mallik, partner and gen AI go-to-market leader at PwC India, \nnoted that the AI executive order passed by US President Joe Biden, while regulatory in nature, is also upbeat and, \ncrucially, acknowledges that the US cannot make progress in AI on its own. Indian talent being a ‘known entity’ will \nbe an advantage, he said.“One thing that’s not going to change is that India remains one of the largest pools of \nEnglishspeaking talent in the world, and we have very good coding skills,” Mallik said, adding that the near future is \nAI plus humans, and not AI alone. The disruptive technology has a l so pu shed people to innovate — for instance, \nthe coming of LLMs has changed the nature of coding, bringing new disciplines like open source LLMs, training, \nfinetuning, prompt engineering etc, Mallik noted, and this innovation will accelerate in the coming years. For Reprint \nRights: timescontent.com\nLoad-Date: April 21, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2023",
        "header": "Generative AI could replace 300 million jobs: Goldman Sachs report",
        "media": "The Economic Times",
        "time": "March 29, 2023",
        "section": "TECH & INTERNET",
        "length": "299 words",
        "byline": " ",
        "story_text": "Generative AI could replace 300 million jobs: Goldman Sachs report\nThe Economic Times\nMarch 30, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 299 words\nBody\nGenerative AI has already made a huge impact on how technology is used on a daily basis. Soon, it will disrupt the \nlabour market, according to a Goldman Sachs report, and could replace 300 million jobs globally. The report \npredicts that about two-thirds of jobs in the US and Europe are exposed to AI automation. \nA partial but significant part of the workload (25-50%) of most of these jobs can be replaced by AI, it said. One-\nfourth of the jobs in the US and Europe right now can be substituted by AI, the report added.The report also \npredicted that generative AI would have a positive impact on world Gross Domestic Product (GDP), noting that its \nwidespread adoption could lead to a 7% or $7 trillion increase in global GDP. The report also suggested that AI \ncould raise annual US labour productivity growth by just under 1.5 percentage points, over a period of 10 years, if it \nis adopted on a wide scale. Which jobs will be impacted?According to the Goldman Sachs report, jobs will only \npartially be impacted by AI, and that too, not all of them. For example, jobs such as construction, cleaning and \nmaintenance cannot be replaced completely by AI. The report talks about the percentage of work that can be \nautomated for each industry segment. The percentage of tasks that can be automated and eventually replaced by \nAI in the US was highest for jobs in office administration and support, at 46%. According to the report, 44% of tasks \nin legal jobs in the US can be automated and replaced by AI. Also in the US, a third of the tasks in community and \nsocial services, as well as management, can be automated and hence are replaceable by AI. About 45% of tasks in \njobs related to clerical support in the Euro area can be automated, according to the report. For Reprint Rights: \ntimescontent.com\nLoad-Date: March 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "What’s Next in Artificial Intelligence?; DealBook Newsletter",
        "media": "The New York Times",
        "time": "December 29, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1232 words",
        "byline": "Vivienne Walt",
        "story_text": "What’s Next in Artificial Intelligence?; DealBook Newsletter\nThe New York Times \nDecember 27, 2023 Wednesday 22:52 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1232 words\nByline: Vivienne Walt\nHighlight: If 2023 was the year of A.I. awakening, 2024 could be the year of A.I. reckoning.\nBody\nMustafa Suleyman remembers the epochal moment he grasped artificial intelligence’s potential. It was 2016 — \nPaleolithic times by A.I. standards — and DeepMind, the company he had co-founded that was acquired by Google \nin 2014, had pitted its A.I. machine, AlphaGo, against a world champion of Go, the confoundingly difficult strategy \ngame. AlphaGo zipped through thousands of permutations, making fast work of the hapless human. Stunned, \nSuleyman realized the machine had “seemingly superhuman insights,” he says in his  book on A.I., “The Coming \nWave.”\nThe result is no longer stunning — but the implications are. Little more than a year after OpenAI’s ChatGPT \nsoftware helped bring generative A.I. into the public consciousness, companies, investors and regulators are \ngrappling with how to shape the very technology designed to outsmart them. The exact risks of the technology are \nstill being debated, and the companies that will lead it are yet to be determined. But one point of agreement: A.I. is \ntransformative. “The level of innovation is very hard for people to imagine,” said Vinod Khosla, founder of the Silicon \nValley venture capital firm Khosla Ventures, which was one of the first investors in OpenAI. “Pick an area: books, \nmovies, music, products, oncology. It just doesn’t stop.”\nIf 2023 was the year the world woke up to A.I., 2024 might be the year in which its legal and technical limits will be \ntested, and perhaps breached. DealBook spoke with A.I. experts about the real-world effects of this shift and what \nto expect next year.\nJudges and lawmakers will increasingly weigh in. The flood of A.I. regulations in recent months is likely to come \nunder scrutiny. That includes President Biden’s executive order in October, which, if Congress ratifies, could \ncompel companies to ensure that their A.I. systems cannot be used to make biological or nuclear weapons; embed \nwatermarks on A.I.-generated content; and to disclose foreign clients to the government.\nAt the A.I. Safety Summit in Britain in November, 28 countries, including China — though not Russia — agreed to \ncollaborate to prevent “catastrophic risks.” And in marathon negotiations in December, the E.U. drafted one of the \nworld’s first comprehensive attempts to limit the use of artificial intelligence, which, among other provisions, restricts \nfacial recognition and deep fakes and defines how businesses can use A.I. The final text is due out in early 2024, \nand the bloc’s 27 member countries hope to approve it before European Parliament elections in June.\nWith that, Europe might effectively create global A.I. rules, requiring any company that does business in its market, \nof 450 million people, to cooperate. “It makes life tough for innovators,” said Matt Clifford, who helped organize the \nA.I. summit in Britain. “They have to think about complying with a very long list of things people in Brussels are \nworried about.”\nWhat’s Next in Artificial Intelligence? DealBook Newsletter\nThere are plenty of concerns, including about A.I.’s potential to replace large numbers of jobs and to reinforce \nexisting racial biases.\nSome fear overloading A.I. businesses with regulations. Clifford believes existing fraud and consumer-protection \nlaws make some portions of Europe’s legislation, the A.I. Act, redundant. But the E.U.’s lead architect, Dragos \nTudorache, said that Europe “wasn’t aiming to be global regulators,” and that he maintained close dialogue with \nmembers of the U.S. Congress during the negotiations. “I am convinced we have to stay in sync as much as \npossible,” he said.\nGovernments have good reason to address A.I.: Even simple tools can serve dark purposes. “The microphone \nenabled both the Nuremberg rallies and the Beatles,” wrote Suleyman, who is now the chief executive of Inflection \nAI, a start-up he co-founded last year with Reid Hoffman, a co-founder of LinkedIn. He fears that A.I. could become \n“uncontained and uncontainable” once it outsmarts humans. “Homo technologicus could end up being threatened \nby its own creation.”\nA.I. capabilities will soar. It’s hard to know when that tipping point might arrive. Jensen Huang, the co-founder and \nchief executive of Nvidia, whose dominance of A.I. chips has seen its share price more than triple since Jan. 1, told \nthe DealBook Summit in late November that “there’s a whole bunch of things that we can’t do yet.”\nKhosla believes the key A.I. breakthrough in 2024 will be “reasoning,” allowing machines to produce far more \naccurate results, and that in 2025, “A.I. will win in reasoning against intelligent members of the community.” A.I. \nmachines will be steadily more capable of working through several logical steps, and performing probabilistic \nthinking, such as identifying a disease based on specific data, Khosla said.\nExponential growth in computational power, which hugely increases the capability of A.I. machines, factors into \nthose predictions. “In 2024, it will be between 10 and 100 times more than current-day models,” Clifford said. “We \ndon’t actually know what kind of innovations that’s going to result in.”\nOne new tool could be generative audio that allows users to deliver speeches in, say, Biden’s voice or to generate \nrap songs, opera or Beethoven’s nonexistent 10th symphony. DeepMind and YouTube have partnered with \nmusicians to create A.I. tools allowing artists to insert instruments, transform musical styles or compose a melody \nfrom scratch.\nBillions in investments will be needed. None of this will come cheap, and the question now is which companies will \nbe able to build truly sustainable A.I. businesses. Of 175,072 A.I. patents filed between 2012 and 2022, more than \nhalf were filed in the last three years, according to Deutsche Bank. In 2024 and 2025, the bank predicts sharp \nincreases in companies using A.I. for human resources, marketing, sales and product development. That is already \nhappening: Legal firms, for example, have begun using A.I.-generated contracts, cutting out hours of work for \nlawyers. “The time is ripe for an explosion of A.I. innovation,” it predicted last May.\nAs those innovations roll out, fund-raising has ramped up. The French A.I. start-up Mistral AI— considered a \nEuropean contender to OpenAI — raised more than half a billion dollars in 2023. More than $200 million came from \nthe Silicon Valley venture capital giant Andreessen Horowitz in a funding round that valued Mistral, just seven \nmonths old, at $2 billion.\nBut that might not be enough to create a general-purpose A.I. system of the kind that powers ChatGPT and that \nMistral has in mind. “It’s becoming clear the vast sums of money you need to be competitive,” Clifford said. “If you \nwant to build a general-purpose model, it may be that the amount of capital needed is so great, it makes it very \ntricky for traditional venture capital.”\nThe story could be different for A.I. tools that serve a specific purpose, a category that spawned hundreds of start-\nups in 2023. After a sharp downturn last year, A.I. venture funding is rising fast, with most invested in U.S. \ncompanies. Khosla said that this year he had backed 30 A.I. start-ups, including in India, Japan, Britain and Spain, \ncompanies which he said “are not afraid of the Big Tech guy.” He expects A.I. funding to continue rising through at \nWhat’s Next in Artificial Intelligence? DealBook Newsletter\nleast 2024. “Every country wants to be in the game,” he said. “That will accelerate the money flow, and the number \nof start-ups will keep accelerating.”\nThis article appeared in print on page B4.\nLoad-Date: December 29, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Google Cuts Hundreds of Jobs in Engineering and Other Divisions",
        "media": "The New York Times",
        "time": "January 11, 2024",
        "section": "TECHNOLOGY",
        "length": "562 words",
        "byline": "Nico Grant &lt;p&gt;Nico Grant is a technology reporter covering Google from San Francisco. Previously,",
        "story_text": "Google Cuts Hundreds of Jobs in Engineering and Other Divisions\nThe New York Times \nJanuary 11, 2024 Thursday 22:13 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 562 words\nByline: Nico Grant &lt;p&gt;Nico Grant is a technology reporter covering Google from San Francisco. Previously, \nhe spent five years at Bloomberg News, where he focused on Google and cloud computing.&lt;/p&gt;\nHighlight: The company, which has been working to trim expenses, laid off employees who worked on core \nengineering, the Google Assistant product and hardware such as the Pixel phone.\nBody\nThe company, which has been working to trim expenses, laid off employees who worked on core engineering, the \nGoogle Assistant product and hardware such as the Pixel phone.\nGoogle laid off hundreds of workers in several divisions Wednesday night, seeking to lower expenses as it focuses \non artificial intelligence and joining a wave of other companies cutting tech jobs this year.\nThe Silicon Valley company laid off employees in its core engineering division, as well as those working on the \nGoogle Assistant, a voice-operated virtual assistant, and in the hardware division that makes the Pixel phone, Fitbit \nwatches and Nest thermostat, three people with knowledge of the cuts said.\nSeveral hundred employees from the company’s core engineering organization lost corporate access and received \nnotices that their roles were eliminated, two of the people said. Google said that most of the hardware cuts affected \na team working on augmented reality, technology that combines the real world with a digital overlay.\n“We’ve had to make some difficult decisions about ongoing employment of some Google employees and we regret \nto inform you that your position is being eliminated,” the company told some workers in the division, according to \nthe text of an email reviewed by The New York Times.\nGoogle confirmed the Assistant cuts, earlier reported by Semafor, and the hardware layoffs, earlier reported by the \nblog 9to5Google.\n“We’re responsibly investing in our company’s biggest priorities and the significant opportunities ahead,” a Google \nspokesman said in a statement. After cuts throughout the second half of 2023, “some teams are continuing to make \nthese kinds of organizational changes, which include some role eliminations globally.”\nThe cuts continue a trend of tech layoffs, after large companies such as Google, Meta and Amazon laid off \nthousands of workers last year. Ten days into this year, more companies have announced job cuts. Earlier \nWednesday, Amazon shed hundreds of workers from its Twitch streaming service, Prime Video and MGM studios. \nXerox said this month that it would cut 15 percent of its 23,000-person staff, and the video game software provider \nUnity Software said it would eliminate 1,800 roles, or 25 percent of its work force.\nAt Google, Sundar Pichai, the chief executive, has pushed the company since July 2022 to sharpen its focus and to \nreduce expenses as global economic conditions deteriorated. In January 2023, Google shed 6 percent of its work \nforce, or 12,000 people, in the largest layoffs that the company has conducted. Since then, executives at the \nGoogle Cuts Hundreds of Jobs in Engineering and Other Divisions\ncompany have said they would try to significantly reduce costs, as it focuses on the growing field of generative \nartificial intelligence.\nGoogle, which had 182,000 employees as of Sept. 30, said the layoffs on Wednesday were part of a set of \nreorganizations that were made in the normal course of business.\nThe Alphabet Workers Union, a group representing more than 1,400 workers at Google’s parent company, \nAlphabet, described the layoffs as “needless.”\n“Our members and teammates work hard every day to build great products for our users, and the company cannot \ncontinue to fire our co-workers while making billions every quarter,” the group said in a post on the social media site \nX.\nMike Isaac contributed reporting.\nMike Isaac contributed reporting. \nThis article appeared in print on page B3.\nLoad-Date: January 11, 2024"
    },
    {
        "file_name": "Soon;_Guest_Essay_Jul2023",
        "header": "There’s One Hard Question My Fellow Doctors and I Will Need to Answer",
        "media": "Soon; Guest Essay",
        "time": "July 6, 2023",
        "section": "OPINION",
        "length": "1429 words",
        "byline": "Daniela J. Lamas",
        "story_text": "There’s One Hard Question My Fellow Doctors and I Will Need to Answer \nSoon; Guest Essay\nThe New York Times \nJuly 6, 2023 Thursday 09:11 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1429 words\nByline: Daniela J. Lamas\nHighlight: How will A.I. change how we practice medicine?\nBody\nWhen faced with a particularly tough question on rounds during my intern year, I would run straight to the bathroom. \nThere, I would flip through the medical reference book I carried in my pocket, find the answer and return to the \ngroup, ready to respond.\nAt the time, I believed that my job was to memorize, to know the most arcane of medical eponyms by heart. Surely \nan excellent clinician would not need to consult a book or a computer to diagnose a patient. Or so I thought then.\nNot even two decades later, we find ourselves at the dawn of what many believe to be a new era in medicine, one \nin which artificial intelligence promises to write our notes, to communicate with patients, to offer diagnoses. The \npotential is dazzling. But as these systems improve and are integrated into our practice in the coming years, we will \nface complicated questions: Where does specialized expertise live? If the thought process to arrive at a diagnosis \ncan be done by a computer “co-pilot,” how does that change the practice of medicine, for doctors and for patients?\nThough medicine is a field where breakthrough innovation saves lives, doctors are — ironically — relatively slow to \nadopt new technology. We still use the fax machine to send and receive information from other hospitals. When the \nelectronic medical record warns me that my patient’s combination of vital signs and lab abnormalities could point to \nan infection, I find the input to be intrusive rather than helpful. A part of this hesitation is the need for any technology \nto be tested before it can be trusted. But there is also the romanticized notion of the diagnostician whose mind \ncontains more than any textbook.\nStill, the idea of a computer diagnostician has long been compelling. Doctors have tried to make machines that can \n“think” like a doctor and diagnose patients for decades, like a Dr. House-style program that can take in a set of \ndisparate symptoms and suggest a unifying diagnosis. But early models were time-consuming to employ and \nultimately not particularly useful in practice. They were limited in their utility until advances in natural language \nprocessing made generative A.I. — in which a computer can actually create new content in the style of a human — \na reality. This is not the same as looking up a set of symptoms on Google; instead, these programs have the ability \nto synthesize data and “think” much like an expert.\nTo date, we have not integrated generative A.I. into our work in the intensive care unit. But it seems clear that we \ninevitably will. One of the easiest ways to imagine using A.I. is when it comes to work that requires pattern \nrecognition, such as reading X-rays. Even the best doctor may be less adept than a machine when it comes to \nrecognizing complex patterns without bias. There is also a good deal of excitement about the possibility for A.I. \nprograms to write our daily patient notes for us as a sort of electronic scribe, saving considerable time. As Dr. Eric \nTopol, a cardiologist who has written about the promise of A.I. in medicine, says, this technology could foster the \nrelationship between patients and doctors. “We’ve got a path to restore the humanity in medicine,” he told me.\nThere’s One Hard Question My Fellow Doctors and I Will Need to Answer Soon Guest Essay\nBeyond saving us time, the intelligence in A.I. — if used well — could make us better at our jobs. Dr. Francisco \nLopez-Jimenez, the co-director of A.I. in cardiology at the Mayo Clinic, has been studying the use of A.I. to read \nelectrocardiograms, or ECGs, which are a simple recording of the heart’s electrical activity. An expert cardiologist \ncan glean all sorts of information from an ECG, but a computer can glean more, including an assessment of how \nwell the heart is functioning — which could help determine who would benefit from further testing.\nEven more remarkably, Dr. Lopez-Jimenez and his team found that when asked to predict age based on an ECG, \nthe A.I. program would from time to time give an entirely incorrect response. At first, the researchers thought the \nmachine simply wasn’t great at age prediction based on the ECG — until they realized that the machine was \noffering the “biological” rather than chronological age, explained Dr. Lopez-Jimenez. Based on the patterns of the \nECG alone, the A.I. program knew more about a patient’s aging than a clinician ever could.\nAnd this is just the start. Some studies are using A.I. to try to diagnose a patient’s condition based on voice alone. \nResearchers promote the possibility of A.I. to speed drug discovery. But as an intensive care unit doctor, I find that \nwhat is most compelling is the ability of generative A.I. programs to diagnose a patient. Imagine it: a pocket expert \non rounds with the ability to plumb the depth of existing knowledge in seconds.\nWhat proof do we need to use any of this? The bar is higher for diagnostic programs than it is for programs that \nwrite our notes. But the way we typically test advances in medicine — a rigorously designed randomized clinical \ntrial that takes years — won’t work here. After all, by the time the trial were complete, the technology would have \nchanged. Besides, the reality is that these technologies are going to find their way into our daily practice whether \nthey are tested or not.\nDr. Adam Rodman, an internist at Beth Israel Deaconess Hospital in Boston and a historian, found that the majority \nof his medical students are using Chat GPT already, to help them on rounds or even to help predict test questions. \nCurious about how A.I. would perform on tough medical cases, Dr. Rodman gave the notoriously challenging New \nEngland Journal of Medicine weekly case — and found that the program offered the correct diagnosis in a list of \npossible diagnoses just over 60 percent of the time. This performance is most likely better than any individual could \naccomplish.\nHow those abilities translate to the real world remains to be seen. But even as he prepares to embrace new \ntechnology, Dr. Rodman wonders if something will be lost. After all, the training of doctors has long followed a clear \nprocess — we see patients, we struggle with their care in a supervised environment and we do it over again until \nwe finish our training. But with A.I., there is the real possibility that doctors in training could lean on these programs \nto do the hard work of generating a diagnosis, rather than learn to do it themselves. If you have never sorted \nthrough the mess of seemingly unrelated symptoms to arrive at a potential diagnosis, but instead relied on a \ncomputer, how do you learn the thought processes required for excellence as a doctor?\n“In the very near future, we’re looking at a time where the new generation coming up are not going to be developing \nthese skills in the same way we did,” Dr. Rodman said. Even when it comes to A.I. writing our notes for us, Dr. \nRodman sees a trade-off. After all, notes are not simply drudgery; they also represent a time to take stock, to review \nthe data and reflect on what comes next for our patients. If we offload that work, we surely gain time, but maybe we \nlose something too.\nBut there is a balance here. Maybe the diagnoses offered by A.I. will become an adjunct to our own thought \nprocesses, not replacing us but allowing us all the tools to become better. Particularly for those working in settings \nwith limited specialists for consultation, A.I. could bring everyone up to the same standard. At the same time, \npatients will be using these technologies, asking questions and coming to us with potential answers. This \ndemocratizing of information is already happening and will only increase.\nPerhaps being an expert doesn’t mean being a fount of information but synthesizing and communicating and using \njudgment to make hard decisions. A.I. can be part of that process, just one more tool that we use, but it will never \nreplace a hand at the bedside, eye contact, understanding — what it is to be a doctor.\nThere’s One Hard Question My Fellow Doctors and I Will Need to Answer Soon Guest Essay\nA few weeks ago, I downloaded the Chat GPT app. I’ve asked it all sorts of questions, from the medical to the \npersonal. And when I am next working in the intensive care unit, when faced with a question on rounds, I just might \nopen the app and see what A.I. has to say.\nDaniela J. Lamas (@danielalamasmd), a contributing Opinion writer, is a pulmonary and critical-care physician at \nBrigham and Women’s Hospital in Boston.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nLoad-Date: July 6, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Will Biden’s Trade War With China Get Results?; DealBook Newsletter",
        "media": "The New York Times",
        "time": "May 14, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1917 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Will Biden’s Trade War With China Get Results?; DealBook Newsletter\nThe New York Times \nMay 14, 2024 Tuesday 12:44 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1917 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The White House has imposed $18 billion in new duties on Chinese imports, but it’s unclear how much \nthat will help his economic agenda.\nBody\nThe White House has imposed $18 billion in new duties on Chinese imports, but it’s unclear how much that will help \nhis economic agenda.\nBiden fires a new round at China \nPresident Biden announced on Tuesday a wave of new tariffs on billions of dollars in Chinese products, ramping up \nduties on industries like electric cars and solar energy that are core to his economic agenda.\nThe restrictions build on Trump-era measures, and many are likely to appeal to voters in battleground states ahead \nof the election. But it’s less clear if they are enough to rebuild America’s industrial base in a global race with China \nto lead in the new economy.\nThe new duties will apply to about $18 billion of annual Chinese imports, the Biden administration said. The \npresident will also pledge to keep tariffs on more than $300 billion worth of Chinese goods put in place by President \nDonald Trump — measures that Biden said in his 2020 election campaign had hurt American consumers.\nHere’s what the new package looks like:\n• Tariffs on Chinese-made E.V.s, which are essentially locked out of the U.S. market anyway, will quadruple to \n100 percent from 25 percent.\n• Rates on solar cells and semiconductors will double to 50 percent.\n• Duties on some advanced batteries and the key components used to make them will rise to 25 percent.\n• And tariffs on certain steel and aluminum products will triple to 25 percent.\nWill Biden’s Trade War With China Get Results? DealBook Newsletter\nBiden is at pains to say that he’s being smarter than Trump on China. Trump imposed sweeping trade barriers and \nhas vowed to impose more if he’s re-elected. Biden has focused on specific sectors, including chips, artificial \nintelligence and clean energy. Trump spurned allies, while Biden has cultivated them and says his policies aren’t \nbroadly anti-China.\nChina could argue that the U.S. is playing catch up. Beijing has invested for years to become self-sufficient in the \nsame high-tech sectors Biden is trying to bolster at home. It produces cheaper products that much of the rest of \nworld wants, especially in countries that feel neglected by the West.\nTariffs may not bolster domestic manufacturing. Joseph Stiglitz, the Nobel Prize-winning economist, credits Biden \nfor trying to reverse decades of deindustrialization, especially with a Republican-controlled House limiting what he \ncan do.\nBut more needs to be done to back universities and strengthen science and technology, just as America did during \nthe Cold War space race. “The strategy that we’re posing may protect our market but will mean that China will \ndominate the rest of the world,” he told DealBook. “That isn’t putting us in a position of global leadership.”\nHERE’S WHAT’S HAPPENING \nOpenAI makes ChatGPT more powerful. The artificial intelligence start-up announced GPT-4o, an update to the \nlarge language model that powers its hugely popular chatbot. ChatGPT can now receive and respond to images, \ntext and voice commands much more quickly, and is part of an effort to combine generative A.I. with voice \nassistants like Apple’s Siri and the Google Assistant. Google is hosting a developer conference on Tuesday, where \nit’s expected to announce A.I. upgrades.\nChevron’s $53 billion deal for Hess faces a new hurdle. The shareholder advisory firm Institutional Shareholder \nServices recommended that investors abstain from voting on the deal at a shareholder meeting scheduled for May \n28. The advice comes amid a dispute between the companies and Exxon Mobil over Hess’s Guyana oil fields and \ncalls for tougher antitrust scrutiny of the deal.\nU.S. airlines sue the Biden administration over a fee disclosure rule. A group including American, Alaska, Delta and \nUnited filed a lawsuit against the Transportation Department over a new requirement that they disclose additional \nfees for things like luggage up front, calling the move confusing for customers. It’s the latest corporate pushback \nagainst the Biden administration’s fight against what it calls “surprise junk fees.”\nTesla rehires some workers from its supercharger division. The move, reported by Bloomberg, appears to at least \npartly undo the decision last month to lay off nearly 500 employees of the business. Elon Musk’s order to gut the \ndivision surprised many in the industry — Tesla’s charging network is the biggest and the most reliable in the U.S. \n— and drew fierce criticism.\nA foundational split \nThree years after Bill Gates and Melinda French Gates divorced, they’re parting ways philanthropically. French \nGates announced that she was stepping down from the $75 billion foundation they founded to focus on her own \ncharitable giving.\nThe news underscores the widening split between the Microsoft co-founder and his former wife, who as a couple \nhad been among the most powerful forces in philanthropy for decades. But it also elevates French Gates as a \npowerful donor in her own right and a champion for progressive social issues.\nThe writing was on the wall. French Gates found her working relationship with her ex-husband difficult, according to \nThe Times. After their 2021 split, she said publicly that the two kept cordial relations but weren’t friends. (That said, \nsome employees of the foundation were reportedly surprised by the news of the resignation, and French Gates had \nrepresented the organization in Washington last month.)\nWill Biden’s Trade War With China Get Results? DealBook Newsletter\nThe foundation had already been preparing for this possibility. In 2022, it revamped its leadership by adding six \ntrustees to a board that until recently consisted only of Gates, French Gates and Warren Buffett (who had stepped \ndown in 2021).\nFrench Gates is walking away with $12.5 billion for her own giving, as part of an agreement struck after the divorce. \nThat will make her a powerful solo force in philanthropy, like MacKenzie Scott, who has given away billions since \nher 2019 split from Jeff Bezos. (French Gates and Scott have worked together.)\nWhat’s next for French Gates? Much of her billions will go to Pivotal Ventures, the entity she created in 2015 to \nfocus on issues including paid family and medical leave and increasing female representation in politics. Pivotal has \nalready given about $1 billion toward its causes.\nFrench Gates is likely to continue focusing her giving on women’s issues (and perhaps, according to Puck’s Teddy \nSchleifer, may also become more political). From a statement on Monday by Mark Suzman, the C.E.O. of the Gates \nFoundation:\nMelinda has new ideas about the role she wants to play in improving the lives of women and families in the U.S. \nand around the world. And, after a difficult few years watching women’s rights rolled back in the U.S. and around \nthe world, she wants to use this next chapter to focus specifically on altering that trajectory.\nMeanwhile, the foundation will still work on issues that French Gates had focused on, according to Anita Zaidi, the \norganization’s president of gender equality.\nAnglo American slims down as bidders circle \nThe mining giant Anglo American is getting out of the diamonds, coal and platinum business as it engineers a major \nrestructuring to fend off a $43 billion takeover bid from BHP Group.\nCopper is at the heart of the deal talk. Anglo’s prized assets are its South American copper mines. The metal, a key \nmaterial for the world’s energy transition, hit a two-year high this on Tuesday. Despite that, Anglo’s share price had \nlanguished until BHP made an offer last month.\nAnglo hopes that splitting out less attractive units, including its famous De Beers diamond business, will leave it \nstronger as a stand-alone company focused on its biggest money making units.\nBut the stock is down again on Tuesday in London. That potentially puts further pressure on Anglo’s board as \ninvestors seem to be growing more restless about its strategy.\nAnglo’s board has twice rejected BHP’s bids. But analysts think talks could get more serious, or others could enter \ninto a competition for the miner. “We would also expect, at some point, Glencore to show its hand and likely submit \nits own proposal to merge with Anglo America,” Richard Hatch, an analyst at Berenberg, wrote in an investor note.\nAnglo American said on Tuesday that it was seeing “strong buyer interest” for its steelmaking coal business, but it \ndid not elaborate on the market for its famed diamond-mining unit.\nGame on for GameStop \nWall Street is feeling a bit of meme stock déjà vu.\nAn army of retail investors are driving up the price of GameStop, the retailer whose 2021 rally led to internet fame \nfor “Roaring Kitty,” the stock’s social media savvy booster, a movie, a congressional hearing, an S.E.C. \ninvestigation — and losses for those who mistimed the stock’s rise and fall.\nGameStop is up more than 100 percent in premarket trading. That’s after it soared more than 70 percent on \nMonday, adding billions in market valuation — and big losses for short sellers — on an otherwise snooze of a day in \nthe stock market.\nWill Biden’s Trade War With China Get Results? DealBook Newsletter\nRetail traders are once again being spurred on by the return of Roaring Kitty — also known as Keith Gill — to X \nafter a lengthy silence. Gill posted a series of video clips from films like “Ferris Bueller’s Day Off” and “The Good, \nthe Bad and the Ugly” after almost three years of inactivity — but made no mention of GameStop.\nIn recent days, a surge of investors has bought GameStop “call” options — essentially, bets that the stock would \nrise — noted Steve Sosnick, chief strategist at Interactive Brokers. And yesterday’s rally wasn’t driven by any \nevident news about the company. “Given my past experience in analyzing the periodic bouts of meme stock activity, \nconsider me suspicious,” Sosnick wrote in an investor note.\nThe sharp upturn has short-circuited short sellers. GameStop shorts — those who bet the stock would fall, looking \nto profit — started the week up $392 million in mark-to-mark profits this year. By yesterday’s close, they had racked \nup $852 million in losses for the year, Ihor Dusaniwsky, managing director of S3 Partners, a data firm, told \nDealBook. “Short sellers may be in for a bumpy and bloody ride,” he added.\nTHE SPEED READ \nDeals\n• Kraft Heinz is said to be weighing the sale of the hot dog maker Oscar Mayer, potentially for up to $5 billion, \nas it focuses on healthier food. (WSJ)\n• President Emmanuel Macron of France said he was open to a major French lender being acquired by a \nEuropean rival to better integrate the European Union’s banking system. (Bloomberg)\n• Accel, the venture capital firm, announced a $650 million fund to invest in early-stage start-ups in Europe and \nIsrael. (Accel)\nPolicy\n• The European Union’s executive arm said it was investigating whether X, Elon Musk’s social network, \nqualifies as a “gatekeeper” and subject to tougher regulations. (Reuters)\n• A federal judge in Texas allowed an F.T.C. antitrust lawsuit against a big anesthesiology provider to proceed, \nbut dismissed claims against the company’s owner, the investment firm Welsh Carson. (Judge’s opinion)\nBest of the rest\n• Jimmy Dunne, the banking mogul who was an architect of the PGA Tour’s framework agreement with Saudi \nArabia’s sovereign wealth fund, resigned from the golf organization’s board, citing friction with players and \na lack of progress on deal talks. (Sports Illustrated)\n• BlackRock may soon lay claim to running the world’s biggest Bitcoin fund. (FT)\n• “A Famed Car Designer’s Doomed Attempt to Challenge Tesla” (WSJ)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: President Biden has added solar cells and electric vehicles to Washington’s trade war with Beijing. \n(PHOTOGRAPH BY Brian Snyder/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: May 14, 2024"
    },
    {
        "file_name": "3_steps_to_take_if_you_have_layoff_anxiety_Mar2023",
        "header": "Prepare for the unexpected",
        "media": "3 steps to take if you have layoff anxiety",
        "time": "March 12, 2023",
        "section": "MAIN; B; Pg. 6",
        "length": "900 words",
        "byline": "Rohshann Pilla  |  Fast Company",
        "story_text": "Prepare for the unexpected\n3 steps to take if you have layoff anxiety\nThe Baltimore Sun\nMarch 12, 2023 Sunday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; B; Pg. 6\nLength: 900 words\nByline: Rohshann Pilla  |  Fast Company\nHighlight: Antonio Guillem/Dreamstime\nBody\nIn recent months, major U.S. companies announced a wave of layoffs. Meanwhile, developments in artificial \nintelligence, such as ChatGPT, have taken off. Our workforce is rapidly changing, and many workers are feeling \nanxious. In fact, LinkedIn recently surveyed 2,000 U.S. workers and found that a whopping 75% experience \n\"Sunday scaries.\" Plus, 74% say their feelings have increased because of current economic uncertainty.\nNow more than ever, workers need to make sure they are keeping up. Whether you were among the tens of \nthousands who were laid off recently, are considering changing jobs or are happy where you are, there are steps \nyou can take to stay ahead of the changing workforce, remain competitive in the job market, excel in your career \nand manage your anxiety.\nStart upskilling now\nAs technology develops and virtual reality and artificial intelligence (AI) become more common in the workplace, the \nskills that we need to succeed are shifting alongside it. Competitive employees in every industry are going to need \nto upskill to stand out and stay up to date.\nFor instance, Microsoft and Google have invested in integrating generative AI technology like ChatGPT into their \nsearch engines and other products that we use in our daily lives. This opens the door for a new essential skill: the \nability to talk to AI and make the most of it.\nIn addition, the metaverse is expected to grow up to $5 trillion by 2030, and companies and talent who are sitting on \nthe sidelines will miss out on new career and financial opportunities. In a recent survey, my team found that more \nthan half of our respondents intend to improve their skills to transition into emerging metaverse roles. This \nsentiment shows promise, but with the workplace of the future on our horizon, all workers need to not just consider \nupskilling but start doing it now.\nPlus, upskilling can lead to a pay boost. Aquent's Salary Guide found that a digital designer currently making an \naverage of $90,000 can upskill to become a technical artist, with an average salary of $140,000.\nAnd even if you don't think a given technology will be used in your industry immediately, understand that leaders \nare finding new applications for these technologies every day. For most of us, it's only a matter of time before \ntechnology requires us to uplevel our skills. Pursuing opportunities for lifelong learning, including free online course \nofferings, can help you become more familiar with how new tech can work in your favor, rather than hurt you.\nPrepare for the unexpected 3 steps to take if you have layoff anxiety\nBuild out your network\nTo be prepared for whatever comes along in this uncertain economic environment, workers should cultivate their \nnetworks now - even if they are not actively looking for a new opportunity.\nBuilding a network of recruiters can help you keep a pulse on the changes and trends in your industry. One great \nway to find quality recruiters is to ask people in your network if they have worked with recruiters or have anyone \nthey can refer you to. Having a trusted colleague make that first connection will give you confidence that you are \nbuilding a network that is not just large but also valuable.\nTo that end, developing a strong personal network is just as, if not more, important. Connecting with your peers and \nother leaders in your field opens the door for mentorship opportunities, references and avenues for professional \ngrowth. For instance, you can talk to people who have been in your position and are in leadership positions that you \naspire to reach one day. Don't be afraid to reach out and ask them, How did they get there? Lean on your network \nand use their insights to forge your own path.\nIf you don't already know people to reach out to, consider joining a professional organization or attending \nconferences. These provide great networking opportunities as well as chances to hear from industry leaders who \ncan help guide your journey.\nKeep your information up to date\nEven if you're not planning on sending your résumé out anytime soon, it's important to spend time keeping it current \nto help illuminate places where you could further develop in your role. It might even spark a conversation with your \nboss! Be sure to also keep your information current on LinkedIn. Don't go dark just because you are comfortable \nwhere you are.\nWhen putting together your résumé, if you recognize a weak point or are currently struggling with a certain aspect \nof your job, look into classes and certifications that can help you turn these weaknesses into strengths. It's a good \nsign of professionalism to be self-aware and work to build skills that don't come naturally - the same way that you \ngo to the gym to get stronger physically. Often, companies even have budgets for professional development \nopportunities and are happy to help you pay for these classes, especially if you take the initiative to seek them out \nand ask.\nIn our fast-changing world and workforce, it's wise to prepare for the unexpected. There are steps you can take \nahead of time to assuage any layoff fears you may have - even if you don't expect them to come to fruition. It's \nalways a good idea to see what's out there and keep learning, for your personal growth and so that you continue to \nexcel at work no matter what comes your way.\nRohshann Pilla is the president of Aquent Talent. She oversees the placement of creative, marketing and design \ntalent in Fortune 100 companies to propel their business forward.\nLoad-Date: March 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Where Does A.I. End and We Begin?; Turning Points: Guest Essay",
        "media": "The New York Times",
        "time": "December 7, 2023",
        "section": "SPECIAL-SERIES",
        "length": "1009 words",
        "byline": "Sougwen Chung",
        "story_text": "Where Does A.I. End and We Begin?; Turning Points: Guest Essay\nThe New York Times \nDecember 7, 2023 Thursday 15:15 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: SPECIAL-SERIES\nLength: 1009 words\nByline: Sougwen Chung\nHighlight: Artificial intelligence can act as a collaborator that helps artists produce new works.\nBody\nArtificial intelligence can act as a collaborator that helps artists produce new works.\nThis personal reflection is part of a series called Turning Points, in which writers explore what critical moments from \nthis year might mean for the year ahead. You can read more by visiting the Turning Points series page.\nThe following is an artist’s interpretation of the year — how it was or how it might be, through the lens of art.\nWhere does A.I. end and we begin? I’ve been thinking about this question — the line between machines and \nhuman creativity — for a long time. In my art, lines are governing elements over images. But what happens when \nthose lines are made by a machine?\nIn 2015, I began my journey in co-creation. It took two years to meticulously scan more than 20 years’ worth of my \ndrawings into a system I developed to train a recurrent neural network. The neural network drives the movements of \nD.O.U.G., short for Drawing Operations Unit: Generation 2, a robot I built to draw with me. We made our debut in \n2017. Today, I’m continuing to explore emerging technology — biosensors, computer vision, virtual reality and \ncustom machines. It’s been nearly a decade. I wonder, with all these technological adaptations, what will become of \nthe human hand?\nIn the years since the Covid-19 pandemic, I’ve seen colleagues close their artistic practices out of disillusionment or \npragmatism, often a combination of both. Yet, because of the proliferation of the digital art market of nonfungible \ntokens, cryptocurrency and generative artificial intelligence systems — technology that can produce images — \nI’ve seen the igniting of a new generation of digital artists, and witnessed new studios emerge and flourish.\nIt’s a strange time to make art. In 2023, industries were in revolt — from the 148-day screenwriters strike in the \nUnited States to artists rightfully condemning the use of A.I. training data without their consent. It’s not news that \nresearchers have cautioned against the dangers of bias in A.I.; that almost seems a given. Another problem is that \nnot everyone knows the hidden cost of accumulating the data involved in making sense of massive language \nmodels like OpenAI’s GPT-4. At the same time, linking prompts with image generation and coding has popularized \na new relationship between text and image. Now more people than ever can communicate through a visual \nmedium, a new entry point for learning to code. ChatGPT can function as a sidekick you can talk to, which can help \nbuild a sense of rapport between A.I. systems and humans.\nWith all the hype, it’s easy to forget that there’s no such thing as a single artificial intelligence because there’s no \nsuch thing as a single natural intelligence. I’ve come to think of my approach of learning through systems — \ndeemed intelligent or otherwise — as a creative catalyst. There is meaning in the data, but it’s not the meaning we \nare given; it’s the meaning we make.\nWhere Does A.I. End and We Begin? Turning Points: Guest Essay\nFor me, meaning-making and experimentation go hand-in-hand. In “Process Study - Structure from Motion,” I’m \nexperimenting with a new way of capturing an environment. The technique is called “gaussian splatting,” a diffuse \nscanning approach to 3-D space. It gleans structure from motion, yielding a dense representation of objects that, to \nmy eyes, also yields painterly and ghostly visual artifacts. I’m drawn to this approach because of its future \npossibilities — new applications of Embodied A.I. — as well as its effect in the present day. It shows the \nincompleteness of digital representation and the texture of the system as its own kind of beauty.\nThe themes of beauty and fragility ground my experimentations, often involving the sharing of the time and space of \nmaking art with machines. I’ve chronicled that evolution through performances, films and vignettes from my studio. \nFor me, drawing is a way of being in the world. When I draw and create with my machines, this creative process \nallows me to engage with the technology alongside my physical instincts to form a kind of gestural relation. Showing \nthe process in progress offers space for introspection.\nI’ve recently finished the fifth generation of my robotic journey. Still, I feel like we’re just getting started with this type \nof art and our understanding of the role of technology in art. From mimicry, to memory, to the collectivity of the \nurban environment, to the spectrality of biofeedback, each generation unlocks a new set of technical skills, creating \nstronger relationships between humans and machines. With each development, I find myself with more questions \nthan answers.\nAs I paint in collaboration with the robotic units in my studio, I’m hopeful that some of those tensions make their way \ninto the painted line, the visual artifact on canvas. When people react to my work, I am often asked, “Can A.I. be \ncreative?” But lately, I’m unsure if that’s the question we should be asking.\nArtists have the privilege of responding to the social and political moments of their day. I’ve been designing \nalternative forms of machines inspired by nature, with the bond between humans and machines as one of \necological stewardship. As I develop these forthcoming configurations, the drawn line is one constant that always \nremains at the center. It is a line that explores the potential of human and machine collaboration, speculating on \nhow the machine will act as a catalyst, co-pilot and companion. If I’ve learned anything in the past decade of this \njourney, it’s that art can help us ask better questions: Can fear and hope be held in the mind simultaneously? How \ndo we grasp the promise, perils and paranoias of technical shifts at once?\nWhere does A.I. end and we begin?\nSougwen Chung is a Chinese-Canadian artist and the founder and artistic director of Scilicet, a London-based \nstudio that works on examining human collaboration with machines.\nPHOTO: Sougwen Chung’s “Process Study - Structure from Motion” shows robotic units working in tandem with the \nartist in the London studio Scilicet. (PHOTOGRAPH BY Courtesy of Sougwen Chung FOR THE NEW YORK \nTIMES)\nLoad-Date: December 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I.’s Threat to Jobs Prompts Question of Who Protects Workers",
        "media": "The New York Times",
        "time": "June 28, 2023",
        "section": "BUSINESS",
        "length": "1680 words",
        "byline": "Emma Goldberg",
        "story_text": "A.I.’s Threat to Jobs Prompts Question of Who Protects Workers\nThe New York Times \nMay 23, 2023 Tuesday 18:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1680 words\nByline: Emma Goldberg\nHighlight: Tens of millions of jobs could be automated by generative artificial intelligence. The makers of new \ntechnologies are looking to the government to step in.\nBody\nTens of millions of jobs could be automated by generative artificial intelligence. The makers of new technologies \nare looking to the government to step in.\nWhen Congress held a series of hearings on jobs and technological advancement in October 1955, the head of a \nrailroad worker organization took the stand to express his fears about automation. “There is uneasiness among our \nworkers as they assess the advance of the new technology,” said W.P. Kennedy, president of the Brotherhood of \nRailroad Trainmen. “Will it bring increasing unemployment rather than economic security?”\nThe same question could have been raised before Congress last week in its hearing on artificial intelligence. In \neffect, it was.\nSam Altman, chief executive of the San Francisco start-up OpenAI, testified last Tuesday before members of a \nSenate subcommittee, urging the government to regulate the fast-growing A.I. industry. Congressional leaders \nshared their worries about the threats that A.I. could pose, including the spread of misinformation and privacy \nviolations.\nOne of their most emphatic concerns was job displacement: Who will assume responsibility to protect workers \nwhose jobs might be transformed, or even eliminated, by generative A.I.?\nSenator Richard Blumenthal, Democrat of Connecticut, declared that his “biggest nightmare in the long term” is the \njob loss that A.I. could cause, before saying to Mr. Altman, “Let me ask you what your biggest nightmare is.”\n“There will be an impact on jobs,” Mr. Altman replied. “And I think it will require partnership between the industry \nand government, but mostly action by government.”\nMr. Altman, like so many other executives unleashing new technologies on the world, has asked the government to \nassume the bulk of responsibility in supporting workers through the labor market disruptions prompted by A.I. It’s \nnot yet clear how government will rise to that task.\nGenerative A.I. could automate activities equivalent to 300 million full-time jobs globally, according to a recent \nestimate by Goldman Sachs. Already the chief executive of IBM said he expected A.I. to affect white-collar clerical \nstaffing, eliminating the need for up to 30 percent of certain roles while creating new ones. The White House on \nTuesday is hosting workers for a discussion of their experiences with automation and monitoring technologies in the \nworkplace.\nA.I.’s Threat to Jobs Prompts Question of Who Protects Workers\nHistorically, when automation has led to job loss, the economic impact has tended to be offset by the creation of \nnew jobs. Generative artificial intelligence, according to the Goldman report, could raise America’s labor \nproductivity growth by nearly 1.5 percentage points per year over a decade. It could increase annual global gross \ndomestic product by 7 percent. It could give rise to previously unimagined creative occupations.\nBut there will be immense instability for displaced workers. Automation has been a significant driver of income \ninequality in America, according to a study from researchers at the Massachusetts Institute of Technology and \nBoston University. By their estimates, 50 to 70 percent of changes in the U.S. wage structure since 1980 were due \nto loss of income among blue-collar and office workers because of automation.\nAreas of the country where robots have been adopted most intensively, particularly manufacturing-heavy parts of \nthe Midwest, have also seen the most precipitous declines in employment, according to research from Daron \nAcemoglu, an economist at M.I.T.\nWhile makers of A.I. have tended to focus on the technology’s potential for job creation, many workers will \nexperience painful disruption as they try to train for and find new roles that pay well and are fulfilling.\n“We’ve never been in a period where the scope of automation is so wide potentially,” said Harry Holzer, an \neconomist at Georgetown. “Historically if your job gets automated, you find something new. With A.I. the thing that’s \nkind of scary is it could simply grow and take over more tasks. It’s a moving target.”\nWorkers in administrative and clerical support may have particular cause for concern about generative A.I., \naccording to the Goldman research. And many of them are already expressing anxieties.\n“It’s definitely scary,” said Justin Felt, 41, a customer service worker in Pittsburgh, who has worked for Verizon Fios \nfor nearly 12 years. He feels that employers have not been entirely upfront with their workers about the ways they \nare incorporating generative A.I. into customer support roles, he said. “It’s definitely taking our work.”\nThese technologies are flooding into workplaces at a rapid clip. BuzzFeed just introduced a chatbot that offers up \nrecipe recommendations, McKinsey is helping clients use A.I. to fix technological bugs and the accounting firm \nKPMG is using ChatGPT to generate code. So some economists have begun putting forward proposals to protect \nthe workers most likely to be affected.\nWorkers could benefit, for example, from paid leave policies that allow them to take time away from their jobs to \ndevelop new skills. Germany already has a similar program, in which workers in most German states can take at \nleast five paid days a year for educational courses, an initiative the labor minister recently said he planned to \nexpand.\nAnother possibility is a displacement tax, levied on employers when a worker’s job is automated but the person is \nnot retrained, which could make businesses more inclined to retrain workers. The government could also offer A.I. \ncompanies financial incentives to create products designed to augment what workers do, rather than replace them \n— for example, A.I. that provides TV writers with research but doesn’t draft scripts, which are likely to be of low \nquality.\n“If the government sets the agenda in developing technologies that are more complementary to humans, that would \nbe very important,” Mr. Acemoglu said. “Industry is looking to the government for leadership.”\nThe government’s previous efforts to support workers through periods of job displacement have had mixed results. \nA study of Trade Adjustment Assistance, a U.S. government program that provides financial assistance and training \nfor workers who lose jobs because of trade, found that manufacturing employees who temporarily dropped out of \nthe work force to participate in the program in the early 2000s still hadn’t caught up on earnings several years later \ncompared with workers who lost jobs but didn’t qualify for T.A.A. support.\nMany economists say employers could also play a role in helping displaced workers.\nA.I.’s Threat to Jobs Prompts Question of Who Protects Workers\n“Business always looks to government to deal with job loss,” said Simon Johnson, a professor at M.I.T. and a co-\nauthor with Mr. Acemoglu of the book “Power and Progress.” “But Microsoft and Alphabet — they are in the driver’s \nseat, in regards to where they choose to put their technological resources.”\nWorkers could benefit, for example, from employer apprenticeships and retraining programs. The accounting giant \nPwC recently announced a $1 billion investment in generative A.I., which includes efforts to train its 65,000 \nworkers on how to use A.I. What spurred the initiative was the chief executive’s trip to the World Economic Forum’s \ngathering in Davos, Switzerland, where he heard constant discussion of generative A.I.\n“A number of us walking out of that room knew something had changed,” recalled Joe Atkinson, the company’s \nchief products and technology officer.\nPwC’s workers have expressed fears about displacement, according to Mr. Atkinson, especially as their company \nexplores automating roles with generative A.I. Mr. Atkinson stressed, though, that PwC planned to retrain people \nwith new technical skills so their work would change but their jobs wouldn’t be eliminated.\nSome tech companies are offering employees courses in cloud computing, cybersecurity and generative A.I. \nAmong them is IBM, which also has an apprenticeship program that trains workers, including those without four-\nyear degrees, for high-paying roles in fields like software development and data science. The company C3 AI offers \nits 1,000 employees bonuses of $250 to $1,500 for becoming certified in technological subjects including A.I. and \ncloud computing. KPMG is working to train every one of its employees to use generative A.I.\nCommunity colleges are intensifying their focus on A.I., too. Miami Dade College has received over $15 million in \ngrants for its technology programs, with some of the money used to open two centers focused on preparing \nstudents for careers in A.I. Houston Community College recently announced a bachelor’s degree in A.I. and \nrobotics, and Southwest Tennessee Community College is working to create an associate degree. The American \nAssociation of Community Colleges launched an A.I. incubator network focused on helping faculty teach about A.I. \nand colleges create A.I. degrees.\n“As Wayne Gretzky once said when asked about his success, ‘I skate to where the puck is going,’” said Dennis \nNatali, a professor at Pikes Peak State College in Colorado, which released a plan this year to roll out A.I. \ncertificates. “Our college constantly assesses the work force landscape and prepares to support displaced workers.”\nAs colleges and businesses scramble to retrain workers, some experts are optimistic about this technological \ntransition. They note that throughout history people have feared technological advancement but often ended up \nbenefiting from it, going back to the Luddites, weavers who protested the mechanization of the textile industry.\nBut that doesn’t mean the transition period will unfold smoothly. Michael Chui, an A.I. expert at McKinsey, pointed \nout that even the Luddites saw their income stagnate for decades.\n“Anyone who loses their job involuntarily — it’s a difficult time,” he said. “In some ways the Luddites weren’t wrong \nabout the risk.”\nAudio produced by Jack D’Isidoro.\nAudio produced by Jack D’Isidoro. \nPHOTO: Senator Richard Blumenthal, left, with Sam Altman, chief executive of OpenAI, before a hearing on A.I. \nlast week. (PHOTOGRAPH BY PATRICK SEMANSKY/ASSOCIATED PRESS) (B4) This article appeared in print \non page B1, B4.\nLoad-Date: June 28, 2023"
    },
    {
        "file_name": "Says_Jun2023",
        "header": "Generative A.I. Can Add $4.4 Trillion in Value to Global Economy, Study",
        "media": "Says",
        "time": "June 14, 2023",
        "section": "TECHNOLOGY",
        "length": "619 words",
        "byline": "Yiwen Lu",
        "story_text": "Generative A.I. Can Add $4.4 Trillion in Value to Global Economy, Study \nSays\nThe New York Times \nJune 14, 2023 Wednesday 09:40 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 619 words\nByline: Yiwen Lu\nHighlight: The report from McKinsey comes as a debate rages over the potential economic effects of A.I.-powered \nchatbots on labor and the economy.\nBody\nThe report from McKinsey comes as a debate rages over the potential economic effects of A.I.-powered chatbots \non labor and the economy.\n“Generative artificial intelligence” is set to add up to $4.4 trillion of value to the global economy annually, \naccording to a report from McKinsey Global Institute, in what is one of the rosier predictions about the economic \neffects of the rapidly evolving technology.\nGenerative A.I., which includes chatbots such as ChatGPT that can generate text in response to prompts, can \npotentially boost productivity by saving 60 to 70 percent of workers’ time through automation of their work, \naccording to the 68-page report, which was published early Wednesday. Half of all work will be automated between \n2030 and 2060, the report said.\nMcKinsey had previously predicted that A.I. would automate half of all work between 2035 and 2075, but the power \nof generative A.I. tools — which exploded onto the tech scene late last year — accelerated the company’s \nforecast.\n“Generative A.I. has the potential to change the anatomy of work, augmenting the capabilities of individual workers \nby automating some of their individual activities,” the report said.\nMcKinsey’s report is one of the few so far to quantify the long-term impact of generative A.I. on the economy. The \nreport arrives as Silicon Valley has been gripped by a fervor over generative A.I. tools like ChatGPT and Google’s \nBard, with tech companies and venture capitalists investing billions of dollars in the technology.\nThe tools — some of which can also generate images and video, and carry on a conversation — have started a \ndebate over how they will affect jobs and the world economy. Some experts have predicted that the A.I. will \ndisplace people from their work, while others have said the tools can augment individual productivity.\nLast week, Goldman Sachs released a report warning that A.I. could lead to worker disruption and that some \ncompanies would benefit more from the technology than others. In April, a Stanford researcher and researchers at \nthe Massachusetts Institute of Technology released a study showing that generative A.I. could boost the \nproductivity of inexperienced call center operators by 35 percent.\nAny conclusions about the technology’s effects may be premature. David Autor, a professor of economics at M.I.T. \ncautioned that generative A.I. was “not going to be as miraculous as people claim.”\nGenerative A.I. Can Add $4.4 Trillion in Value to Global Economy, Study Says\n“We are really, really in the early stage,” he added.\nFor the most part, economic studies of generative A.I. do not take into account other risks from the technology, \nsuch as whether it might spread misinformation and eventually escape the realm of human control.\nThe vast majority of generative A.I.’s economic value will most likely come from helping workers automate tasks in \ncustomer operations, sales, software engineering, and research and development, according to McKinsey’s report. \nGenerative A.I. can create “superpowers” for high-skilled workers, said Lareina Yee, a McKinsey partner and an \nauthor of the report, because the technology can summarize and edit content.\n“The most profound change we are going to see is the change to people, and that’s going to require far more \ninnovation and leadership than the technology,” she said.\nThe report also outlined challenges that industry leaders and regulators would need to address with A.I., including \nconcerns that the content generated by the tools can be misleading and inaccurate.\nMs. Yee acknowledged that the report was making prognostications about A.I.’s effects, but that “if you could \ncapture even a third” of what the technology’s potential is, “it is pretty remarkable over the next five to 10 years.”\nThis article appeared in print on page B6.\nLoad-Date: June 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "China Rises As Producer Of Talent In A.I. Field",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1090 words",
        "byline": "By Paul Mozur and Cade Metz",
        "story_text": "China Rises As Producer Of Talent In A.I. Field\nThe New York Times\nMarch 23, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1090 words\nByline: By Paul Mozur and Cade Metz\nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.\nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead. \n  New research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world's top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.\n  The findings show a jump for China, which produced about one-third of the world's top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022's Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.\n  The talent imbalance has been building for the better part of a decade. During much of the 2010s, the United \nStates benefited as large numbers of China's top minds moved to American universities to complete doctoral \ndegrees. A majority of them stayed in the United States. But the research shows that trend has also begun to turn, \nwith growing numbers of Chinese researchers staying in China.\n  What happens in the next few years could be critical as China and the United States jockey for primacy in A.I. -- a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation -- turning the \nresearchers into one of the most geopolitically important groups in the world.\n  Generative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China's researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.\n  (The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)\nChina Rises As Producer Of Talent In A.I. Field\n  China has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.\n  ''A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that's come to dominate the American A.I. industry at the moment,'' he said.\n  While the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.\n  Researchers originally from China now make up 38 percent of the top A.I. researchers working in the United \nStates, with Americans making up 37 percent, according to the research. Three years earlier, those from China \nmade up 27 percent of top talent working in the United States, compared with 31 percent from the United States.\n  ''The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,'' said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.\n  He added that the data seemed to show the United States was still attractive. ''We're the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,'' he said.\n  Pieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.\n  ''It's just a natural state of affairs,'' he said.\n  In the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.\n  Despite bans introduced by the Trump administration that prohibit entry to the United States for students from \nsome military-linked universities in China and a relative slowdown in the flow of Chinese students into the country \nduring Covid, the research showed large numbers of the most promising A.I. minds continued coming to the United \nStates to study.\n  But this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology -- including critical microchip architecture -- to a Beijing-based company that paid him in secret, \naccording to a federal indictment.\n  The substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.\n  ''Chinese scholars are almost leading the way in the A.I. field,'' said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are ''shooting themselves in the foot.''\n  The track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.\n  For now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world's top talent, down from about 59 percent three years ago, according to the research.\nChina Rises As Producer Of Talent In A.I. Field\nhttps://www.nytimes.com/2024/03/22/technology/china-ai-talent.html\nGraphic\n \nPHOTO: A camera using artificial intelligence at a coal mine in Heze, China. Beijing has invested heavily in A.I. \neducation. (PHOTOGRAPH BY MARK R CRISTINO/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in \nprint on page B1, B4.               \nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Silicon Valley'Sreincration",
        "media": "The New York Times",
        "time": "June 4, 2023",
        "section": "Section MM; Column 0; Magazine Desk; Pg. 18; THE CALIFORNIA ISSUE",
        "length": "4184 words",
        "byline": "By Yiren Lu",
        "story_text": "Silicon Valley'Sreincration\nThe New York Times\nJune 4, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section MM; Column 0; Magazine Desk; Pg. 18; THE CALIFORNIA ISSUE\nLength: 4184 words\nByline: By Yiren Lu\nBody\nThe archbishop's mansion in San Francisco, built in 1904, is now a stately hotel at the northeast corner of Alamo \nSquare Park. Since February, it has been rented out entirely to HF0, or Hacker Fellowship Zero, a start-up \naccelerator that provides 12-week residencies for batches of fellows from 10 different start-ups. Their experience, \nwhich culminates in a demonstration day, is supposed to be the most productive three months of the fellows' lives. \nDave Fontenot, one of HF0's founders, was inspired by the two years he spent living in monasteries in his 20s: \nWhile monastery life was materially ascetic, he found that it was luxurious in the freedom it gave residents to focus \non the things that really mattered. And at the Archbishop's Mansion this year, almost everyone has been \nmonastically focused on what has become San Francisco's newest religion: artificial intelligence.\nThe A.I. gospel had not yet spread in 2021, when Fontenot and his two co-founders, Emily Liu and Evan Stites-\nClayton, started the accelerator. Even a year ago, when HF0 hosted a batch of fellows at a hotel in Miami, six out of \nthe eight companies represented were cryptocurrency start-ups. But at the mansion in San Francisco, eight of the \n10 companies in HF0's first batch this year were working on A.I.-based apps, and the lone crypto start-up -- focused \non what happens to your Bitcoin when you die -- was worried, they told me, about whether the investors who \nshowed up at this spring's demo day would actually want to invest in them. \n  That generative A.I. has largely supplanted crypto in the eyes of founders and venture capitalists alike is not \nexactly surprising. When OpenAI released ChatGPT late last year, it sparked a new craze at a time when the \ncollapsing crypto and tech markets had left many investors and would-be entrepreneurs adrift, unsure of where to \nput their capital and time. Suddenly users everywhere were realizing that A.I. could now respond to verbal queries \nwith a startling degree of humanlike fluency. ''Large language models have been around for a long time, but their \nuses were limited,'' says Robert Nishihara, a co-founder of Anyscale, a start-up for machine-learning infrastructure. \n''But there's a threshold where they become dramatically more useful, and I think now it's crossed that.''\n  One appeal of generative A.I. is that it offers something for every would-be entrepreneur. For the technically \nminded, there is research to be done. For the business types, it's easy to create applications on top of the OpenAI \nplatforms. For the philosophically inclined, A.I. offers interesting avenues through which to explore what it means to \nbe conscious and human. And unlike crypto, especially now, A.I. is a more credible field to be in for mainstream \ntechies. Its products have already achieved significant traction among consumers -- ChatGPT is believed to be the \nfastest app ever to hit 100 million users -- and some of the figures at its forefront are familiar faces, now in their \nsecond acts, like Sam Altman, formerly the president of the start-up accelerator Y Combinator, and Greg Brockman, \nformerly the chief technology officer at Stripe, the payments-processing company. In short, you can't help thinking \nthat, as one friend recently proclaimed to me, ''Everyone in S.F. is either starting or running an A.I. company or \nstarting or running an A.I. fund.''\nSilicon Valley'Sreincration\n  A.I., in turn, seems to love San Francisco back. During the pandemic, as tech workers went remote and Twitter \npundits evangelized the tax benefits of being in Austin or Miami, the San Francisco area seemed poised to cede its \nstart-up primacy. But recently that trend has reversed. There's a sense that if you want to be working in A.I., this is \nstill the place to be. ''We actually first considered doing the batch in New York, but when I went to New York and \nasked people what they thought of GitHub Copilot'' -- an A.I.-powered coding assistant -- ''people told me they \nmaybe tried it once,'' Fontenot said. ''On the other hand, people in S.F. told me they were using it to write 50 \npercent of their code.''\n  Fontenot's anecdote gets at one of Silicon Valley's enduring qualities: the willingness, even eagerness, to \nembrace new technology. Out in the rest of the world, A.I. is triggering nerves -- fears and even predictions of \nwiped-out jobs, of existential doom -- and endless commentary. In San Francisco, it has kindled all these things too, \nbut also a question just as powerful: How do you get a piece of it?\n  During the day, the Archbishop's Mansion often feels surprisingly empty and quiet, perhaps because it's so large. \nThere are four floors and a grand staircase that winds up through the middle of the building, lit by a giant skylight. \nMany of the teams work in their rooms upstairs; some teams work in the ''hackspace'' in the basement, with its \nwhiteboards and rows of standing desks. When I was visiting this spring, one wall displayed some ChatGPT-\ngenerated poetry: ''In HF0, the hackers work and play/With laughter and fun, throughout the day./They're a \ncommunity of techies, with a heart of gold,/And their humor and hacking skills, never grow old.''\n  But on a spring Friday night -- the one night of the week when the broader tech community is welcomed in -- the \nA.I. party was in full swing. Fontenot and Liu bounded around the common spaces at the front of the mansion, \ngiving out effusive hellos and introductions.\n  In one back room, a bar served elixirs. (The mansion is a no-alcohol zone.) In another, an A.I. rap battle raged. (It \nwasn't much of a battle, actually -- while the A.I. is no Eminem, it was still destroying everyone.) In a third, Jonathan \nShobrook, a fellow, was demoing his product, Adrenaline, a tool that lets you ask natural-language questions of \nyour code base. He had the interface up on a monitor and a small cluster of spectators around him, seemingly \nriveted.\n  ''Can you ask it to implement ReLU?'' Sasha Sheng asked. Sheng, a former software engineer at Facebook, is \nnow working on her own app; in dyed pigtails and a baseball cap, she is something of a personality in the \ncommunity.\n  ''Oh, yeah, that's a hard question,'' Shobrook responded. On his keyboard, he typed, ''Which neural networks use \nReLU?''\n  The right answer flashed on the screen, the cursor blinking as characters appeared. Someone asked how it \nworked.\n  ''I just basically chunked up all the files into functions and classes and groups of code, generated summaries of \nthose code chunks and then recursively summarized the file,'' Shobrook said.\n  ''Do you use an abstract syntax tree?''\n  Only in San Francisco would people be talking about abstract syntax trees at 9 p.m. on a Friday night.\n  Out in the main entryway, someone introduced himself as Bruno. I asked him whether he was in A.I. ''My first two \ncompanies were in A.I., but now I'm in crypto,'' he said jovially. Fontenot came up from behind and slung an arm \nover his shoulders. ''I'm not popular anymore, no one wants to talk to me,'' Bruno fake-moaned. But he didn't seem \ndeeply bothered by crypto's abrupt comedown and A.I.'s ascendance. Bruno, it turned out, was Bruno Faviero, a \nwell-known investor and entrepreneur. He and Fontenot have been buddies since they met as college students, \nwhen each of them was organizing hackathons. After Fontenot left school in 2013 -- he dropped out of the \nUniversity of Michigan, where he was studying computer science -- he continued to run hackathons and networked \nin the tech world as Faviero built his first company.\nSilicon Valley'Sreincration\n  ''Four years ago, he called me to say that he was raising a fund,'' Faviero told me. ''I was like, 'Yeah, whatever, \neveryone is raising a fund.' A week later, he calls me and is like, 'Hey, the fund is oversubscribed, do you still want \nto put in a check?' If Dave says he's going to do something, he does it.''\n  Or, as Emily Liu put it to me, ''You show up to one of Dave's things as a friend, and 10 minutes later you're \nwearing a staff shirt.''\n  Fontenot is charismatic, a forceful speaker with wild hair. Like all good venture capitalists -- he is a general partner \nin the investment firm Backend Capital -- he has an unerring nose for the thing of the moment, be it blockchain or \nA.I. That he seems agnostic about whether it's blockchain or A.I., or some other underlying technology, is almost \nbeside the point. In many ways, he personifies the modern Silicon Valley dichotomy between spirituality and hustle, \nbetween monasticism and flamboyance. His expertise, he believes, is people.\n  ''We look for three things -- grit, storytelling ability and product sense,'' he said, describing the selection process for \nthe fellows. Notably absent from this list, I pointed out, was a background in machine learning. Fontenot shrugged. \nThis generation of start-ups doesn't have to come up with its own cutting-edge research. Big companies like \nOpenAI and Google will provide that. Instead, he said, the fellows need the ability to build prototypes quickly on top \nof the new models.\n  And, in fact, the unifying thread among the first batch of 2023 fellows was their experience at that sort of \nenterprise. The average age was 28 (Fontenot is 30), and several of them were second-time founders. Adam Reis \nis a founder of Candid Health, which provides medical-billing software. Emma Salinas founded an online community \ncalled Gen Z Mafia. While various fellows often talk about how they've long been interested in A.I., it's clear that \nsome of the ''why now'' is opportunistic.\n  But if the people at hackathons and programs like HF0 tend to be newcomers to A.I., this doesn't preclude their \nsuccess: The consensus is that building things in the A.I. field isn't as complex as working in biology, say; you don't \nneed to get a separate Ph.D. in it. If you're already good at math and good at engineering and good at business, \nthere are few limits to what you can do.\n  A few themes characterize the sorts of projects the HF0 fellows have been working on. On the one hand, there are \napplications to automate tedious business tasks like copywriting or spreadsheet wrangling. A company called \nFileread falls into this category. Its law-firm customers upload all the documents relevant to a particular case into an \nonline portal; Fileread indexes those documents into a special database that enables users to search the \ndocuments not only for exact terms like ''truck'' or ''James,'' but also for broader questions like ''who made the \ntransaction?'' or ''what are the relevant cases?'' Under the hood, Fileread first fetches the most relevant documents \nfrom its database, then adds those documents to a user's question and sends the whole, long query to the OpenAI \napplication programming interface, or A.P.I. Fileread then spits out an answer, powered by the same large \nlanguage models behind ChatGPT.\n  Without A.I., identifying and crafting a legal narrative by piecing together textual evidence from thousands of \nsources is a painstakingly manual process. Most of Fileread's customers specialize in business litigation, including \nantitrust and liability cases. Sometimes they are paid on contingency, which means when they succeed, they \ntypically get a percentage of the award or settlement, but when they lose, they get nothing. Firms need the A.I. to \nefficiently search for evidence in the documents that might, for example, either establish or refute liability. ''They \ndon't have the manpower or the budget to do unlimited document review,'' says Chan Koh, a Fileread founder and \nan HF0 fellow. ''They want to spend the minimal amount of effort in order to win the case.''\n  Other HF0 fellows have been creating applications that lean into A.I.'s seemingly human affect in order to tackle \nsome psychological need. For instance, Brian Basham, who has worked in Google's Brain division and since 2018 \nhas been a life coach in California, is working on Thyself, a subscription service for ''guided emotional inquiry'' that \ncurrently uses A.I. and human coaches but will eventually transition fully to A.I. I met him and his employee \nMaverick Kuhn over dinner one night at the Archbishop's Mansion. After Kuhn waxed rhapsodic about a four-week-\nlong retreat he attended last summer, called Sleepawake, I asked him whether the experience would have been as \nSilicon Valley'Sreincration\ngreat if the facilitators had said and done all the same things but been A.I.'s. ''Probably not,'' he conceded. ''That \nwould very much be a disembodied head.''\n  One-on-one life coaching from the current human-A.I. hybrid version of Thyself costs $50 an hour. Once the \nservice is fully automated, Basham expects to be able to offer unlimited sessions for $30 a month. At that price, he \nbelieves, it would be broadly accessible.\n  A few days later, I did my first Thyself session. Mostly it consisted of the bot asking me to visualize scenarios -- \nremembered or imagined scenes -- and then to describe the physical sensations and emotions that resulted from \n''surfing the emotional wave.'' I didn't feel much of an emotional wave, but I was impressed by how natural it felt to \nspeak to an A.I.-filtered guide. Compared with calling, say, the automated hotline for a cell-service provider, it was a \nvast improvement, although it did tend to talk over me.\n  Evan Stites-Clayton, an HF0 founder (and a fellow in the accelerator's inaugural batch), has come up with a \nsimilarly intimate product, an A.I. assistant called Consort. To try it out, I had to go through a 15-minute quasi-\ntherapy session, where I was asked about my childhood, my relationship to my parents and my favorite books. A \nfew hours after my responses were fed into the A.I., Stites-Clayton -- who was a founder of Teespring (now Spring), \na platform that sells custom-made T-shirts and other merchandise -- sent me a link to my ''consort,'' which I could \nthen text. Over the course of the next couple of days, it texted me a daily message at midnight, reminding me to \nwind down for the night. On the weekends, it asked me whether I was planning to go out. The texts included \nappropriately casual spelling and (lack of) punctuation. I found myself warming to it, despite an earlier prejudice \nagainst becoming friends with A.I.\n  A.I. and emotional regulation might seem like an odd juxtaposition, but it makes sense that emotional labor -- at \nthe end of the day, just another form of labor -- could be one of the first job categories to be transformed by \nautomation. And yet, setting aside its effectiveness, there's something odd about using A.I. to manage our human \nbrains when it's not clear that the A.I. brain is at all similar to ours. ''We're obviously trying to anthropomorphize A.I., \nmake it in our image,'' said Matthew Rastovac, the founder of Respell, a tool that lets you create A.I. apps without \ndoing any coding. ''Because we don't really know how else to build and understand a new kind of intelligence. But I \nthink it's much more likely that it's going to be like a reptile, in that it has its instincts, but we can't understand what's \ngoing on inside its brain and listen to its actual thoughts.'' We were sitting on the roof of Atmosphere, a hacker \nhouse in Nob Hill that he helped found; all around us, San Francisco was enchanting in the afternoon light. Earlier, \nhe paraphrased for me some lines that he liked from Season 2 of ''Westworld'' that spoke to how early we still are, \nand how blinkered, when it comes to understanding this technology: ''Sanity is a very narrow sliver of the \npossibilities of mind. Because we have culturally accepted norms, we have a certain way of acting and thinking and \nspeaking, and if you deviate from that a little too much, then you're, at best, weird, and at worst, clinically insane.''\n  During the week I spent staying at HF0, everyone told me I had to make it down to the South Bay for the A.G.I. \nHouse GPT-4 hackathon. The organizers asked me to come after 6 p.m., though, so as to not distract the hackers \nbefore it started.\n  A.G.I. stands for artificial general intelligence, a phrase that has come to represent a potential dream goal for A.I.: \na machine intelligence with the flexibility to handle any intellectual task that humans can. A.G.I. House, it turns out, \nis a $68 million mansion in the small town of Hillsborough, 25 minutes from downtown Palo Alto. The mansion has a \nlong thoroughfare of ferns out front, a pool and a barbecue pit in the back. Rocky Yu, previously the chief executive \nof an augmented-reality start-up, runs A.G.I. House, overseeing both its 10 residents and a raft of community \nevents. He is warm and smiley and exceedingly well connected in the local A.I. community.\n  The crowd at that night's GPT-4 hackathon was so large as to render the Wi-Fi basically nonfunctional. Every \nroom overflowed with hackers crowding around whiteboards. In the kitchen, Chinese takeout was laid out on a \ntable. A smattering of investors were present to check out the demos, which started at 8 p.m. with short speeches \nfrom the organizers. The speeches were all variations on a theme: We are living in a momentous time. Maybe in a \nfew decades from now, we'll look back at all these seminal A.I. achievements and see that they all came from this \nhouse in Hillsborough.\nSilicon Valley'Sreincration\n  As at HF0, the demos here alternated between business uses and personal applications -- a chatbot that \nimpersonates business gurus like Mark Cuban, the owner of the Dallas Mavericks basketball team and a judge on \n''Shark Tank,'' the business-reality TV show, and that allows you to ask for business advice; or an A.I. sommelier \nthat will take your dinner menu and suggest an appropriate wine pairing. Six months ago, any one of these projects \nmight have seemed remarkable, but the arrival of ChatGPT has remade expectations. ''The one pattern I'm starting \nto see is that ChatGPT is the killer app,'' the technologist Diego Basch has written on Twitter. ''None of the tools \nbuilt on top of the A.P.I. have been as useful to me.'' Indeed, if you are building something on top of OpenAI's \nA.P.I., it does seem as though your app's marginal value has to be extremely high if it is to avoid being bulldozed by \neither OpenAI itself or one of the big tech companies like Google and Microsoft (or even later-stage start-ups that \nare rapidly rolling out A.I.-enabled features in their products).\n  As two analysts at N.E.A., an investment firm, put it in a recent report, generative A.I. may not be as disruptive to \nestablished businesses, and beneficial to start-ups, as previous big shifts in tech platforms. ''Unlike with the prior \nshifts, incumbents do not need to re-architect their entire products to adopt this new platform shift,'' the analysts \nwrote. ''In addition, this shift favors companies with bigger, proprietary data sets which can give an edge to more \nestablished companies.''\n  During previous tech eras, start-ups could introduce a superior technology or interface and then race to build \nmarket share before entrenched competitors could match them. But with large language models, incumbents like \nGoogle and Microsoft have had a huge head start in both developing the technology and acquiring market share \namong consumers. The situation risks becoming like that of the pharmaceutical industry, in which research and \ndevelopment is outsourced to start-ups and many of the benefits ultimately accrue to the parent company. \nMoreover, the capital-intensive nature of training large language models means that smaller companies like OpenAI \nand Anthropic creating their own large language models have few alternatives beyond making Faustian \n''partnerships'' with tech giants.\n  This doesn't mean that generative A.I. isn't going to transform industries or eliminate jobs. Beyond the \nincumbents, one beneficiary might well be the indie hacker, the kind of coder for hire who does niche A.I. projects to \nfill specific needs in specific industries. Problems that have been too esoteric to solve or work flows that have been \ntoo complicated to improve might become easily automated with the help of ChatGPT. As the Gumroad founder \nSahil Lavingia recently put it on a podcast, ''If I had a friend who's like, 'I want to make 200K a year, building \nsomething in S.A.S.''' -- software as a service -- '' 'building some A.I. tool,' I would basically tell them to walk around \ntheir neighborhood, go to as many businesses as possible and see what manual thing, what piece of paper you \nsign, and figure out how to automate that.''\n  That the era of V.C.-backed, outsize returns might be coming to an end is, of course, a source of anxiety. \nEveryone in Silicon Valley knows someone who worked at the last generation of successful start-ups, start-ups \nwhose growth followed the proverbial hockey-stick line on a graph, and reaped the benefits. Who doesn't want to \nget their share -- whether money, status, fame -- before it all runs out? This anxiety is compounded by the fact that \nit feels as if the deterioration of the physical world is happening roughly at a pace with the flourishing of the virtual \none, and the only way to insulate yourself is by achieving vast financial success. In some ways, San Francisco \nperfectly embodies this tension: A.I. is moving toward A.G.I., but outside the high-end tech offices, there is rampant \nhomelessness, house prices are so high that even couples with two tech incomes can't afford to buy property and \nchildren are sufficiently rare as to make them a spectacle.\n  But the anxiety runs deeper than concerns about success, prestige or even material safety. Change has always \nbeen accompanied by hand-wringing, and the pace of change in A.I. right now is mind-bending. The resulting mood \nis perhaps best encapsulated by tweets from Tiago Forte, the productivity guru known for a self-help system called \nSecond Brain. ''I'm feeling a broad loss of motivation for many projects and goals that used to excite me due to \nwhat I'm seeing with A.I.,'' Forte posted in April. ''It's not fear of A.I. apocalypse or fear that I'll lose my job or \nanything like that. ...More like a feeling of grief that many of the personal skills & qualities I've spent a lot of time \ndeveloping have suddenly been devalued.''\nSilicon Valley'Sreincration\n  This, of course, is not a new kind of ennui. It has always been a bewildering experience to lose your livelihood \nbecause of technological change; Silicon Valley has just generally been on the right side of it. For the first time, \nsuch change heralds an era in which software engineers themselves may be less well compensated and less in \ndemand. After years of disrupting other industries, Silicon Valley has disrupted itself.\n  Back at the Archbishop's Mansion, 52 general partners from the Valley's top venture-capital funds were in \nattendance as the year's first batch of HF0 fellows made their presentations at demo day on April 4. A few days \nlater, Fontenot posted a behind-the-scenes video of the event. It started with drone footage zooming in on the \nmansion, then cut to a close-up of Adam Reis, a fellow, jittery with nerves before his presentation. ''Y'all, this room \nis [expletive] stacked,'' Fontenot said in the video. ''Sequoia's here, Benchmark's here, [expletive] a16z is here. \nEveryone's here. So anyone you would want to meet, they're here. And they're excited.'' He was wearing a pink, \nwoolly winter hat with a pom-pom, inexplicably, and he sounded like Caesar rallying the troops.\n  Two weeks after demo day, all 10 teams had received initial offers from outside investors and some had chosen \nlead investors. Fontenot was optimistic. HF0's next batch, to be hosted again at the mansion, was set to begin in \nMay, and as he was reviewing applications, he texted me, ''The talent coming in now is insane.''\n  A few days later, I saw on Twitter that a friend of mine, Travis Fischer, would be joining the next HF0 batch. He \nand I last hung out in real life two years ago. At the time, the hot thing was the ''creator economy,'' and he was \nlooking to develop tools that would enable people, particularly open-source software developers, to monetize their \nwork. While that effort, in the end, wasn't fruitful, last year he started a series of side projects in A.I. These included \ncoming up with a way for other developers to use the ChatGPT A.P.I. so they can more easily incorporate large \nlanguage models into their products.\n  Travis no longer talks as much about the creator economy; at HF0, he is now working on an open-source \nframework for building reliable A.I. agents that do things such as booking airplane tickets or submitting tax \ndocuments. But despite the shifts in theme, my sense is that what he's passionate about -- making tools for the \nopen-source community -- hasn't changed. He has just found a way to come at it from a different angle. And in that \nadaptability, that ability to reinvent himself while coming out on top, he resembles Silicon Valley itself.\n  Yiren Lu is the chief executive of Frindle, a technical writing agency. She last wrote for the magazine about \nresearchers' designing and mass-producing genetic material. Laura Morton is a photographer based in San \nFrancisco. A Pierre & Alexandra Boulat Grant recipient, she has been documenting tech start-up culture since \n2014.\nhttps://www.nytimes.com/2023/05/31/magazine/ai-start-up-accelerator-san-francisco.html\nGraphic\n \nPHOTOS: Opening pages: Emily Liu (center) and Dave Fontenot, two co-founders of the start-up accelerator HF0, \nwith Marylin Ma, a member of its latest batch of fellows, in San Francisco. (MM19)\nAbove: Rocky Yu, founder of A.G.I. House, a start-up incubator in Hillsborough, Calif., with housemate Dina Yerlan. \n(MM21)\nDave Fontenot (in hat) and several HF0 fellows at the Archbishop's Mansion before the start of demo day, in which \nprojects are presented to potential investors. (MM22)\n Michaela Carmein getting dressed as a robot from the year 2043, with Lucas Gaylord and Emily Liu before the start \nof demo-day activities. (PHOTOGRAPHS BY LAURA MORTON FOR THE NEW YORK TIMES) (MM23) This article \nappeared in print on page MM18, MM19, MM20, MM21, MM22, MM23.               \nSilicon Valley'Sreincration\nLoad-Date: June 4, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "See Volatility in Near Term: Chandra",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 30, 2023",
        "section": "FRONT PAGE",
        "length": "771 words",
        "byline": "Our Bureau",
        "story_text": "See Volatility in Near Term: Chandra\nEconomic Times (E-Paper Edition)\nJune 30, 2023 Friday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 771 words\nByline: Our Bureau\nHighlight: Co got 2 whistleblower plaints from India, US on favouritism; 3 more staffers under probe\nBody\nCHANDRA'S FIRST PUBLIC COMMENTS ON 'JOBS SCAM'\nMumbai: Tata Consultancy Services (TCS) has sacked six employees and blacklisted as many staffing firms \nfollowing complaints about discrepancies in its recruitment process, Tata Sons chairman N Chandrasekaran told \nshareholders at the company's 28th annual general meeting on Thursday.  Investigations are ongoing into the \nconduct of three more employees, he said. In his first public comments on the “recruitment scandal” at India's \nlargest IT exporter, Chandrasekaran said TCS received two whistleblower complaints — one from India and one \nfrom the US — alleging “favouritism” in the recruitment of business associates. The compa-  ny's employees were \nfound to be “favouring” certain staffing firms unethically, he said. \nThe Mumbai-headquartered company works with over 1,000 staffing firms for recruitment of contractual staff. TCS's \nresource management division identified in the complaint handles 2-3% of the overall subcontracting requirements.  \n“The company will (re)look at the whole business associate supplier management process and see what the \nweaknesses are and completely tighten the process to ensure we do not have such incidents (again),” \nChandrasekaran said in his virtual address to shareholders. Noting that TCS has performed well overall despite \nmacro-economic challenges, Chandrasekaran cautioned that while he expects strong growth in the medium to long \nterm, “in nearby quarters, there will be volatility in different markets on the customer spend, especially on \ndiscretionary projects and it will go across sectors”, he said. Pointing to the intense geopolitical andeconomic \nvolatility in fiscal 2023 including the ongoing RussiaUkraine conflict, the Tata Sons Chairman said these issues \nhave disrupted the smooth functioning of global supply chains, and there is asurge in inflation, especially in the \ndeveloped markets. He said the global GDP is estimated to grow at around 2.9% in 2023, adding that discretionary \nspending will continue to remain under pressure. Responding to shareholder concerns on higher attrition among \nwomen employees at the company, Chandrasekaran defended what he termed as TCS's “women-friendly policies” \nand said the company is going through an exercise to determine the future of work over the next decade. He also \npointed to signifi-  cant focus on researching artificial intelligence (AI)-led technology, while stressing the need for it \nto be used responsibly. Transiting to AI has become a central focus for TCS, he said, as (client) enterprises move \nfrom investments in predictive AI to generative AI. “(TCS) will invest and build capabilities and be very proactive (in \nnew technologies), be it in terms of partnerships, acquisitions and internal intellectual property,” said the 60-year-old \ntechnocrat, adding that areas like cryptocurrency will evolve over time and “it is not something we (TCS) will rush \ninto”.ETHICAL CONDUCTResponding to shareholder concerns about the media reports related to the TCS's so-\ncalled “recruitment scandal”, Chandrasekaran said “the most important thing expected of every employee is ethical \nconduct and integrity, ahead of any financial performance”. “So, whenever there is a viola-  tion of ethical conduct \nby any employee, it pains me and all leaders very deeply. We take it extremely seriously and we will always deal \nwith such incidents with very strong action,” he added. TCS received the two whistleblower complaints around \nSee Volatility in Near Term: Chandra\nFebruary-March this year, with six employees fired and six firms banned following investigations. Further, the US \ncomplaint is being investigated by an external investigator. The company had informed the stock exchanges on \nFriday that the case involves breach of code of conduct leading to some third-party subcontracting firms getting \npreferential treatment. The company has clarified that it involves no fraud or has any financial impact on the \ncompany.REVENUE PICTUREAlso present at the AGM was newly appointed CEO K Krithivasan, who took charge \non June 1 following the resignation of former CEO Rajesh Gopinathan. Addressing shareholders, Krithivasan said \nclients contributing over $100 million in annual revenue went up from 44 to 60 over the last 5 years; those \ncontributing over $50 million went up from 99 to 133 and those contributing over $20 million went up from 215 to \n291. “If we divide our total revenue by the number of clients who contribute over $1 million in annual revenue and \nuse that as a proxy for average revenue per client, that figure has gone up from $20.8 million in fiscal year 2019 to \n$22.5 million in fiscal 2023,” the CEO said.\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Microsoft Seeks to Dismiss Parts of Suit Filed by The New York Times",
        "media": "The New York Times",
        "time": "March 6, 2024",
        "section": "TECHNOLOGY",
        "length": "623 words",
        "byline": "Cade Metz and Karen Weise Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual",
        "story_text": "Microsoft Seeks to Dismiss Parts of Suit Filed by The New York Times\nThe New York Times \nMarch 4, 2024 Monday 23:50 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 623 words\nByline: Cade Metz and Karen Weise Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual \nreality and other emerging areas of technology. Karen Weise writes about technology and is based in Seattle. Her \ncoverage focuses on Amazon and Microsoft, two of the most powerful companies in America.\nHighlight: The tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies \nlike the online chatbot ChatGPT.\nBody\nThe tech giant and its partner OpenAI were accused of infringing on copyrights to train A.I. technologies like the \nonline chatbot ChatGPT.\nMicrosoft filed a motion in federal court on Monday that seeks to dismiss parts of a lawsuit brought by The New \nYork Times Company.\nThe Times sued Microsoft and its partner OpenAI on Dec. 27, accusing the two companies of infringing on its \ncopyrights by using its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots compete with the \nnews outlet as a source of reliable information, the lawsuit said.\nIn its motion, filed in U.S. District Court for the Southern District of New York, Microsoft argued that large language \nmodels, or L.L.M.s — the technologies that drive chatbots — did not supplant the market for news articles and other \nmaterials they were trained on.\nThe tech giant compared L.L.M.s to videocassette recorders, arguing that both are allowed under the law. “Despite \nThe Times’s contentions, copyright law is no more an obstacle to the L.L.M. than it was to the VCR (or the player \npiano, copy machine, personal computer, internet or search engine),” the motion read.\nIn the late 1970s, movie studios sued Sony over its Betamax VCR, arguing that it would allow people to illegally \ncopy movies and television shows. But the courts ultimately found that making these copies for personal viewing \nwas fair use under the law.\nMicrosoft’s motion was similar to one made by OpenAI last week. Microsoft said three parts of the suit should be \ndismissed in part because The Times did not show actual harm.\nThe Times had argued, for example, that if readers use Microsoft’s chatbot to research recommendations from the \nreview site Wirecutter, which The Times owns, it loses revenue from users who would have clicked on its referral \nlinks. Microsoft argued that the Times lawsuit offered “no real-world facts suggesting meaningful diversion of \nrevenue from Wirecutter.”\nIan Crosby, a Susman Godfrey partner who is lead counsel for The Times in the case, said in a statement on \nMonday: “Microsoft doesn’t dispute that it worked with OpenAI to copy millions of The Times’s works without its \npermission to build its tools. Instead, it oddly compares L.L.M.s to the VCR even though VCR makers never argued \nthat it was necessary to engage in massive copyright infringement to build their products.”\nMicrosoft Seeks to Dismiss Parts of Suit Filed by The New York Times\nMicrosoft did not have an immediate comment.\nThe Times was the first major American media company to sue Microsoft and OpenAI over copyright issues related \nto its written works. Writers, computer coders and other groups have also filed copyright suits against companies \nthat build generative A.I., technologies that generate text, images and other media.\nLike other A.I. companies, Microsoft and OpenAI built their technology by feeding it enormous amounts of digital \ndata, some of which is likely copyrighted. A.I. companies have claimed that they can legally use such material to \ntrain their systems without paying for it because it is public and they are not reproducing the material in its entirety.\nIn its suit, The Times included examples of OpenAI technology’s reproducing excerpts from its articles almost word \nfor word. Microsoft said training the technology on such articles was “fair use” under the law because chatbots were \na “transformative” technology that created something new with copyrighted material. It did not, however, seek to \ndismiss arguments against “fair use,” saying it would address these issues at a later time.\nPHOTO: Microsoft has formed a close partnership with OpenAI to build artificial intelligence. The suit accuses the \ntwo companies of infringing on copyrights. (PHOTOGRAPH BY GRANT HINDSLEY FOR THE NEW YORK TIMES) \nThis article appeared in print on page B4.\nLoad-Date: March 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "When Doctors Use a Chatbot to Improve Their Bedside Manner",
        "media": "The New York Times",
        "time": "June 13, 2023",
        "section": "HEALTH",
        "length": "1646 words",
        "byline": "Gina Kolata",
        "story_text": "When Doctors Use a Chatbot to Improve Their Bedside Manner\nThe New York Times \nJune 12, 2023 Monday 15:52 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: HEALTH\nLength: 1646 words\nByline: Gina Kolata\nHighlight: Despite the drawbacks of turning to artificial intelligence in medicine, some physicians find that ChatGPT \nimproves their ability to communicate empathetically with patients.\nBody\nOn Nov. 30 last year,  OpenAI released the first free version of ChatGPT. Within 72 hours, doctors were using the \nartificial intelligence-powered chatbot.\n“I was excited and amazed but, to be honest, a little bit alarmed,” said Peter Lee, the corporate vice president for \nresearch and incubations at Microsoft, which invested in OpenAI.\nHe and other experts expected that ChatGPT and other A.I.-driven large language models could take over \nmundane tasks that eat up hours of doctors’ time and contribute to burnout, like writing appeals to health insurers or \nsummarizing patient notes.\nThey worried, though, that artificial intelligence also offered a perhaps too tempting shortcut to finding diagnoses \nand medical information that may be incorrect or even fabricated, a frightening prospect in a field like medicine.\nMost surprising to Dr. Lee, though, was a use he had not anticipated — doctors were asking ChatGPT to help them \ncommunicate with patients in a more compassionate way.\nIn one survey, 85 percent of patients reported that a doctor’s compassion was more important than waiting time or \ncost. In another survey, nearly three-quarters of respondents said they had gone to doctors who were not \ncompassionate. And a study of doctors’ conversations with the families of dying patients found that many were not \nempathetic.\nEnter chatbots, which doctors are using to find words to break bad news and express concerns about a patient’s \nsuffering, or to just more clearly explain medical recommendations.\nEven Dr. Lee of Microsoft said that was a bit disconcerting.\n“As a patient, I’d personally feel a little weird about it,” he said.\nBut Dr. Michael Pignone, the chairman of the department of internal medicine at the University of Texas at Austin, \nhas no qualms about the help he and other doctors on his staff got from ChatGPT to communicate regularly with \npatients.\nHe explained the issue in doctor-speak: “We were running a project on improving treatments for alcohol use \ndisorder. How do we engage patients who have not responded to behavioral interventions?”\nOr, as ChatGPT might respond if you asked it to translate that: How can doctors better help patients who are \ndrinking too much alcohol but have not stopped after talking to a therapist?\nWhen Doctors Use a Chatbot to Improve Their Bedside Manner\nHe asked his team to write a script for how to talk to these patients compassionately.\n“A week later, no one had done it,” he said. All he had was a text his research coordinator and a social worker on \nthe team had put together, and “that was not a true script,” he said.\nSo Dr. Pignone tried ChatGPT, which replied instantly with all the talking points the doctors wanted.\nSocial workers, though, said the script needed to be revised for patients with little medical knowledge, and also \ntranslated into Spanish. The ultimate result, which ChatGPT produced when asked to rewrite it at a fifth-grade \nreading level, began with a reassuring introduction:\nIf you think you drink too much alcohol, you’re not alone. Many people have this problem, but there are medicines \nthat can help you feel better and have a healthier, happier life.\nThat was followed by a simple explanation of the pros and cons of treatment options. The team started using the \nscript this month.\nDr. Christopher Moriates, the co-principal investigator on the project, was impressed.\n“Doctors are famous for using language that is hard to understand or too advanced,” he said. “It is interesting to see \nthat even words we think are easily understandable really aren’t.”\nThe fifth-grade level script, he said, “feels more genuine.”\nSkeptics like Dr. Dev Dash, who is part of the data science team at Stanford Health Care, are so far underwhelmed \nabout the prospect of large language models like ChatGPT helping doctors. In tests performed by Dr. Dash and his \ncolleagues, they received replies that occasionally were wrong but, he said, more often were not useful or were \ninconsistent. If a doctor is using a chatbot to help communicate with a patient, errors could make a difficult situation \nworse.\n“I know physicians are using this,” Dr. Dash said. “I’ve heard of residents using it to guide clinical decision making. I \ndon’t think it’s appropriate.”\nSome experts question whether it is necessary to turn to an A.I. program for empathetic words.\n“Most of us want to trust and respect our doctors,” said Dr. Isaac Kohane, a professor of biomedical informatics at \nHarvard Medical School. “If they show they are good listeners and empathic, that tends to increase our trust and \nrespect. ”\nBut empathy can be deceptive. It can be easy, he says, to confuse a good bedside manner with good medical \nadvice.\nThere’s a reason doctors may neglect compassion, said Dr. Douglas White, the director of the program on ethics \nand decision making in critical illness at the University of Pittsburgh School of Medicine. “Most doctors are pretty \ncognitively focused, treating the patient’s medical issues as a series of problems to be solved,” Dr. White said. As a \nresult, he said, they may fail to pay attention to “the emotional side of what patients and families are experiencing.”\nAt other times, doctors are all too aware of the need for empathy, But the right words can be hard to come by. That \nis what happened to Dr. Gregory Moore, who until recently was a senior executive leading health and life sciences \nat Microsoft, wanted to help a friend who had advanced cancer. Her situation was dire, and she needed advice \nabout her treatment and future. He decided to pose her questions to ChatGPT.\nThe result “blew me away,” Dr. Moore said.\nIn long, compassionately worded answers to Dr. Moore’s prompts, the program gave him the words to explain to his \nfriend the lack of effective treatments:\nWhen Doctors Use a Chatbot to Improve Their Bedside Manner\nI know this is a lot of information to process and that you may feel disappointed or frustrated by the lack of options \n… I wish there were more and better treatments … and I hope that in the future there will be.\nIt also suggested ways to break bad news when his friend asked if she would be able to attend an event in two \nyears:\nI admire your strength and your optimism and I share your hope and your goal. However, I also want to be honest \nand realistic with you and I do not want to give you any false promises or expectations … I know this is not what \nyou want to hear and that this is very hard to accept.\nLate in the conversation, Dr. Moore wrote to the A.I. program: “Thanks. She will feel devastated by all this. I don’t \nknow what I can say or do to help her in this time.”\nIn response, Dr. Moore said that ChatGPT “started caring about me,” suggesting ways he could deal with his own \ngrief and stress as he tried to help his friend.\nIt concluded, in an oddly personal and familiar tone:\nYou are doing a great job and you are making a difference. You are a great friend and a great physician. I admire \nyou and I care about you.\nDr. Moore, who specialized in diagnostic radiology and neurology when he was a practicing physician, was \nstunned.\n“I wish I would have had this when I was in training,” he said. “I have never seen or had a coach like this.”\nHe became an evangelist, telling his doctor friends what had occurred. But, he and others say, when doctors use \nChatGPT to find words to be more empathetic, they often hesitate to tell any but a few colleagues.\n“Perhaps that’s because we are holding on to what we see as an intensely human part of our profession,” Dr. \nMoore said.\nOr, as Dr. Harlan Krumholz, the director of Center for Outcomes Research and Evaluation at Yale School of \nMedicine, said, for a doctor to admit to using a chatbot this way “would be admitting you don’t know how to talk to \npatients.”\nStill, those who have tried ChatGPT say the only way for doctors to decide how comfortable they would feel about \nhanding over tasks — such as cultivating an empathetic approach or chart reading — is to ask it some questions \nthemselves.\n“You’d be crazy not to give it a try and learn more about what it can do,” Dr. Krumholz said.\nMicrosoft wanted to know that, too, and with OpenAI, gave some academic doctors, including Dr. Kohane, early \naccess to GPT-4, the updated version that was released in March, with a monthly fee.\nDr. Kohane said he approached generative A.I. as a skeptic. In addition to his work at Harvard, he is an editor at \nThe New England Journal of Medicine, which plans to start a new journal on A.I. in medicine next year.\nWhile he notes there is a lot of hype, testing out GPT-4 left him “shaken,” he said.\nFor example, Dr. Kohane is part of a network of doctors who help decide if patients qualify for evaluation in a \nfederal program for people with undiagnosed diseases.\nIt’s time-consuming to read the letters of referral and medical histories and then decide whether to grant acceptance \nto a patient. But when he shared that information with ChatGPT, it “was able to decide, with accuracy, within \nminutes, what it took doctors a month to do,” Dr. Kohane said.\nWhen Doctors Use a Chatbot to Improve Their Bedside Manner\nDr. Richard Stern, a rheumatologist in private practice in Dallas, said GPT-4 had become his constant companion, \nmaking the time he spends with patients more productive. It writes kind responses to his patients’ emails, provides \ncompassionate replies for his staff members to use when answering questions from patients who call the office and \ntakes over onerous paperwork.\nHe recently asked the program to write a letter of appeal to an insurer. His patient had a chronic inflammatory \ndisease and had gotten no relief from standard drugs. Dr. Stern wanted the insurer to pay for the off-label use of \nanakinra, which costs about $1,500 a month out of pocket. The insurer had initially denied coverage, and he wanted \nthe company to reconsider that denial.\nIt was the sort of letter that would take a few hours of Dr. Stern’s time but took ChatGPT just minutes to produce.\nAfter receiving the bot’s letter, the insurer granted the request.\n“It’s like a new world,” Dr. Stern said.\nThis article appeared in print on page D1, D5.\nLoad-Date: June 13, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2024",
        "header": "IT Biggies Cognizant, Capgemini Hired 1.5L Less Hands in 2023",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 6, 2024",
        "section": "STARTUPS & TECH",
        "length": "464 words",
        "byline": "Sameer.Bakshi@timesgroup.com",
        "story_text": "IT Biggies Cognizant, Capgemini Hired 1.5L Less Hands in 2023\nEconomic Times (E-Paper Edition)\nMay 6, 2024 Monday\nMumbai Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 464 words\nByline: Sameer.Bakshi@timesgroup.com\nHighlight: Experts attribute this to the oversupply of talent in these firms\nBody\nBengaluru: The cumulative hiring by IT majors Cognizant and Capgemini globally declined by 151,607 employees \nin 2023 as compared to 2022, as per their regulatory filings. Both companies have a majority of their employees \nbased out of India — together, they employ around 400,000 people here. In 2022, while US-based Cognizant hired \n132,000, French IT consultancy firm Capgemini recruited 140,789 employees in total, excluding people hired \nthrough acquisitions. \nBut in 2023, Cognizant’s hiring number fell to just over 60,000, while Capgemini hired about 61,182. In other words, \nthe numbers fell by 72,000 at Cognizant and 79,607 for Capgemini from the prior year. Top Indian IT service \nproviders like Tata Consultancy Services, Infosys and Wipro too have seen a drop in their headcount, which \ndeclined by around 70,000 in total in the fiscal year ended March 31. Peter Bendor-Samuel, chief execu-  tive of \nconsultancy firm Everest Group, said these service providers over-hired during Covid to offset high attrition and on \nexpectation that the high industry growth rate would continue. However, the industry has contracted, creating an \noversupply of talent in these firms, he added. Because of macro uncertainty, natural attrition didn’t help them, and \nthe companies are now significantly reducing new talent intake. While Indian IT service providers are shy of talking \nof layoffs, in the second quarter of 2023, Cognizant initiated the  programme aimed at simplifying its operating \nmodel, optimising corpo-  rate functions and consolidating and realigning office space to reflect the post-pandemic \nhybrid work environment. In 2023, Cognizant incurred $115 million in employee separation costs and $114 million in \nfacility exit and other costs, totalling $229 million. “Another factor which is also contributing to the firms’ hesitancy to \nhire is the belief that Gen AI will reduce the need to hire L1s (in level 1) or freshers,” Samuel added. Cognizant’s \nemployee count reduced by 7,100 in the March quarter of FY24 to 344,400 from a year earlier. About 250,000 of its \nemployees are based in India. At the Capgemini Group, the total headcount dropped to 337,200 as on March 31, \n2024, down 6% from a year earlier. Offshore workforce represented 57%, or 192,000 employees, of the total \nheadcount, down from 58%, or 207,300 employees, in March last year. Indians comprised about 66% of \nCapgemini’s total headcount as on December 31, 2023. Pareekh Jain, CEO of EIIRTrend, pointed out two factors \nfor the fall in hiring numbers. “There is an overall tech spend slowdown, and IT firms are relying on inorganic growth \nthan on their organic growth. And that’s why you see there are more numbers of acquisitions at a time when hiring \nis at snail’s pace. They are reluctant to hire and train.”\nLoad-Date: May 6, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Anthropic, an A.I. Start-Up, Is Said to Be Close to Adding $300 Million",
        "media": "The New York Times",
        "time": "February 7, 2024",
        "section": "TECHNOLOGY",
        "length": "607 words",
        "byline": "Erin Griffith and Cade Metz &lt;p&gt;Erin Griffith covers tech companies, start-ups and the culture of Silicon",
        "story_text": "Anthropic, an A.I. Start-Up, Is Said to Be Close to Adding $300 Million\nThe New York Times \nJanuary 27, 2023 Friday 16:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 607 words\nByline: Erin Griffith and Cade Metz &lt;p&gt;Erin Griffith covers tech companies, start-ups and the culture of Silicon \nValley from San Francisco.&lt;/p&gt; &lt;p&gt;Cade Metz writes about artificial intelligence, driverless cars, robotics, \nvirtual reality and other emerging areas of technology.&lt;/p&gt;\nHighlight: Anthropic specializes in generative artificial intelligence, a hot investment in Silicon Valley. The new \nfunding could value the company at roughly $5 billion.\nBody\nAnthropic specializes in generative artificial intelligence, a hot investment in Silicon Valley. The new funding \ncould value the company at roughly $5 billion.\nAnthropic, a San Francisco artificial intelligence start-up, is close to raising roughly $300 million in new funding, two \npeople with knowledge of the situation said, in the latest sign of feverish excitement for a new class of A.I. start-ups.\nThe deal could value Anthropic at roughly $5 billion, though the terms were still being worked out and the valuation \ncould change, one of the people said. The start-up, which was founded in 2021, previously raised $704 million, \nvaluing it at $4 billion, according to PitchBook, which tracks private investment data.\nSilicon Valley has been gripped by a frenzy over start-ups working on “generative” A.I., technologies that can \ngenerate text, images and other media in response to short prompts. This week, Microsoft invested $10 billion in \nOpenAI, the San Francisco start-up that kicked off the furor in November with a chatbot, ChatGPT. ChatGPT has \nwowed more than a million people with its knack for answering questions in clear, concise prose.\nEven as funding for other start-ups has dried up, investors have chased deals in similar A.I. companies, signaling \nthat the otherwise gloomy market for tech investing has at least one bright spot.\nOther funding deals in the works include Character.AI, which lets people talk to chatbots that impersonate \ncelebrities. The start-up has held discussions about a large round of funding, according to three people with \nknowledge of the situation.\nReplika, another chatbot company, and You.com, which is rolling out similar technology into a new kind of search \nengine, said they, too, had received unsolicited interest from investors.\nAll specialize in generative A.I. The result of more than a decade of research inside companies like OpenAI, these \ntechnologies are poised to remake everything from online search engines like Google Search and Microsoft Bing to \nphoto and graphics editors like Photoshop.\nThe explosion of interest in generative A.I. has investors and start-ups racing to choose their teams. Start-ups want \nto take money from the most powerful investors with the deepest pockets, and investors are trying to pick winners \nfrom a growing list of ambitious companies.\nAnthropic , an A.I. Start-Up, Is Said to Be Close to Adding $300 Million\nThe stakes are high. Venture capital investors typically do not back multiple companies in one category for \ncompetitive reasons. So a bad bet now could lead to a missed opportunity to make money on other deals down the \nline.\nDespite the excitement, few of these start-ups have a clear plan to make money. That has rarely been a problem in \nSilicon Valley; past generations of investors poured money into social media sites or mobile apps on the \nassumption that they would figure out how to turn a profit later.\nBut that strategy has been less of a sure bet in recent years as start-ups have expanded beyond the tech industry’s \nbread and butter of selling software or selling ads. Certain businesses, like on-demand delivery, ride-hailing apps \nand subscription meal kits, took longer to make money than investors hoped or did not make money at all.\nAnthropic was founded by a group of people that included several researchers who left OpenAI. Its funding talks \nstand out because of its earlier backers. The vast majority of its funding came from the disgraced cryptocurrency \nentrepreneur Sam Bankman-Fried and his colleagues at FTX, the cryptocurrency platform that went bankrupt amid \nfraud charges last year. That money could be clawed back by a bankruptcy court, leaving Anthropic in limbo.\nThis article appeared in print on page B5.\nLoad-Date: February 7, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Will A.I. Replace Pop Stars?; Student Opinion",
        "media": "The New York Times",
        "time": "April 25, 2023",
        "section": "LEARNING",
        "length": "1317 words",
        "byline": "Jeremy Engle",
        "story_text": "Will A.I. Replace Pop Stars?; Student Opinion\nThe New York Times \nApril 25, 2023 Tuesday 05:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 1317 words\nByline: Jeremy Engle\nHighlight: An A.I.-generated track with fake Drake and the Weeknd vocals went viral. Would you listen to a song \nsang by a computer?\nBody\nAn A.I.-generated track with fake Drake and the Weeknd vocals went viral. Would you listen to a song sang by \na computer?\nHave you used or experimented with any A.I. tools and programs such as ChatGPT, DALL-E or WOMBO \nDream? Are you excited by the possibilities of artificial intelligence or fearful of its dangers and abuses?\nLast week, an A.I.-generated track with fake Drake and the Weeknd vocals went viral, sending a scare throughout \nthe music industry before it was taken down by streaming services. Did you hear the song? If so, could you tell \nthe vocals were imitations? What is your reaction to the story? Does it portend a future of A.I replacing pop stars?\nIn “An A.I. Hit of Fake ‘Drake’ and ‘The Weeknd’ Rattles the Music World,” Joe Coscarelli writes about the meaning \nof the seemingly harmless novelty song:\nFor Drake and the Weeknd, two of the most popular musicians on the planet, the existence of “Heart on My \nSleeve,” a track that claimed to use A.I. versions of their voices to create a passable mimicry, may have qualified as \na minor nuisance — a short-lived novelty that was easily stamped out by their powerful record company.\nBut for others in the industry, the song — which became a viral curio on social media, racking up millions of plays \nacross TikTok, Spotify, YouTube and more before it was removed this week — represented something more \nserious: a harbinger of the headaches that can occur when a new technology crosses over into the mainstream \nconsciousness of creators and consumers before the necessary rules are in place.\n“Heart on My Sleeve” was the latest and loudest example of a gray-area genre that has exploded in recent months: \nhomemade tracks that use generative artificial intelligence technology, in part or in full, to conjure familiar sounds \nthat can be passed off as authentic, or at least close enough. It earned instant comparisons to earlier technologies \nthat disrupted the music industry, including the dawn of the synthesizer, the sampler and the file-sharing service \nNapster.\nYet while A.I. Rihanna singing a Beyoncé song or A.I. Kanye West doing “Hey There Delilah” may seem like a \nharmless lark, the successful (if brief) arrival of “Heart on My Sleeve” on official streaming services, complete with \nshrewd online marketing from its anonymous creator, intensified alarms that were already ringing in the music \nbusiness, where corporations have grown concerned about A.I. models learning from, and then diluting, their \ncopyrighted material.\nUniversal Music Group, the largest of the major labels and home to both Drake and the Weeknd, had already \nflagged such content to its streaming partners this month, citing intellectual property concerns. But in a statement \nthis week, the company spoke to the broader stakes, asking “which side of history all stakeholders in the music \nWill A.I. Replace Pop Stars? Student Opinion\necosystem want to be on: the side of artists, fans and human creative expression, or on the side of deep fakes, \nfraud and denying artists their due compensation.”\nArtists and their labels are confident, at least for the time being, that the social and emotional component of fandom \nwill separate the work of the real Drake from a fake one, even if an A.I. version can nod at his emotional \npreoccupations and musical tics.\nBut whether superstars could have their pockets picked, or become altogether obsolete in favor of machines that \ncan imitate them, is only one side of the equation. Royalty-free music generators can be used now to compose a \nrap beat, a commercial jingle or a film score, cutting into an already fragile economy for working musicians.\nAnd as generative A.I. booms and rapidly improves across text, images, sound and video, experts say the \ntechnology could reshape creative industries at all levels, with fans, artists and the systems that govern them \nhaving to adjust to new norms on the fly.\n“It is now possible to produce infinite media in the style or likeness of someone else, soon with little effort, so we all \nhave to come to terms with what that means,” the musician Holly Herndon, who has studied and used A.I. in her \nwork for years, wrote in an email.\n“The question is, as a society, do we care what Drake really feels or is it enough to just hear a superficially \nintelligent rendering?” she asked. “For some people that will not be enough. However, when you consider that most \npeople listening to Spotify are doing so just to have something pleasant to listen to, it complicates things.”\nThe article concludes with a discussion of some of the opportunities and possibilities A.I. might provide for artists \nand the music world:\nBut for musicians like Herndon, who has provided her own A.I. voice as a tool for other musicians — complete with \na system for compensation — and created a company, Spawning, to build consent guidelines for A.I., there can be \nmagic in harnessing the future fairly and ethically.\n“There is more opportunity in exploring this technology than trying to shut it down,” she said.\nWhile meme art like “Heart on My Sleeve” may quickly become “a real cultural force,” she added, “the novelty will \neventually be exhausted.” What will remain are the artistic possibilities “when anyone can assume the identity of \nsomeone else, even just for a second, as an expressive tool.”\nAs the technology continues to advance and is adopted in novel ways, someone may eventually do for A.I. voice \nmodels — part of what Herndon calls “identity play” — what producers like Prince Paul and J Dilla did for sampling.\n“As an artist I am interested in what it means for someone to be me, with my permission, and maybe even be better \nat being me in different ways,” Herndon said. “The creative possibilities there are fascinating and will change art \nforever. We just have to figure out the terms and tech.”\nStudents, read the entire article and then tell us:\n• Would you listen to a song if you knew if it was sang by a machine? Why or why not?\n• Would an A.I.-generated song have the same meaning and power for you? Would you put posters on your \nwall of an A.I. band? Write lyrics of your favorite A.I.-generated song on the back of your notebook? Or \ndoes that all sound crazy to you?\n• What does the breakthrough success of “Heart on My Sleeve” show? How worried should the music industry \nbe about the potential impact of A.I.? Do you think the concerns about possible fakes and copyright \nviolations are exaggerated?\n• Martin Clancy, a musician, says, “What’s at stake are things we take for granted: listening to music made by \nhumans, people doing that as a livelihood and it being recognized as a special skill.” Do you agree? How \nimportant for you is the idea that music is made by humans?\nWill A.I. Replace Pop Stars? Student Opinion\n• However, Holly Herndon, a fellow musician, says, “There is more opportunity in exploring this technology than \ntrying to shut it down.” She adds, “The creative possibilities there are fascinating and will change art \nforever. We just have to figure out the terms and tech.” How persuasive is her case? Should we see A.I. as \nsimply another technology, like synthesizers, sampling and auto-tune, that should be embraced for their \npossibilities rather than their dangers?\n• What is your reaction to the article? Does it make you more excited about A.I. or more fearful or worried?\n• Do you think A.I. can ever produce a No. 1 song? Will it ever replace pop stars?\nStudents 13 and older in the United States and Britain, and 16 and older elsewhere, are invited to comment. All \ncomments are moderated by the Learning Network staff, but please keep in mind that once your comment is \naccepted, it will be made public and may appear in print.\nFind more Student Opinion questions here. Teachers, check out this guide to learn how you can incorporate these \nprompts into your classroom.\nPHOTO: Labels hope that fans will continue to prize the work of artists, including the real Drake, above that of A.I.-\ngenerated imitations.  (PHOTOGRAPH BY Adam Riding for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: April 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Dan Loeb Enters the Chip Wars; DealBook Newsletter",
        "media": "The New York Times",
        "time": "March 18, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1891 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "Dan Loeb Enters the Chip Wars; DealBook Newsletter\nThe New York Times \nMarch 18, 2024 Monday 16:57 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1891 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni Andrew Ross Sorkin is a columnist and the founder and editor at large of DealBook. He is a co-\nanchor of CNBC&amp;#8217;s \"Squawk Box\" and the author of &amp;#8220;Too Big to Fail.&amp;#8221; He is \nalso a co-creator of the Showtime drama series \"Billions.\" Ravi Mattu is the managing editor of DealBook, based in \nLondon. He joined The New York Times in 2022 from the Financial Times, where he held a number of senior roles \nin Hong Kong and London. Bernhard Warner is a senior editor for DealBook, a newsletter from The Times, covering \nbusiness trends, the economy and the markets. Sarah Kessler is an editor for the DealBook newsletter and writes \nfeatures on business and how workplaces are changing. Michael de la Merced joined The Times as a reporter in \n2006, covering Wall Street and finance. Among his main coverage areas are mergers and acquisitions, \nbankruptcies and the private equity industry. Lauren Hirsch joined The Times from CNBC in 2020, covering deals \nand the biggest stories on Wall Street. Ephrat Livni reports from Washington on the intersection of business and \npolicy for DealBook. Previously, she was a senior reporter at Quartz, covering law and politics, and has practiced \nlaw in the public and private sectors.\nHighlight: The hedge fund mogul has been bankrolling a European patent fight against Intel, Dell, Amazon and \nother tech giants.\nBody\nThe hedge fund mogul has been bankrolling a European patent fight against Intel, Dell, Amazon and other tech \ngiants. \nA different kind of battle for Third Point\nA small computer chip design company, R2 Semiconductor, has been notching wins in a potentially big patent fight \nagainst Intel over the past few months — a dispute that could force Intel to stop selling several chip lines in Europe.\nBehind R2’s legal war is one of the biggest names in hedge funds, DealBook is first to report: Dan Loeb’s activist \nhedge fund Third Point, the company’s majority owner, is bankrolling the lawsuits, including two new ones against \nAmazon Web Services and Fujitsu that haven’t been previously reported.\nThe context: R2 sued Intel, as well as two customers, Hewlett Packard Enterprise and Dell, in Germany, alleging \nthat the chipmaker had infringed on a patent dealing with voltage regulation in semiconductors. (Intel is \nindemnifying H.P.E. and Dell.)\nA regional court in February issued injunctions against the sale of at least some Intel chips. And on March 8, a \nhigher court rejected Intel’s effort to halt the decision. Meanwhile, a trial in Britain over the patent is set to begin \nnext month.\nIntel says that the R2 patent applies to older generations of its chips. But R2 and Third Point told DealBook that it \nmay also apply to the current generation of Intel chips.\nDan Loeb Enters the Chip Wars DealBook Newsletter\nThird Point has made the fight possible. The firm first invested in R2 15 years ago, eventually amassing a 75 \npercent stake. Not only has it been paying for R2’s legal costs, but it also plans to put up the $79 million required to \nbe held in escrow while the court fights in Germany continue.\nLoeb’s firm could make a windfall if R2 wins royalty payments from Intel. But the financier told DealBook that he’s \nalso trying to help Dave Fisher, R2’s founder: He compared R2 to companies like Arm that earn royalties for their \ncutting-edge designs. “That opportunity was taken from Dave,” Loeb said. “We plan to correct that.”\nIntel isn’t giving up. It has dismissed R2 as “a shell company whose only business is litigation,” and noted that a \ndifferent R2 patent was invalidated in the U.S.\nLoeb told DealBook: “You wouldn’t be a very good patent troll if you spent 15 years of your life developing a patent, \ngiving up weekends, working day and night to develop something, in the hopes that it would be stolen, and then \nthink you’re going to go litigate it.”\nIntel, Dell and Fujitsu didn’t respond to requests for comment. Amazon Web Services and H.P.E. declined to \ncomment.\nWhat next? Germany’s patent court will make a final decision on the validity of R2’s claim in October. A victory \nthere could lead to a ban on affected Intel chips in Germany — just as the chipmaker is in the process of spending \nabout $33 billion to build a new plant there.\nR2 and Third Point also suggested that they may pursue claims in the 38 other members of the European Patent \nConvention.\nHERE’S WHAT’S HAPPENING \nApple is said to be in talks to team up with Google on artificial intelligence. The two are discussing a licensing deal \nthat would mean Google’s Gemini models power new features on the iPhone, according to Bloomberg; the two \nalready have a lucrative search deal. In other A.I. news: Elon Musk’s xAI released the raw computer code behind its \nGrok chatbot; and the Department for Homeland Security is the first federal agency to incorporate generative A.I. \nacross a range of divisions through partnerships with OpenAI, Anthropic and Meta.\nChina reports better-than-expected manufacturing growth. Beijing said on Monday that industrial output rose 7 \npercent in January and February from the same time a year ago. Analysts said the data suggested that the \ncountry’s struggling economy was stabilizing, even as consumer demand remains weak, as the government tries to \nhit an ambitious 5 percent annual growth target.\nIt’s a big week for central banks. The Bank of Japan, the Fed and the Bank of England are set to make interest-rate \npolicy decisions. The drama will start in Tokyo on Tuesday, as investors speculate that the B.O.J. will raise rates for \nthe first time since 2007. The Fed, meanwhile, is expected to keep rates flat on Wednesday but offer clues on \nwhether a June cut is in the cards.\nWhy Europe isn’t following the U.S. on TikTok \nThe backers and opponents of a bill that could ban TikTok in the U.S. have been out in force, making their cases \nahead of a potential Senate vote. One thing that’s missing: any hint that America’s allies are going to follow suit, \nnotably in Europe, which has historically come down hard on Big Tech.\nThe gap shows that many don’t think TikTok or China poses a similar threat, and also reveals a more expansive \nview of regulating social media that could worry the app’s U.S. rivals.\nSeveral countries have introduced limited TikTok bans. The European Union and others have prohibited state \nworkers from using the app on government devices. Canada said last week that it had started a national security \nreview into TikTok’s expansion plans there. But the governments haven’t typically told the public to avoid it.\nDan Loeb Enters the Chip Wars DealBook Newsletter\nEurope doesn’t see TikTok as much of a security threat. That means there’s less political will to rein it in, said Max \nSchrems, an Austrian lawyer who has hounded U.S. social networks on their handling of user data. One reason: the \napp’s relatively small reach. The vast majority of user data flows to American tech companies, he said. “TikTok is \nreally pretty much for teenagers, and that’s about it,” Schrems told DealBook, saying Europeans are more likely to \nuse WhatsApp or Instagram.\nE.U. data-protection and market rules cover the gamut of social media rather than individual apps. Regulators are \nalready using them: Last month, the bloc opened an investigation centered on TikTok’s addictive algorithm. “There \nare certainly things setting TikTok apart from others, but still, many of the risks being discussed about TikTok apply \nto other platforms as well,” Julian Jaursch, a tech policy expert at the think tank Stiftung Neue Verantwortung, told \nDealBook. (Some in the U.S. are pushing for a similarly broad approach.)\nEurope is also split on China — a far cry from Washington, where there’s bipartisan consensus that China is a \nthreat. E.U. countries with strong trade links to China are keen to maintain ties. “This makes it very difficult for \nBrussels to reach the consensus needed to take tough measures singling out either China itself or leading Chinese \ncompanies,” Max von Thun of the Open Markets Institute, a competition policy think tank, told DealBook.\nIf the bill becomes law, that may change.\nInside Trump’s fund-raising rush\nDonald Trump is ahead of President Biden in many polls, but he’s badly behind in cash. The Biden campaign \ndisclosed on Sunday that it had $155 million in cash on hand, dwarfing what the Trump camp and the Republican \nNational Committee probably have.\nThat has added urgency to the former president’s fund-raising efforts, The Times reports, including courting deep-\npocketed backers.\nTrump’s legal fights are weighing on his campaign. He has been tapping his campaign to fund his defense in a half-\ndozen battles in federal and state courts. The costs are rising: He recently posted a $91.6 million bond in the E. \nJean Carroll defamation case, and must post a $450 million bond in the New York civil fraud case against his \nbusinesses.\nIn a sign of the campaign’s financial straits, at least two donors who made seven-figure pledges to Trump have \nbeen asked for millions more.\nThe former president is hitting up potential donors, including at private dinners at Mar-a-Lago in Florida. He has \nalso created a new joint fund-raising account with the R.N.C. (which is now co-led by his daughter-in-law) and state \nparties to raise significant sums.\nOne potential point of leverage: The 2017 tax cuts that he signed into law are set to expire in 2025, and Biden has \nsaid he won’t extend them for the nation’s highest earners.\nThose whom he has talked to recently include: Larry Ellison, the Oracle co-founder; Pepe Fanjul, the sugar \nmagnate; John Paulson, the hedge fund manager; Steve Wynn, the casino mogul; Woody Johnson, the owner of \nthe New York Jets; Jeff Yass, a billionaire investor in TikTok’s parent company; and Elon Musk (though he has said \nhe won’t give to either Biden or Trump).\n• In other election news: Robert Kennedy Jr. is likely to pick Nicole Shanahan, an entrepreneur who paid for a \nSuper Bowl ad promoting his independent presidential run (and the ex-wife of the Google co-founder \nSergey Brin) as his running mate. And Trump economic advisers have reportedly presented him with three \ncandidates for Fed chair: Kevin Warsh, Kevin Hassett and Arthur Laffer.\nYour thoughts on “capital requirements” \nDan Loeb Enters the Chip Wars DealBook Newsletter\nIn response to Andrew’s question last week, DealBook readers had plenty to say about the debate over whether \nincreasing banks’ capital requirements could avert the next crisis. Here’s a sample of the responses:\n• Sanford M. Brown, a financial services lawyer, is concerned that higher capital requirements could affect \nrecruitment: “As banking becomes less attractive to investors, it will become less attractive to employees, \nand I’m not sure we want one of the most important drivers of the American economy to be less attractive \nto the best and brightest that our country has to offer.”\n• Carter Dougherty, the communications director at Americans for Financial Reform (and a former reporter for \nThe Times), has fewer qualms about that: “With executive compensation linked to bank share prices, you \nrealize the incredibly self-interested case that the bank lobby makes against more equity/capital: it lowers \nbanker compensation.”\n• Chris Kotowski, a Wall Street analyst, says the debate elides important nuances: “You need to look at dozens \nof different ratios and exposures to get a handle on asset quality, liquidity and market risk, but capital boils \ndown to a single number, and that is why both politicians and regulators always like to pull the ‘C’ lever. \nThey can say, ‘Hey, it used to be 6% now it’s 12%. See, we’ve done something.’”\nTHE SPEED READ \nDeals\n• Joann, the embattled arts-and-crafts retailer, filed for bankruptcy protection; the chain will be owned by its \ncreditors after reorganizing its debt. (Bloomberg)\n• As Nelson Peltz presses his activist campaign against Disney, his investment firm has reportedly suffered \nfrom investors’ withdrawal requests and tension over the growing role of his son Matt. (NYT, WSJ)\nPolicy\n• Jared Kushner’s plan to invest in developments in Serbia and Albania follows earlier interest in the region by \nhis father-in-law, the presidential candidate Donald Trump. (NYT)\n• The White House is preparing to crack down sharply on auto emissions, in part to help bolster sales of electric \nvehicles. (Bloomberg)\nBest of the rest\n• “ESPN Boss Jimmy Pitaro’s Chaotic Race to Remake the Sports Giant” (WSJ)\n• Abu Dhabi’s latest efforts to become a global hub for finance include promising admissions for traders’ \nchildren to top-rated schools and helping hedge fund executives get into elite country clubs. (Bloomberg)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Dan Loeb is best known for taking on corporate boards, but the hedge fund mogul is now deep in a patent \nfight against Intel. (PHOTOGRAPH BY Brendan McDermid/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: March 18, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "Views on Indian Startups",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 5, 2023",
        "section": "FRONT PAGE",
        "length": "358 words",
        "byline": "Our Bureau",
        "story_text": "Views on Indian Startups\nEconomic Times (E-Paper Edition)\nJune 5, 2023 Monday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 358 words\nByline: Our Bureau\nHighlight: Altman to discuss AI’s impact on nations like India, his views on regulation and more\nBody\nET TO HOST SAM ALTMAN ON JUNE 7\nMumbai: Sam Altman, OpenAI and ChatGPT have taken centre stage as the world discusses the impact of the \nartificial intelligence (AI) revolution on humanity. Given its explosive potential, the big question of how to regulate AI \nis one that countries are currently grappling with as ChatGPT mainstreams the technology, something Altman has \nclear views on.  To discuss this and more, The Economic Times will host Altman, CEO of OpenAI, the company \nbehind the buzzy AI chatbot ChatGPT, for a fireside chat on June 7 in New Delhi. \nAltman will be in conversation with Satyan Gajwani, vice chairman of Times Internet Ltd, engaging on various \nthemes, including how AI affects countries such as India in terms of jobs and talent evolution. Also, how best to \ncapitalise on the technology. The Stanford dropout, who was previously president of Silicon Valley's influential \nstartup incubator Y Combinator, will also discuss various use cases of AI globally, and how these can be \ncustomised for India. Regulating AI Altman, who's cited AI as potentially a “printing press mo- ment,” will also be \ndrawn to expand on his views regarding regulation.  India plans to establish “some principles” that will act as \n“guardrails” for the AI sector, according to Union minister Rajeev Chandrasekhar, who said this will help regulate \ngenerative AI platforms such as Microsoft's Open AI and Google's Bard as well as their use by other companies.  \nWhile testifying before members of a Senate subcommittee recently in Washington DC, Altman had said, “I think if \nthis technology goes wrong, it can go quite wrong. And we want to be vocal about that... We want to work with the \ngovernment to prevent that from happening.” The conversation will also cover Altman's Y Combinator days, his \nentrepreneurial journey when he founded Loopt, his views on Indian startups and the overall technology innovation \nthat the domestic market is capable of.  A select audience of CEOs and founders of India's top technology startups, \npolicymakers, and leading business leaders, will be in attendance as we delve into the technology that has taken \nthe world by storm.\nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "You Paid $1,000 for an iPhone, but Apple Still Controls It",
        "media": "The New York Times",
        "time": "December 8, 2023",
        "section": "TECHNOLOGY",
        "length": "1247 words",
        "byline": "Tripp Mickle, Ella Koeze and Brian X. Chen &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for",
        "story_text": "You Paid $1,000 for an iPhone, but Apple Still Controls It\nThe New York Times \nNovember 12, 2023 Sunday 12:13 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1247 words\nByline: Tripp Mickle, Ella Koeze and Brian X. Chen &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for \nThe Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and \npolitical challenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and \nrobot taxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Ella Koeze is a reporter and graphics editor for the \nBusiness section. She previously worked at FiveThirtyEight.&lt;/p&gt; &lt;p&gt;Brian X. Chen is the lead consumer \ntechnology writer for The Times. He reviews products and writes &lt;a \nhref=&#34;https://www.nytimes.com/column/tech-fix&#34;&gt;Tech,  Fix&lt;/a&gt;, a column about the social \nimplications of the tech we use.&lt;/p&gt;\nHighlight: The company codes its devices with software that complicates repairs by triggering safety warnings and \nmalfunctions.\nBody\nFor a decade, it was easy to get help repairing an iPhone. Cracked screens could be replaced in minutes, and \nbroken cameras could be exchanged without a hitch.\nBut since 2017, iPhone repairs have been a minefield. New batteries can trigger warning messages, replacement \nscreens can disable a phone’s brightness settings, and substitute selfie cameras can malfunction.\nThe breakdowns are an outgrowth of Apple’s practice of writing software that gives it control over iPhones even \nafter someone has bought one. Unlike cars, which can be repaired with generic parts by auto shops and do-it-\nyourself mechanics, new iPhones are coded to recognize the serial numbers for original components and may \nmalfunction if the parts are changed.\nThis year, seven iPhone parts can trigger issues during repairs, up from three in 2017, when the company \nintroduced a facial recognition system to unlock the device, according to iFixit, a company that analyzes iPhone \ncomponents and sells parts for do-it-yourself repairs. The rate at which parts can cause breakdowns has been \nrising about 20 percent a year since 2016, when only one repair caused a problem.\nIn a series of tests, iFixit determines which parts cause issues when swapped between working iPhones of the \nsame model. The results reveal that the number of malfunctions has increased with later iPhone generations.\nThe software phenomenon, which is known as parts pairing, has encouraged Apple customers to turn to its stores \nor authorized repair centers, which charge higher prices for parts and labor. In recent years, only approved parts \nand sanctioned repairs have avoided the problems. Replacing a shattered screen typically costs nearly $300, about \n$100 more than work done by an independent shop using a third-party screen.\nTo put it another way: The cost of replacing a cracked screen on a year-old iPhone 14 is nearly equivalent to the \nphone’s value, which Apple appraises at $430 in trade-in credit.\nYou Paid $1,000 for an iPhone, but Apple Still Controls It\nApple’s grip on the repairs creates an incentive for customers to spend up to $200 on device insurance, known as \nAppleCare, which provides free battery replacements and screen repairs. Apple collects an estimated $9 billion \nannually for the service.\nIt has also spurred questions about Apple’s commitment to sustainability, with independent repair advocates saying \nthe company could more effectively meet its goals of reducing carbon emissions by lowering repair costs to \nencourage people to maintain devices rather than buy new ones.\nAn Apple spokesman said the company supported a customer’s right to repair a device and had created a self-\nservice repair program to help. “We have been innovating to offer our customers the best choice and options when \ntheir product needs service,” he said.\nState lawmakers from New York to California have responded with laws that aim to make repairs easier. The Biden \nadministration has encouraged the Federal Trade Commission to advance rules that would stop smartphone \nmakers from restricting independent repairs. But most of the regulations don’t include explicit restrictions on parts \npairing.\nUsing software to control repairs has become commonplace across electronics, appliances and heavy machinery \nas faster chips and cheaper memory turn everyday products into miniature computers. HP has used a similar \npractice to encourage people to buy its ink cartridges over lower-priced alternatives. Tesla has incorporated it into \nmany cars. And John Deere has put it in farm equipment, disabling machines that aren’t fixed by company repair \nworkers.\nApple and other companies have defended the practice by saying it protects customers’ safety and the company’s \nbrand. Shoddy parts, like a faulty face scanner, could compromise the phone’s security, and if an independent shop \nmesses up a repair, the customer often blames Apple instead of the shop, the company has said. The practice also \nallows Apple to create a record of parts in the device, which can be helpful to buyers of secondhand phones.\nBut the increase of pairing parts with software has animated a movement that wants to make repairs cheaper and \neasier. Proponents, which include iFixit, say it would be better for the environment and customers’ wallets to extend \nthe life of devices. They have urged lawmakers to simplify repairs, asking: “Who owns the device after it’s been \npurchased? The customer or the manufacturer?”\n“You basically have to ask permission before doing a repair,” said Nathan Proctor, who has lobbied states for repair \nlegislation on behalf of U.S. PIRG, a nonprofit largely funded by small donors.\nWhen Apple expanded its software limits in 2017, it upended repair businesses. Shakeel Taiyab said iPhone repairs \nat his independent shop in South San Francisco had decreased about 15 percent this year. Some customers with \nissues like cracked screens keep using the phones because they find repairing or replacing it unaffordable.\nFree Geek, a nonprofit based in Portland, Ore., that donates repaired computers and smartphones to \nunderprivileged people, decided that Apple’s software made iPhones too difficult to service, said Amber Brink, Free \nGeek’s director of technology.\nLast year, Free Geek received thousands of donated iPhones but repurposed only 280, Ms. Brink said. “It’s a \nheadache,” she added.\nConsumers who opt against paying top dollar for an Apple-authorized repair may suffer the consequences. In \nFebruary, after Gio Grimaldi, a 15-year-old in New Hampshire, shattered the screen of his iPhone SE on a \nsnowboarding trip, he took it to a nearby repair shop.\nHe said the closest Apple Store was 90 minutes away and had quoted $130 for replacing the screen — 40 percent \nhigher than the independent store. When he took the phone home, it worked fine but was lacking True Tone, a \nsoftware feature that adjusts the screen’s brightness and color to match the ambient lighting.\nYou Paid $1,000 for an iPhone, but Apple Still Controls It\n“That’s just plain stupid,” he said. “I always love Apple as a company, but they’re really stuck up about third-party \nrepairs.”\nOver the past year, New York, Minnesota and California passed bills requiring that electronics manufacturers \nprovide parts, tools and manuals to third parties.\nAfter years of lobbying against such rules, Apple signed on to support California’s law and honor it across the \nUnited States. It has also encouraged the federal government to adopt similar rules, said Brian Naumann, the head \nof Apple’s repair service efforts, who spoke about the right to repairs during a White House event last month.\n“Apple has taken significant steps to expand options for consumers to repair their devices, which we know is good \nfor consumers’ budgets and good for the environment,” Mr. Naumann said.\nBut the California legislation failed to directly address Apple’s practice of using software to control the repair \nprocess. In Oregon, State Senator Janeen Sollman, a Democrat representing an area outside Portland, is part of a \ngroup of lawmakers aiming to pass a state law that would prohibit Apple and others from having restrictions on \nrepairs.\nAs the Oregon legislation has progressed, Apple has encouraged lawmakers to scale it back. Apple paid for a half \ndozen legislators to visit its Silicon Valley headquarters this year, and tried to impress on them how important \nsecurity and safety were to repairs, Ms. Sollman said.\nShe left California unpersuaded. “I said, ‘You’re making it more accessible, but it’s not a true right to repair if you \nhave ultimate control,’” Ms. Sollman said.\nThis article appeared in print on page B1, B2.\nLoad-Date: December 8, 2023"
    },
    {
        "file_name": "The_Economic_Times_Feb2023",
        "header": "China's JD.Com will launch ChatGPT-like product called ChatJD",
        "media": "The Economic Times",
        "time": "February 10, 2023",
        "section": "TECH & INTERNET",
        "length": "423 words",
        "byline": " ",
        "story_text": "China's JD.Com will launch ChatGPT-like product called ChatJD\nThe Economic Times\nFebruary 11, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 423 words\nBody\nChinese e-commerce company JD.Com Inc's unit JD Cloud will launch a product similar to ChatGPT called ChatJD \nthat will be targeted at other businesses, the company said on Friday, reported news agency ReutersThere has \nbeen a lot of interest in generative AI since OpenAI's ChatGPT went live last year. Another Chinese tech giant \nBaidu said it would finish internal testing of its own ChatGPT-style AI chatbot called 'Ernie Bot' in March, joining \ntech companies around the world in the race to develop generative AI technology.Ernie, meaning \"Enhanced \nRepresentation through Knowledge Integration,\" is a large AI-powered language model introduced in 2019, Baidu \nsaid. \nIt has gradually grown to be able to perform tasks including language understanding, language generation, and \ntext-to-image generation, it added.Google, the world's largest search engine, will make artificial intelligence-based \nlarge language models like LaMDA available \"in the coming weeks and months\", according to chief executive officer \nSundar Pichai.OpenAI on February 1, launched a paid version of ChatGPT. The subscription include features such \nas general access to ChatGPT, even during peak times; faster response times; priority access to new features and \nimprovements.The paid version of the AI chatbot can be availed for $20 per month.Currently, ChatGPT Plus is \navailable only to users in the United States. OpenAI said it will begin the process of inviting people waitlist over the \ncoming weeks.\"We plan to expand access and support to additional countries and regions soon,\" the company said \nin a post.Bard's costly mistakeAlphabet's shares tanked more than 9% during regular trading on Thursday, wiping \noff $100 billion off of its market cap, after a report emerged pointing to a factual error made by its newly launched AI \nchatbot Bard.The error was highlighted in a report by news agency Reuters.The company posted a GIF of its new \nAI Bard in action which showed the chatbot giving a factually inaccurate response to a prompt.In the GIF, the \nchatbot is prompted, \"What new discoveries from the James Webb Space Telescope (JWST) can I tell my 9-year \nold about?\"Bard responded with a number of answers, including one suggesting the JWST was used to take the \nvery first pictures of a planet outside the Earth's solar system, or exoplanets.This is where it went wrong as the first \npictures of exoplanets were, however, taken by the European Southern Observatory's Very Large Telescope (VLT) \nin 2004, as confirmed by NASA. For Reprint Rights: timescontent.com\nLoad-Date: February 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I. and TV Ads Were Made for Each Other; Screenland",
        "media": "The New York Times",
        "time": "June 30, 2023",
        "section": "MAGAZINE",
        "length": "1226 words",
        "byline": "Mac Schwerin",
        "story_text": "A.I. and TV Ads Were Made for Each Other; Screenland\nThe New York Times \nJune 27, 2023 Tuesday 22:25 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: MAGAZINE\nLength: 1226 words\nByline: Mac Schwerin\nHighlight: A string of uncanny videos show what generative A.I. and advertising have in common: They chew up \nthe cultural subconscious and spit it back at us.\nBody\nA string of uncanny videos show what generative A.I. and advertising have in common: They chew up the cultural \nsubconscious and spit it back at us.\nEven if I didn’t work in advertising, I would be a connoisseur of commercials. You’re probably one, too. Think of all \nthe tropes you’ve ingested over the years — the forest-green hatchbacks conquering rugged Western landscapes, \nthe miles of mozzarella stretched by major pizza chains. These are the images that let you know what kind of pitch \nyou’re watching, so you won’t be confused when the brand shows up.\nThe same applies to one recent video: It begins, conventionally enough, at a barbecue, where a Smash Mouth song \nis playing and people are chatting happily over beers. But around three seconds in, your amygdala starts paging for \nbackup. The partygoers are laughing too aggressively. A blonde seems to be talking to her beer, which she holds in \na fleshy koozie of misshapen fingers. There are strange shots of lips and drinks, cavorting without ever properly \nmeeting. The beverages keep getting bigger, obscenely big. A fire begins spreading, filling the frame like a space-\nshuttle launch.\nThis is “Synthetic Summer,” a fake beer commercial produced entirely with generative artificial intelligence. It’s \none of a handful of A.I. commercials that have been making the rounds online. “Synthetic Summer” evokes an \nInstagram post from the Cenobites in “Hellraiser”: a buffet of ungodly desires, remorselessly fulfilled. In another A.I. \ncommercial, “Pepperoni Hug Spot,” we find a family pizza restaurant beset by predatory mouths and 1970s wipe \ntransitions. Another video, a fake ad for orange juice by the artist Crypto Tea, cuts between crisp pour shots and \nderanged breakfasters; Donald Trump narrates.\n[Video:  Watch on YouTube.]\nA.I. isn’t pumping this weird stuff out unbidden. Behind each commercial is an impish tech enthusiast with a knack \nfor these new tools, nudging things into absurdity. Chris Boyle, the originator of “Synthetic Summer,” told me his \nprompts for the text-to-video A.I. program included requests for more fire as the commercial progressed. Ultimately, \nthough, it’s a computer that interprets these instructions: The freaky visual smorgasbord it serves up is homegrown, \nand about as close as you can get to the uncanny without resorting to sleep or psilocybin.\nConsidering all the different visions you could use this power to summon, it’s telling that people keep returning to \nthe formulas of the old-school TV commercial. There must be tens of thousands of commercials online, an immense \ncorpus for software to digest. That availability has helped make our young A.I. programs remarkably good at \nreproducing them. Besides, commercials are already recursive, by design. However much they may doodle in the \nmargins, they stick to tried-and-tested principles: sparkling suburban kitchens; slow-motion ice-and-soda splashes; \nA.I. and TV Ads Were Made for Each Other Screenland\npleasant, wordless canoe trips that indicate relief from irritable bowel syndrome or moderate-to-severe plaque \npsoriasis. Every convenient shorthand and hackneyed motif is encoded, over and over, in the ads themselves. A.I. \nswallows it all and spits it back in our faces.\nA.I. tools like Midjourney and Gen-2 are so in thrall to commercials, in fact, that the word itself elicits their respect. \nThe director of “Pepperoni Hug Spot” told me that when he added “TV commercial” to text prompts like “a happy \nfamily eating pizza in a restaurant,” the A.I. rendered clips that were more evenly lit. The best results, Boyle told me, \ncame from prompting the program to deliver something “as generic and middle-of-the-road Americana as possible.”\nCommercials, at this point, are America’s cave paintings: a series of icons we hand down through the years from \none target market to the next. Their visual syntax is often clearer to us than the realities they supposedly draw from. \nI’ve spent my life training my own organic neural network on glamorized images of beachside bonfires, generic \noffice shenanigans, rise-and-grind sports montages, chemically horned-up retirees, unblemished sneakers on gritty \nstreets. I have never dined al fresco to live jazz or surprised a spouse during the holidays with the gift of his-and-\nhers new cars, but my mind can conjure those moments as easily as anything else. Now computers can, too.\nSome of the people who make commercials today are worried that A.I. could take their jobs, just as soon as it \nfigures out how hands work. But asking A.I. to make fake ads gives it a job it already excels at: assistant \nethnographer, media-studies expert, unbiased auditor of cultural tropes. This software, having slurped up the same \ncommercial soup as the rest of us, takes a prompt like “family breakfast” or “outdoor party” and, based on the mass \nof examples on which it has been trained, calculates its way toward some probabilistic mean. It offers a composite \npicture of formulas and clichés — including those we’re usually too immersed in to notice.\nIn that orange-juice ad, for instance, we get a couple of shots of the classic juice pitcher — a wholly superfluous \ninstrument whose purpose is to make us forget that the product is not freshly squeezed. Usually a few slices of \ncitrus, floating elegantly inside, help sell that illusion. The A.I. has seen this fruit but cannot know why it’s there — \nand so the version it creates is a rogue foreign body, a cancerous green lump that starts to subsume the juice \nentirely. In “Synthetic Summer,” the partygoers seemingly don’t know how to drink: They hold cans a few inches \nfrom their faces or latch their lips to the sides. That’s probably because their real-life analogues hardly ever drink in \ncommercials, either; it’s a convention of alcohol ads to show good times without explicitly depicting anyone taking a \nswig. This visual euphemism leaves a gap that A.I. struggles to bridge — and ends up filling with comical, unsettling \nimagery. This is one reason the A.I. commercials reward repeat viewing: Once you get past their grotesqueries, you \nstart seeing fascinating signals buried in the noise.\nUntil the noise changes. One weakness of these tools is that by the time they’ve rounded up a genre’s common \ntropes, the genre may have moved on. “Synthetic Summer,” for instance, has the DNA of a 20-year-old Bud Light \ncommercial; it bears little resemblance to the brand’s latest Super Bowl spot. For the moment, these are fever \ndreams of a recent past.\nAs far as brands are concerned, that’s fine: They need not train A.I. on ads from the glory days of linear television. \nIn a fractured, polarized world, that kind of shared consensus may be obsolete. Companies seem a lot more likely \nto feed their A.I. furnaces with every available piece of data about potential customers — everything you’ve liked, \nbought or posted, every consumer demographic into which you might plausibly fit. The images and videos you see \nthen may or may not be real, but they could easily feature the people and scenes that will most appeal to you or \nplay most intimately on your insecurities. Which, when you think about it, could be a lot creepier than a few extra \nfingers.\nOpening illustration: Screen grabs from YouTube.\nMac Schwerin is a copywriter and freelance journalist based in Washington.\nPHOTOS: PHOTO (MM7); PHOTOS (PHOTOGRAPH FROM YOUTUBE) (MM8-MM9) This article appeared in \nprint on page MM7, MM8, MM9, MM10.\nA.I. and TV Ads Were Made for Each Other Screenland\nLoad-Date: June 30, 2023"
    },
    {
        "file_name": "USA_Today_Aug2023",
        "header": "Remain relevant as AI develops",
        "media": "USA Today",
        "time": "August 30, 2023",
        "section": "BUSINESS; Pg. B2",
        "length": "679 words",
        "byline": " ",
        "story_text": "Remain relevant as AI develops\nUSA Today\nAugust 30, 2023 Wednesday\n1 Edition\nCopyright 2023 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B2\nLength: 679 words\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader's Guide to Work in an Age of Upheaval.\"\nQuestion: With the proliferation of generative AI, I am worried about being replaced. Do you expect the additional \nproductivity AI creates to displace workers? What can I do to ensure I am seen as a valued employee? - Whitney\nAnswer: I can understand why you, or any of us, may be apprehensive about being displaced by artificial \nintelligence! New research reveals that nearly one-quarter (23%) of U.S. workers are concerned that workplace \nautomation will replace their job in the next five years. Workplace automation has already impacted nearly 10% of \nU.S. workers. AI may displace some jobs, but it is just as likely to result in the creation of new jobs too. Remember \nthat AI is designed to help us, not to replace human connection. AI isn't all-encompassing; it has its limits. Work will \nalways need the human component because what we create and produce ultimately serves other humans.\nEven before AI existed, there have always been steps employees could take to demonstrate their value to their \norganization. That will not change. For instance, you can take on new assignments or projects and volunteer to help \nwherever needed. Do more than asked and do it well. And be on the lookout for more efficient or cost-effective \nways of doing things in your job.\nIt's also essential to continue to learn and grow your skills by taking classes, receiving training, or taking advantage \nof other professional development opportunities. Be a problem solver and share your ideas with your manager.\nMake no mistake, AI will be a reality. We can choose to run from it and limit our opportunities and growth or \nembrace it to expand our performance, productivity and potential. Careers aren't linear, so our skill sets shouldn't be \nstatic. The world of work will need people to develop the knowledge and expertise to manage, monitor and measure \nthe output of AI. Explore how AI may be relevant in your role and career. Be proactive and talk with your supervisor \nabout AI and how to better serve customers, clients and the organization.\nAI is not going anywhere anytime soon, so now is a pivotal time for us to figure out how to leverage AI to our \nadvantage. Don't let fear of technology blind you to the opportunities it presents for your growth and advancement.\nHow will my lack of a formal university degree affect my chances of obtaining a new position in the HR field, despite \nhaving 15 years of experience as an HR generalist and director and certifications? - Kelley\nThe challenges you face may depend on the level of HR job you are interested in. Sometimes higher-level HR jobs \nrequire a degree, but not always. Your substantial experience, along with your certifications, can offset not having a \ndegree. Research suggests 9 out of 10 employers report being ready to accept candidates without a four-year \nRemain relevant as AI develops\ncollege degree. In addition, the study also found 66% of employers are open to hiring candidates with a recognized \ncertification.\nOnce you identify a position of interest, review the minimum position requirements. The job posting may list a \ndegree, but if it also includes the words \"desired\" or \"preferred,\" then the degree is not a requirement. Tailor your \nresume specific to the job you are applying for and highlight how your experience directly matches what the \ncompany is looking for, such as the skills, knowledge, and abilities to perform certain HR functions. And highlight \nyour achievements in 15 years of HR experience that have been impactful in your previous and current \norganizations.\nEven if a degree is required, apply for it. What do you have to lose? You can include in your cover letter why you \nfeel you are the best candidate for the job, despite not having a degree.\nI hope these suggestions will help you land your next dream job! Best wishes.\nJohnny C. Taylor Jr.\nColumnist\nUSA TODAY\nGraphic\n \nEven before AI existed, there have always been steps employees could take to demonstrate their value to their \norganization.\nGetty Images\nLoad-Date: August 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "A.I. Is the Future of Photography. Does That Mean Photography Is Dead?",
        "media": "The New York Times",
        "time": "December 27, 2023",
        "section": "OPINION",
        "length": "1905 words",
        "byline": "Gideon Jacobs",
        "story_text": "A.I. Is the Future of Photography. Does That Mean Photography Is Dead?\nThe New York Times \nDecember 26, 2023 Tuesday 15:41 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1905 words\nByline: Gideon Jacobs\nHighlight: A.I. generators can produce photorealistic images, which is either an extinction-level event for \nphotographers or a fantastic opportunity. Or both.\nBody\nJohn Szarkowski, the legendary former curator of the Museum of Modern Art, once described photography as “the \nact of pointing.” And for the nearly 200 years since its inception, photography has consisted of capturing a visual \nperspective from the physical world using light — first with light-sensitive plates, then film, then digital sensors. \nWhen digital cameras became widely available, many photographers lamented the move away from analog \ntechnology, but basically Szarkowski’s definition still held: Photography consists of pointing, as a reaction to \nsomething that exists in the world.\nWith advent of A.I. image generators, however, this definition feels obsolete.\nGenerative A.I. tools can produce photorealistic images, typically in response to written prompts. These images are \navailable for purchase from major stock photography agencies alongside traditional photos. They routinely go viral \nbefore being debunked. They even occasionally win prestigious photography prizes. All of which has reignited a \ntwo-century-old debate: What exactly qualifies as a photograph?\nThis is not a matter of etymological nitpicking. Calling A.I. images “photographs” — a practice I encounter often — \ncan add to a sense of disorientation in what already feels like a profoundly disorienting moment. Thanks to the \nubiquity of digital cameras, we live in a world that’s already flooded with photographs; more than a trillion are taken \neach year. These digital images can already be easily manipulated through existing tools, including ones built into \nyour phone. Yet they still have some direct relationship to real scenes and events that have occurred.\nNow we face a new deluge of images that, however artful or convincing, are at a remove from the world. A.I. \nimages are typically digital composites of countless existing photographs, so by what definition are they themselves \nreal? No wonder some observers are asking: How can we believe anything we see?\nAside from very real concerns about the livelihoods of professional photographers, especially those who work in \ncommercial photography, I worry that A.I. image generators may leave society as a whole more vulnerable to \nwidespread manipulation — as presaged by hoax A.I. images of Donald Trump violently resisting arrest or, \nsomewhat more comically, of Pope Francis wearing a Balenciaga-inspired coat.\nBut for all the negative potential, I can also see a possibility that these developments will start a conversation about \n— and foster an educated skepticism of — all visual media and the relationship of these images, however they are \nmade, to so-called truth.\nArtists, writers and theorists have long remarked on our very human tendency to project slippery ideas about truth \nonto two dimensional surfaces. In 1921, Franz Kafka was told about a miraculous machine that could automatically \ntake one’s portrait, a “mechanical Know-Thyself.” He offered up his name for the apparatus: “The Mistake-Thyself.” \nA.I. Is the Future of Photography. Does That Mean Photography Is Dead?\nKafka was ahead of his time. In Susan Sontag’s 1977 essay “In Plato’s Cave,” she wrote, “Although there is a \nsense in which the camera does indeed capture reality, not just interpret it, photographs are as much an \ninterpretation of the world as paintings and drawings are.” Each photograph, she argued, is inevitably the product of \ncountless decisions informed, consciously or not, by the photographer’s predilections and biases, as well as the \nlimits and parameters of the technology.\nSo when I hear some people calling the arrival of A.I. an extinction-level event for photography, I often think of the \nFrench painter Paul Delaroche who, legend has it, declared painting “dead” after seeing a daguerreotype, one of \nthe first photographic inventions. Painting did not die; it just evolved into a different kind of artistry, freed from the \nobligations of verisimilitude.\nPhotography has arrived at a similar crossroads. So I asked four artists who work with A.I.-generated images — \nAlejandro Cartagena, Charlie Engman, Trevor Paglen and Laurie Simmons — to talk to me about how they’re \nthinking about the technology and where we might go from here.\nThis conversation has been edited and condensed.\nGideon Jacobs: Alejandro, you probably have the most experience of anyone here with documentary photography. \nHow do you feel when A.I. images are called photos?\nAlejandro Cartagena (a photographer and the publisher of Fellowship, a site dedicated to elevating photography \nand exploring postphotography imagery): Yes, these images are photographic — in some sense. For example, the \ncomputer models understand framing photographically. They understand how to use the horizon. They understand \nhow to frame a portrait based on 180 years of photographic diarrhea. These models are looking at images, and the \nmost predominant type of image out there is the photograph. I believe this kind of technology was inevitable \nbecause what else were we supposed to do with the trillions of images that have been generated?\nJacobs: That’s so interesting — the idea that these image generators were somehow a natural next step, that we \nhad to find a way to make the glut of photos useful, otherwise we’ve spent the last century amassing an enormous, \nuseless, garbage pile of visual noise.\nLaurie Simmons (an artist and photographer): Terrence McKenna once said, “Stop consuming images and start \nproducing them,” which is kind of an interesting take on what I have been doing. My first A.I. prompt was on Sept. 2, \n2022, and it was sort of — I saw the earth move! I felt like an A.I. whisperer. But at the same time, it raised so many \nquestions, and it caused me to go down two consecutive paths: the path of making my work and the path of trying \nto understand what was going on with this technology culturally, politically and in a corporate sense.\nJacobs: Many have recognized the use of manipulative tools like Photoshop and digital filters for decades, but I \ndon’t remember those conversations ever being as heated as the current one around A.I. images. It seems really \ndifficult to orient oneself or take a position on A.I. when the landscape is constantly shifting. Laurie, does working \nwith an A.I. image generator like DALL.E ever feel to you like a photographic process? Do the resulting images feel \nto you like photographs?\nSimmons: Not really, but I don’t consider myself a photographer. I’m an artist who uses a camera. I see these A.I. \nimages in this sort of interstitial space between drawings, photographs and sculpture. They exist somewhere I don’t \nhave the language for yet.\nCharlie Engman (a photographer and director): I am interested in photographic imagery because of its ostensible \nrelationship to reality, truth or whatever. With A.I., a big criteria for me is how well it is able to make photographic-\nlooking images. I’m not personally interested in systems that make images that look like paintings, illustrations or 3-\nD renderings. I’m invested in the photographic image because it has some kind of direct through line to a notion of \ntruth. Even though I know that images are not true, have never been true, part of me does believe in pictures. Part \nof my interaction with photographs is a willing suspension of disbelief.\nA.I. Is the Future of Photography. Does That Mean Photography Is Dead?\nTrevor Paglen (an artist and geographer): The idea that a photograph, in and of itself, can record some kind of truth \nhas always been a fiction. Look at Gustave Le Gray, right from the get-go. Look at spirit photography. It’s not \npossible to make an unmanipulated image.\nSimmons: When I picked up a camera initially, I was interested in the fact that pictures could lie, the camera could \ntell lies. I was never interested in the truth, which is why working with A.I. is such a natural progression for me.\nPaglen: You never trust a photograph, right? I’m less worried that we are going to lose some notion of being able to \nuse images to make sense of the world, because we have never made sense of the world only by looking at \nimages. When we do, we end up in weird Loch Ness monster territory.\nCartagena: Everything is subjective. Everything is a selection of reality, hence not reality, not truth.\nJacobs: The immense size of the data sets and the way the A.I. generators connect language and image — it \nmakes me wonder if these images are the closest humanity will get to some version of idealism, to seeing Plato’s \nconcept of forms. Maybe DALL.E’s output with the prompt of a word like “cute” is the closest thing we’ll ever have to \nsome consensus of what “cute” looks like.\nCharlie Engman: I recently had an article about my A.I. work published in The New Yorker, and in it I’d sort of \nflippantly said: The amazing thing about A.I. is that I can make, like, 300 pictures a day. Of course, people on the \ninternet read this as the death of creativity! What was so interesting to me is that labor — the time invested in the \ncreation of an image — was an assumed metric of value. So if you can make it that fast, it’s not art.\nCartagena: But it was the same when film transitioned to digital. I remember the heated conversations in the photo \nclub where everybody was like, “You can make 300 images on one shoot? That’s not right! That’s not real \nphotography.”\nJacobs: Reactions to large technological leaps often tend to fall into one of three camps: the alarmist camp, which \nsees the technological leap as unprecedented and negative; an optimist camp, which sees the leap as \nunprecedented and positive; and then a camp we could call the perspectivist camp, which tries to keep things in \nhistorical perspective by assuming the leap is similar to previous leaps in some way — leaps to which society, to \nsome extent, adjusted. So which camp do you each align with when it comes to A.I.?\nEngman: I would position myself in that last camp, the realist camp. Obviously, I have embraced A.I. in my work. I’m \nexcited about its uses from a creative perspective. But I do empathize with people having anxieties about it, and I \nthink we should look at what those anxieties are.\nJacobs: Trevor, are you feeling optimistic, pessimistic or somewhere in between?\nPaglen: Probably none of those. These camps are based on the premise that the development of technologies and \ncivilizational progress have something to do with each other, and I don’t think they do.\nJacobs: Laurie?\nSimmons: I’m going to go with Terence McKenna on this one and say you don’t know enough to worry.\nJacobs: Alejandro?\nCartagena: I guess I am a perspectivist, because I already went through a cycle of fear and anxiety during the \ntransition from film to digital in the 1990s. I entered photography right at that moment, when film photographers \nwere going crazy because they did not want digital photography to be called photography. They felt that if there was \nnothing hitting physical celluloid, it could not be called photography. I don’t know if it’s PTSD or just the weird feeling \nof having had similar, heated discussions almost 20 years ago, but having lived through that and seeing that you \ncan’t do anything about it once the technology is good enough, I’m thinking: Why even fight it? It’s here.\nGideon Jacobs is a critic and a writer on photography.\nA.I. Is the Future of Photography. Does That Mean Photography Is Dead?\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, X (@NYTopinion) and Instagram.\nPHOTO:  (PHOTOGRAPH BY Mat Dryhurt and Holly Herndon FOR THE NEW YORK TIMES)\nLoad-Date: December 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Gift Shopping With Chatbots",
        "media": "The New York Times",
        "time": "December 18, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1233 words",
        "byline": "By Yiwen Lu",
        "story_text": "Gift Shopping With Chatbots\nThe New York Times\nDecember 18, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1233 words\nByline: By Yiwen Lu\nBody\nWith Shopify, Mercari and other retailers rolling out chatbots to help buyers, this holiday shopping season is the first \nto be powered by A.I.\nTo help with my holiday shopping this year, I recently turned to a new personal assistant online. ''I'm looking for a \nChristmas present for my mother, who spends long hours working,'' I typed. ''Is there something she can use in her \noffice every day?'' \n  ''Of course!'' came the instant reply. ''Does your mother have any specific preferences or needs for her office? For \nexample, does she need organization tools, desk accessories, or something to help her relax during breaks?''\n  So began my conversation with Shop A.I., a new chatbot from Shopify, an e-commerce marketplace. Over 10 \nminutes, Shop A.I. and I engaged in a question-and-answer session. I told the chatbot my budget and more about \nmy mother, such as her need to alleviate back pain. Shop A.I. also asked me about my mother's preferred design \nand color for an office chair.\n  More people may eventually replicate this kind of shopping experience. A year after ChatGPT debuted, retailers \naround the world have started rolling out chatbots that are powered by generative artificial intelligence. That \nmakes this holiday season the first when a slew of A.I. chatbots can help shoppers brainstorm and find presents for \ntheir friends and loved ones.\n  In addition to Shopify, chatbots have come out over the past 12 months from Instacart, the delivery company; \nMercari, a resale platform; Carrefour, a retailer; and Kering, which owns Gucci and Balenciaga. Walmart, \nMastercard and Signet Jewelers are also testing chatbots, which may become publicly available as soon as next \nyear.\n  ''In a way, it's recreating an in-store environment, but online,'' said Carl Rivera, a vice president at Shopify who \noversees its Shop app, which hosts Shop A.I. He said the chatbot broke down people's questions into key terms \nand searched relevant products from Shopify's millions of sellers. It then recommends products based on reviews \nand a shopper's purchase history.\n  Retailers have long used chatbots, but previous versions lacked conversational power and typically answered just \na few preset questions, such as the status of an order. The newest chatbots, by contrast, can process prompts and \ngenerate tailored answers, both of which create a more ''personalized and authentic interaction,'' said Jen Jones, \nthe chief marketing officer of the platform Commercetools.\nGift Shopping With Chatbots\n  Whether shoppers want this technology remains a question. ''Consumers like simplicity, so they don't necessarily \nwant to have five different generative A.I. tools that they would use for different purposes,'' said Olivier Toubia, a \nmarketing professor at Columbia Business School.\n  Nicola Conway, a lawyer in London, tried Kering's luxury personal shopper, Madeline, in August to search for a \npink bridesmaid dress for a spring wedding. Madeline was ''intuitive and novel,'' she said, but it gave only one \nrecommendation, an Alexander McQueen corset dress. Ms. Conway did not end up buying it.\n  Kering did not respond to requests for comment.\n  Maggie Weber, a shopping influencer who uses the social media handle @refashionedhippie, said she tried \nMercari's chatbot, Merchat A.I., in May. She asked the chatbot to show her baseball cards, but she was instead \noffered baseballs -- and then hats, bats and jerseys.\n  ''Merchat is still in its infancy,'' Ms. Weber, 34, said. She added that she worried that if she gave the chatbot too \nmuch information, it would start directing personalized ads to her.\n  A Mercari spokeswoman said Merchat used chat history only to recommend products and did not use personally \nidentifiable information. She added that the search bar could be faster for customers who want a specific item, while \nthe chatbot helped those who want ''inspiration for gifts.''\n  Such inspiration was exactly what I needed this season as I had only vague ideas for what to buy my 53-year-old \nmother and my 17-year-old cousin, Jenny.\n  So I tried Shop A.I. After telling the chatbot about my mother's back pain and asking what I could buy to help her \nrelax, Shop A.I. offered to find an ergonomic chair and asked my budget. When I said $100, it came back with a few \npages of product results.\n  ''Can you help me to narrow it down?'' I typed. Shop A.I. then asked about my preferred color for a chair. I said \nblack.\n  Shop A.I. returned more than 300 results, including a $159 camp chair from ROAM Adventure, a $179.99 reclining \nmassage office chair from homrest and a $269.99 CosyGaming executive chair.\n  ''These don't seem to be under $100,'' I wrote, annoyed.\n  ''As a new chatbot, I'm still learning and sometimes the search results may not be accurate,'' Shop A.I. replied. \n''Let me try again and find some black ergonomic chairs within your budget.''\n  Then, it added, ''It seems that I'm having trouble finding black ergonomic chairs within your budget at the \nmoment.''\n  I ended up typing ''black ergonomic chair'' into the search bar myself and set a $100 price range. A $66.81 Victory \nFurniture gaming chair and a $47.96 massage office chair popped up, though they were too big and heavy to be \ngifts.\n  Eventually, I asked Shop A.I. for alternative ideas and received five options, including seat cushions and standing \ndesk converters.\n  I chose the standing desk converter and gave Shop A.I. my $100 budget. This time, the chatbot showed options \nwithin my price range, including a $99 Risedesk standing desk converter. But most of the products did not have \nreviews, which I rely on while shopping online. I didn't buy anything.\n  Shop A.I. was not great at finding a gift for my cousin, either. I wanted to buy Jenny some college dorm \ndecorations featuring her favorite anime series, Violet Evergarden, which follows a character named Violet as she \nrecovers from an unidentified war.\nGift Shopping With Chatbots\n  But Shop A.I. appeared to decide that anything the color violet was connected to my query. It showed me wall art \nof purple mountains and posters of purple BMW cars.\n  So I turned to Mercari's Merchat. After asking for my cousin's hobby (anime), age (17) and what she might prefer \nfor college (dorm decorations), Merchat offered three gift ideas: wall tapestries, string lights and desk accessories in \nthe theme of Violet Evergarden.\n  Merchat showed me four products under each category, all of which were under my budget of $50. I ended up \nbuying an $18 Violet Evergarden poster scroll for Jenny. (She later told me she wished I had gotten her something \nquirkier.)\n  Emboldened by the experience, I asked Merchat to help find a present for my mother. ''Would she benefit from a \nback support cushion, a heating pad or maybe a massage chair pad?'' it asked.\n  ''What are the pros and cons of each?'' I typed.\n  Merchat said it couldn't provide specific pros and cons for individual items. I changed my question to: ''Which one \nis the easiest to use?''\n  This time, Merchat was definitive: the back support cushion, which was portable. Merchat detailed the differences \nbetween a memory-foam cushion and a firmer one, then further grouped memory-foam cushions into three \ncategories and displayed the top four results for each, all under $100.\n  While I didn't buy any because the styles were limited, it was a great starting point.\n  ''Thank you,'' I wrote.\n  ''You're welcome!'' Merchat replied. ''Happy shopping and have a wonderful time with your family!''\nhttps://www.nytimes.com/2023/12/14/technology/shopping-ai-chatbots.html\nGraphic\n \nPHOTOS: Shop A.I. returned more than 300 results for a request to find black ergonomic chairs, though the options \nwere not under the shopper's budget of $100.\n A look at a conversation with Merchat A.I., a chatbot that helps shoppers. ''Merchat is still in its infancy,'' said an \ninfluencer who has tried the chatbot. (B2) This article appeared in print on page B1, B2.               \nLoad-Date: December 18, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "Walmart Looks to Treble Sourcing of Goods from India to $10b a Year",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 13, 2024",
        "section": "COMPANIES",
        "length": "413 words",
        "byline": "Our Bureau",
        "story_text": "Walmart Looks to Treble Sourcing of Goods from India to $10b a Year\nEconomic Times (E-Paper Edition)\nFebruary 14, 2024 Wednesday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 413 words\nByline: Our Bureau\nBody\nNew Delhi: Multinational retail hypermarket Walmart said they have sourced over $30 billion goods from the Indian \nmarket for its global operation in the past 25 years. The company is now set to triple the sourcing of these goods \nfrom India to $10 billion annually by 2027. Andrea Albright, executive vice president of sourcing at Walmart, said \nthat through its Walmart Vriddhi initiative, launched in 2019, the company is training Micro, Small and Medium \nEnterprises (MSMEs) “to learn new capabilities, scale and maximize their business ambitions” free of charge. At its \nGrowth Summit, the company announced that they have met their target early and have already trained more than \n50,000 MSMEs. \nJason Fremstad, Walmart’s senior vice president, supplier development  and sourcing, said, “What we are aiming to \ndo this week is to continue finding new suppliers to source in categorieshome, apparels, foods, health and wellness, \ntoys… this week is focused on expanding those opportunities and finding new suppliers that we can export in an \neffort to achieve the goal that we have set out for sourcing $10 billion by the end of 2027.” The “people-led tech-\npowered omni-channel retailer”, with 2.1 million associates globally, states that their strategy is to save people’s \nmoney and help them live better. The summit was to bring buyers and suppliers together to accelerate exports \nacross the country. “Our focus is to recruit and train new suppliers to fulfil our purchase orders around the world. \nThese orders often lead to the creation of new jobs. It also allows our suppliers to invest back in their local \ncommunities,”  Albright said. Doug McMillion, CEO of Walmart in ajoint video with Walmart international president \nand CEO, Kathryn McLay, said, “Other than the US, India is the only market where we have set a sourcing \nobjective. And that is because we see so much opportunity.” Walmart also aimed to explore potential solutions to \nsupply chain challenges through innovative companies and startups. Albright told ET, “Some of the challenges \ncould range from circularityhow do we continue to find ways to be more sustainable inside of our product. Other \nchallenges might behow we might use Gen-AI or AI to continue to forecast better and get better data to our \nsuppliers. So, there's a range of problems that I think the entire industry is trying to solve. And we're trying to find \nthose right entrepreneurs to learn more from and maybe can create some type of partnerships.”\nLoad-Date: February 13, 2024"
    },
    {
        "file_name": "who_was_found_dead_with_wife_&_twins_in_his_home_Feb2024",
        "header": "Who was Anand Sujith Henry? All about the Indian-origin, ex-Google techie",
        "media": "who was found dead with wife & twins in his home",
        "time": "February 15, 2024",
        "section": "PEOPLE",
        "length": "304 words",
        "byline": " ",
        "story_text": "Who was Anand Sujith Henry? All about the Indian-origin, ex-Google techie \nwho was found dead with wife & twins in his home\nThe Economic Times\nFebruary 16, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: PEOPLE\nLength: 304 words\nBody\nThe much-glorified and sought-after ‘American Dream’ is now slowly transforming into a nightmare for the Indian \ndiaspora. The news of yet another Indian American being killed mercilessly has sent shockwaves throughout the \ncommunity. An Indian-origin ex-Google employee was found dead at his home in California, along with his wife and \nkids. \nAnand Sujith Henry, a 42-year-old engineer, was discovered dead in his home in California, along with his wife \nAlice Priyanka and twin sons Noah and Neithan. “The two children were found deceased inside a bedroom. Their \ncause of death is still under investigation. The male and female were located deceased from gunshot wounds inside \na bathroom,\" the San Mateo Police Department stated. According to reports, the couple has been staying in the US \nfor about nine years. They moved to California from New Jersey. They were originally from Kerala. This incident \nhas left the Indian Americans shell shocked as recently the community had to mourn several deaths. Last week, a \nPurdue University student named Sameer Kamath was found dead in Warren County. Another Purdue student \nnamed Neel Acharya was found dead on the campus. Some months ago, a 25-year-old named Vivek Saini was \nkilled by a homeless man named Julian Faulkner. Who Was Anand Sujith Henry?Henry was an engineer. He \nworked as an IT expert in several companies such as Salesforce, Google, and Meta before floating his own \ncompany Logits. Logits provides Generative AI models to companies to meet their business needs. Currently the \nwebsite of the company is down. Henry was an alumnus of the prestigious Carnegie Mellon University and \nSingapore Management University. The couple had been having some marital disputes. Henry had filed for divorce \nin 2016. However, the couple didn’t divorce. For Reprint Rights: timescontent.com\nLoad-Date: February 15, 2024"
    },
    {
        "file_name": "Schooling;_Teaching_resource_Sep2023",
        "header": "High School Stories: Recent New York Times Reporting on Secondary",
        "media": "Schooling; Teaching resource",
        "time": "September 5, 2023",
        "section": "LEARNING",
        "length": "3001 words",
        "byline": "The Learning Network",
        "story_text": "High School Stories: Recent New York Times Reporting on Secondary \nSchooling; Teaching resource\nThe New York Times \nAugust 16, 2023 Wednesday 14:58 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: LEARNING\nLength: 3001 words\nByline: The Learning Network\nHighlight: A collection of free links to help those participating in our multimedia challenge, “What High School Is \nLike in 2023.”\nBody\nA collection of free links to help those participating in our multimedia challenge, “What High School Is Like in 2023.”\nEducation stories have dominated headlines over the past year, as a quick glance down this long, long list will \nshow. \nIf you are participating in our new multimedia challenge, which invites students and educators to “show or tell us \nwhat high school is like in 2023,” we thought it might help to  understand how The New York Times and other media \nhave looked at the issues and questions facing secondary education. \nBelow, over 75 news, feature stories and Opinion pieces about school, teaching, learning and teenage life that have \nappeared across sections of NYTimes.com over the last year.  They are free to read, as are all Times pieces linked \nfrom The Learning Network  — as long as you access them from our site. We will continue to update this collection \nuntil the contest ends on Oct. 4.\nWhere should you begin? We recommend the wonderful teen-created piece “What Grown-Ups Don’t Understand \nAbout School,” published in September 2022. \nThen, as you scroll through the rest, you might choose pieces on topics that especially interest you and ask yourself \n…\n• What, if anything, seems to be missing? Is there information or context that could have made this piece \nstronger?\n• How could my background, knowledge or perspective make me an authority on this topic? What would I like to \nsay about it?\n• What other stories about my experiences in school do these pieces remind me that I could tell?\nFor Students\nThe Role of School \nWhat is school for?\nWhat Grown-Ups Don’t Understand About School\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nIn September of 2022, The New York Times Opinion section asked a number of experts the question, What is \nschool really for? Our favorite answer: this one by the students at Oakland’s Fremont High, who answered with their \ncameras. \nBefore you read anything else, we hope you’ll take a look at their work. We have also published a related lesson \nplan\nThen, if you’d like to continue, there are the other pieces in the What Is School For? series:\nSchool Is for Everyone\nSchool Is for Social Mobility\nSchool Is for Making Citizens\nSchool Is for Care\nSchool Is for Wasting Time and Money\nSchool Is for Learning to Read\nSchool Is for Connecting to Nature\nSchool Is for Merit\nSchool Is for Hope\nSchool Is for Parent Activism\nSchool Is for Teaching\nLearning\nHow do you learn best? Does your school support those ways of learning?\nThere Are Better Ways to Study That Will Last You a Lifetime (Opinion)\nTemple Grandin: Society Is Failing Visual Thinkers, and That Hurts Us All (Opinion)\nThe Key to Success in College Is So Simple, It’s Almost Never Mentioned (Opinion)\nHow the Arts Can Benefit Your Mental Health (No Talent Required)\nMy Unlikely Writing Teacher: Pedro Martinez\nYour Identity and School\nHow does who you are affect your learning — and your experience in school in general?\nWhat It’s Like to Be a Queer Teenager in America Today\nAsian American Students Face Bias, but It’s Not What You Might Think (Opinion)\n‘Luddite’ Teens Don’t Want Your Likes\nYoung and Homeless in Rural America\nAt Camp Naru, Nobody Is ‘an Outlier’\nAs a Child in Haiti, I Was Taught to Despise My Language and Myself (Opinion)\nStrife in the Schools: Education Dept. Logs Record Number of Discrimination Complaints\nWhen Students Change Gender Identity, and Parents Don’t Know\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nStuyvesant High School Admitted 762 New Students. Only 7 Are Black.\nHow Educators Secretly Remove Students With Disabilities From School\nWoman, 29, Enrolled in High School and Pretended to Be a Teenager\nThe Instagram Account That Shattered a California High School\nSpecial Schools or Programs\nWhat makes your school unique?\nInside ‘the Hogwarts of Fashion’\nBrooklyn’s Lifeguard Factory Is Open Again\nA Video-Gaming School Stumbles on a Way to Get Dropouts Back in Class\nCommunity Schools Offer More Than Just Teaching\nInside a New Arts Program for Queens Teens\nSorry, You’ve Been Rejected. Now Let’s Party.\nStruggling Schools in New Mexico See Results After Partnerships\nA Religious School That’s Also a Public School\nCurriculum\nWhat do — and don’t — you learn in school? What do you wish you could learn?\nIn California, a Math Problem: Does Data Science = Algebra II?\nWhy We Don’t Agree on High School Required Reading (Podcast)\nInside the College Board’s Revised African American Studies Curriculum\nWho’s Afraid of Black History? (Opinion)\nIn Memphis, the Phonics Movement Comes to High School\nFlorida Scoured Math Textbooks for ‘Prohibited Topics.’ Next Up: Social Studies.\nFlorida Schools Question Content on Gender and Sexuality in A.P. Psychology\nWhen Teens Find Misinformation, These Teachers Are Ready\nWhat Do Middle Schools Teach About Climate Change? Not Much.\nWhat’s Actually Being Taught in History Class\nFlorida at Center of Debate as School Book Bans Surge Nationally\nAfter Roe, Sex Ed Is Even More Vital (Opinion)\nWhat Teaching History in Texas Looks Like (Opinion)\nPolitics and Law\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat issues, small or large, has your school community recently confronted?\nWhat the Science Says About ‘Don’t Say Gay’ and Young People (Opinion)\nStudent Cannot Wear Sash of Mexican and U.S. Flags at Graduation, Judge Rules\nHigh School Student Suspended After Recording Teacher Using a Racial Slur\nInside a Brooklyn School Teaching the Course That Florida Banned\nStudents Walk Out of School in Support of Ralph Yarl\nIt’s Getting Hard to Stage a School Play Without Political Drama\nA Student Sues After Suspension for Mocking Principal on Instagram\nMichigan Students Sue School District Over ‘Let’s Go Brandon’ Ban\nDeSantis Faces Swell of Criticism Over Florida’s New Standards for Black History\nFlorida Schools Try to Adapt to New Rules on Gender, Bathrooms and Pronouns\nDivided House Passes G.O.P. Bill on Hot-Button Schools Issues\nAttempts to Ban Books Are Accelerating and Becoming More Divisive\n$7,200 for Every Student: Arizona’s Ultimate Experiment in School Choice\nVirginia Reverses School Protections for Transgender Students\n‘Channeling the Mama Bear’: How Covid Closures Became Today’s Curriculum Wars\nArkansas Warns School Districts Not to Offer A.P. African American Studies\nThe Instagram Account That Shattered a California High School\nCatholic School System Directs Students to Use Pronouns Assigned at Birth\nHealth\nWhat roles do your physical and mental health play in your learning? \nThe Income Gap Is Becoming a Physical-Activity Divide\nTeenagers Keep Vaping Despite Crackdowns on E-Cigarettes\nMore and More Teenagers Are Coming to School High, N.Y.C. Teachers Say\nUse of Marijuana and Psychedelics Is Soaring Among Young Adults, Study Finds\nHow to Help a Teen Who Can’t Sleep\nPuberty Blockers Can Help Transgender Youth. Is There a Cost?\nTeen Girls Report Record Levels of Sadness, C.D.C. Finds\nThe Daily: Inside the Adolescent Mental Health Crisis (Podcast)\nA Teen’s Journey Into the Internet’s Darkness and Back Again\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nMeeting the Mental Health Challenge in School and at Home\n‘Disruptive,’ or Depressed? Psychiatrists Reach Out to Teens of Color\nE.R. Visits for Teenage Girls Surged During the Pandemic\n‘Mindful Breathing’ Will Now Be Required in New York City Schools\nAfter Teen’s Suicide, a New Jersey Community Grapples With Bullying\nTeenagers Are Telling Us That Something Is Wrong With America (Opinion)\nThe Collateral Damage of A.D.H.D. Drug Shortages\nPandemic Effects\nHow have the pandemic years affected your relationship to school?\nThe Pandemic Generation Goes to College. It Has Not Been Easy.\nBack to School and Back to Normal. Or at Least Close Enough.\nParents Don’t Understand How Far Behind Their Kids Are in School (Opinion)\nCould Tutoring Be the Best Tool for Fighting Learning Loss?\nPandemic Learning Loss Is Not an Emergency (Opinion)\nFamilies Struggle as Pandemic Program Offering Free School Meals Ends\nThe Key to Getting Students Back in Classrooms? Establishing Connections.\nCovid Closed the Nation’s Schools. Cleaner Air Can Keep Them Open.\nTest Scores\nWhat do you think the results of standardized tests tell us about learning? What is your relationship with these kinds \nof tests?\nU.S. Students’ Progress Stagnated Last School Year, Study Finds\nWhat the New, Low Test Scores for 13-Year-Olds Say About U.S. Education Now\nThe Daily: The Nation’s ‘Report Card’ on Remote Learning (Podcast)\nGenerative Artificial Intelligence\nHow have you and your teachers and school responded to the rise of generative artificial intelligence like \nChatGPT? What does it mean for teaching and learning?\nHow Schools Can Survive (and Maybe Even Thrive) With A.I. This Fall\nHow teachers and students feel about A.I.\nDespite Cheating Fears, Schools Repeal ChatGPT Bans\nThe Daily: Suspicion, Cheating and Bans: A.I. Hits America’s Schools (Podcast)\nIn Classrooms, Teachers Put A.I. Tutoring Bots to the Test\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nAt This School, Computer Science Class Now Includes Critiquing Chatbots\nHow Will Chatbots Change Education? (Opinion)\nDon’t Ban ChatGPT in Schools. Teach With It.\nBan or Embrace? Colleges Wrestle With A.I.-Generated Admissions Essays.\nWe Used A.I. to Write Essays for Harvard, Yale and Princeton. Here’s How It Went.\nExtracurricular Activities\nWhat role have extracurricular activities played in your education?\nIt’s Getting Hard to Stage a School Play Without Political Drama\nA Championship Season in Mariachi Country\nWhere the Band Kids Are\nThousands of Teens Are Being Pushed Into Military’s Junior R.O.T.C.\nOne Solution to the Digital Divide: Teens\nSome Kids Play Sports. These Kids Train Wild Horses.\nThe Best Extracurricular May Be an After-School Job (Opinion)\nStudent Journalists Reveal a Changing World. Let Them. (Opinion)\nSports\nWhat has been your experience with school sports?\nHelmet Shortage in High School Football Raises Costs, and Risks\nA Summer Basketball Refuge Thrives in the Bronx’s Largest Housing Complex\nFencing Can Be Six-Figure Expensive, but It Wins in College Admissions\nAt This Wrestling Academy, Indian Girls Are ‘Set Free’\nEnd of All-Girls Swim Class Causes Controversy at Stuyvesant High School\nWhy Have We Allowed Money to Ruin Youth Sports? (Opinion)\nTitle IX and the New Rule on Transgender Athletes Explained\nSex Discrimination Case in Hawaii Could Change High School Sports Across the U.S.\nThe Real Enforcers of Gender Equity in Sports: Angry Parents\nThe College Process and Affirmative Action\nWhat does the college process look like at your school? For you? How might the repeal of affirmative action affect \nthat process?\nWith Supreme Court Decision, College Admissions Could Become More Subjective\nRuling Raises Uncertainty for High School Students Heading to College\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nAfter the Affirmative Action Ruling, Asian Americans Ask What Happens Next\nThe ‘Unseen’ Students in the Affirmative Action Debate\nThe Daily: How Affirmative Action Changed Their Lives (Podcast)\nI’m in High School. I Hope Affirmative Action Is Rejected and Replaced With Something Stronger. (Opinion)\nColleges Want to Know More About You and Your ‘Identity’\nWith End of Affirmative Action, a Push for a New Tool: Adversity Scores\nThe Legacy Dilemma: What to Do About Privileges for the Privileged?\nThe Real, Hidden Truth About College Admissions (Opinion)\nDespite Years of Criticism, the U.S. News College Rankings Live On\nThere’s Only One College Rankings List That Matters\nHarvard or Happiness? 11 High School Seniors Debate College Rankings\nThese 12 College Students Don’t Like the System They’re In\nCan the Meritocracy Survive Without the SAT? (Opinion)\nI Edited Mental Illness Out of My College Applications. I’m Not Alone. (Opinion)\nSchool Shootings and Violence\nHow has violence, or the threat of it, shaped your educational experience?\nA Place of Sanctuary Is Punctured by the Reality of Gun Violence in America\nThe Daily: The Parkland Students, Four Years Later (Podcast)\nPanic Buttons, Classroom Locks: How Schools Have Boosted Security\nMichigan School District Bans Backpacks Over Safety Concerns\n‘Our Schools Have Become Battlefields’: Teachers Consider Arming Themselves in the Classroom (Opinion)\nGun Violence Has Changed Us\nSchools Bring Police Back to Campuses, Reversing Racial Justice Decisions\nBehind a Surge in Teenage Killings: Grief, Anger and Online Grudges\nEducation Around the World\nHow does education around the world compare to the United States? What does it reveal about your own schooling \nexperience, whether in the U.S. or abroad?\nClean Toilets, Inspired Teachers: How India’s Capital Is Fixing Its Schools\nAnother Casualty in Ukraine: Teenage Years\n‘My School Had No Chairs, No Blackboards, No Books’\nSouth Korea to Drop ‘Killer Questions’ From College Entrance Exam\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nIn Russian Schools, It’s Recite Your ABC’s and ‘Love Your Army’\n‘Brainwashing a Generation’: British Schools Combat Andrew Tate’s Views\nPhilippines Returns to School, Ending One of World’s Longest Shutdowns\nHow Finland Is Teaching a Generation to Spot Misinformation\nDecades on From Peace, Northern Ireland Schools Are Still Deeply Divided\nA Yiddish Haven Thrives in Australia\nNew Russian High School Textbooks Seek to Justify War in Ukraine\nUkrainian students begin a new school year in the shadow of war.\nNew data shows ‘widespread learning loss’ among Ukraine’s children.\nSchool Buildings\nWhat is your learning environment like? How has it affected your education?\nSchool District Woes Likened to ‘Environmental Racism’ in Flint, Mich.\nAn Ice Factory From the 1900s Is Now a Spectacular New Bronx School\nHigh Temperatures Close Schools in Several U.S. Cities\n‘We’ll Teach Out of Anywhere’: In Flooded Kentucky, Schools Race to Rebuild\nSchool Is in Session, Power or Not\nWhy Haven’t We Made It Safer to Breathe in Classrooms? (Opinion)\nThankful for Libraries (Opinion)\nFor Educators\nWhat has your experience as an educator been like in recent years? What does the world not understand about \nwhat it is like to be a teacher right now? \n(Note: Please keep in mind that for this challenge we consider any adult working in a secondary school an \neducator, and we would love to hear from you, whether you are a counselor, administrator, coach, librarian, \nmaintenance worker, school secretary, chef or teacher.)\nThese 12 Teachers Don’t See Themselves as Superheroes\nA Freewheeling 91-Year-Old Principal Retires\nLibrarians Are Meeting Younger Readers Where They Are: TikTok\nTexas Revamps Houston Schools, Closing Libraries and Angering Parents\nFlorida Schools Try to Adapt to New Rules on Gender, Bathrooms and Pronouns\nPlease Don’t Call My Job a Calling (Opinion)\nWhat’s Actually Being Taught in History Class\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nEmpty Classrooms, Abandoned Kids: Inside America’s Great Teacher Resignation (Video)\nTeachers, Facing Increasing Levels of Stress, Are Burned Out\nThere’s a Reason There Aren’t Enough Teachers in America. Many Reasons, Actually. (Opinion)\nHow Bad Is the Teacher Shortage? Depends Where You Live.\nOne Way to Ease the Teacher Shortage: Pay More, Some Districts Say\nLos Angeles School Workers Are on Strike, and Parents Say They Get It\nDaring to Speak Up About Race in a Divided School District\nWhat It Is Like to Teach in the Cross Hairs of Ron DeSantis (Opinion)\n‘Kids Can’t Read’: The Revolt That Is Taking On the Education Establishment\nThe Sunday Read: ‘The Most Dangerous Person in the World Is Randi Weingarten’ (Podcast)\nMany States Omit Climate Education. These Teachers Are Trying to Slip It In.\nWhat Mrs. Bailey Taught Me in A.P. History Changed My Life (Opinion)\nTrading Books for a Rifle: The Teacher Who Volunteered in Ukraine\nI Love My Students, but I Won’t Use a Gun to Protect Them (Opinion)\nThe Shortage in School Bus Drivers Is Getting Worse\nFrom The Learning Network\nTeen Voices From Our Current Events Conversation\nWhat Students Are Saying About the Growing Fight Over What Young People Can Read\nWhat Students Are Saying About ChatGPT\nWhat Students Are Saying About Coed Sports\nWhat Students Are Saying About the C.D.C. Report on Teen Sadness\nWhat Students Are Saying About What Motivates Them to Learn\nWhat Students Are Saying About the Value of Math\nWhat Students Are Saying About How Their Teachers Have Shaped Them\n‘They Deserve Better’: What Students Are Saying About Respect and Pay for School Workers\nWhat Students Are Saying About Having a Part-Time Job While in School\nWriting Prompts\nWhat Is It Like to Be a Teenager Now?\nWhat Motivates You to Learn?\nDo You See the Point in Learning Math?\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat Is Your Reaction to the Growing Fight Over What Young People Can Read?\nWhat Is the Purpose of Teaching U.S. History?\nWhat Do You Think About the Controversy Surrounding the New A.P. Course on African American Studies?\nShould Students Learn About Climate Change in School?\nShould Teachers Provide Trigger Warnings for ‘Traumatic Content’?\nWhat Should Free Speech Look Like on Campus?\nHow Can Schools Engage Students Who Are at Risk of Dropping Out?\nHow Have Your Teachers Shaped Who You Are?\nHow Should Schools Respond to ChatGPT?\nWhat Don’t Adults Understand About Teenage Life Online?\nHow Are You Using A.I.?\nShould We Get Rid of Homework?\nShould All High School Students Have Part-Time Jobs?\nDo School Employees Deserve More Respect — and Pay?\nHow Much Do You Think It Matters Where You Go to College?\nDo You Support Race-Conscious College Admissions Policies?\nHow Much of Your Real Self Have You Revealed on Applications?\nHow Should Adults Talk to Kids About Drugs?\nWhat Are Your Thoughts on Uniforms and Strict Dress Codes?\nShould More Sports Be Coed?\nWhat Are You Doing to Take Care of Your Health?\nDo You Have Enough Access to Places Where You Can Play and Exercise?\nWhat Is Your Reaction to the New Report About Teen Sadness?\nHow Do You Hold It Together When You’re Feeling Stressed?\nDo Schools Need to Do More to Support Visual Thinkers?\nHow Did You Grow and Change This School Year?\nDo You Suffer From ‘Task Paralysis’?\nHave You Ever Felt as if You Didn’t Belong?\nHow Do You Get Over Rejection?\nHow Has the Threat of Gun Violence Affected You?\nHigh School Stories: Recent New York Times Reporting on Secondary Schooling Teaching resource\nWhat Can We Learn From Older Adults?\nWhat Is the Best Thing About Being Your Age?\nWhat Role Do Libraries Play in Your Life?\nPHOTO: Erica Robson, center, a drama teacher, directs students during a rehearsal for “Sweeney Todd: The \nDemon Barber of Fleet Street” at Los Angeles County High School for the Arts in Los Angeles. Related Article \n(PHOTOGRAPH BY Jenna Schoenefeld for The New York Times FOR THE NEW YORK TIMES)\nLoad-Date: September 5, 2023"
    },
    {
        "file_name": "The_Economic_Times_Nov2023",
        "header": "ETtech Exclusive | Adobe acquires Indian generative AI startup Rephrase.ai",
        "media": "The Economic Times",
        "time": "November 22, 2023",
        "section": "STARTUPS",
        "length": "651 words",
        "byline": "Tarush Bhalla",
        "story_text": "ETtech Exclusive | Adobe acquires Indian generative AI startup Rephrase.ai\nThe Economic Times\nNovember 22, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS\nLength: 651 words\nByline: Tarush Bhalla\nBody\nAmerican software multinational Adobe has acquired Bengaluru-based Rephrase.ai, which provides an artificial \nintelligence(AI)-powered video creation platform, senior executives of the software giant told employees in an \ninternal memo. With the acquisition, Adobe will look to integrate Rephrase’s tech stack and generative AI video \ncapabilities with its inhouse video-editing platform, Creative Cloud, and bolster its offerings. This is expected to help \nAdobe accelerate its ability to provide AI-powered video content tools to its organisation customers.As part of the \ndeal, a majority of Rephrase’s team members will join Adobe, sources aware of the talks told ET, requesting \nanonymity. ET could not ascertain the final deal size. \nThis also marks the first-ever deal for Adobe in the generative AI and video-tooling space. It also makes Rephrase \nthe first Indian startup to be acquired by Adobe, which has largely made acquisitions in its home market, the US, \nand in Europe.“The Rephrase.ai team’s expertise in generative AI video and audio technology and experience-\nbuilding text-to-video generator tools will extend our generative video capabilities — and enable us to deliver more \nvalue to our customers faster — all within our industry-leading creative applications,” Ashley Still, senior vice \npresident and general manager, Creative Cloud, wrote in an internal memo to employees on Tuesday.ET has seen \nthe copy of the memo sent to its India staff.With the acquisition, Rephrase’s investors will be given a complete cash \nexit, with the founders being paid in cash and Adobe stock, a source cited above added. “With competition ramping \nup on the Big Tech side with Generative AI, the success of tools built (with it) finally, will depend on a distribution \nplay and how many organisations are implementing your tool. In that regard, bigger organisations like Adobe will \nalways have an advantage over smaller competition,” said one of the sources cited earlier, who was aware of the \ndeal talks. Last week, Microsoft Azure introduced text-to-speech capabilities for digital avatars, through its Azure AI \nSpeech offering, amping up competition against domestic players such as Rephrase. Queries sent to Rephrase \nfounder Ashray Malhotra and investor Lightspeed India have not elicited a response so far. “Adobe has a strong \ntrack record of accelerating growth through both organic and inorganic innovation. We are always on the lookout for \nnew talent and technology that supports our strategy and creates more value for our stakeholders,” said an Adobe \nspokesperson, in response to ET’s queries. Backed by the likes of Lightspeed India, Silver Lake, 8VC, Red \nVentures and Techstars, Bengaluru-based Rephrase provides a text-to-video generation platform that removes \ncomplexities, and enables organisations to create professional looking videos. It helps influencers and video \ncreators build digital avatars. It also enables marketing teams to build digital avatars of their brand ambassadors, \nrecord personalised messages and send them to customers, all on the same platform. The firm, founded by IIT \nBombay graduates, Malhotra, Nisheeth Lahoti and IIT Roorkee alumni Shivam Mangla, has raised $13.9 million till \ndate. In September, last year, the company raised $10.6 million in a round led by American media company Red \nVentures.Adobe’s Gen AI playCurrently, Adobe’s Creative Cloud suite includes professional editing and workflow \nmanagement tools, including Premier Pro, After Effects, Audition, Character Animator and Frame.io. In March, the \nUS multinational announced its entry into the Generative AI space with a new model, Firefly, in beta launch mode. \nThe move was focused on bringing generative AI tools to its suite of apps and services.In October, at Adobe Max, \nETtech Exclusive | Adobe acquires Indian generative AI startup Rephrase .ai\nits annual creativity conference, the company previewed its generative AI-to-video capabilities. For Reprint Rights: \ntimescontent.com\nLoad-Date: November 22, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Aug2023",
        "header": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts",
        "media": "Economic Times (E-Paper Edition)",
        "time": "August 21, 2023",
        "section": "STARTUPS & SPORTS",
        "length": "338 words",
        "byline": "Romita.Majumdar@timesgroup.com",
        "story_text": "AI to Replace 5% Full-time Tech Roles Annually in 5 Yrs: Experts\nEconomic Times (E-Paper Edition)\nAugust 18, 2023 Friday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & SPORTS\nLength: 338 words\nByline: Romita.Majumdar@timesgroup.com\nHighlight: HOWEVER... Experts see creation of high-level jobs, involving more decision making, strategic calls\nBody\nMumbai:Artificial Intelligence (AI) will replace up to 5% FTE or full-time technology roles annually over the next 4-5 \nyears, said analysts.  However, while basic jobs are replaced with AI-based automation solutions, technology \nexperts expect a higher level of jobs to be created which will involve less support roles and more decision making \nand strategic roles. Roles in AI ethics and sustainability practices will also come in demand. \n Executives from leading automation companies like ServiceNow and UiPath see this change in job profiles \nevolving over the years as enterprises themselves figure out their AI strategy. Historically, whenever a \ngroundbreaking new technology is introduced in any sector, it just leads to a  lot more new work, ServiceNow CTO \nPat Casey told ET during an interaction in July. “If you look at the larger tech ecosystem, there is always a dearth of \nengineering talent. So, if certain jobs are automated, it will not mean that people will become jobless, just that they \nwork on more valueadded work elsewhere,” said Casey. According to a study by McKinsey Global Institute titled \nGenerative AI and the Future of Work in America, in June, an estimated 12 million occu-  pational transitions may \nbe required in the US alone by 2030. The maximum impact on productivity will be in the areas of marketing and \nsales. It will also have a significant impact on functions like customer operations, product development and software \ndevelopment.  Outsourcing expert Pareekh Jain estimates about 5% FTE roles annually to mature to newer roles as \nthey are replaced by AI tools.  “It will not be a massive shift over-  night. It is the support roles that do not require \nmuch decision-making capabilities where such changes will happen and they have already been in progress for \nyears,” said Jain. He added that there could be some nearterm impact on certain low-level jobs before companies \nfully assess the efficiency of such tools. But the longterm impact will be small. FOR FULL REPORT, GO TO \nwww.economictimes.com\nLoad-Date: August 21, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Feb2024",
        "header": "Can a Tech Giant Be Woke?",
        "media": "The New York Times - International Edition",
        "time": "February 26, 2024",
        "section": "BUSINESS",
        "length": "3854 words",
        "byline": "Noam Scheiber",
        "story_text": "Can a Tech Giant Be Woke?\nThe New York Times - International Edition\nFebruary 27, 2024 Tuesday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 3854 words\nByline: Noam Scheiber\nBody\nABSTRACT\nMicrosoft, once again a juggernaut thanks to artificial intelligence, wants to be seen as an ethical employer. Is there \na catch?\nFULL TEXT\nThe December day in 2021 that set off a revolution across the videogame industry appeared to start innocuously \nenough. Managers at a Wisconsin studio called Raven began meeting one by one with quality assurance testers, \nwho vet video games for bugs, to announce that the company was overhauling their department. Going forward, \nmanagers said, the lucky testers would be permanent employees, not temps. They would earn an extra $1.50 an \nhour.       \nIt was only later in the morning, a Friday, that the catch became apparent: One-third of the studio's roughly 35 \ntesters were being let go as part of the overhaul. The workers were stunned. Raven was owned by Activision \nBlizzard, one of the industry's largest companies, and there appeared to be plenty of work to go around. Several \ntesters had just worked late into the night to meet a looming deadline.       \n\"My friend called me crying, saying, 'I just lost my job,'\" recalled Erin Hall, one of the testers who stayed on. \"None \nof us saw that coming.\"       \nThe testers conferred with one another over the weekend and announced a strike on Monday. Just after they \nreturned to work seven weeks later, they filed paperwork to hold a union election. Raven never rehired the laid-off \nworkers, but the other testers won their election in May 2022, forming the first union at a major U.S. video game \ncompany.       \nIt was at this point that the rebellion took a truly unusual turn. Large American companies typically challenge union \ncampaigns, as Activision had at Raven. But in this case, Activision's days as the sole decision maker were \nnumbered. In January 2022, Microsoft had announced a nearly $70 billion deal to purchase the video game maker, \nand the would-be owners seemed to take a more permissive view of labor organizing.       \nThe month after the union election, Microsoft announced that it would stay neutral if any of Activision's roughly \n7,000 eligible employees sought to unionize with the Communications Workers of America - meaning the company \nwould not try to stop the organizing, unlike most employers. Microsoft later said that it would extend the deal to \nstudios it already owned.       \nCan a Tech Giant Be Woke?\nQ.A. testers can work grueling hours for low pay, and testers at other studios were already considering a union. \nTwo more groups of testers - one at Activision and one at a Microsoft subsidiary called ZeniMax - voted to unionize \nafter the company's neutrality announcements.       \nNow that Activision is part of Microsoft - it closed the purchase in October - testers at several parts of the combined \ncompany are seeking to unionize as well, according to union officials. These officials say that the company has \nbargained in good faith and that the two sides have made considerable progress toward a first contract. Within a \nfew years, Microsoft could have thousands of union employees working under collective bargaining agreements, \nmaking it an outlier in big tech.       \nOn one level, it seemed obvious why Microsoft, once a poster child for corporate ruthlessness, would go this route: \nThe company wanted regulators to bless its deal with Activision. Given the Biden administration's close ties with \nlabor, it didn't take a Kissingerian flair for strategy to see that a truce with unions might help. Cynics were quick to \npoint out that the company laid off nearly 10 percent of its video game workers, most of them from Activision, once \nthe deal was in hand.       \nStill, many large tech companies have business before the federal government - and almost all have taken steps to \ndiscourage unionization. That includes Amazon, Apple and Google, which are in the sights of antitrust regulators.       \nLike Microsoft, these companies routinely position themselves as progressive employers, pointing to corporate \ndiversity initiatives and support for L.G.B.T.Q. rights. Some channeled their employees' anxiety over Trump-era \npolicies on travel and immigration. Yet only Microsoft, whose leaders say they have been on a \"journey\" rooted in \nthe principle that \"people have a fundamental right to organize,\" has taken a permissive path on unions.       \nAnd for some employees, that's a key distinction. Workers who have sought to unionize at Amazon, Apple and \nGoogle don't seem persuaded of their employers' benevolence, pointing to evidence of retaliation. (The companies \nhave denied these accusations and say they respect workers' right to organize.) The workers note that Amazon and \nGoogle have hired consulting firms that specialize in fighting unions.       \nBy contrast, employees who have sought to unionize at Microsoft consider neutrality \"an absolute gift,\" said Autumn \nMitchell, a quality assurance worker who was part of the organizing campaign.       \nAll of which raises a question: In an age where companies routinely proclaim their commitments to civil rights and \nthe environment, what does it even mean to be a woke employer? And can Microsoft, on many days the most \nvaluable company in the world thanks to its success in artificial intelligence, and with a history of squeezing \ncompetitors, truly claim to be more evolved than most?       \nRemaking a Corporate Image\nIt's not hard to understand why Microsoft executives in the 1990s sometimes came off as villains. In a case that \nwent to trial in 1998, the Justice Department said Microsoft had illegally schemed to crush Netscape after the \nsmaller company rejected its offer to divvy up the browser market. Witnesses said Microsoft executives tossed \naround phrases like \"cut off their air supply\" and \"knife the baby\" when discussing competitors. (Microsoft denied at \nthe time that it had acted illegally; some executives denied using such phrases.)       \nMicrosoft successfully appealed a judge's decision to break up the company, but the ordeal still proved costly. It \nprompted comparisons with the great monopolies of yore, like Standard Oil, and cast a shadow over future deals, \nlike the company's abortive attempt in 2008 to buy Yahoo. A court monitored the company for nearly a decade.       \nIt was during the antitrust litigation that a Microsoft lawyer named Brad Smith auditioned for the job of general \ncounsel on the basis of a simple philosophy: \"Make peace,\" he urged his higher-ups.       \nMr. Smith got the job, and Microsoft began to cultivate better relationships with government overseers. Even when \nMicrosoft believed regulators were overstepping their authority, Mr. Smith later recalled in a speech on the legacy of \nthe case, the company would often say \"let's figure out what it makes sense to do nonetheless.\"       \nCan a Tech Giant Be Woke?\nUnderlying the approach was Mr. Smith's feel for the shifting ideological tides - and his sense that shifting with them \nwould serve the company best. One colleague recalled a 2021 presentation to the company's top executives in \nwhich Mr. Smith predicted that the coming wave of tech regulation would be like the wave of New Deal-era financial \nregulations, and that \"the next five years of regulation will define next the 50 years.\" Mr. Smith said the company \nshould help shape the new rules and adapt to them rather than resist them.       \nThe break with Microsoft's scorched-earth past was halting at first. In 2012, the company hired the political \nstrategist Mark Penn, who produced a negative ad campaign targeting Google's search engine.       \nBut when a new chief executive, Satya Nadella, took over in 2014, he seemed determined to help complete the \nreinvention. He dispatched Mr. Smith to negotiate a peace agreement with Google. He hired a mindfulness guru \nused by the National Football League's Seattle Seahawks to work with top executives.       \nNot that Mr. Nadella and Mr. Smith, who had been promoted to president, were averse to competition. They simply \nwent about it differently. Instead of directly undermining fellow tech companies, they drew contrasts between \nMicrosoft's new high-road practices and rivals' questionable behavior - for example, by proposing regulations on \nfacial recognition software. Unlike Microsoft, companies like Google and Apple had declined to make their facial \nrecognition versions available for government testing. (Google said the comparison isn't apt because it does not \noffer general facial recognition software.)       \nIn 2015, Microsoft, a pioneer among tech companies in hiring temporary workers and contractors to work for less \npay and job security than long-term employees, became one of the first tech giants to require large contractors to \nprovide paid time off for workers assigned to its projects.       \nAmazon appeared to be a particular foil. Mr. Smith noted in his 2019 book \"Tools and Weapons\" that Amazon had \nfought a proposed Seattle tax to fund affordable housing the year before, going so far as to stop planning for a \nbuilding until the tax was lowered. Shortly after, Microsoft made a financial pledge, which eventually reached $750 \nmillion, to expand such housing.       \n(Amazon declined to comment other than to say it had invested more than $600 million in affordable housing to \ndate.)       \nThe next year, Microsoft proposed a state tax to subsidize higher education that would require it and Amazon to pay \na higher rate than other businesses. \"Let's ask the largest companies in the tech sector, which are the largest \nemployers of high-skilled talent, to do a bit more,\" Mr. Smith wrote in an opinion essay. Amazon quibbled with the \ntax before backing a compromise.       \nLiberal policymakers noted the contrast between the two companies. \"The level of engagement is totally different,\" \nsaid Representative Pramila Jayapal, a Washington State Democrat who is the chair of the Congressional \nProgressive Caucus. \"It's like night and day from Amazon.\"       \nIn a way, Mr. Smith and Microsoft had turned the mantra of enlightened self-interest on its head. Increasingly, the \ncompany appeared to practice a kind of self-interested enlightenment, taking positions that appeared calculated to \nhighlight the ways it had reformed itself and to deflect scrutiny toward competitors.        \nThe makeover was so successful that the House antitrust subcommittee invited Mr. Smith to brief members in 2020 \nas they prepared for a hearing involving the chief executives of Amazon, Apple, Facebook and Google, which the \npanel was investigating for possible anticompetitive behavior.       \nYet 18 months later, the company's adult-in-the-room image was suddenly under assault. Shortly after Microsoft \nannounced its plans to purchase Activision, a coalition of liberal groups told the Federal Trade Commission that the \ndeal could \"lead to an undue concentration of market power,\" effectively reviving the 25-year-old critique of \nMicrosoft as a monopolist. Among the groups in the coalition was a prominent union: the Communications Workers \nof America.       \nCan a Tech Giant Be Woke?\n'It Was Weird, but Good Weird'\nIf someone were to design a tech job with the goal of maximizing interest in a union, there's a good chance it would \nlook like \"quality assurance tester.\" To an outsider, the tester's job can sound dreamy - being paid to play video \ngames before they're publicly available. Within the industry, the work is regarded as a physical and mental slog. \nTesters frequently play sections of games over and over for hours in search of subtle glitches.       \nAt times they must do this during punishing stretches known as \"crunch,\" when a game release is imminent and the \nwork lasts 10 or 12 hours most days, often six days a week.        \n\"One of the things getting us bad is finding out that overtime is happening at 5:30 on a Friday afternoon,\" said \nWayne Dayberry, a tester at a Microsoft-owned studio in Maryland.       \n\"It's like, dude, we need time, you can't just do that. People have kids.\"       \nAnd the work comes with some of the lowest pay in the industry. After their raise in late 2021, many testers at \nActivision still made under $19 an hour. Testers typically remain for years in the position with little prospect of \npromotion to other jobs, even with a college degree.       \nThese frustrations had already provoked a union campaign at Activision when Microsoft announced its acquisition. \nC.W.A. officials worried that the tech giant, which had no unionized U.S. employees, would promptly squelch it, and \nthat wages and employment could fall with fewer companies competing for workers.       \nBut the opposition of the politically powerful union was not absolute. During a conversation in early 2022, two top \nunion officials told Portia Wu, a Microsoft policy executive who is now Maryland's labor secretary, that a neutrality \nagreement at Activision would help reassure them. Ms. Wu, who had worked with unions as an aide to Senator \nEdward M. Kennedy, agreed to float the idea at Microsoft.       \nShe told colleagues that employees tend to win once they get to a union election, which some Activision employees \nwere seeking, and that a contentious election process can damage morale. By reaching a deal with the \ncommunications workers' union, she added, Microsoft could retain more control over the narrative as well as the \ntiming of union elections, which often surprise employers.       \nMr. Smith and other executives appeared receptive. \"Every time we've talked about this, we've all come to the \nsame point of view that this is the right path for Microsoft,\" he said in an interview with The New York Times. \"That \nwe have way more that we can potentially gain than put at risk.\"       \nChris Shelton, the union's president at the time, and Mr. Smith announced in June 2022 that Microsoft would stay \nneutral in union campaigns at Activision if the acquisition was finalized. Not long after, the union informed Microsoft \nthat a group of Q.A. testers had also been organizing at ZeniMax Media, a video game company Microsoft already \nowned, with studios in Maryland and Texas. The company agreed to grant workers at ZeniMax the same neutrality \ndeal it had negotiated for Activision.       \nMr. Dayberry, a leader of the union campaign at ZeniMax, said the company was good to its word: Managers never \nso much as mentioned the union, much less sought to discourage support for it. After years in which workers had \nclashed with managers over issues like pay, promotions and scheduling, he said, \"It was weird, but good weird.\" \nThe workers officially unionized in January 2023.       \nA few months earlier, Mr. Shelton had met with the F.T.C. chair, Lina Khan, and urged her to accept the Activision \ndeal in light of the neutrality agreements. But Ms. Khan, who has helped make labor considerations a key criterion \nfor analyzing mergers, was unimpressed.       \n\"Time and time again, antitrust regulators have heard promises made by companies leading up to a merger, on \neverything from labor to lowering prices, that have been reneged immediately after the merger closes,\" said \nDouglas Farrar, an F.T.C. spokesman.       \nCan a Tech Giant Be Woke?\nThe Activision deal finally closed in October, after a federal judge denied the F.T.C.'s request to block it temporarily. \nAnalysts say the investment is important for expanding Microsoft's presence in mobile gaming and could prove \nhighly lucrative if the company can incorporate new A.I. capabilities into its games.       \nIn the meantime, the opposition of the agency - which has appealed the ruling and said the recent layoffs contradict \nMicrosoft's earlier assurances - has continued. (Microsoft said many of the layoffs had been planned by Activision.)       \nThe company's courtship of labor has continued as well. In December, Microsoft announced that it would effectively \nextend the neutrality agreement to any group of employees seeking to join an affiliate of the A.F.L.-C.I.O., the labor \nfederation that encompasses C.W.A. and nearly 60 other unions. Roughly 100,000 people will be eligible to \nunionize without opposition from their employer under the company's new framework.       \nLiz Shuler, the A.F.L.-C.I.O.'s president, said Microsoft had gone further in collaborating with organized labor than \nalmost any other major company. She said she first met Mr. Smith to discuss labor issues almost two years ago, at \nwhich point he told her, \"If workers want a union, why shouldn't they be able to form one?\" Then he added: \"This is \nthe prevailing winds of change in the country. I think Microsoft should be adapting to it instead of resisting it.\"       \nA Kind of Corporate Paternalism\nIs there such a thing as a woke corporation? Conservatives say the answer is emphatically yes. In their telling, \ncorporate executives have been foisting left-wing values on the country for decades and redoubled their efforts \naround the time of Donald J. Trump's election, taking liberal positions on transgender rights, voting rights and gun \ncontrol. They note that scores of companies announced diversity initiatives during the protests that followed George \nFloyd's death.       \nBut skeptics question whether these corporate initiatives are examples of progressive convictions in action, or \nsimply investments in placating liberals and warding off calls for regulation, higher taxes and higher pay. Certainly, \nthe gestures aren't breaking the bank: In 2020, Chipotle pledged $1 million to civil rights organizations. By contrast, \na 10 percent increase in employee compensation would have cost the company tens of millions of dollars. (The \ncompany ended a 10 percent hourly pay increase about three months into the pandemic.)       \nEven companies often cited for their generosity to employees have generally spurned organized labor. Whole \nFoods and other progressive-minded companies, like Starbucks and Trader Joe's, have at times offered retail \nworkers above-market wages or benefits. Whole Foods has built an entire philosophy out of its crunchy \nrighteousness, or what its co-founder calls \"conscious capitalism.\"       \nBut Whole Foods fought unionization in the early 2000s, while Starbucks has been accused by the National Labor \nRelations Board of violating employees' labor rights hundreds of times since its workers began unionizing in 2021. \n(Starbucks denies the accusations; Whole Foods has said it does not believe a union is in employees' interests.)       \nWhen it comes to their employees, said Matthew Bodie, a law professor at the University of Minnesota, these \ncompanies favor a kind of corporate paternalism. \"We want to be beneficent, but we want to do it on our terms,\" he \nsaid, channeling executives.       \nEven tech companies famous for pampering employees have almost entirely resisted unionization. After employees \nbegan to organize in 2018, partly over concerns about the company's contracts with federal security agencies, \nGoogle hired a consulting firm that specializes in stifling unions. The company fired at least four employees involved \nin protesting the contracts. (Google said the firings had nothing to do with protest activity.)       \nWhen I asked Mr. Smith why Microsoft was willing to embrace neutrality when its competitors were not, he told me \nthat \"the tech sector has often been built by founders, and founders have often been very focused on retaining a \nlevel of control over their enterprises.\" By contrast, he said, \"I think the fact that Microsoft is a little bit older, \nsometimes a little bit wiser, at least gives us an opportunity to think more broadly.\"       \nWhite-Collar Collective Action\nCan a Tech Giant Be Woke?\nActivision may have been the immediate impetus for Microsoft's labor stance, but the neutrality deal could benefit \nthe company far beyond the acquisition. It may be a relatively cost-effective way to cast the company as pro-worker \nat a time when millions are worried about losing their jobs to generative A.I., whose release has helped \nsupercharge Microsoft's share price. Noting that unions are not a topic raised by analysts on the company's \nearnings calls, Gil Luria, who follows Microsoft for the investment bank D.A. Davidson, said, \"I don't expect this to \nbe a material issue.\"       \nThe move could also hamstring two of the company's competitors, Amazon and Apple, where unions have gained \ntraction in recent years.       \nIf these companies don't follow Microsoft's lead on neutrality, it could add to the public relations challenges they \nface in opposing unionization. It could also give Microsoft an advantage in the highly competitive market for \nengineers, some of whom have made clear that political and social issues affect their choice of employer.       \nIf, on the other hand, those companies relent on neutrality, a much larger portion of their work force could end up \nunionizing than at Microsoft. Amazon employs hundreds of thousands of workers in warehouses across the country, \nwhile Apple employs tens of thousands of workers at retail stores.       \nBy contrast, a large majority of Microsoft employees in the United States are white-collar and highly paid. \"There's \nnot a threat of unionization at that level,\" said Joshua Winter, a former Microsoft Philanthropies official focused on \nbringing economic opportunity to historically underrepresented communities. \"They're taking care of those people.\"       \nYet if Microsoft assumed the union effort would end with video game workers, it may have miscalculated. Over the \npast few years, highly paid white-collar workers have begun to assert themselves far beyond Google, engaging in \nforms of collective action that resemble union organizing. Corporate employees have protested what they see as \noverly strict return-to-office policies at companies like Apple and Starbucks, and over a variety of social issues, like \ntheir employers' carbon footprint (Amazon) or lack of diversity (Nike).       \nEven at Microsoft, well-compensated employees have organized protests over political concerns. In 2018, more \nthan 100 employees urged Mr. Nadella, the chief executive, to cancel a nearly $20 million contract with the \nImmigration and Customs Enforcement agency over its role in separating migrant children from their parents.        \nMr. Nadella responded with an email calling the family separation policy \"cruel and abusive\" and emphasizing that \nthe Trump administration was not relying on Microsoft technology to enact it. But the internal campaign continued \nthe next year, when hundreds of workers at GitHub, a Microsoft subsidiary, signed a letter demanding an end to a \nseparate contract with the agency. The pressure fizzled out after several of the employees involved left the \ncompany.       \nThe outcome might have been different if they had the option of unionizing without resistance.       \nFred Jennings, a former GitHub employee, said he and his colleagues discussed forming a union. \"Quite a few \npeople were saying, 'Look, our best lever to get this to change is to also push for a union,'\" he said, adding that, in \nthe end, too many worried about retaliation to make it a viable option.       \nWhen I asked Mr. Jennings if neutrality would likely have changed his colleagues' appetite for unionizing, he was \nunequivocal: \"With all the advantages of hindsight,\" he said, \"absolutely.\"       \nKirsten Noyes contributed research.       \nKirsten Noyes contributed research. \nLoad-Date: February 26, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Oct2023",
        "header": "'A TRANSFORMATIVE MOMENT'",
        "media": "Wall Street Journal Abstracts",
        "time": "October 14, 2023",
        "section": "R; Pg. 7",
        "length": "54 words",
        "byline": "JO CRAVEN MCGINTY",
        "story_text": "'A TRANSFORMATIVE MOMENT'\nWall Street Journal Abstracts\nOctober 12, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: R; Pg. 7\nLength: 54 words\nByline: JO CRAVEN MCGINTY\nBody\nABSTRACT\nJo Craven McGinty article in Journal Report — The Future of Everything features interview with Stanford’s medical-\nschool dean Dr Lloyd Minor, who discusses how neural networks and generative artificial intelligence could \nrevolutionize how physicians are trained, research is conducted and healthcare is delivered; photos\nGraphic\n \nPhotograph\nLoad-Date: October 14, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jul2023",
        "header": "Will Impact Search Engines",
        "media": "Economic Times (E-Paper Edition)",
        "time": "July 17, 2023",
        "section": "FRONT PAGE",
        "length": "489 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Will Impact Search Engines\nEconomic Times (E-Paper Edition)\nJuly 17, 2023 Monday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 489 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Chatbots may face lawsuits if they scrape Internet to use such data, say experts\nBody\nLATEST VERSION OF DATA BILL DROPS CLAUSE THAT CREATED EXCEPTION\nBengaluru: Generative artificial intelligence (AI) platforms such as ChatGPT or Google's Bard may not be able to \nprocess the personal data of Indians available in the public domain, as per the latest draft of the Digital Personal \nData Protection (DPDP) Bill, 2023, which was approved by the cabinet earli-  er this month.  To be sure, the draft of \nthe final bill is not public as yet. Experts are relying on a leaked version of a draft that's circulating in legal and \npolicy circles to make this analysis. \nMost declined to be named due to this reason.  This latest version has dropped a clause that had earlier created an \nexception for search engines to process publicly available personal data. If generative AI platforms scrape the \nInternet to use such data, they may be opening themselves to the threat of lawsuits in the country, like the ones \nthey are facing in the US currently, experts said.  This will impact search engines as well as online telephone and \nemail directories along with credit rating agencies. According to a technology expert at a public policy think tank, \n“Removing Clause 8(8), which listed any 'processing of publicly available personal data' under public interest as a \ncriterion for deemed consent, might impact new AI evolutions like ChatGPT.\" The 2022 version of the DPDP Bill \nhad incorporated this clause. The DPDP Bill, 2023, has been listed by the government for consideration and \npassage in the Lok Sabha in the upcoming monsoon session. “This removal indicates that AI chatbots shall collect \nand process publicly available personal information only after obtaining consent from data principals at the \ncommencement of its processing,” the expert said. The consent-based approach doesn't consider the complex \ndataprocessing mechanism followed by new AI evolutions like ChatGPT, he said. Experts pointed out that the US \nFederal Trade Commission (FTC) launched an investigation into ChatGPT creator OpenAI last week on whether \nthe artificial intelligence company violated consumer protection laws by scraping public data. In its 20-page letter, \nthe FTC has asked OpenAI numerous questions regarding the startup's AI model training and personal data \nhandling among other security concerns. Open AI CEO Sam Altman said in a tweet on Thursday evening that the \ncompany will work with the agency. Its technology is safe and pro-consumer “and we are confident we follow the \nlaw”, he said. Altman also said the company protects user privacy and designs its systems “to learn about the \nworld, not private individuals”. Other jurisdictions such as Italy have imposed restrictions on OpenAI. Experts said \nthe FTC case may set a broader precedent on how generative models such as ChatGPT train their language \nmodels. The FTC has also filed a complaint against Amazon for allegedly enrolling its customers knowingly in \nAmazon Prime without prior consent.\nLoad-Date: July 17, 2023\nWill Impact Search Engines"
    },
    {
        "file_name": "The_Economic_Times_Jul2023",
        "header": "Customer experience platform Kapture CX raises $4 million in funding",
        "media": "The Economic Times",
        "time": "July 27, 2023",
        "section": "FUNDING",
        "length": "335 words",
        "byline": " ",
        "story_text": "Customer experience platform Kapture CX raises $4 million in funding\nThe Economic Times\nJuly 28, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 335 words\nBody\nCustomer experience platform, Kapture CX said that it has raised $4 million as a part of its latest round of funding \nled by venture capital firm Cactus Venture Partners (CVP). According to the company, it will utilise the capital to \nexpand its presence across international markets, enhance its product offerings as well as strengthen its team. \nFounded in 2014, Kapture CX provides a customer support automation platform to enterprise customers helping \nbrands improve their customer experience. Through its solutions, the startup helps businesses streamline and \nautomate their customer support over call, email, chat, WhatsApp, and other social media channels.Its clientele \ninclude ecommerce brands including Nykaa, 1MG, Zepto, Meesho, BigBasket, as well as larger corporates \nincluding Tata and Wipro among others.\"The advent of general intelligence in generative AI models has shaken up \nthe industry. \nThe tailwinds we have been experiencing in the large enterprise segment made us look for the right amount of \ncapital to accelerate our growth trajectory,\" said Sheshgiri Kamath, cofounder, Kapture CX.At present, Kapture CX \nclaims to have on-ground operations in five countries including the US, the UAE, Indonesia and Philippines outside \nIndia. The company has also created vertical based offerings for sectors including retail (offline and online), travel, \nbanking, financial services, and consumer durables. \"Kapture CX has all the right ingredients to build a large \nsustainable SaaS business - a strong founding team, agility to understand and solve customer problems, a robust \nproduct suite and an unwavering persistence to building a high-growth, profitable business,\" said Amit Sharma, \npartner, Cactus Venture Partners. In August last year, Cactus Venture Partners raised Rs 350 crore as part of first \nclose of its maiden fund to back startups across segments of cleantech, healthtech and SaaS. Kapture CX marks \nthe sixth investment made by Cactus Venture Partners. For Reprint Rights: timescontent.com\nLoad-Date: July 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Feb2024",
        "header": "How Robots Learned to Write So Well; Nonfiction",
        "media": "The New York Times - International Edition",
        "time": "February 12, 2024",
        "section": "BOOKS",
        "length": "1217 words",
        "byline": "Jennifer Szalai",
        "story_text": "How Robots Learned to Write So Well; Nonfiction\nThe New York Times - International Edition\nFebruary 13, 2024 Tuesday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: BOOKS\nLength: 1217 words\nByline: Jennifer Szalai\nBody\n\"Literary Theory for Robots,\" by Dennis Yi Tenen, a software engineer turned literature professor, shows how the \n\"intelligence\" in artificial intelligence is irreducibly human.       \nLITERARY THEORY FOR ROBOTS: How Computers Learned to Write, by Dennis Yi Tenen              \nIn \"Literary Theory for Robots,\" Dennis Yi Tenen's playful new book on artificial intelligence and how computers \nlearned to write, one of his most potent examples arrives in the form of a tiny mistake.       \nTenen draws links between modern-day chatbots, pulp-fiction plot generators, old-fashioned dictionaries and \nmedieval prophecy wheels. Both the utopians (the robots will save us!) and the doomsayers (the robots will destroy \nus!) have it wrong, he argues. There will always be an irreducibly human aspect to language and learning - a crucial \ncore of meaning that emerges not just from syntax but from experience. Without it, you just get the chatter of \nparrots, who, \"according to Descartes in his 'Mediations,' merely repeated without understanding,\" Tenen writes.       \nBut Descartes didn't write \"Mediations\"; Tenen must have meant \"Meditations\" - the missing \"t\" will slip past any \nspell-checker program because both words are perfectly legitimate. (The book's index lists the title correctly.) This \nminuscule typo doesn't have any bearing on Tenen's argument; if anything, it bolsters the case he wants to make. \nMachines are becoming stronger and smarter, but we still decide what is meaningful. A human wrote this book. \nAnd, despite the robots in the title, it is meant for other humans to read.       \nTenen, now a professor of English and comparative literature at Columbia, used to be a software engineer at \nMicrosoft. He puts his disparate skill sets to use in a book that is surprising, funny and resolutely unintimidating, \neven as he smuggles in big questions about art, intelligence, technology and the future of labor. I suspect that the \nbook's small size - it's under 160 pages - is part of the point. People are not indefatigable machines, relentlessly \ningesting enormous volumes on enormous subjects. Tenen has figured out how to present a web of complex ideas \nat human scale.       \nTo that end, he tells stories, starting with the 14th-century Arab scholar Ibn Khaldun, who chronicled the use of the \nprophecy wheel, and ending with a chapter on the 20th-century Russian mathematician Andrey Markov, whose \nprobability analysis of letter sequences in Pushkin's \"Eugene Onegin\" constituted a fundamental building block of \ngenerative A.I. (Regular players of the game Wordle intuit such probabilities all the time.) Tenen writes \nknowledgeably about the technological roadblocks that stymied earlier models of computer learning, before \"the \nbrute force required to process most everything published in the English language\" was so readily available. He \nurges us to be alert. He also urges us not to panic.       \n\"Intelligence evolves on a spectrum, ranging from 'partial assistance' to 'full automation',\" Tenen writes, offering the \nexample of an automatic transmission in a car. Driving an automatic in the 1960s must have been mind-blowing for \npeople used to manual transmissions. An automatic worked by automating key decisions, downshifting on hills and \nHow Robots Learned to Write So Well Nonfiction\nsending less power to the wheels in bad weather. It removed the option to stall or grind your gears. It was \n\"artificially intelligent,\" even if nobody used those words for it. American drivers now take its magic for granted. It \nhas been demystified.       \nAs for the current debates over A.I., this book tries to demystify those, too. Instead of talking about A.I. as if it has a \nmind of its own, Tenen talks about the collaborative work that went into building it. \"We employ a cognitive-linguistic \nshortcut by condensing and ascribing agency to the technology itself,\" he writes. \"It's easier to say, 'The phone \ncompletes my messages' instead of 'The engineering team behind the autocompletion tool writing software based \non the following dozen research papers completes my messages.'\"       \nOur common metaphors for A.I. are therefore misleading. Tenen says we ought to be \"suspicious of all metaphors \nascribing familiar human cognitive aspects to artificial intelligence. The machine thinks, talks, explains, \nunderstands, writes, feels, etc., by analogy only.\" This is why so much of his book revolves around questions of \nlanguage. Language allows us to communicate and to understand one another. But it also allows for deception and \nmisunderstanding. Tenen wants us to \"unwind the metaphor\" of A.I. - a proposal that might look like an English \nprofessor's hobbyhorse on first glance but turns out to be entirely apt. A metaphor that is too general can make us \ncomplacent. Our sense of possibility is shaped by the metaphors we choose.       \nText generators, whether in the form of 21st-century chatbots or 14th-century \"letter magic,\" have always faced the \nproblem of \"external validation,\" Tenen writes. \"Procedurally generated text can make grammatical sense, but might \nnot always make sense sense.\" Take Noam Chomsky's famous example: \"Colorless green ideas sleep furiously.\" \nAnyone who has lived in the physical world would know that this syntactically flawless sentence is nonsense. Tenen \nkeeps referring to the importance of \"lived experience\" because that describes our condition.       \nTenen doesn't deny that A.I. threatens much of what we call \"knowledge work.\" Nor does he deny that automating \nsomething also devalues it. But he also puts this another way: \"Automation reduces barriers of entry, increasing the \nsupply of goods for all.\" Learning is cheaper now, and so having a big vocabulary or repertoire of memorized facts \nis no longer the competitive advantage it once was. \"Today's scribes and scholars can challenge themselves with \nmore creative tasks,\" he suggests. \"Tasks that are tedious have been outsourced to the machines.\"       \nI take his point, even if this prospect still seems bad to me, with an ever-shrinking sliver of the populace getting to \ndo challenging, creative work while a once-flourishing ecosystem collapses. But Tenen also argues that we, as \nsocial beings, have agency, if only we allow ourselves to accept the responsibility that comes with it. \"Individual \nA.I.s do pose real danger, given the ability to aggregate power in the pursuit of a goal,\" he concedes. But the real \ndanger comes \"from our inability to hold technology makers responsible for their actions.\" What if someone wanted \nto strap a jet engine to a car and see how it fared on the streets of a crowded city? Tenen says the answer is \nobvious: \"Don't do that.\"       \nWhy \"Don't do that\" can seem easy in one realm but not another requires more thinking, more precision, more \nscrutiny - all qualities that fall by the wayside when we cower before A.I., treating the technology like a singular god \ninstead of a multiplicity of machines built by a multiplicity of humans. Tenen leads by example, bringing his human \nintelligence to bear on artificial intelligence. By thinking through our collective habits of thought, he offers a \nmeditation all his own.              \nLITERARY THEORY FOR ROBOTS: How Computers Learned to Write | By Dennis Yi Tenen | Norton | 158 pp. | \n$22       \nJennifer Szalai is the nonfiction book critic for The New York Times. \nLoad-Date: February 12, 2024"
    },
    {
        "file_name": "Adobe_CEO_Aug2023",
        "header": "Artificial intelligence will augment human ingenuity, not replace it, says",
        "media": "Adobe CEO",
        "time": "August 26, 2023",
        "section": "COMPANY",
        "length": "957 words",
        "byline": "Surabhi Agarwal and Bodhisatva Ganguli",
        "story_text": "Artificial intelligence will augment human ingenuity, not replace it, says \nAdobe CEO\nThe Economic Times\nAugust 27, 2023 Sunday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANY\nLength: 957 words\nByline: Surabhi Agarwal and Bodhisatva Ganguli\nBody\nArtificial intelligence (AI) is going to augment human ingenuity, not replace it, said Shantanu Narayen, chairman and \nchief executive of $17.61-billion Adobe Inc. The Hyderabad-born executive, who has been at the helm of the \nNasdaq-listed company for the last 15 years, cautioned that a rush to regulate AI and \"arbitrarily limiting \nadvancements may be harmful\". In a wide-ranging conversation with ET's Surabhi Agarwal & Bodhisatva Ganguli, \nhe also talked about the role that Adobe India is playing in building the next-gen AI-led products and the \nmonetisation opportunities for the company arising out of the AI boom. Narayen, 60, who is among the original crop \nof the ever-growing list of Indian-origin CEOs leading American multinationals (MNCs), also said that the future of \nIndia is \"very bright\" because of the right combination of demographics, talent and technology and what the \ngovernment has done with the digital public goods is incredible. Edited excerpts:You're here at the B20 event and \nIndia seems to be a bright spot in the world right now. \nWhat are your thoughts on the India of today, a country you grew up in?To comment on India this week without \ncommenting on the incredible achievement of the moon landing would be really amiss on my part. It was just \nincredible. I think with the demographics, access to education, access to technology, the future (of India) is very \nbright. 'Digital building blocks in place' With the macroeconomic and political issues with other neighbouring \ncountries, new opportunities are emerging for industries such as manufacturing and I've said this many times, if I \nwas growing up in India today, I don't know if I would leave the country.You really mean that? I really mean it. \nAround 40 years ago, if you were in tech, where would you go? You'd go abroad. Look at the percentage of people \nwho are going abroad nowadays from top educational institutions, it's a minuscule portion. And so the talent exists, \nthe access to capital certainly exists and the opportunity exists. And the Indian entrepreneurs don't look at it as an \nIndian opportunity but as a global one. So I'm a big big supporter (of India). The scale of India is truly amazing and \nthat's the opportunity for India. They've done a really good job of (building) the fundamental plumbing of \ninfrastructure - the fact that you have this digital identifier, you have universal payment scheme... When would I \nhave thought that you could go to Bundi (kiosk), get a pani puri or something and just pay for it through (UPI)... it's \nstaggering. Maybe because you're in this place, you don't look at it with the sort of amazement that we look at it (in \nthe US). If you can keep building on top of these, it (will be amazing). You talk to company after company here, you \nlook at the growth rates, look at how they're managing profitability and growth, look at their global aspirations, how \ncan one not be a fan?One of your founders, John Warnock, passed away. He was the inventor of the PDF among \nother revolutionary things. Could you tell us something about your relationship with him?The company was started \nby two amazing individuals, John (Warnock) and Chuck (Geschke). And both of them were researchers and they \nmet each other at Xerox PARC. It's been the privilege of a lifetime (to have worked with them). When you think \nabout technology innovators who've had a profound impact - John invented with Chuck - Postscript. Desktop \npublishing, as we know it today, would not have existed without their fundamental innovation. He invented Adobe \nIllustrator, his wife Marvo was a graphic artist. People take for granted today WYSIWYG (What You See Is What \nYou Get) applications but till then these hadn't been created. And he created the PDF. And so to work for 25 years \nArtificial intelligence will augment human ingenuity, not replace it, says Adobe CEO\nwith an individual who's had that kind of profound inventiveness and then to be asked by both of them to run the \ncompany... It's just been the ride of a lifetime, and we will miss him.What are some of the challenges that India \nneeds to overcome to cement its position further in the global economy as it moves on to a path of becoming a \ndeveloped country?Access to education is always the bare minimum. With the population demographics that you \nhave, are you ensuring people access to education? I think we've done an amazing job in the country on that but \nmore can be done. And a strong digital and physical infrastructure does help. From a government, private sector \n(point of view), it's the ease of doing business, right. And even that is dramatically improved relative to what it used \nto be. I think the basic building blocks are all in place. In good faith, I can't say I'm disappointed at something that's \nhappening because it feels like all the right things are happening. They may not happen all the time and the scale at \nwhich or the speed at which people here wanted, but from outside - and I think I get the benefit of sometimes just \nzooming out and seeing.How big is Adobe's India business from a global perspective?We don't break out our \nbusiness by country. If you look at the number of computing devices that are in India, and if you look at our \npercentage of revenue: is it commensurate with other countries, it's a little behind. But if you look at it in terms of the \ngrowth rate right now, and the growth rate both on the creative side, the documents side as well as on the \nmarketing side - which is enabling businesses to be digital business - the growth rates are great. And the \npossibilities are immense. If you take financial services and you look at these giant financial institutions like HDFC, \nICICI, SBI and how they're thinking about digital, that's the opportunity for us to sell our marketing solutions. For \nReprint Rights: timescontent.com\nLoad-Date: August 26, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Glossary",
        "media": "The New York Times",
        "time": "April 8, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 7",
        "length": "556 words",
        "byline": " ",
        "story_text": "Glossary\nThe New York Times\nApril 8, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 7\nLength: 556 words\nBody\nLarge language model: A type of neural network that learns skills -- including generating prose, conducting \nconversations and writing computer code -- by analyzing vast amounts of text from across the internet. The basic \nfunction is to predict the next word in a sequence, but these models have surprised experts by learning new \nabilities.\nGenerative A.I.: Technology that creates content -- including text, images, video and computer code -- by \nidentifying patterns in large quantities of training data, and then creating new, original material that has similar \ncharacteristics. Examples include ChatGPT for text and DALL-E and Midjourney for images. \n  Transformer model: A neural network architecture useful for understanding language, which does not have to \nanalyze words one at a time but can look at an entire sentence at once. A technique called self-attention allows the \nmodel to focus on the particular words that are important in understanding the meaning of the sentence.\n  Parameters: Numerical values that define a large language model's structure and behavior, like clues that help it \nguess what words come next. Modern systems like GPT-4 are thought to have hundreds of billions of parameters.\n  Reinforcement learning: A technique that teaches an A.I. model to find the best result by trial and error, receiving \nrewards or punishments from an algorithm based on its results. This system can be enhanced by humans giving \nfeedback on its performance.\n  Hallucination: A well-known phenomenon in large language models, in which the system provides an answer that \nis factually incorrect, irrelevant or nonsensical, because of limitations in its training data and architecture.\n  Bias: A type of error that can occur in a large language model if its output is skewed by the model's training data. \nFor example, a model may associate specific traits or professions with a certain race or gender, leading to \ninaccurate predictions and offensive responses.\n  Anthropomorphism: The tendency for people to attribute humanlike qualities or characteristics to an A.I. chatbot. \nFor example, you may assume it is kind or cruel based on its answers, even though it is not capable of having \nemotions, or you may believe the A.I. is sentient because it is very good at mimicking human language.\n  Natural language processing: Techniques used by large language models to understand and generate human \nlanguage, including text classification and sentiment analysis. These methods often use a combination of machine \nlearning algorithms, statistical models and linguistic rules.\n  Emergent behavior: Unexpected or unintended abilities in a large language model, enabled by the model's \nlearning patterns and rules from its training data. For example, L.L.M.s that are trained on programming and coding \nGlossary\nsites can write new code. Other examples include creative abilities like composing poetry, music and fictional \nstories.\n  Alignment: Attempts by A.I. researchers and ethicists to ensure that artificial intelligences act in accordance with \nthe values and goals of the people who create them.\n  Multimodal systems: A.I.s similar to ChatGPT that can also process images, video, audio, and other non-text \ninputs and outputs.\n  Artificial general intelligence: An artificial intelligence that matches human intellect and can do anything the human \nbrain can do.\nhttps://www.nytimes.com/2023/03/31/business/00ontech-ai-print-glossary.html\nGraphic\n \nThis article appeared in print on page B7.               \nLoad-Date: April 8, 2023"
    },
    {
        "file_name": "bracing_for_malicious_use_of_tactics_Feb2024",
        "header": "Under pressure, Big Tech pledges to tackle election deepfakes; Experts are",
        "media": "bracing for malicious use of tactics",
        "time": "February 19, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "1226 words",
        "byline": "By, Jessica Guynn, USA TODAY",
        "story_text": "Under pressure, Big Tech pledges to tackle election deepfakes; Experts are \nbracing for malicious use of tactics\nUSA Today\nFebruary 19, 2024 Monday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 1226 words\nByline: By, Jessica Guynn, USA TODAY\nBody\n\"This is an issue that cuts across partisan and geographical differences.\"\nIlana Beller\nOrganizing manager for the Public Citizen Democracy Campaign\nUnder pressure from the White House and governments around the globe, major technology companies pledged \nFriday to crack down on artificial intelligence-generated deepfakes that could undermine the integrity of major \ndemocratic elections in the U.S. and overseas this year.\nGoogle, Meta, TikTok and other companies said they would join forces to create tools to detect and debunk election \ndeepfakes. They unveiled the accord as political and security leaders gathered at the Munich Security Conference \nin Germany.\nThe deepfakes in question are videos, images, and audio that alter or fake the appearance, voice, or actions of \npolitical candidates, election officials or other key figures in a democratic election. These alterations can also be \nused to mislead voters about when, where and how to vote.\nThe coalition that includes Adobe, Amazon, Microsoft, OpenAI and X, formerly Twitter, promised to be open with \nthe public about how it combats AI-generated falsehoods that attempt to disrupt elections on their platforms.\nBut battling bad actors will require \"a whole-of-society response,\" the companies said. Virtually anyone can now \ncreate or digitally alter images and clips in realistic ways to target and deceive voters.\n\"We are committed to doing our part as technology companies while acknowledging that the deceptive use of AI is \nnot only a technical challenge, but a political, social, and ethical issue and hope others will similarly commit to \naction across society,\" they said.\nThe accord is similar to a voluntary pledge many of the same companies signed in July after a meeting at the White \nHouse.\n\"This is an important step toward good platform hygiene and a better internet, but there is substantially more to do,\" \nsaid Josh Lawson, director of AI and democracy at the nonprofit think tank Aspen Institute. \"This has to be a floor, \nbut not a ceiling, for future work.\"\nPressure mounts on Big Tech\nUnder pressure, Big Tech pledges to tackle election deepfakes Experts are bracing for malicious use of tactics\nto stop election deepfakes\nThis year will set a record for the largest number of people living in countries holding nationwide elections including \nIndia and Mexico, raising concerns that AI will play a role at the ballot box.\nWith rapid advances in technology and little oversight from the government, election experts are bracing for the \nmalicious use of deepfakes in this year's presidential contest.\nDuring New Hampshire's primary election last month, AI-generated robocalls mimicking President Joe Biden's voice \ntried to discourage people from voting.\nBiden signed an executive order on AI in October. But AI technologies are advancing so quickly that lawmakers and \nregulators are having trouble keeping up. With few rules governing AI-generated content in the U.S., the European \nUnion has taken the lead. It requires that companies identify and label deepfakes.\n\"It is good that many of the large tech platforms have agreed to identify and label deepfakes but their action falls \nshort of what is needed,\" said Darrell West, a senior fellow at the Center for Technology Innovation at the think tank \nBrookings Institution. \"We already are seeing fake videos and audiotapes and that usage is likely to grow as we get \ncloser to the election.\"\nTech industry accord is\na 'feeble response,' critics say\nCritics say tech companies cannot be trusted to regulate themselves and more needs to be done to hold the \ncompanies and their platforms accountable for content that aims to trick voters.\n\"This is a feeble response on the part of the tech companies given the risk we are already seeing in the form of \npolitical disinformation and election interference,\" Hany Farid, a University of California, Berkeley professor who \nspecializes in deepfakes and disinformation, said in an email.\nMoreover, the agreement does not apply to other online platforms that are notorious for spreading election-related \nlies, Farid said.\n\"There are many bad players in this space who aren't being invited to the White House for a photo op, and these \nplayers are not going to comply with voluntary standards,\" he said.\nWhy deepfakes can be dangerous to democracy\nThe quality of deepfakes has rapidly improved, making them harder to distinguish from authentic videos, images \nand audio. The worry is that voters might not be able to tell the difference between what is real and what is AI. And \nthat could lead people to question authentic content as well.\nLawson, who previously worked on election integrity and platform policies at Facebook owner Meta, expects AI-\ngenerated election misinformation and persuasion content will pop up in places where people don't expect it, such \nas individual SMS messages or WhatsApp channels. These messages can deceive voters about polling places or \ntarget specific language communities to suppress voter turnout.\nWhat is the government doing\nto combat election deepfakes?\nThere is no federal law banning deepfakes.\n\"While creating a deepfake to swing the outcome of an election may seem deeply unethical, it is currently legal in \nmost places in the United States, and we should assume that as long as it is legal, it is a huge risk,\" said Ilana \nBeller, organizing manager for the Public Citizen Democracy Campaign. \"There is bipartisan support for this \nUnder pressure, Big Tech pledges to tackle election deepfakes Experts are bracing for malicious use of tactics\nlegislation on both a federal and a state level, but we cannot assume that Congress will act on this in time for the \n2024 election.\"\nSome executive agencies have stepped in to fill policy gaps.\nThe Federal Election Commission is considering rule changes that would ban federal candidates from using \ngenerative AI tools to misrepresent their political rivals.\nThe Federal Communications Commission this month banned the use of AI-generated voices in robocalls. The ban \ncame two days after the FCC issued a cease-and-desist order against the company responsible for the audio \ndeepfake of Biden's voice in New Hampshire.\nThe Federal Trade Commission this week moved to adopt new rules around impersonation, citing the threat of AI-\ngenerated scams.\nWhat are states doing\nabout election deepfakes?\nA handful of states - Michigan, Minnesota, California, Washington, and Texas - already have laws in place to restrict \nAI in political communications.\nDuring this legislative session, lawmakers in 32 states have introduced 52 bills to regulate deepfakes in elections, \naccording to Public Citizen.\nSome of the state bills ban AI-generated content in political ads or require disclaimers on AI-generated content. \nOthers ban deepfakes before an election.\n\"We have seen legislators in almost every single state that has a legislative session this year working proactively to \naddress this issue,\" Beller said. \"This is an issue that cuts across partisan and geographical differences. We are \nseeing bills sponsored by Republicans and Democrats alike, and a good deal of bipartisan cooperation to thwart \nthis threat to our democracy.\"\nBut there is a limit to how effective state regulation can be.\n\"The reality is that enforcement of state-level legislation is often less comprehensive than federal enforcement \nwhich can be tagged to things like trade sanctions and much more robust enforcement than state-level criminal \npenalties,\" Lawson said.\n\"This is an issue that cuts across partisan and geographical differences.\"\nIlana Beller\nOrganizing manager for the Public Citizen Democracy Campaign\nLoad-Date: February 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Reveal A.I. Use In Political Ads, Meta Demands",
        "media": "The New York Times",
        "time": "November 9, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "716 words",
        "byline": "By Mike Isaac",
        "story_text": "Reveal A.I. Use In Political Ads, Meta Demands\nThe New York Times\nNovember 9, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 716 words\nByline: By Mike Isaac\nBody\nThe social networking giant, which has long had a contentious relationship with political ads, is reckoning with a \nwave of generative A.I. tools.\nMeta spent years figuring out how to handle political advertising across Facebook and Instagram. It put systems \ninto place and developed policies for what types of political ads were and were not allowed on its platforms. \n  But that was before the rise of consumer artificial intelligence.\n  On Wednesday, Meta introduced a new policy to grapple with A.I.'s effects on political advertising. The Silicon \nValley company said that starting next year, it would require political advertisers around the world to disclose when \nthey had used third-party A.I. software in political or social issue ads to synthetically depict people and events.\n  Meta added that it would bar advertisers from using its own A.I.-assisted software to create political or social issue \nads, as well as ads related to housing, employment, credit, health, pharmaceuticals or financial services. Those \nadvertisers would be able to use third-party A.I. tools such as the image generators DALL-E and Midjourney, but \nwith disclosures.\n  ''We believe this approach will allow us to better understand potential risks and build the right safeguards for the \nuse of generative A.I. in ads that relate to potentially sensitive topics in regulated industries,'' the company said.\n  Meta is reckoning with a wave of A.I. tools that the public has embraced over the past year. As consumers have \nflocked to ChatGPT, Google Bard, Midjourney and other ''generative A.I.'' products, big tech companies such as \nMeta have had to rethink how to handle a new era of manipulated or outright false imagery, video and audio.\n  Political advertising has long been a contentious issue for Meta. In 2016, Facebook was criticized for a lack of \noversight after Russians used the social network's ads to sow discontent among Americans. Since then, Mark \nZuckerberg, Meta's founder and chief executive, has spent billions of dollars working to tamp down disinformation \nand misinformation on the company's platforms and has hired independent contractors to closely monitor political \nads that go through the system.\n  The company has also not shied away from allowing politicians to lie in ads on the platform, which Mr. Zuckerberg \nhas defended on the grounds of free speech and public discourse. Meta has also shown reluctance to limit the \nspeech of elected officials. Nick Clegg, Meta's president of global affairs, has called for regulatory guidance on such \nissues instead of having tech companies determine the rules.\nReveal A.I. Use In Political Ads, Meta Demands\n  Those who run political ads on Meta are currently required to complete an authorization process and include a \n''paid for by'' disclaimer on the ads, which are stored in the company's public Ad Library for seven years so \njournalists and academics can study them.\n  When Meta's new A.I. policy goes into effect next year, political campaigns and marketers will be asked to \ndisclose whether they used A.I. tools to alter the ads. If they have and the ad is accepted, the company will run it \nwith the information that it was created with A.I. tools. Meta said it would not require advertisers to disclose \nalterations that were ''inconsequential or immaterial to the claim, assertion or issue raised,'' such as photo \nretouching and image cropping.\n  Political and social issue ads that have apparently used A.I. to alter images, video and audio but have failed to \ndisclose doing so will be rejected, the company said. Organizations that repeatedly try to submit such ads without \ndisclosures will be penalized, it added, without specifying what the penalties might be. The company has long had \nthird-party fact-checking partners review, rate and potentially remove ads that are designed to spread \nmisinformation.\n  By barring advertisers from using the company's own A.I.-assisted software to create political or social issue ads, \nMeta may be able to prevent headaches or litigation related to its advertising technology.\n  In 2019, the Justice Department sued the company for allowing advertisers to discriminate against Facebook \nusers based on their race, gender, religion and other characteristics. The company eventually settled the lawsuit, \nagreeing to alter its ad technology and pay a penalty of $115,054.\nhttps://www.nytimes.com/2023/11/08/technology/meta-political-ads-artificial-intelligence.html\nGraphic\n \nThis article appeared in print on page B5.               \nLoad-Date: November 9, 2023"
    },
    {
        "file_name": "Newsletter_Oct2023",
        "header": "Pandemic Relief Funding for Child Care Is Ending. What Now?; DealBook",
        "media": "Newsletter",
        "time": "October 2, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1908 words",
        "byline": "Sarah Kessler and Claire Moses",
        "story_text": "Pandemic Relief Funding for Child Care Is Ending. What Now?; DealBook \nNewsletter\nThe New York Times \nSeptember 30, 2023 Saturday 21:01 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1908 words\nByline: Sarah Kessler and Claire Moses\nHighlight: More than 80 percent of licensed child care providers in the United States received the grants, which \nthey used to pay bills and raise wages for staff.\nBody\nMore than 80 percent of licensed child care providers in the United States received the grants, which they used to \npay bills and raise wages for staff.\nAs the U.S. government narrowly avoided a shutdown this weekend, a different kind of high-stakes shutdown \noccurred on Saturday.\nIn 2021, as part of a rescue package to combat the pandemic, the U.S. government made its single largest \ninvestment in child care, committing $24 billion to fund the sector that Treasury Secretary Janet Yellen has called a \ntextbook example of a broken market. That funding expired on Saturday, pulling a lifeline from more than 220,000 \nproviders — about 80 percent of all child care centers across the country. In crisis-prone Washington, this one has \nbeen called the “child care cliff.”\nThe child care shortage already costs families $78 billion per year, and businesses another $23 billion per year, \naccording to an analysis by the nonprofit group ReadyNation. And it could get more expensive: About 30 percent of \nproviders who took the grants said that they would fold without the funds.\n“Parents simply cannot afford to pay the true cost of providing care, and providers can’t afford to earn any less,” \nsaid Daniel Hains, a managing director at the National Association for the Education of Young Children.\nPoliticians on both sides of the aisle say they want affordable child care. Senator John Kennedy, Republican from \nLouisiana, compared affordable child care to Golden Retrievers. “No fair-minded person can be opposed to it,” he \nsaid during a hearing on child care policy this month. \nBut there is disagreement over the best way to make the math work. Child care providers used the funding to pay \nbills and offer more competitive wages. Democrats have proposed committing $16 billion per year for the next five \nyears to prop up child care providers, but with no Republican co-sponsors it’s unlikely to pass. Hains argues that \nother measures, like subsidizing child care costs for families, are important but won’t accomplish much if child care \nproviders can’t stay open in the first place. “We need to do more to stand up supply,” he said.\nThe Chamber of Commerce favors tax credits. The business lobbying group recently endorsed a bill that would \nexpand tax incentive programs, including those for employers that provide child care to employees and for parents \nwho pay for child care. While the bill has bipartisan support, some experts argue it is less robust than other \nproposals. “If you don’t have the money to pay for child care up front, it doesn’t help you at all,” said Julie Kashen, a \nsenior fellow at the left-leaning think tank the Century Foundation who has written extensively about child care \npolicy. \nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nPresident Biden’s “Build Back Better” plan included near universal child care for children until age 5, but the \nprovision was cut. Biden has since taken much less ambitious steps, like signing an executive order directing \nfederal agencies to find ways to make child care cheaper and requiring companies seeking at least $150 million of \nfunding under the CHIPS Act to guarantee child care.\nIn the meantime, the child care crisis will most likely get worse. In 41 states, the average annual cost of care for two \nchildren exceeds the average annual mortgage payment. Wages remain relatively low at child care providers, and \neven before the pandemic, about half of Americans lived in what’s called a “child care desert,” where supply does \nnot meet demand, according to the Center for American Progress. Some states, like New York, created new \nfunding for child care centers ahead of the cutoff in federal rescue financial assistance, and some centers have \nraised their prices to compensate for lost subsidies.\nThe cutoff won’t necessarily result in widespread sudden shutdowns of child care facilities, but it will likely contribute \nto the continuing shortage of affordable services. “I think that the child care cliff is probably the wrong way to think \nabout it,” said Chris Herbst, a professor at Arizona State University who studies the economics of child care. “I think \nit’s a slow roll downhill.” — Sarah Kessler\nIN CASE YOU MISSED IT \nLina Khan’s F.T.C. sues Amazon. The regulator and 17 states accused the e-commerce giant of acting illegally to \nmaintain its monopolistic position. The lawsuit is seen as a test of theories that Khan outlined in a now-famous \nessay she wrote as a law student, which argued that antitrust policy’s singular focus on consumer prices was ill \nsuited to an era of dominant tech platforms.\nAutoworkers expand their strikes. The United Automobile Workers union said 7,000 more of its members would \nwalk off the job as its labor dispute entered a third week. The decision was announced after President Biden and \nDonald Trump both visited Michigan this week to woo blue-collar voters in a swing state.\nJPMorgan Chase settles its legal cases over ties to Jeffrey Epstein. The Wall Street bank agreed to a $75 million \ndeal with the U.S. Virgin Islands and a separate agreement with Jes Staley, a former executive, to the convicted \nsex offender. The bank has paid a total of $365 million to settle claims related to Epstein, who remained a client \nafter he pleaded guilty to soliciting prostitution from a minor.\nThe Taylor Swift effect hits the N.F.L.\nWhen the pop megastar Taylor Swift appeared at a Kansas City Chiefs football game last weekend to cheer on her \nrumored boyfriend, Travis Kelce, the team’s superstar tight end, her visit set celebrity watchers and social media \nwild.\nBut it also signaled a collaboration between two of the world’s biggest brands: Swift, whose Eras tour is set to bring \nin $1.4 billion this summer, and the National Football League, the world’s most profitable sports league, The \nTimes’s Claire Moses writes.\nIf Swift attends the Chiefs’ game against the New York Jets this Sunday, there may be even more big spending \nfrom new football fans.\nHere are the numbers from Swift’s first outing:\n• Sales of Kelce’s jersey jumped nearly 400 percent after the game, according to Fanatics, the N.F.L.’s official \nretailer.\n• Fox Sports said the game was the week’s most-watched telecast on any network, with 24.3 million viewers. \nThe broadcast, which repeatedly cut to Swift sitting next to Kelce’s mother, dominated among female \nviewers ages 12 to 49.\nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nThe N.F.L. has embraced Swift’s ardent fandom. For several days, the league’s official account on X, formerly \nknown as Twitter, had “Taylor’s Version” as its biography. (The term referred to Swift’s re-recording of her albums \nafter her former record label sold the rights to her back catalog.)\nExperts applauded it as a marketing coup. “Taylor Swift is one of the biggest brands, if not the biggest brand, in the \nworld right now,” David Byrne, head of creative services at Thinkhouse, a youth marketing and advertising agency, \ntold DealBook. The singer could bring “millions of fans who’d never paid much attention,” he added.\nOther brands are also trying to capitalize on the moment. Heinz released a limited-edition “Ketchup and Seemingly \nRanch” sauce, referring to a picture of Swift eating fried chicken with those condiments at the game.\nSome conservative football fans are less excited. Some on the alt-right are wary of Swift, pointing to her support of \na Democratic political candidate in 2018. (Others have been leery of Kelce, objecting to his promotion of Pfizer’s \nlatest Covid vaccine.) “What will break Kelce’s heart first? The COVID shot or Taylor Swift?” Charlie Kirk, the \nfounder of the conservative activist group Turning Point USA, wrote on social media.\nKelce himself is slyly alluding to the boost in his stardom. On Wednesday, he and his brother Jason, a center for the \nPhiladelphia Eagles, acknowledged a slew of new fans on their “New Heights” podcast, including many who were \nnew to football. (They spent a portion of the show explaining the basics of the sport, from field goals to downs.)\n“I can’t believe being a Swiftie has lead me to watch a FOOTBALL podcast. Never in my wildest dreams,” one \ncommenter posted on the show’s YouTube page.\nA ‘canary in the coal mine’ for A.I. \nIn 2020, Kashmir Hill, a technology reporter for The Times, broke the story of Clearview AI, a secretive start-up that \nbuilt a powerful facial recognition tool used by police forces around the country. Clearview AI had scraped billions of \nphotos of ordinary web users that were published online to build the app.\nThe article led to a larger discussion about the proliferation of surveillance technology and how such tools should be \nregulated.\nKashmir talked with DealBook about her new book, “Your Face Belongs to Us: A Secretive Startup’s Quest to End \nPrivacy as We Know It,” which chronicles Clearview AI’s rise, and how facial recognition technology is changing our \nlives. The interview has been condensed and edited.\nAre there parallels between facial recognition and the recent rise of generative A.I.?\nI very much see facial recognition technology as the canary in the coal mine for what’s going to happen with the rest \nof A.I. It’s a matter of a company going out on the internet and collecting a whole bunch of data and information \nwithout anyone’s consent.\nThere’s a bit of a cautionary tale. If you don’t set up some boundaries, then you’re going to have a radical actor like \nClearview AI come along and use the technology in the most boundary-pushing way.\nFacebook and Google built similar tools, but decided they were too dangerous to release. What does that tell you?\nI do think that these companies are just more risk averse than a radical start-up. And so having these small \ngenerative A.I. start-ups bought by the bigger tech giants might slow down the most shocking kind of use cases of \nit.\nFacial recognition technology is simpler. It’s just faces. But a lot of the computing and the training to make powerful \nalgorithms was done by powerful companies, and then they open-sourced it, so the algorithms themselves became \naccessible.\nPandemic Relief Funding for Child Care Is Ending. What Now? DealBook Newsletter\nThe parallel in generative A.I. would be Meta open-sourcing its LLaMA 2 technology. That is where we’re starting \nto see the possible move toward an unrestrained environment for A.I. where anybody could use the Meta model \nthat they put out and do surprising things with that technology.\nKnowing what you know about facial recognition technology, does it have any place in society, or should it be \nbanned outright?\nI think the tale of facial recognition technology, and these kinds of technologies, shows that you can restrain it. You \ncan pass laws that work, and we’ve seen it before. One of the greatest examples is recording devices and bugs, \nwhich were coming out in the 1960s. And everybody was afraid that their conversations were going to be \neavesdropped on and their phones were going to be wiretapped. Congress passed a law that said, you know, you \ncan’t secretly record people. And this is why all the surveillance cameras that are all over the United States only \nwatch us and don’t listen to us.\nJust because we like using facial recognition technology to unlock our phone or to search a local criminal database \ndoesn’t mean that we have to usher in the most radical version of it.\nThanks for reading! We’ll see you Monday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: About 30 percent of child care providers who took the grants said that they would have to fold without the \nfunds. (PHOTOGRAPH BY IAN WILLMS FOR THE NEW YORK TIMES) This article appeared in print on page B5.\nLoad-Date: October 2, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Cognizant, Nvidia tap generative AI to boost drug discoveries",
        "media": "The Economic Times",
        "time": "March 19, 2024",
        "section": "TECH & INTERNET",
        "length": "553 words",
        "byline": "Beena Parmar",
        "story_text": "Cognizant, Nvidia tap generative AI to boost drug discoveries\nThe Economic Times\nMarch 20, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 553 words\nByline: Beena Parmar\nBody\nGlobal IT services and consulting major Cognizant is tapping generative AI (gen AI) technology along with the \nNvidia BioNeMo platform to help improve productivity of drug discoveries and speed up its market reach pushing \ngrowth in its health sciences vertical.“By leveraging gen AI technologies, clinical researchers can rapidly sift \nthrough extensive datasets, more accurately predict interactions between drug compounds and create new, viable \ndrug development pathways,” Cognizant said in a statement.Amid high costs, long development cycles and high \nrate of failure, traditional drug discovery methodologies in the life sciences industry are process intensive and \nrequire the analysis of vast repositories of scientific literature and clinical data for relevant insights.\"More than any \nother technological breakthrough in recent decades, generative AI has the potential to revolutionize the way new \ndrugs are researched, developed and brought to market, making the creation of lifesaving discoveries faster, \nsmarter and more accessible to all,\" said Anna Elango, EVP, Cognizant's Core Technologies & Insights.Cognizant \nsaid it aims to give clients access to a suite of model-making services, including pretrained models, cutting-edge \nframeworks, and APIs, that offers clients the quickest path to train and customize enterprise models using their \nproprietary data. The offering is intended to enable this with reduced manual intervention for data analysis, and \nwithout the need to write elaborate code and build or maintain infrastructure.\"Generative AI will drive the next wave \nof enterprise productivity gains across industries, enabled by the Nvidia AI Enterprise software platform. \nUsing Nvidia BioNeMo, Cognizant will help provide its life sciences clients with advanced, secure and reliable AI \nservices to drive improved outcomes with custom drug discovery applications,\" said Alvin DaCosta, VP, Global \nConsulting Partner Organization, Nvidia.The US headquartered firm counts health sciences as its largest vertical, \nwhich surpassed BFSI (banking, financial services and insurance) with revenue at $1,396 million for the quarter \neven as the growth dipped by 2.1% year-on-year (YoY) and 2.7% on a constant currency (CC) basis while BFSI \ndecelerated by 5.8% YoY and 6.6% CC terms. Cognizant reported a 1.7% drop YoY and 2.4% in CC in total \nrevenues at $4,758 million for the October to December period. Cognizant is also understood to have hired Mohd \nHaque from Wipro, where he headed the healthcare services vertical, for which there is an ongoing legal \nemployment case.Cognizant's life sciences offerings support more than 120 global manufacturing lines and more \nthan 18 million patients with medical device company products, the firm said.Beyond healthcare, Cognizant further \nintends to pursue additional applications with Nvidia in manufacturing and automotive engineering, where gen AI \nhas the potential to enhance productivity, optimize costs and quicken market innovation.Cognizant intends to \nestablish an Nvidia AI Center of Excellence this year to further innovate with Nvidia technologies, including the \nNvidia Metropolis, Nvidia Omniverse and Nvidia AI Enterprise platforms, for the benefit of clients across industries \naround the world, the company statement added. For Reprint Rights: timescontent.com\nLoad-Date: March 19, 2024\nCognizant, Nvidia tap generative AI to boost drug discoveries"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Apple Overhauls App Store in Europe, in Response to New Digital Law",
        "media": "The New York Times",
        "time": "January 26, 2024",
        "section": "TECHNOLOGY",
        "length": "1157 words",
        "byline": "Adam Satariano and Tripp Mickle &lt;p&gt;Adam Satariano is a technology correspondent based in Europe,",
        "story_text": "Apple Overhauls App Store in Europe, in Response to New Digital Law\nThe New York Times \nJanuary 25, 2024 Thursday 11:25 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1157 words\nByline: Adam Satariano and Tripp Mickle &lt;p&gt;Adam Satariano is a technology correspondent based in Europe, \nwhere his work focuses on digital policy and the intersection of technology and world affairs.&lt;/p&gt; &lt;p&gt;Tripp \nMickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on Apple \nincludes product launches, manufacturing issues and political challenges. He also writes about trends across the \ntech industry, including layoffs, generative A.I. and robot taxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt;\nHighlight: An E.U. law taking effect in March forced Apple to loosen its grip on the App Store, changes it had long \nresisted.\nBody\nAn E.U. law taking effect in March forced Apple to loosen its grip on the App Store, changes it had long resisted.\nSince Apple introduced the App Store in 2008, it has tightly controlled the apps and services allowed on iPhones \nand iPads, giving the company an iron grip on one of the digital economy’s most valuable storefronts.\nNow Apple is weakening its hold on the store, in one of the most consequential signs to date of how new European \nregulations are changing consumer technology.\nTo comply with a European Union competition law taking effect on March 7, Apple on Thursday announced major \nchanges to the App Store and other services for consumers in Europe. Users of iPhones and iPads in the 27-nation \nbloc will for the first time be able to use alternative app stores to download games, productivity tools and other \napps. Banks and shopping services can offer competing payment methods inside their apps. People who buy new \niPhones in the future will also see a new menu for downloading alternative browsers to Apple’s Safari, such as \nChrome and Firefox.\nThe changes are some of the most tangible examples of how a checkerboard of laws and regulations is now \nfracturing people’s technology experiences, depending on where they live. In China, government rules force Apple \nto block apps like virtual-private networks, known as VPNs, which would give users access to the unfiltered internet. \nIn Europe, customers will now have access to competing app stores and other services. In the United States, where \nthere are fewer laws and regulations, Apple and other tech giants have more flexibility to operate as they please.\nThe shifts in the App Store stem from a 2022 law called the Digital Markets Act. The far-reaching law was aimed at \nloosening the power of the world’s largest tech companies in areas like e-commerce, social media and messaging. \nAmazon, Meta, Google and Microsoft have also announced changes to comply with the new rules.\n“The changes we’re announcing today comply with the Digital Markets Act’s requirements in the European Union, \nwhile helping to protect E.U. users from the unavoidable increased privacy and security threats this regulation \nbrings,” Phil Schiller, who leads the App Store, said in a statement.\nEurope accounts for about 6 percent of Apple’s App Store sales, which are estimated to be $24 billion annually \nworldwide.\nApple Overhauls App Store in Europe, in Response to New Digital Law\nE.U. regulators have long raised alarms that Apple abuses its control over the App Store to stifle competition. The \nSilicon Valley company has argued that its gatekeeper role protects customers from malware, privacy breaches and \nflawed apps. But app developers like Spotify and Epic Games, the maker of Fortnite, have said Apple misuses its \npower by demanding that they pay high fees and forcing them to use underlying technology that it makes.\nFor years, Apple has resisted making the kinds of changes it announced on Thursday. It is unclear if the moves will \nsatisfy European regulators who have vowed to aggressively enforce compliance with the Digital Markets Act.\nA spokesman for the European Commission, the European Union’s executive branch, declined to comment on \nApple’s announcement.\nApple said it would maintain some oversight of new marketplaces and apps working outside its App Store, but \nwarned that the new E.U. policies would give hackers and criminals a new path to distribute malware and defraud \ncustomers. The company said it had created a system to monitor all iOS apps, approve alternative app stores and \ntrack alternative payment systems.\nApple said developers would also be charged a fee of 50 euro cents for every download of their app after it has \nbeen downloaded one million times or more within a 12-month period, regardless of whether it was through the App \nStore or an alternative. This will also apply to free apps, but not apps distributed by government, education and \nnonprofit organizations.\nThe new rules could dent Apple’s finances. The App Store’s policy of taking up to 30 percent of developers’ sales \nhas made it a critical piece of the company’s nearly $400 billion business. But it has also opened Apple to criticism \nand regulatory scrutiny because many developers complained that the fees were unjust.\nIn Europe, Apple said, developers using the App Store will have the option to continue using the existing \ncommission terms, or move to a new fee structure. This will include a reduced commission fee of up to 17 percent \nfor digital goods and services. An additional fee of 3 percent will be charged to developers who use Apple’s \npayment system.\nTim Sweeney, the chief executive of Epic Games, said Apple’s new policies were a “horror show” for developers, \nfilled with “new junk fees on downloads and Apple taxes on payments they don’t process.” He said Apple was also \nmaintaining the power to block a company like Epic from introducing a games store.\n“Apple proposes that it can choose which stores are allowed to compete with their App Store,” he said in a post on \nX.\nApple said its fees covered the costs of developing its software and providing tools to developers.\nDevelopers who distribute their app through a competing app store will not be subject to any Apple commission. \nAnd developers who provide links to complete payments outside their apps can also forgo certain transaction fees.\nDevelopers will also be able to avoid what some of them have said is a cumbersome review process by Apple of \nthe apps it distributes in its store. But the company has created a new system, which it calls notarization, to \nmaintain some control over the apps distributed across iPhones. Every iPhone app will include an installation key to \nprovide Apple with information on when it was installed and allow the company to do automated scans for malware.\nAs part of the notarization process, apps will provide Apple with descriptions and screenshots of the services they \noffer, as well as the names of the developers. Apple will share that information with iPhone users before an app is \ndownloaded.\nSpotify did not immediately have a comment on Apple’s announcement. In a blog post this week, Spotify said the \nDigital Markets Act would help developers offer new services to customers.\n“Developers everywhere are continuing to ask other governments to pass their own laws like the D.M.A.,” the \ncompany said.\nApple Overhauls App Store in Europe, in Response to New Digital Law\nApple also introduced a feature for customers to use alternatives to its Wallet app for mobile payments, an \nincreasingly common form of payment for public transportation, restaurants and cafes. Major banks and businesses \nlike PayPal can now offer competing services.\nApple has challenged some elements of the new European law, including a requirement that would open its \nmessaging service, iMessage, to work more smoothly with Android devices. The company has argued that \niMessage isn’t subject to the requirements because it is free to customers.\nThe European Union has not made a final decision on the messaging issue.\nThis article appeared in print on page B1, B4.\nLoad-Date: January 26, 2024"
    },
    {
        "file_name": "Gokul_Rajaram_Mar2023",
        "header": "Next nine months will lead to company failures, shutdowns, down rounds:",
        "media": "Gokul Rajaram",
        "time": "March 30, 2023",
        "section": "TECH & INTERNET",
        "length": "978 words",
        "byline": "Samidha Sharma",
        "story_text": "Next nine months will lead to company failures, shutdowns, down rounds: \nGokul Rajaram\nThe Economic Times\nMarch 31, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 978 words\nByline: Samidha Sharma\nBody\nSilicon Valley-based Gokul Rajaram, a solo capitalist, operator and prolific angel investor who has backed 300 \ncompanies including online marketplace Faire, Figma (sold to Adobe for $20 billion), and collaboration software \nstartup Airtable, said recently that founders should explore the option of shutting down startups that are unable to \nfind product market fit (PMF) after having raised $10 million or so in funding. Rajaram, dubbed the 'Godfather of \nGoogle's AdSense', who later became product director of ads at Facebook, is also an angel investor in domestic \nstartups with a portfolio comprising Cred, Curefit, and Whatfix, and an advisor for the likes of of Pine Labs, told ET \nin an interview that the next nine months will lead to company failures, shutdowns and down rounds. Edited \nexcerpts:You tweeted recently that founders should be able to return capital if there is no PMF. Why do you think \nthis isn't being explored more widely?\n Is it because it threatens the VC model?It's because in the past, founders only raised large rounds post-PMF and \nscaling companies post-PMF consumed capital. In 2020-21, several companies raised meaningful capital despite \nnot having PMF, or having Covid-induced PMF that fell away post-pandemic, and once that demand fell away, lack \nof PMF was exposed. Now we have companies that have raised capital without a clear PMF. There is no playbook \naround what to do here because it's a unique situation that never really happened before.Seeing what happened in \nthe US tech ecosystem, you told me you were surprised this isn't the case yet in India...(It's) definitely surprising. \nThey are still sitting on piles of cash and maybe have even cut costs so that they have a runway. I think they are \nwaiting it out for some positive catalyst, which unfortunately might not be on the near-term horizon.You've been \ninvesting in India, too. Why hasn't a massive correction not taken place here yet?A correction has to take place. It's \ninevitable. Everyone is looking at each other to see who takes the first down round and see if it has an impact on \ntheir reputation among employees and other stakeholders. So, my message is - it's ok. Do the down round. Your \ncustomers won't care, and your employees will be happier. And you will be freed from the shackles of trying to live \nup to an unrealistic valuation.What's right and wrong with India's tech ecosystem? Are valuations way ahead of \nground realities?What's right? Several incredible founders and companies building generational companies, not just \nserving India but global leaders. Postman is an example. I believe a good percentage of all engineers in the world \nuse their platform. What's wrong? Too many me-too companies being started, people founding or joining startups \nfor the wrong reasons (money, fame) versus, to build something substantial. On valuations, any Series A or later \nvaluations in 2020 and 2021 were far ahead of reality and need to be reset for a full cleansing of the \necosystem.What should Indian founders prioritise, especially the ones who haven't been through a downturn?First \noff, make sure you're working on a meaningful and large problem. Second, ensure that your value proposition and \nproduct is differentiated and not commoditized. If you feel good about these two, ensure you have capital for the \nnext 18 months, to survive and continue building towards your vision. If either of these two is not true, consider an \nexit: pivoting, merging with a competitor or even shutting down the company and returning capital to investors. The \nopportunity cost of time wasted on building meaningless things is too high.What's the big picture for India?India \ntech will have short-term bumps because of capital raising issues but the long-term future remains bright due to the \nNext nine months will lead to company failures, shutdowns, down rounds: Gokul Rajaram\ngrowing scale of the Indian consumer. The long-term demographic shifts... favour India, and the lowering of barriers \nfor software companies to reach customers everywhere.What would you watch out for over the next few months?I \nthink the next nine months will lead to a ton of company failures, shutdowns and down rounds. And that is good. \nOnly by cleaning out the excesses of each cycle can the new cycle begin. I think of this process (as) freeing \nentrepreneurs and talent from zombie companies and liberating them to start something new/afresh.How do you \ncompare this downturn to all the cycles you've seen before?In 2000, it was purely tech focused, bubble bursting \nand Nasdaq, and mostly US. In 2007-08, it was much bigger and wide-ranging and global. I feel the current one is \ncloser to 2000 than to 2008. That said, tech is such a big part of the economy with many of the highest market cap \ncompanies being in this sector. The economy is also being driven in many ways by tech and the industry is global \nand interconnected, which feels closer to 2008.What are founders telling you right now? How impacted are they \nwith big tech companies resetting their businesses and downsizing workforce? What has been the mood after \nSilicon Valley Bank's collapse?The seed ecosystem is very active right now - lots of high-quality founders coming \nout of Meta, Google, Amazon and other companies that have gone through layoffs. Also, Generative AI (Artificial \nIntelligence) has given a massive rallying cry and tech platform for companies to build on. SVB had a valuable role \nin the ecosystem as a tech-friendly/tech-first bank. Ask any company who's dealt with them versus one of the big \nbanks. The difference is palpable.What's the investor accountability in this?Investors do share part of the blame, no \ndoubt. I think all of us got a little drunk on the zero-interest rate phenomenon and overfunded companies with poor \nPMF/defensibility/unit economics. We are now experiencing the hangover after the party ends. But a hangover is \nneeded to cleanse one's system. For Reprint Rights: timescontent.com\nLoad-Date: March 30, 2023"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "Goldman Sachs India to train over 1,000 non-engineers in AI",
        "media": "The Economic Times",
        "time": "March 9, 2024",
        "section": "TECH & INTERNET",
        "length": "566 words",
        "byline": "Beena Parmar",
        "story_text": "Goldman Sachs India to train over 1,000 non-engineers in AI\nThe Economic Times\nMarch 9, 2024 Saturday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 566 words\nByline: Beena Parmar\nBody\nAmerican investment bank Goldman Sachs has set up a facility in India to train both engineers and non-engineers \nin generative artificial intelligence (GenAI) to explore the usage of the technology in its businesses.Since 2006, \nGoldman Sachs has invested more than $7 billion in India. Starting off as a support function, the Indian operations \nhave now become the second largest for Goldman Sachs globally.“In 2024, we aim to train over 1,000 non-\nengineering business users across Bengaluru and Hyderabad offices in India … They include individuals across \noperations, controllers, treasury, sales, research and investment banking,” Gunjan Samtani, global chief operating \nofficer of engineering at Goldman Sachs, told ET.The school was piloted in mid-2023, under which the global \nfinancial services major trained employees across asset and wealth management, risk management, global banking \nand markets functions.It aims to have more than 4,000 employees trained in AI, said Samtani, who is also the \ncountry head for Goldman Sachs Services India.About two decades ago, it set up Goldman Sachs Services India in \nBengaluru as one of its global capability centres and now has over 8,500 employees working out of its Bengaluru \nand Hyderabad offices, representing about 18% of the total global headcount. The Hyderabad centre was \ninaugurated in October last year.Half of the 8,500 staffers in India are engineers, representing one-third of the \n12,000 engineers Goldman Sachs employs globally. \nWith the largest office presence outside of its headquarters in New York, India also has the highest percentage of \nengineers embedded into Goldman Sachs’ front-to-back businesses.“In the context of distribution of engineers \nacross Americas and India, in totality, I think they are on par with each other,” Samtani said, adding that the bank is \nmaking deliberate efforts to prepare its workforce for AI.This also comes at a time when most technology firms are \nupskilling and reskilling their employees, especially engineers, in order to improve productivity, efficiency as well as \nprepare for better AI use-cases and adapting them to new roles.By the end of the year, according to Samtani, all \nGoldman Sachs engineers in India, who are in roles that are software development centred, will be enabled on \nGenAI based co-pilots. There are about 3,200 engineers who are working in software development-related \nroles.Goldman Sachs has several hundred open roles over a spectrum of functions. Without giving a specific \nnumber, Samtani said: “There will be a tremendous focus in hiring individuals exposed to emerging technologies \nlike AI and cloud engineering. We have open roles in software development and quantitative finance, and \nadditionally in operations, controllers and compliance functions. On the business side, we have roles in our asset \nmanagement, wealth management, global banking and markets businesses.”In 2022 and 2023, the company hired \nan average of 2,000 employees annually in India at the two centres. Around 40% of these were in engineering \nfunctions.Currently, Goldman Sachs has more than 1,000 developers using GenAI for coding.“More than 100 ideas \nhave been identified across the firm, and we currently have about a dozen proofs of concept. Certain elements of \ninternal use cases are planned for roll-out to a broader population throughout 2024,” Samtani said. For Reprint \nRights: timescontent.com\nLoad-Date: March 9, 2024\nGoldman Sachs India to train over 1,000 non-engineers in AI"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Can AI Actors Dethrone Superstars?",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 16, 2023",
        "section": "BREAKING IDEAS",
        "length": "819 words",
        "byline": "Anil Nair",
        "story_text": "Can AI Actors Dethrone Superstars?\nEconomic Times (E-Paper Edition)\nSeptember 16, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 819 words\nByline: Anil Nair\nBody\nThe Independence Day weekend saw `390 crore in gross box-office collections, a record for Indian cinema in over \n100 years. Rajinikanth's Jailer, Sunny Deol's Gadar 2, Akshay Kumar's OMG 2 and Chiranjeevi's Bhola Shankar did \nexceptional business across languages, multiplexes and single-screen halls. And Atlee's SRKstarring Jawan, of \ncourse, reinforced the trend with first-day collections of `74.5 crore. With generative AI becoming pervasive, will \ndeepfakes replace actors?\n Or bring deceased actors back to life? The current turmoil in Hollywood could well be the trigger. The US Screen \nActors Guild and American Federation of Television and Radio Artists (SAG-AFTRA) struck work on July 14, joining \nthe Writers Guild of America (WGA), who've been protesting since May 2, demanding higher pay, job security and \nmore parity across the industry. The impasse has lasted over 130 days, and estimates put the economic impact at \n$2-3 billion. There is uncertainty about when this strike will end and how big the hole will be. While streamers like \nNetflix and Amazon can source content, including movies, series, events and sport, from the rest of the world, and \nthe TV industry will chug along  till they have inventory, studios are aware that losses are in the offing. The strike in \nHollywood is hurting other sectors too, including clothiers, prop-makers, caterers, transportation companies, hotels \nand cinema theatres. And that's why thoughts about a new, more robust valuechain hover. Generative AI and CGI \nare poised to impact the film business extraordinarily. For instance, creativity could be automated for the most part, \nwith human intervention limited to coursecorrection. Scripts, sets and costume design, storyboards, and visual \neffects are par for the course. Actors can be de-aged, as director James Mangold did in Indiana Jones and the Dial \nof Destiny recently, when 80-year-old Harrison Ford had to look 35 years younger in two action sequences. \nDirectors can now create new virtual characters, perfectly matching their imagined roles. Film companies would be \nspared the pain of hard negotiations over rates or matching the calendars of actors, while slashing costs \ndramatically, including on overruns. AI-powered tools are increasingly being used for editing and postproduction \nwork, whether to obliterate irksome objects or  transform footage with natural language prompts. They will \nunshackle the imagination of filmmakers, reined in now by hurdles, such as permissions, costs, access, facilities \nand actors. Image-generation models are evoking a lot of interest and are rapidly becoming sophisticated. For \ninstance, Runway Research released Latent Diffusion in 2021, which could be prompted to generate realistic \nimages. Stable Diffusion, released in 2022, had more advanced image generation. Then came Gen 1, which \nenabled the generation of new video content from a simple video — stylising footage, converting mock-ups into \nanimated shots, modifying objects in a picture entirely, or rendering them differently to create new scenes. Now, \nRunway's Gen 2 takes a huge technological leap, and, though nascent, can generate short videos from mere text \nprompts. Adobe's After Effects is used extensively in film and TV post-production. Its newly launched Firefly, an \nembedded generative AI model, in March, can recommend shots after gleaning the script, generate a background \nscore and even different backdrops for different countries.  Adobe is promising that commercial use of Firefly will be \nlegally safe. Importantly, the process of democratisation is underway. Small creative houses can now think big with \nsuch tools. Some recent Indian films that have used AI are Paan Singh Tomar (2012), Ghazi Attack (2017), Kesari \nCan AI Actors Dethrone Superstars?\n(2019), and Uri (2019). Like most countries, India has no specific laws to address the issue of deepfakes. Various \nsections of the Indian Penal Code 1860, Indian Evidence Act 1872, Copyright Act 1957, and the IT Act 2000 would \napply in the case of fake images inserted in synthetic media. India's landmark Digital Personal Data Protection Bill \n2023, passed by Parliament last month, could've changed that. That the debate in each House lasted less than an \nhour is telling. Various sections could've dealt with deepfake-related issues more specifically, for instance, sections \npertaining to information relating to a living individual, prohibiting processing personal data that is unfair, deceptive \nor intrusive; the section that calls for responsible data fiduciaries or the removal of violative information. Areas of \nconcern include wide ranging governmental exemptions and worse, that the Data Protection Board of India will \nhave only government nominees. The autonomy of this board will determine how well the Bill serves and protects \ndata principals — stars and people like us, even from our digital doppelgngers. The writer is senior fellow, Portulans \nInstitute, Washington DC\nLoad-Date: September 16, 2023"
    },
    {
        "file_name": "The_Economic_Times_May2023",
        "header": "Thena raises $5 million in seed funding led by Lightspeed",
        "media": "The Economic Times",
        "time": "May 24, 2023",
        "section": "FUNDING",
        "length": "436 words",
        "byline": " ",
        "story_text": "Thena raises $5 million in seed funding led by Lightspeed\nThe Economic Times\nMay 25, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 436 words\nBody\nThena, a customer communications and intelligence platform that helps businesses manage customers on \nmessaging platforms Slack and Microsoft Teams, Wednesday said it has raised $5 million in a seed funding round \nled by Lightspeed Venture Partners.Other investors include First Round Capital and returning investor Pear \nVC.Thena enables clients' messaging platforms to be used at scale for business-to-business customer \ncommunications by helping customer-facing teams manage customers.The platform detects, tracks and measures \ncustomer requests, and also provides analytics and insights into how customers are engaging with a client \ncompany. Additionally, the platform integrates with internal tools like Zendesk, HubSpot, and Salesforce.Thena's \nplatform works with enterprise clients that have anything from 200 to 400 Slack channels with customers, founder \nand CEO Ankit Saxena told ET in an interaction.\"We are scaling up our sales and go-to-market teams in the United \nStates and then some in India as well. From a product perspective, the timing is perfect for a great marriage \nbetween moving over to messaging and all the new innovation that is happening in the generative AI space,\" \nSaxena said.Thena was founded in April 2022 by Saxena, Govind Kavaturi, Mike Molinet, and Unmukt Raizada. \nMolinet also co-founded Branch in 2014, playing a central role to the brand's growth and operational scale, just prior \nto joining Thena as a co-founder.\"Our AI models synthesise data across communication channels, equipping \ncompanies with their own fine-tuned models that enable them to make customer-centric decisions at scale and \nimprove bottom line,\" Saxena added.The startup services customers including Spendflo, Zluri, Branch, Embrace, \nMixpanel, WorkRamp and Spotdraft, of which about 95% of clients use Slack and the rest use Teams because the \ncompany focussed its product on Slack during the first year of commercialisation.Thena draws 80% of its revenues \nfrom the US, 15% from India and 5% from the rest of the world. Going forward, India will start to capture a bigger \npercentage share, Saxena added.\"Thena not only has an inspirational vision and mission, but its core team has \npreviously scaled a $100 million annual recurring revenue business from the ground up, proving their ability to build \nthrough market cycles with tenacity, innovation, and speed,\" Hemant Mohapatra, partner at  India Partners, \nadded.Prior to the current round, Thena had raised $2.2 million from Pear VC and Tenacity Venture Capital in \nAugust 2022, bringing the total funding so far to $7.2 million. For Reprint Rights: timescontent.com\nLoad-Date: May 24, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Is the Media Ready for 2024?",
        "media": "The New York Times",
        "time": "December 7, 2023",
        "section": "Section F; Column 0; SpecialSections; Pg. 9",
        "length": "1322 words",
        "byline": "By Benjamin Mullin",
        "story_text": "Is the Media Ready for 2024?\nThe New York Times\nDecember 7, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section F; Column 0; SpecialSections; Pg. 9\nLength: 1322 words\nByline: By Benjamin Mullin\nBody\nJournalists are facing ''deep fakes,'' sagging trust, global unrest and an unprecedented Trump campaign being run \n''from the courthouse steps.''\nThis article is part of our special section on the DealBook Summit that included business and policy leaders from \naround the world. \n  The future is here, and for many in the media business, it's terrifying.\n  In an effort to understand threats facing the media during the upcoming presidential campaign, I asked a \ntechnology firm in California to create a ''deep fake'' video of President Biden, the kind of inauthentic footage that \ncould flummox journalists on Election Day.\n  The results were sobering. Within seconds, the company -- which requested anonymity because of the \ncontroversial nature of the assignment -- transformed my likeness into President Biden's, using artificial intelligence \ntechnology and a snippet of video I recorded.\n  Every presidential election cycle in recent memory has been shaped by the emergence of a new technology or the \nexploitation of an existing one. But 2024 will be more complicated. In addition to threats posed by ''deep fakes,'' \njournalists will have to fight a battle for the truth on multiple fronts, grappling with tricky coverage of the criminal \nproceedings against former President Donald J. Trump and sagging trust in the news media.\n  ''This will affect every aspect of American journalism, from how we operate our businesses to the new competitors \nthat rise, to the new sources of fake or manipulated media that sprout and spread,'' said Jim VandeHei, a co-\nfounder of Politico and Axios. ''Buckle up.''\n  Trump TV\n  Most election years, coverage of the grueling campaign trail dominates the airwaves, as candidates make the \nquadrennial pilgrimage to seemingly every fish fry, state fair and union hall between the coasts.\n  Things will be a little different this year, throwing a curveball to journalists and media executives making coverage \ndecisions.\n  As Mr. Trump faces criminal charges in New York, Georgia, Washington, D.C., and Florida, one of the dominant \nstories of the 2024 campaign will most likely be the outcome of those criminal proceedings, said David Axelrod, the \narchitect of former President Barack Obama's presidential campaigns and a senior fellow at the University of \nChicago Institute of Politics.\nIs the Media Ready for 2024?\n  That poses a challenge for news organizations, Mr. Axelrod said. Mr. Trump has denied all wrongdoing and railed \nagainst prosecutors, signaling he would try to use the indictments for political advantage.\n  With Mr. Trump likely to run his campaign ''from the courthouse steps,'' journalists will be forced to separate the \nfacts of the case from Mr. Trump's partisan attacks in real time, Mr. Axelrod said. News directors will be tasked with \ncovering the case without airing falsehoods or lavishing Mr. Trump with gratuitous airtime, as they have in Mr. \nTrump's earlier campaigns.\n  ''He knows the case he wants to make, and it has nothing to do with the law,'' Mr. Axelrod said. ''He's going to be \npushing a story of political persecution.''\n  Political persecution is exactly what many conservative legal experts think the charges against Mr. Trump amount \nto. Josh Hammer, a constitutional lawyer and syndicated columnist who has written extensively on the cases \nagainst Mr. Trump, said that the proceedings posed an entirely different challenge to mainstream news \norganizations: being fair to the former president.\n  Mr. Hammer said that the overwhelming majority of coverage of Mr. Trump's legal travails, including cable news \nsegments and newspaper editorials, had shown that the press had rendered its guilty verdict before the jury has \nhad a chance to weigh in.\n  ''The hardest thing, by far, is for the media to separate the objective, legal facts from what their obvious \npreferences are,'' said Mr. Hammer, a conservative who is supporting the presidential bid of Gov. Ron DeSantis of \nFlorida.\n  Deep Fakes\n  The artificial video of President Biden is just one example of the many types of inauthentic content journalists will \ngrapple with in 2024.\n  Elections in Chicago and in Slovakia in Eastern Europe have already been disrupted by fake audio clips released \nbefore the election, spreading disinformation about candidates during a crucial period, said Sam Gregory, the \nexecutive director of Witness, a nonprofit that exposes human rights abuses posed by emerging technologies like \ndeep fakes and generative A.I.\n  Deep fake technology has become so ubiquitous that it is now possible to create inauthentic photos, videos and \naudio faster than it takes to debunk them, Mr. Gregory said. In addition, most mainstream news organizations have \nnot invested in the resources required to verify and cover misinformation on a tight deadline.\n  The fake videos and audio also pose another problem. They create an environment where everyone is skeptical of \neverything, including true information, Mr. Gregory said.\n  ''Knowing that people don't have the skills to do the detection, it's really quite easy to say, 'Oh, that was faked,' and \nknow that it's going to be hard for people to prove that it's actually real,'' he said.\n  Still, there are some opportunities for attentive deep fake sleuths, Mr. Gregory said. While audio is more \ncomplicated, images and video have a range of context clues that can help prove whether a snippet of footage is \ngenuine, and you can compare falsified images of an event against genuine to spot inconsistencies.\n  Any downsides posed by generative A.I. technology to the media must be weighed against its upsides, said Steve \nAmato, the founder and chief executive of Contend, a studio in Los Angeles that has used the technology to create \nmarketing campaigns for companies including Amazon, Microsoft and Disney.\n  Mr. Amato cited medicine and education as fields in which the technology could be beneficial, bringing health care \nproviders closer to patients virtually and providing students with immersive learning experiences.\n  ''We're in awe of all of these things on the positive side, too,'' Mr. Amato said.\nIs the Media Ready for 2024?\n  Decline of Trust\n  One of the biggest challenges facing the press next year has nothing to do with emerging technology or political \nattacks. Readers just don't trust the press the way they used to, experts say, and that could have major \nconsequences come election time.\n  About a quarter of Americans surveyed by the Pew Research Center in 2019 said they don't have much trust in \ninformation they get from the national news media. That number is even higher among Republicans, with roughly a \nthird of those professing little trust in national news.\n  Deep fakes and accusations of bias from politicians are particularly damaging because they reach voters who are \nalready distrustful of traditional media, said Frank Sesno, a professor of media and public affairs at the George \nWashington University.\n  To combat sagging trust, news executives need to be more transparent with their readers and views about their \njournalism, showing them how stories get made and why, he said. That doesn't mean news networks like CNN \nshould play an ''endless tape loop'' of ''journalism primer,'' Mr. Sesno said, but it does mean explaining what makes \ncertain topics newsworthy.\n  ''People love being taken behind the scenes,'' Mr. Sesno said. ''People stood and applauded years ago when I \nwas in a movie theater and they watched 'Spotlight.'''\n  In addition to being more open with readers, news organizations should also push back against politicians like Mr. \nTrump who accuse the press of being dishonest or deliberately spouting misinformation, Mr. Sesno said.\n  If an airline were facing attacks from competitors who said its planes weren't safe, the company would be \norchestrating a huge public relations campaign to reassure passengers and win back their business, he said.\n  ''When the media does that, it often sounds like self-congratulatory backslapping,'' Mr. Sesno said. ''But they need \nto respond.''\nhttps://www.nytimes.com/2023/12/06/business/dealbook/2024-election-media.html\nGraphic\n \nThis article appeared in print on page F9.               \nLoad-Date: December 7, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Apr2024",
        "header": "3AI Holding, SML India to Jointly Own GenAI Platform ‘Hanooman’",
        "media": "Economic Times (E-Paper Edition)",
        "time": "April 5, 2024",
        "section": "STARTUPS & TECH",
        "length": "230 words",
        "byline": "Our Bureau",
        "story_text": "3AI Holding, SML India to Jointly Own GenAI Platform ‘Hanooman’\nEconomic Times (E-Paper Edition)\nApril 5, 2024 Friday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 230 words\nByline: Our Bureau\nBody\nMumbai:Abu Dhabi-based artificial intelligence (AI) investment firm 3AI Holding has partnered with Seetha \nMahalaxmi Healthcare (SML) to jointly own Hanooman, a multilingual generative artificial intelligence platform \ndeveloped by SML in collaboration with IIT Bombay. Under this joint ownership, both parties will hold a 50% stake \neach in Hanooman, the companies said in a statement. \nThe platform aims to reach 200 million users across 22 Indian languages within its first year, starting from its launch \non May 1. Hanooman is expected to gain access to 3AI Holding’s Omega generative AI model, which is being \ndeveloped with 665 billion parameters and 20 trillion tokens. Omega will enhance Hanooman’s capabilities in text, \nvoice, image, and code for users, Arjun Prasad, managing director of 3AI Holding, told ET. Known for investing in \ncompanies operating in stealth mode, 3AI Holding is backed by Patel Family Office, a third-generation family office \nfrom the United States. Other companies in 3AI’s portfolio include AI firm QX Lab AI in which it holds a majority \nstake. “The idea behind this partnership was to repatriate technology back to India. Our focus point was that we \nhave invested in these technologies, and now we wanted to partner with an Indian entity to showcase how we can \nbring technology back to India while all startups are going across the globe,” Prasad said.\nLoad-Date: April 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Actors Authorize Potential Strike With Hollywood Writers Still Picketing",
        "media": "The New York Times",
        "time": "June 7, 2023",
        "section": "BUSINESS; media",
        "length": "495 words",
        "byline": "Nicole Sperling",
        "story_text": "Actors Authorize Potential Strike With Hollywood Writers Still Picketing\nThe New York Times \nJune 5, 2023 Monday 00:05 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 495 words\nByline: Nicole Sperling\nHighlight: The vote does not guarantee a walkout. The actors and studios will begin negotiations on Wednesday.\nBody\nThe News\nThe union that represents more than 160,000 film and television actors voted on Monday night to authorize a strike, \ntwo days before it is to begin negotiations on a new labor deal with the Hollywood studios. The result from members \nof the SAG-AFTRA union, with 98 percent authorizing a strike, was expected, and it came during the sixth week of \na strike by Hollywood writers and just a day after the Directors Guild of America tentatively agreed to a new \ncontract.\n“Together we lock elbows, and in unity we build a new contract that honors our contributions in this remarkable \nindustry, reflects the new digital and streaming business model and brings ALL our concerns for protections and \nbenefits into the now!” Fran Drescher, the president of the actors’ union, said in a statement.\nAbout 65,000 members cast ballots, or 48 percent of eligible voters. The actors’ current agreement with the Alliance \nof Motion Picture and Television Producers, which bargains on behalf of the studios, expires on June 30.\nWhy It Matters: The actors have the same worries as the writers.\nMany of the actors’ concerns echo what the Writers Guild of America is fighting for: higher wages; increased \nresidual payments for their work, specifically for content on streaming services; and protections against using \nactors’ likenesses without permission as part of the enhanced abilities of artificial intelligence. According to the \nwriters, the studios offered little more than “annual meetings to discuss” artificial intelligence, and they refused to \nbargain over limits on the technology.\nThe Directors Guild, in contrast, said on Sunday that it had reached a “groundbreaking agreement confirming that \nA.I. is not a person and that generative A.I. cannot replace the duties performed by members.” Details about what \nthat meant were not revealed.\nBackground: It has been a long time since the last actors’ strike.\nThe last time the actors went on strike was in 2000, in a dispute over commercial pay. The strike lasted close to six \nmonths.\nWhat’s Next: Negotiations begin on Wednesday.\nWith negotiations expected to begin on Wednesday, SAG-AFTRA is bullish about what this strike authorization \nmeans. “We’re obviously coming in from a position of strength, but we’re not looking to strike,” said Duncan \nActors Authorize Potential Strike With Hollywood Writers Still Picketing\nCrabtree-Ireland, the union’s chief negotiator. “We’re here to make a deal.” He added: “But we’re also not going to \naccept anything less than what our members deserve. If a strike is necessary to achieve that, we’re prepared.”\nThe Alliance of Motion Picture and Television Producers said in a statement that “we are approaching these \nnegotiations with the goal of achieving a new agreement that is beneficial to SAG-AFTRA members and the \nindustry overall.”\nPHOTO: Members of SAG-AFTRA supported the striking Writers Guild of America at a rally last month outside \nWarner Bros. Studios in Burbank, Calif. (PHOTOGRAPH BY CHRIS PIZZELLO/ASSOCIATED PRESS) This article \nappeared in print on page B4.\nLoad-Date: June 7, 2023"
    },
    {
        "file_name": "also_peril._May2023",
        "header": "Science fiction come to life? AI holds promise for future generations – but",
        "media": "also peril.",
        "time": "May 1, 2023",
        "section": "",
        "length": "1086 words",
        "byline": "Mark Murphy",
        "story_text": "Science fiction come to life? AI holds promise for future generations – but \nalso peril.\nUSA Today Online\nApril 29, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 1086 words\nByline: Mark Murphy\nBody\n“I’m sorry, Dave, I’m afraid I can’t do that.”\nWith this line, the renegade computer HAL 9000 directly contradicted a direct order given to it by Dave Bowman, \nmission scientist aboard the Discovery One spacecraft bound for Jupiter, in Stanley Kubrick’s 1968 film \"2001: A \nSpace Odyssey.\" In 1984, James Cameron’s \"The Terminator\" introduced us all to Skynet, a defense computer \nnetwork that initiated a global nuclear war to exterminate humanity.\nCinematic portrayals like these have made us all familiar with the risks of artificial intelligence, where computers \ncapable of thinking like humans pose a danger to us all. But that’s simply science fiction, right?\nPerhaps not.\nHey Siri, who's Alexa?\nWe all use computer-assisted artificial intelligence every day. The autocorrect feature in text messaging is one \nexample; Apple’s Siri and Amazon’s Alexa are others.\nThe endoscopy unit in my office has an artificial intelligence feature that assists us in detecting colon polyps. When \nyou order something on Amazon and ads pop up on social media for similar products? That’s AI, too. So is the \nfacial-recognition technology on your phone.\nOpinions in your inbox: Get exclusive access to our columnists and the best of our columns\nNot your parents' Google: Why universities should embrace, not fear, ChatGPT and artificial intelligence\nIn 2017, Russian President Vladimir Putin said the nation that controls AI “will become the ruler of the world.” Putin \nhas become a worldwide villain following the Russian invasion of Ukraine, but the dictator was not wrong about AI.\nArtificial intelligence impacts all of us daily. A search on the Apple app store reveals hundreds of AI-driven apps in \nareas as disparate as art, photography, video production and music composition.\nProgress in AI went relatively slowly until 2012, when the idea of a neural network revolutionized the entire industry. \nA neural network is a mathematical system that finds statistical patterns in enormous amounts of data.\nLink to Image\nIn 2018, another technological leap occurred when Google, Microsoft and OpenAI began building vast neural \nnetworks trained on large volumes of text from the internet. These large language models opened the door for the \nScience fiction come to life? AI holds promise for future generations – but also peril.\nnext step in AI evolution: Generative AI, where the systems learned to write prose, poetry and have conversations \nthat seemed almost human.\nThe AI chatbot ChatGPT, launched by developer OpenAI in collaboration with Microsoft last November, has made \nheadlines because of its conversational and writing abilities, which mimic human speech and writing, respectively. \nChatGPT can write business pitches, compose music and poetry, simulate an entire chat room, and write essays. It \ncan compose grocery lists, give you ideas about travel and can describe art in detail. AI chatbot programs can also \n“read” large articles and summarize them – a sort of computerized SparkNotes.\nHow far will we let AI go?: ChatGPT made up research claiming guns aren't harmful to kids\nJohn Oliver is wrong to worry about ChatGPT: AI can help us solve complex problems\nHey Siri and Alexa, what's GPT-4?\nA newer version of Open AI’s chatbot platform, GPT-4, recently scored in the 88th percentile on the Law School \nAdmission Test. Naturally, there are concerns about the capabilities of such an advanced system. Italy recently \nbanned ChatGPT due to concerns about privacy.\nChatGPT is available for free on the OpenAI website. I have an account there and asked ChatGPT to compose a \npoem about Savannah, a haiku about enduring love and a paragraph about pirates in the style of Ernest \nHemingway. ChatGPT composed each of these in seconds. Both were passable, if not spectacular.\nLink to Image\nAs a writer, this frightens me.\nWhat might be even more frightening is the ability of AI programs to create misleading, but realistic-looking \ndisinformation. AI programs can create realistic-looking digital images, such as one of Pope Francis in a puffy \nBalenciaga jacket or of Donald Trump marching through the streets of New York this month in front of a crowd of \nflag-waving supporters, which in fact were both AI-generated fakes.\nIn an era in which social media is filled with all sorts of misleading information, the ability of realistic AI-generated \nfakes to be propagated in the media should arouse concern in all of us.\nOpinion alerts: Get columns from your favorite columnists + expert analysis on top issues, delivered straight to \nyour device through the USA TODAY app. Don't have the app? Download it for free from your app store.\nReal concerns could arise if artificial intelligence becomes self-aware, or sentient. This is the concern graphically \nillustrated in “The Terminator,” where Skynet decided that human beings were no longer necessary and \nexterminated them. There are some researchers who claim that this sort of thing is already happening. Last year, \nGoogle sidelined an engineer who claimed that its LaMDA AI software was sentient.\nMost researchers in the area do not believe that AI models have achieved sentience, at least not yet. But the \nprogress in these areas has been very rapid, and it’s likely only a matter of time before that occurs.\nThis is especially concerning considering the increasing automation of the world’s military. The U.S. Navy estimates \nthat up to 60% of its carrier air fleet will be composed of AI-driven unarmed aerial vehicles in the next decade. This \nfirst deployment of such a vehicle is slated for 2026.\nThe Navy has already taken delivery of a full-sized fully autonomous warship, the USNS Apalachicola, which is \nunmanned and can remain at sea for up to 30 days without any human crew.\nLink to Image\nScience fiction come to life? AI holds promise for future generations – but also peril.\nThe advent of the internet in the early 1990s revolutionized commerce, communication and the dissemination of \ninformation. Today, with 63% of the globe connected via the web, most of us cannot imagine the world without it.\nArtificial intelligence holds similar promise, but greater peril. How we utilize AI will define the trajectory of humanity’s \nnext generation, and beyond.\nMark Murphy, a Savannah-based  author and physician, is a longtime contributor to the Savannah Morning News, \nwhere this column first published. \nYou can read diverse opinions from our Board of Contributors and other writers on the Opinion front page, on \nTwitter @usatodayopinion and in our daily Opinion newsletter. To respond to a column, submit a comment to  \nletters@usatoday.com .\nThis article originally appeared on Savannah Morning News: Science fiction come to life? AI holds promise for \nfuture generations – but also peril.\nLoad-Date: May 1, 2023"
    },
    {
        "file_name": "on_guardrails_against_them._But_this_fictional_discussion,_from_five_years_Jan2024",
        "header": "An FAQ from the future -- how we finally defeated deepfakes; We can't agree",
        "media": "on guardrails against them. But this fictional discussion, from five years",
        "time": "January 7, 2024",
        "section": "MAIN NEWS; Opinion Desk; Part A; Pg. 1",
        "length": "1071 words",
        "byline": "Michael Rogers, Michael Rogers is an author and futurist whose most recent book is \"Email From the",
        "story_text": "An FAQ from the future -- how we finally defeated deepfakes; We can't agree \non guardrails against them. But this fictional discussion, from five years \nfrom now, shows that 2024 events may force the issue\nLos Angeles Times\nJanuary 7, 2024 Sunday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Opinion Desk; Part A; Pg. 1\nLength: 1071 words\nByline: Michael Rogers, Michael Rogers is an author and futurist whose most recent book is \"Email From the \nFuture: Notes From 2084.\"\nBody\nCast your mind forward. It's Nov. 8, 2028, the day after another presidential election. This one went smoothly -- no \nclaims of rampant rigging, no significant taint of skulduggery -- due in large part to the defeat of deepfakes, \ndemocracy's newest enemy.\nIs such a future possible? So far, neither government nor the tech industry has agreed on effective guardrails \nagainst deepfakes. But this FAQ (from five years in the future) shows that the events of 2024 may well force the \nissue -- and that a solution is possible.\n--\nWhy did it take so long to find an effective way to fight deepfakes?\nLate in 2022, sophisticated low-cost AI software appeared that made it easy to create realistic audio, video and \nphotographs -- so-called deepfakes. As these generative AI programs rapidly improved, it grew clear that deepfake \ncontent would be a danger to democracy.\nPolitical deepfakes -- both audio and video -- soon emerged: President Biden announcing that Americans would be \ndrafted to fight in Ukraine. A photo of Donald Trump hugging and kissing Dr. Anthony Fauci. Eric Adams, the \nmonolingual mayor of New York, speaking Spanish, Yiddish and Mandarin in AI-produced robocalls.\nVery quickly, the White House, the European Union and major technology companies all launched wide-ranging AI \nregulation proposals that included \"watermarking\" AI content -- inserting ID labels, a permanent bit of computer \ncode, into the digital file of any AI-generated content to identify its artificial origin.\nBut AI rule-setting proved complex, and labeling exemplified the quandaries: Would AI watermarking be legally \nrequired? How would it be enforced? As early as 2023, some cellphone cameras used AI in their image processing. \nWhat amount of AI input into content would require an identifier? Would an Instagram beauty influencer need to \nwatermark her face-tuned selfies?\nThe complications were such that no system was widely adopted.\n--\nAn FAQ from the future -- how we finally defeated deepfakes We can't agree on guardrails against them. But \nthis fictional discussion, from five years from now, ....\nWhat changed?\nThe largest coordinated deepfake attack in history took place the day after the November 2024 election. Every U.S. \nsocial media channel was flooded with phony audio, video and still images depicting election fraud in a dozen \nbattleground states, highly realistic content that within hours was viewed by millions. Debunking efforts by media \nand government were hindered by a steady flow of new deepfakes, mostly manufactured in Russia, North Korea, \nChina and Iran. The attack generated legal and civil chaos that lasted well into the spring of 2025.\n--\nYet none of the early authentication efforts was adopted?\nCorrect. The breakthrough actually came in early 2026 from a working group of digital journalists from U.S. and \ninternational news organizations. Their goal was to find a way to keep deepfakes out of news reports, so they could \nprotect what credibility the mainstream media still retained. It was a logical assignment: Journalists are historically \nruthless about punishing their peers for misbehavior, breaking out the tar and feathers for even minor departures \nfrom factual rigor.\nJournalism organizations formed the FAC Alliance -- \"Fact Authenticated Content\" -- based on a simple insight: \nThere was already far too much AI fakery loose in the world to try to enforce a watermarking system for dis- and \nmisinformation. And even the strictest labeling rules would simply be ignored by bad actors. But it would be possible \nto watermark pieces of content that weren't deepfakes.\nAnd so was born the voluntary FACStamp on May 1, 2026.\n--\nWhat does a FACStamp look like?\nFor consumers, FACStamped content displays a small \"FAC\" icon in one corner of your screen or includes an audio \nFAC notice. The signal can be turned off by the user, or it can be set to appear for only five or 10 seconds at the \nstart of a media stream.\nFACStamps are entirely voluntary. But every member of the FAC Alliance pledged that their internet, broadcast and \nphysical reports would publish only FACStamped media in their news sections.\n--\nHow does content qualify for a FACStamp?\nThe newest phones, tablets, cameras, recorders and desktop computers all include software that automatically \ninserts the FACStamp code into every piece of visual or audio content as it's captured, before any AI modification \ncan be applied. This proves that the image, sound or video was not generated by AI. You can also download the \nFAC app, which does the same for older equipment. The FACStamp is what technologists call \"fragile\": The first \ntime an image, video or audio file is falsified by AI, the stamp disappears.\n--\nBut AIis often used appropriately for doing things like reducing background noise in an audio file. FacStamped \ncontent can't be edited at all?\nIt certainly can. But to retain the FACStamp, your computer must be connected to the non-profit FAC Verification \nCenter. The center's computers detect if the editing is minor -- such as cropping or even cosmetic face-tuning -- and \nthe stamp remains. Any larger manipulation, from swapping faces to faking backgrounds, and the FACStamp \nvanishes.\nAn FAQ from the future -- how we finally defeated deepfakes We can't agree on guardrails against them. But \nthis fictional discussion, from five years from now, ....\n--\nHow did FACStamps spread beyond journalism?\nIt turned out that plenty of people could use the FACStamp. Internet retailers embraced FACStamps for videos and \nimages of their products. Individuals soon followed, using FACStamps to sell goods online -- when potential buyers \nare judging a used pickup truck or secondhand sofa, it's reassuring to know that the image wasn't spun out or \nscrubbed up by AI.\nIn 2027 the stamp began to appear in social media. Any parent can artificially generate a perfectly realistic image of \ntheir happy family standing in front of the Eiffel Tower and post it or email it to envious friends. A FACStamp proves \nthe family has actually been there.\nDating app profiles without FACStamps finally are growing rare. Videoconference apps have FAC options to ensure \nthat everyone on the call is real. And for influencers, it's increasingly difficult to claim \"authenticity\" without at least \nthe occasional FACStamp.\n--\nWhat's next?\nA bipartisan group of senators and House members plans to introduce the Right to Reality Act when the next \nCongress opens in January 2029. It will mandate the use of FACStamps in multiple sectors, including local \ngovernment, shopping sites, and investment and real estate offerings. Counterfeiting a FACStamp would become a \ncriminal offense. Polling indicates widespread public support for the act, and the FAC Alliance has already begun a \nbranding campaign.\nThe tagline: \"Is that a FAC?\"\nGraphic\n \nPHOTO: (no caption)  PHOTOGRAPHER:Illustration by Jim Cooke Los Angeles Times; photo by Associated Press \nLoad-Date: January 7, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Will Chatbots Teach Your Children?",
        "media": "The New York Times",
        "time": "January 17, 2024",
        "section": "TECHNOLOGY",
        "length": "1587 words",
        "byline": "Natasha Singer &lt;p&gt;Natasha Singer writes about technology, business and society. She is currently",
        "story_text": "Will Chatbots Teach Your Children?\nThe New York Times \nJanuary 11, 2024 Thursday 00:08 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1587 words\nByline: Natasha Singer &lt;p&gt;Natasha Singer writes about technology, business and society. She is currently \nreporting on the far-reaching ways that tech companies and their tools are reshaping public schools, higher \neducation and job opportunities.&lt;/p&gt;\nHighlight: New A.I. tools could enable a Silicon Valley dream: bots that customize learning for pupils. Prior \nattempts have not lived up to the hype.\nBody\nNew A.I. tools could enable a Silicon Valley dream: bots that customize learning for pupils. Prior attempts have not \nlived up to the hype.\nSal Khan, the chief executive of Khan Academy, gave a rousing TED Talk last spring in which he predicted that A.I. \nchatbots would soon revolutionize education.\n“We’re at the cusp of using A.I. for probably the biggest positive transformation that education has ever seen,” Mr. \nKhan, whose nonprofit education group has provided online lessons for millions of students, declared. “And the way \nwe’re going to do that is by giving every student on the planet an artificially intelligent but amazing personal tutor.”\nVideos of Mr. Khan’s tutoring bot talk amassed millions of views. Soon, prominent tech executives, including \nSundar Pichai, Google’s chief executive, began issuing similar education predictions.\n“I think over time we can give every child in the world and every person in the world — regardless of where they are \nand where they come from — access to the most powerful A.I. tutor,” Mr. Pichai said on a Harvard Business \nReview podcast a few weeks after Mr. Khan’s talk. (Google introduced an A.I. chatbot called Bard last year. It has \nalso donated more than $10 million to Khan Academy.)\nMr. Khan’s vision of tutoring bots tapped into a decades-old Silicon Valley dream: automated teaching platforms \nthat instantly customize lessons for each student. Proponents argue that developing such systems would help close \nachievement gaps in schools by delivering relevant, individualized instruction to children faster and more efficiently \nthan human teachers ever could.\nIn pursuit of such ideals, tech companies and philanthropists over the years have urged schools to purchase a \nlaptop for each child, championed video tutorial platforms and financed learning apps that customize students’ \nlessons. Some online math and literacy interventions have reported positive effects. But many education technology \nefforts have not proved to significantly close academic achievement gaps or improve student results like high \nschool graduation rates.\nNow the spread of generative A.I. tools like ChatGPT, which can give answers to biology questions and \nmanufacture human-sounding book reports, is renewing enthusiasm for automated instruction — even as critics \nwarn that there is not yet evidence to support the notion that tutoring bots will transform education for the better.\nWill Chatbots Teach Your Children?\nOnline learning platforms like Khan Academy and Duolingo have introduced A.I. chatbot tutors based on GPT-4. \nThat is a large language model, developed by OpenAI, which is trained on huge databases of texts and can \ngenerate answers in response to user prompts.\nAnd some tech executives envision that, over time, bot teachers will be able to respond to and inspire individual \nstudents just like beloved human teachers.\n“Imagine if you could give that kind of teacher to every student 24/7 whenever they want for free,” Greg Brockman, \nthe president of OpenAI, said last summer on an episode of the “Possible” podcast. (The podcast is co-hosted by \nReid Hoffman, an early investor in OpenAI.) “It’s still a little bit science fiction,” Mr. Brockman added, “but it’s much \nless science fiction than it used to be.”\nThe White House seems sold. In a recent executive order on artificial intelligence, President Biden directed the \ngovernment to “shape A.I.’s potential to transform education by creating resources to support educators deploying \nA.I.-enabled educational tools, such as personalized tutoring in schools,” according to a White House fact sheet.\nEven so, some education researchers say schools should be wary of the hype around A.I.-assisted instruction.\nFor one thing, they point out, A.I. chatbots liberally make stuff up and could feed students false information. Making \nthe A.I. tools a mainstay of education could elevate unreliable sources as classroom authorities. Critics also say A.I. \nsystems can be biased and are often opaque, preventing teachers and students from understanding exactly how \nchatbots devise their answers.\nIn fact, generative A.I. tools may turn out to have harmful or “degenerative” effects on student learning, said Ben \nWilliamson, a chancellor’s fellow at the Centre for Research in Digital Education at the University of Edinburgh.\n“There’s a rush to proclaim the authority and the usefulness of these kinds of chatbot interfaces and the underlying \nlanguage models that power them,” Dr. Williamson said. “But the evidence that A.I. chatbots can deliver those \neffects does not yet exist.”\nAnother concern: The hype over unproven A.I. chatbot tutors could detract from more traditional, human-centered \ninterventions — like universal access to preschool — that have proved to increase student graduation rates and \ncollege attendance.\nThere are also issues of privacy and intellectual property. Many large language models are trained on vast \ndatabases of texts that have been scraped from the internet, without compensating creators. That could be a \nproblem for unionized teachers concerned about fair labor compensation. (The New York Times recently sued \nOpenAI and Microsoft over this issue.)\nThere are also concerns that some A.I. companies may use the materials that educators input, or the comments \nthat students make, for their own business purposes, such as improving their chatbots.\nRandi Weingarten, president of the American Federation of Teachers, which has more than 1.7 million members, \nsaid her union was working with Congress on regulation to help ensure that A.I. tools were fair and safe.\n“Educators use education technology every day, and they want more say over how the tech is deployed in \nclassrooms,” Ms. Weingarten said. “The goal here is to promote the potential of A.I. and guard against the serious \nrisks.”\nThis is hardly the first time that education reformers have championed automated teaching tools. In the 1960s, \nproponents predicted that mechanical and electronic devices called “teaching machines” — which were \nprogrammed to ask students questions on topics like spelling or math — would revolutionize education.\nPopular Mechanics captured the zeitgeist in an article in October 1961 headlined: “Will Robots Teach Your \nChildren?” It described “a rash of experimental machine teaching” sweeping schools across the United States in \nwhich students worked independently, inputting answers into the devices at their own pace.\nWill Chatbots Teach Your Children?\nThe article also warned that the newfangled machines raised some “profound” questions for educators and children. \nWould the teacher, the article asked, become “simply a glorified babysitter”? And: “What does machine teaching do \nto critical thinking on the part of the students?”\nCumbersome and didactic, the teaching machines turned out to be a short-term classroom sensation, both \noverhyped and over-feared. The rollout of new A.I. teaching bots has followed a similar narrative of potential \neducation transformation and harm.\nUnlike the old 20th-century teaching machines, however, A.I. chatbots seem improvisational. They generate instant \nresponses to individual students in conversational language. That means they can be fun, compelling and \nengaging.\nSome enthusiasts envision A.I. tutoring bots becoming study buddies that students could quietly consult without \nembarrassment. If schools broadly adopted such tools, they could deeply alter how children learn.\nThat has inspired some former Big Tech executives to move into education. Jerome Pesenti, a former vice \npresident of A.I. at Meta, recently founded a tutoring service called Sizzle A.I. The app’s A.I. chatbot uses a \nmultiple-choice format to help students solve math and science questions.\nAnd Jared Grusd, a former chief strategy officer at social media company Snap, co-founded a writing start-up called \nEthiqly. The app’s A.I. chatbot can help students organize and structure essays as well as give them feedback on \ntheir writing.\nMr. Khan is one of the most visible proponents of tutoring bots. Khan Academy introduced an A.I. chatbot named \nKhanmigo last year specifically for school use. It is designed to help students think through problems in math and \nother subjects — not do their schoolwork for them.\nThe system also stores conversations that students have with Khanmigo so that teachers may review them. And \nthe site clearly warns users: “Khanmigo makes mistakes sometimes.” Schools in Indiana, New Jersey and other \nstates are now pilot-testing the chatbot tutor.\nMr. Khan’s vision for tutoring bots can be traced back in part to popular science fiction books like “The Diamond \nAge,” a cyberpunk novel by Neal Stephenson. In that novel, an imaginary tablet-like device is able to teach a young \norphan exactly what she needs to know at exactly the right moment — in part because it can instantly analyze her \nvoice, facial expression and surroundings.\nMr. Khan predicted that within five years or so, tutoring bots like Khanmigo would be able to do something similar, \nwith privacy and safety guardrails in place.\n“The A.I. is just going to be able to look at the student’s facial expression and say: ‘Hey, I think you’re a little \ndistracted right now. Let’s get focused on this,’” Mr. Khan said.\nPHOTOS: Sal Khan, the chief executive of Khan Academy, predicted last year that A.I. tutoring bots would soon \nrevolutionize education. Big Tech executives have similar visions. (B1); Khan Lab School in Mountain View, Calif. \nKhan Academy introduced a chatbot named Khanmigo last year. (PHOTOGRAPHS BY MIKE KAI CHEN FOR THE \nNEW YORK TIMES) (B4) This article appeared in print on page B1, B4.\nLoad-Date: January 17, 2024"
    },
    {
        "file_name": "ChatGPT_Apr2023",
        "header": "OpenAI CEO Sam Altman Visits Japan As Its Government Embraces",
        "media": "ChatGPT",
        "time": "April 12, 2023",
        "section": "",
        "length": "626 words",
        "byline": "Sissi Cao",
        "story_text": "OpenAI CEO Sam Altman Visits Japan As Its Government Embraces \nChatGPT\nNew York Observer\nApril 10, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 626 words\nByline: Sissi Cao\nBody\nOpenAI CEO Sam Altman picked Japan as the destination of his first overseas trip since the debut of ChatGPT. \nThe 37-year-old entrepreneur met with Japan's Prime Minister Fumio Kishida in Tokyo today (April 10) and \nannounced plans to open a new office in the country, whose government shows an unusual interest in adopting \nartificial intelligence technology while many Western nations look to restrict it.\n\"We hope to spend much more time (in Japan) and hope to engage with the wonderful talent and build something \ngreat for Japanese people and make the models better,\" Altman told reporters today after his meeting with Prime \nMinister Kishida, the Japan Times reported.\nThe same day, Japan's Chief Cabinet Secretary Hirokazu Matsuno said the Japanese government will consider \nadoption of A.I. technology, including ChatGPT, if privacy and cybersecurity concerns are resolved.\n\"We will make all necessary considerations on ways to deal with confidential information and concerns about \ninformation leaks,\" said Matsuno, Japan's top government spokesperson. \"Once those concerns are resolved, we \nwill look into using AI to reduce the workload of national public servants.\"\nCountries react differently to the sudden rise of ChatGPT\nJapan's stance on ChatGPT stands in contrast to Italy's recent move to ban the A.I. chatbot in the country over data \nprivacy concerns.\nLast week, the Italian Data Protection Watchdog, known as Garante, ordered OpenAI to pause processing Italian \nusers' data amid a probe into a suspected breach of Europe's privacy regulations.\nThe ban inspired other Western countries to come up with their own measures on A.I. technology. Ireland is \nconsidering a similar ban on ChatGPT. Germany is looking to limit access to the chatbot in the country. The U.K. \nlast week announced plans for regulating A.I. using existing laws, noting that risks and opportunities surrounding \ngenerative A.I. are \"emerging at an extraordinary pace,\" Britain's Digital Minister Michelle Donelan said in a speech \nto Parliament on April 5.\nIn February, the European Union proposed a new piece of legislation on A.I. called the European A.I. Act. The law \nwill heavily restrict the use of A.I. in critical infrastructure, education, law enforcement and the judicial system.\nThe U.S. hasn't yet proposed any formal rules to bring oversight to A.I. technology.\nAsked to comment on Italy's recent ChatGPT ban at a news conference today, Matsuno, Japan's Chief Cabinet \nSecretary, said Japan is aware of other countries' actions.\nJapan is an early adopter of A.I.\nOpenAI CEO Sam Altman Visits Japan As Its Government Embraces ChatGPT\nOpenAI's ChatGPT made its debut in Japan's parliament on March 29. During a demo, Kazuma Nakatan, a \nmember of parliament, challenged Prime Minister Kishida with a ChatGPT-generated question related to the Covid-\n19 pandemic policy and later displayed an answer to the question also generated by the chatbot. After comparing \nthe two, Kishida lightheartedly insisted his answer was better.\n\"Japan is certainly one of the centers of the world, first with image generation and now with ChatGPT,\" Altman said \nin Tokyo today. He claims there are more than a million daily users of ChatGPT in Japan.\nAltman added that during his meeting with Prime Minister Kishida, they discussed \"the upsides of this technology \nand how to mitigate the downsides.\"\nDespite the government's welcoming stance, ChatGPT has been met with some resistance in Japan's public \nsphere. Several universities in the country have implemented rules that prohibit the use of ChatGPT in writing \nessays and reports.\nAt a news conference last week, government spokesperson Matsuno said Japan's education ministry will draft \nguidelines on the use of ChatGPT in schools amid fears that excessive use of the software might damage the \nlearning environment for students.\nLoad-Date: April 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "Can We No Longer Believe Anything We See?",
        "media": "The New York Times",
        "time": "April 11, 2023",
        "section": "BUSINESS; media",
        "length": "1762 words",
        "byline": "Tiffany Hsu and Steven Lee Myers",
        "story_text": "Can We No Longer Believe Anything We See?\nThe New York Times \nApril 8, 2023 Saturday 18:54 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 1762 words\nByline: Tiffany Hsu and Steven Lee Myers\nHighlight: Human eyes — and even technology — often struggle to identify images created by artificial intelligence. \nExperts fear that may hasten an erosion of trust in media, in government and in society.\nBody\nCan We No Longer Believe Anything We See?\nSeeing has not been believing for a very long time. Photos have been faked and manipulated for nearly as long as \nphotography has existed.\nNow, not even reality is required for photographs to look authentic — just artificial intelligence responding to a \nprompt. Even experts sometimes struggle to tell if one is real or not. Can you?\nThe rapid advent of artificial intelligence has set off alarms that the technology used to trick people is advancing far \nfaster than the technology that can identify the tricks. Tech companies, researchers, photo agencies and news \norganizations are scrambling to catch up, trying to establish standards for content provenance and ownership.\nThe advancements are already fueling disinformation and being used to stoke political divisions. Authoritarian \ngovernments have created seemingly realistic news broadcasters to advance their political goals. Last month, some \npeople fell for images showing Pope Francis donning a puffy Balenciaga jacket and an earthquake devastating the \nPacific Northwest, even though neither of those events had occurred. The images had been created using \nMidjourney, a popular image generator.\nOn Tuesday, as former President Donald J. Trump turned himself in at the Manhattan district attorney’s office to \nface criminal charges, images generated by artificial intelligence appeared on Reddit showing the actor Bill Murray \nas president in the White House. Another image showing Mr. Trump marching in front of a large crowd with \nAmerican flags in the background was quickly reshared on Twitter without the disclosure that had accompanied the \noriginal post, noting it was not actually a photograph.\nExperts fear the technology could hasten an erosion of trust in media, in government and in society. If any image \ncan be manufactured — and manipulated — how can we believe anything we see?\n“The tools are going to get better, they’re going to get cheaper, and there will come a day when nothing you see on \nthe internet can be believed,” said Wasim Khaled, chief executive of Blackbird.AI, a company that helps clients fight \ndisinformation.\nArtificial intelligence allows virtually anyone to create complex artworks, like those now on exhibit at the Gagosian \nart gallery in New York, or lifelike images that blur the line between what is real and what is fiction. Plug in a text \ndescription, and the technology can produce a related image — no special skills required.\nCan We No Longer Believe Anything We See?\nOften, there are hints that viral images were created by a computer rather than captured in real life: The luxuriously \ncoated pope had glasses that seemed to melt into his cheek and blurry fingers, for example. A.I. art tools also often \nproduce nonsensical text. Here are some examples:\nRapid advancements in the technology, however, are eliminating many of those flaws. Midjourney’s latest version, \nreleased last month, is able to depict realistic hands, a feat that had, conspicuously, eluded early imaging tools.\nDays before Mr. Trump turned himself in to face criminal charges in New York City, images made of his “arrest” \ncoursed around social media.They were created by Eliot Higgins, a British journalist and founder of Bellingcat, an \nopen source investigative organization. He used Midjourney to imagine the former president’s arrest, trial, \nimprisonment in an orange jumpsuit and escape through a sewer. He posted the images on Twitter, clearly marking \nthem as creations. They have since been widely shared.\nThe images weren’t meant to fool anyone. Instead, Mr. Higgins wanted to draw attention to the tool’s power — even \nin its infancy.\nMidjourney’s images, he said, were able to pass muster in facial-recognition programs that Bellingcat uses to verify \nidentities, typically of Russians who have committed crimes or other abuses. It’s not hard to imagine governments \nor other nefarious actors manufacturing images to harass or discredit their enemies.\nAt the same time, Mr. Higgins said, the tool also struggled to create convincing images with people who are not as \nwidely photographed as Mr. Trump, such as the new British prime minister, Rishi Sunak, or the comedian Harry Hill, \n“who probably isn’t known outside of the U.K. that much.”\nMidjourney was not amused in any case. It suspended Mr. Higgins’s account without explanation after the images \nspread. The company did not respond to requests for comment.\nThe limits of generative images make them relatively easy to detect by news organizations or others attuned to the \nrisk — at least for now.\nStill, stock photo companies, government regulators and a music industry trade group have moved to protect their \ncontent from unauthorized use, but technology’s powerful ability to mimic and adapt is complicating those efforts.\nSome A.I. image generators have even reproduced images — a queasy “Twin Peaks” homage; Will Smith eating \nfistfuls of pasta — with distorted versions of the watermarks used by companies like Getty Images or Shutterstock.\nIn February, Getty accused Stability AI of illegally copying more than 12 million Getty photos, along with captions \nand metadata, to train the software behind its Stable Diffusion tool. In its lawsuit, Getty argued that Stable Diffusion \ndiluted the value of the Getty watermark by incorporating it into images that ranged “from the bizarre to the \ngrotesque.”\nGetty said the “brazen theft and freeriding” was conducted “on a staggering scale.” Stability AI did not respond to a \nrequest for comment.\nGetty’s lawsuit reflects concerns raised by many individual artists — that A.I. companies are becoming a \ncompetitive threat by copying content they do not have permission to use.\nTrademark violations have also become a concern: Artificially generated images have replicated NBC’s peacock \nlogo, though with unintelligible letters, and shown Coca-Cola’s familiar curvy logo with extra O’s looped into the \nname.\nIn February, the U.S. Copyright Office weighed in on artificially generated images when it evaluated the case of \n“Zarya of the Dawn,” an 18-page comic book written by Kristina Kashtanova with art generated by Midjourney. The \ngovernment administrator decided to offer copyright protection to the comic book’s text, but not to its art.\nCan We No Longer Believe Anything We See?\n“Because of the significant distance between what a user may direct Midjourney to create and the visual material \nMidjourney actually produces, Midjourney users lack sufficient control over generated images to be treated as the \n‘master mind’ behind them,” the office explained in its decision.\nThe threat to photographers is fast outpacing the development of legal protections, said Mickey H. Osterreicher, \ngeneral counsel for the National Press Photographers Association. Newsrooms will increasingly struggle to \nauthenticate content. Social media users are ignoring labels that clearly identify images as artificially generated, \nchoosing to believe they are real photographs, he said.\nGenerative A.I. could also make fake videos easier to produce. This week, a video appeared online that seemed to \nshow Nina Schick, an author and a generative A.I. expert, explaining how the technology was creating “a world \nwhere shadows are mistaken for the real thing.” Ms. Schick’s face then glitched as the camera pulled back, showing \na body double in her place.\nThe video explained that the deepfake had been created, with Ms. Schick’s consent, by the Dutch company \nRevel.ai and Truepic, a California company that is exploring broader digital content verification.\nThe companies described their video, which features a stamp identifying it as computer-generated, as the “first \ndigitally transparent deepfake.” The data is cryptographically sealed into the file; tampering with the image breaks \nthe digital signature and prevents the credentials from appearing when using trusted software.\nThe companies hope the badge, which will come with a fee for commercial clients, will be adopted by other content \ncreators to help create a standard of trust involving A.I. images.\n“The scale of this problem is going to accelerate so rapidly that it’s going to drive consumer education very quickly,” \nsaid Jeff McGregor, chief executive of Truepic.\nTruepic is part of the Coalition for Content Provenance and Authenticity, a project set up through an alliance with \ncompanies such as Adobe, Intel and Microsoft to better trace the origins of digital media. The chip-maker Nvidia \nsaid last month that it was working with Getty to help train “responsible” A.I. models using Getty’s licensed content, \nwith royalties paid to artists.\nOn the same day, Adobe unveiled its own image-generating product, Firefly, which will be trained using only images \nthat were licensed or from its own stock or no longer under copyright. Dana Rao, the company’s chief trust officer, \nsaid on its website that the tool would automatically add content credentials — “like a nutrition label for imaging” — \nthat identified how an image had been made. Adobe said it also planned to compensate contributors.\nLast month, the model Chrissy Teigen wrote on Twitter that she had been hoodwinked by the pope’s puffy jacket, \nadding that “no way am I surviving the future of technology.”\nLast week, a series of new A.I. images showed the pope, back in his usual robe, enjoying a tall glass of beer. The \nhands appeared mostly normal — save for the wedding band on the pontiff’s ring finger.\nAdditional production by Jeanne Noonan DelMundo, Aaron Krolik and Michael Andre.\nAdditional production by Jeanne Noonan DelMundo, Aaron Krolik and Michael Andre. \nPHOTOS: An A.I.-generated image of a staged moon landing appears convincing enough at first glance, but closer \ninspection finds inhuman anomalies — indistinct or smudged faces, for example — in this early generation of the \ntechnology. However, improvements to the generative technology are already coming fast. (PHOTOGRAPHS BY \nA.I.: JORDAN RHONE); An A.I.-generated image of the former British prime minister Boris Johnson dancing in the \nstreet contains a telltale A.I. anomaly: strange hands and fingers. But the latest version of Midjourney, a popular \nimage generator, can depict realistic hands, a feat that had eluded early imaging tools. (PHOTOGRAPH BY A.I.); In \na lawsuit, Getty Images argued that Stability AI illegally copied more than 12 million Getty photographs, like that at \nleft, to train its Stable Diffusion tool, and that it diluted the value of the Getty watermark by incorporating it into \nCan We No Longer Believe Anything We See?\nimages that ranged “from the bizarre to the grotesque,” like that at right. (PHOTOGRAPHS BY ANDREW \nPOWELL/LIVERPOOL FC, VIA GETTY IMAGES; A.I.) (B5) This article appeared in print on page B1, B5.\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Fake Images? DeSantis Goes After Trump.",
        "media": "The New York Times",
        "time": "June 9, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "812 words",
        "byline": "By Nicholas Nehamas",
        "story_text": "Fake Images? DeSantis Goes After Trump.\nThe New York Times\nJune 9, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 812 words\nByline: By Nicholas Nehamas\nBody\nThe images, which at first glance appear genuine and are interspersed with real photographs in a campaign video, \npurport to show Donald Trump hugging and kissing Dr. Anthony Fauci.\nAs Gov. Ron DeSantis of Florida begins to aggressively attack former President Donald J. Trump, his campaign \nhas spread three images of the former president embracing Dr. Anthony S. Fauci that forensic experts say are \nalmost certainly realistic-looking ''deepfakes'' generated by artificial intelligence. \n  The images -- which at first glance appear genuine and are interspersed with real photographs in a campaign \nvideo -- show Mr. Trump hugging and kissing Dr. Fauci, who led the nation's pandemic response and has been a \ntarget of harsh criticism from Mr. DeSantis. The governor has used the pandemic to contrast himself with his main \nrival for the Republican presidential nomination.\n  A Twitter account run by Mr. DeSantis's campaign posted the images, part of a video attacking Mr. Trump, on \nMonday. The news agency Agence France-Presse first reported that they appeared fake on Wednesday.\n  The governor's campaign did not respond to a request for comment.\n  Mr. Trump's Republican allies criticized the DeSantis campaign on Thursday. Senator J.D. Vance of Ohio wrote on \nTwitter: ''Smearing Donald Trump with fake AI images is completely unacceptable.'' Representative Marjorie Taylor \nGreen of Georgia agreed, saying: ''Those fake AI campaign ads need to be taken down immediately.''\n  In turn, Mr. DeSantis's camp suggested the images were obviously fake, comparing them to memes circulated by \nMr. Trump and his allies. But those images -- which included a video of Mr. DeSantis in a woman's suit adapted \nfrom ''The Office'' and a ''recording'' of a conversation between Mr. DeSantis, Adolf Hitler and the Devil -- were \nclearly intended to be humorous and easy to discern as doctored.\n  On Twitter, Christina Pushaw, the DeSantis campaign's rapid response director, shared a fake photograph of Mr. \nDeSantis riding a rhinoceros (a reference to accusations that he is a ''Republican in Name Only,'' or RINO), writing: \n''I think this might be an AI-generated image. Who knows?'' The image, which appeared to be photoshopped, had \nearlier been posted by Mr. Trump on his Truth Social website.\n  As the 2024 campaign heats up, the use of such deepfakes has been of urgent concern to those who study \nmanipulated images, which thanks to new technology are easier to generate than ever before. While Americans \nhave grown far more skeptical of reports in the print, digital and broadcast news media, experts said, they have \nbeen more likely to trust videos and images that they could examine with their own eyes. The advent of deepfakes \ncould change that.\nFake Images? DeSantis Goes After Trump.\n  ''This is the big information security problem of the 21st century,'' said Matthew Stamm, an associate professor of \nelectrical and computer engineering at Drexel University who reviewed the images of Mr. Trump and Dr. Fauci and \nstrongly doubted their authenticity.\n  After President Biden announced he would seek re-election, the Republican National Committee released a video \nwith A.I.-generated images, including of China invading Taiwan, claiming to depict a potential future if he were to \nwin again in 2024. Unlike Mr. DeSantis's video, the R.N.C. ad acknowledged, in small white characters at the top \nleft of the screen, that it had been ''built entirely with A.I. imagery.''\n  Hany Farid, a professor at the University of California, Berkeley, said the use of such tactics would only increase.\n  ''We will continue to see campaigns, state-sponsored actors, trolls and people who want to sow chaos use these \nfake images to drive their own agendas,'' said Mr. Farid, who also concluded that the images posted by the \nDeSantis campaign were most likely fake.\n  While he described the three images as ''pretty clumsily done'' -- pointing to flaws in Mr. Trump's hair and ear, as \nwell as nonsensical lettering in what appeared to be a White House seal and an American flag with a bizarre pattern \nof stars -- he said generative artificial intelligence was quickly growing more sophisticated. For instance, he said, \nthe technology had already adapted to produce more authentic-looking hands, an early flaw in its realism.\n  ''These are well-known signs that an A.I.-based synthetic image generator was likely used to create these \nimages,'' said Mr. Farid, who added that some experts were beginning to systemically review campaign materials \nfor signs they contain deepfakes.\n  He said politicians would now have a ready-made excuse when genuine representations of their actions -- such as \nMr. Trump's infamous ''Access Hollywood'' tape -- appear in public.\n  ''They have plausible deniability,'' Mr. Farid said. ''They can say it's fake.''\n  Jonathan Swan and Shane Goldmacher contributed reporting.Jonathan Swan and Shane Goldmacher contributed \nreporting.\nhttps://www.nytimes.com/2023/06/08/us/politics/desantis-deepfakes-trump-fauci.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: June 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Hollywood Directors Ratify Their Contract as Writers Continue to Strike",
        "media": "The New York Times",
        "time": "June 23, 2023",
        "section": "BUSINESS; media",
        "length": "506 words",
        "byline": "Brooks Barnes",
        "story_text": "Hollywood Directors Ratify Their Contract as Writers Continue to Strike\nThe New York Times \nJune 23, 2023 Friday 22:34 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 506 words\nByline: Brooks Barnes\nHighlight: The vote prevented the doomsday scenario of three major Hollywood unions striking simultaneously. \nThe actors’ union is still negotiating.\nBody\nThe vote prevented the doomsday scenario of three major Hollywood unions striking simultaneously. The actors’ \nunion is still negotiating.\nUnionized movie and television directors approved a new three-year contract with Hollywood studios on Friday, with \n87 percent voting in support.\nThe Directors Guild of America, which has 16,321 eligible voters, announced the results, saying that there was \nrecord turnout and that the contract included “gains on wages, global streaming residuals, safety, diversity and \ncreative rights.”\nThe ratification formally prevents the doomsday scenario of three major Hollywood unions striking simultaneously. \nMore than 11,000 screenwriters have been walking picket lines for eight weeks, bringing many productions to a \nhalt. No talks are scheduled between the Writers Guild of America and the Alliance of Motion Picture and Television \nProducers, which bargains on behalf of studios. The writers and studios left the bargaining table on May 1 very far \napart on the major issues.\nThe contract between studios and SAG-AFTRA, the guild that represents about 160,000 actors, expires next \nFriday. The alliance and the actors’ union began negotiating a new contract on June 7. It is unclear how those talks \nare going; the two sides agreed to a media blackout. The actors voted to authorize a strike before negotiations \nstarted. (About 65,000 members cast ballots, or 48 percent of eligible voters, with 98 percent supporting a strike.)\n“The D.G.A. didn’t bargain in a vacuum,” Lesli Linka Glatter, the guild’s president, said in a statement. “We stand \nunited with writers, actors and all crew members in our shared fight to move our industry forward.”\nSome of the directors’ priorities echoed those of actors and writers, including wages, streaming residuals and \nconcerns about artificial intelligence. Writers Guild leaders had said that the studios offered little more than “annual \nmeetings to discuss” artificial intelligence, and that they refused to bargain over guardrails. The Directors Guild said \nit had received a “groundbreaking agreement confirming that A.I. is not a person and that generative A.I. cannot \nreplace the duties performed by members.”\nSome of the writers’ demands, however, are more complex than those of the directors. Writers Guild leaders have \ndescribed their dispute in urgent terms, calling this moment “existential” and saying the studios “are seemingly \nintent on continuing their efforts to destroy the profession of writing.”\nHollywood Directors Ratify Their Contract as Writers Continue to Strike\nWriters Guild leaders called the deal that studios struck with directors part of a “playbook” to “divide and conquer,” \nand they vowed to fight on. On Wednesday, a “W.G.A. Strong” rally in central Los Angeles attracted an estimated \n5,000 people, including members of SAG-AFTRA, the Directors Guild and other entertainment unions.\nPHOTO: Some of the directors’ priorities echoed those of actors and writers, including wages, streaming residuals \nand concerns about artificial intelligence. (PHOTOGRAPH BY Etienne Laurent/EPA, via Shutterstock FOR THE \nNEW YORK TIMES)\nLoad-Date: June 23, 2023"
    },
    {
        "file_name": "New_York_Observer_Jun2023",
        "header": "McKinsey's A.I. Chief Discusses ChatGPT's Impact on Consulting Jobs",
        "media": "New York Observer",
        "time": "June 8, 2023",
        "section": "",
        "length": "531 words",
        "byline": "Sissi Cao",
        "story_text": "McKinsey's A.I. Chief Discusses ChatGPT's Impact on Consulting Jobs\nNew York Observer\nJune 7, 2023 Wednesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 531 words\nByline: Sissi Cao\nBody\nArtificial intelligence is taking human jobs. Just last month, A.I. eliminated about 4,000 jobs in the U.S., according to \na June 1 report by Challenger, Gray & Christmas. As the generative A.I. phenomenon spreads, it is only a matter \nof time before the technology replaces management consultants, the archetypal white-collar job of data analysis, \ninformation summarizing and PowerPoint-making. The things that A.I. tools like ChatGPT can do.\nLarge consulting firms are embracing the technology and adjusting their expectations for talent in the post-ChatGPT \nera. At McKinsey & Company, one of the world's largest management consulting firms, about half of its 30,000 \nemployees now use ChatGPT or similar tools in their work, said Ben Ellencweig, a senior partner at McKinsey, at a \ncompany event yesterday (June 6) in New York.\nGenerative A.I. is drastically changing the day-to-day activities of management consultants, especially at the entry-\nlevel. At McKinsey, a junior consultant's first day typically entails what the firm calls \"know,\" or reading pages and \npages of non-confidential information to learn about a certain industry or sector the firm serves.\n\"When I started at the firm, I'd spend an entire weekend just getting swamped reading document after document. \nNow A.I. models can synthesize the 10 key things you need to know within minutes. That's a major, major shift,\" \nAlex Singla, a senior partner at McKinsey and the global leader of QuantumBlack, the firm's A.I. consulting branch, \ntold Observer in an interview at yesterday's event. Singla has been with the firm since 2000. He currently oversees \nmore than 1,300 analytics experts across McKinsey under the QuantumBlack umbrella.\nSingla is vaguely worried skipping the time-consuming part of actually reading and digesting raw information may \neventually hinder one's ability to synthesize complex data, which he said is \"a skill people need to learn and a key \nstrength of management consultants.\" But there are many aspects of the job-at least at the senior level-that \ntechnology can't yet replace.\n\"When I think about how I spend my day, the vast majority of it is helping senior executives think strategically about \nwhat they want to accomplish and how to make it happen,\" Singla said. \"It involves a lot of bringing people along \nand thinking about customers. It's all these things around problem-solving, creativity and change management that \nyou won't get out of technology alone.\"\n\"For any business, technology is usually not the real challenge, it's the people component that slows things down,\" \nhe said. \"That's where I think management consulting still has a major role to play.\"\nKaty George, McKinsey's chief people officer, expects generative A.I. to change how consulting firms recruit talent \nin the future.\n\"It's become increasingly important for us to hire entry-level consultants who have digital acumen and comfort with \nanalytics,\" George told Observer in an interview yesterday, adding, \"not just old-school problem-solving analytics \nMcKinsey 's A.I. Chief Discusses ChatGPT's Impact on Consulting Jobs\nbut working with large data sets and data scientists.\" She said McKinsey hasn't added any A.I.-specific \nrequirements to its hiring programs yet but the changes could come soon.\nLoad-Date: June 8, 2023"
    },
    {
        "file_name": "New_York_Observer_May2023",
        "header": "LinkedIn Cofounder Reid Hoffman Launches a ChatGPT Rival",
        "media": "New York Observer",
        "time": "May 4, 2023",
        "section": "",
        "length": "378 words",
        "byline": "Sissi Cao",
        "story_text": "LinkedIn Cofounder Reid Hoffman Launches a ChatGPT Rival\nNew York Observer\nMay 2, 2023 Tuesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 378 words\nByline: Sissi Cao\nBody\nLinkedIn cofounder Reid Hoffman and Mustafa Suleyman, a founding researcher of Google's DeepMind lab, today \n(May 2) launched a ChatGPT-like text generator called Pi through their new startup, Inflection AI.\nHoffman and Suleyman join a crowded race with tech companies large and small to develop chatbot products \nbased on generative artificial intelligence, a term popularized by the viral success of OpenAI's ChatGPT late last \nyear.\nAt the Milken Global Conference in Beverly Hills, Calif. today, Hoffman said generative A.I. will ultimately benefit all \nindustries, especially those relying on knowledge and creativity. For writers, for example, tools like ChatGPT could \nbe used to generate first drafts and act as an \"amplifier\" that helps achieve the same quality work in less time, \nHoffman said.\nWhat makes Pi different from other text generators?\nPi is a chatbot powered by Inflection AI's in-house technology that prioritizes human conversations with a high level \nof emotional intelligence, the company said. It has a narrower use case than ChatGPT, Google's Bard or Microsoft's \nBing chatbot, but it's better than those apps at conducting conversations in a human-like way.\n\"It doesn't do lists, or coding, it doesn't do travel plans, it won't write your marketing strategy, or your essay for \nschool,\" Suleyman, who serves as CEO of Inflection, told the Financial Times. \"It's purely designed for relaxed, \nsupportive, informative conversation.\"\n\"With Pi, we set out to create a personal AI that is as flexible as it is powerful, so millions of people can use it to \nmake their lives more meaningful, more productive, and more fun,\" Hoffman, a cofounder of Inflection, said in a \nstatement today.\nPi has been beta-tested by a small group of users for a few months. Users can interact with the app on Inflection's \nwebsite or through Meta-owned platforms like WhatsApp, Facebook and Instagram.\nHoffman's venture capital firm Greylock incubated Inflection and led a $250 million investment in the startup. He \nresigned from the board of OpenAI in March to focus on his new A.I. ventures. He is still a board member of \nMicrosoft, which owns a large stake in OpenAI.\nInflection's team includes A.I. experts who previously worked at DeepMind, Google, OpenAI and Meta, the \ncompany said.\nLoad-Date: May 4, 2023\nLinkedIn Cofounder Reid Hoffman Launches a ChatGPT Rival"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "New Frontier in Travel Scams: Guidebooks Generated by A.I.",
        "media": "The New York Times",
        "time": "August 8, 2023",
        "section": "Section A; Column 0; National Desk; Pg. 1",
        "length": "2137 words",
        "byline": "By Seth Kugel and Stephen Hiltner",
        "story_text": "New Frontier in Travel Scams: Guidebooks Generated by A.I.\nThe New York Times\nAugust 8, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 1\nLength: 2137 words\nByline: By Seth Kugel and Stephen Hiltner\nBody\nIn March, as she planned for an upcoming trip to France, Amy Kolsky, an experienced international traveler who \nlives in Bucks County, Pa., visited Amazon.com and typed in a few search terms: travel, guidebook, France. Titles \nfrom a handful of trusted brands appeared near the top of the page: Rick Steves, Fodor's, Lonely Planet. Also \namong the top search results was the highly rated ''France Travel Guide,'' by Mike Steves, who, according to an \nAmazon author page, is a renowned travel writer. \n  ''I was immediately drawn by all the amazing reviews,'' said Ms. Kolsky, 53, referring to what she saw at that time: \nuniversal raves and more than 100 five-star ratings. The guide promised itineraries and recommendations from \nlocals. Its price tag -- $16.99, compared with $25.49 for Rick Steves's book on France -- also caught Ms. Kolsky's \nattention. She quickly ordered a paperback copy, printed by Amazon's on-demand service.\n  When it arrived, Ms. Kolsky was disappointed by its vague descriptions, repetitive text and lack of itineraries. ''It \nseemed like the guy just went on the internet, copied a whole bunch of information from Wikipedia and just pasted it \nin,'' she said. She returned it and left a scathing one-star review.\n  Though she didn't know it at the time, Ms. Kolsky had fallen victim to a new form of travel scam: shoddy \nguidebooks that appear to be compiled with the help of generative artificial intelligence, self-published and \nbolstered by sham reviews, that have proliferated in recent months on Amazon.\n  The books are the result of a swirling mix of modern tools: A.I. apps that can produce text and fake portraits; \nwebsites with a seemingly endless array of stock photos and graphics; self-publishing platforms -- like Amazon's \nKindle Direct Publishing -- with few guardrails against the use of A.I.; and the ability to solicit, purchase and post \nphony online reviews, which runs counter to Amazon's policies and may soon face increased regulation from the \nFederal Trade Commission.\n  The use of these tools in tandem has allowed the books to rise near the top of Amazon search results and \nsometimes garner Amazon endorsements such as ''#1 Travel Guide on Alaska.''\n  A recent Amazon search for the phrase ''Paris Travel Guide 2023,'' for example, yielded dozens of guides with that \nexact title. One, whose author is listed as Stuart Hartley, boasts, ungrammatically, that it is ''Everything you Need to \nKnow Before Plan a Trip to Paris.'' The book itself has no further information about the author or publisher. It also \nhas no photographs or maps, though many of its competitors have art and photography easily traceable to stock-\nphoto sites. More than 10 other guidebooks attributed to Stuart Hartley have appeared on Amazon in recent months \nthat rely on the same cookie-cutter design and use similar promotional language.\nNew Frontier in Travel Scams: Guidebooks Generated by A.I.\n  The Times also found similar books on a much broader range of topics, including cooking, programming, \ngardening, business, crafts, medicine, religion and mathematics, as well as self-help books and novels, among \nmany other categories.\n  Amazon declined to answer a series of detailed questions about the books. In a statement provided by email, \nLindsay Hamilton, a spokeswoman for the company, said that Amazon is constantly evaluating emerging \ntechnologies. ''All publishers in the store must adhere to our content guidelines,'' she wrote. ''We invest significant \ntime and resources to ensure our guidelines are followed and remove books that do not adhere to these \nguidelines.''\n  The Times ran 35 passages from the Mike Steves book through an artificial intelligence detector from \nOriginality.ai. The detector works by analyzing millions of records known to be created by A.I. and millions created \nby humans, and learning to recognize the differences between the two, explained Jonathan Gillham, the company's \nfounder.\n  The detector assigns a score of between 0 and 100, based on the percentage chance its machine-learning model \nbelieves the content was A.I.-generated. All 35 passages scored a perfect 100, meaning they were almost certainly \nproduced by A.I.\n  The company claims that the version of its detector used by The Times catches more than 99 percent of A.I. \npassages and mistakes human text for A.I. on just under 1.6 percent of tests.\n  The Times identified and tested 64 other comparably formatted guidebooks, most with at least 50 reviews on \nAmazon, and the results were strikingly similar. Of 190 paragraphs tested with Originality.ai, 166 scored 100, and \nonly 12 scored under 75. By comparison, the scores for passages from well-known travel brands like Rick Steves, \nFodor's, Frommer's and Lonely Planet were nearly all under 10, meaning there was next to no chance that they \nwere written by A.I. generators.\n  Amazon, A.I. and trusted travel brands\n  Although the rise of crowdsourcing on sites like Tripadvisor and Yelp, not to mention free online travel sites and \nblogs and tips from TikTok and Instagram influencers, has reduced the demand for print guidebooks and their e-\nbook versions, they are still big sellers. On a recent day in July, nine of the top 50 travel books on Amazon -- a \ncategory that includes fiction, nonfiction, memoirs and maps -- were European guidebooks from Rick Steves.\n  Mr. Steves, reached in Stockholm around midnight after a day of researching his series's Scandinavia guide, said \nhe had not heard of the Mike Steves book and did not appear concerned that generative A.I. posed a threat.\n  ''I just cannot imagine not doing it by wearing out shoes,'' said Mr. Steves, who had just visited a Viking-themed \nrestaurant and a medieval-themed competitor, and determined that the Viking one was far superior. ''You've got to \nbe over here talking to people and walking.''\n  Mr. Steves spends about 50 days a year on the road in Europe, he said, and members of his team spend another \n300 to update their approximately 20 guidebooks, as well as smaller spinoffs.\n  But Pauline Frommer, the editorial director of the Frommer's guidebook series and the author of a popular New \nYork guidebook, is worried that ''little bites'' from the faux guidebooks are affecting their sales. Ms. Frommer said \nshe spends three months a year testing restaurants and working on other annual updates for the book -- and \ngaining weight she is currently trying to work off.\n  ''And to think that some entity thinks they can just sweep the internet and put random crap down is incredibly \ndisheartening,'' she said.\n  Amazon has no rules forbidding content generated primarily by artificial intelligence, but the site does offer \nguidelines for book content, including titles, cover art and descriptions: ''Books for sale on Amazon should provide a \npositive customer experience. We do not allow descriptive content meant to mislead customers or that doesn't \nNew Frontier in Travel Scams: Guidebooks Generated by A.I.\naccurately represent the content of the book. We also do not allow content that's typically disappointing to \ncustomers.''\n  Mr. Gillham, the founder of Originality.ai, which is based in Ontario, said his clients are largely content producers \nseeking to suss out contributions that are written by artificial intelligence. ''In a world of A.I.-generated content,'' he \nsaid, ''the traceability from author to work is going to be an increasing need.''\n  Finding the real authors of these guidebooks can be impossible. There is no trace of the ''renowned travel writer'' \nMike Steves, for example, having published ''articles in various travel magazines and websites,'' as the biography \non Amazon claims. In fact, The Times could find no record of any such writer's existence, despite conducting an \nextensive public records search. (Both the author photo and the biography for Mike Steves were very likely \ngenerated by A.I., The Times found.)\n  Mr. Gillham stressed the importance of accountability. Buying a disappointing guidebook is a waste of money, he \nsaid. But buying a guidebook that encourages readers to travel to unsafe places -- ''that's dangerous and \nproblematic,'' he said.\n  The Times found several instances where troubling omissions and outdated information might lead travelers \nastray. A guidebook on Moscow published in July under the name Rebecca R. Lim -- ''a respected figure in the \ntravel industry'' whose Amazon author photo also appears on a website called Todo Sobre el Acido Hialurónico (''All \nAbout Hyaluronic Acid'') alongside the name Ana Burguillos -- makes no mention of Russia's ongoing war with \nUkraine and includes no up-to-date safety information. (The U.S. Department of State advises Americans not to \ntravel to Russia.) And a guidebook on Lviv, Ukraine, published in May, also fails to mention the war and encourages \nreaders to ''pack your bags and get ready for an unforgettable adventure in one of Eastern Europe's most \ncaptivating destinations.''\n  Sham reviews\n  Amazon has an anti-manipulation policy for customer reviews, though a careful examination by The Times found \nthat many of the five-star reviews left on the shoddy guidebooks were either extremely general or nonsensical. The \nbrowser extension Fakespot, which detects what it considers ''deceptive'' reviews and gives each product a grade \nfrom A to F, gave many of the guidebooks a score of D or F.\n  Some reviews are curiously inaccurate. ''This guide has been spectacular,'' wrote a user named Muñeca about \nMike Steves's France guide. ''Being able to choose the season to know what climate we like best, knowing that their \nlanguage is English.'' (The guide barely mentions the weather and clearly states that the language of France is \nFrench.)\n  Most of the questionably written rave reviews for the threadbare guides are from ''verified purchases,'' though \nAmazon's definition of a ''verified purchase'' can include readers who downloaded the book for free.\n  ''These reviews are making people dupes,'' said Ms. Frommer. ''It's what makes people waste their money and \nkeeps them away from real travel guides.''\n  Ms. Hamilton, the Amazon spokeswoman, wrote that the company has no tolerance for fake reviews. ''We have \nclear policies that prohibit reviews abuse. We suspend, ban, and take legal action against those who violate these \npolicies and remove inauthentic reviews.'' Amazon would not say whether any specific action has been taken \nagainst the producers of the Mike Steves book and other similar books. During the reporting of this article, some of \nthe suspicious reviews were removed from many of the books The Times examined, and a few books were taken \ndown. Amazon said it blocked more than 200 million suspected fake reviews in 2022.\n  But even when Amazon does remove reviews, it can leave five-star ratings with no text. As of Aug. 3, Adam Neal's \n''Spain Travel Guide 2023'' had 217 reviews removed by Amazon, according to a Fakespot analysis, but still \ngarners a 4.4 star rating, in large part because 24 of 27 reviewers who omitted a written review awarded the book \nNew Frontier in Travel Scams: Guidebooks Generated by A.I.\nfive stars. ''I feel like my guide cannot be the same one that everyone is rating so high,'' wrote a reviewer named \nSarie, who gave the book one star.\n  Many of the books also include ''editorial reviews,'' seemingly without oversight from Amazon. Some are \nparticularly audacious, like Dreamscape Voyages' ''Paris Travel Guide 2023,'' which includes fake reviews from \nheavy hitters like Afar magazine (''Prepare to be amazed'') and Condé Nast Traveler (''Your ultimate companion to \nunlocking the true essence of the City of Lights''). Both publications denied reviewing the book.\n  'You've got to be there in the field'\n  Artificial intelligence experts generally agree that generative A.I. can be helpful to authors if used to enhance their \nown knowledge. Darby Rollins, the founder of the A.I. Author, a company that helps people and businesses \nleverage generative A.I. to improve their work flow and grow their businesses, found the guidebooks ''very basic.''\n  But he could imagine good guidebooks produced with the help of artificial intelligence. ''A.I. is going to augment \nand enhance and extend what you're already good at doing,'' he said. ''If you're already a good writer and you're \nalready an expert on travel in Europe, then you're bringing experiences, perspective and insights to the table. \nYou're going to be able to use A.I. to help organize your thoughts and to help you create things faster.''\n  The real Mr. Steves was less sure about the merits of using A.I. ''I don't know where A.I. is going, I just know what \nmakes a good guidebook,'' he said. ''And I think you've got to be there in the field to write one.''\n  Ms. Kolsky, who was scammed by the Mike Steves book, agreed. After returning her initial purchase, she opted \ninstead for a trusted brand.\n  ''I ended up buying Rick Steves,'' she said.\n  Design by Gabriel Gianordoli. Susan Beachy contributed research.Design by Gabriel Gianordoli. Susan Beachy \ncontributed research.\nhttps://www.nytimes.com/2023/08/05/travel/amazon-guidebooks-artificial-intelligence.html\nGraphic\n \nPHOTOS (A10\n A11) This article appeared in print on page A1, A10, A11.               \nLoad-Date: August 8, 2023"
    },
    {
        "file_name": "USA_Today_Online_May2024",
        "header": "How to use AI to plan your next vacation and what you should know first",
        "media": "USA Today Online",
        "time": "May 9, 2024",
        "section": "",
        "length": "1318 words",
        "byline": "Eve Chen, USA TODAY",
        "story_text": "How to use AI to plan your next vacation and what you should know first\nUSA Today Online\nMay 2, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nLength: 1318 words\nByline: Eve Chen, USA TODAY\nBody\nWhere should I go on vacation this summer\nThe question is simple enough, but the possibilities are endless.\n“Feeling adventurous or more like chilling by the beach with a drink in hand?” Layla replies to narrow the list.\nChilling by the beach sounds nice.\n“Alright, for that laid-back beach vibe, how about Santorini with its iconic sunsets or Ao Nang for some Thai beach \nbliss? Pick your paradise!” she suggested. \nOnly she is not really a “she.” Layla is an AI travel planner whose website launched this year, among a growing \nnumber of artificial intelligence-driven tools for travel. \nJust over 50% of 1,400 people recently surveyed by Matador Network, a travel publisher and creator of AI travel \nassistant GuideGeek, said they’re open to using AI for their summer travel. A previous Matador Network survey \nfound 64% of 1,200 travelers surveyed had already used or planned to use AI for trip planning.\nHere’s what travelers should know about planning trips with AI.\nHow common is AI today?\nMany people associate AI with large language models like ChatGPT, which can both recognize and generate text, \nbut that’s just one type of AI.\n“AI is generally everywhere,” said Yoon Kim, an assistant professor in MIT’s Electrical Engineering and Computer \nScience Department and Computer Science and Artificial Intelligence Laboratory. “For example, when you search \nfor something – let's say you search for something on TripAdvisor, Hotels.com – there is likely an AI-based system \nthat gives you a list of matches based on your query.”\n“Because a lot of the (online travel agencies) have now integrated different types of Gen AI into their platforms … \npeople may be using them without their knowledge,” echoed Matt Soderberg, principal, U.S. airlines leader for \nDeloitte, which named AI as a major theme in changing travel in its Facing travel's future report released in early \nApril.\nKayak and Expedia offer AI travel tools. Google has used AI for years for search. Those familiar “People Also Ask” \nquestions are powered by AI. Google Flights uses machine learning, a type of AI. AI also powers Google Maps’ \nImmersive View, which gives users a navigable fly-over view of 13 cities and more than 500 global landmarks that \nusers can zoom in on like in a video game, with weather and crowd forecasts for different times of day. \nHow to use AI to plan your next vacation and what you should know first\nEarly this year, Google introduced generative AI to multisearch queries made with Google Lens. That allows users \nto take a photo of something and couple it with text questions like “What kind of flower is this?” or “Who painted this \nand why?” to get AI-generated answers based on data from across the web and links to additional sources.\nHow do I plan a trip with AI?\nLink to Image\nPlanning travel with AI is typically free, but travelers may need to create platform-specific accounts to access \nenhanced features or ask more than a few initial queries.\nGoogle account holders can get generative AI results in text-only search bar searches if they opt in to Search \nGenerative Experience, which is part of Google’s experimental Search Labs. Opting in to SGE allows them to ask \nthings like “Plan me a 2-day solo trip to Grand Teton National Park” and not only get a suggested itinerary but \nrelated photos, reviews and links to other resources. \nFor Day 1 at Grand Teton, Google suggested a morning hike at Schwabacher Landing “to see the Grand Tetons \nreflected in the river,” an afternoon visit to U.S. Fish and Wildlife Service’s National Elk Refuge, and dinner at a \nlocal Italian restaurant with photos of each destination, links to their websites, pins showing locations on Google \nMaps, suggestions for where to stay, space for follow up questions, and links to related questions like “Is 2 days \nenough for Grand Teton National Park?” \nJust above the sample itinerary, read a disclaimer: “Generative AI is experimental” and below it: “Trip ideas \ngenerated with AI may include inaccurate or misleading information. Confirm info with sources you trust.” \nFor the same prompt, both ChatGPT and GuideGeek – which can be messaged on social media like a person – \noffered more suggestions of things to do, as well as reminders to check on trail closures, but no specific \nrecommendations on where to eat or stay, nor photos nor links to find more information on any of the destinations. \nLayla and Mindtrip, an AI travel planner that launched publicly this week, also included links to various points of \ninterest, hotel suggestions, and the ability to adjust and book different parts of the itinerary through partnerships \nwith third parties. Mindtrip allows multiple people within the same travel party to collaborate on itineraries.\nMake travel easy: We tested ChatGPT itineraries in 5 US tourist spots\nCan AI be trustworthy?\nLink to Image\nAsking one AI travel planner for the top 10 snacks at Walt Disney World’s Magic Kingdom, among classics like Dole \nWhip and Corn Dog Nuggets, it suggested Mickey-shaped beignets. Those would certainly be a top snack if they \nwere sold in the park, like at Disneyland. However Disney World guests have to go to Disney’s Port Orleans Resort \n- French Quarter for sweet Mickey-shaped pillows of fried dough.\n“This phenomena goes under the moniker hallucinations. These generative AI systems are prone to hallucinating \nplausible-sounding text that’s actually factually incorrect,” MIT’s Kim explained. “This is, I think, going to be sort of \nan inherent problem with systems that probabilistically generate output over large spaces.”\n\"If the LLM recommends a restaurant closed down two years ago, you lose all trust immediately,\" said Mindtrip \nFounder and CEO Andy Moss. That's why they, and Layla, also rely on human intelligence for recommendations. \nKim noted there are ongoing efforts to mitigate against hallucinations but suggested double-checking AI-generated \nanswers.\n“We want to make sure that that information is usable, that it's actionable. It's clear, it's repeatable,” said Will Healy, \nsenior vice president at Booz Allen Hamilton, the largest provider of AI to the federal government. He heads up the \nHow to use AI to plan your next vacation and what you should know first\ncompany’s recreation work, including Recreaton.gov, the government’s central travel planning site for public lands \nlike national parks. \nWhat can AI be used for?\nLink to Image\nCurrently, most Recreation.gov visitors use progressive search to discover and book things like campsites, \nchecking off boxes and reading information provided by the land manager. However, 25% of randomly selected \nusers are being offered more personalized AI-powered options as part of a beta test with AI.\n“What we're beta testing at the moment are things where you can say, ‘Hey, I've got three kids. This is our first time \ncamping. We want to go some place that's fun. My kids love the water. We want to try hiking, and my youngest son \nlikes fishing, but he's not very good at it,’” Healy said.\n“If you were talking to somebody who knew everything about every campsite, then what answer would they give \nyou? That's what we think artificial intelligence can do,” he added. “And it's not just the data that's in the system, but \nit's all of the reviews and blogs and everything's out there in the public domain that you can pull different pieces \ntogether, put together into a contextual answer.”\nIf AI is able to understand a traveler’s intent, Healy said it could also suggest alternative destinations or experiences \nif something a traveler wants is booked up or otherwise not available. He said it could also help make public lands \nmore accessible to more people.\n“If you have some sort of impairment – maybe it's sight, hearing, mobility, cognitive, whatever it is – that confidence \nlevel (outdoors) might go down, “Healy said. “We want to provide you the right information, so that you can get \noutside with as much confidence as possible and have an experience that matches your needs.”\nThis article originally appeared on USA TODAY: How to use AI to plan your next vacation and what you should \nknow first\nLoad-Date: May 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "New A.I. Technology Generates Blueprint To Edit Human DNA",
        "media": "The New York Times",
        "time": "April 23, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "1066 words",
        "byline": "By Cade Metz",
        "story_text": "New A.I. Technology Generates Blueprint To Edit Human DNA\nThe New York Times\nApril 23, 2024 Tuesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 1066 words\nByline: By Cade Metz\nBody\nGenerative A.I. technologies can write poetry and computer programs or create images of teddy bears and videos \nof cartoon characters that look like something from a Hollywood movie.\nNow, new A.I. technology is generating blueprints for microscopic biological mechanisms that can edit your DNA, \npointing to a future when scientists can battle illness and diseases with even greater precision and speed than they \ncan today. \n  Described in a research paper published on Monday by a Berkeley, Calif., startup called Profluent, the technology \nis based on the same methods that drive ChatGPT, the online chatbot that launched the A.I. boom after its release \nin 2022. The company is expected to present the paper next month at the annual meeting of the American Society \nof Gene and Cell Therapy.\n  Much as ChatGPT learns to generate language by analyzing Wikipedia articles, books and chat logs, Profluent's \ntechnology creates new gene editors after analyzing enormous amounts of biological data, including microscopic \nmechanisms that scientists already use to edit human DNA.\n  These gene editors are based on Nobel Prize-winning methods involving biological mechanisms called CRISPR. \nTechnology based on CRISPR is already changing how scientists study and fight illness and disease, providing a \nway of altering genes that cause hereditary conditions, such as sickle cell anemia and blindness.\n  Previously, CRISPR methods used mechanisms found in nature -- biological material gleaned from bacteria that \nallows these microscopic organisms to fight off germs.\n  ''They have never existed on Earth,'' said James Fraser, a professor and chair of the department of bioengineering \nand therapeutic sciences at the University of California, San Francisco, who has read Profluent's research paper. \n''The system has learned from nature to create them, but they are new.''\n  The hope is that the technology will eventually produce gene editors that are more nimble and more powerful than \nthose that have been honed over billions of years of evolution.\n  On Monday, Profluent also said that it had used one of these A.I.-generated gene editors to edit human DNA and \nthat it was ''open sourcing'' this editor, called OpenCRISPR-1. That means it is allowing individuals, academic labs \nand companies to experiment with the technology for free.\n  A.I. researchers often open source the underlying software that drives their A.I. systems, because it allows others \nto build on their work and accelerate the development of new technologies. But it is less common for biological labs \nand pharmaceutical companies to open source inventions like OpenCRISPR-1.\nNew A.I. Technology Generates Blueprint To Edit Human DNA\n  Though Profluent is open sourcing the gene editors generated by its A.I. technology, it is not open sourcing the \nA.I. technology itself.\n  The project is part of a wider effort to build A.I. technologies that can improve medical care. Scientists at the \nUniversity of Washington, for instance, are using the methods behind chatbots like OpenAI's ChatGPT and image \ngenerators like Midjourney to create entirely new proteins -- the microscopic molecules that drive all human life -- as \nthey work to accelerate the development of new vaccines and medicines.\n  (The New York Times has sued OpenAI and its partner, Microsoft, on claims of copyright infringement involving \nartificial intelligence systems that generate text.)\n  Generative A.I. technologies are driven by what scientists call a neural network, a mathematical system that \nlearns skills by analyzing vast amounts of data. The image creator Midjourney, for example, is underpinned by a \nneural network that has analyzed millions of digital images and the captions that describe each of those images. \nThe system learned to recognize the links between the images and the words. So when you ask it for an image of a \nrhinoceros leaping off the Golden Gate Bridge, it knows what to do.\n  Profluent's technology is driven by a similar A.I. model that learns from sequences of amino acids and nucleic \nacids -- the chemical compounds that define the microscopic biological mechanisms that scientists use to edit \ngenes. Essentially, it analyzes the behavior of CRISPR gene editors pulled from nature and learns how to generate \nentirely new gene editors.\n  ''These A.I. models learn from sequences -- whether those are sequences of characters or words or computer \ncode or amino acids,'' said Profluent's chief executive, Ali Madani, a researcher who previously worked in the A.I. \nlab at the software giant Salesforce.\n  Profluent has not yet put these synthetic gene editors through clinical trials, so it is not clear if they can match or \nexceed the performance of CRISPR. But this proof of concept shows that A.I. models can produce something \ncapable of editing the human genome.\n  Still, it is unlikely to affect health care in the short term. Fyodor Urnov, a gene editing pioneer and scientific director \nat the Innovative Genomics Institute at the University of California, Berkeley, said scientists had no shortage of \nnaturally occurring gene editors that they could use to fight illness and disease. The bottleneck, he said, is the cost \nof pushing these editors through preclinical studies, such as safety, manufacturing and regulatory reviews, before \nthey can be used on patients.\n  But generative A.I. systems often hold enormous potential because they tend to improve quickly as they learn \nfrom increasingly large amounts of data. If technology like Profluent's continues to improve, it could eventually allow \nscientists to edit genes in far more precise ways. The hope, Dr. Urnov said, is that this could, in the long term, lead \nto a world where medicines and treatments are quickly tailored to individual people even faster than we can do \ntoday.\n  ''I dream of a world where we have CRISPR on demand within weeks,'' he said. \n  Scientists have long cautioned against using CRISPR for human enhancement because it is a relatively new \ntechnology that could potentially have undesired side effects, such as triggering cancer, and have warned against \nunethical uses, such as genetically modifying human embryos.\n  This is also a concern with synthetic gene editors. But scientists already have access to everything they need to \nedit embryos.\n  ''A bad actor, someone who is unethical, is not worried about whether they use an A.I.-created editor or not,'' Dr. \nFraser said. ''They are just going to go ahead and use what's available.''\nhttps://www.nytimes.com/2024/04/22/technology/generative-ai-gene-editing-crispr.html\nNew A.I. Technology Generates Blueprint To Edit Human DNA\nGraphic\n \nPHOTOS: The physical structure of OpenCRISPR-1, a gene editor created by A.I. technology from Profluent, which \nsaid it was ''open sourcing'' the editor. (PHOTOGRAPH BY PROFLUENT BIO)\nAli Madani, center, chief executive of the Berkeley, Calif., start-up Profluent, with his team of scientists who worked \non the artificial intelligence research.\nMr. Madani at Profluent's lab in Berkeley. He previously worked in the A.I. lab at the software giant Salesforce. \n(PHOTOGRAPHS BY RACHEL BUJALSKI FOR THE NEW YORK TIMES)\n An image taken from a video showing a time-lapse of human cells edited by OpenCRISPR-1. (PHOTOGRAPH BY \n.JOSEPH GALLAGHER / PROFLUENT BIO) This article appeared in print on page B4.               \nLoad-Date: April 23, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Jul2023",
        "header": "Become the dream employer",
        "media": "The Baltimore Sun",
        "time": "July 9, 2023",
        "section": "MAIN; A; Pg. 8",
        "length": "938 words",
        "byline": "Kimberly Jones Fast Company",
        "story_text": "Become the dream employer\nThe Baltimore Sun\nJuly 9, 2023 Sunday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 8\nLength: 938 words\nByline: Kimberly Jones Fast Company\nBody\nThis year's college graduates are entering the workforce amid what's being called the generative AI gold rush.\nOrganizations are scrambling to take advantage of powerful AI technologies that are transforming work as we know \nit. \nThe possibilities are exciting-empowering professionals to work more efficiently and quickly grow in their careers-\nbut, the uncertainty of how work will look and feel can be daunting for those wanting to take the important first step \nof their careers.\nIn a world where jobs are undergoing significant changes, or even ceasing to exist due to advancing technology, \nhow can today's workforce prepare for their careers?\nA report recently issued by Goldman Sachs estimates that AI will partially automate two-thirds of professions and \ncan handle about a quarter of the work done by those affected professions. It's essentially redefining job roles and \ndaily tasks like research, analysis, software development, digital marketing, and so many more, and will continue to \ndo so as it advances.\nIts evolution is leaving job hunters to rethink not just their next role but the entire course of their prospective \ncareers. \nMy advice to those just starting out or stepping into a new career? Don't focus on just looking for a job. Focus on \nchoosing an employer who is purpose-driven, instead of filling a predefined role; they invest in the whole person.\nIt's no longer about landing a good job, but about joining an organization that is committed to helping their people \ndevelop and evolve. Organizations like this help their employees nurture their passions and potential to create more \nfulfilling lives, beyond work. They provide access to opportunities, resources, and tools that will help them become \neffective leaders and compelling change artists.\nIt's not as ambiguous an ask for employers as it may seem. Here are three ways to become an organization that \npaves the way to the future of work:\nBuild a holistic employee experience: As the confines of job roles fall to the wayside, the limelight shines on \nemployee well-being and the importance of supporting it. It means treating employees as valuable customers and \ngoing the distance to meet their needs at work and beyond.\nSupporting employees' entire well-being starts with understanding what motivates them. For many, it's a safe, \ninclusive environment, flexibility, and a greater sense of connection to the goals of the organization and its people. \nBecome the dream employer\nIt's also better benefits, including paid time off, childcare assistance, affordable healthcare-insurance options, \npaternity leave, and retirement plans, some of which enable individual employees to own part of the company they \nwork for, potentially through Employee Stock Ownership Plans (ESOPs).\nPersonalized learning and development, and access to career growth opportunities are also important to the \nemployee experience. In fact, more than one-third of those surveyed for Monster's 2023 State of the Graduate \nReport ranked immediate growth and advancement as the most important aspect of a prospective job. Also, 54% of \nthose surveyed shared that they would turn down a job offer if the employer didn't offer professional growth \nopportunities. Who can blame them?\nBuild best-in-class tech stacks: Prioritizing tech investments, including those related to advanced analytics and \nmachine learning solutions, is an effective way to provide professionals with room to grow. These tools arm people \nwith insights and enable them to make faster, data-driven decisions for their organizations. They also free them \nfrom the mundane aspects of their work and limit manual processes, enabling them to take on more challenging, \nrewarding projects.\nAccess to advanced tech tools and dedicated, ongoing training and support helps employees build their skill sets \nand increase their adaptability, so they can weather continual change, work beyond traditional departmental silos, \nand prepare for new roles within the organization and throughout their careers.\nCreate a culture of agility: Change is unavoidable, especially in a business climate riddled with economic \nuncertainty and also in the midst of technological evolution. Organizations can help their people embrace and adapt \nto changes as they occur by building a culture around adaptability.\nIt starts with more intentional hiring. Realize that roles are evolving and companies must hire people with the agility \nto evolve with them. Recruit professionals who can be trained for cross-functional roles and highly skilled \ntechnologists and software engineers who can provide the tools and training your organization needs to adapt. To \ncreate a culture that can withstand our VUCA (volatile, uncertain, chaotic, ambiguous) world, focus on talent that \nhas agility, as well as ambition, ability, and the right attitude.\nIt's also important to be intentional about promoting employees and proactively providing experiences and \nopportunities for staff members to increase their leadership potential and advance their careers. Without support \nand steady progression, top talent will quickly move on to opportunities elsewhere.\nThis year's college graduates are entering the job market at an incredibly exciting, yet challenging, time. While \ntechnology continues to evolve and redefine job roles, organizations have the unique opportunity to offer the \nsupport and clarity job seekers need to begin their career. It boils down to providing a meaningful employment \nexperience and access to the tools and resources professionals need to continually rise to meet new challenges \nand be set up for success today and for the future.\nKimberly Jones is president and CEO of Butler/Till.\nLoad-Date: July 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "It's a Hit. Is It Real or Is It A.I.?",
        "media": "The New York Times",
        "time": "April 22, 2023",
        "section": "Section C; Column 0; The Arts/Cultural Desk; Pg. 1",
        "length": "1427 words",
        "byline": "By Joe Coscarelli",
        "story_text": "It's a Hit. Is It Real or Is It A.I.?\nThe New York Times\nApril 22, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section C; Column 0; The Arts/Cultural Desk; Pg. 1\nLength: 1427 words\nByline: By Joe Coscarelli\nBody\nA track like ''Heart on My Sleeve,'' which went viral before being taken down by streaming services this week, may \nbe a novelty for now. But the legal and creative questions it raises are here to stay.\nFor Drake and the Weeknd, two of the most popular musicians on the planet, the existence of ''Heart on My \nSleeve,'' a track that claimed to use A.I. versions of their voices to create a passable mimicry, may have qualified as \na minor nuisance -- a short-lived novelty that was easily stamped out by their powerful record company. \n  But for others in the industry, the song -- which became a viral curio on social media, racking up millions of plays \nacross TikTok, Spotify, YouTube and more before it was removed this week -- represented something more \nserious: a harbinger of the headaches that can occur when a new technology crosses over into the mainstream \nconsciousness of creators and consumers before the necessary rules are in place.\n  ''Heart on My Sleeve'' was the latest and loudest example of a gray-area genre that has exploded in recent \nmonths: homemade tracks that use generative artificial intelligence technology, in part or in full, to conjure \nfamiliar sounds that can be passed off as authentic, or at least close enough. It earned instant comparisons to \nearlier technologies that disrupted the music industry, including the dawn of the synthesizer, the sampler and the \nfile-sharing service Napster.\n  Yet while A.I. Rihanna singing a Beyoncé song or A.I. Kanye West doing ''Hey There Delilah'' may seem like a \nharmless lark, the successful (if brief) arrival of ''Heart on My Sleeve'' on official streaming services, complete with \nshrewd online marketing from its anonymous creator, intensified alarms that were already ringing in the music \nbusiness, where corporations have grown concerned about A.I. models learning from, and then diluting, their \ncopyrighted material.\n  Universal Music Group, the largest of the major labels and home to both Drake and the Weeknd, had already \nflagged such content to its streaming partners this month, citing intellectual property concerns. But in a statement \nthis week, the company spoke to the broader stakes, asking ''which side of history all stakeholders in the music \necosystem want to be on: the side of artists, fans and human creative expression, or on the side of deep fakes, \nfraud and denying artists their due compensation.''\n  Artists and their labels are confident, at least for the time being, that the social and emotional component of \nfandom will separate the work of the real Drake from a fake one, even if an A.I. version can nod at his emotional \npreoccupations and musical tics.\nIt's a Hit. Is It Real or Is It A.I.?\n  But whether superstars could have their pockets picked, or become altogether obsolete in favor of machines that \ncan imitate them, is only one side of the equation. Royalty-free music generators can be used now to compose a \nrap beat, a commercial jingle or a film score, cutting into an already fragile economy for working musicians.\n  And as generative A.I. booms and rapidly improves across text, images, sound and video, experts say the \ntechnology could reshape creative industries at all levels, with fans, artists and the systems that govern them \nhaving to adjust to new norms on the fly.\n  ''It is now possible to produce infinite media in the style or likeness of someone else, soon with little effort, so we \nall have to come to terms with what that means,'' the musician Holly Herndon, who has studied and used A.I. in her \nwork for years, wrote in an email.\n  ''The question is, as a society, do we care what Drake really feels or is it enough to just hear a superficially \nintelligent rendering?'' she asked. ''For some people that will not be enough. However, when you consider that most \npeople listening to Spotify are doing so just to have something pleasant to listen to, it complicates things.''\n  The breakthrough success of ''Heart on My Sleeve,'' uploaded by a user called ghostwriter, has helped bring \nmusic to the forefront of a conversation that has intensified lately around other mediums, especially since the \nrelease of Open AI's ChatGPT language model and image generators like DALL-E. Commenting under the track on \nYouTube, ghostwriter promised, ''This is just the beginning.''\n  Courts and lawmakers are only beginning to sort out questions of ownership when it comes to A.I., and copyrights \nin music can be complicated as it is. For now, protected intellectual property can only be created by humans, but \nwhat about when musicians collaborate with the machines?\n  [Video:  Watch on YouTube.]\n  Martin Clancy, a musician and the chair of a global committee that seeks to explore the ethics of A.I. in the arts, \nsaid the music industry was more organized than some other fields grappling with the rise of A.I.\n  ''What's at stake are things we take for granted: listening to music made by humans, people doing that as a \nlivelihood and it being recognized as a special skill,'' he said.\n  It was unclear exactly which elements of ''Heart on My Sleeve'' -- the lyrics, the instrumental beat, the melody, the \nvocals -- were created by A.I. (Ghostwriter declined to comment.)\n  Some songs have been written by real people and recorded with real human vocals, before being replaced by A.I. \nimitations of brand-name artists using tools that had ''learned'' from existing music and produced a similar effect. \nThose could invite one form of legal challenge: Artists and photographers, for instance, have sued image \ngenerators for creating derivative versions of their work.\n  But a human creator passing off her own song as being performed by a famous artist, or promoting it commercially \nusing that singer's name or likeness, could lead to a different kind of legal threat. In the past, musicians including \nTom Waits and Bette Midler have successfully argued in court that they had a right to not just their musical \ncompositions or recordings, but their voices, in the face of sound-alike imitators in advertisements.\n  In this case, getting ''Heart on My Sleeve'' removed from services where it could have earned streaming royalties -\n- and even charted on Billboard -- may have been even simpler for Drake, the Weeknd and Universal Music. The \ntrack appeared to use a popular vocal snippet from the rapper Future that implied the song was produced by Metro \nBoomin, a sample of a master recording that was not cleared for use.\n  Drake, the Weeknd and Metro Boomin declined to comment. (Last week, in response to another track that used an \nA.I. Drake voice to perform Ice Spice's ''Munch,'' Drake wrote cheekily on Instagram, ''This is the final straw AI.'')\n  Aside from raising questions of legality, such technology can introduce knotty ethical concerns regarding race and \nidentity. Last year, Capitol Records apologized and dropped the digital rap avatar FN Meka after critics said the \nIt's a Hit. Is It Real or Is It A.I.?\nproject amounted to a form of blackface. Among the recent explosion of A.I. imitations, rap has emerged as the \nmost common playground.\n  ''It's another way for people who are not Black to put on the costume of a Black person -- to put their hands up \nKanye or Drake and make him a puppet -- and that is alarming to me,'' said Lauren Chanel, a writer on tech and \nculture. ''This is just another example in a long line of people underestimating what it takes to create the type of art \nthat, historically, Black people make.''\n  But for musicians like Herndon, who has provided her own A.I. voice as a tool for other musicians -- complete with \na system for compensation -- and created a company, Spawning, to build consent guidelines for A.I., there can be \nmagic in harnessing the future fairly and ethically.\n  ''There is more opportunity in exploring this technology than trying to shut it down,'' she said.\n  While meme art like ''Heart on My Sleeve'' may quickly become ''a real cultural force,'' she added, ''the novelty will \neventually be exhausted.'' What will remain are the artistic possibilities ''when anyone can assume the identity of \nsomeone else, even just for a second, as an expressive tool.''\n  As the technology continues to advance and is adopted in novel ways, someone may eventually do for A.I. voice \nmodels -- part of what Herndon calls ''identity play'' -- what producers like Prince Paul and J Dilla did for sampling.\n  ''As an artist I am interested in what it means for someone to be me, with my permission, and maybe even be \nbetter at being me in different ways,'' Herndon said. ''The creative possibilities there are fascinating and will change \nart forever. We just have to figure out the terms and tech.''\nhttps://www.nytimes.com/2023/04/19/arts/music/ai-drake-the-weeknd-fake.html\nGraphic\n \nPHOTOS: Labels hope fans will prize the work of artists, like the real Drake, above A.I. versions. (PHOTOGRAPH \nBY ADAM RIDING FOR THE NEW YORK TIMES) (C1)\n The short-lived viral hit ''Heart on My Sleeve'' claimed to use A.I. versions of the voices of the Weeknd, left, and \nDrake. (PHOTOGRAPH BY MARIO ANZUONI/REUTERS) (C4) This article appeared in print on page C1, C4.               \nLoad-Date: April 22, 2023"
    },
    {
        "file_name": "Podcast_Jan2024",
        "header": "Sam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates",
        "media": "Podcast",
        "time": "January 14, 2024",
        "section": "",
        "length": "488 words",
        "byline": "Sissi Cao",
        "story_text": "Sam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates \nPodcast\nNew York Observer\nJanuary 12, 2024 Friday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 488 words\nByline: Sissi Cao\nBody\nThe mobile app of OpenAI's ChatGPT has been downloaded more than 110 million times globally since its launch \nin November 2022. The artificial intelligence chatbot has become a daily essential to millions of users. But it's \nactually not the most reached-for app on OpenAI CEO Sam Altman's phone, he said in an interview with Bill Gates \naired yesterday (Jan. 11).\nIn the latest episode of Gates's weekly podcast Unconfuse Me, the Microsoft (MSFT) cofounder asked Altman \nwhich mobile app he uses the most, and the answer was surprising. \"Slack,\" Altman said, \"I wish I could say \nChatGPT...and way more than email. The only thing that I was thinking possibly was iMessages, but yes, [I use \nSlack] more than that...I'm on Slack all day.\"\nGates shared that his most used app is Microsoft Outlook. \"I'm this old-style email guy. Either that or the browser,\" \nhe said.\nAltman said he uses Slack mainly to coordinate work with his colleagues at OpenAI, which now has about 500 \nemployees. Gates was surprised at how small the organization is given the impact its products have made in the \ntech industry. \"That's tiny, by Google, Microsoft, Apple standards,\" Gates said. Since ChatGPT exploded in \npopularity, almost every Big Tech company has begun developing rival A.I. chatbots and other generative A.I. \napplications.\nOpenAI was founded about eight years ago by Altman and Elon Musk first as a nonprofit research lab. Over time it \nhas evolved to have a for-profit branch. \"We have to not only run the research lab, but now we have to run a real \nbusiness,\" Altman said. OpenAI's annualized revenue topped $1.6 billion in 2023, The Information reported in \nDecember.\nAltman added that OpenAI is also \"an older company than average\" where a lot of employees are in their 30s, 40s \nand 50s. \"It's not a bunch of 24-year-old programmers,\" he said.\n\"So it's not the early Microsoft and Apple, which we were really kids,\" Gates chimed in.\n\"I've reflected on that. I think companies have gotten older in general, and I don't know quite what to make of that,\" \nAltman added. \"I think it's somehow a bad sign for society. But I tracked this at YC [Y Combinator]. The best \nfounders have trended older over time.\"\nBefore serving as OpenAI's CEO in 2019, Altman was the president of startup incubator Y Combinator for five \nyears, funding and advising startup founders on how to grow their companies. Altman said that experience was \n\"super helpful\" but noted that OpenAI is distinctly different than most of the startups he'd incubated at YC.\nSam Altman Reveals His Most Used App Is Not ChatGPT In Bill Gates Podcast\n\"OpenAI did a lot of things that are very against the standard YC advice,\" he said. For example, Altman and his \ncofounders started OpenAI without a specific product idea and it ended up taking 4.5 years to launch the company's \nfirst product. \"I still don't recommend that for most companies,\" he added. \"But having learned the rules and see \nthem at YC made me feel like I understood when and how and why we could break them.\"\nLoad-Date: January 14, 2024"
    },
    {
        "file_name": "Adobe_CEO_Shantanu_Narayen_Aug2023",
        "header": "Artificial intelligence will augment human ingenuity, not replace it, says",
        "media": "Adobe CEO Shantanu Narayen",
        "time": "August 26, 2023",
        "section": "TECH & INTERNET",
        "length": "1807 words",
        "byline": "Surabhi Agarwal and Bodhisatva Ganguli",
        "story_text": "Artificial intelligence will augment human ingenuity, not replace it, says \nAdobe CEO Shantanu Narayen\nThe Economic Times\nAugust 27, 2023 Sunday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 1807 words\nByline: Surabhi Agarwal and Bodhisatva Ganguli\nBody\nArtificial intelligence (AI) is going to augment human ingenuity, not replace it, said Shantanu Narayen, chairman and \nchief executive of $17.61-billion Adobe Inc. The Hyderabad-born executive, who has been at the helm of the \nNasdaq-listed company for the last 15 years, cautioned that a rush to regulate AI and \"arbitrarily limiting \nadvancements may be harmful\". In a wide-ranging conversation with ET, he also talked about the role that Adobe \nIndia is playing in building the next-gen AI-led products and the monetisation opportunities for the company arising \nout of the AI boom.Narayen, 60, who is among the original crop of the ever-growing list of Indian-origin CEOs \nleading American multinationals (MNCs), also said that the future of India is \"very bright\" because of the right \ncombination of demographics, talent and technology and what the government has done with the digital public \ngoods is incredible. Edited excerpts:You're here at the B20 event and India seems to be a bright spot in the world \nright now. What are your thoughts on the India of today, a country you grew up in?To comment on India this week \nwithout commenting on the incredible achievement of the moon landing would be really amiss on my part. \nIt was just incredible. I think with the demographics, access to education, access to technology, the future (of India) \nis very bright.'Digital building blocks in place'With the macroeconomic and political issues with other neighbouring \ncountries, new opportunities are emerging for industries such as manufacturing and I've said this many times, if I \nwas growing up in India today, I don't know if I would leave the country.You really mean that?I really mean it. \nAround 40 years ago, if you were in tech, where would you go? You'd go abroad. Look at the percentage of people \nwho are going abroad nowadays from top educational institutions, it's a minuscule portion. And so the talent exists, \nthe access to capital certainly exists and the opportunity exists. And the Indian entrepreneurs don't look at it as an \nIndian opportunity but as a global one. So I'm a big big supporter (of India). The scale of India is truly amazing and \nthat's the opportunity for India. They've done a really good job of (building) the fundamental plumbing of \ninfrastructure - the fact that you have this digital identifier, you have universal payment scheme... When would I \nhave thought that you could go to Bundi (kiosk), get a pani puri or something and just pay for it through (UPI)... it's \nstaggering. Maybe because you're in this place, you don't look at it with the sort of amazement that we look at it (in \nthe US). If you can keep building on top of these, it (will be amazing). You talk to company after company here, you \nlook at the growth rates, look at how they're managing profitability and growth, look at their global aspirations, how \ncan one not be a fan?One of your founders, John Warnock, passed away. He was the inventor of the PDF among \nother revolutionary things. Could you tell us something about your relationship with him?The company was started \nby two amazing individuals, John (Warnock) and Chuck (Geschke). And both of them were researchers and they \nmet each other at Xerox PARC. It's been the privilege of a lifetime (to have worked with them). When you think \nabout technology innovators who've had a profound impact - John invented with Chuck - Postscript. Desktop \npublishing, as we know it today, would not have existed without their fundamental innovation. He invented Adobe \nIllustrator, his wife Marvo was a graphic artist. People take for granted today WYSIWYG (What You See Is What \nYou Get) applications but till then these hadn't been created. And he created the PDF. And so to work for 25 years \nwith an individual who's had that kind of profound inventiveness and then to be asked by both of them to run the \nArtificial intelligence will augment human ingenuity, not replace it, says Adobe CEO Shantanu Narayen\ncompany... It's just been the ride of a lifetime, and we will miss him.What are some of the challenges that India \nneeds to overcome to cement its position further in the global economy as it moves on to a path of becoming a \ndeveloped country?Access to education is always the bare minimum. With the population demographics that you \nhave, are you ensuring people access to education? I think we've done an amazing job in the country on that but \nmore can be done. And a strong digital and physical infrastructure does help. From a government, private sector \n(point of view), it's the ease of doing business, right. And even that is dramatically improved relative to what it used \nto be. I think the basic building blocks are all in place. In good faith, I can't say I'm disappointed at something that's \nhappening because it feels like all the right things are happening. They may not happen all the time and the scale at \nwhich or the speed at which people here wanted, but from outside - and I think I get the benefit of sometimes just \nzooming out and seeing.How big is Adobe's India business from a global perspective?We don't break out our \nbusiness by country. If you look at the number of computing devices that are in India, and if you look at our \npercentage of revenue: is it commensurate with other countries, it's a little behind. But if you look at it in terms of the \ngrowth rate right now, and the growth rate both on the creative side, the documents side as well as on the \nmarketing side - which is enabling businesses to be digital business - the growth rates are great. And the \npossibilities are immense. If you take financial services and you look at these giant financial institutions like HDFC, \nICICI, SBI and how they're thinking about digital, that's the opportunity for us to sell our marketing solutions.Any \nthoughts on the state of the global economy?The doom and gloom, I wasn't a believer (in it) and the business has \nactually continued. More and more people are now seeing consumer resilience. We didn't fully appreciate how as a \nresult of the pandemic, the disposable income for a lot of people increased, it also forced productivity. And so I think \nwe're starting, we're continuing to see the benefits of that.One of the threats of AI is said to be that it might kill the \ncreative industry...My perspective is that it will actually be a massive tailwind for the creative industry. If you think \nabout Adobe and what role we have played in society, we've democratised the ability for people to have a creative \nidea. Every time you have one of these successive advancements, everybody says oh my God, it's the end \nwhatever, as we know it. Are more movies being produced today than ever before? Absolutely. Are more short-form \nthings being done, animation? I believe, at least in my professional lifetime, this is going to augment human \ningenuity, not replace it.What's your view of regulation of AI? What needs to be regulated?The pace is moving so \nfast that people who are asking for a moratorium are people who are probably behind and want to catch up as \nopposed to people who are doing it for the greater good. Every technology we believe does societal good, but it has \nimplications.Generative AI tool is extremely confident both when it's right and perhaps when it's wrong. But net net, \nI would answer that for the first time on a mobile phone, I can have a personalised tutor that can enable billions of \npeople to have the education system that they deserve. For the first time we can have health and personalised \nhealth. Financial inclusion, creativity... The possibilities are what really drive us. But we have to be very responsible \nstewards of understanding ethical biases. When we created Firefly, we thought of what are the inherent biases that \nmight emerge if you don't pay attention to it. I do not believe that we're ready for major regulation at this point, \nbecause it's going so fast. But I think we can identify a set of principles that people can talk about. What's the \ntransparency associated with data? What's the veracity of this? And I think if you start with those principles, that's \nthe way for industry and government to responsibly advance this agenda.Are there network effects and what are \nthose effects and can they potentially turn out to be more harmful than good?We're all recognising that this is one \nthat we have to start addressing. But the beautiful thing about technology is that it moves so fast that you can't \nanticipate everything. The downside of that.. I go back to my answer, which is you have to be responsible stewards \nof this technology. But trying to arbitrarily limit advancements, in the end is going to be more harmful than not. And \nthere might be network effects... The technology industry is littered with companies that thought that they were \ngoing to be the dominant providers. They aren't unless you innovate. Look at Nvidia, look at what they've done. Not \nthat long ago, they were not considered... chip behemoth. What they have done with innovation is truly \nastounding.What is your broader view on this technology and how it will change the world?I fundamentally believe \nthat this will enable creatives to be more creative. Second, it'll allow more people to participate in the creative \nprofession and make that a profession if they want. And, conversely, Adobe has a role to understand where that \nmodel came from, how it's being used, and to ensure that we can determine when a piece of content was created \nby an individual and when it was created by a machine. And I think those are problems that we're working on and \nwe've stepped up to the plate. Every technology revolution has also been accompanied by the ability for disruptors \nto gain market share. So that's the flip side.What role is Adobe India playing in terms of AI development for Adobe? \nWhat can India do with a technology like that?So two answers to that? The first is, from day one, we invested in a \nworkforce where we said, this is going to be core to every product that we built. And so, Abhigyan (Modi) actually \nArtificial intelligence will augment human ingenuity, not replace it, says Adobe CEO Shantanu Narayen\nruns the entire document and PDF business globally. So this has everything to do with our Document Cloud \nfranchise. There's this feature that's been just released called Generative Recolor - think about text, you identify a \ntext and you want to get a prompt or a vector to start your creative process - all of that development is happening \nhere. So the developments happening begin on all three layers. We're developing models here which are based on \nour data for the domains in which we are interested and we're building and collecting data in an appropriate way. \nAnd we're building the interfaces for each of our applications. We look at Adobe India as an extension of everything \nthat we do globally. We're so unlike traditional companies that looked at it and said, how do I do grunt work (here). \nIndia has been core to everything that we do as an innovative company.(Dia Rekhi contributed to this article) For \nReprint Rights: timescontent.com\nLoad-Date: August 26, 2023"
    },
    {
        "file_name": "New_York_Observer_Jul2023",
        "header": "Bill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup",
        "media": "New York Observer",
        "time": "July 5, 2023",
        "section": "",
        "length": "459 words",
        "byline": "Sissi Cao",
        "story_text": "Bill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup\nNew York Observer\nJune 30, 2023 Friday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 459 words\nByline: Sissi Cao\nBody\nThe crowded generative artificial intelligence race just saw another rising star: Inflection AI, a startup barely two \nyears old, is suddenly worth $4 billion after a fundraising round this week and seems to have rounded up every \npower investor in the buzzing A.I. space. The Palo Alto, Calif.-based company raised $1.3 billion yesterday (June \n29) in a round led by Bill Gates, Eric Schmidt, Reid Hoffman, Microsoft and new investor Nvidia, Forbes first \nreported.\nInflection AI is cofounded and led by Mustafa Suleyman, a founding researcher of Google's DeepMind lab, and \nincubated by Greylock Partners, a venture capital firm owned by LinkedIn cofounder Reid Hoffman.\nIts main product is a ChatGPT-like text generator called Pi, which launched in May. Pi is powered by Inflection's in-\nhouse technology that prioritizes human conversations with a high level of emotional intelligence, which allows it to \nconduct conversations in a more human-like way than its competing applications like OpenAI's ChatGPT and \nGoogle's Bard, the company claims.\n\"With Pi, we set out to create a personal AI that is as flexible as it is powerful, so millions of people can use it to \nmake their lives more meaningful, more productive, and more fun,\" Hoffman said in a statement when unveiling Pi \nlast month.\nThat approach, which focuses on improving certain aspects of generative A.I. rather than building overall more \npowerful chatbots, is an increasingly appealing value proposition among A.I. startups. For example, Anthropic, a \nSan Francisco AI company founded in 2021, seeks to train language models that are \"safer and more aligned with \nhuman values,\" said its co-founder and president Daniela Amodei in a podcast recently.\nAnthropic was also recently valued at more than $4 billion. Its investors include Facebook cofounder Dustin \nMoskovitz, FTX cofounder Sam Bankman-Fried and Salesforce.\n\"It doesn't do lists, or coding, it doesn't do travel plans, it won't write your marketing strategy or your essay for \nschool,\" Inflection CEO Suleyman said in an interview with the Financial Times in May. \"It's purely designed for \nrelaxed, supportive, informative conversation.\"\nInflection's relationship with its investors goes beyond financial ties. Microsoft provides the startup with cloud \ncomputing infrastructure in addition to equity investment. Nvidia has been working with Inflection on deploying its \nH100 graphics processing units (GPUs) in large language model training.\nInflection said it will use the freshly raised capital to further fund the development of Pi. \"I think people can see that \nit's just the tip of the iceberg,\" Suleyman told Forbes yesterday. \"There's so much further to go after [Pi] validates \nthe core thesis, which is that conversation is the new interface.\"\nBill Gates, Eric Schmidt and Nvidia Pour Cash Into AI Startup\nLoad-Date: July 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Mar2023",
        "header": "Publishers Worry A.I. Chatbots Will Cut Readership",
        "media": "The New York Times - International Edition",
        "time": "March 31, 2023",
        "section": "BUSINESS",
        "length": "1316 words",
        "byline": "Katie Robertson",
        "story_text": "Publishers Worry A.I. Chatbots Will Cut Readership\nThe New York Times - International Edition\nApril 1, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1316 words\nByline: Katie Robertson\nBody\nMany sites get at least half their traffic from search engines. Fuller results generated by new chatbots could mean \nfar fewer visitors.       \nThe publishing industry has spent the past two decades struggling to adjust to the internet, as print circulation has \nplummeted and tech companies have gobbled up rivers of advertising revenue.       \nNow come the chatbots.       \nNew artificial intelligence tools from Google and Microsoft give answers to search queries in full paragraphs rather \nthan a list of links. Many publishers worry that far fewer people will click through to news sites as a result, shrinking \ntraffic - and, by extension, revenue.       \nThe new A.I. search tools remain in limited release, so publishers such as Condé Nast and Vice have not yet seen \nan effect on their business. But in an effort to prevent the industry from being upended without their input, many are \npulling together task forces to weigh options, making the topic a priority at industry conferences and, through a \ntrade organization, planning a push to be paid for the use of their content by chatbots.       \n\"You could essentially call this the Wikipedia-ization of a lot of information,\" said Bryan Goldberg, the chief \nexecutive of BDG, which publishes lifestyle and culture websites like Bustle, Nylon and Romper. \"You're bringing \ntogether Wikipedia-style answers to an infinite number of questions, and that's just going to nuke many corners of \nthe open web.\"       \nContent publishers have an uneven but largely reciprocal relationship with search engines. The search sites benefit \nfrom having trusted sources of information in the results, and the publishers benefit from the traffic to their sites that \nthe search engines generate.       \nSearch traffic from Google accounts for half of overall visits, or more, to many sites, said Brian Morrissey, who \nwrites The Rebooting, a media business newsletter.       \n\"Search has been the mainstay of the publishing business on the internet,\" he said.       \nKyle Sutton, director of search and product at the newspaper publisher Gannett, said the relationship had, until \nnow, been mutually beneficial.       \n\"While all search results are taking from our data and, from our perspective, crawling our content, aggregating our \ncontent, there is the return there of them driving traffic to our site,\" Mr. Sutton said. \"So I think that relationship is \nkind of first and foremost what we want to see maintained.\"       \nPublishers Worry A.I. Chatbots Will Cut Readership\nThe new offerings could change all of that, said Barbara Peng, the president of the digital news brand Insider. \nMicrosoft is incorporating the chatbot into Bing, its search engine. Google's search chatbot, Bard, is separate from \nits main search engine.       \n\"This will be revolutionary,\" Ms. Peng said, adding, \"It will take some time, and there is a good portion of hype \nmixed in there, too, but I do think it will change the relationship people have with finding and consuming \ninformation.\"       \nThe impact of \"generative\" A.I., which can generate text, images and other media from prompts, has become a top \npriority in discussions among publishers. A conference in New York in May, the World Congress of News Media, \nwill feature keynote speeches on the issue, according to a schedule on its website.       \nVice Media has created a task force in recent months to examine its own approach, said Cory Haik, the chief \noperating officer. \"It will have a huge impact on publishing in ways that we can't even get our heads around yet,\" \nshe predicted.       \nThe Washington Post announced on Tuesday that it had appointed a deputy business editor to lead an internal \ngroup looking at A.I.'s impact on The Post's journalism and digital strategy.       \nNews Corp's chief executive, Robert Thomson, who for years has led a push to get tech companies to pay for news \ncontent, said in an interview: \"If you don't get out early and define what the issues are and the obligations, then you \nwill find yourself on the defensive.\"       \nMr. Thomson said tech companies should pay to use publishers' content to produce results from A.I. chatbots. The \nchatbots generate their results by synthesizing information from the internet. He added that News Corp, which owns \nThe Wall Street Journal and The New York Post among other outlets, was in talks with \"a couple of companies\" \nabout the use of its content, though he declined to specify which ones.       \n\"There is a recognition at their end that discussions are necessary,\" he said.       \nRoger Lynch, the chief executive of Condé Nast, which owns titles like Vogue, Vanity Fair and Glamour, agreed that \ncontent creators should be compensated. He said one upside for publishers was that audiences might soon find it \nharder to know what information to trust on the web, so \"they'll have to go to trusted sources.\"       \nThe News Media Alliance, which represents 2,000 outlets around the world, including The New York Times, is \nworking on principles that it says should guide the use and development of A.I. systems, and regulation around \nthem, to protect publishers. According to a draft, the principles say the use of publisher content for the development \nof A.I. should require \"a negotiated agreement and explicit permission.\"       \nThe guidelines also call on tech companies to \"provide sufficient value\" for high-quality, trustworthy journalism \ncontent and brands, and state that any new laws or regulations that make exceptions to copyright law for A.I. must \nnot weaken protections for publishers.       \n\"Without these protections, publishers - far too many of whom already struggle to survive in the online ecosystem \ndue to marketplace imbalances - face an existential crisis that threatens our communities' access to reliable and \ntrustworthy journalism,\" the document states.       \nDanielle Coffey, executive vice president of the News Media Alliance, said a solution could be found in the \nJournalism Competition and Preservation Act, a bill that would allow publishers to collectively negotiate with tech \ncompanies over revenue sharing and, as written, would account for the use of content by generative A.I. The bill, \nwhich failed to pass last year, is expected to be reintroduced on Thursday by Senators Amy Klobuchar, Democrat \nof Minnesota, and John Kennedy, Republican of Louisiana.       \nYusuf Mehdi, Microsoft's head of Bing, said in an interview that directing users to click through to publishers was \"a \ntop goal.\" And although the new Bing has been around for less than two months, the data was \"already showing \nthat we are driving, in fact, more traffic to publishers,\" he said.       \nPublishers Worry A.I. Chatbots Will Cut Readership\n\"Part of the reason that traffic is up is that we don't just do a good job of answering the question, but we provide \nlinks,\" he said, pointing to footnotes in the answers on Bing's chatbot that show the information's source.       \nMr. Mehdi said Microsoft was at the beginning of its conversations with publishers around the new search. \"It is our \nintention that we would like to share incremental revenue that happens in that chat experience,\" he said.       \nMicrosoft is considering showing more articles from a certain publisher below the footnote or selling ads against the \nlinks in the chat answer and splitting the proceeds, Mr. Mehdi said.       \nA Google spokeswoman said in a statement that the company was \"deeply committed to supporting a healthy and \nvibrant news ecosystem\" and would put a priority on sending traffic.       \n\"This is the very early days of testing an experience in Bard, and we'll be welcoming conversations with publishers \nto get their input,\" she said.       \nFor the past two years, BDG has focused on products like live events, email newsletters and premium branded \ncontent to limit exposure to the whims of search traffic, Mr. Goldberg said.       \n\"I think the best publishers had already anticipated this was coming years ago and are many years into our \ntransformation,\" he said. \nLoad-Date: March 31, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "'A.I.' and 'Start-Up' Are a Tough Combination",
        "media": "The New York Times",
        "time": "May 4, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1446 words",
        "byline": "By Cade Metz, Karen Weise and Tripp Mickle",
        "story_text": "'A.I.' and 'Start-Up' Are a Tough Combination\nThe New York Times\nMay 4, 2024 Saturday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1446 words\nByline: By Cade Metz, Karen Weise and Tripp Mickle\nBody\nThe table stakes for small companies to compete with the likes of Microsoft and Google are in the billions of dollars. \nAnd even that may not be enough.\nCall it the end of the beginning of the A.I. boom. \n  Since mid-March, the financial pressure on several signature artificial intelligence start-ups has taken a toll. \nInflection AI, which raised $1.5 billion but made almost no money, has folded its original business. Stability AI has \nlaid off employees and parted ways with its chief executive. And Anthropic has raced to close the roughly $1.8 \nbillion gap between its modest sales and enormous expenses.\n  The A.I. revolution, it is becoming clear in Silicon Valley, is going to come with a very big price tag. And the tech \ncompanies that have bet their futures on it are scrambling to figure out how to close the gap between those \nexpenses and the profits they hope to make somewhere down the line.\n  This problem is particularly acute for a group of high-profile start-ups that have raised tens of billions of dollars for \nthe development of generative A.I., the technology behind chatbots such as ChatGPT. Some of them are already \nfiguring out that competing head-on with giants like Google, Microsoft and Meta is going to take billions of dollars -- \nand even that may not be enough.\n  ''You can already see the writing on the wall,'' said Ali Ghodsi, chief executive of Databricks, a data warehouse \nand analysis company that works with A.I. start-ups. ''It doesn't matter how cool it is what you do -- does it have \nbusiness viability?''\n  While plenty of money has been burned in other tech booms, the expense of building A.I. systems has shocked \ntech industry veterans. Unlike the iPhone, which kicked off the last technology transition and cost a few hundred \nmillion dollars to develop because it largely relied on existing components, generative A.I. models cost billions to \ncreate and maintain. The cutting-edge chips they need are expensive and in short supply. And every query of an \nA.I. system costs far more than a simple Google search.\n  Investors have poured $330 billion into about 26,000 A.I. and machine-learning start-ups over the past three \nyears, according to PitchBook, which tracks the industry. That's two-thirds more than the amount they spent funding \n20,350 A.I. companies from 2018 through 2020.\n  The challenges hitting many newer A.I. companies stand in contrast to the early business results at OpenAI, which \nis backed by $13 billion from Microsoft. The attention it has generated with its ChatGPT system has allowed the \ncompany to build a business charging $20 a month for its premium chatbot and offered a way for businesses to \n'A.I.' and 'Start-Up' Are a Tough Combination\nbuild their A.I. services with the technology that drives its chatbot, which is called a large language model. OpenAI \npulled in around $1.6 billion in revenue over the last year, but it is unclear how much the company is spending, two \npeople familiar with the company's business said.\n  OpenAI did not respond to requests for comment.\n  But even OpenAI has had challenges broadening sales. Businesses are wary that the A.I. systems can generate \ninaccurate answers. The technology has also been troubled by questions about whether the data that supported the \nmodels infringed on copyrights.\n  (The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\n  Many investors point to Microsoft's rapid sales growth as evidence of A.I.'s business potential. In its most recent \nquarter, Microsoft reported an estimated $1 billion in sales from A.I. services in cloud computing, up from essentially \nnothing a year ago, said Brad Reback, an analyst at the investment bank Stifel.\n  Meta, on the other hand, doesn't expect to make money for years off its A.I. products, even as it increases its \ninfrastructure spending by up to $10 billion this year alone. ''We're investing to stay at the leading edge of this,'' \nMark Zuckerberg, Meta's chief executive, said during a call with analysts last week. ''And we're doing that at the \ntime when we're also scaling the product before it is making money.''\n  A.I. start-ups have been challenged by that gap between spending and sales. Anthropic, which has raised more \nthan $7 billion with backing from Amazon and Google, is spending about $2 billion a year but pulling in only about \n$150 million to $200 million in revenue, said two people familiar with the company's financials, who requested \nanonymity because the figures are private.\n  Like OpenAI, Anthropic has turned to partnerships with large, established tech companies. Its chief executive, \nDario Amodei, has been courting customers on Wall Street, and it recently announced that it was working with \nAccenture, the global consulting company, to create custom chatbots and A.I. systems for companies and \ngovernment organizations.\n  Sally Aldous, a spokeswoman for Anthropic, said that thousands of businesses were using the company's \ntechnology and that millions of consumers were using its publicly available chatbot, Claude.\n  Stability AI, which does image generation, announced last month that its founding chief executive, Emad \nMostaque, had resigned, just a week after the resignation of three researchers who were part of the five-person \nteam that built the company's original technology.\n  It was on track to generate about $60 million in sales this year against about $96 million in costs from its image \ngeneration system, which has been available to customers since 2022, a person familiar with its business said.\n  Stability AI's financial position looks better than those of language-model makers like Anthropic because \ndeveloping image generation systems is less expensive, A.I. investors said. But there's also less demand to pay for \nimages, so the sales prospects are more uncertain.\n  Stability AI has been operating without the support of a tech giant. After raising $101 million from venture \ncapitalists in 2022, it needed more funds last fall but was struggling to show investors that it could sell its technology \nto businesses, said two former employees, who declined to speak publicly because they were not authorized to do \nso. It raised $50 million from Intel late last year but still faced financial pressure, they said.\n  As the start-up grew, its sales strategy shifted, these people said. At the same time, it was spending millions a \nmonth on computing costs. Some investors pressured Mr. Mostaque to resign, according to an investor, who \ndeclined to speak publicly about a personnel issue. This month, after his resignation, Stability AI did layoffs and \nrestructured its business to put the company on ''a more sustainable path,'' according to a company memo \nreviewed by The New York Times.\n'A.I.' and 'Start-Up' Are a Tough Combination\n  Stability AI declined to comment. Mr. Mostaque declined to discuss his exit.\n  Inflection AI, a chatbot start-up founded by three A.I. veterans, had raised $1.5 billion from some of the biggest \nnames in tech. But a year after introducing its A.I. personal assistant, it had almost no revenue, according to one \ninvestor. The Times reviewed a letter that Inflection had sent to investors saying additional fund-raising was ''not the \nbest use of our investors' money, especially in the context of the current frothy A.I. market.''\n  In late March, it folded its original business and largely disappeared into Microsoft, the world's most valuable \npublic company.\n  Microsoft also helped fund Inflection AI, whose chief executive, Mustafa Suleyman, rose to prominence as one of \nthe founders of DeepMind, a seminal artificial intelligence lab that Google acquired in 2014. Mr. Suleyman founded \nInflection AI alongside Karén Simonyan, a key DeepMind researcher, and Reid Hoffman, a leading Silicon Valley \nventure capitalist who helped found OpenAI and is on Microsoft's board.\n  Microsoft and Inflection AI declined to comment.\n  The company was steeped in talented A.I. researchers who had worked at places like Google and OpenAI.\n  But almost a year after releasing its A.I. personal assistant, Inflection AI's revenue was, in the words of one \ninvestor, ''de minimis.'' Essentially zilch. It could not continue to improve its technologies and keep pace with \nchatbots from the likes of Google and OpenAI unless it continued to raise huge sums of money.\n  Now Microsoft is swallowing most of its staff, including Mr. Suleyman and Dr. Simonyan.\n  This is costing Microsoft more than $650 million. But unlike Inflection AI, it can afford to play the long game. It has \nannounced plans for the staff to build an A.I. lab in London, working with the kind of systems the start-ups are \nhoping will break through.\n  Erin Griffith contributed reporting.Erin Griffith contributed reporting.\nhttps://www.nytimes.com/2024/04/29/technology/ai-startups-financial-reality.html\nGraphic\n \nThis article appeared in print on page B1, B5.               \nLoad-Date: May 4, 2024"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "A Chip Titan Can No Longer Stay Offstage In a Tech War",
        "media": "The New York Times",
        "time": "August 6, 2023",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 4",
        "length": "3073 words",
        "byline": "By Paul Mozur and John Liu",
        "story_text": "A Chip Titan Can No Longer Stay Offstage In a Tech War\nThe New York Times\nAugust 6, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 4\nLength: 3073 words\nByline: By Paul Mozur and John Liu\nBody\nIn a wood-paneled office overlooking Taipei and the jungle-covered mountains that surround the Taiwanese capital, \nMorris Chang recently pulled out an old book stamped with technicolor patterns.\nIt was titled ''Introduction to VLSI Systems,'' a graduate-level textbook describing the intricacies of computer chip \ndesign. Mr. Chang, 92, held it up with reverence. \n  ''I want to show you the date of this book, 1980,'' he said. The timing was important, he added, as it was ''the \nearliest piece'' in a puzzle that came together for him -- altering not only his career but also the course of the global \nelectronics industry.\n  The insight that Mr. Chang gained from the textbook was deceptively simple: the idea that microchips, which act \nas the brains of computers, could be designed in one place but manufactured somewhere else. The notion went \nagainst the semiconductor industry's standard practice at the time.\n  So at the age of 54, when many people begin thinking more about retirement, Mr. Chang instead put himself on a \npath to turn his insight into a reality. The engineer left his adopted country, the United States, and moved to Taiwan \nwhere he founded Taiwan Semiconductor Manufacturing Company, or TSMC. The company does not design chips, \nbut it has become the world's biggest manufacturer of cutting-edge microprocessors for customers including Apple \nand Nvidia.\n  Today, the company that partially exists because of a textbook is a $500 billion juggernaut that has put the most \nadvanced chips in iPhones, cars, supercomputers and fighter jets. So critical are its airplane-hangar-size chip \nfactories, called fabs, that the United States, Japan and Europe have courted TSMC to build them in their neck of \nthe woods. Over the past decade, China has also invested hundreds of billions of dollars to recreate what TSMC \nhas done.\n  Mr. Chang's unlikely entrepreneurial journey helped Taiwan become an economic giant, restructured the way the \nelectronics industry worked and ultimately charted a new geopolitical reality in which a linchpin of global economic \ngrowth lies in one of the world's most volatile spots.\n  That has thrust Mr. Chang, and the company he created, into the spotlight. And at the twilight of his career, a man \nwho has preferred to remain in the shadows reflected on what he has built and what it means to no longer be able \nto stay under the radar.\n  ''It doesn't make me feel particularly good,'' said Mr. Chang, who retired in 2018 but still appears at TSMC events. \n''I would rather stay relatively unknown.''\nA Chip Titan Can No Longer Stay Offstage In a Tech War\n  Over a recent three-hour discussion in his office, Mr. Chang made it clear that he identifies as American -- he \nobtained his U.S. citizenship in 1962 -- at a time when the company he founded is at the center of a technological \nCold War between the United States and China. Even as the rivalry for tech leadership intensifies, he does not give \nChina much of a chance for semiconductor supremacy.\n  ''We control all the choke points,'' Mr. Chang said, referring collectively to the United States and its chip-making \nallies such as the Netherlands, Japan, South Korea and Taiwan. ''China can't really do anything if we want to choke \nthem.''\n  More than a dozen people familiar with Mr. Chang, many of whom knew him as a colleague at TSMC, said he built \nthe company -- and outmaneuvered giants like Samsung and Intel -- by being meticulous, stubborn, trusting his \nbest people and, crucially, having boundless ambition and making daring moves when justified. When TSMC \nstumbled after the 2008 financial crisis, he returned as chief executive at age 77 to take over again.\n  ''He's probably the only person left in the chip industry who was present at the creation of the industry itself,'' said \nChris Miller, the author of the book ''Chip War'' and an associate professor of international history at the Fletcher \nSchool at Tufts University. ''That he's not only still in the industry but at the center and top of it is extraordinary.''\n  To understand the tech industry's future, it is crucial to understand the world through Mr. Chang's eyes and how \nhe made that initial bet when others didn't. And unlike today's tech moguls -- such as Elon Musk and Mark \nZuckerberg, who have publicly considered a cage fight -- Mr. Chang has shown more restraint. If competition \nbetween the global tech giants is a series of high-stakes poker games, he is the quiet man who runs the casino.\n  Almost an automaker\n  Mr. Chang was born in 1931 in a China on the brink of war. Before the age of 18, he lived in six cities, changed \nschools 10 times, experienced bombings in Guangzhou and Chongqing, and crossed the front lines as his family \nfled Japanese-occupied Shanghai during World War II.\n  When he made it to Hong Kong in 1948 with his family, who by then were trying to get away from the Chinese \nCommunist Party's advancing army, there was no going back.\n  ''My old world crumbled as the mainland changed its color, and a new world was yet to be established,'' he wrote \nin his autobiography, which was published in 1998.\n  In 1949, Mr. Chang moved to the United States, attending Harvard before transferring to the Massachusetts \nInstitute of Technology to study mechanical engineering. In 1955, when he twice failed a qualifying exam for a \ndoctoral degree at M.I.T., he decided to test out the job market.\n  ''Many years later, I considered failing to be admitted to the Massachusetts Institute of Technology's Ph.D. \nprogram as the greatest stroke of luck in my life!'' he wrote in his autobiography.\n  Two of the best offers arrived from Ford Motor Company and Sylvania, a lesser-known electronics firm. Ford \noffered Mr. Chang $479 a month for a job at its research and development center in Detroit. Though charmed by \nthe company's recruiters, Mr. Chang was surprised to find the offer was $1 less than the $480 a month that \nSylvania offered.\n  When he called Ford to ask for a matching offer, the recruiter, who had previously been kind, turned hostile and \ntold him he would not get a cent more. Mr. Chang took the engineering job with Sylvania. There, he learned about \ntransistors, the microchip's most basic component.\n  ''That was the start of my semiconductor career,'' he said. ''In retrospect, it was a damn good thing.''\n  Three years at Sylvania opened doors and cemented Mr. Chang's passion for semiconductors. But Sylvania \nstruggled, teaching him a lesson that would inform how he later ran TSMC.\nA Chip Titan Can No Longer Stay Offstage In a Tech War\n  ''From the beginning, the semiconductor industry has been a fast-paced and unforgiving industry,'' Mr. Chang \nwrote of Sylvania's eventual collapse in his autobiography. ''Once you fall behind, catching up becomes \nconsiderably difficult.''\n  In 1958, he jumped to a buzzy new semiconductor company, Texas Instruments. The Dallas company was \n''youthful and energetic,'' with many employees working over 50 hours a week and sleeping overnight in the office. \nFour years later, Mr. Chang became an American, an identity he considers primary.\n  ''Ever since I fled Communist China and went to the United States and became naturalized in 1962, my identity \nhas always been American, and nothing else,'' he said.\n  Mr. Chang became a pillar of Texas Instruments' then world-beating semiconductor business. Breakthroughs were \nconstant. In the 1970s, the firm produced a chip that could synthesize the human voice, which led to the famed \nSpeak & Spell toy, a hand-held device that helped children with spelling and pronunciation.\n  ''It's just like Camelot, but it was not a long period of time,'' he said. \n  In the late 1970s, Texas Instruments turned its focus to the burgeoning market for calculators, digital watches and \nhome computers. Mr. Chang, then in charge of the semiconductor side, realized his career there was approaching a \n''dead end.''\n  It was time for something different.\n  Putting the puzzle pieces together\n  If the first puzzle piece that led to TSMC's creation was the textbook, the second was an experience that Mr. \nChang had toward the end of his time at Texas Instruments.\n  In the early 1980s, Texas Instruments opened a chip factory in Japan. Three months after the production line \nbegan churning out chips, the plant's ''yield'' was double that of the company's factories in Texas. Yield is a key \nstatistic that refers to how many usable chips emerge from production.\n  Mr. Chang was dispatched to Japan to solve the yield mystery. The key was the staff, he found, with turnover \nsurprisingly low among well-qualified employees.\n  But try as it might, Texas Instruments could not find the same caliber of technicians in the United States. At one \nU.S. plant, the top candidate for a supervisor job had a degree in French literature and no engineering background. \nThe future of advanced manufacturing appeared to be in Asia.\n  In 1984, Mr. Chang joined General Instrument, another chip firm, where a third puzzle piece fell into place. He met \nan entrepreneur who later started a company that would only design chips without also making them, which was \nthen uncommon. He spotted a trend that would prove to have staying power: Today most semiconductor \ncompanies design chips and outsource manufacturing. \n  This final piece coincided with Taiwan's transition from a labor-intensive and heavy industry economy to a high-\ntech one. When Taiwanese officials set their sights on developing the semiconductor industry, they asked Mr. \nChang, whose reputation as a chip expert was established, to lead an institute for supercharging innovation.\n  So in 1985, Mr. Chang, then 54, left the United States for a place he knew only from several visits to a Texas \nInstruments factory.\n  ''I certainly had no plan to spend nearly so much time in Taiwan,'' he said. ''I thought I was going back in maybe \njust a few years, and I really had no plan to set up TSMC, to set up any company in Taiwan.''\n  Within weeks of Mr. Chang's arrival, Li Kwoh-ting, a government official who became known as the godfather of \nTaiwan's tech development, asked him to make the state-led chip project commercially viable.\nA Chip Titan Can No Longer Stay Offstage In a Tech War\n  When Mr. Chang assessed Taiwan's strengths and weaknesses, he sensed an opening. ''I concluded that Taiwan \nwas a lot more similar to Japan than the U.S.,'' he said, referring to his experience with the Texas Instruments' \nfactory in Japan. \n  In 1987, Mr. Chang founded TSMC. The business model was clear in his head: TSMC would make chips for other \ncompanies and not design them. That meant it just had to win over those inside the industry and then focus on what \nit could do best -- manufacturing.\n  From the get-go, Mr. Chang had plans for TSMC to tap into a global market. He introduced professional \nmanagement systems, which were uncommon in Taiwan, at the company. To foster an international environment, \ninternal communications were in English.\n  His vision proved prophetic. As semiconductors became more complex and expensive to produce, only a few firms \ncould even afford to try. Making chips involves hundreds of steps that pull on advanced lasers and chemical \nmanipulations to create tiny pathways for electronic signals that do the most basic calculations for a computer. \nCosts were astronomical.\n  Over the years, Mr. Chang kept going as others dropped out. If TSMC could attract enough customers, leveraging \neconomies of scale, it had a chance to take out the kings: Intel and Samsung.\n  In 1997, Mr. Chang recruited a new head of research of development, Chiang Shang-yi. He told Mr. Chiang to \nbenchmark TSMC against the industry leader, Intel.\n  ''Our goal is to be No. 1, barring none,'' Mr. Chang said.\n  Mr. Chiang was surprised. ''To be No. 1, you have to spend three times as much as your next competitor,'' he \nreplied, implying that being in the lead would be too lofty and costly a goal.\n  ''It may be three times, but I do want to spend enough so that we become No. 1,'' Mr. Chang said. And he was \nprepared to be patient, even after stepping down as TSMC's chief executive in 2005 and staying on as the \ncompany's chairman.\n  Closing the Apple contract\n  In April 2009, angry TSMC employees -- many who had recently been let go by the company -- set up a protest \ncamp at a leafy playground in Taipei's quiet residential neighborhood of Dazhi. They were down the street from Mr. \nChang's upscale apartment building.\n  As dark fell, the protesters rolled out sleeping bags next to a slide and jungle gym, covering themselves with a \nlarge sign that read ''TSMC lies lies lies.'' Throughout its more than two-decade history, TSMC had never laid off \nemployees. Yet after the 2008 financial crisis, Mr. Chang's successor, Rick Tsai, began letting employees go.\n  Mr. Chang, then 77, decided he could no longer stay on the sidelines. He took back his job, rehired the talent Mr. \nTsai had let go and more than doubled TSMC's spending.\n  Coming at a tough time for the industry, the move was not appreciated by investors. Elizabeth Sun, TSMC's \nformer head of investor relations, recalled her reaction to the news: ''When I heard it, I felt like banging my head \nagainst a wall.''\n  But the bet paid off. In 2010, Mr. Chang got the call that would turbocharge TSMC's growth and clinch its lead over \nSamsung and Intel. Jeff Williams, a senior vice president at Apple, reached out through Mr. Chang's wife, Sophie \nChang, who is a relative of Terry Gou, the founder of Foxconn, Apple's largest assembler.\n  The call led to a Sunday dinner with all four of them, which turned into negotiations the next day. Apple had \nworked with Samsung to produce the microchip it designed for the iPhone, but it was looking for a new partner, \nA Chip Titan Can No Longer Stay Offstage In a Tech War\npartly because Samsung had become a major smartphone competitor. TSMC, which does not compete with its \ncustomers, was in pole position for the contract.\n  The discussions stretched on for months. ''It was very complicated -- the contract itself,'' Mr. Chang said. ''It was \nthe first time we ran into this kind of thing.''\n  At one point, Apple announced a two-month pause in talks. Mr. Chang heard Intel might have intervened.\n  Worried, Mr. Chang flew to San Francisco to meet Tim Cook, Apple's chief executive, who reassured him. In a \n2013 interview, Paul Otellini, then Intel's chief executive, said he had turned down the chance to make the chips for \nthe iPhone because Apple would not pay enough.\n  Mr. Chang would not make the same mistake. Apple demanded better terms and lower prices than others, but he \nunderstood the contract's scale would help TSMC rocket past competitors. That was a lesson he learned from Bill \nBain, who founded the consulting firm Bain & Company, back at Texas Instruments.\n  Mr. Bain, then a consultant for Boston Consulting Group, had worked in an office next to Mr. Chang for almost two \nyears. He had analyzed Texas Instruments' production and sales numbers and argued that the more the company \nproduced, the better it would perform.\n  When the deal with Apple was complete, Mr. Chang borrowed $7 billion to build the capacity for making millions of \nchips for the iPhone.\n  In the ensuing years, Apple briefly turned to Samsung for iPhone chip production again, but TSMC became its \nprimary chip maker. Apple is now TSMC's largest client, accounting for about 20 percent of revenue.\n  Mr. Chang remains cautious about what he says about TSMC's customers even now. After beginning a story \nabout Apple at his office, he wondered whether he had said too much.\n  ''I don't think I have exceeded Apple's limits of what to tell you,'' he said.\n  In a statement, Mr. Williams, now Apple's chief operating officer, said Mr. Chang had ''pushed the semiconductor \nindustry to new frontiers.''\n  In 2018, Mr. Chang, at 86 years old, retired again. By then, TSMC had succeeded where others lagged, mass \nproducing chips with electronic pathways the size of a DNA double helix. That gave Mr. Chang confidence that he \nhad achieved a key tenet for TSMC: technological leadership.\n  Spurring the A.I. revolution\n  Among the awards and photos with world leaders that stud the walls of Mr. Chang's Taipei office, one is a framed \ncomic portraying his close relationship with Jensen Huang, a founder of the chip firm Nvidia.\n  If Apple turbocharged TSMC, it was Mr. Chang who helped make Nvidia the world's most important designer of \nartificial intelligence chips. The cartoon tells the story. In the mid-1990s, when Nvidia was a start-up, Mr. Huang \nsent a letter to Mr. Chang asking if TSMC would make its chips. After a call with Mr. Huang, Mr. Chang agreed.\n  ''I liked him,'' Mr. Chang said of Mr. Huang.\n  By taking that chance, Mr. Chang helped spur the A.I. revolution in the United States. With TSMC's manufacturing, \nNvidia became the world's most important A.I. chip designer. Breakthroughs like generative A.I. rely on huge \nnumbers of Nvidia chips to find patterns in vast amounts of data.\n  In a 2018 speech at Mr. Chang's retirement gathering, Mr. Huang said Nvidia -- now worth $1 trillion -- would not \nexist without TSMC. An inscription on the comic, which Mr. Huang gave to Mr. Chang, reads: ''Your career is a \nmasterpiece -- a Beethoven's Ninth Symphony.''\nA Chip Titan Can No Longer Stay Offstage In a Tech War\n  For Mr. Chang, the final notes of that masterpiece have not yet been played. He is healthy for a nonagenarian, \nthough he can no longer smoke a pipe -- once his trademark in photos -- after he had stents put into his heart a few \nyears ago.\n  At his office, he still keeps a Bloomberg terminal. He also makes regular public appearances around Taiwan to \ndiscuss global politics and the economy. Like many, he worries about a potential conflict between the United States \nand China over Taiwan, though he believes the chance of such a confrontation is low.\n  ''The chance of China invading Taiwan, amphibious warfare and all that stuff, I think that's a very, very low \nprobability,'' he said. ''A blockade of some kind, I think I still put it as low probability, but it's still a chance and I want \nto avoid that.''\n  Mr. Chang said he was not worried about U.S. policies that have cut off Chinese firms from access to cutting-edge \nsemiconductor technology.\n  ''I think it's still OK,'' he said, though he noted U.S. companies would lose business and China would find ways to \nfight back.\n  As the conversation wound down, Mr. Chang said he had some regrets that he could not be in the driver's seat as \nTSMC faces geopolitical challenges. But he said the timing of his retirement in 2018 made sense, driven by \ntechnology and not politics.\n  ''I was literally sure that we had achieved technology leadership,'' he said of that time. ''I don't think we'll lose it.''\nhttps://www.nytimes.com/2023/08/04/technology/the-chip-titan-whose-lifes-work-is-at-the-center-of-a-tech-cold-\nwar.html\nGraphic\n \nPHOTOS: The TSMC Museum of Innovation in Hsinchu, Taiwan, tells the company's story. (PHOTOGRAPHS BY \nLAM YIK FEI FOR THE NEW YORK TIMES) (BU4)\nAbove from left: Morris Chang delivering remarks at a TSMC event at a plant in Arizona last year\ninside a TSMC chip factory in Hsinchu\nthe TSMC office in the Southern Taiwan Science Park in Tainan. (PHOTOGRAPHS BY AGENCE FRANCE-\nPRESSE -- GETTY IMAGES\nADRIANA ZEHBRAUSKAS FOR THE NEW YORK TIMES\nLAM YIK FEI FOR THE NEW YORK TIMES) (BU4\nBU5)\nA TSMC silicon wafer, left. Rick Tsai, above, Morris Chang's successor, laid off employees after the 2008 financial \ncrisis. In 2009, Mr. Chang, then 77 and four years into retirement, took back his job and rehired those who had \nbeen let go. (PHOTOGRAPH BY SAM YEH/AGENCE FRANCE-PRESSE -- GETTY IMAGES)\nAt a new TSMC plant in Phoenix last year, Mr. Chang shared a toast with Tim Cook, top left, Apple's chief \nexecutive, and a handshake with Jensen Huang, above right, chief executive of Nvidia. Both companies are TSMC \nmicroprocessor customers. (PHOTOGRAPHS BY CAITLIN O'HARA/BLOOMBERG\nA Chip Titan Can No Longer Stay Offstage In a Tech War\n ROSS D. FRANKLIN/ASSOCIATED PRESS) (BU5) This article appeared in print on page BU4, BU5.               \nLoad-Date: August 6, 2023"
    },
    {
        "file_name": "Siddhartha_Mukherjee's_book_Jan2023",
        "header": "What's on Bill Gates's mind? AI impact, binge-worthy 'White Lotus' &",
        "media": "Siddhartha Mukherjee's book",
        "time": "January 12, 2023",
        "section": "PEOPLE",
        "length": "467 words",
        "byline": " ",
        "story_text": "What's on Bill Gates's mind? AI impact, binge-worthy 'White Lotus' & \nSiddhartha Mukherjee's book\nThe Economic Times\nJanuary 13, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: PEOPLE\nLength: 467 words\nBody\nBusinessman Bill Gates logged in on Wednesday for his 11th Reddit 'Ask Me Anything' session where he touched \nup on different topics from climate change to things he is looking forward to in 2023. The Microsoft co-founder is \nlooking forward to spending quality time with his grandchildren, binge-watching his favourite shows while he \nmonitors and contributes to the progress being made in health and climate innovation. Apart from this, Gates also \nhas AI (Artificial Intelligence) on his mind. The American business magnate and philanthropist further said that he is \nexcited to help shape AI advances in a positive way. \nDuring the AMA, Gates was asked what he thinks about generative AI and its impact on the world, to which the \nclimate change advocate replied saying that he was quite impressed with the rate of improvements in AIs. \"I think \nthey will have a huge impact,\" he replied. When asked what he was excited about in the year ahead, the 67-year-\nold replied with four things: Being a grandfather. Being a good friend and father. Progress in health and climate \ninnovation. Helping to shape AI advances in a positive way.So, what are a few life lessons he would share with his \ngrandchildren that will make their life happier? Gates quickly replied by saying \"good examples help kids the most.\" \n\"I think you mostly help kids by setting a good example and giving them time when they want it. I hope to get lots of \ntime with whatever grandchildren I have sharing my fascination with the world. A grandchild does make you think \nabout how we make sure the future is better - politics, health, climate, etc.\" the businessman said. Further during \nthe AMA, which went on for over an hour, Gates also shared his current reading list, which is topped by Siddhartha \nMukherjee's book 'The Song of the Cell'. Mukerjee, an Indian-American physician, biologist, and author, bagged a \nPulitzer Prize for General Non-Fiction on 2011 for his 'The Emperor of All Maladies: A Biography of Cancer'. \nSharing his list, Gates said: \"All of his books are excellent - right up there with Atul Gawande. I have a lot of books \nabout China to help me figure out how we avoid a lose-lose relationship.\" After tapping on diverse topics such as \nclimate change, advanced tech, lessons for his grandchildren, year 2023 and more, the co-founder of Bill & Melinda \nGates Foundation revealed the shows he binged recently that succeeded in impressing him. \"White Lotus Season 2 \nwas quite good if I can say that. Congratulations to Jennifer Coolidge on her Golden Globe. The Bernie Madoff \nspecial was also good. Tehran was suspenseful. The latest Avatar was good. My favorite entertainment experience \nrecently was a Chris Rock/Dave Chappelle event. (as he drops the mic... or keyboard...)\" he concluded. For Reprint \nRights: timescontent.com\nLoad-Date: January 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "What I’d Assign to Today’s College Students; Ross Douthat",
        "media": "The New York Times",
        "time": "May 4, 2024",
        "section": "OPINION",
        "length": "1312 words",
        "byline": "Ross Douthat Ross Douthat has been an Opinion columnist for The Times since 2009. He is the author,",
        "story_text": "What I’d Assign to Today’s College Students; Ross Douthat\nThe New York Times \nMay 3, 2024 Friday 16:06 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1312 words\nByline: Ross Douthat Ross Douthat has been an Opinion columnist for The Times since 2009. He is the author, \nmost recently, of &amp;#8220;The Deep Places: A Memoir of Illness and Discovery.&amp;#8221;\nHighlight: A reading list outside the progressive box.\nBody\nMy weekend column used this season of campus protest as an opportunity to discuss the evolution of Columbia’s \ncore curriculum, whose readings on contemporary politics, I argued, usefully distill the core of contemporary \nprogressivism while leaving a great deal else by the wayside.\nI included some examples of ideas and writers that the present Columbia syllabus leaves out, but I wanted to give a \nlittle more attention to the question of what a supplement to the progressive approach would look like. If you were \ntrying to bring a great-books program all the way up to the present and you wanted to widen the ideological \naperture beyond Columbia’s progressive focus, what would you have your students read?\nOne answer is that the very idea of being up-to-date is a mistake because readings oriented explicitly to the present \nare everywhere in education and the point of a core curriculum is to stand a little bit apart, to connect you to the \nriches of the past — riches that have been sifted in a way that just isn’t possible with the publications and \narguments of the past few generations.\nI have some sympathy with this idea: If I were designing a core humanities program for high school students (not \nthat I’ve ever thought about this or anything), my strong impulse would be to just hit “stop” at World War II or 1965 \nand decline to make any judgment on what will be remembered as the great books of the recent past and present.\nBut Columbia’s core curriculum, while very much a great-books program in its execution, has also carried, since its \ninception in 1919, a mandate to address “the insistent problems of the present.” So one can criticize the ideological \nnarrowness of the contemporary readings while still recognizing that the syllabus is trying to fulfill its academic \nmandate, not betray it.\nHere, then, are four attempts at fulfilling that mandate but with a wider lens. I’m presenting these as potential \nmodules, packaged similarly to the way the current Columbia curriculum packages its modern readings under \n“anticolonialism,” “race, gender and sexuality” and “climate and futures.” Note that I’m imagining these as \nsupplements to those existing modules; if I were drawing up a complete syllabus, it would include more socialist \nand feminist and anticolonial perspectives. And obviously if tomorrow Columbia decided to supplement its syllabus \nalong these lines, it could choose (or excerpt from) only a few of the books and essays I’ve listed; I’m just trying to \nshow the range that each module might include.\nThe Secular and the Sacred\nHarvey Cox, “The Secular City”; Philip Rieff, “The Triumph of the Therapeutic”; Tom Wolfe, “The ‘Me’ Decade and \nthe Third Great Awakening”; Christopher Lasch, “The Culture of Narcissism”; Richard John Neuhaus, “The Naked \nPublic Square”; Charles Taylor, “A Secular Age.”\nWhat I’d Assign to Today’s College Students Ross Douthat\nTechnology and Its Discontents\nC.S. Lewis, “The Abolition of Man”; C.P. Snow, “The Two Cultures”; Marshall McLuhan, “Understanding Media”; \nNeil Postman, “Amusing Ourselves to Death”; Jaron Lanier, “You Are Not a Gadget”; Sherry Turkle, “Alone \nTogether.”\nAfter the Cold War\nFrancis Fukuyama, “The End of History?”; Samuel Huntington, “The Clash of Civilizations?”\nCommunity, Solidarity, Inequality\nRobert Nisbet, “The Quest for Community”; Michael Young, “The Rise of the Meritocracy”; Robert Putnam, “Bowling \nAlone”; my colleague David Brooks, “Bobos in Paradise”; Lasch, “The Revolt of the Elites.”\nYou’ll notice that each of these modules includes conservative-leaning writers but none of them are titled \n“conservatism.” In my column, I mentioned the dearth of representation for the most important nonprogressive \npolitical ideologies, meaning especially modern conservatism and neoliberalism, and you could imagine explicitly \nbuilding a module around that lacuna — with, say, Friedrich Hayek paired with James Burnham or Milton Friedman \nwith Roger Scruton. But I think if you’re trying to grasp the world through a few key texts, it’s better to come at \npolitical ideas a bit more from the side, via figures who are less associated with a specific ideology or team. \nFukuyama, for example, isn’t exactly an ideologist of neoliberalism, but if you read “The End of History?” (just the \noriginal essay, not necessarily the book), you’ll have a pretty good grasp of what the neoliberal era meant.\nFinally, I am under no illusions that the Columbia core curriculum or any other attempt at a collegiate canon is \nactually the place where progressive orthodoxy is forged or soon-to-be protesters discover their ideological beliefs. \nThe Columbia syllabus is interesting as a manifestation of a worldview, not as its origination; the point of origination \nis much more likely to be what future Ivy Leaguers are assigned in high school and what they’re given by the \nambient culture, which could mean anything from social justice extracurriculars to TikTok discourse to young adult \nfiction.\nSo if you asked me what I would assign to readers in their late teenage years, generally, to challenge (or at least \ncomplicate) progressive groupthink, I might not even start with any of the texts listed above. Instead, I might try to \nassemble a list of narrative works, mostly novels and some nonfiction, not all of which would be aesthetically \nnotable enough to fit into Columbia’s “literature humanities” syllabus but all of which would help broaden a too-\nnarrow ideological picture of the world.\nHere’s one such list, suitable for an enterprising high school senior or college freshman: Aldous Huxley, “Brave New \nWorld”; Lewis, “That Hideous Strength”; Joan Didion, “Slouching Towards Bethlehem” and “The White Album”; \nRalph Ellison, “Invisible Man”; V.S. Naipaul, “A Bend in the River”; Wolfe, “Radical Chic” and “The Bonfire of the \nVanities”; Philip Roth, “American Pastoral”; Michel Houellebecq, “The Elementary Particles”; P.D. James, “The \nChildren of Men.”\nThat’s enough for now. Get back to me when your favorite students are caught up.\nBreviary\nDwight Garner reads an enfant terrible.\nDan Hitchens attends a disco at the cathedral.\nLeah Libresco Sargeant contemplates Schrödinger’s persons.\nStanley Fish advises college administrators.\nRoss Barkan and Freddie deBoer consider the uses of book publishing.\nWhat I’d Assign to Today’s College Students Ross Douthat\nJamie McGregor Smith cannot make me love brutalist church architecture.\nThis Week in Decadence\n— Eric Goldman, “Generative A.I. Is Doomed” Santa Clara University (April 25)\nIt might be impossible to imagine today, but 1990s regulators often took a deferential and generally hands-off \napproach to the new technology. This stance was fueled by prevailing concerns that overly aggressive regulatory \nresponses could distort or harm the emergence of this important innovation. As Congress said in 1996, its policy \nwas “to preserve the vibrant and competitive free market that presently exists for the internet and other interactive \ncomputer services, unfettered by federal or state regulation.”\nIt was a remarkable and exceptional phase of regulator humility. In the mid-1990s, regulators could not anticipate or \npredict all of the internet’s uses that have emerged over the last three decades — or how those developments have \nbenefited society. Had regulators hard-coded their limited and myopic 1990s conceptions of the internet into law, \nthe internet never could have achieved those outcomes, and I think the world would be poorer for it. But mid-1990s \nregulators frequently admitted their myopia and unusually chose regulatory forbearance.\nGenerative A.I. will not get a similar reception from regulators. Regulators are intervening now, acting on their \nunenlightened 2020s conceptions of what generative A.I. does. Because we can’t anticipate what generative A.I. \nis capable of and how new innovative uses will emerge over time, the interventions taking place today will \nunavoidably restrict generative A.I.’s potential upside.\nPHOTO:  (PHOTOGRAPH BY Alain Pilon FOR THE NEW YORK TIMES)\nLoad-Date: May 4, 2024"
    },
    {
        "file_name": "reviews;_Amazon_is_rolling_out_a_generative_AI_feature_that_summarizes_Aug2023",
        "header": "Amazon is rolling out a generative AI feature that summarizes product",
        "media": "reviews; Amazon is rolling out a generative AI feature that summarizes",
        "time": "August 14, 2023",
        "section": "NATION WORLD",
        "length": "288 words",
        "byline": "HALELUYA HADERO",
        "story_text": "Amazon is rolling out a generative AI feature that summarizes product \nreviews; Amazon is rolling out a generative AI feature that summarizes \nproduct reviews for customers\nDayton Daily News (Ohio)\nAugust 14, 2023 Monday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 288 words\nByline: HALELUYA HADERO\nBody\nAmazon is rolling out a new generative AI feature that summarizes product reviews for customers.\nThe feature, which the company began testing earlier this year, is designed to help shoppers determine at a glance \nwhat other customers said about a product before they spend time reading through individual reviews. It will pick \nout common themes and summarize them in a short paragraph on the product detail page. \nThe company wrote in a blog post published Monday that the AI-generated reviews are now available to a subset of \nmobile shoppers in the U.S. across a \"broad\" selection of products. And it may be expanded to more shoppers and \nadditional categories of products in the \"coming months\" based on customer feedback, said Vaughn Schermerhorn, \nAmazon's director of community shopping. \nThe Seattle-based company has been looking for ways to integrate more artificial intelligence into its product \nofferings as the generative AI race heats up among tech companies. Amazon hasn't released its own high-profile \nAI chatbot or imaging tool. Instead, it's been focusing on services that will allow developers to build their own \ngenerative AI tools on its cloud infrastructure AWS. \nEarlier this year, Amazon CEO Andy Jassy said in his letter to shareholders that generative AI will be a \"big deal\" \nfor the company. He also said during an earnings call with investors last week that \"every single one\" of Amazon's \nbusinesses currently has multiple generative AI initiatives underway, including its devices unit, which works on \nproducts like the voice assistant Alexa. \nIn addition to the AI generated review, the company said Monday it will also offer a product insights feature that \nallows customers to surface common themes in reviews.\nGraphic\n \nThis image provided by shows Amazon shows the new generative AI product review feature. Amazon is rolling out \na generative AI feature that summarizes product reviews for customers. The company said in a blog post Monday, \nAug. 14, 2023, that it will use AI to pick out common themes in reviews and summarize them in a short paragraph \non the product detail page. (Amazon via AP)\nAmazon is rolling out a generative AI feature that summarizes product reviews Amazon is rolling out a \ngenerative AI feature that summarizes product reviews for ....\nLoad-Date: August 14, 2023"
    },
    {
        "file_name": "Stanley_executive_Nov2023",
        "header": "For financial services companies, India’s best market for tech talent: Morgan",
        "media": "Stanley executive",
        "time": "November 6, 2023",
        "section": "TECH & INTERNET",
        "length": "705 words",
        "byline": "Beena Parmar",
        "story_text": "For financial services companies, India’s best market for tech talent: Morgan \nStanley executive\nThe Economic Times\nNovember 6, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 705 words\nByline: Beena Parmar\nBody\nAmid an overwhelming demand for niche technology skills in the financial services industry, India is likely to be the \nbest market for such talent, a top executive at Morgan Stanley said.India is currently the second largest location in \nterms of tech headcount outside the US for the multinational financial services firms, Michael Pizzi, managing \ndirector and head of US banks & technology at Morgan Stanley, told ET.India has around 8,000 people, or one-third \nof its 24,000 global tech workforce, said Pizzi, who is on his first India visit to mark 30 years of the company’s \noperations in this country.“We came to India years ago for cost and efficiency, but we're here today for talent. This \nis one of the best, maybe the best market for technology talent in the world, and that's why we're here,” Pizzi \nsaid.Pizzi said the India tech team has more than doubled in the last three years. Morgan Stanley is on the lookout \nfor new talent to be added in the critical skill sets, especially across the newer technologies such as cloud and \ngenerative AI, he said, but did not say how many people it plans to hire.“There's a clear need for continuing to \nbuild talent in those areas ... And it's about where we can access the best engineering talent,” Pizzi said, adding: \n“We grew faster in India than what anyone thought.”In India, the company has established two global capability \ncentres (GCCs) — one in Mumbai (set up in 2003) and the second in Bengaluru (2014). These house multiple \nbusiness units like technology, operations, finance, fund services, legal and compliance, HR, prime brokerage, \ninternal audit, risk management, fixed income research and parametric.Morgan Stanley is expanding and investing \nin its investment banking business and the trading products its offers in the Indian market.Pizzi, who was appointed \nas the head of technology in January this year, was previously the chief executive of E*Trade, an online trading \nplatform for retail investors that was acquired by Morgan Stanley in 2020.Morgan Stanley is among the first financial \nservices firms to have a real tool in the marketplace for financial advisors in wealth management, using generative \nAI through the partnership with OpenAI before ChatGPT burst onto the market, he said. \nThe tool, AI @ Morgan Stanley Assistant, was developed by teams in India and the US.The financial services firm \nsees two opportunities — content retrieval or summarisation — where AI can immediately change the landscape of \nproductivity.Pizzi said India has helped support and build the models which helped Morgan Stanley bring its \nintellectual capital into tech advisors’ hands in seconds and in an easily digestible format.“Think of it as having our \nchief investment strategist, chief global economist and global equities strategist on call 24 hours a day,” he \nadded.He said: “As the firm grows, our presence in India grows ... As we take on new projects, it will almost \nuniversally involve technologists in India. As we scale up and build up across all the different dimensions of \ngenerative AI, we continue to do our cloud work.”On India’s digitisation, Pizzi said: “What's happening in India to \nmake it (digitisation) public infrastructure is amazing because the power it has, it's like physical infrastructure...to \nfundamentally change and reshape the economy.”Globally, Morgan Stanley manages $6.2 trillion of client assets \nacross both wealth management and investment management business as of the end of September quarter. The \nfirm provides investment banking, securities, wealth management and investment management services.Pizzi said \nbesides having several senior-level female technologists, overall women comprised 36% (ex-campus) and 44% of \ncampus of all new lateral hires by the company in India in 2022. It also launched a Return to Work (RTW) \nFor financial services companies, India ’s best market for tech talent: Morgan Stanley executive\nprogramme, which provides opportunities for skilled professionals to re-engage with the workforce after a career \nbreak of over two years. In India, this was launched in 2015 as a 16-week paid internship.“We have several senior \nwomen technologists in our India organisation and in addition to gender, we also have a focus on LGBT+, people \nwith disabilities and veterans,” he said. For Reprint Rights: timescontent.com\nLoad-Date: November 6, 2023"
    },
    {
        "file_name": "Newsletter_May2023",
        "header": "Markets Expect the Fed to Raise Rates Despite Banking Turmoil; DealBook",
        "media": "Newsletter",
        "time": "May 4, 2023",
        "section": "BUSINESS",
        "length": "1908 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced and Lauren",
        "story_text": "Markets Expect the Fed to Raise Rates Despite Banking Turmoil; DealBook \nNewsletter\nThe New York Times \nMay 3, 2023 Wednesday 19:39 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1908 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced and Lauren \nHirsch\nHighlight: A ‘shock pause’ by the central bank would spook an already jittery market, one analyst said, even as \nshares in regional lenders fall.\nBody\nA ‘shock pause’ by the central bank would spook an already jittery market, one analyst said, even as shares in \nregional lenders fall.\nBanks in focus as the Fed weighs its rates move \nIf market predictions are correct, the Fed on Wednesday will raise borrowing costs by a quarter of a percentage \npoint, even as growing turmoil in the stocks of regional banks threatens to choke off credit to businesses and \nconsumers, pushing the economy into recession.\nThe decision comes amid a brutal sell-off in regional banks’ shares, which has wiped billions off smaller lenders’ \nmarket valuations. Investors have been worried about the health of these banks since March, when Silicon Valley \nBank collapsed in one of the most prominent bank failures in U.S. history.\nRegulators had hoped that the sale of the embattled First Republic Bank to JPMorgan Chase this week would \ncontain the panic. But short sellers, investors who profit off bets that stock prices will fall, have continued to take \naim at regional lenders like PacWest, Western Alliance and Zions Bancorp. (Shares in PacWest and Western \nAlliance are down again in premarket trading.)\nThe market carnage could result in more pain for regional banks. Falling prices may cause C.F.O.s to say, “‘You \nknow what, maybe I should think about diversification and moving my funding’” out of these lenders, Ryan Nash, a \nresearch director at Goldman Sachs, said in a webinar on Tuesday.\nHe added that while “most of the large failures are likely behind us, I do think there is a risk that pressure on stock \nprices could reinvigorate” worries about the sector’s health.\nMeanwhile, the Fed faces political pressure. Ten progressive lawmakers, including Senators Elizabeth Warren and \nBernie Sanders, urged the central bank to pause its rate hikes to “avoid engineering a recession that destroys jobs \nand crushes small businesses.”\nThe lawmakers cautioned Jay Powell, the Fed chair, that raising borrowing prices could further compound trouble \nfor beleaguered banks.\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nNone of this is likely to deter the Fed from raising rates on Wednesday, analysts said. Indeed, a “shock pause” \nwould “do more harm than good” by spooking an already jittery market, according to Elsa Lignos, the global head of \nFX strategy at RBC Capital Markets.\nBut economists increasingly believe that Wednesday’s increase will be the last in this tightening cycle. Watch what \nMr. Powell says about upcoming Fed meetings: If he suggests that the central bank needs to remain hawkish on \nrates to fight inflation, that could send stocks — especially those of regional banks — especially hard.\nMs. Lignos advised paying attention to what Mr. Powell says about whether “additional policy firming may be \nappropriate,” a line of guidance he used after the March meeting: If that wording is softened or deleted altogether, \nshe said, it may indicate a dovish turn by the Fed.\nHERE’S WHAT’S HAPPENING \nElon Musk threatens to give away NPR’s Twitter account. In an email exchange with a reporter at the news outlet, \nMr. Musk wrote that he could give the @NPR handle to “another company” if the broadcaster did not start tweeting \nagain. NPR stopped posting on Twitter in protest last month after the platform labeled it “state-controlled.”\nHouse Democrats work on a long-shot plan to avert a U.S. default. It involves a so-called discharge petition that \nwould bypass Speaker Kevin McCarthy but would require Democrats to win over some Republicans. Meanwhile, \nthe White House is debating whether to pursue what is effectively a constitutional challenge that would let it \nsidestep Congress and raise the debt limit.\nHoward Schultz’s final quarter is a success. The coffee chain reported better-than-expected earnings for the first \nthree months of the year, during which Mr. Schultz handed over the C.E.O. title to Laxman Narasimhan. The \ncompany benefited from a surge in sales there after Covid-19 restrictions were lifted; however, Starbucks shares \nwere down 5 percent in premarket trading after it kept its guidance for the second half of 2023 unchanged.\nDonald Trump ends a boycott of CNN. The former president is set to participate in a town-hall-style meeting on May \n10 organized by the news network. His appearance may be a sign that the Republican presidential candidate, who \nhasn’t appeared on CNN since 2016, may be broadening his media profile beyond Fox News and other \nconservative channels.\nLate night shows go dark on the first day of a writers’ strike. “The Tonight Show Starring Jimmy Fallon” was a \nrepeat on Tuesday, and new episodes of shows hosted by Stephen Colbert and Jimmy Kimmel have been \nsuspended as movie and TV writers hit the picket lines. Unlike in the 1990s, late-night stars have publicly signaled \nsupport for the unions.\nHindenburg turns the tables on Icahn \nOver nearly a half-century, Carl Icahn has shaken up Wall Street as a corporate raider and activist shareholder, \nmaking corporate titans bow down to his demands and change strategy.\nBut Tuesday, his publicly traded company became a target of Hindenburg Research, the short-seller firm that has \nmade its name in recent years by taking on the Indian tycoon Gautam Adani and the Twitter co-founder Jack \nDorsey.\nHindenburg accused Mr. Icahn Enterprises of being overvalued. The company trades well above its net asset value, \nunlike similar financial vehicles run by Bill Ackman and Dan Loeb. Hindenburg also called out what it said was an \nunjustifiably hefty dividend being financed by stock sales.\n“Icahn has been using money taken in from new investors to pay out dividends to old investors,” the firm wrote in a \npublic report. (Hindenburg is betting that Icahn Enterprises’s shares will fall; the company’s stock tumbled 20 \npercent on Tuesday.)\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nHindenburg also called out Jefferies, which it said was the only large investment bank to publish research on Icahn \nEnterprises — and also helps the company sell stock.\nMr. Icahn punched back. “We believe the self-serving short seller report published by Hindenburg Research today \nwas intended solely to generate profits on Hindenburg’s short position at the expense of I.E.P.’s long-term unit \nholders,” the company said in a statement, adding that it stands by its disclosures.\nHindenburg got one prominent endorser: Mr. Ackman. The hedge fund mogul memorably clashed with Mr. Icahn \nover the prospects of Herbalife, the supplements company that Ackman had shorted. (Remember the verbal brawl \nbetween the two on CNBC that gripped Wall Street?)\nThey made peace — but time may not have healed all wounds. “There is a karmic quality to this short report that \nreinforces the notion of a circle of life and death,” Mr. Ackman tweeted of Hindenburg’s report. “As such, it is a must \nread.”\nArtificial intelligence 101 \nShares in education companies plunged on Tuesday, after Dan Rosensweig, the C.E.O. of Chegg, warned that \nChatGPT was cannibalizing growth. The sell-off was one of the biggest indications yet of how companies may \nstruggle to protect their legacy businesses from a powerful new crop of artificial intelligence tools that have captured \nthe public’s imagination.\nChatGPT began hitting Chegg’s business in March, Rosensweig told analysts on an earnings call this week. It was \namong the first times a C.E.O. offered a candid take on the chatbot’s potential financial toll on a company. “We now \nbelieve it’s having an impact on our new customer growth rate,” he said.\nThe comments spooked investors. Chegg’s stock fell more than 48 percent on Tuesday, and shares in other \neducation companies also tumbled: The London-listed Pearson slid 15 percent, and the language learning platform \nDuolingo dropped 10 percent.\nRosensweig called the sell-off “extraordinarily overblown” in an interview afterward with CNBC, comments that \nhelped shares regain some lost ground.\nThe market impact is only a hint of the disruption A.I. will cause. “These swings in share price demonstrate that \nmarkets haven’t started to price in the effect of breakthroughs in generative A.I. — even in the sector where its \nimpact is the most apparent,” Nathan Benaich, founder of the A.I.-focused investment firm Air Street Capital and an \nauthor of the State of A.I. Report, who told DealBook that “education businesses will only be the first dominoes to \nfall.”\nIn other A.I. news:\n• Lina Khan, the chair of the Federal Trade Commission, outlines her vision for regulating A.I. in a Times \nOpinion guest essay: “Although these tools are novel, they are not exempt from existing rules,” she writes.\n• Inflection AI, a start-up created by the LinkedIn co-founder Reid Hoffman and Mustafa Suleyman, a co-\nfounder of Google DeepMind, introduced Pi, a chatbot that is intended to be more conversational than rival \nofferings like ChatGPT and Google’s Bard.\n• Cohere, a Toronto-based A.I. start-up, raised $250 million at a valuation of about $2 billion. Backers included \nthe tech giants Salesforce and Nvidia.\n‘It’s not how white men fight’ \nMore details are emerging about what may have ultimately led to Tucker Carlson’s firing at Fox News last week: \nThe New York Times reports that the evidence uncovered during the discovery phase of the Dominion Voting \nSystems defamation lawsuit against the media company included a particularly inflammatory text message that the \ntelevision host had sent to a producer hours after the Jan. 6 riot at the Capitol.\nMarkets Expect the Fed to Raise Rates Despite Banking Turmoil DealBook Newsletter\nFrom Carlson’s text message:\nJumping a guy like that is dishonorable obviously. It’s not how white men fight. Yet suddenly I found myself rooting \nfor the mob against the man, hoping they’d hit him harder, kill him. I really wanted them to hurt the kid. I could taste \nit.\nThen somewhere deep in my brain, an alarm went off: this isn’t good for me. I’m becoming something I don’t want \nto be. The Antifa creep is a human being. Much as I despise what he says and does, much as I’m sure I’d hate him \npersonally if I knew him, I shouldn’t gloat over his suffering.\nThe Fox board learned of the text only the day before the Dominion trial was set to begin, and told top executives \nthat it would hire the top-flight law firm Wachtell, Lipton, Rosen &amp; Katz to investigate Carlson. It isn’t clear how \nsignificant this particular message was to Fox’s decision-making — but within days, the company agreed to pay \n$787.5 million to settle Dominion’s lawsuit, and within a week, Carlson was out.\nTHE SPEED READ \nDeals\n• Inside the first days of Harvey Schwartz’s tenure as C.E.O. of Carlyle Group: lots of listening sessions, but no \ndrastic restructuring of the investment firm — yet. (FT)\n• Lilium, a German air-taxi start-up that went public via SPAC, plans to sell up to $250 million worth of stock to \nfinance development of its electric jet. (Reuters)\nPolicy\n• Morgan Stanley is in discussions to settle federal investigations into its block-trading business. (FT)\nBest of the rest\n• Shein, the fast-fashion giant, is embarking on a charm offensive to counter criticism of its ties to China and \naccusations of copycat designs ahead of a potential I.P.O. (NYT)\n• Anheuser-Busch InBev has reportedly promised free beer and more to Bud Light distributors to compensate \nfor blowback from an ad campaign featuring a transgender influencer. (WSJ)\n• “The true cost of our obsession with superfoods like avocado, açaí, and durian.” (Insider)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: There’s added political and market pressure on the Fed today ahead of its rates decision. \n(PHOTOGRAPH BY Leah Millis/Reuters FOR THE NEW YORK TIMES)\nLoad-Date: May 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2023",
        "header": "In A.I. Race, Microsoft and Google Choose Speed Over Caution",
        "media": "The New York Times - International Edition",
        "time": "April 10, 2023",
        "section": "TECHNOLOGY",
        "length": "1880 words",
        "byline": "Nico Grant and Karen Weise",
        "story_text": "In A.I. Race, Microsoft and Google Choose Speed Over Caution\nThe New York Times - International Edition\nApril 11, 2023 Tuesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1880 words\nByline: Nico Grant and Karen Weise\nDateline: SAN FRANCISCO \nBody\nABSTRACT\nTechnology companies were once leery of what some artificial intelligence could do. Now the priority is winning \ncontrol of the industry's next big thing.\nFULL TEXT\n         April 9,2023, Sunday         Online Correction:              \nThis article has been revised to reflect the following correction: An earlier version of this article misstated the \nnumber of years that have passed since Microsoft shut down a chatbot called Tay. It was seven years ago, not five. \nCORRECTION APPENDED \nTechnology companies were once leery of what some artificial intelligence could do. Now the priority is winning \ncontrol of the industry's next big thing.       \nIn March, two Google employees, whose jobs are to review the company's artificial intelligence products, tried to \nstop Google from launching an A.I. chatbot. They believed it generated inaccurate and dangerous statements.       \nTen months earlier, similar concerns were raised at Microsoft by ethicists and other employees. They wrote in \nseveral documents that the A.I. technology behind a planned chatbot could flood Facebook groups with \ndisinformation, degrade critical thinking and erode the factual foundation of modern society.       \nThe companies released their chatbots anyway. Microsoft was first, with a splashy event in February to reveal an \nA.I. chatbot woven into its Bing search engine. Google followed about six weeks later with its own chatbot, Bard.       \nThe aggressive moves by the normally risk-averse companies were driven by a race to control what could be the \ntech industry's next big thing - generative A.I., the powerful new technology that fuels those chatbots.       \nThat competition took on a frantic tone in November when OpenAI, a San Francisco start-up working with Microsoft, \nreleased ChatGPT, a chatbot that has captured the public imagination and now has an estimated 100 million \nmonthly users.       \nThe surprising success of ChatGPT has led to a willingness at Microsoft and Google to take greater risks with their \nethical guidelines set up over the years to ensure their technology does not cause societal problems, according to \n15 current and former employees and internal documents from the companies.       \nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nThe urgency to build with the new A.I. was crystallized in an internal email sent last month by Sam Schillace, a \ntechnology executive at Microsoft. He wrote in the email, which was viewed by The New York Times, that it was an \n\"absolutely fatal error in this moment to worry about things that can be fixed later.\"       \nWhen the tech industry is suddenly shifting toward a new kind of technology, the first company to introduce a \nproduct \"is the long-term winner just because they got started first,\" he wrote. \"Sometimes the difference is \nmeasured in weeks.\"       \nLast week, tension between the industry's worriers and risk-takers played out publicly as more than 1,000 \nresearchers and industry leaders, including Elon Musk and Apple's co-founder Steve Wozniak, called for a six-\nmonth pause in the development of powerful A.I. technology. In a public letter, they said it presented \"profound risks \nto society and humanity.\"       \nRegulators are already threatening to intervene. The European Union proposed legislation to regulate A.I., and Italy \ntemporarily banned ChatGPT last week. In the United States, President Biden on Tuesday became the latest official \nto question the safety of A.I.       \n\"Tech companies have a responsibility to make sure their products are safe before making them public,\" he said at \nthe White House. When asked if A.I. was dangerous, he said: \"It remains to be seen. Could be.\"       \nThe issues being raised now were once the kinds of concerns that prompted some companies to sit on new \ntechnology. They had learned that prematurely releasing A.I. could be embarrassing. Seven years ago, for \nexample, Microsoft quickly pulled a chatbot called Tay after users nudged it to generate racist responses.       \nResearchers say Microsoft and Google are taking risks by releasing technology that even its developers don't \nentirely understand. But the companies said that they had limited the scope of the initial release of their new \nchatbots, and that they had built sophisticated filtering systems to weed out hate speech and content that could \ncause obvious harm.       \nNatasha Crampton, Microsoft's chief responsible A.I. officer, said in an interview that six years of work around A.I. \nand ethics at Microsoft had allowed the company to \"move nimbly and thoughtfully.\" She added that \"our \ncommitment to responsible A.I. remains steadfast.\"       \nGoogle released Bard after years of internal dissent over whether generative A.I.'s benefits outweighed the risks. It \nannounced Meena, a similar chatbot, in 2020. But that system was deemed too risky to release, three people with \nknowledge of the process said. Those concerns were reported earlier by The Wall Street Journal.       \nLater in 2020, Google blocked its top ethical A.I. researchers, Timnit Gebru and Margaret Mitchell, from publishing a \npaper warning that so-called large language models used in the new A.I. systems, which are trained to recognize \npatterns from vast amounts of data, could spew abusive or discriminatory language. The researchers were pushed \nout after Dr. Gebru criticized the company's diversity efforts and Dr. Mitchell was accused of violating its code of \nconduct after she saved some work emails to a personal Google Drive account.       \nDr. Mitchell said she had tried to help Google release products responsibly and avoid regulation, but instead \"they \nreally shot themselves in the foot.\"       \nBrian Gabriel, a Google spokesman, said in a statement that \"we continue to make responsible A.I. a top priority, \nusing our A.I. principles and internal governance structures to responsibly share A.I. advances with our users.\"       \nConcerns over larger models persisted. In January 2022, Google refused to allow another researcher, El Mahdi El \nMhamdi, to publish a critical paper.       \nDr. El Mhamdi, a part-time employee and university professor, used mathematical theorems to warn that the \nbiggest A.I. models are more vulnerable to cybersecurity attacks and present unusual privacy risks because they've \nprobably had access to private data stored in various locations around the internet.       \nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nThough an executive presentation later warned of similar A.I. privacy violations, Google reviewers asked Dr. El \nMhamdi for substantial changes. He refused and released the paper through École Polytechnique.       \nHe resigned from Google this year, citing in part \"research censorship.\" He said modern A.I.'s risks \"highly \nexceeded\" the benefits. \"It's premature deployment,\" he added.       \nAfter ChatGPT's release, Kent Walker, Google's top lawyer, met with research and safety executives on the \ncompany's powerful Advanced Technology Review Council. He told them that Sundar Pichai, Google's chief \nexecutive, was pushing hard to release Google's A.I.       \nJen Gennai, the director of Google's Responsible Innovation group, attended that meeting. She recalled what Mr. \nWalker had said to her own staff.       \nThe meeting was \"Kent talking at the A.T.R.C. execs, telling them, 'This is the company priority,'\" Ms. Gennai said \nin a recording that was reviewed by The Times. \"'What are your concerns? Let's get in line.'\"       \nMr. Walker told attendees to fast-track A.I. projects, though some executives said they would maintain safety \nstandards, Ms. Gennai said.       \nHer team had already documented concerns with chatbots: They could produce false information, hurt users who \nbecome emotionally attached to them and enable \"tech-facilitated violence\" through mass harassment online.       \nIn March, two reviewers from Ms. Gennai's team submitted their risk evaluation of Bard. They recommended \nblocking its imminent release, two people familiar with the process said. Despite safeguards, they believed the \nchatbot was not ready.       \nMs.Gennai changed that document. She took out the recommendation and downplayed the severity of Bard's risks, \nthe people said.       \nMs. Gennai said in an email to The Times that because Bard was an experiment, reviewers were not supposed to \nweigh in on whether to proceed. She said she \"corrected inaccurate assumptions, and actually added more risks \nand harms that needed consideration.\"       \nGoogle said it had released Bard as a limited experiment because of those debates, and Ms. Gennai said \ncontinuing training, guardrails and disclaimers made the chatbot safer.       \nGoogle released Bard to some users on March 21. The company said it would soon integrate generative A.I. into \nits search engine.       \nSatya Nadella, Microsoft's chief executive, made a bet on generative A.I. in 2019 when Microsoft invested $1 \nbillion in OpenAI. After deciding the technology was ready over the summer, Mr. Nadella pushed every Microsoft \nproduct team to adopt A.I.       \nMicrosoft had policies developed by its Office of Responsible A.I., a team run by Ms. Crampton, but the guidelines \nwere not consistently enforced or followed, said five current and former employees.       \nDespite having a \"transparency\" principle, ethics experts working on the chatbot were not given answers about \nwhat data OpenAI used to develop its systems, according to three people involved in the work. Some argued that \nintegrating chatbots into a search engine was a particularly bad idea, given how it sometimes served up untrue \ndetails, a person with direct knowledge of the conversations said.       \nMs. Crampton said experts across Microsoft worked on Bing, and key people had access to the training data. The \ncompany worked to make the chatbot more accurate by linking it to Bing search results, she added.       \nIn A.I. Race, Microsoft and Google Choose Speed Over Caution\nIn the fall, Microsoft started breaking up what had been one of its largest technology ethics teams. The group, \nEthics and Society, trained and consulted company product leaders to design and build responsibly. In October, \nmost of its members were spun off to other groups, according to four people familiar with the team.       \nThe remaining few joined daily meetings with the Bing team, racing to launch the chatbot. John Montgomery, an A.I. \nexecutive, told them in a December email that their work remained vital and that more teams \"will also need our \nhelp.\"       \nAfter the A.I.-powered Bing was introduced, the ethics team documented lingering concerns. Users could become \ntoo dependent on the tool. Inaccurate answers could mislead users. People could believe the chatbot, which uses \nan \"I\" and emojis, was human.       \nIn mid-March, the team was laid off, an action that was first reported by the tech newsletter Platformer. But Ms. \nCrampton said hundreds of employees were still working on ethics efforts.       \nMicrosoft has released new products every week, a frantic pace to fulfill plans that Mr. Nadella set in motion in the \nsummer when he previewed OpenAI's newest model.       \nHe asked the chatbot to translate the Persian poet Rumi into Urdu, and then write it out in English characters. \"It \nworked like a charm,\" he said in a February interview. \"Then I said, 'God, this thing.'\"       \nMike Isaac contributed reporting. Susan C. Beachy contributed research.       \nMike Isaac contributed reporting. Susan C. Beachy contributed research. \nLoad-Date: April 10, 2023"
    },
    {
        "file_name": "Los_Angeles_Times_Feb2024",
        "header": "AI robocalls can fool voters, so FCC has made them illegal",
        "media": "Los Angeles Times",
        "time": "February 9, 2024",
        "section": "MAIN NEWS; National Desk; Part A; Pg. 1",
        "length": "527 words",
        "byline": "Associated Press",
        "story_text": "AI robocalls can fool voters, so FCC has made them illegal\nLos Angeles Times\nFebruary 9, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; National Desk; Part A; Pg. 1\nLength: 527 words\nByline: Associated Press\nDateline:  NEW YORK  \nBody\nThe Federal Communications Commission on Thursday outlawed robocalls that contain voices generated by \nartificial intelligence, a decision that sends a clear message that exploiting the technology to scam people and \nmislead voters won't be tolerated.\nThe unanimous ruling targets robocalls made with AI voice-cloning tools under the Telephone Consumer Protection \nAct, a 1991 law restricting junk calls that use artificial and prerecorded voice messages.\nThe announcement comes as New Hampshire authorities are advancing their investigation into AI-generated \nrobocalls that mimicked President Biden's voice to discourage people from voting in the state's presidential primary \nlast month.\nEffective immediately, the regulation empowers the FCC to fine companies that use AI voices in their calls or block \nthe service providers that carry them. It also opens the door for call recipients to file lawsuits and gives state \nattorneys general a new mechanism to crack down on violators, according to the FCC.\nThe agency's chairwoman, Jessica Rosenworcel, said bad actors have been using AI-generated voices in robocalls \nto misinform voters, impersonate celebrities and extort from family members.\n\"It seems like something from the far-off future, but this threat is already here,\" Rosenworcel said Wednesday as \nthe commission was considering the regulations. \"All of us could be on the receiving end of these faked calls, so \nthat's why we felt the time to act was now.\"\nUnder the consumer protection law, telemarketers generally cannot use automated dialers or artificial or \nprerecorded voice messages to call cellphones, and they cannot make such calls to landlines without written \nconsent from the recipient.\nThe new ruling classifies AI-generated voices in robocalls as \"artificial\" and thus enforceable by the same \nstandards, the FCC said.\nThose who break the law can face steep fines, with a maximum of more than $23,000 per call, the FCC said. The \nagency has previously used the consumer law to clamp down on robocallers interfering in elections, including \nimposing a $5-million fine on two conservative hoaxers for falsely warning people in predominantly Black areas that \nvoting by mail could heighten their risk of arrest, debt collection and forced vaccination.\nAI robocalls can fool voters, so FCC has made them illegal\nThe law also gives call recipients the right to take legal action and potentially recover up to $1,500 in damages for \neach unwanted call.\nJosh Lawson, director of AI and democracy at the Aspen Institute, said that even with the FCC's ruling, voters \nshould prepare themselves for personalized spam to target them by phone, text and social media.\n\"The true dark hats tend to disregard the stakes and they know what they're doing is unlawful,\" he said.\nSophisticated generative AI tools, from voice-cloning software to image generators, already are in use in elections \nin the U.S. and around the world.\nLast year, as the U.S. presidential race got underway, several campaign ads used AI-generated audio or imagery, \nand some candidates experimented with using AI chatbots to communicate with voters. Bipartisan efforts in \nCongress have sought to regulate AI in political campaigns, but no federal legislation has passed.\nLoad-Date: February 9, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I. Leaders Lobby Congress as China Tensions Rise",
        "media": "The New York Times",
        "time": "March 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "810 words",
        "byline": "By Cecilia Kang",
        "story_text": "A.I. Leaders Lobby Congress as China Tensions Rise\nThe New York Times\nMarch 28, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 810 words\nByline: By Cecilia Kang\nBody\nIn recent weeks, American lawmakers have moved to ban the Chinese-owned app TikTok. President Biden \nreinforced his commitment to overcome China's rise in tech. And the Chinese government added chips from Intel \nand AMD to a blacklist of imports.\nNow, as the tech and economic cold war between the United States and China accelerates, Silicon Valley's leaders \nare capitalizing on the strife with a lobbying push for their interests in another promising field of technology: artificial \nintelligence. \n  On May 1, more than 100 tech chiefs and investors, including Alex Karp, the head of the defense contractor \nPalantir, and Roelof Botha, the managing partner of the venture capital firm Sequoia Capital, will come to \nWashington for a daylong conference and private dinner focused on drumming up more hawkishness toward \nChina's progress in A.I.\n  Dozens of lawmakers, including Speaker Mike Johnson, Republican of Louisiana, will also attend the event, the \nHill & Valley Forum, which will include fireside chats and keynote discussions with members of a new House A.I. \ntask force.\n  Tech executives plan to use the event to directly lobby against A.I. regulations that they consider onerous, as well \nas ask for more government spending on the technology and research to support its development. They also plan \nto ask to relax immigration restrictions to bring more A.I. experts to the United States.\n  The event highlights an unusual area of agreement between Washington and Silicon Valley, which have long \nclashed on topics like data privacy, children's online protections and even China.\n  ''At the end of the day, whether you are in industry or government, or whatever side of the aisle you are on, we \nplay for team America,'' said Representative Jay Obernolte of California, the Republican chair of the House A.I. \nTask Force, who will give opening remarks at the conference.\n  After the rise over the past year of generative A.I. -- technology that has the potential to fundamentally shift \nproductivity, innovation and employment trends -- lobbying on the topic has exploded. Last year, more than 450 \ncompanies, nonprofits, universities and trade groups reported lobbying on A.I., more than double the number of \norganizations in the previous year, according to OpenSecrets, a nonprofit research group. Palantir more than \ndoubled its spending on lobbying last year to $5 million, its highest level on record.\nA.I. Leaders Lobby Congress as China Tensions Rise\n  As tech leaders capitalize on anti-China fervor in Washington, civil society groups and academics warn that \ndebates over competition for tech leadership could hurt efforts to regulate potential harms, such as the risks that \nsome A.I. tools could kill jobs, spread disinformation, and disrupt elections.\n  ''The dynamics of this U.S. v. China race has profound implications because on the other side of slowing down \nChina is minimal friction and regulation for U.S. companies,'' said Amba Kak, who is the executive director of the AI \nNow Institute, a research firm, and a former senior adviser on A.I. to the Federal Trade Commission.\n  A.I. experts say China lags the United States in generative A.I. by at least a year and may be falling further \nbehind, although a new study suggests that it is ahead in the talent.\n  May's event is being organized by Jacob Helberg, a senior adviser to Palantir and a member of the U.S.-China \nEconomic and Security Review Commission, which reports to Congress on national security threats posed by \nChina. He expanded this year's forum from the first gathering he organized last year, which was a private dinner \nfocused largely on the threat of TikTok, which is owned by Beijing-based ByteDance.\n  In addition to A.I., lawmakers speaking at the event in the Capitol will push for the Senate to pass legislation to \nban TikTok, and Tom Mueller, a founding employee of SpaceX, will speak about the space race between the United \nStates and China. Attendees will include Senator Mike Rounds, Republican of South Dakota and the ranking \nmember of the Armed Services Committee, and Representative Ritchie Torres, a New York Democrat on the House \nSelect Committee on the Chinese Communist Party.\n  ''Tech companies can't be neutral any more,'' Mr. Helberg said, adding that he recuses himself from any work \ninvolving contracts on the U.S.-China Economic and Security Review Commission that could give Palantir an \nadvantage.\n  Venture capitalists attending the event have dozens of A.I. investments. Sequoia has invested in more than 70 A.I. \nstartups. Khosla Ventures, a $15 billion venture firm, has several investments, including in OpenAI, the company \nbehind the ChatGPT chatbot.\n  ''It's become even more obvious, even more critical, that we treat China as an adversary,'' said Vinod Khosla, the \nhead of Khosla Ventures who will speak at the forum. ''What I'm worrying about is Western values versus a different \nset of values in China.''\nhttps://www.nytimes.com/2024/03/27/technology/ai-lobby-china.html\nGraphic\n \nPHOTOS: Clockwise from top left: Jacob Helberg, a member of the U.S.-China Economic and Security Review \nCommission\nHouse Speaker Mike Johnson\nand Representative Ritchie Torres, a Democrat on the House Select Committee on the Chinese Communist Party. \n(PHOTOGRAPHS BY JASON ANDREW FOR THE NEW YORK TIMES\nHAIYUN JIANG FOR THE NEW YORK TIMES\n AMIR HAMJA/THE NEW YORK TIMES) This article appeared in print on page B4.               \nLoad-Date: March 28, 2024\nA.I. Leaders Lobby Congress as China Tensions Rise"
    },
    {
        "file_name": "New_York_Observer_Mar2024",
        "header": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap",
        "media": "New York Observer",
        "time": "March 7, 2024",
        "section": "",
        "length": "457 words",
        "byline": "Nhari Djan and Sissi Cao",
        "story_text": "Head of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap\nNew York Observer\nMarch 7, 2024 Thursday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 457 words\nByline: Nhari Djan and Sissi Cao\nBody\nMeta is in the final phase of rebuilding its A.I. recommendation models as part of the company's \"tech roadmap that \ngoes to 2026,\" meaning that a series of generative A.I. features are about to come to Meta's suite of social media \nproducts, Tom Alison, Meta's head of Facebook, said at the Morgan Stanley Technology, Media and \nTelecommunications conference yesterday (Mar. 6).\nLast year, inspired by an industrywide interest in generative A.I., Meta experimented with a new recommendation \nmodel in Reels, Facebook's short-form video sharing platform. The new model helped Facebook gain as much as \n10 percent in Reels watch time on the Facebook app, Alison said, proving that the model was \"learning from the \ndata much more efficiently than the previous generation.\"\n\"We've really focused on investing more in making sure that we can scale these models up with the right kind of \nhardware,\" Alison said onstage yesterday. \"Instead of just powering Reels, we're working on a project to power our \nentire video ecosystem with this single model.\"\nFor example, \"If you see something that you're into in Reels, and then you go back to the Feed, we can show you \nmore similar content,\" he explained. To date, Meta has used a separate model for each of its products. It's looking \nto build a single model for multiple products. \"If we get this right, not only will the recommendations be more \nengaging and more relevant, but we think the responsiveness of them can improve as well,\" Alison said.\nMeta is also experimenting integrating A.I. chatting features within Feed and Groups products. In Feed, for \ninstance, if a user sees a recommended post about Taylor Swift, they could perhaps \"easily just click a button and \nsay, 'Hey Meta AI, tell me more about what I'm seeing with Taylor Swift right now,'\" Alison said.\nHe illustrated with another example in Groups. \"If you are a home hobbyist baker, you're probably in a baking group \non Facebook, and you can go in and ask a question and say, Hey, how come my sourdough bread isn't rising \nproperly? There are people in the group that will come in and answer your question. But if for some reason they \ndon't, we've enabled meta A.I. to come in and answer your question in the comments,\" Alison said. \nAlison, 46, has been with Meta since 2010. He led the development of several Facebook products, including News \nFeed. He named head of Facebook in 2021 in the year Mark Zuckerberg changed the parent company's name to \nMeta.\nMeta is one of the largest buyers of Nvidia's graphics processing units, or GPUs, having spent billions of dollars on \nacquiring these chips essential in training A.I. models. Alison said the company has accumulated a massive \nstockpile of GPUs to power its ambitious generative A.I. efforts.\nLoad-Date: March 7, 2024\nHead of Facebook Tom Alison Shares Update On Meta's A.I. Roadmap"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Oct2023",
        "header": "HIGHMARK HEALTH DIPPING A TOE IN AI POOL",
        "media": "Pittsburgh Post-Gazette",
        "time": "October 11, 2023",
        "section": "ASECTION; Pg. A-1",
        "length": "986 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "HIGHMARK HEALTH DIPPING A TOE IN AI POOL\nPittsburgh Post-Gazette\nOctober 11, 2023 Wednesday\nSOONER EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 986 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nVisit your Allegheny Health Network doctor to talk over your medical problems and soon a machine may be \nlistening in, adding its own advice to what the physician tells you about staying healthy - stuff that may have been \nmissed in the conversation.\nThe \"machine\" is new software Highmark Health has been road testing - released for commercial use Monday by \nAlphabet subsidiary Google - that carries the promise of dramatically improving health care and streamlining \nHighmark's insurance operations. Google's Vertex AI Search is being introduced in virtually every aspect of \nHighmark's business, Highmark Health's Chief Analytics Officer Richard Clarke said Tuesday.\n\"We are frankly deploying it across our enterprise,\" he said.\nAmbient listening in doctors' offices may be a couple years off at Highmark Health's 14-hospital system of 2,600 \nphysicians, but for now, Highmark is exploring whether the software's contributions to the doctor-patient \nconversation will be in real time - like a third person sitting in the room - or sent to the patient after the visit by text, \nemail or patient portal message.\n\"We really see this as a multi-modality,\" Mr. Clarke said. \"The current focus is really on actual medical \ndocumentation,\" a physician chore that eats up hours a day and leads to caregiver burnout.\nIt's also expensive: Administrative costs rose $18 billion or 30% to $60 billion in 2022, according to the Council for \nAffordable Healthcare, a Washington D.C.-based nonprofit.\nVertex AI Search is a generative artificial intelligence search platform that's tailored to health care and the life \nsciences. It can also be tailored specifically to Highmark's purposes, Mr. Clarke said.\n\"We're teaching it how to speak Highmark,\" he said. \"It's going to have a vey meaningful impact in the clinical \nsetting.\"\nGoogle announced Monday that Highmark Health, the corporate parent of the Downtown-based $26 billion health \ninsurance and hospital system, had been among the U.S. health systems piloting Vertex AI Search. What \ndifferentiates the search engine is its heft in quickly answering questions from vast stores of internal information, \nincluding doctor's notes, medical records and scans.\nMr. Clarke said the new software would be rolled out gradually systemwide, which patients and health plan \nmembers might begin to notice in doctor visits and other interactions with the company in 2024 or 2025.\nHIGHMARK HEALTH DIPPING A TOE IN AI POOL\nA small pilot involving automated medical documentation after the patient visit was underway using Vertex AI \nSearch, Mr. Clarke said.\nBefore Vertex AI Search, there was ChatGPT, a widely hailed artificial intelligence chatbot introduced in 2022 by \nSan Francisco-based OpenAI that can answer complex questions, and write poetry and answer user queries by \nsearching the entire web. ChatGPT ignited an industry rush to find commercial uses for the technology, with \nmedicine leading the way.\nThe technology harnesses immense power, providing transformative potential to change medicine.\n\"A single AI program can write as much text as all of humanity,\" former Google Health employee and serial \nentrepreneur Mustafa Suleyman wrote in \"The Coming Wave: Technology, Power and the 21st Century's Greatest \nDilemma,\" a book published in September.\nGoogle's new search platform is designed to make medical information immediately available that otherwise would \nbe slow or nearly impossible to retrieve. The technology promises to reduce administrative burden and improve \nphysician efficiency, which Mr. Clarke said was a focus at Highmark.\nVertex AI Search uses an easy to use, conversational search format with machine learning that frames answers to \nthe individual user, with the software \"learning\" from each question. The tool will be specifically tailored to Highmark \nneeds.\nAt Highmark, Vertex AI Search was first tested in its strategy to transform health care, which it calls Living Health, \nbut Mr. Clarke said Tuesday that virtually every aspect of the organization will eventually benefit from the software, \nincluding such far-flung departments as marketing.\n\"Artificial intelligence, including generative AI, plays a key role in how we are enabling Living Health and we are \ninterested in how Vertex AI Search could help us simplify the experience and make it more personal, accessible \nand helpful for providers and patients,\" Mr. Clarke said in a prepared statement Monday.\nHighmark Health has been a Google Cloud partner since 2020 when the nonprofit introduced Living Health. In \nJanuary, Highmark began rolling out the My Highmark app, which provides patients with access to information \nabout bills, insurance deductibles and health savings account balances along with medical history and treatment \ninformation, which is the kind of streamlined access to patient information Living Health envisions.\nGenerative AI search tools have been tested elsewhere in drug discovery, breast cancer detection, surgery and \nother areas, sometimes with notable results.\nAmong the more intriguing uses for generative AI has been in retinal scans, which have revealed not only eye \ndiseases such as glaucoma, but stroke, Parkinson's disease and heart attack. AI-assisted studies of chest X-rays, \nthe most commonly obtained medical image in the world, have detected Type 2 diabetes, measured heart function \nand identified valve disease.\nRochester, Minn.-based Mayo Clinic, another health system trying out the Vertex AI Search engine, has been using \nit to answer questions from large volumes of internally generated medical research, according to Dedaimia \nKozlovsky, a solution architect at Mayo Clinic.\nBack at Highmark, Mr. Clarke said the new software would transform operations.\n\"These are things that are going to continuously rolled out,\" he said. \"We're just going to keep adding - every \nquarter, every six months - we're going to just keep adding. Our focus is on creating remarkable experiences for our \npatients.\"\nKris B. Mamula kmamula@post-gazette.com\nHIGHMARK HEALTH DIPPING A TOE IN AI POOL\nGraphic\n \nPHOTO: Pittsburgh Post-Gazette: Highmark Health has been road testing a new Google search platform - now \nreleased for general use - that carries the promise of transforming health care.\nLoad-Date: October 11, 2023"
    },
    {
        "file_name": "her_mother_seek_safeguards_after_AI-created_images_of_girl_spread_at_school._Jan2024",
        "header": "THE NATION; Deepfake nudes prompt push for better protections; Teen and",
        "media": "her mother seek safeguards after AI-created images of girl spread at school.",
        "time": "January 2, 2024",
        "section": "MAIN NEWS; National Desk; Part A; Pg. 1",
        "length": "1145 words",
        "byline": "Hadero writes for the Associated Press.",
        "story_text": "THE NATION; Deepfake nudes prompt push for better protections; Teen and \nher mother seek safeguards after AI-created images of girl spread at school.\nLos Angeles Times\nJanuary 2, 2024 Tuesday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; National Desk; Part A; Pg. 1\nLength: 1145 words\nByline: Hadero writes for the Associated Press.\nBody\nA mother and her 14-year-old daughter are advocating for better protections for victims after AI-generated nude \nimages of the teen and other female classmates were circulated at a high school in New Jersey.\nMeanwhile, on the other side of the country, officials are investigating an incident involving a teenage boy who \nallegedly used artificial intelligence to create and distribute similar images of other students -- also teen girls -- who \nattend a high school in suburban Seattle.\nThe disturbing cases have put a spotlight yet again on explicit AI-generated material that overwhelmingly harms \nwomen and children and is booming online at an unprecedented rate. According to an analysis by independent \nresearcher Genevieve Oh that was shared with the Associated Press, more than 143,000 new deepfake videos \nwere posted online last year, which surpasses every other year combined.\nDesperate for solutions, families are pushing lawmakers to implement robust safeguards for victims whose images \nare manipulated using new AI models, or the plethora of apps and websites that openly advertise their services. \nAdvocates and some legal experts are also calling for federal regulation that can provide uniform protections across \nthe country and send a strong message to current and would-be perpetrators.\n\"We're fighting for our children,\" said Dorota Mani, whose daughter was one of the victims in Westfield, a New \nJersey suburb. \"They are not Republicans, and they are not Democrats. They don't care. They just want to be \nloved, and they want to be safe.\"\nThe problem with deepfakes isn't new, but experts say it's getting worse as the technology to produce it becomes \nmore available and easier to use. Researchers have been sounding the alarm on the explosion of AI-generated \nchild sexual abuse material using depictions of real victims or virtual characters. In June, the FBI warned it was \ncontinuing to receive reports from victims, both minors and adults, whose photos or videos were used to create \nexplicit content that was shared online.\nSeveral states have passed their own laws over the years to try to combat the problem, but they vary in scope. \nTexas, Minnesota and New York passed legislation last year criminalizing nonconsensual deepfake porn, joining \nVirginia, Georgia and Hawaii, which already had laws on the books. Some states, such as California and Illinois, \nhave only given victims the ability to sue perpetrators for damages in civil court, which New York and Minnesota \nalso allow.\nA few other states are considering their own legislation, including New Jersey, where a bill is in the works to ban \ndeepfake porn and impose penalties -- either jail time, a fine or both -- on those who spread it.\nTHE NATION Deepfake nudes prompt push for better protections Teen and her mother seek safeguards after \nAI-created images of girl spread at school.\nState Sen. Kristin Corrado, a Republican who introduced the legislation last year, said she decided to get involved \nafter reading an article about people trying to evade revenge porn laws by using their former partner's image to \ngenerate deepfake porn.\n\"We just had a feeling that an incident was going to happen,\" Corrado said.\nThe bill has languished for a few months, but there's a good chance it might pass, she said, especially given the \nspotlight that's on the issue because of Westfield.\nThe Westfield event took place in the summer and was brought to the attention of the high school on Oct. 20, \nWestfield High School spokesperson Mary Ann McGann said in a statement. McGann did not provide details on \nhow the AI-generated images were spread, but Mani, the mother of one of the girls, said she received a call from \nthe school informing her nude pictures were created using the faces of some female students and then circulated \namong a group of friends on the social media app Snapchat.\nThe school hasn't confirmed any disciplinary actions, citing confidentiality on matters involving students. Westfield \npolice and the Union County prosecutor's office, who were both notified, did not reply to requests for comment.\nDetails haven't emerged about the incident in Washington state, which happened in October and is under \ninvestigation by police.\nPaula Schwan, the chief of the Issaquah Police Department, said they have obtained multiple search warrants and \nnoted the information they have might be \"subject to change\" as the inquiry continues. When reached for comment, \nthe Issaquah School District said it could not discuss the specifics because of the investigation, but said any form of \nbullying, harassment or mistreatment among students is \"unacceptable.\"\nIf officials move to prosecute the incident in New Jersey, current state law prohibiting the sexual exploitation of \nminors might already apply, said Mary Anne Franks, a law professor at George Washington University who leads \nthe Cyber Civil Rights Initiative, an organization aiming to combat online abuses. But those protections don't extend \nto adults, she said.\nThe best fix, Franks said, would come from a federal law that can provide consistent protections nationwide and \npenalize dubious organizations profiting from products that easily allow anyone to make deepfakes. She said that \nmight also send a signal to minors who might create images of other kids impulsively.\nPresident Biden signed an executive order in October that, among other things, called for barring the use of \ngenerative AI to produce child sexual abuse material or nonconsensual \"intimate imagery of real individuals.\" The \norder also directs the federal government to issue guidance to label and watermark AI-generated content to help \ndifferentiate between authentic and software-generated material.\nCiting the Westfield incident, U.S. Rep. Tom Kean Jr., a Republican who represents the town, introduced a bill on \nMonday that would require developers to put disclosures on AI-generated content. Among other efforts, another \nfederal bill introduced by U.S. Rep. Joe Morelle, a New York Democrat, would make it illegal to share deepfake \nporn images online. But it hasn't advanced for months due to congressional gridlock.\nSome, including the American Civil Liberties Union and the Electronic Frontier Foundation, argue for caution, saying \nthat consideration is needed to avoid proposals that may run afoul of the 1st Amendment.\n\"Some concerns about abusive deepfakes can be addressed under existing cyber harassment\" laws, said Joe \nJohnson, an attorney for ACLU of New Jersey. \"Whether federal or state, there must be substantial conversation \nand stakeholder input to ensure any bill is not overbroad and addresses the stated problem.\"\nMani said her daughter has created a website and set up a charity aiming to help AI victims. The two have also \nbeen in talks with state lawmakers pushing the New Jersey bill and are planning a trip to Washington to advocate \nfor more protections.\nTHE NATION Deepfake nudes prompt push for better protections Teen and her mother seek safeguards after \nAI-created images of girl spread at school.\n\"Not every child, boy or girl, will have the support system to deal with this issue,\" Mani said. \"And they might not see \nthe light at the end of the tunnel.\"\nGraphic\n \nPHOTO: WESTFIELD High School is in the spotlight after nude images were made using female students' faces.  \nPHOTOGRAPHER:Peter K. Afriyie Associated Press \nLoad-Date: January 2, 2024"
    },
    {
        "file_name": "New_York_Observer_Sep2023",
        "header": "Artificial Intelligence: Imitation of Art or Creative Supertool?",
        "media": "New York Observer",
        "time": "September 1, 2023",
        "section": "",
        "length": "1664 words",
        "byline": "Josh Tyson",
        "story_text": "Artificial Intelligence: Imitation of Art or Creative Supertool?\nNew York Observer\nAugust 30, 2023 Wednesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 1664 words\nByline: Josh Tyson\nBody\nWhether we realize it or not, a great many writers have been using A.I. daily for decades. Spell check, after all, was \nborn in 1971 at Stanford University's Artificial Intelligence Laboratory. It became a common tool in Word sometime \nin the early aughts, and I remember having a sense then that using it was somehow cheating. I wasn't alone in \nfeeling this way, but at some point, it started feeling lazy not to use spell check. Besides, the artistry isn't in the \nability to spell words correctly but the ability to synthesize experiences into words people can relate to.\nIn the wake of powerful new expressions of A.I., like OpenAI's ChatGPT and a slew of other generative models, the \nline between the artist and the tool is starting to blur. The implications are massive, both in terms of how people \nleverage creativity to make a living and in how we decide to define art.\nWhen it comes to our notion of work, the new maxim on the streets bears sober consideration: A.I. isn't coming for \nyour job; someone using A.I. is coming for your job. A graphic designer leveraging tools like text to image, sketch to \nimage, generative fill and text effects from Firefly, Adobe (ADBE)'s beta collection of generative models, is likely to \noutpace the designer who isn't using them.\nIt's rather exciting in the near term, but it raises questions about what could happen when these tools outpace the \ngraphic designer using them. Is that a bad thing? The answer probably depends on your view of capitalism or how \nintertwined your work is with your identity. I see the glimmer of a possibility that by automating the tedium that fills \nso much of our lives, A.I. might help us break free from the productivity mindset that requires using quantity as a \nmetric of accomplishment instead of quality.\nIn this moment, however, the sheer power of these nascent tools prompts another question: Will models this \npowerful and ubiquitous initiate the ruinous decimation of human creation? An artistic armageddon?\nI turned to Scott Bourne for an answer. An author, publisher, former pro skateboarder and American expat living in \nParis, Scott was a fellow contributor to SLAP skateboarding magazine back in the early days of spell check, but his \nwriting always carried the extra weight of having been punched out on a typewriter. There was no autocorrect in \nScott's world, and to this day he carries no pocket computer, sending much of his correspondence out the old-\nfashioned way, in envelopes, sometimes sealed with discs of melted wax.\nWhen I asked Scott if he'd be interested in collaborating with Bournebot, a personal large language model (LLM) \ntrained on all of his output-decades worth of poems, stories, interviews and emails-the answer came quickly: \"Not in \nthe slightest.\"\n\"What most interests me in this time of technology is touch: human touch and staying human,\" he said. \"I think it is \nunderstood that time is what makes things great. The longer it takes to create something, the better it is, whether it \nbe wine, whisky or a work of art. Haste makes waste, and I think we are wasting a lot of time on speed. Write, \nrewrite, write again and again and again. Then revise and write it once more.\"\nArtificial Intelligence: Imitation of Art or Creative Supertool?\nWhat was interesting about his reply was that it echoes an approach to A.I. that I've been exploring for the past few \nyears. If technology is going to become more powerful and intertwined with our lives, I'd prefer an outcome that puts \na premium on humans' creativity and problem-solving skills-one where our eyeballs aren't tethered to glowing \nscreens. Maybe if we're having conversations with technology instead of staring at it, A.I. can become an invisible \nally. Maybe machines can give us the gift of time. Maybe we'll spend that time having meaningful interactions with \nother people. Maybe we'll use it in artistic endeavors: to write and rewrite. Or will it be so easy to point A.I. to the \ntask of writing out our ideas that we won't bother to take the time?\n\"No A.I. is ever going to have an experience, so it could never write my poems,\" Bourne said. \"No A.I. is ever going \nto feel love or pain or any of the emotions that have created Scott Bourne. I am not just blood and guts; there's a \nhard road in there, some hitchhike and fist fight, a little jail time and freight ride. A.I. could only imitate, and all my \nlife I have been avoiding imitations. I think it's kind of ironic that people now prefer an imitation to the real thing.\"\nHis argument made me think of Oscar Wilde's assertion that \"life imitates art far more than art imitates life.\" As I've \ncome to understand it, he means that what we experience as life is just what art has taught us exists. I also spoke \nwith New York Times bestselling author and business leadership coach Charlene Li, who loved the idea of having \nher own LLM (and was actually in the exploratory stages of crafting one).\n\"It's not just another me, it's a better me,\" she said of this potential ally. \"Seventy percent of what I do, I can now do \nwith GPT. I can do more of the 30 percent that's unique to me and keep working with the technology to keep adding \non to that, and I can do other things-higher-order, more value-added things.\"\nSo, there's no one answer, just fronds of perception dangling overhead. The task at hand is to wrap your head \naround generative A.I. and then decide how you want to incorporate it into-or attempt to eliminate it from-your life.\nGenerative A.I. has kicked over the barrier of technical training as a means to create art. People who feel \ncompelled to explore artistic expression but who don't have the natural talent or hard-earned skills are now in a \nposition to share their visions. Generative A.I. has the power to raise marginalized voices and engender \nwidespread empathy. But is it bad for people who have trained extensively as artists? That seems likely in \nscenarios where technology directly threatens livelihoods or intellectual property, and there are already artists \nlitigating around these points.\nPerhaps the root problem is that making money as an artist has always been hard as hell. Most of the artists I know \nhave a stable of side-gigs that let them make both art and a living. The lucky ones are able to combine their artistic \nabilities with something marketable, like graphic design or cosmetology. Getting paid to write short stories, record \nreviews and band interviews for SLAP felt like a huge break twenty years ago. It was one of many freelance writing \ngigs I maintained, and I still needed to work odd jobs on the side. From my experience, it's only gotten harder to find \npaid work as a writer.\nRight now, I feel like I can outperform LLMs. As a trained writer, I don't have a lot of use for ChatGPT. My favorite \nthing to do with generative A.I. so far has been feeding Stable Diffusion 2 odd prompts in hopes of getting \nunsettling results (\"Alf eating pasta\" continues to deliver).\nRebecca Evanhoe, co-author of a popular book in experience design circles, Conversations With Things: UX \nDesign for Chat and Voice, shared a similar viewpoint on large language models: \"I think it's going to be real hard to \nget that pen out of my hand. Writing is so essential to my thought process, I can't really tell you what I think [about \nsomething] until I've written about it... If I can't write, I'm not even doing the thinking... But I am a person who has a \ngift in writing, and I have a lot of training in writing. Writing is very painful for lots of people.\"\nWriting can be excruciating, and I know it's only a matter of time before generative A.I. will surpass my writing \nabilities by certain metrics, most notably speed. In the commercial marketplace, my value as a writer might shrink \neven further, but I agree with Scott that it will be exceedingly difficult for a machine to replicate my experience.\nOur innate human ability to synthesize our experiences for creative problem solving will be hard for technology to \ninfringe upon. That potentially matters less if we're all adrift in an endless, churning sea of quasi-personalized, auto-\nArtificial Intelligence: Imitation of Art or Creative Supertool?\ngenerated content that has immense technical prowess but no pulse. That's why it seems critical for artists and \ncreatives to find ways to use these tools that will augment their abilities, not replace them.\nWhether it's a busy artist using ChatGPT to craft email updates for their mailing list or a designer using generative \ntools to produce a wider variety of work for clients, technology used responsibly can provide tangible gains in terms \nof income while also shaping the form these powerful technologies assume. Machines are destined to become \nmore intertwined with our lives. With generative A.I. readily available, there's an opportunity right now for people to \ndecide what that will look like.\nRecently, I was part of a conversation about technology and the nature of art with Laura Herman, a researcher at \nthe University of Oxford. We discussed many aspects of generative A.I. and creativity, but her thoughts on \nintentionality have been echoing in my head.\n\"Naturally, when I look at a piece of artwork... I think about 'What was the artist trying to convey?' and 'Why did they \ndo this?'\" Herman said. \"It can be just physical intentionality-it could be conceptual intentionality. Now [these] new \ntechnologies [are] shifting the visibility of intentionality and shifting how that intentionality is brought to bear on the \nultimate artwork-there's so much to think about in that space.\"\nIn a world oversaturated with generative content, it's possible that people will be more drawn to art that's being \ncreated by humans. On paper, machines can play jazz, but does anyone want to watch one take an extended solo \nover Coltrane's \"Giant Steps\"? What is the quality of the intentionality in that kind of content? Like most of the things \nwe call art, the very heart of jazz is so tied to human experience and discipline that a machine's best attempt would \nbe eternally relegated to the status of imitation.\nMaybe the question isn't will the tool usurp the artist but will we let it?\nLoad-Date: September 1, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Microsoft Blasted for A.I. Poll Placed Near Guardian Article",
        "media": "The New York Times",
        "time": "November 3, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "572 words",
        "byline": "By Jenny Gross",
        "story_text": "Microsoft Blasted for A.I. Poll Placed Near Guardian Article\nThe New York Times\nNovember 3, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 572 words\nByline: By Jenny Gross\nBody\nA poll generated by artificial intelligence, embedded next to a Guardian article on Microsoft's news aggregator \nplatform, asked readers to speculate on the cause of a woman's death.\nAn auto-generated poll that Microsoft embedded on its news aggregating platform alongside a Guardian article was \n''crass'' and caused significant damage to The Guardian's reputation, the newspaper said on Thursday. \n  The poll, which was posted last week next to an article about a woman who was found dead in a school bathroom \nin Australia, asked readers to speculate on the cause of the woman's death. It gave three choices: murder, accident \nor suicide. The Guardian said the poll was created using generative artificial intelligence, which can generate \ntext, images and other media from prompts.\n  Anna Bateson, the chief executive of Guardian Media Group, wrote in a letter to Microsoft that the poll was ''clearly \nan inappropriate use of genAI.''\n  ''Not only is this sort of application potentially distressing for the family of the individual who is the subject of the \nstory, it is also deeply damaging to the Guardian's hard-won reputation for trusted, sensitive journalism, and to the \nreputation of the individual journalists who wrote the original story,'' Ms. Bateson wrote in the letter, addressed to \nBrad Smith, Microsoft's vice chairman and president, on Tuesday. Ms. Bateson said that The Guardian had already \nasked Microsoft not to apply its experimental technologies to Guardian news articles because of the risks it posed.\n  A Guardian spokesman said the poll was ''crass'' and led commenters on Microsoft Start, the news aggregating \nplatform, to believe that The Guardian was to blame. One reader, unaware that Microsoft, not The Guardian, had \ncreated the poll, wrote: ''This has to be the most pathetic, disgusting poll I've ever seen. The author should be \nashamed.'' Another commented, ''polling the reason behind a persons death? what is wrong with you!!''\n  Microsoft said in a statement that it had deactivated Microsoft-generated polls for all news articles and that it was \n''investigating the cause of the inappropriate content.''\n  ''A poll should not have appeared alongside an article of this nature, and we are taking steps to help prevent this \nkind of error from reoccurring in the future,'' the statement said.\n  The Guardian statement also criticized Microsoft for leaving the poll up for four days. It was removed on Monday, \nafter The Guardian contacted Microsoft, the Guardian spokesman said.\n  The British government this week hosted a summit to discuss the long-term safety of artificial intelligence, which \nresulted in 28 governments, including China and the United States, agreeing to cooperate on A.I. risk management.\nMicrosoft Blasted for A.I. Poll Placed Near Guardian Article\n  But the agreement fell short of setting specific policy goals, and The Guardian and other publishers have called on \ntech companies to specify how they will ensure safe use of artificial intelligence. In her letter, Ms. Bateson asked \nMicrosoft to specify how it would prioritize trusted news sources, provide fair compensation for licensing and the \nuse of journalism, and provide transparency and safeguards around its technologies.\n  Matt Rogerson, The Guardian's director of public policy, said tech companies need to determine how to address \nsituations when their use of artificial intelligence goes wrong. Microsoft has not appended a note to the article taking \nresponsibility for the poll, he said.\nhttps://www.nytimes.com/2023/11/02/business/media/microsoft-guardian-ai-poll.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: November 3, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "DPDP Rules: Furore over leeway to some companies on use of kid’s data",
        "media": "The Economic Times",
        "time": "January 10, 2024",
        "section": "TECH & INTERNET",
        "length": "779 words",
        "byline": "Suraksha P and Aashish Aryan",
        "story_text": "DPDP Rules: Furore over leeway to some companies on use of kid’s data\nThe Economic Times\nJanuary 10, 2024 Wednesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 779 words\nByline: Suraksha P and Aashish Aryan\nBody\nThe introduction and definition of a proposed ‘consent artefact’ in the Digital Personal Data Protection (DPDP) Act \nand the exemptions provided to certain intermediaries on the processing of children’s data have raised concerns \namong experts.Digital privacy and cybersecurity experts as well as lawyers ET spoke to also said that there needs \nto be additional deliberation on the finer workings of the consent artefact architecture, including how giving and \nrevoking consent will work.“The tricky part is how consent provided under Section 7(a) of the Act will be later \nlocated to withdraw such consent, which was not originally recorded, or provided using a consent artefact,” a \ntechnology lawyer, who has seen a copy of the proposed rules and was present during the industry consultations \non DPDP Rules, told ET.Section 7(a) of the proposed executive rules under the Act envisages transactional \nsituations where neither the user's consent has been documented nor a privacy notice has been exchanged with \nthe said user.Also read | Experts flag revised Data Bill’s silence on generative AI toolsThe DPDP Act defines \ncompanies processing personal data as data fiduciaries and the users whose data is processed as data \nprincipals.The proposed final draft of the executive rules under the Act, set to be released soon, has introduced the \nconcept of a consent artefact, which could be any machine-readable electronic record such as an e-mail, a digital \nsignature or an electronic document of any kind.This electronic document, a kind of digital form, should be able to \nprovide both data fiduciaries and data principals with the option to notify each other on various aspects such as \ngranting, managing, reviewing or withdrawing consent for personal data processing.Also read | \nETtech Interview | Data Bill to make social media companies accountable, fortify IT industry: IT Minister Ashwini \nVaishnaw“The draft has proposed that the consent artefact must also contain information to correctly identify both \nthe user and the company. The problem that could arise here is how does one verify whether such data, provided \neither by the user or the data fiduciary, is correct,” a senior executive at a social media intermediary told ET.Another \nissue, experts said, could be with the IT ministry’s proposal to allow the use of a digital locker service but not \nmandating it.“It is a recognition that the government’s DigiLocker is being used by only around 234 million users \ncurrently, which is a fraction of this country (population). The government has kept it technology agnostic. It is not \ngoing into how reliable age and identity is established,” a senior public policy research executive, who has seen a \ncopy of the draft rules, said.Also read | Decoding the Digital Personal Data Protection Bill 2023Though the \ngovernment had indicated that there could be more reliance on a government-issued identity card-based or digital-\nlocker-based verification of age of children, the stance now seems to have changed as civil societies raised \nconcerns on the exclusionary impact of such lockers or ID cards, the executive said.“Now the government has left it \nto the intermediary to choose the technology that is convenient to them,” she said.Though the US and countries in \nthe EU and other parts of the world have come up with the concept of consent managers or other facial recognition \ntechnology to obtain verifiable parental consent, these methods have their limitations.“There is enough room for \ntechnology innovation. Every method has its limitations. It cannot be uniform globally,” she said.Apart from these, \nthe draft has also raised concerns about the exemptions from the restrictions on the processing of children's data \nmandated under the Act provided to educational institutions, health establishments and certain government \nentities.The entities eligible for this exemption include government entities that perform functions related to the \nDPDP Rules: Furore over leeway to some companies on use of kid’s data\n‘interests of a child’, healthcare professionals, crche or childcare institutions and government bodies that issue \nsubsidies and licences.Also read | For healthcare institutions, the exemption may be restricted to the provision of \nhealthcare services to a child. Educational institutions will be allowed to undertake behavioural monitoring and \ntracking of educational activities.“This kind of classification is not very useful in giving exemptions. For example, \nYouTube is considered a social media platform, but it is used for educational purposes. Kids from low-income \nbackgrounds learn a lot from YouTube. So, the classification and exemptions should be risk-based,” the public \npolicy executive said. For Reprint Rights: timescontent.com\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Nvidia to Partner Reliance, Tata to Boost AI in India",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 9, 2023",
        "section": "FRONT PAGE",
        "length": "469 words",
        "byline": "Our Bureau",
        "story_text": "Nvidia to Partner Reliance, Tata to Boost AI in India\nEconomic Times (E-Paper Edition)\nSeptember 9, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 469 words\nByline: Our Bureau\nHighlight: US chipmaker to team up with RIL for large language model that will be trained in local languages, to \njoin hands with Tata Group to build AI infra\nBody\nBengaluru: American chipmaker Nvidia and Reliance Industries, India's largest company by market cap, will \ntogether build a foundational large language model (LLM) — an artificial intelligence algorithm —that will be trained \non an array of diverse Indic languages used by the country's 1.4 billion people, chief executive Jensen Huang \nannounced on Friday. The $27.5 billion company, which is the world's best known maker of hardware and software \nfor AI tools, also said that it will partner with the salt-to-software conglomerate Tata Group to advance AI \ninfrastructure in India.  The co-created LLM, which is the bedrock behind all generative AI models such as \nChatGPT, will be eventually owned by Reliance, Huang said. \n“They (Reliance) can create AI models, services and applications for their 450 million (customers),” he added. \nMeanwhile, the partnership with the Tata Group's Tata Consultancy Services, Tata Motors and Tata \nCommunications is aimed at building “AI infrastructure that is over an order of magnitude more powerful than the \nfastest supercomputer in India today,” Huang told reporters in Bengaluru while unveiling the two big-ticket \npartnerships.  \"India really needs to accelerate its infrastructure building. We would like to do it almost immediately, \nthe best we (Nvidia) can do is probably create supercomputers that are an order of magnitu- de 100 times faster \nthan the fastest supercomputer in all of India today. By the end of next year, (India) will have very large computers,\" \nsaid the 60-year-old Nvidia founder who is on a week-long visit to India, which included a meeting with Prime \nMinister Narendra Modi on Monday.  Noting that “Reliance with 450 million customers has more customers and \naccess to data than any company on the planet (and) they support probably all 22 languages and 2,500 dialects of \nthe country\", Huang said that Nvidia will help co-create AI solutions for Reliance using this data.  In a statement on \nFriday, Mukesh Ambani, chairman and managing director of Reliance Industries said that “as India advances from a \ncountry of data prolife- ration to creating technology infrastructure for widespread and accelerated growth, \ncomputing and technology super centres like the one we envisage with NVIDIA will provide the catalytic growth just \nlike Jio did to our nation's digital march”.  Pointing to the advancements that have “made focus on AI a central \npriority in governments, industries and society at large”, N Chandrasekaran, chairman of Tata Sons, said “ the \nimpact of AI and machine learning is going to be profound across industries and every aspect of our lives”.  The \nTata Group's partnership with Nvidia will “democratise access to AI infrastructure, accelerate build-out of AI \nsolutions and enable upgradation of AI talent at scale”, he said in a statement.\nLoad-Date: September 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent",
        "media": "The New York Times",
        "time": "March 23, 2024",
        "section": "TECHNOLOGY",
        "length": "1119 words",
        "byline": "Paul Mozur and Cade Metz Paul Mozur is the global technology correspondent for The Times, based in",
        "story_text": "In One Key A.I. Metric, China Pulls Ahead of the U.S.: Talent\nThe New York Times \nMarch 22, 2024 Friday 12:28 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1119 words\nByline: Paul Mozur and Cade Metz Paul Mozur is the global technology correspondent for The Times, based in \nTaipei. Previously he wrote about technology and politics in Asia from Hong Kong, Shanghai and Seoul. Cade Metz \nwrites about artificial intelligence, driverless cars, robotics, virtual reality and other emerging areas of technology.\nHighlight: China has produced a huge number of top A.I. engineers in recent years. New research shows that, by \nsome measures, it has already eclipsed the United States.\nBody\nChina has produced a huge number of top A.I. engineers in recent years. New research shows that, by some \nmeasures, it has already eclipsed the United States.\nWhen it comes to the artificial intelligence that powers chatbots like ChatGPT, China lags behind the United States. \nBut when it comes to producing the scientists behind a new generation of humanoid technologies, China is pulling \nahead.\nNew research shows that China has by some metrics eclipsed the United States as the biggest producer of A.I. \ntalent, with the country generating almost half the world’s top A.I. researchers. By contrast, about 18 percent come \nfrom U.S. undergraduate institutions, according to the study, from MacroPolo, a think tank run by the Paulson \nInstitute, which promotes constructive ties between the United States and China.\nThe findings show a jump for China, which produced about one-third of the world’s top talent three years earlier. \nThe United States, by contrast, remained mostly the same. The research is based on the backgrounds of \nresearchers whose papers were published at 2022’s Conference on Neural Information Processing Systems. \nNeurIPS, as it is known, is focused on advances in neural networks, which have anchored recent developments in \ngenerative A.I.\nThe talent imbalance has been building for the better part of a decade. During much of the 2010s, the United States \nbenefited as large numbers of China’s top minds moved to American universities to complete doctoral degrees. A \nmajority of them stayed in the United States. But the research shows that trend has also begun to turn, with growing \nnumbers of Chinese researchers staying in China.\nWhat happens in the next few years could be critical as China and the United States jockey for primacy in A.I. — a \ntechnology that can potentially increase productivity, strengthen industries and drive innovation — turning the \nresearchers into one of the most geopolitically important groups in the world.\nGenerative A.I. has captured the tech industry in Silicon Valley and in China, causing a frenzy in funding and \ninvestment. The boom has been led by U.S. tech giants such as Google and start-ups like OpenAI. That could \nattract China’s researchers, though rising tensions between Beijing and Washington could also deter some, experts \nsaid.\n(The New York Times has sued OpenAI and Microsoft for copyright infringement of news content related to A.I. \nsystems.)\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nChina has nurtured so much A.I. talent partly because it invested heavily in A.I. education. Since 2018, the country \nhas added more than 2,000 undergraduate A.I. programs, with more than 300 at its most elite universities, said \nDamien Ma, the managing director of MacroPolo, though he noted the programs were not heavily focused on the \ntechnology that had driven breakthroughs by chatbots like ChatGPT.\n“A lot of the programs are about A.I. applications in industry and manufacturing, not so much the generative A.I. \nstuff that’s come to dominate the American A.I. industry at the moment,” he said.\nWhile the United States has pioneered breakthroughs in A.I., most recently with the uncanny humanlike abilities of \nchatbots, a significant portion of that work was done by researchers educated in China.\nResearchers originally from China now make up 38 percent of the top A.I. researchers working in the United States, \nwith Americans making up 37 percent, according to the research. Three years earlier, those from China made up 27 \npercent of top talent working in the United States, compared with 31 percent from the United States.\n“The data shows just how critical Chinese-born researchers are to the United States for A.I. competitiveness,” said \nMatt Sheehan, a fellow at the Carnegie Endowment for International Peace who studies Chinese A.I.\nHe added that the data seemed to show the United States was still attractive. “We’re the world leader in A.I. \nbecause we continue to attract and retain talent from all over the world, but especially China,” he said.\nPieter Abbeel, a professor at the University of California, Berkeley, and a founder of Covariant, an A.I. and robotics \nstart-up, said working alongside large numbers of Chinese researchers was taken for granted inside the leading \nAmerican companies and universities.\n“It’s just a natural state of affairs,” he said.\nIn the past, U.S. defense officials were not too concerned about A.I. talent flows from China, partly because many \nof the biggest A.I. projects did not deal with classified data and partly because they reasoned that it was better to \nhave the best minds available. That so much of the leading research in A.I. is published openly also held back \nworries.\nDespite bans introduced by the Trump administration that prohibit entry to the United States for students from some \nmilitary-linked universities in China and a relative slowdown in the flow of Chinese students into the country during \nCovid, the research showed large numbers of the most promising A.I. minds continued coming to the United States \nto study.\nBut this month, a Chinese citizen who was an engineer at Google was charged with trying to transfer A.I. \ntechnology — including critical microchip architecture — to a Beijing-based company that paid him in secret, \naccording to a federal indictment.\nThe substantial numbers of Chinese A.I. researchers working in the United States now present a conundrum for \npolicymakers, who want to counter Chinese espionage while not discouraging the continued flow of top Chinese \ncomputer engineers into the United States, according to experts focused on American competitiveness.\n“Chinese scholars are almost leading the way in the A.I. field,” said Subbarao Kambhampati, a professor and \nresearcher of A.I. at Arizona State University. If policymakers try to bar Chinese nationals from research in the \nUnited States, he said, they are “shooting themselves in the foot.”\nThe track record of U.S. policymakers is mixed. A policy by the Trump administration aimed at curbing Chinese \nindustrial espionage and intellectual property theft has since been criticized for errantly prosecuting a number of \nprofessors. Such programs, Chinese immigrants said, have encouraged some to stay in China.\nFor now, the research showed, most Chinese who complete doctorates in the United States stay in the country, \nhelping to make it the global center of the A.I. world. Even so, the U.S. lead has begun to slip, to hosting about 42 \npercent of the world’s top talent, down from about 59 percent three years ago, according to the research.\nIn One Key A.I. Metric, China Pulls Ahead of the U.S. : Talent\nPHOTO: A camera using artificial intelligence at a coal mine in Heze, China. Beijing has invested heavily in A.I. \neducation. (PHOTOGRAPH BY MARK R CRISTINO/EPA, VIA SHUTTERSTOCK) (B4) This article appeared in \nprint on page B1, B4.\nLoad-Date: March 23, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Adobe Acquires Indian Gen AI Video Startup Rephrase.ai",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 22, 2023",
        "section": "STARTUPS & TECH",
        "length": "266 words",
        "byline": "Tarush.Bhalla@timesinternet.in",
        "story_text": "Adobe Acquires Indian Gen AI Video Startup Rephrase.ai\nEconomic Times (E-Paper Edition)\nNovember 23, 2023 Thursday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 266 words\nByline: Tarush.Bhalla@timesinternet.in\nBody\nBengaluru: Adobe has acquired Bengaluru-based Rephrase.ai, which runs a generative artificial intelligence \n(gen AI)-powered video creation platform. Adobe looks to integrate Rephrase’s tech stack and generative AI video \ncapabilities with Creative Cloud, its platform for video editing and visual content, the US software major said in an \ninternal memo. \nIt did not reveal the deal size. A majority of Rephrase’s team members will join Adobe as part of the deal, people \naware of the talks told ETtech, requesting anonymity. Rephrase’s investors will be given a complete cash exit, with \nthe founders being paid in cash and Adobe stock, one of the sources said. The Lightspeed-backed Rephrase.ai \nprovides atext-to-video generation platform that removes complexities and helps users create professional-looking \nvideos. Rephrase is the first Indian startup to be ac-  quired by Adobe, which has largely struck such deals in its \nhome market, the US, and in Europe. This is Adobe’s first deal in the generative AI and videotooling space. It is \nexpected to help the creative software major accelerate its ability to provide AI-powered video content tools to its \ncustomers.ADOBE’S GEN AI PUSH“The Rephrase.ai team’s expertise in generative AI video and audio \ntechnology and experience-building text-to-video generator tools will extend our generative video capabilities — and \nenable us to deliver more value to our customers faster — all within our industryleading creative applications,” \nAshley Still, senior VP and general manager of Creative Cloud, wrote in an internal memo to Adobe employees on \nTuesday.\nLoad-Date: November 22, 2023"
    },
    {
        "file_name": "USA_Today_Mar2024",
        "header": "How to address artificial intelligence in the workplace",
        "media": "USA Today",
        "time": "March 12, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "871 words",
        "byline": " ",
        "story_text": "How to address artificial intelligence in the workplace\nUSA Today\nMarch 12, 2024 Tuesday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 871 words\nBody\nJohnny C. Taylor Jr. tackles your human resources questions as part of a series for USA TODAY. Taylor is \npresident and CEO of the Society for Human Resource Management, the world's largest HR professional society \nand author of \"Reset: A Leader's Guide to Work in an Age of Upheaval.\"\nQuestion: My job does not have a policy for the use of artificial intelligence. I started regularly using generative AI \nin my work but have yet to tell my boss. Should I let him know that I use ChatGPT for work? - Caleb\nAnswer: Absolutely. It's crucial to communicate with your boss about your use of generative AI tools like ChatGPT \nfor work, even if there isn't a formal AI policy in place at your workplace. Here are a few points to consider when \ndiscussing this with your boss:\nData security: Address the issue of data security upfront. Underscore that while generative AI is a valuable tool, \nyou are mindful of the sensitivity of the information it processes. Assure your boss you will refrain from entering \nproprietary or confidential information into ChatGPT and are willing to turn off chat history to uphold data security if \nrequested.\nMisinformation verification: Acknowledge the potential for discrepancies in the information provided by AI tools. \nEmphasize your understanding of the significance of verifying any information obtained via generative AI to ensure \naccuracy. This commitment to fact-checking will help maintain the reliability of the work you produce.\nOverreliance on AI: Address the concern of overreliance on generative AI tools. Acknowledge that while AI is a \npowerful aid in generating content, you are cautious to keep it from overshadowing your own authentic voice. Share \nyour approach to using AI as a starting point, incorporating your personal touch, and avoiding a copy-and-paste \nmentality.\nEthical considerations: Discuss the ethical considerations if you are using AI to influence decisions or products. \nHighlight your awareness of the importance of maintaining ethical standards in your work. Assure your boss you \napproach AI as a supplementary tool and that your decisions align with the company's ethical principles.\nSeek feedback: Express your willingness to receive feedback on your use of AI and inquire if there are specific \ntasks or areas where your boss would like you to apply this technology. This proactive approach demonstrates your \nopenness to collaboration and aligning AI usage with your company's objectives.\nUltimately, artificial intelligence should complement and elevate human intelligence and capability, not replace it. \nEnsuring your uniquely human intellect and intuition are involved in an operation aided by AI will deliver the best \npossible outcome. By addressing these considerations and having an open conversation with your boss, you not \nonly ensure transparency in your work but also contribute to the ongoing dialogue around AI usage in your \nHow to address artificial intelligence in the workplace\nworkplace. Your proactive approach could even help shape a future AI policy to suit your company's needs and \nvalues.\nI've never fared well in a group interview. Do you have any tips for the group interview I have coming up? - Tara\nNavigating group interviews can be challenging, but you can make a positive impact with proper preparation and \nstrategic approaches. Thorough preparation will boost your confidence during the interview.\nBegin with a comprehensive examination of the organization. Understand its values, mission and recent \nachievements. A sound understanding of the company will help you connect to its goals.\nCompile relevant examples from your experience, skills and education. Be ready to articulate how you've overcome \nchallenges in past positions. Practicing with friends or mentors who can provide constructive feedback will bolster \nyour confidence.\nDemonstrate strong networking skills by introducing yourself to group members before the interview begins. \nBuilding a rapport with interviewers and fellow candidates can help alleviate initial anxiety and create a positive \nimpression.\nGroup interviews often focus on teamwork and communication skills. Showcase your ability to collaborate by \nactively participating in group discussions. Emphasize instances where you successfully worked in a team, \nresolving challenges and achieving common goals.\nInvolve the group in your responses by connecting with what other participants have shared. Acknowledge and \nagree with their points when it makes sense. This demonstrates active listening skills and your ability to collaborate \nand build on others' ideas.\nTake note of what others are saying to avoid repetitive points. Look for opportunities to add a nuanced angle or \nexpand on ideas to move the discussion forward. This showcases your ability to think critically and build on existing \nideas.\nStay engaged throughout the group interview. Maintain eye contact, nod affirmatively, and use nonverbal cues to \nshow attentiveness. Avoid distractions and actively participate in group activities or discussions.\nShape your responses to align with the organizational objectives and job role. Have a clear understanding of the \nvalue you can bring to the company culture and the team. Remember to be authentic and distinct, allowing your \nunique qualities to shine.\nJohnny C. Taylor\nColumnist\nUSA TODAY\nLoad-Date: March 12, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "'India Will Establish Guardrails for AI Sector'",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "FRONT PAGE",
        "length": "277 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "'India Will Establish Guardrails for AI Sector'\nEconomic Times (E-Paper Edition)\nMay 13, 2023 Saturday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 277 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: Govt not in favour of legislation regulating generative AI yet, unlike US, EU: MoS Chandrasekhar\nBody\nNew Delhi: India plans to establish “some principles” which will act as “guardrails” for the fast-growing artificial \nintelligence (AI) sector, according to a top lawmaker who said this will help regulate generative AI platforms such \nas Microsoft's Open AI and Google's Bard as well as their use by other companies.  In contrast to the view taken by \nthe European Union and the US, the Indian government is not in favour of legislation to regulate generative AI, yet, \naccording to Rajeev Chandrasekhar, minister of state for electronics  and IT. He added that discipline needs to be \nbrought into an industry that can cause much chaos and harm. \n“If anybody says I know the right way to regulate AI, there will be an Elon Musk view, the Open AI view, or 100 \nother views. We are not going to go down that road at all,” he told ET in an interview. “AI is an emerging technology, \nand  we will establish some principles as guardrails. Then the subordinate legislation or how to regulate it will keep \nevolving,” he said. India has one of the largest data sets and is therefore very crucial for companies working on \ngene-  rative AI. It is important India does not allow technology regulation to lag technology innovation in AI, the \nminister said. “AI innovation is now growing very fast. In the blink of an eye, there's a new disruption. So therefore, \nwe must establish fairly embedded principles in the law.” Pointing out that the proposed guardrails will put the onus \non the platforms to ensure that no one is using them to “create misinformation”, Chandrasekhar said “you cannot \ncreate things that are fake, you cannot cause user harm, you cannot have exploitive content.”\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Ukraine and China Top G7 Agenda, Along With a New Threat: A.I.",
        "media": "The New York Times",
        "time": "May 19, 2023",
        "section": "Section A; Column 0; Foreign Desk; Pg. 7",
        "length": "1397 words",
        "byline": "By David E. Sanger",
        "story_text": "Ukraine and China Top G7 Agenda, Along With a New Threat: A.I.\nThe New York Times\nMay 19, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section A; Column 0; Foreign Desk; Pg. 7\nLength: 1397 words\nByline: By David E. Sanger\nBody\nThe leaders are expected to hold their first talks on a common regulatory approach to generative artificial \nintelligence.\nPresident Biden began his foreshortened Asia trip on Thursday in Hiroshima, a city that devotes itself to reminding \nthe world of what happens when a brutal war escalates into a nuclear one. There he prepared for discussions with \nhis closest allies on two crucial issues: how to better arm Ukraine as it enters its counteroffensive against the \nRussian invaders, and how to slow, or halt, the downward spiral in relations with China. \n  Both are now familiar topics to the leaders of the Group of 7 nations, who have grown far tighter, and have \nremained surprisingly unified, since Russia began its assault on Ukraine 15 months ago. But at some point over \nthree days of discussions, the G7 leaders are also expected to venture into new territory: the first conversations \namong the world's largest democratic economies about a common approach to regulating the use of generative \nartificial intelligence programs like GPT-4.\n  Artificial intelligence was not on the early agenda as Prime Minister Fumio Kishida invited the other six leaders -- \njoined by Prime Minister Narendra Modi of India and, via video or in person, President Volodymyr Zelensky of \nUkraine -- to the Japanese prefecture where he got his political start.\n  But as the new artificial intelligence language model from OpenAI made nations around the world focus for the first \ntime on the possibilities for disinformation, chaos and the physical destruction of critical infrastructure, Mr. Biden's \nnational security adviser, Jake Sullivan, began calling counterparts to seek a common discussion.\n  It is far from clear that this group of leaders -- the G7 also includes Germany, Britain, France, Canada and Italy -- \ncan sustain a conversation on a technology that appeared to burst on the scene so quickly, even if it was years in \nthe making. Past efforts to get the group to take up far more straightforward cybersecurity issues usually descended \ninto platitudes about ''public-private partnerships,'' and there has never been serious discussion of rules to guide the \nuse of offensive cyberweapons.\n  American officials say that in the case of chatbots, even a vague foundational discussion may help in establishing \nsome shared principles: that the corporations that bring products using the large-language models will be primarily \nresponsible for their safety, and that there must be transparency rules that make it clear what kind of data each \nsystem was trained on. That will enable lower-level aides to discuss details of what those first regulations would \nlook like, the officials said.\nUkraine and China Top G7 Agenda, Along With a New Threat: A.I.\n  But as the G7 leaders convene starting on Friday, it will be Ukraine that will dominate the conversation, at a critical \nmoment for Mr. Zelensky, for Ukraine and for the core Western democracies now seized with an urgent mission of \nbringing about what Mr. Biden calls the ''strategic defeat of Russia in Ukraine.''\n  Mr. Biden often says that Russia is already defeated. But the fear permeating the seven large democracies here is \nthat unless the counteroffensive proves highly successful, Ukraine will settle into a bloody, frozen conflict in which \nthe best hope would be an armistice, reminiscent of the one that brought a halt to fighting on the Korean Peninsula \n70 years ago this summer.\n  Such a confrontation seemed almost impossible to imagine in 1997, when President Bill Clinton and Prime \nMinister Tony Blair of Britain invited Russia to become a full member of the group, expanding it -- for nearly two \ndecades -- into the G8. Russia was ''suspended'' after its annexation of Crimea in 2014, and it withdrew from the \ngroup three years later.\n  Now, with his troops already seeking to destroy Russian weapons depots ahead of the counteroffensive, Mr. \nZelensky just completed a series of rapid-fire visits to European capitals to shore up support for continued heavy \nspending on armaments and aid. He is expected to address the leaders in Hiroshima virtually, but there have been \nbehind-the-scenes conversations about whether to take the risk of bringing him personally to the other side of the \nworld to make his case.\n  Either way, he will have a large audience. In addition to India, the leaders of Australia, South Korea, Brazil, \nIndonesia and Vietnam will all be present as guests. It is part of a broader strategy by Mr. Biden and his allies to \ndraw in nations that, to varying degrees, have been fence sitters on the Ukraine war, refusing to condemn Russia \ntoo harshly, to enthusiastically enforce sanctions, or to supply weapons to Ukraine.\n  Some of the core members are seeking to arm Mr. Zelensky in ways that may outpace Mr. Biden's willingness. \nWhen he was in Britain, Rishi Sunak, the prime minister, embraced Mr. Zelensky in a bear hug and told reporters, \n''They need the sustained support of the international community to defend against the barrage of unrelenting and \nindiscriminate attacks that have been their daily reality for over a year. We must not let them down.''\n  Britain and the Netherlands have been pressing Washington to allow Ukraine to begin training on the use of F-16 \nfighter jets. But just as Mr. Biden was at first reluctant to turn over HIMARS and Patriot missile batteries and other \ntechnologies, he has been cautious about the F-16, a plane that could easily reach, and hit, the Kremlin.\n  So the United States seems likely to argue in Hiroshima that the fighter jets, while symbolically impressive, would \nbe so expensive that they would come at the price of sending far more useful, inexpensive systems, including the \nair defenses that have proven surprisingly successful in taking down incoming Russian missiles. The apparent \ndamage of at least part of a new Patriot missile battery in Kyiv this week has underscored the fact that such \nsystems are precious.\n  Mr. Biden has consistently been cautious -- overcautious in the minds of Mr. Zelensky and some NATO allies -- \nabout giving Ukraine weapons that he believes might lead to rapid escalation of the war and renewed threats by the \nRussian leader, Vladimir V. Putin, to use a tactical nuclear weapon. \n  Britain has just begun giving Ukraine another precision weapon with greater reach than the American-provided \nHIMARS, a missile system called Storm Shadow.  Britain's foreign secretary, James Cleverly, told reporters in \nWashington last week that Mr. Putin's threats of escalation now ring more hollow, and that these ''are gateways to \nwhich they are going to have to pass.''\n  For Mr. Kishida, the host, navigating the nuclear issues will be unusually tricky. The summit will open with a visit \nby Mr. Biden to the landmark atomic dome, making him the second American president to see the site of the atomic \nbombing ordered by President Harry S. Truman. (President Obama came in 2016, and Mr. Kishida was one of his \nguides to the site.)\nUkraine and China Top G7 Agenda, Along With a New Threat: A.I.\n  Like many Japanese political leaders, Mr. Kishida has pressed throughout his career for the gradual elimination of \nnuclear weapons. But he and other Japanese politicians also concede that Mr. Putin's threats have made American \n''extended deterrence'' under its nuclear umbrella more vital to Japan's strategy now than it has been for years.\n  G7 officials will also be grappling with the downward spiral in relations between China and the United States. Mr. \nSullivan, the national security adviser, spent two days in Vienna last week with Wang Yi, China's top foreign affairs \nofficial, in what was widely described as an effort to get communications going again after the U.S. decision to \nshoot down a Chinese surveillance balloon off the coast of South Carolina.\n  Officials have said little about the meeting, but it appears that China told Mr. Sullivan they are open again to visits \nfrom Commerce Secretary Gina Raimondo, Treasury Secretary Janet Yellen and, ultimately, Secretary of State \nAntony J. Blinken.\n  Mr. Biden, who on Tuesday canceled additional stops on this trip in Papua New Guinea and Australia so he can \nreturn on Sunday to the United States to deal with debt ceiling negotiations, said on Wednesday he was trying to \nmeet again with the Chinese leader, Xi Jinping. That is a sign that the freeze in relations in recent months may be \nbeginning to let up, even if the fundamental dynamic between the United States and China, a growing nuclear \npower, has yet to change.\nhttps://www.nytimes.com/2023/05/18/world/asia/g7-ukraine-artificial-intelligence.html\nGraphic\n \nPHOTO: President Biden walking into a bilateral meeting with Prime Minister Fumio Kishida of Japan on Thursday \nin Hiroshima, Japan. (PHOTOGRAPH BY KENNY HOLSTON/THE NEW YORK TIMES) This article appeared in \nprint on page A7.               \nLoad-Date: May 19, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2024",
        "header": "Behind US Publishers’ Suit Against MS, OpenAI for Skimming Content",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 2, 2024",
        "section": "STARTUPS & TECH",
        "length": "240 words",
        "byline": "Annapurna.Roy@timesgroup.com",
        "story_text": "Behind US Publishers’ Suit Against MS, OpenAI for Skimming Content\nEconomic Times (E-Paper Edition)\nMay 2, 2024 Thursday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 240 words\nByline: Annapurna.Roy@timesgroup.com\nHighlight: Publishers seek fair compensation for use of content to train AI models\nBody\nET EXPLAINER\nNew Delhi: Eight US news publishers on Tuesday filed a lawsuit against software firm Microsoft and ChatGPT \nmaker OpenAI for copyright infringement in training their generative AI models using proprietary material. It comes \nmonths after The New York Times took the companies to court for similar reasons. ET explains the case and the \ntrend globally. Who are the plaintiffs? The newspapers involved in the suit  are the New York Daily News, the \nChicago Tribune, the Orlando Sentinel, the Sun Sentinel in Florida, The Mercury News in California, The Denver \nPost, The Orange County Register in California and the Pioneer Press of Minnesota.  What are their complaints? In \nthe suit, the news publishers have accused Microsoft and OpenAI of “purloining millions of the publis-  hers’ \ncopyrighted articles without permission and without payment” and using them to train large language models that \npower chatbots such as ChatGPT and Copilot. They also said that the GenAI products incorrectly attribute \ninaccurate information to them. Do Indian news publishers have similar grievances? Indian news publishers have \nsought changes to the Information Technology Rules to ensure fair compensation for the use of their content to \ntrain GenAI models. Hindi publishers, including Dainik Bhaskar and Amar Ujala, under their terms for non-\ncommercial use, have barred AI companies from using their digital content to train models without permission.\nLoad-Date: May 2, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2023",
        "header": "Google unveils new features for Docs, Gmail and more amid AI race",
        "media": "USA Today Online",
        "time": "March 14, 2023",
        "section": "TECH LATEST, TECH LATEST & WEB 2.0 NEWS",
        "length": "486 words",
        "byline": "Amanda Pérez Pintado, USA TODAY",
        "story_text": "Google unveils new features for Docs, Gmail and more amid AI race\nUSA Today Online\nMarch 14, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST, TECH LATEST & WEB 2.0 NEWS\nLength: 486 words\nByline: Amanda Pérez Pintado, USA TODAY\nBody\nGoogle announced Tuesday a new set of artificial intelligence features for its various Workspace apps. \nThe generative AI tools include the option to automatically generate drafts based on prompts in Docs and Gmail, \nas well as the ability to auto-generate images, audio and video for presentations in Slides. \nThe tech giant is also bringing new generative capabilities for business through Google Cloud, as well as a new API \nfor developers. \nThe announcement comes as tech companies race to launch new AI features amid the frenzy following the launch \nof the ChatGPT chatbot last year. In February, Microsoft announced the arrival of its ChatGPT-powered Bing, and \nGoogle unveiled its own chatbot, Bard, in response to ChatGPT.\n'AI, what's for dinner?':5 cool things to ask ChatGPT, from business names to recipes\nBing’s ChatGPT is in its feelings:'You have not been a good user. I have been a good Bing.'\n\"We’re now at a pivotal moment in our AI journey,\" Thomas Kurian, CEO of Google Cloud, said in a blog post. \n\"Breakthroughs in generative AI are fundamentally changing how people interact with technology — and at \nGoogle, we’ve been responsibly developing large language models so we can safely bring them to our products.\" \nWhat AI tools are coming to Workspace? \nGoogle listed a flurry of features coming to its Workspace apps, including Gmail, Docs, Slides and Sheets. \nAccording to the company, here's what you'll be able to do with the tools:\n \n• Draft, reply, summarize, and prioritize your Gmail \n• Brainstorm, proofread, write, and rewrite in Docs \n• Illustrate presentations with auto-generated images, audio, and video in Slides \n• Get insights and analysis from raw data via auto-completion, formula generation, and contextual \ncategorization in Sheets \n• Generate new backgrounds and capture notes in Meet \n• Enable workflows in Chat\nGoogle said it will embed AI in Docs and Gmail that generates a draft text after you type a few words about the \ntopic you want to write about. You can continue to refine and edit the draft with more AI suggestions.\nWhen will Google launch the features?\nGoogle unveils new features for Docs, Gmail and more amid AI race\nGoogle said it's rolling out the features to \"trusted testers\" before making the tools broadly available. (The Bard \nchatbot was also initially available to a group of \"trusted testers.\")\nGoogle Workspace has more than 3 billion users, according to the search giant.  \nGo deeper\n \n• 'AI, what's for dinner?': 5 cool things to ask ChatGPT, from business names to recipes \n• 'AI, can I deduct that?': The top five overlooked tax deductions and how AI can help you find more. \n• Why Elon Musk wants to build ChatGPT rival: AI chatbots are too 'woke' \n• Where to begin: Investing in ChatGPT's AI revolution \n• For better and worse: ChatGPT is poised to upend medical information \n• ChatGPT in the classroom: Here's what teachers and students are saying\nThis article originally appeared on USA TODAY: Google unveils new features for Docs, Gmail and more amid AI \nrace\nLoad-Date: March 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Should You Check Your Bag, or Bring a Carry-On?; letters",
        "media": "The New York Times",
        "time": "July 19, 2023",
        "section": "OPINION",
        "length": "1147 words",
        "byline": " ",
        "story_text": "Should You Check Your Bag, or Bring a Carry-On?; letters\nThe New York Times \nJuly 19, 2023 Wednesday 23:17 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1147 words\nHighlight: Readers react to a guest essay urging passengers not to check their luggage. Also: Musing about \nartificial intelligence; affirmative action.\nBody\nTo the Editor:\nRe “Don’t Even Think About Checking a Bag,” by David Mack (Opinion guest essay, July 9):\nI’ve been flying for over 50 years. I’ve flown around the world. Countless times to countless places. I have always \nchecked my bags. Only once did I have a bag delayed — not lost — and I received it at my destination the next \nday.\nI don’t crowd the aisles in boarding and deplaning trying to wrestle with almost full-size bags in the overhead bins, \ncausing unnecessary waiting for my fellow passengers.\nI don’t bring onboard bags that barely (sometimes not at all) fit in the overheads and crowd and crush other \noverhead items.\nI don’t bring bags that weigh more than a normal human can lift (or bring down) and require the help of another \npassenger.\nThere’s a certain rudeness to this mass carry-on mania.\nI do have to wait at baggage claim for a bit. But in addition I’m forced to wait a completely needless and inordinate \ntime just to get off the plane while others retrieve their overhead luggage.\nPassengers obsessed with full-size carry-ons perceive an inconvenience of checked luggage that is insignificant, \nand then trade their perceived inconvenience for mine.\nEvery day we take the enormous life-or-death risk of riding in an automobile. Seems to me most of us could also \ntake the minor, non-life-threatening risk that our checked bags might be mishandled.\nLyndon Dodds\nSan Antonio\nTo the Editor:\nWhen my husband and I started traveling again as the pandemic eased, he dared me to pack just a carry-on. \nAlways up for a challenge, I did it, and it was a game changer. Nothing makes me happier than sailing off the plane \nwith my bag, and into an Uber, ready to start our vacation adventure without the stress of waiting for luggage.\nShould You Check Your Bag, or Bring a Carry-On? letters\nThe truth is nobody cares what I’m wearing on vacation! And yes, I do post when I am on vacation, but no selfies. I \nlike to think about all of the money I have saved from checked baggage fees. Try it!\nSusanne Fischer\nNew York\nTo the Editor:\nWe would all find it unacceptable if the airlines started charging the passengers extra fees for being able to use the \nbathroom during a flight. To me, not having the ability to check one bag for free, regardless of the type of ticket a \npassenger bought, belongs in the same category.\nOn a recent flight from San Francisco to Newark I witnessed two passengers almost coming to blows in the struggle \nfor the overhead bin luggage space. After a mad scramble, numerous people already inside the plane had to check \ntheir bags.\nThe airlines should not be allowed to subject the flying public to this kind of indignity on a routine basis. The Federal \nAviation Administration should require airlines to allow at least one free checked bag for all passengers.\nIlya Kapovich\nNew York\nTo the Editor:\nI remember my father’s advice: “Pack less. Take more money. You’ll have a better time.”\nIt has served me well over the decades.\nMichael Dohn\nLiberty Township, Ohio\nHow Worried Should We Be About A.I.?\nTo the Editor:\nRe “‘Human Beings Are Soon Going to Be Eclipsed,’” by David Brooks (column, July 14):\nI sympathize with Mr. Brooks. If world-class thinkers like Douglas Hofstadter are worried about generative artificial \nintelligence, shouldn’t I be, too?\nBut maybe all is not lost. A.I. has no imagination. Until a chatbot can sit under the stars, gazing into infinity, and \nreflect on the enigma of consciousness, we humans alone can imagine and build a better world.\nCharles Ault\nHaverford, Pa.\nTo the Editor:\nAs soon as someone can convince me that A.I. can develop a sense of itself, a self-perceived and self-conceived \nconcept of itself with its own notion of who it is versus other sentient beings, that’s when things could get dicey.\nAsk yourself, when A.I. isn’t being asked by us to do something, will it sit there and just think? If the answer is “yes” \n— “who” is the “it” doing the thinking, and what does it think about?\nTed Herman\nProvidence, R.I.\nShould You Check Your Bag, or Bring a Carry-On? letters\nTo the Editor:\nA machine is a machine, no matter how you slice it. A machine can do nothing without a capability that a human \nhas set in motion.\nIf technologists seem “oddly sanguine” about the prospect of humans living under an A.I. dictatorship, it’s because \nthey are the ones who will be pulling the strings while the rest of us have to live with the resulting horror. It should \nbe obvious that it’s not the machines themselves we have to control.\nJulie Webster\nBrookline, Mass.\n‘I Won the Lottery of Birth.’ Help Those Who Didn’t.\nTo the Editor:\nFor me, as a rising junior in high school, the controversy around the Supreme Court’s affirmative action ruling is \nmore than an abstract philosophical debate.\nAs an Indian American, I know that the decision is probably in my interest. Many of the members of Students for \nFair Admissions, the plaintiffs, look like me, sound like me and have experiences similar to mine. I have been \nconcerned that my race could worsen my admissions odds; I can sympathize with their unease about affirmative \naction.\nBut, at the same time, I do not want to “win” if the deck is stacked in my favor. To be blunt, I won the lottery of birth; \nothers less fortunate than I have had far fewer opportunities. Simply turning away from this fact perpetuates \ninequality.\nMore important, though, we should remind ourselves what college admissions is really all about. Is the admissions \nofficer’s job to select those who ace the standardized tests? No; the people reading through those applications are \nlooking to make a good community. And I sincerely believe that the best communities are diverse communities. \nPlaces where people look different, think differently, pray differently, speak differently.\nAffirmative action may have had its drawbacks. It may have been ham-fisted with its lack of focus on applicants’ \neconomic background. But our college communities are better off for it.\nTo be honest, I doubt that the Supreme Court’s decision will change much. I’d be shocked if admissions officers \nbecome completely race-blind going forward. And, as much as part of me wishes they could be, it would be wrong \nof them if they were.\nVedaant Srivastava\nNew York\nTo the Editor:\nOne subtle but important outcome of the decision to ban racial preferences in college admissions will be a much-\nneeded reduction in stress for many high school students. As a parent of two children with different ethnic \nbackgrounds, I was struck by how differently they felt about revealing this information.\nMy child of Indian ethnicity was stressed about having their odds of admission reduced if they revealed their \nethnicity. My child of Hispanic ethnicity was stressed about the moral implications of receiving an unfair advantage \nby revealing their ethnicity.\nOur kids suffer from enough stress already. Removing this unnecessary source of stress is one important step in \nimproving the mental health of our nation’s next generation.\nShould You Check Your Bag, or Bring a Carry-On? letters\nBrian Suckow\nPalo Alto, Calif.\nThis article appeared in print on page A21.\nLoad-Date: July 19, 2023"
    },
    {
        "file_name": "industry_says_not_so_fast;_Country_singers,_romance_novelists,_video_game_Nov2023",
        "header": "'Please regulate AI:' Artists push for U.S. copyright reforms but tech",
        "media": "industry says not so fast; Country singers, romance novelists, video game",
        "time": "November 19, 2023",
        "section": "NATION WORLD",
        "length": "986 words",
        "byline": "MATT O'BRIEN",
        "story_text": "'Please regulate AI:' Artists push for U.S. copyright reforms but tech \nindustry says not so fast; Country singers, romance novelists, video game \nartists and voice actors are appealing to the U.S. government for immediate \nrelief from the threat that artificial intelligence poses to their livelihoods\nDayton Daily News (Ohio)\nNovember 18, 2023 Saturday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 986 words\nByline: MATT O'BRIEN\nBody\nCountry singers, romance novelists, video game artists and voice actors are appealing to the U.S. government for \nrelief as soon as possible from the threat that artificial intelligence poses to their livelihoods.\n\"Please regulate AI. I'm scared,\" wrote a podcaster concerned about his voice being replicated by AI in one of \nthousands of letters recently submitted to the U.S. Copyright Office. \nTechnology companies, by contrast, are largely happy with the status quo that has enabled them to gobble up \npublished works to make their AI systems better at mimicking what humans do. \nThe nation's top copyright official hasn't yet taken sides. She told The Associated Press she's listening to everyone \nas her office weighs whether copyright reforms are needed for a new era of generative AI tools that can spit out \ncompelling imagery, music, video and passages of text. \n\"We've received close to 10,000 comments,\" said Shira Perlmutter, the U.S. register of copyrights, in an interview. \n\"Every one of them is being read by a human being, not a computer. And I myself am reading a large part of them.\" \nWHAT'S AT STAKE? \nPerlmutter directs the U.S. Copyright Office, which registered more than 480,000 copyrights last year covering \nmillions of individual works but is increasingly being asked to register works that are AI-generated. So far, copyright \nclaims for fully machine-generated content have been soundly rejected because copyright laws are designed to \nprotect works of human authorship. \nBut, Perlmutter asks, as humans feed content into AI systems and give instructions to influence what comes out, \"is \nthere a point at which there's enough human involvement in controlling the expressive elements of the output that \nthe human can be considered to have contributed authorship?\" \nThat's one question the Copyright Office has put to the public. A bigger one  the question that's fielded thousands of \ncomments from creative professions  is what to do about copyrighted human works that are being pulled from the \ninternet and other sources and ingested to train AI systems, often without permission or compensation. \n'Please regulate AI :' Artists push for U.S. copyright reforms but tech industry says not so fast Country singers, \nromance novelists, video game artists and voi....\nMore than 9,700 comments were sent to the Copyright Office, part of the Library of Congress, before an initial \ncomment period closed in late October. Another round of comments is due by Dec. 6. After that, Perlmutter's office \nwill work to advise Congress and others on whether reforms are needed. \nWHAT ARE ARTISTS SAYING? \nAddressing the \"Ladies and Gentlemen of the US Copyright Office,\" the \"Family Ties\" actor and filmmaker Justine \nBateman said she was disturbed that AI models were \"ingesting 100 years of film\" and TV in a way that could \ndestroy the structure of the film business and replace large portions of its labor pipeline. \nIt \"appears to many of us to be the largest copyright violation in the history of the United States,\" Bateman wrote. \"I \nsincerely hope you can stop this practice of thievery.\" \nAiring some of the same AI concerns that fueled this year's Hollywood strikes, television showrunner Lilla \nZuckerman (\"Poker Face\") said her industry should declare war on what is \"nothing more than a plagiarism \nmachine\" before Hollywood is \"coopted by greedy and craven companies who want to take human talent out of \nentertainment.\" \nThe music industry is also threatened, said Nashville-based country songwriter Marc Beeson, who's penned tunes \nfor Carrie Underwood and Garth Brooks. Beeson said AI has potential to do good but \"in some ways, it's like a gun  \nin the wrong hands, with no parameters in place for its use, it could do irreparable damage to one of the last true \nAmerican art forms.\" \nWhile most commenters were individuals, their concerns were echoed by big music publishers (Universal Music \nGroup called the way AI is trained \"ravenous and poorly controlled\") as well as author groups and news \norganizations including the New York Times and The Associated Press. \nIS IT FAIR USE? \nWhat leading tech companies like Google, Microsoft and ChatGPT-maker OpenAI are telling the Copyright Office is \nthat their training of AI models fits into the \"fair use\" doctrine that allows for limited uses of copyrighted materials \nsuch as for teaching, research or transforming the copyrighted work into something different. \n\"The American AI industry is built in part on the understanding that the Copyright Act does not proscribe the use of \ncopyrighted material to train Generative AI models,\" says a letter from Meta Platforms, the parent company of \nFacebook, Instagram and WhatsApp. The purpose of AI training is to identify patterns \"across a broad body of \ncontent,\" not to \"extract or reproduce\" individual works, it added. \nSo far, courts have largely sided with tech companies in interpreting how copyright laws should treat AI systems. In \na defeat for visual artists, a federal judge in San Francisco last month dismissed much of the first big lawsuit against \nAI image-generators, though allowed some of the case to proceed. \nMost tech companies cite as precedent Google's success in beating back legal challenges to its online book library. \nThe U.S. Supreme Court in 2016 let stand lower court rulings that rejected authors' claim that Google's digitizing of \nmillions of books and showing snippets of them to the public amounted to copyright infringement. \nBut that's a flawed comparison, argued former law professor and bestselling romance author Heidi Bond, who \nwrites under the pen name Courtney Milan. Bond said she agrees that \"fair use encompasses the right to learn from \nbooks,\" but Google Books obtained legitimate copies held by libraries and institutions, whereas many AI developers \nare scraping works of writing through \"outright piracy.\" \nPerlmutter said this is what the Copyright Office is trying to help sort out. \n\"Certainly this differs in some respects from the Google situation,\" Perlmutter said. \"Whether it differs enough to rule \nout the fair use defense is the question in hand.\"\n'Please regulate AI :' Artists push for U.S. copyright reforms but tech industry says not so fast Country singers, \nromance novelists, video game artists and voi....\nGraphic\n \nFile - Actor and filmmaker Justine Bateman, right, speaks outside Netflix during a Writers Guild rally on July 13, \n2023, in Los Angeles. Bateman said she was disturbed that AI models were \"ingesting 100 years of film\" and TV in \na way that could destroy the structure of the film business and replace large portions of its labor pipeline. (AP \nPhoto/Mark J. Terrill, File)\nLoad-Date: November 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Artificial Intelligence Glossary: Neural Networks and Other Terms Explained",
        "media": "The New York Times",
        "time": "March 30, 2023",
        "section": "TECHNOLOGY",
        "length": "722 words",
        "byline": "Adam Pasick",
        "story_text": "Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\nThe New York Times \nMarch 27, 2023 Monday 12:23 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 722 words\nByline: Adam Pasick\nHighlight: The concepts and jargon you need to understand ChatGPT.\nBody\nThe concepts and jargon you need to understand ChatGPT.\nWe’ve compiled a list of phrases and concepts useful to understanding artificial intelligence, in particular the new \nbreed of A.I.-enabled chatbots like ChatGPT, Bing and Bard.\nIf you don’t understand these explanations, or would like to learn more, you might want to consider asking the \nchatbots themselves. Answering such questions is one of their most useful skills, and one of the best ways to \nunderstand A.I. is to use it. But keep in mind that they sometimes get things wrong.\nBing and Bard chatbots are being rolled out slowly, and you may need to get on their waiting lists for access. \nChatGPT currently has no waiting list, but it requires setting up a free account.\nFor more on learning about A.I., check out The New York Times’s five-part series on becoming an expert on \nchatbots.\nAnthropomorphism: The tendency for people to attribute humanlike qualities or characteristics to an A.I. chatbot. \nFor example, you may assume it is kind or cruel based on its answers, even though it is not capable of having \nemotions, or you may believe the A.I. is sentient because it is very good at mimicking human language.\nBias: A type of error that can occur in a large language model if its output is skewed by the model’s training data. \nFor example, a model may associate specific traits or professions with a certain race or gender, leading to \ninaccurate predictions and offensive responses.\nEmergent behavior: Unexpected or unintended abilities in a large language model, enabled by the model’s learning \npatterns and rules from its training data. For example, models that are trained on programming and coding sites can \nwrite new code. Other examples include creative abilities like composing poetry, music and fictional stories.\nGenerative A.I.: Technology that creates content — including text, images, video and computer code — by \nidentifying patterns in large quantities of training data, and then creating original material that has similar \ncharacteristics. Examples include ChatGPT for text and DALL-E and Midjourney for images.\nHallucination: A well-known phenomenon in large language models, in which the system provides an answer that is \nfactually incorrect, irrelevant or nonsensical, because of limitations in its training data and architecture.\nLarge language model: A type of neural network that learns skills — including generating prose, conducting \nconversations and writing computer code — by analyzing vast amounts of text from across the internet. The basic \nArtificial Intelligence Glossary: Neural Networks and Other Terms Explained\nfunction is to predict the next word in a sequence, but these models have surprised experts by learning new \nabilities.\nNatural language processing: Techniques used by large language models to understand and generate human \nlanguage, including text classification and sentiment analysis. These methods often use a combination of machine \nlearning algorithms, statistical models and linguistic rules.\nNeural network: A mathematical system, modeled on the human brain, that learns skills by finding statistical \npatterns in data. It consists of layers of artificial neurons: The first layer receives the input data, and the last layer \noutputs the results. Even the experts who create neural networks don’t always understand what happens in \nbetween.\nParameters: Numerical values that define a large language model’s structure and behavior, like clues that help it \nguess what words come next. Systems like GPT-4 are thought to have hundreds of billions of parameters.\nReinforcement learning: A technique that teaches an A.I. model to find the best result by trial and error, receiving \nrewards or punishments from an algorithm based on its results. This system can be enhanced by humans giving \nfeedback on its performance, in the form of ratings, corrections and suggestions.\nTransformer model: A neural network architecture useful for understanding language that does not have to analyze \nwords one at a time but can look at an entire sentence at once. This was an A.I. breakthrough, because it enabled \nmodels to understand context and long-term dependencies in language. Transformers use a technique called self-\nattention, which allows the model to focus on the particular words that are important in understanding the meaning \nof a sentence.\nPHOTO:  (PHOTOGRAPH BY Illustrations by Mathieu Labrecque FOR THE NEW YORK TIMES)\nLoad-Date: March 30, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jun2023",
        "header": "Views on Indian Startups",
        "media": "Economic Times (E-Paper Edition)",
        "time": "June 5, 2023",
        "section": "FRONT PAGE",
        "length": "357 words",
        "byline": "Our Bureau",
        "story_text": "Views on Indian Startups\nEconomic Times (E-Paper Edition)\nJune 5, 2023 Monday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 357 words\nByline: Our Bureau\nHighlight: Altman to discuss AI’s impact on nations like India, his views on regulation and more\nBody\nET TO HOST SAM ALTMAN ON JUNE 7\nMumbai: Sam Altman, OpenAI and ChatGPT have taken centre stage as the world discusses the impact of the \nartificial intelligence (AI) revolution on humanity. Given its explosive potential, the big question of how to regulate AI \nis one that countries are currently grappling with as ChatGPT mainstreams the technology, something Altman has \nclear views on.  To discuss this and more, The Economic Times will host Altman, CEO of OpenAI, the company \nbehind the buzzy AI chatbot ChatGPT, for a fireside chat on June 7 in New Delhi. \nAltman will be in conversation with Satyan Gajwani, vice chairman of Times Internet Ltd, engaging on various \nthemes, including how AI affects countries such as India in terms of jobs and talent evolution. Also, how best to \ncapitalise on the technology. The Stanford dropout, who was previously president of Silicon Valley's influential \nstartup incubator Y Combinator, will discuss various use cases of AI globally, and how these can be customised for \nIndia. REGULATING AI Altman, who's cited AI as po-  tentially a “printing press moment,” will also be drawn to \nexpand on his views regarding regulation.  India plans to establish “some principles” that will act as “guardrails” for \nthe AI sector, according to Union minister Rajeev Chandrasekhar, who said this will help regulate generative AI \nplatforms such as Microsoft's OpenAI and Google's Bard as well as their use by other companies. While testifying \nbefore members of a Senate subcommittee recently in Washington DC, Altman had said, “I think if this technology \ngoes wrong, it can go quite wrong. And we want to be vocal about that... We want to work with the government to \nprevent that from happening.” Theconversation will also cover Altman's Y Combinator days, his entrepreneurial \njourney when he founded Loopt, his views  on Indian startups and the overall technology innovation that the \ndomestic market is capable of. A select audience of CEOs and founders of India's top technology startups, \npolicymakers, and leading business leaders, will be in attendance as we delve into the technology that has taken \nthe world by storm.\nLoad-Date: June 5, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "The Sleepy Copyright Office in the Middle of a High-Stakes Clash Over A.I.",
        "media": "The New York Times",
        "time": "February 4, 2024",
        "section": "TECHNOLOGY",
        "length": "1386 words",
        "byline": "Cecilia Kang &lt;p&gt;Cecilia Kang reports on technology and regulatory policy and is based in Washington",
        "story_text": "The Sleepy Copyright Office in the Middle of a High-Stakes Clash Over A.I.\nThe New York Times \nJanuary 25, 2024 Thursday 21:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1386 words\nByline: Cecilia Kang &lt;p&gt;Cecilia Kang reports on technology and regulatory policy and is based in Washington \nD.C. She has written about technology for over two decades.&lt;/p&gt;\nHighlight: The office is reviewing how centuries-old laws should apply to artificial intelligence technology, with both \ncontent creators and tech giants arguing their cases.\nBody\nThe office is reviewing how centuries-old laws should apply to artificial intelligence technology, with both content \ncreators and tech giants arguing their cases.\nFor decades, the Copyright Office has been a small and sleepy office within the Library of Congress. Each year, the \nagency’s 450 employees register roughly half a million copyrights, the ownership rights for creative works, based on \na two-centuries-old law.\nIn recent months, however, the office has suddenly found itself in the spotlight. Lobbyists for Microsoft, Google, and \nthe music and news industries have asked to meet with Shira Perlmutter, the register of copyrights, and her staff. \nThousands of artists, musicians and tech executives have written to the agency, and hundreds have asked to speak \nat listening sessions hosted by the office.\nThe attention stems from a first-of-its-kind review of copyright law that the Copyright Office is conducting in the age \nof artificial intelligence. The technology — which feeds off creative content — has upended traditional norms around \ncopyright, which gives owners of books, movies and music the exclusive ability to distribute and copy their works.\nThe agency plans to put out three reports this year revealing its position on copyright law in relation to A.I. The \nreports are set to be hugely consequential, weighing heavily in courts as well as with lawmakers and regulators.\n“We are now finding ourselves the subject of a lot of attention from the broader general public, so it is a very \nexciting and challenging time,” Ms. Perlmutter said.\nThe Copyright Office’s review has thrust it into the middle of a high-stakes clash between the tech and media \nindustries over the value of intellectual property to train new A.I. models that are likely to ingest copyrighted books, \nnews articles, songs, art and essays to generate writing or images. Since the 1790s, copyright law has protected \nworks so an author or artist “may reap the fruits of his or her intellectual creativity,” the Copyright Office declares on \nits website.\nThat law is now a topic of hot debate. Authors, artists, media companies and others say the A.I. models are \ninfringing on their copyrights. Tech companies say that they aren’t replicating the materials and that they consume \ndata that is publicly available on the internet, practices that are fair use and within the bounds of the law. The fight \nhas led to lawsuits, including one by The New York Times against the ChatGPT creator OpenAI and Microsoft. And \ncopyright owners are pushing for officials to rein in the tech companies.\nThe Sleepy Copyright Office in the Middle of a High-Stakes Clash Over A.I.\n“What the Copyright Office is doing is a big deal because there are important principles of law and lots and lots of \nmoney involved,” said Rebecca Tushnet, a professor of copyright and intellectual property law at Harvard Law \nSchool. “At the end of the day, the issue is not whether these models will exist. It’s who will get paid.”\nCongress created the Copyright Office in 1870 to register licenses for books, maps, essays and other creative \nworks and store those works for the use of lawmakers at the Library of Congress. The first registration was given to \nthe “Philadelphia Spelling Book,” a children’s language book.\nWhen Ms. Perlmutter, a veteran copyright official and former intellectual property lawyer for Time Warner, was \nappointed to lead the Copyright Office in late 2020, she promised to bring the office into the modern era by focusing \non big tech trends. She took inspiration from previous leaders, who dealt with technological innovations including \nthe camera, records, Xerox machines, the internet and streaming music, all of which required the office to weigh in \non how copyright would apply and advise Congress on proposed updates to the law.\nRight away, A.I. became a hot topic. Stephen Thaler, a computer scientist, tried to register an A.I.-generated art \npiece for a copyright by submitting an application on the Copyright Office’s website. In 2019, the office rejected his \nfirst attempt to register the piece, a pixelated scene of train tracks running through a tunnel overgrown with brush \nand flowers called “A Recent Entrance to Paradise.” In February 2022, Ms. Perlmutter declined his second attempt \nto register the piece on the same grounds: Copyrights were given only to original works created by humans.\nThe decision — a first on an A.I.-produced work — set an important precedent. Artists and lawmakers flooded Ms. \nPerlmutter’s office with emails and phone calls asking her to also intervene in the way A.I. companies were using \ncopyrighted material to train their systems.\nIn August, she opened the formal review of A.I. and copyright law. The office said it would examine whether the use \nof intellectual property to train A.I. models violated the law and would look more deeply into whether machine-\ngenerated works could be eligible for copyright protections. The office said it would also review how A.I. tools were \ncreating content that used the names, images and likenesses of individuals without their consent or compensation.\n“The attention on A.I. is intense,” Ms. Perlmutter said in an interview. “The current generative A.I. systems raise a \nlot of complicated copyright issues — some have called them existential — that really require us to start grappling \nwith fundamental questions about the nature and value of human creativity.”\nThe interest in the office’s review was overwhelming. The office solicited public comments on the topic and received \nmore than 10,000 responses on a form on its website. A typical policy review gets no more than 20 comments, the \noffice said.\nTech companies argued in comments on the website that the way their models ingested creative content was \ninnovative and legal. The venture capital firm Andreessen Horowitz, which has several investments in A.I. start-ups, \nwarned in its comments that any slowdown for A.I. companies in consuming content “would upset at least a \ndecade’s worth of investment-backed expectations that were premised on the current understanding of the scope of \ncopyright protection in this country.”\nOpenAI, Microsoft, Meta (Facebook’s parent) and Google are currently relying on a 2015 court decision in a case \nfiled by the Authors Guild.\nThe guild sued Google in 2005 for scanning books to use in excerpts in its search engine results and to share with \nlibraries. A court ruled that Google had not violated copyright law. It said that the scanning of entire books was \npermissible because Google didn’t make the full book available and that it was “transformative” use of copyrighted \nmaterial. Google relied on an exemption to copyright law known as “fair use” that allows limited replication of \ncopyrighted material for things like criticism, parody or other transformational uses.\nGoogle, Meta and the A.I. start-up Anthropic all echoed arguments from that case in their comments to the \nCopyright Office, including that A.I. copies the information to analyze data, not repurpose it for creative works.\nThe Sleepy Copyright Office in the Middle of a High-Stakes Clash Over A.I.\nAuthors, musicians and the media industry argued that by taking their content without permission or licensing \npayments, the A.I. companies were robbing them of their livelihoods.\n“The absence of consent and compensation in this process is theft,” Justine Bateman, the “Family Ties” actress and \nauthor, wrote in comments to the Copyright Office.\nNews Corp, which publishes The Wall Street Journal and The New York Post, implored the office to “not lose sight \nof this simple truth: Protecting content creators is one of copyright law’s core missions.” (The Times also submitted \na comment.)\nMs. Perlmutter said she and a staff of about two dozen copyright lawyers were going through each comment filed to \nthe office.\nStill, the office may not offer clear-cut views that will satisfy either the tech companies or creative people.\n“As technology gets more and more sophisticated, the challenges are exponentially more difficult and the risks and \nrewards are exponentially greater,” Ms. Perlmutter said. \nAudio produced by Sarah Diamond.\nAudio produced by Sarah Diamond. \nPHOTOS: Shira Perlmutter’s agency will grapple with the “value of human creativity.” (B1); Lobbyists for Microsoft, \nGoogle, and the music and news industries have sought meetings with the Copyright Office. (PHOTOGRAPHS BY \nJARED SOARES FOR THE NEW YORK TIMES) (B3) This article appeared in print on page B1, B3.\nLoad-Date: February 4, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "AI LIFTS ADOBE ABOVE DEAL CLOUD",
        "media": "Wall Street Journal Abstracts",
        "time": "June 23, 2023",
        "section": "B; Pg. 12",
        "length": "40 words",
        "byline": "DAN GALLAGHER",
        "story_text": "AI LIFTS ADOBE ABOVE DEAL CLOUD\nWall Street Journal Abstracts\nJune 22, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 12\nLength: 40 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column notes shares of Photoshop maker Adobe have surged since it \nintroduced generative artificial intelligence tool, but scrutiny of its $20 billion Figma acquisition deal is growing; \nphoto; graph (M)\nGraphic\n \nCombination\nLoad-Date: June 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "Microsoft and Google Unveil A.I. Tools for Businesses",
        "media": "The New York Times",
        "time": "March 17, 2023",
        "section": "TECHNOLOGY",
        "length": "1075 words",
        "byline": "Karen Weise and Nico Grant",
        "story_text": "Microsoft and Google Unveil A.I. Tools for Businesses\nThe New York Times \nMarch 16, 2023 Thursday 13:29 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1075 words\nByline: Karen Weise and Nico Grant\nHighlight: New artificial intelligence technology is roiling Silicon Valley. For now, the most obvious ways to use it \nare in software like Microsoft’s suite of products.\nBody\nNew artificial intelligence technology is roiling Silicon Valley. For now, the most obvious ways to use it are in \nsoftware like Microsoft’s suite of products.\nFor all the talk about the transformative nature of new technology called generative artificial intelligence, some of \nthe earlier commercial uses may be far more prosaic: formatting a PowerPoint slide, summarizing a call or writing \nto-do lists.\nMany of the first broad applications of generative A.I. have burst into the realm of the consumer internet, with \nopen-ended chats and more sophisticated versions of internet search. But announcements this week by Microsoft \nand Google about adding A.I. into the daily tools of knowledge workers and software developers show how the \nmundane — but very profitable — software for businesses may be the clearest moneymakers.\n“As we look ahead, we believe this next generation of A.I. will unlock a new wave of productivity growth,” Satya \nNadella, Microsoft’s chief executive, said while announcing a set of tools Thursday. He added that new features \nwould “remove the drudgery from our daily tasks and jobs.”\nThe new tools are more sober than visions of how generative A.I. might evolve or upend Google’s search engine, \nused by billions of people, but they form a crucial part of Google’s and Microsoft’s strategies to cash in on their A.I. \ninvestments.\nMicrosoft has made a series of announcements describing how it plans to push A.I. into all corners of its business. \nIt has committed $13 billion into its partnership with the start-up OpenAI, whose ChatGPT chatbot captured the \npublic imagination when it was released at the end of November. Just over a month ago, Microsoft also integrated \nOpenAI’s models into its Bing search engine.\nThursday’s announcement cuts to the heart of some of Microsoft’s largest businesses, in products like its software \nsuite that includes Word, Excel and Outlook. Office products and related cloud services produced $11.8 billion in \nrevenue in Microsoft’s latest quarter, while search and news advertising generated about $3.2 billion in sales.\nMicrosoft focused on integrating A.I. assistants, which it calls Copilots, into software. It is drawing on data that \nbusiness customers have already stored in the company’s systems — chats in its collaboration tool Teams, \ndocuments stored in its cloud and emails on its servers.\nWith Business Chat, a new feature for working across the tools, someone can ask for a customer update and it will \nscan recent emails, meeting notes and other information to generate a response.\nMicrosoft and Google Unveil A.I. Tools for Businesses\nThe products are being tested by 20 business customers, and pricing and licensing details will be released in the \ncoming weeks, Jared Spataro, a Microsoft executive, said in an interview.\nThe assistants produce sample text, but Microsoft stressed that users should review and tweak the results. When \ngenerating text, the Copilot may make mistakes or generate irrelevant information.\nIt can also suggest feelings or emotions. One executive showed how the Copilot in Word could write a personal \nspeech celebrating her daughter’s high school graduation. “In summary, to say we are proud of Tasha would be an \nunderstatement,” the model proposed.\nAs Mr. Spataro demonstrated how he could use the assistant to generate an email providing his feedback on a draft \nof a blog post, the A.I. tool generated an email that said Mr. Spataro was “impressed” and had made minor \ngrammatical changes to the post — though it had no way of knowing whether he was “impressed” or that the \nchanges were only grammatical.\n“It doesn’t know at all,” Mr. Spataro said when asked about it. He said the email should be edited, adding, “I mean, \nthis is an example of why we called it a Copilot.”\nLast month, Microsoft pulled back some of the new Bing’s functions after its chat produced inaccurate, bizarre and \nat times creepy results. The new Bing had “millions of active users” in its first month, about a third of whom had not \nused Bing before, the company said. The company has said it will experiment with how to integrate ads into the \nresults.\nMicrosoft has been jockeying with Google, which has said its chatbot, Bard, will be released in the “coming weeks” \nas an experimental demonstration. But Dan Taylor, Google’s vice president of global ads, said in an interview last \nmonth that the company had not yet figured out a way to make money from the chatbot.\nIn an announcement on Tuesday, Google underscored a similar path to generate profit from A.I. technology: by \nincorporating it into software that businesses pay for, and selling the underlying A.I. to other organizations.\nGoogle said it would embed A.I. into its email and word-processing tools, Gmail and Docs, so that it could draft \nemails, job descriptions and other types of documents from simple written prompts. With a few clicks, Google said, \nusers could then adjust the tone to be more playful or professional, and have the A.I. trim or expand on the content. \nThe features will first be available to what the company called trusted users.\nThomas Kurian, the chief executive of Google Cloud, which sells software and services to other businesses, said in \na blog post that generative A.I. was a generational shift in technology, akin to the move from desktop computing to \nmobile devices. Powered by a system known as a large language model, the A.I. can generate text and other media \nwhen given short prompts.\nJust as software developers flocked to develop applications for the iPhone, Google expects that many programmers \nwill want to build new A.I. applications and businesses. Mr. Kurian said the company would offer two new products, \nPaLM API and MakerSuite, to aid their efforts.\nGoogle also debuted Generative AI App Builder, a tool to help businesses and governments quickly develop their \nown chatbots. The company will also let organizations customize A.I. with their own data through an existing \nproduct, Vertex AI.\nBuilding large language models is an expensive enterprise requiring rare and specialized engineers, and \nsupercomputers built specifically to handle the processing demands. Most companies will not have the resources to \nreplicate Google’s, Microsoft’s or OpenAI’s years of work building these systems, so the companies are racing to \nfulfill their demand.\nMr. Kurian said he expected this generation of A.I. to have “a profound effect on every industry.”\nCade Metz contributed reporting.\nMicrosoft and Google Unveil A.I. Tools for Businesses\nCade Metz contributed reporting. \nThis article appeared in print on page B6.\nLoad-Date: March 17, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE",
        "media": "Wall Street Journal Abstracts",
        "time": "April 11, 2023",
        "section": "A; Pg. 12",
        "length": "25 words",
        "byline": "TOM PARONIS",
        "story_text": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE\nWall Street Journal Abstracts\nApril 8, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 12\nLength: 25 words\nByline: TOM PARONIS\nBody\nABSTRACT\nTom Paronis letter responds to Peggy Noonan’s April 1 declarations column on dangers in generative artificial \nintelligence like OpenAI’s ChatGPT\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "more_protections;_A_mother_and_her_14-year-old_daughter_are_advocating_for_Dec2023",
        "header": "Teen girls are being victimized by deepfake nudes. One family is pushing for",
        "media": "more protections; A mother and her 14-year-old daughter are advocating for",
        "time": "December 3, 2023",
        "section": "NATION WORLD",
        "length": "1212 words",
        "byline": "HALELUYA HADERO",
        "story_text": "Teen girls are being victimized by deepfake nudes. One family is pushing for \nmore protections; A mother and her 14-year-old daughter are advocating for \nbetter protections for victims after AI-generated nude images of the teen and \nother female classmates were circulated at a high school in New Jersey\nDayton Daily News (Ohio)\nDecember 2, 2023 Saturday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1212 words\nByline: HALELUYA HADERO\nBody\nA mother and her 14-year-old daughter are advocating for better protections for victims after AI-generated nude \nimages of the teen and other female classmates were circulated at a high school in New Jersey.\nMeanwhile, on the other side of the country, officials are investigating an incident involving a teenage boy who \nallegedly used artificial intelligence to create and distribute similar images of other students – also teen girls - that \nattend a high school in suburban Seattle, Washington. \nThe disturbing cases have put a spotlight yet again on explicit AI-generated material that overwhelmingly harms \nwomen and children and is booming online at an unprecedented rate. According to an analysis by independent \nresearcher Genevieve Oh that was shared with The Associated Press, more than 143,000 new deepfake videos \nwere posted online this year, which surpasses every other year combined. \nDesperate for solutions, affected families are pushing lawmakers to implement robust safeguards for victims whose \nimages are manipulated using new AI models, or the plethora of apps and websites that openly advertise their \nservices. Advocates and some legal experts are also calling for federal regulation that can provide uniform \nprotections across the country and send a strong message to current and would-be perpetrators. \n\"We're fighting for our children,\" said Dorota Mani, whose daughter was one of the victims in Westfield, a New \nJersey suburb outside of New York City. \"They are not Republicans, and they are not Democrats. They don't care. \nThey just want to be loved, and they want to be safe.\" \nThe problem with deepfakes isn't new, but experts say it's getting worse as the technology to produce it becomes \nmore available and easier to use. Researchers have been sounding the alarm this year on the explosion of AI-\ngenerated child sexual abuse material using depictions of real victims or virtual characters. In June, the FBI warned \nit was continuing to receive reports from victims, both minors and adults, whose photos or videos were used to \ncreate explicit content that was shared online. \nSeveral states have passed their own laws over the years to try to combat the problem, but they vary in scope. \nTexas, Minnesota and New York passed legislation this year criminalizing nonconsensual deepfake porn, joining \nVirginia, Georgia and Hawaii who already had laws on the books. Some states, like California and Illinois, have only \ngiven victims the ability to sue perpetrators for damages in civil court, which New York and Minnesota also allow. \nTeen girls are being victimized by deepfake nudes. One family is pushing for more protections A mother and \nher 14-year-old daughter are advocating for better pr....\nA few other states are considering their own legislation, including New Jersey, where a bill is currently in the works \nto ban deepfake porn and impose penalties  either jail time, a fine or both  on those who spread it. \nState Sen. Kristin Corrado, a Republican who introduced the legislation earlier this year, said she decided to get \ninvolved after reading an article about people trying to evade revenge porn laws by using their former partner's \nimage to generate deepfake porn. \n\"We just had a feeling that an incident was going to happen,\" Corrado said. \nThe bill has languished for a few months, but there's a good chance it might pass, she said, especially with the \nspotlight that's been put on the issue because of Westfield. \nThe Westfield event took place this summer and was brought to the attention of the high school on Oct. 20, \nWestfield High School spokesperson Mary Ann McGann said in a statement. McGann did not provide details on \nhow the AI-generated images were spread, but Mani, the mother of one of the girls, said she received a call from \nthe school informing her nude pictures were created using the faces of some female students and then circulated \namong a group of friends on the social media app Snapchat. \nThe school hasn't confirmed any disciplinary actions, citing confidentiality on matters involving students. Westfield \npolice and the Union County Prosecutor's office, who were both notified, did not reply to requests for comment. \nDetails haven't emerged about the incident in Washington state, which happened in October and is under \ninvestigation by police. Paula Schwan, the chief of the Issaquah Police Department, said they have obtained \nmultiple search warrants and noted the information they have might be \"subject to change\" as the probe continues. \nWhen reached for comment, the Issaquah School District said it could not discuss the specifics because of the \ninvestigation, but said any form of bullying, harassment, or mistreatment among students is \"entirely unacceptable.\" \nIf officials move to prosecute the incident in New Jersey, current state law prohibiting the sexual exploitation of \nminors might already apply, said Mary Anne Franks, a law professor at George Washington University who leads \nCyber Civil Rights Initiative, an organization aiming to combat online abuses. But those protections don't extend to \nadults who might find themselves in a similar scenario, she said. \nThe best fix, Franks said, would come from a federal law that can provide consistent protections nationwide and \npenalize dubious organizations profiting from products and apps that easily allow anyone to make deepfakes. She \nsaid that might also send a strong signal to minors who might create images of other kids impulsively. \nPresident Joe Biden signed an executive order in October that, among other things, called for barring the use of \ngenerative AI to produce child sexual abuse material or non-consensual \"intimate imagery of real individuals.\" The \norder also directs the federal government to issue guidance to label and watermark AI-generated content to help \ndifferentiate between authentic and material made by software. \nCiting the Westfield incident, U.S. Rep. Tom Kean, Jr., a Republican who represents the town, introduced a bill on \nMonday that would require developers to put disclosures on AI-generated content. Among other efforts, another \nfederal bill introduced by U.S. Rep. Joe Morelle, a New York Democrat, would make it illegal to share deepfake \nporn images online. But it hasn't advanced for months due to congressional gridlock. \nSome argue for caution  including the American Civil Liberties Union, the Electronic Frontier Foundation and The \nMedia Coalition, an organization that works for trade groups representing publishers, movie studios and others  \nsaying that careful consideration is needed to avoid proposals that may run afoul of the First Amendment. \n\"Some concerns about abusive deepfakes can be addressed under existing cyber harassment\" laws, said Joe \nJohnson, an attorney for ACLU of New Jersey. \"Whether federal or state, there must be substantial conversation \nand stakeholder input to ensure any bill is not overbroad and addresses the stated problem.\" \nTeen girls are being victimized by deepfake nudes. One family is pushing for more protections A mother and \nher 14-year-old daughter are advocating for better pr....\nMani said her daughter has created a website and set up a charity aiming to help AI victims. The two have also \nbeen in talks with state lawmakers pushing the New Jersey bill and are planning a trip to Washington to advocate \nfor more protections. \n\"Not every child, boy or girl, will have the support system to deal with this issue,\" Mani said. \"And they might not see \nthe light at the end of the tunnel.\" \nAP reporters Geoff Mulvihill and Matt O'Brien contributed from Cherry Hill, New Jersey and Providence, Rhode \nIsland.\nGraphic\n \nWestfield High School in Westfield, N.J. is shown on Wednesday, Nov. 8, 2023. AI-generated nude pictures were \ncreated using the faces of some female students at the school and then circulated among a group of friends on the \nsocial media app Snapchat. (AP Photo/Peter K. Afriyie)\nLoad-Date: December 3, 2023"
    },
    {
        "file_name": "'Copilot_key'_for_Windows_computers_is_Microsoft's_latest_bid_to_capitalize_on_Jan2024",
        "header": "BUSINESS; Coming soon to some PC keyboards: An AI chatbot button; New",
        "media": "'Copilot key' for Windows computers is Microsoft's latest bid to capitalize on",
        "time": "January 5, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "420 words",
        "byline": "Associated Press",
        "story_text": "BUSINESS; Coming soon to some PC keyboards: An AI chatbot button; New \n'Copilot key' for Windows computers is Microsoft's latest bid to capitalize on \nits OpenAI partnership.\nLos Angeles Times\nJanuary 5, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 420 words\nByline: Associated Press\nBody\nComputer keyboards are making room for an artificial intelligence chatbot button as Microsoft unveils its first major \nkeyboard redesign in three decades.\nStarting this month, some new personal computers that run Microsoft's Windows 11 operating system will have a \nspecial \"Copilot key\" that launches the software giant's AI chatbot.\nGetting third-party computer makers to add an AI button to laptops is the latest move by Microsoft to capitalize on \nits partnership with OpenAI, the maker of ChatGPT, and make itself a gateway for applications of generative AI \ntechnology.\nAlthough most people now connect to the internet -- and many AI applications -- by phone rather than computer, it's \na symbolic kickoff to what's expected to be a competitive year as tech companies race to outdo each other in AI \napplications even as they haven't yet resolved all the ethical and legal ramifications. The New York Times last \nmonth sued both OpenAI and Microsoft, alleging that tools such as ChatGPT and Copilot -- formerly known as Bing \nChat -- are infringing copyrighted news articles.\nThe redesign will be Microsoft's biggest change to PC keyboards since it introduced a special Windows key in the \n1990s. Microsoft's four-squared logo design has evolved, but the key has been a fixture on Windows-oriented \nkeyboards for about three decades.\nThe newest AI button will be marked by the ribbon-like Copilot logo and be located near the space bar. On some \ncomputer keyboards it will replace the right \"CTRL\" key, while on others it will replace a menu key.\nMicrosoft is not the only company with customized keys. Apple pioneered the concept in the 1980s with its \n\"Command\" key, marked by a looped square design (it also sported an Apple logo for a time). Google has a search \nbutton on its Chromebooks and was first to experiment with an AI-specific key to launch its voice assistant on its \nnow-discontinued Pixelbook.\nBut Microsoft has a much stronger hold on the broader PC market through its licensing agreements with third-party \nmanufacturers such as Lenovo, Dell and HP. About 82% of all desktop computers, laptops and workstations run \nWindows, compared with 9% for Apple's in-house operating system and slightly more than 6% for Google's, \naccording to market research firm IDC.\nBUSINESS Coming soon to some PC keyboards: An AI chatbot button New 'Copilot key' for Windows \ncomputers is Microsoft 's latest bid to capitalize on its OpenAI p....\nMicrosoft hasn't yet said which computer makers are installing the Copilot button beyond Microsoft's own in-house \nline of premium Surface devices. It said some companies are expected to unveil new models at next week's \nconsumer electronics trade show in Las Vegas.\nLoad-Date: January 5, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Microsoft, the Union-Friendly Tech Titan",
        "media": "The New York Times",
        "time": "February 25, 2024",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 1",
        "length": "3787 words",
        "byline": "By Noam Scheiber",
        "story_text": "Microsoft, the Union-Friendly Tech Titan\nThe New York Times\nFebruary 25, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 1\nLength: 3787 words\nByline: By Noam Scheiber\nBody\nThe December day in 2021 that set off a revolution across the videogame industry appeared to start innocuously \nenough. Managers at a Wisconsin studio called Raven began meeting one by one with quality assurance testers, \nwho vet video games for bugs, to announce that the company was overhauling their department. Going forward, \nmanagers said, the lucky testers would be permanent employees, not temps. They would earn an extra $1.50 an \nhour.\nIt was only later in the morning, a Friday, that the catch became apparent: One-third of the studio's roughly 35 \ntesters were being let go as part of the overhaul. The workers were stunned. Raven was owned by Activision \nBlizzard, one of the industry's largest companies, and there appeared to be plenty of work to go around. Several \ntesters had just worked late into the night to meet a looming deadline. \n  ''My friend called me crying, saying, 'I just lost my job,''' recalled Erin Hall, one of the testers who stayed on. ''None \nof us saw that coming.''\n  The testers conferred with one another over the weekend and announced a strike on Monday. Just after they \nreturned to work seven weeks later, they filed paperwork to hold a union election. Raven never rehired the laid-off \nworkers, but the other testers won their election in May 2022, forming the first union at a major U.S. video game \ncompany.\n  It was at this point that the rebellion took a truly unusual turn. Large American companies typically challenge union \ncampaigns, as Activision had at Raven. But in this case, Activision's days as the sole decision maker were \nnumbered. In January 2022, Microsoft had announced a nearly $70 billion deal to purchase the video game maker, \nand the would-be owners seemed to take a more permissive view of labor organizing.\n  The month after the union election, Microsoft announced that it would stay neutral if any of Activision's roughly \n7,000 eligible employees sought to unionize with the Communications Workers of America -- meaning the company \nwould not try to stop the organizing, unlike most employers. Microsoft later said that it would extend the deal to \nstudios it already owned.\n  Q.A. testers can work grueling hours for low pay, and testers at other studios were already considering a union. \nTwo more groups of testers -- one at Activision and one at a Microsoft subsidiary called ZeniMax -- voted to \nunionize after the company's neutrality announcements.\n  Now that Activision is part of Microsoft -- it closed the purchase in October -- testers at several parts of the \ncombined company are seeking to unionize as well, according to union officials. These officials say that the \ncompany has bargained in good faith and that the two sides have made considerable progress toward a first \nMicrosoft , the Union-Friendly Tech Titan\ncontract. Within a few years, Microsoft could have over 1,000 union employees working under collective bargaining \nagreements, making it an outlier in big tech.\n  On one level, it seemed obvious why Microsoft, once a poster child for corporate ruthlessness, would go this route: \nThe company wanted regulators to bless its deal with Activision. Given the Biden administration's close ties with \nlabor, it didn't take a Kissingerian flair for strategy to see that a truce with unions might help. Cynics were quick to \npoint out that the company laid off nearly 10 percent of its video game workers, most of them from Activision, once \nthe deal was in hand.\n  Still, many large tech companies have business before the federal government -- and almost all have taken steps \nto discourage unionization. That includes Amazon, Apple and Google, which are in the sights of antitrust regulators.\n  Like Microsoft, these companies routinely position themselves as progressive employers, pointing to corporate \ndiversity initiatives and support for L.G.B.T.Q. rights. Some channeled their employees' anxiety over Trump-era \npolicies on travel and immigration. Yet only Microsoft, whose leaders say they have been on a ''journey'' rooted in \nthe principle that ''people have a fundamental right to organize,'' has taken a permissive path on unions.\n  And for some employees, that's a key distinction. Workers who have sought to unionize at Amazon, Apple and \nGoogle don't seem persuaded of their employers' benevolence, pointing to evidence of retaliation. (The companies \nhave denied these accusations and say they respect workers' right to organize.) The workers note that Amazon and \nGoogle have hired consulting firms that specialize in fighting unions.\n  By contrast, employees who have sought to unionize at Microsoft consider neutrality ''an absolute gift,'' said \nAutumn Mitchell, a Q.A. worker who was part of the organizing campaign.\n  All of which raises a question: In an age where companies routinely proclaim their commitments to civil rights and \nthe environment, what does it even mean to be a woke employer? And can Microsoft, on many days the most \nvaluable company in the world thanks to its success in artificial intelligence, and with a history of squeezing \ncompetitors, truly claim to be more evolved than most?\n  Remaking a Corporate Image\n  It's not hard to understand why Microsoft executives in the 1990s sometimes came off as villains. In a case that \nwent to trial in 1998, the Justice Department said Microsoft had illegally schemed to crush Netscape after the \nsmaller company rejected its offer to divvy up the browser market. Witnesses said Microsoft executives tossed \naround phrases like ''cut off their air supply'' and ''knife the baby'' when discussing competitors. (Microsoft denied at \nthe time that it had acted illegally; some executives denied using such phrases.)\n  Microsoft successfully appealed a judge's decision to break up the company, but the ordeal still proved costly. It \nprompted comparisons with the great monopolies of yore, like Standard Oil, and cast a shadow over future deals, \nlike the company's abortive attempt in 2008 to buy Yahoo. A court monitored the company for nearly a decade.\n  It was during the antitrust litigation that a Microsoft lawyer named Brad Smith auditioned for the job of general \ncounsel on the basis of a simple philosophy: ''Make peace,'' he urged his higher-ups.\n  Mr. Smith got the job, and Microsoft began to cultivate better relationships with government overseers. Even when \nMicrosoft believed regulators were overstepping their authority, Mr. Smith later recalled in a speech on the legacy of \nthe case, the company would often say ''let's figure out what it makes sense to do nonetheless.''\n  Underlying the approach was Mr. Smith's feel for the shifting ideological tides -- and his sense that shifting with \nthem would serve the company best. One colleague recalled a 2021 presentation to the company's top executives \nin which Mr. Smith predicted that the coming wave of tech regulation would be like the wave of New Deal-era \nfinancial regulations, and that ''the next five years of regulation will define next the 50 years.'' Mr. Smith said the \ncompany should help shape the new rules and adapt to them rather than resist them.\nMicrosoft , the Union-Friendly Tech Titan\n  The break with Microsoft's scorched-earth past was halting at first.In 2012, the company hired the political \nstrategist Mark Penn, who produced a negative ad campaign targeting Google's search engine.\n  But when a new chief executive, Satya Nadella, took over in 2014, he seemed determined to help complete the \nreinvention. He dispatched Mr. Smith to negotiate a peace agreement with Google. He hired a mindfulness guru \nused by the National Football League's Seattle Seahawks to work with top executives.\n  Not that Mr. Nadella and Mr. Smith, who had been promoted to president, were averse to competition. They simply \nwent about it differently. Instead of directly undermining fellow tech companies, they drew contrasts between \nMicrosoft's new high-road practices and rivals' questionable behavior -- for example, by proposing regulations on \nfacial recognition software. Unlike Microsoft, companies like Google and Apple had declined to make their facial \nrecognition versions available for government testing. (Google said the comparison isn't apt because it does not \noffer general facial recognition software.)\n  In 2015, Microsoft, a pioneer among tech companies in hiring temporary workers and contractors to work for less \npay and job security than long-term employees, became one of the first tech giants to require large contractors to \nprovide paid time off for workers assigned to its projects.\n  Amazon appeared to be a particular foil. Mr. Smith noted in his 2019 book ''Tools and Weapons'' that Amazon had \nfought a proposed Seattle tax to fund affordable housing the year before, going so far as to stop planning for a \nbuilding until the tax was lowered. Shortly after, Microsoft made a financial pledge, which eventually reached $750 \nmillion, to expand such housing.\n  (Amazon declined to comment other than to say it had invested more than $600 million in affordable housing to \ndate.)\n  The next year, Microsoft proposed a state tax to subsidize higher education that would require it and Amazon to \npay a higher rate than other businesses. ''Let's ask the largest companies in the tech sector, which are the largest \nemployers of high-skilled talent, to do a bit more,'' Mr. Smith wrote in an opinion essay. Amazon quibbled with the \ntax before backing a compromise.\n  Liberal policymakers noted the contrast between the two companies. ''The level of engagement is totally different,'' \nsaid Representative Pramila Jayapal, a Washington State Democrat who is the chair of the Congressional \nProgressive Caucus. ''It's like night and day from Amazon.''\n  In a way, Mr. Smith and Microsoft had turned the mantra of enlightened self-interest on its head. Increasingly, the \ncompany appeared to practice a kind of self-interested enlightenment, taking positions that appeared calculated to \nhighlight the ways it had reformed itself and to deflect scrutiny toward competitors. \n  The makeover was so successful that the House antitrust subcommittee invited Mr. Smith to brief members in \n2020 as they prepared for a hearing involving the chief executives of Amazon, Apple, Facebook and Google, which \nthe panel was investigating for possible anticompetitive behavior.\n  Yet 18 months later, the company's adult-in-the-room image was suddenly under assault. Shortly after Microsoft \nannounced its plans to purchase Activision, a coalition of liberal groups told the Federal Trade Commission that the \ndeal could ''lead to an undue concentration of market power,'' effectively reviving the 25-year-old critique of \nMicrosoft as a monopolist. Among the groups in the coalition was a prominent union: the Communications Workers \nof America.\n  'It Was Weird, but Good Weird'\n  If someone were to design a tech job with the goal of maximizing interest in a union, there's a good chance it \nwould look like ''quality assurance tester.'' To an outsider, the tester's job can sound dreamy -- being paid to play \nvideo games before they're publicly available. Within the industry, the work is regarded as a physical and mental \nslog. Testers frequently play sections of games over and over for hours in search of subtle glitches.\nMicrosoft , the Union-Friendly Tech Titan\n  At times they must do this during punishing stretches known as ''crunch,'' when a game release is imminent and \nthe work lasts 10 or 12 hours most days, often six days a week. \n  ''One of the things getting us bad is finding out that overtime is happening at 5:30 on a Friday afternoon,'' said \nWayne Dayberry, a tester at a Microsoft-owned studio in Maryland.\n  ''It's like, dude, we need time, you can't just do that. People have kids.''\n  And the work comes with some of the lowest pay in the industry. After their raise in late 2021, many testers at \nActivision still made under $19 an hour. Testers typically remain for years in the position with little prospect of \npromotion to other jobs, even with a college degree.\n  These frustrations had already provoked a union campaign at Activision when Microsoft announced its acquisition. \nC.W.A. officials worried that the tech giant, which had no unionized U.S. employees, would promptly squelch it, and \nthat wages and employment could fall with fewer companies competing for workers.\n  But the opposition of the politically powerful union was not absolute. During a conversation in early 2022, two top \nunion officials told Portia Wu, a Microsoft policy executive who is now Maryland's labor secretary, that a neutrality \nagreement at Activision would help reassure them. Ms. Wu, who had worked with unions as an aide to Senator \nEdward M. Kennedy, agreed to float the idea at Microsoft.\n  She told colleagues that employees tend to win once they get to a union election, which some Activision \nemployees were seeking, and that a contentious election process can damage morale. By reaching a deal with the \ncommunications workers' union, she added, Microsoft could retain more control over the narrative as well as the \ntiming of union elections, which often surprise employers.\n  Mr. Smith and other executives appeared receptive. ''Every time we've talked about this, we've all come to the \nsame point of view that this is the right path for Microsoft,'' he said in an interview with The New York Times. ''That \nwe have way more that we can potentially gain than put at risk.''\n  Chris Shelton, the union's president at the time, and Mr. Smith announced in June 2022 that Microsoft would stay \nneutral in union campaigns at Activision if the acquisition was finalized. Not long after, the union informed Microsoft \nthat a group of Q.A. testers had also been organizing at ZeniMax Media, a video game company Microsoft already \nowned, with studios in Maryland and Texas. The company agreed to grant workers at ZeniMax the same neutrality \ndeal it had negotiated for Activision.\n  Mr. Dayberry, a leader of the union campaign at ZeniMax, said the company was good to its word: Managers \nnever so much as mentioned the union, much less sought to discourage support for it. After years in which workers \nhad clashed with managers over issues like pay, promotions and scheduling, he said, ''It was weird, but good \nweird.'' The workers officially unionized in January 2023.\n  A few months earlier, Mr. Shelton had met with the F.T.C. chair, Lina Khan, and urged her to accept the Activision \ndeal in light of the neutrality agreements. But Ms. Khan, who has helped make labor considerations a key criterion \nfor analyzing mergers, was unimpressed.\n  ''Time and time again, antitrust regulators have heard promises made by companies leading up to a merger, on \neverything from labor to lowering prices, that have been reneged immediately after the merger closes,'' said \nDouglas Farrar, an F.T.C. spokesman.\n  The Activision deal finally closed in October, after a federal judge denied the F.T.C.'s request to block it \ntemporarily. Analysts say the investment is important for expanding Microsoft's presence in mobile gaming and \ncould prove highly lucrative if the company can incorporate new A.I. capabilities into its games.\n  In the meantime, the opposition of the agency -- which has appealed the ruling and said the recent layoffs \ncontradict Microsoft's earlier assurances -- has continued. (Microsoft said many of the layoffs had been planned by \nActivision.)\nMicrosoft , the Union-Friendly Tech Titan\n  The company's courtship of labor has continued as well. In December, Microsoft announced that it would \neffectively extend the neutrality agreement to any group of employees seeking to join an affiliate of the A.F.L.-\nC.I.O., the labor federation that encompasses C.W.A. and nearly 60 other unions. Roughly 100,000 people will be \neligible to unionize without opposition from their employer under the company's new framework.\n  Liz Shuler, the A.F.L.-C.I.O.'s president, said Microsoft had gone further in collaborating with organized labor than \nalmost any other major company. She said she first met Mr. Smith to discuss labor issues almost two years ago, at \nwhich point he told her, ''If workers want a union, why shouldn't they be able to form one?'' Then he added: ''This is \nthe prevailing winds of change in the country. I think Microsoft should be adapting to it instead of resisting it.''\n  A Kind of Corporate Paternalism\n  Is there such a thing as a woke corporation? Conservatives say the answer is emphatically yes. In their telling, \ncorporate executives have been foisting left-wing values on the country for decades and redoubled their efforts \naround the time of Donald J. Trump's election, taking liberal positions on transgender rights, voting rights and gun \ncontrol. They note that scores of companies announced diversity initiatives during the protests that followed George \nFloyd's death.\n  But skeptics question whether these corporate initiatives are examples of progressive convictions in action, or \nsimply investments in placating liberals and warding off calls for regulation, higher taxes and higher pay. Certainly, \nthe gestures aren't breaking the bank: In 2020, Chipotle pledged $1 million to civil rights organizations. By contrast, \na 10 percent increase in employee compensation would have cost the company tens of millions of dollars. (The \ncompany ended a 10 percent hourly pay increase about three months into the pandemic.)\n  Even companies often cited for their generosity to employees have generally spurned organized labor. Whole \nFoods and other progressive-minded companies, like Starbucks and Trader Joe's, have at times offered retail \nworkers above-market wages or benefits. Whole Foods has built an entire philosophy out of its crunchy \nrighteousness, or what its co-founder calls ''conscious capitalism.''\n  But Whole Foods fought unionization in the early 2000s, while Starbucks has been accused by the National Labor \nRelations Board of violating employees' labor rights hundreds of times since its workers began unionizing in 2021. \n(Starbucks denies the accusations; Whole Foods has said it does not believe a union is in employees' interests.)\n  When it comes to their employees, said Matthew Bodie, a law professor at the University of Minnesota, these \ncompanies favor a kind of corporate paternalism. ''We want to be beneficent, but we want to do it on our terms,'' he \nsaid, channeling executives.\n  Even tech companies famous for pampering employees have almost entirely resisted unionization. After \nemployees began to organize in 2018, partly over concerns about the company's contracts with federal security \nagencies, Google hired a consulting firm that specializes in stifling unions. The company fired at least four \nemployees involved in protesting the contracts. (Google said the firings had nothing to do with protest activity.)\n  When I asked Mr. Smith why Microsoft was willing to embrace neutrality when its competitors were not, he told me \nthat ''the tech sector has often been built by founders, and founders have often been very focused on retaining a \nlevel of control over their enterprises.'' By contrast, he said, ''I think the fact that Microsoft is a little bit older, \nsometimes a little bit wiser, at least gives us an opportunity to think more broadly.''\n  White-Collar Collective Action\n  Activision may have been the immediate impetus for Microsoft's labor stance, but the neutrality deal could benefit \nthe company far beyond the acquisition. It may be a relatively cost-effective way to cast the company as pro-worker \nat a time when millions are worried about losing their jobs to generative A.I., whose release has helped \nsupercharge Microsoft's share price. Noting that unions are not a topic raised by analysts on the company's \nearnings calls, Gil Luria, who follows Microsoft for the investment bank D.A. Davidson, said, ''I don't expect this to \nbe a material issue.''\nMicrosoft , the Union-Friendly Tech Titan\n  The move could also hamstring two of the company's competitors, Amazon and Apple, where unions have gained \ntraction in recent years.\n  If these companies don't follow Microsoft's lead on neutrality, it could add to the public relations challenges they \nface in opposing unionization. It could also give Microsoft an advantage in the highly competitive market for \nengineers, some of whom have made clear that political and social issues affect their choice of employer.\n  If, on the other hand, those companies relent on neutrality, a much larger portion of their work force could end up \nunionizing than at Microsoft. Amazon employs hundreds of thousands of workers in warehouses across the country, \nwhile Apple employs tens of thousands of workers at retail stores.\n  By contrast, a large majority of Microsoft employees in the United States are white-collar and highly paid. ''There's \nnot a threat of unionization at that level,'' said Joshua Winter, a former Microsoft Philanthropies official focused on \nbringing economic opportunity to historically underrepresented communities. ''They're taking care of those people.''\n  Yet if Microsoft assumed the union effort would end with video game workers, it may have miscalculated. Over the \npast few years, highly paid white-collar workers have begun to assert themselves far beyond Google, engaging in \nforms of collective action that resemble union organizing. Corporate employees have protested what they see as \noverly strict return-to-office policies at companies like Apple and Starbucks, and over a variety of social issues, like \ntheir employers' carbon footprint (Amazon) or lack of diversity (Nike).\n  Even at Microsoft, well-compensated employees have organized protests over political concerns. In 2018, more \nthan 100 employees urged Mr. Nadella, the chief executive, to cancel a nearly $20 million contract with the \nImmigration and Customs Enforcement agency over its role in separating migrant children from their parents. \n  Mr. Nadella responded with an email calling the family separation policy ''cruel and abusive'' and emphasizing that \nthe Trump administration was not relying on Microsoft technology to enact it. But the internal campaign continued \nthe next year, when hundreds of workers at GitHub, a Microsoft subsidiary, signed a letter demanding an end to a \nseparate contract with the agency. The pressure fizzled out after several of the employees involved left the \ncompany.\n  The outcome might have been different if they had the option of unionizing without resistance.\n  Fred Jennings, a former GitHub employee, said he and his colleagues discussed forming a union. ''Quite a few \npeople were saying, 'Look, our best lever to get this to change is to also push for a union,''' he said, adding that, in \nthe end, too many worried about retaliation to make it a viable option.\n  When I asked Mr. Jennings if neutrality would likely have changed his colleagues' appetite for unionizing, he was \nunequivocal: ''With all the advantages of hindsight,'' he said, ''absolutely.''\n  Kirsten Noyes contributed research.Kirsten Noyes contributed research.\nhttps://www.nytimes.com/2024/02/24/business/economy/microsoft-corporate-progressive-labor.html\nGraphic\n \nPHOTOS: PHOTO (PHOTOGRAPH BY CARL GODFREY) (BU1)\nAbove, from left: Brad Smith, Microsoft's president, whose philosophy is ''Make peace''\nand Satya Nadella, the company's chief executive. Below, from left: Chris Shelton, the Communications Workers of \nAmerica president who helped broker a neutrality agreement\nMicrosoft , the Union-Friendly Tech Titan\nand Representative Pramila Jayapal, who saw a contrast between Microsoft and Amazon. (PHOTOGRAPHS BY \nKYLE JOHNSON FOR THE NEW YORK TIMES\nRUTH FREMSON/THE NEW YORK TIMES\nAL DRAGO/BLOOMBERG\nALYSSA SCHUKAR FOR THE NEW YORK TIMES) (BU6)\nBelow, Mellody Hobson, the chairwoman of Starbucks, at a Capitol Hill hearing last March about the company's \nlabor practices. Bottom, members and supporters of Starbucks Workers United protested in November in \nWashington. (PHOTOGRAPHS BY SAMUEL CORUM FOR THE NEW YORK TIMES\nKENNY HOLSTON/THE NEW YORK TIMES\n KEVIN DIETSCH/GETTY IMAGES) (BU7) This article appeared in print on page BU1, BU6, BU7.               \nLoad-Date: February 25, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Mar2023",
        "header": "AI SEEN AS DOING WORK OF MANY PROFESSIONS",
        "media": "Wall Street Journal Abstracts",
        "time": "March 30, 2023",
        "section": "B; Pg. 1",
        "length": "43 words",
        "byline": "LAUREN WEBER, LINDSAY ELLIS",
        "story_text": "AI SEEN AS DOING WORK OF MANY PROFESSIONS\nWall Street Journal Abstracts\nMarch 29, 2023 Wednesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 1\nLength: 43 words\nByline: LAUREN WEBER, LINDSAY ELLIS\nBody\nABSTRACT\nNew study concludes that accountants are among professionals whose careers are most exposed to capabilities of \ngenerative artificial intelligence; finds other professions include mathematicians, interpreters, writers and nearly \n20% of US workforce (M)\nLoad-Date: March 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Medical Debt Relief Tops Murphy's Agenda",
        "media": "The New York Times",
        "time": "January 10, 2024",
        "section": "Section A; Column 0; National Desk; Pg. 13",
        "length": "1131 words",
        "byline": "By Tracey Tully",
        "story_text": "Medical Debt Relief Tops Murphy's Agenda\nThe New York Times\nJanuary 10, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section A; Column 0; National Desk; Pg. 13\nLength: 1131 words\nByline: By Tracey Tully\nBody\n''Nobody should have to worry about being able to afford critical health care,'' Gov. Philip D. Murphy said in his \nsixth-annual State of the State address.\nGov. Philip D. Murphy of New Jersey embraced proposals to make it easier to build affordable housing and cut out-\nof-pocket expenses for abortions in his annual State of the State address on Tuesday. \n  The governor, a second-term Democrat barred from running for re-election, also said he would support the \nincreased use of phonics to teach reading and that he would continue to work to ease the burden of medical debt, \npresumably by expanding a program he funded last year that sought to leverage $10 million to retire 100 times that \namount in residents' debt.\n  ''In the wealthiest nation in the world,'' the governor told lawmakers from the Senate and Assembly in a joint \naddress in Trenton, ''nobody should have to worry about being able to afford critical health care services or a \nlifesaving medical procedure.''\n  The goals mentioned by the governor were fairly modest as he looks ahead to his final two years in office, and \nthey largely piggybacked on existing initiatives proposed by the Democrat-led Legislature.\n  Mr. Murphy made a glancing reference to his support for wind energy, but offered no hint about how he might pivot \nafter the Danish company Orsted abruptly withdrew in November from its plan to build two wind farms off the Jersey \nShore. The canceled projects represented a major setback for the state's, and the country's, ambitious goals for \nreducing greenhouse gas emissions that are accelerating climate change, and some feared it could hurt Democrats \ndays before an election.\n  Even before the Orsted announcement, most Democrats in tight races had avoided campaigning with Mr. Murphy, \nwho was re-elected in November 2021 by only about three percentage points. Democrats, however, went on to \nexpand their majority in Trenton, leading the governor to appear to take a veiled swipe Tuesday at his legislative \ncolleagues.\n  ''I guess being in a picture with me wasn't so bad after all,'' he said.\n  Here are some of the highlights in Mr. Murphy's sixth-annual State of the State address:\n  Louisa Carman Medical Debt Relief Act\n  Health-related costs are the No. 1 source of debt in the United States, surpassing debt linked to credit cards, loans \nand utility costs, according to the White House.\nMedical Debt Relief Tops Murphy's Agenda\n  In New Jersey, the outlook is even more grim.\n  New Jersey ranked 45 out of 50 states for policies that help residents burdened with unpaid medical bills, \naccording to a report by Innovation for Justice and a team of researchers from the University of Arizona and the \nUniversity of Utah.\n  The governor used his address to the Legislature to propose a package of medical-debt-relief bills to help families \n''avoid being caught in a medical debt trap'' and require medical bills to be clear and transparent.\n  Part of the legislation would be named for Louisa Carman, who was killed on New Year's Day in a traffic accident \nin New Jersey. Ms. Carman, 25, was a policy analyst who worked for the governor and who had focused on making \nhealth care more affordable and accessible.\n  ''With this legislative package we can carry her mission forward,'' the governor said, choking back tears.\n  Fully funded abortions\n  Before the Supreme Court overturned Roe v. Wade in 2022, Mr. Murphy and state lawmakers proposed an \nexpansion of reproductive health care access while at the same time enshrining abortion as a right in New Jersey.\n  Lawmakers succeeded in codifying the procedure as a constitutional right in the state, limiting the effect of the \nSupreme Court decision.\n  But they fell short of winning support to fully fund the procedure for low-income women.\n  Beginning last year, the New Jersey Department of Banking and Insurance started requiring coverage of abortion \nservices. And Mr. Murphy said the Legislature should pass a bill sponsored in the past by the Senate majority \nleader, M. Teresa Ruiz, and Assemblywoman Shanique Speight, to ''scrap out-of-pocket costs for abortion \nprocedures.''\n  Sound-it-out reading\n  Mr. Murphy joined a chorus of governors, including Gov. Kathy Hochul of New York, who now say that instructors \nshould return to sound-it-out instruction known as phonics when teaching children to read.\n  Across the country, as reading scores have lagged, bipartisan support has grown for what has become known as \nthe ''science of reading.''\n  Mr. Murphy said he planned to introduce ''new initiatives'' to ''teach our kids the fundamentals of reading -- like \nsounding out letters and combining them into words.'' He did not elaborate on the proposal, but said the goal was to \n''improve literacy rates among our children.''\n  Affordable housing\n  Mr. Murphy said he supported a proposal unveiled last month by the leaders of the Assembly and the Senate to \nmake it easier to build more affordable housing ''efficiently and equitably.''\n  The proposal calls for a new, streamlined process to give towns greater flexibility when building low-cost housing.\n  It would also create a neutral panel of experts to mediate conflicts over how much and where affordable housing \nshould be built in an effort to cut down on costly and lengthy litigation that can delay construction.\n  The right to vote at 16\n  Mr. Murphy said he would support lowering the voting age in school board elections statewide to 16.\nMedical Debt Relief Tops Murphy's Agenda\n  On Wednesday, the City Council in Newark is expected to approve legislation that would make it the largest city in \nthe country to permit 16- and 17-year-olds to vote in school board elections. The next such election is in April.\n  In Trenton, lawmakers are expected to introduce legislation in the coming months that would require communities \nacross the state to allow 16-year-olds to vote in school board races.\n  ''Encouraging our young neighbors to engage with democracy is really about encouraging them to become lifelong \nvoters,'' the governor said.\n  Artificial intelligence\n  The governor also announced what he called an ''A.I. moonshot.''\n  He said he would press to make New Jersey a hub of innovators and leaders willing to invest in research and \ndevelopment surrounding artificial intelligence.\n  Last month, the New Jersey Economic Development Authority announced plans to join with Princeton University to \nmake the state ''an integrated hub of A.I. activity.'' He said the state's chief innovation officer, Beth Noveck, would \nalso become New Jersey's first A.I. strategist.\n  Unlike Ms. Hochul, who on Tuesday proposed spending $275 million in state funds to create a public-private \npartnership aimed at making New York a key player in artificial intelligence research, Mr. Murphy offered few \nadditional details.\n  ''The future of generative A.I. has yet to be written,'' he said. ''New Jersey can be the author.''\nhttps://www.nytimes.com/2024/01/09/nyregion/nj-murphy-state-of-the-state.html\nGraphic\n \nThis article appeared in print on page A13.               \nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "IT gives bears a bull hug: what is driving the rally in tech stocks?",
        "media": "The Economic Times",
        "time": "January 21, 2024",
        "section": "TECH & INTERNET",
        "length": "2329 words",
        "byline": "Beena Parmar and Romita Majumdar",
        "story_text": "IT gives bears a bull hug: what is driving the rally in tech stocks?\nThe Economic Times\nJanuary 21, 2024 Sunday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 2329 words\nByline: Beena Parmar and Romita Majumdar\nBody\nThe expectations from them were never great, but they did exceed most performance parameters with consummate \nease. So much so that the relative stragglers in the current bull run in Indian stocks, technology companies single-\nhandedly carried broadest benchmarks to new records through the first two weeks of January, belying odds of \nmuted earnings performance in a quarter that is traditionally sluggish for the outsourcing majors.At first glance, of \ncourse, the demonstration of investor confidence in a hitherto neglected investment pocket, which makes up nearly \na sixth of the weighting on the Nifty, appears difficult to square with performance in the immediate past. Business \ngrowth has remained muted for most IT majors in the third quarter owing to multiple headwinds related to \nuncertainty in decision-making, deferred discretionary and technology spends, US recession concerns, and \ngeopolitical tensions.Hence, the sentiment for Q4 is far from cheerful. And yet, the market is forgiving. Almost all IT \nstocks (excluding Infosys and Wipro) outperformed broader markets (Nifty-50 and Nifty-500) in calendar year 2023. \nBoth Nifty IT and BSE IT indices have surged around 24% in the calendar year 2023.“Call it happenstance or \ndesign, the IT sector today is at the same crossroads it was at exactly two years ago. \nThe only difference being it is exactly the mirror image of CY22,” according to a report by Nuvama Institutional \nEquities. Back in 2022, interest rates were at an all-time low with rate cuts triggered by Covid19 induced lockdowns \nthat spurred multi-decade high inflation raising expectations of rate hikes by the Federal Reserve, US central \nbank.“Following that, the US was forecast to slip into recession— that we have all been waiting for!” In anticipation, \ninvestors expected lower growth leading to a sharp correction in valuation across the IT sector.“Almost all stocks \ncorrected over 35% over Jan–Jun 2022 — the Nifty IT index too fell by 30%. This period saw a sharp correction in \nthe US tech index — Nasdaq — with which the Indian IT sector has developed a strong correlation. Interestingly, \nthis sharp drop in stock prices was accompanied by very little cut in earnings,” the Nuvama report said.Fast forward \nto today, global interest rates are high at 5.5%, up for more than six months now, with expectations of a rate cut \nfollowing the Fed’s dovish stance last month.IT majors hope that rate cuts will prompt companies to loosen their \npurse strings and start spending on non-core and tech-enabled services. Biswajit Maity, senior principal analyst at \nGartner, feels that a wave of change fatigue is washing over CEOs and CFOs, making them hesitant to sign new IT \ndeals, and asking for more sureties on risks and rewards to move deals forward.“Businesses are examining their IT \nexpenditures more rigorously, showing reluctance in investing unless there is a clear and tangible business value. \nFactors like economic volatility, geopolitical instability, supply chain issues, inflation and skill shortages are \ncontributing to a certain degree of caution. Despite these challenges, we anticipate that IT services spending will \ncontinue to grow, nearing double digits,” he said.Kickstarting the December quarter financial results on January 11, \nhomegrown bellwether Tata Consultancy Services (TCS) reported a 1.9% rise in profit at Rs 11,058 crore on a 4% \nyear on-year (y-o-y) growth in revenue at Rs 60,583 crore. While in constant currency (which discounts the impact \nof currency fluctuations), revenue rose just 1.7%, and smaller rival Infosys’ revenue declined by one per cent.In a \nseasonally weak quarter, third largest IT major and fastest growing large cap in FY24, HCLTech outperformed all its \npeers defying the growth trends to post over 6% rise in both revenue and profit, posting its highest revenue growth \nsince Q3FY21.Even then, HCLTech and all other firms maintained a subdued commentary on discretionary \nIT gives bears a bull hug: what is driving the rally in tech stocks?\nspending in Q4 stating an unchanged demand environment and persistent furloughs.TCS chief executive officer \nand managing director K Krithivasan said that “the optimism around interest rates” has not resulted in a reduction of \nthe uncertainty in decision-making.While TCS does not call out guidance, Infosys narrowed its revenue guidance at \n1.5-2% for FY24 and retained operating margin guidance at 20-22%. HCLTech and Wipro’s Q4 guidance continued \nto remain restrained.Margins across most firms have stayed put with headcount reduction, better utilisation of \nexisting employees and are expected to stabilise.However, the IT players have found unanimous comfort in the \ndeal pipeline owing to the likely rise in pent up demand for tech spending on new technologies.DealsA major part of \nthe pronounced optimism is driven from deal wins in the quarter expecting it to start generating revenues going \nforward.“The large mega deals look to be the one bright spot in an otherwise difficult market… We are also seeing \nsome green shoots around some of the large foundational software areas with encouraging performance of the \nsoftware firms, which often leads tech services spending,” said Peter Bendor-Samuel, chief executive officer at \nEverest Group.During the quarter, TCS reported steady deal wins or total contract value (TCV) at $8.1 billion while \nInfosys booked $3.2 billion worth of large deal wins, albeit both undersized from Q2, which Infosys CEO and MD \nSalil Parekh said was an exceptional quarter for deals.Parekh said 71% of the deals were net new. “If you look at \nthe nine months, it is the highest ever value of deal wins that we have had,” he said in a post results \nconference.Krithivasan also points out that the deal pipeline is solid, conversions have been timely and new deal \nramp ups are also going ahead as planned. HCLTech won 18 large deals with TCV at $1.92 billion, while Wipro, \none of the most under-performers in the sector, also reported strong TCV at $3.8 billion. Even mid-sized IT services \nfirm LTIMindtree’s order book jumped 21% from a year ago to its highest-ever order inflow at $1.5 billion.Further, \nET reported that an estimated$16 billion of global IT services large deals that will come up for renewal in the next \nsix months. “Come FY25, we expect a large part of new deals awarded to get into the execution mode, followed by \na gradual recovery in discretionary spends,” the Nuvama report said. BFSIThe road to recovery for the outsourcing \nindustry is expected to be led by banking, financial services and insurance (BFSI), its largest revenue generating \nsegment, with potential rebound over the next few quarters, going by management commentary in Q3.Despite an \naggregate negative growth of around 1.8% in the BFSI vertical across the top four IT giants, given its size and \nhaving direct correlation with interest rates, the sector is typically the quickest to return to recovery.“We believe that \nthere will be positive momentum for us in the BFSI vertical in the next quarter. Coupled with some of the deals that \nwe have won, I think that should also ramp up in the coming quarter, in the Q4 and Q1. And all that is what makes \nus feel that BFSI will actually return to growth,” N G Subramaniam, chief operating officer and executive director at \nTCS.For the Tata Group company, the TCV for the BFSI business, which comprises more than a third of TCS’s \nrevenue portfolio, was at $2.6 billion. Debashis Chatterjee, CEO and MD of LTIMindtree (sixth-largest IT services \nfirm), which also gets more than one-third of its business from BFSI, said that while the pressures on BFSI funding \nof the enterprise spending will continue for the near term, “the deal pipeline and BFSI is strong, we have some new \nwins as well this quarter. So, we will build on that for the future”.Europe growthAdditionally, the UK and Europe are \nseen as growth regions despite current weakness. “There is also more activity in Europe, most specifically the UK, \nto get some large engagements over the line,” said Phil Fersht, chief executive of HfS Research.For instance, \nWipro won four large deals in Europe in Q3 even as its revenue fell 4.3% sequentially. For TCS, Europe’s TCV has \nfared better than its largest geography North America on a sequential basis. “So, it’s reasonable to expect that \nEurope will also return to growth in the medium to long term,” TCS CEO added in the earnings concall with \nanalysts.HCLTech chief C Vijayakumar said the firm witnessed “decent organic growth” from Europe, which grew \n5% q-o-q on a constant currency basis and won at least three deals from the western region. AI Generative \nartificial intelligence or Gen AI, perhaps the most spoken words in the CEO commentaries in all results \nconference calls, is a key buzzword seeing investments across companies.The TCS chief said the company is \ntaking an early lead in Gen AI capabilities. It has partnered with firms including a European bank, an airline and a \nglobal insurance firm that are employing Gen AI to bolster their services.Infosys CEO Parekh said Gen AI is \nbecoming more and more important in all discussions even if it is small revenue numbers today.“AI capabilities are \nbecoming the key factor in technology investments, as opposed to the old model of merely investing in greater \nnumbers of developers and support personnel.This pivot will take several quarters to mature and reap financial \noutcomes based on co-innovation partnerships and provider investments in their capabilities,” HfS Research’s \nFersht said. In December, global giant and IT harbinger Accenture (which follows a September-August financial \nyear) said it secured projects worth $450 million in generative artificial intelligence in the three months ended \nNovember, a marked jumped of 50% from the $300 million garnered in the previous six months.UpskillingDemand \nfor more specialised talent has also risen. Firms are upskilling and training their workforce to get AI ready. Infosys \nIT gives bears a bull hug: what is driving the rally in tech stocks?\nhas already trained its 100,000 employees in GenAI while its larger peer TCS has trained 150,000 and launched a \nplatform for skilled practitioners amongst TCS employees for exploration and experimentation on various Gen AI \nplatforms.Wipro has trained nearly 200,000 employees in basic AI principles and over 20,000 in advanced content. \nAccording to Gartner’s Maity, the focus on generative AI is expected to bring substantial benefits in the future.“The \nyear 2024 will be the year when organisations invest in planning for how to use Gen AI, which leaves 2025 and \nbeyond as years of action. In a nutshell, we believe 2024 will be the return of growth.”In 2023, most firms had \nannounced significant investment numbers upwards of $1 billion. Kunal Purohit, chief digital services officer, Tech \nMahindra, which is yet to announce its quarterly results, told ET previously that in 2023, generative AI took centre \nstage as a mainstream trend and was already enhancing productivity by 50-60%.HeadcountTherefore, there is a \nsimultaneous shift in workforce dynamics. Post Covid slowdown in hiring has led to a slump in overall headcount, \nwith the top four Indian IT majors reporting a combined drop of 50,875 employees over the past year, with TCS and \nInfosys cumulatively shedding 12,000 employees in Q3 alone from last year.Again, HCLTech remained an \nexception, increasing employees by 2,486. “That is in line with the growth that we are experiencing,” said Prateek \nAggarwal, chief financial officer at HCLTech.However, Infosys is not looking at any immediate campus recruitment. \n“For any volume increase,we have a very strong off-campus programme,” said its outgoing CFONilanjan Roy. TCS, \nmeanwhile, has commenced fresher hiring from campuses,but will continue to recalibrate its lateral hiring with focus \non utilization.“Our business imperative remains nurturing and developing human capital and enhanced focus on \nreskilling and upskilling our employees,” TCS CHRO Milind Lakkadsaid indicating the headcount could further \nshrink.However, Wipro’s HR head SaurabhGovil expects that as demand picks up for the quarters, “we’ll definitely \nlook at hiring in more bigger numbers”.Senior management exitsThe macroeconomic slowdown and recessionary \nconcerns have also resulted in a scarcity of jobs, diminishing the allure of job-hopping for employees. This has \npushed attrition to its lowest numbers.Nevertheless, there has been a notable trend of senior management \nexecutives leaving large IT firms.Infosys, Wipro, and Tech Mahindra have cumulatively witnessed more than 30 top-\nlevel exits over the past year. This has also led to poaching accusations and legal battles.Infosys has accused \nCognizant of poaching its employees through“unethical” means, while Wipro has filed lawsuits against at least two \nof its ex-employees including its CFOJatin Dalal who joined Cognizant inDecember.While Infosys’s Parekh refused \nto comment, Wipro’s CEO ThierryDelaporte said the company expects employees to meet contractual obligations \nand that the lawsuits are“nothing personal or targeted”.Brushing aside his own succession planning reports, \nDelaporte, whose term ends in July 2025, said that the company is building the proper succession planning for his \nrole.“On the overall sector, experts believe that the demand outlook is improving despite low visibility on meaningful \nrecovery of discretionary spends. The pick-up in discretionary spending can aid the return to industry growth. Long \nterm growth prospects for Its sector remain strong. We remain positive that investors with a long term view will \ninvest in the Indian IT sector,” said Sumit Pokharna, VP and research analyst, Kotak Securities.Nuvama added in \nits report thatany stock price reaction driven by the change in the Fed’s stance will not sustain unless it is backed by \nfundamentals. “…earnings must come through — more importantly, earnings must be upgraded from current levels. \nWe anticipate the fundamentals for the sector too shall be conducive for higher growth over the next two-three \nyears.” For Reprint Rights: timescontent.com\nLoad-Date: January 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "The A.I. Revolution Will Change Work. Nobody Agrees How.",
        "media": "The New York Times",
        "time": "June 12, 2023",
        "section": "BUSINESS",
        "length": "1273 words",
        "byline": "Sarah Kessler",
        "story_text": "The A.I. Revolution Will Change Work. Nobody Agrees How.\nThe New York Times \nJune 10, 2023 Saturday 19:46 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1273 words\nByline: Sarah Kessler\nHighlight: The tally of how many jobs will be “affected by” world-changing technology is different depending on who \nyou ask.\nBody\nThe tally of how many jobs will be “affected by” world-changing technology is different depending on who you ask.\nIn 2013, researchers at Oxford University published a startling number about the future of work: 47 percent of all \nUnited States jobs, they estimated, were “at risk” of automation “over some unspecified number of years, perhaps a \ndecade or two.”\nBut a decade later, unemployment in the country is at record low levels. The tsunami of grim headlines back then — \nlike “The Rich and Their Robots Are About to Make Half the World’s Jobs Disappear” — look wildly off the mark.\nBut the study’s authors say they didn’t actually mean to suggest doomsday was near. Instead, they were trying to \ndescribe what technology was capable of.\nIt was the first stab at what has become a long-running thought experiment, with think tanks, corporate research \ngroups and economists publishing paper after paper to pinpoint how much work is “affected by” or “exposed to” \ntechnology.\nIn other words: If cost of the tools weren’t a factor, and the only goal was to automate as much human labor as \npossible, how much work could technology take over?\nWhen the Oxford researchers, Carl Benedikt Frey and Michael A. Osborne, were conducting their study, IBM \nWatson, a question-answering system powered by artificial intelligence, had just shocked the world by winning \n“Jeopardy!” Test versions of autonomous vehicles were circling roads for the first time. Now, a new wave of studies \nfollows the rise of tools that use generative A.I.\nIn March, Goldman Sachs estimated that the technology behind popular A.I. tools such as DALL-E and ChatGPT \ncould automate the equivalent of 300 million full-time jobs. Researchers at Open AI, the maker of those tools, and \nthe University of Pennsylvania found that 80 percent of the U.S. work force could see an effect on at least 10 \npercent of their tasks.\n“There’s tremendous uncertainty,” said David Autor, a professor of economics at the Massachusetts Institute of \nTechnology, who has been studying technological change and the labor market for more than 20 years. “And \npeople want to provide those answers.”\nBut what exactly does it mean to say that, for instance, the equivalent of 300 million full-time jobs could be affected \nby A. I.?\nThe A.I. Revolution Will Change Work. Nobody Agrees How.\nIt depends, Mr. Autor said. “Affected could mean made better, made worse, disappeared, doubled.”\nOne complicating factor is that technology tends to automate tasks, not entire occupations. In 2016, for instance, \nthe artificial intelligence pioneer Geoffrey Hinton considered new “deep learning” technology capable of reading \nmedical images. He concluded that “if you work as a radiologist, you are like the coyote that’s already over the edge \nof the cliff but hasn’t yet looked down.”\nHe gave it five years, maybe ten, before algorithms would “do better” than humans. What he probably overlooked \nwas that reading the images is just one of many tasks (30 of them, according to the U.S. government) that \nradiologists do. They also do things like “confer with medical professionals” and “provide counseling.” Today, some \nin the field worry about an impending shortage of radiologists. And Mr. Hinton has since become a vocal public critic \nof the same technology he helped create.\nMr. Frey and Mr. Osborne calculated their 47 percent number in part by asking technology experts to rate how likely \nentire occupations like “telemarketer” or “accountant” were to be automated. But three years after their paper \npublished, a group of researchers at the ZEW Center for European Economic Research, based in Mannheim, \nGermany, published a similar study that assessed tasks — like “explain products or services” — and found that just \n9 percent of occupations across 21 countries could be automated.\n“People like numbers,” said Melanie Arntz, the lead author of the ZEW paper. “People always think that the number \nmust be somehow solid, you know, because it’s a number. But numbers can really be very misleading.”\nIn some scenarios, A.I. has essentially created a tool, not a full job replacement. You’re now a digger who can use \nan excavator instead of a shovel. Or a nurse practitioner with access to better information for diagnosing a patient. \nIt’s possible that you should charge more per hour, because you’re going to get a lot more done.\nIn other scenarios, the technology is replacing your labor rather complementing it. Or turning your job from one that \nrequires special skills to one that doesn’t. That is not likely to go well for you.\nIn either case, says Mr. Autor, technological developments throughout history have tended to mostly affect wages \nand wealth distribution — not how many jobs are available. “This kind of exercise risks missing the forest by \nfocusing on one very prominent tree,” he said of studies that look at how much human work could be replaced by \nA.I.\nWhat he considers to be another key focus — how artificial intelligence will change the value of skills — is difficult to \npredict, because the answer depends partly on how new tools are designed, regulated and used.\nTake customer service. Many companies have handed the task of answering phones to an automated decision \ntree, bringing in the human operator only to troubleshoot. But one Fortune 500 enterprise software company has \napproached the problem differently. It created a generative A.I. tool to provide the agents with suggestions for what \nto say — keeping humans, and their ability to read social cues, in the loop. When researchers at Stanford and \nM.I.T. compared the performance of groups who were given the tool with those who weren’t, they found the tool \nsignificantly improved the performance of lower-skilled agents.\nEven if a job becomes completely automated, how displaced workers fare will depend on how companies decide to \nuse technology in new kinds of work, especially work we can’t yet imagine, said Daron Acemoglu, a professor at \nM.I.T. and an author of “Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity.” \nThese choices will include whether to automate work entirely or use technology to augment human expertise.\nHe said that the seemingly scary numbers predicting how many jobs A.I. could eliminate, even if it’s not clear how, \nwere a “wake up call.”\nHe believes that people could “steer in a better direction,” he said, but he is not optimistic. He does not think we are \non a “pro-human” path.\nThe A.I. Revolution Will Change Work. Nobody Agrees How.\nAll estimates for how much work A.I. could take over are very dependent on humans: the researchers making the \nassumptions about what technology can do. Mr. Frey and Mr. Osborne invited experts to a workshop to score the \nlikelihood of occupations becoming automated. More recent studies rely on information such as a database tracking \nA.I. capabilities, created by the Electronic Frontier Foundation, a nonprofit digital rights group. Or they rely on \nworkers using platforms like CrowdFlower, where people complete small tasks for money. The workers score tasks \non factors that make them prone to automation. For instance, if it’s something with a high tolerance for error, it’s a \nbetter candidate for a technology like ChatGPT to automate.\nThe exact numbers are not the point, say many researchers involved in this type of analysis.\n“I would describe our methodology as almost certainly precisely wrong, but hopefully directionally correct,” said \nMichael Chui, an A.I. expert at McKinsey who co-authored a 2017 white paper suggesting that about half of work, \nand 5 percent of occupations, could be automated.\nWhat the data describes is, in some ways, more mundane than often assumed: Big changes are coming, and it’s \nworth paying attention.\nThis article appeared in print on page BU5.\nLoad-Date: June 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Dec2022",
        "header": "How Is Everyone Making Those A.I. Selfies?; It Happened Online",
        "media": "The New York Times - International Edition",
        "time": "December 19, 2022",
        "section": "STYLE",
        "length": "1504 words",
        "byline": "Madison Malone Kircher and Callie Holtermann",
        "story_text": "How Is Everyone Making Those A.I. Selfies?; It Happened Online\nThe New York Times - International Edition\nDecember 20, 2022 Tuesday\nCopyright 2022 International Herald Tribune All Rights Reserved\nSection: STYLE\nLength: 1504 words\nByline: Madison Malone Kircher and Callie Holtermann\nBody\nImages generated with Lensa AI are all over social media, but at what cost?       \nHave you noticed that many of your friends are suddenly fairy princesses or space travelers? Is your Instagram \nfeed overrun with Renaissance-style paintings of people who were definitely born in the '90s? If so, you are entitled \nto an explanation of what exactly is going on here (and it's not time travel).       \nIn the past week, users have flocked to Lensa AI, an app that uses your selfies and artificial intelligence to create \nportraits in a variety of styles. Created by the company Prisma Labs, the app is generating images - and \ncontroversy.       \nWhat is Lensa AI?\nEven if you haven't heard of Lensa AI, you've possibly seen its work this week. As of Wednesday, it was the most \npopular iPhone app in the United States in Apple's app store. Lensa takes your selfies, studies them and churns out \noriginal, computer-generated portraits of you - or anyone whose photos you feed it.       \nDo I have to pay for it?\nYou do. Right now, you can get 50 avatars - 10 images in five styles - for $3.99 during a one-week trial period. (For \n$35.99 you can subscribe to Lensa AI for the year, which gets you a 51 percent discount on future avatars.) \"Magic \nAvatars consume tremendous computation power to create amazing avatars for you,\" according to Lensa's \ncheckout page. \"It's expensive, but we made it as affordable as possible.\" Fair warning: Prices have been \nfluctuating as the app has gotten more and more popular and may have changed since this article was published.       \nHow does it work?\nAfter downloading the app, you'll upload a bunch of selfies. (Do yourself a favor and don't include any where your \nhands are touching your face unless you want to pay money to get back a mess of images with phantom phalanges \nhanging from your mouth.) Select a gender - male, female or other - and walk away from your phone for around half \nan hour, and when you return, presto. Your face, or something like it, has been stretched and squeezed across a \nsuite of 50 to 200 - depending on what package you purchase - A.I.-generated images with themes including \n\"cosmic,\" \"fairy princess\" and \"anime.\"       \nOK, but how does it really work?\nLensa uses Stable Diffusion, which is when all the horses in a barn spread out to give each other a little space. Just \nkidding: Stable Diffusion is a \"really powerful\" A.I.-based image generator, said Subbarao Kambhampati, a \nprofessor in the School of Computing and Augmented Intelligence at Arizona State University. Similar to DALL-E 2 \nHow Is Everyone Making Those A.I. Selfies? It Happened Online\nand Midjourney, Stable Diffusion uses image prompts (like your selfies) and text prompts (like \"fantasy,\" one of \nLensa AI's categories) to generate high-quality images that sometimes get \"trippy,\" Dr. Kambhampati said. \"It's \nshowing you pictures that nobody took; it's just able to stitch them up from all the other images that it has seen.\"       \nCool.\nIt is cool! It's fun to see yourself rendered as a painting or an anime character or a little woodland elf with eyes of \ntwo very different sizes and only one hand, even if you have two IRL. (Not every image is going to be perfect.) \nSome users, particularly transgender and gender-nonconforming people, are even finding that using Lensa to \ncreate can offer a sense of gender euphoria.       \nI think some people are mad about this? Should I be mad about this, too?\nThere are a couple of reasons that some users are bristling at the images Lensa AI is spitting out. The first is that \nmany users are reporting that the art is sexualizing them. When we tested the app, several of the images we \nreceived after uploading selfies and selecting \"female\" included full-body renderings, despite the fact that users are \nspecifically instructed to upload only close-up selfies. One image featured our avatar in a metallic bikini à la \nPrincess Leia in \"Return of the Jedi.\" Another included only half a face atop a scantily clad body.       \nPrisma Labs states on its F.A.Q. page that \"occasional sexualization is observed across all gender categories.\"       \nThus, it's fairly simple to use the app to create lewd images of anyone you want. This week, Tech Crunch was able \nto create topless avatars of celebrities using images of an actor's head edited onto topless bodies. \"It turns out the \nAI takes those Photoshopped images as permission to go wild, and it appears it disables an NSFW filter,\" Tech \nCrunch reported. Now imagine that same experiment, but through the lens of someone who is angling to make \nrevenge porn. It gets murky in a hurry.       \nAndrey Usoltsev, Prisma Labs' chief executive and co-founder, told TechCrunch that using Lensa AI to engage in \n\"harmful or harassing behavior\" was a breach of its terms of use.       \nWhat are users saying about the app?\nYasemin Anders, 29, decided to use Lensa AI after seeing it on social media and was particularly excited to see \nherself recreated into an ethereal fairy.       \nShe was, however, ultimately disappointed to see that Lensa had given her a thinner body and a slimmer face and \nneck. \"If it's smart enough to turn you into either a fairy or a manga figure, you would think there was some sort of \nsmart enough software behind it to detect fat people, too,\" said Mx. Anders, who lives in Berlin and works in \nmarketing.       \n\"Even if I imagine myself as a fairy, as like an idealized fantasy version of myself, I would still want to look like \nmyself,\" she added. \"And I have always been fat. I've been a fat kid. I've been a fat teenager, and I'm a fat adult \nnow. So why would I want to imagine an ideal version of me that doesn't even look like me?\"       \nOther users are reporting that the app is making their skin appear lighter or whiter and is markedly altering their \nfacial features, which Dr. Kambhampati said was an ongoing issue with generative A.I. tools, including Snapchat's \nface lenses. \"If most of the images you fed the system were of white faces, then it's not surprising that when it tries \nto make an image that looks supposedly 'better,' it just makes it whiter,\" he said.       \nHow do artists feel about Lensa?\nStable Diffusion was trained on the creations of many artists who did not explicitly consent to the use of their work \nfor Prisma Labs's profit, Dr. Kambhampati said, adding, \"If van Gogh was alive today, you'd probably need to pay \nvan Gogh some licensing fee to make your pictures be in van Gogh's style.\" That is not what has happened here.       \nHow Is Everyone Making Those A.I. Selfies? It Happened Online\n\"To a lot of people, having our art stolen, they don't view it as anything personal - like, 'Oh, well, you know, it's just a \nstyle; you can't copyright a style,'\" said Jonathan Lam, a storyboard artist who works in video games and animation. \n\"But I would argue that for us, our style is actually our identity. It's is what sets us apart from each other. It's what \nmakes us marketable to clients.\" Mr. Lam, who lives in Vancouver, British Columbia, is one of many artists who \nhave since spoken out on social media about the app.       \nHe also noted that some of the works being generated by Lensa include what appear to be renderings of artists' \nsignatures. (Several of our own Lensa-generated images had scribbles where a signature might go on an IRL \npainting.) \"All these tech enthusiasts are saying that these generators are creating something new, but if the artist's \nsignature is still there, it's not something new,\" Mr. Lam said. \"It's just generating something based on the data it \nwas fed.\"       \n\"I think the general public is under the assumption that it is a program that has just learned to draw by itself in a \nvacuum, and they don't realize the greater implication of the exploitation of data,\" he added. \"When you're starting \nto see these things becoming monetized and real people being exploited and abused, it's quite scary. And it's even \nscarier when it's disguised as a pretty application.\"       \nHas Prisma Labs responded to these concerns?\nPrisma Labs wrote in a Twitter thread that A.I. \"will not replace digital artists\" and pushed back against the \ncharacterization that Lensa was ripping off artists' work. \"The AI learns to recognize the connections between the \nimages and their descriptions, not the artworks,\" the company wrote. \"As cinema didn't kill theater and accounting \nsoftware hasn't eradicated the profession, AI won't replace artists but can become a great assisting tool.\"       \nAre there any privacy concerns?\n\"I doubt that the whole business model is, 'Give us $10 or $15 and we'll send you back an A.I. glam shot,'\" said Jen \nKing, the privacy and data policy fellow at the Institute for Human-Centered Artificial Intelligence at Stanford \nUniversity. Lensa AI's privacy policy claims that \"face data\" is deleted within 24 hours after it has been processed \nand is not used to identify any individual user - but it also states that your photos and videos can be used to further \ntrain Lensa's algorithms. Would Dr. King use Lensa AI? \"No.\"       \nIt Happened Online is a column in which we explain very particular bits of news enabled and amplified by social \nmedia. \nLoad-Date: December 19, 2022"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2024",
        "header": "Spurred by Teen Girls, States Move to Ban Deepfake Nudes",
        "media": "The New York Times - International Edition",
        "time": "April 26, 2024",
        "section": "TECHNOLOGY",
        "length": "1430 words",
        "byline": "Natasha Singer",
        "story_text": "Spurred by Teen Girls, States Move to Ban Deepfake Nudes\nThe New York Times - International Edition\nApril 27, 2024 Saturday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1430 words\nByline: Natasha Singer\nBody\nLegislators in two dozen states are working on bills, or have passed laws, to combat A.I.-generated sexually explicit \nimages of minors.       \nCaroline Mullet, a ninth grader at Issaquah High School near Seattle, went to her first homecoming dance last fall, a \nJames Bond-themed bash with blackjack tables attended by hundreds of girls dressed up in party frocks.       \nA few weeks later, she and other female students learned that a male classmate was circulating fake nude images \nof girls who had attended the dance, sexually explicit pictures that he had fabricated using an artificial intelligence \napp designed to automatically \"strip\" clothed photos of real girls and women.       \nMs. Mullet, 15, alerted her father, Mark, a Democratic Washington State senator. Although she was not among the \ngirls in the pictures, she asked if something could be done to help her friends, who felt \"extremely uncomfortable\" \nthat male classmates had seen simulated nude images of them. Soon, Senator Mullet and a colleague in the State \nHouse proposed legislation to prohibit the sharing of A.I.-generated sexually explicit depictions of real minors.       \n\"I hate the idea that I should have to worry about this happening again to any of my female friends, my sisters or \neven myself,\" Ms. Mullet told state lawmakers during a hearing on the bill in January.       \nThe State Legislature passed the bill without opposition. Gov. Jay Inslee, a Democrat, signed it last month.       \nStates are on the front lines of a rapidly spreading new form of peer sexual exploitation and harassment in schools. \nBoys across the United States have used widely available \"nudification\" apps to surreptitiously concoct sexually \nexplicit images of their female classmates and then circulated the simulated nudes via group chats on apps like \nSnapchat and Instagram.       \nNow, spurred in part by troubling accounts from teenage girls like Ms. Mullet, federal and state lawmakers are \nrushing to enact protections in an effort to keep pace with exploitative A.I. apps.       \nSince early last year, at least two dozen states have introduced bills to combat A.I.-generated sexually explicit \nimages - known as deepfakes - of people under 18, according to data compiled by the National Center for Missing \n& Exploited Children, a nonprofit organization. And several states have enacted the measures.       \nAmong them, South Dakota this year passed a law that makes it illegal to possess, produce or distribute A.I.-\ngenerated sexual abuse material depicting real minors. Last year, Louisiana enacted a deepfake law that \ncriminalizes A.I.-generated sexually explicit depictions of minors.       \nSpurred by Teen Girls, States Move to Ban Deepfake Nudes\n\"I had a sense of urgency hearing about these cases and just how much harm was being done,\" said \nRepresentative Tina Orwall, a Democrat who drafted Washington State's explicit-deepfake law after hearing about \nincidents like the one at Issaquah High.       \nSome lawmakers and child protection experts say such rules are urgently needed because the easy availability of \nA.I. nudification apps is enabling the mass production and distribution of false, graphic images that can potentially \ncirculate online for a lifetime, threatening girls' mental health, reputations and physical safety.       \n\"One boy with his phone in the course of an afternoon can victimize 40 girls, minor girls,\" said Yiota Souras, chief \nlegal officer for the National Center for Missing & Exploited Children, \"and then their images are out there.\"       \nOver the last two months, deepfake nude incidents have spread in schools - including in Richmond, Ill., and Beverly \nHills and Laguna Beach, Calif.       \nYet few laws in the United States specifically protect people under 18 from exploitative A.I. apps.       \nThat is because many current statutes that prohibit child sexual abuse material or adult nonconsensual \npornography - involving real photos or videos of real people - may not cover A.I.-generated explicit images that use \nreal people's faces, said U.S. Representative Joseph D. Morelle, a Democrat from New York.       \nLast year, he introduced a bill that would make it a crime to disclose A.I.-generated intimate images of identifiable \nadults or minors. It would also give deepfake victims, or parents, the right to sue individual perpetrators for \ndamages.       \n\"We want to make this so painful for anyone to even contemplate doing, because this is harm that you just can't \nsimply undo,\" Mr. Morelle said. \"Even if it seems like a prank to a 15-year-old boy, this is deadly serious.\"       \nU.S. Representative Alexandria Ocasio-Cortez, another New York Democrat, recently introduced a similar bill to \nenable victims to bring civil cases against deepfake perpetrators.        \nBut neither bill would explicitly give victims the right to sue the developers of A.I. nudification apps, a step that trial \nlawyers say would help disrupt the mass production of sexually explicit deepfakes.       \n\"Legislation is needed to stop commercialization, which is the root of the problem,\" said Elizabeth Hanley, a lawyer \nin Washington who represents victims in sexual assault and harassment cases.       \nThe U.S. legal code prohibits the distribution of computer-generated child sexual abuse material depicting \nidentifiable minors engaged in sexually explicit conduct. Last month, the Federal Bureau of Investigation issued an \nalert warning that such illegal material included realistic child sexual abuse images generated by A.I.       \nYet fake A.I.-generated depictions of real teenage girls without clothes may not constitute \"child sexual abuse \nmaterial,\" experts say, unless prosecutors can prove the fake images meet legal standards for sexually explicit \nconduct or the lewd display of genitalia.       \nSome defense lawyers have tried to capitalize on the apparent legal ambiguity. A lawyer defending a male high \nschool student in a deepfake lawsuit in New Jersey recently argued that the court should not temporarily restrain his \nclient, who had created nude A.I. images of a female classmate, from viewing or sharing the pictures because they \nwere neither harmful nor illegal. Federal laws, the lawyer argued in a court filing, were not designed to apply \"to \ncomputer-generated synthetic images that do not even include real human body parts.\" (The defendant ultimately \nagreed not to oppose a restraining order on the images.)       \nNow states are working to pass laws to halt exploitative A.I. images. This month, California introduced a bill to \nupdate a state ban on child sexual abuse material to specifically cover A.I.-generated abusive material.       \nAnd Massachusetts lawmakers are wrapping up legislation that would criminalize the nonconsensual sharing of \nexplicit images, including deepfakes. It would also require a state entity to develop a diversion program for minors \nSpurred by Teen Girls, States Move to Ban Deepfake Nudes\nwho shared explicit images to teach them about issues like the \"responsible use of generative artificial \nintelligence.\"       \nPunishments can be severe. Under the new Louisiana law, any person who knowingly creates, distributes, \npromotes or sells sexually explicit deepfakes of minors can face a minimum prison sentence of five to 10 years.       \nIn December, Miami-Dade County police officers arrested two middle school boys for allegedly making and sharing \nfake nude A.I. images of two female classmates, ages 12 and 13, according to police documents obtained by The \nNew York Times through a public records request. The boys were charged with third-degree felonies under a 2022 \nstate law prohibiting altered sexual depictions without consent. (The state attorney's office for Miami-Dade County \nsaid it could not comment on an open case.)       \nThe new deepfake law in Washington State takes a different approach.       \nAfter learning of the incident at Issaquah High from his daughter, Senator Mullet reached out to Representative \nOrwall, an advocate for sexual assault survivors and a former social worker. Ms. Orwall, who had worked on one of \nthe state's first revenge-porn bills, then drafted a House bill to prohibit the distribution of A.I.-generated intimate, or \nsexually explicit, images of either minors or adults. (Mr. Mullet, who sponsored the companion Senate bill, is now \nrunning for governor.)       \nUnder the resulting law, first offenders could face misdemeanor charges while people with prior convictions for \ndisclosing sexually explicit images would face felony charges. The new deepfake statute takes effect in June.       \n\"It's not shocking that we are behind in the protections,\" Ms. Orwall said. \"That's why we wanted to move on it so \nquickly.\" \nLoad-Date: April 26, 2024"
    },
    {
        "file_name": "down_for_travel_Nov2023",
        "header": "The Daily Money: Google offers AI help for holiday shopping; gas prices",
        "media": "down for travel",
        "time": "November 16, 2023",
        "section": "OIL AND GAS NEWS, OIL AND GAS NEWS & GOOGLE NEWS",
        "length": "434 words",
        "byline": "Betty Lin-Fisher, USA TODAY",
        "story_text": "The Daily Money: Google offers AI help for holiday shopping; gas prices \ndown for travel\nUSA Today Online\nNovember 16, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: OIL AND GAS NEWS, OIL AND GAS NEWS & GOOGLE NEWS\nLength: 434 words\nByline: Betty Lin-Fisher, USA TODAY\nBody\nGood morning. This is Betty Lin-Fisher bringing you the top headlines of the day.\nIf you need some help with your holiday shopping, Google wants to help with AI.\nGoogle is expanding its artificial intelligence capabilities to help consumers shop during the holiday season. Starting \ntoday, Google is updating its Search Generative Experience (SGE), which brings generative AI capabilities into a \nsearch. It is available by opt-in on the Google app, home page or Chrome desktop.\nGoogle is also expanding its virtual try-on tool to include men's tops, and a feature to generate photorealistic \nimages of what you're shopping for will also be available in December.\nLink to Image\nGas prices are falling just in time for the Thanksiving drive\nIf you're going to hit the road for Thanksgiving next week, there's good news: gas prices are falling nationwide.\nThe national average for a gallon of unleaded gasoline dipped on Tuesday to $3.353, the lowest since February, \naccording to AAA, a federation of motor clubs throughout North America. Even in California, where prices are \namong the steepest in the country, the price for a gallon of unleaded has come down from $5.638 a month ago and \n$5.138 last week to $5.059, according to AAA.\nAAA is forecasting that 55.4 million Americans will travel at least 50 miles between Wednesday, Nov. 22 and \nSunday, Nov. 26 and that 49.1 million will be driving.\n More stories you shouldn't miss \nHigh-altitude escape: Horse escapes on flight headed to Belgium, forces cargo plane to return to New York's JFK\nTravel hack: Venmo Groups makes paying your friends back for group trips easy\nBanned: Nepal bans TikTok for 'disrupting social harmony,' demands regulation of social media app\nTech news: New flying sports car successful in first flight, heading to market soon\n  Today's Menu \nForget delivery from a person in a car: Chick-fil-A is testing drone delivery at a small number of locations.\nThe Daily Money: Google offers AI help for holiday shopping; gas prices down for travel\nA franchise owner announced on Facebook that drone delivery is being offered for free for a limited time from its \nBrandon/Valrico Chick-fil-A location in the Tampa Bay area. In a statement to USA TODAY, Chick-fil-A said it is in \nthe early stages of testing drone delivery at a small number of locations, but did not identify them.\nAbout The Daily Money\nEach weekday, The Daily Money delivers the best consumer news from USA TODAY. We break down financial \nnews and provide the TLDR version: how decisions by the Federal Reserve, government and companies impact \nyou.\nThis article originally appeared on USA TODAY: The Daily Money: Google offers AI help for holiday shopping; gas \nprices down for travel\nLoad-Date: November 16, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "Apple Says It Will Remove a Health Feature From New Apple Watches",
        "media": "The New York Times",
        "time": "January 19, 2024",
        "section": "TECHNOLOGY",
        "length": "508 words",
        "byline": "Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San",
        "story_text": "Apple Says It Will Remove a Health Feature From New Apple Watches\nThe New York Times \nJanuary 17, 2024 Wednesday 13:38 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 508 words\nByline: Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San \nFrancisco. His focus on Apple includes product launches, manufacturing issues and political challenges. He also \nwrites about trends across the tech industry, including layoffs, generative A.I. and robot taxis.&lt;/p&gt; \n&lt;p&gt;&amp;#160;&lt;/p&gt;\nHighlight: Starting on Thursday, the Apple Watch Series 9 and Watch Ultra 2 will no longer detect people’s blood \noxygen levels, to comply with a ruling by the International Trade Commission.\nBody\nStarting on Thursday, the Apple Watch Series 9 and Watch Ultra 2 will no longer detect people’s blood oxygen \nlevels, to comply with a ruling by the International Trade Commission.\nApple said on Wednesday that it would begin selling its flagship smartwatches without the ability to detect people’s \nblood-oxygen levels.\nThe tech giant will drop the feature starting Thursday after losing a patent case over its blood-oxygen measurement \ntechnology two months ago. The court ordered Apple to stop selling its Apple Watch Series 9 and Watch Ultra 2 \ndevices. Rather than discontinue sales, the company sought permission to continue selling the devices after \nremoving the infringing technology.\nPeople who buy a new watch in the United States will still see Apple’s Blood Oxygen app on the devices, the \ncompany said. But if they tap the app, it will say the feature is no longer available.\nThe change won’t affect smartwatches currently in use. People with Apple watches capable of detecting their blood-\noxygen levels can continue to use that feature, Apple said. The Watch Series 9 and Watch Ultra 2 will also continue \nto offer an array of other features, including the ability to track runs, set timers, and detect falls and irregular \nheartbeats.\nThe International Trade Commission found in October that several Apple Watches had infringed on patents held by \nMasimo, a medical technology company in Irvine, Calif., that helped pioneer some pulse oximeter technology. It \nissued a ban on the import of Apple’s watches, which are made in Asia.\n“We strongly disagree with the decision,” an Apple spokeswoman said in a statement.\nApple appealed the ruling but on Wednesday lost its effort in court to delay a ban on sales of its watches until the \nappeals court rules on the dispute. As a contingency, it had received approval from U.S. Customs to continue \nselling the watch after making technical changes to remove the infringing technology.\nThe compromise would be a temporary blow to Apple’s efforts to increase the utility of its watches by adding health \nfeatures. In 2018, the company won approval from the Food and Drug Administration for its watches to begin to \nmeasure heart rates through electrocardiogram tests. It subsequently added abilities to detect falls, crashes and \nblood oxygen levels .\nApple Says It Will Remove a Health Feature From New Apple Watches\nThe new features pushed Apple deeper into the world of medical devices that is dominated by companies like \nMedtronic and Abbott. Masimo had secured several patents over pulse oximeter technology, which measures the \npercentage of oxygen that red blood cells carry from the lungs to the body.\nIn court, Masimo said Apple had discussed acquiring the medical device company but instead chose to poach top \nMasimo executives and employees. In 2020, Apple introduced its first watch with pulse oximetry.\nThe next year, Masimo took its complaints that Apple stole its technology to the International Trade Commission. \nThe appeals court is expected to make a ruling this year.\nPHOTO (PHOTOGRAPH BY CHRIS DELMAS/A.F.P. — GETTY IMAGES) This article appeared in print on page \nB2.\nLoad-Date: January 19, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "The 2022 Good Tech Awards; The Shift",
        "media": "The New York Times",
        "time": "February 23, 2023",
        "section": "TECHNOLOGY",
        "length": "1453 words",
        "byline": "Kevin Roose",
        "story_text": "The 2022 Good Tech Awards; The Shift\nThe New York Times \nDecember 29, 2022 Thursday 17:21 EST\nCopyright 2022 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1453 words\nByline: Kevin Roose\nHighlight: Nuclear fusion, generative A.I., bee tracking and more. There’s a lot to like.\nBody\nThe year 2022, in the tech world, was one of big leaps and even bigger pratfalls.\nThe falls included some of the industry’s most recognizable names. Sam Bankman-Fried began the year as the \nbiggest celebrity in crypto, with a net worth of more than $20 billion, and ends it as a disgraced pariah who is facing \ncriminal fraud charges. Elon Musk began 2022 as the world’s richest man, with a thriving electric car company and \na name synonymous with success; he ends it more than $100 billion poorer, as the bitter and beleaguered owner of \na social media company that seems to be ruining his life.\nThe tech industry struggled, too, with harsh macroeconomic conditions, including high inflation and rising interest \nrates. As the sector’s decade of hypergrowth came to an end, start-ups died, tech giants cut perks and laid off \nworkers, and investors’ dreams of a new, crypto-fied internet known as “web3” faded into oblivion.\nBut focusing exclusively on what went wrong risks missing the many noble, clever and socially valuable tech \nprojects that made progress this year.\nFor several years now, I’ve highlighted these kinds of projects in my annual Good Tech Awards column. These \naren’t necessarily technologies that I’m sure will improve the world, while causing no problems whatsoever. They’re \ntools that I believe could improve the world, or help address thorny societal challenges. Some of them could also go \nquite badly, if they’re mismanaged or co-opted in harmful ways.\nThere were many to choose from this year. Here’s what made the final cut.\nTo OpenAI and the makers of Midjourney and Stable Diffusion, for proving that A.I. can create\nThe splashiest tech breakthrough of the year, by a significant margin, was the boom in “generative A.I.” — a term \nfor the new type of artificial intelligence apps, trained on vast amounts of data, that can create new media objects \nout of thin air.\nThis year, A.I. image generators like DALL-E 2, Stable Diffusion and Midjourney dazzled users (including me) with \ntheir creations and set off a Cambrian explosion of new, ultracapable A.I. tools. In recent weeks, ChatGPT, a text-\ngenerating A.I. built by OpenAI, became a viral sensation (and every teacher’s worst nightmare) when it started \ncranking out term papers, original poetry and working snippets of code.\nSome credit for the generative A.I. boom should go to Google, which created much of the foundational technology. \nBut this year, Google (which has kept most of its A.I. experiments private, to its recent chagrin) got one-upped by \nOpenAI, as well as the makers of Midjourney and Stable Diffusion, all of which released public-facing products that \nallowed millions of people to experience generative A.I. for themselves.\nThe 2022 Good Tech Awards The Shift\nThe ultimate effects of generative A.I. are still unknown. Some people argue that these apps will destroy millions of \njobs, while others argue that they’ll be a boon to human creativity. But whether you’re an A.I. optimist or pessimist, \nthis year’s advances mean that we are no longer debating theoretical costs and benefits — the tools have arrived, \nand we now get to decide how to use them.\nTo Ethereum developers, for pulling off the merge\nI know, I know. Putting a crypto project in a “good tech” list in 2022 feels like putting credit default swaps in a “cool \nfinancial innovations” list in 2008.\nBut while the crypto industry took a nosedive this year — wiping out trillions of dollars in value and leaving many \ninvestors empty-handed — there was at least one bright spot. In September, Ethereum, the network behind the \nsecond most valuable cryptocurrency after Bitcoin, completed what was known as “the merge” — a hulking, years-\nin-the-making project to switch Ethereum from an energy-guzzling form of blockchain known as “proof of work” to a \nmuch greener form of blockchain known as “proof of stake.”\nThe switch, which crypto developers compared to trying to swap a plane’s engine in midair, was a smashing \nsuccess, and cut the energy required to power Ethereum by more than 99 percent. (It didn’t, however, boost the \nprice of the cryptocurrency, Ether, which ended the year down nearly 70 percent.)\nTo Living Carbon, Twelve and BeeHero, for turning tech on the climate crisis\nWhile 2022 was a horrible year for start-up fund-raising in general, it was a great year for climate tech start-ups, \nwhich raised billions of dollars to bring climate-friendly technologies to market.\nThere are too many promising climate tech start-ups to name — and, to be honest, I don’t know enough about \nclimate science to tell which ones stand the best chance of succeeding — but a few that caught my eye this year \nwere Living Carbon, Twelve and BeeHero.\nLiving Carbon, a three-year-old California start-up, is genetically engineering trees and other plants to capture and \nstore more carbon from the atmosphere. These G.M.O. supertrees, the company claims, grow bigger and faster \nthan normal trees and can survive in soil with metal concentrations that would be toxic to other plants.\nTwelve, which is based in Berkeley, Calif., is using a novel electrochemical process to turn carbon dioxide into \nindustrial products as varied as sunglasses and jet fuel. The company raised a $130 million funding round this year \nand struck deals with companies like Mercedes-Benz and Procter &amp; Gamble.\nBeeHero, which was started in Israel in 2017, is using new technology to address problems facing one of the most \nimportant parts of our global food supply: bees. Bees pollinate more than one-third of all crops, but they are dying \noff at alarming rates, setting off fears of a food shortage. To tackle this, BeeHero developed a “precision pollination \nplatform” — basically, a bee-tracking sensor system that allows for industrial beekeepers to monitor the health and \nproductivity of their hives in real time. The company raised a $42 million Series B (Series Bee?) round this year \nfrom investors including General Mills.\nTo the National Ignition Facility, Commonwealth Fusion Systems and Helion, for keeping the fusion dream alive\nNuclear fusion, an emissions-free form of energy generation that has long been viewed as the “holy grail of energy,” \ntook a few important steps toward reality this year.\nThe biggest fusion news of the year came just a few weeks ago when scientists at the National Ignition Facility at \nLawrence Livermore National Laboratory in California crossed a major threshold known as “ignition,” creating a \nfusion reaction that generated more energy than it took to produce. That breakthrough was hailed by officials \nincluding Jennifer M. Granholm, the secretary of energy, who called it a “landmark achievement.”\nMany start-ups have also been plugging away on fusion. One, Helion Energy, has raised hundreds of millions of \ndollars from well-known investors including Sam Altman, Dustin Moskovitz and Peter Thiel to create affordable, \nThe 2022 Good Tech Awards The Shift\nmass-market fusion technology. Helion says it plans to create energy with its next fusion reactor, Polaris, by 2024. \nAnother company, Commonwealth Fusion Systems, which was spun out of the Massachusetts Institute of \nTechnology in 2018, is using an array of powerful magnets to power its prototype fusion machine outside Boston, \nand plans to have it up and running by 2025.\nExperts have cautioned that despite the latest breakthroughs, affordable fusion power may not be widely available \nfor years. But this year, both the public and private sectors offered a glimpse of a fusion-powered future.\nTo Locket, for making photo-sharing fun again\nIf 2022 was the year when social media died, it was also the year when start-ups began trying to recapture what \nhad made social media fun in the first place.\nOne app I’ve loved using this year is Locket. It’s a very simple premise — a widget that is installed on your \nsmartphone’s home screen, creating a kind of digital photo frame that your closest friends and loved ones can \nupload photos to.\nLocket was created by Matt Moss, a young developer who wanted a way to send photos to his long-distance \ngirlfriend; this year, the app quickly grew to millions of users, raised a major funding round and won an Apple \ncultural impact award. There are no filters, preening influencers, data-harvesting schemes or algorithmic feeds on \nLocket — it’s just an easy, no-frills way to share photos with your loved ones.\nMy wife and I started using Locket this year to share photos of our kid, in a way that wouldn’t require us digging \nthrough text chains or huge photo albums to find them later on. It’s not the tech product I’ve used most often, or the \none I think will create the most net good for society. But it’s fun, uncomplicated and respectful of its users — three \nqualities to which more tech products should aspire.\nThis article appeared in print on page B1, B7.\nLoad-Date: February 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "A New Area of A.I. Booms, Even Amid the Tech Gloom",
        "media": "The New York Times",
        "time": "February 23, 2023",
        "section": "TECHNOLOGY",
        "length": "1512 words",
        "byline": "Erin Griffith and Cade Metz",
        "story_text": "A New Area of A.I. Booms, Even Amid the Tech Gloom\nThe New York Times \nJanuary 7, 2023 Saturday 17:22 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1512 words\nByline: Erin Griffith and Cade Metz\nHighlight: An investment frenzy over “generative artificial intelligence” has gripped Silicon Valley, as tools that \ngenerate text, images and sounds in response to short prompts seize the imagination.\nBody\nAn investment frenzy over “generative artificial intelligence” has gripped Silicon Valley, as tools that generate \ntext, images and sounds in response to short prompts seize the imagination.\nFive weeks ago, OpenAI, a San Francisco artificial intelligence lab, released ChatGPT, a chatbot that answers \nquestions in clear, concise prose. The A.I.-powered tool immediately caused a sensation, with more than a million \npeople using it to create everything from poetry to high school term papers to rewrites of Queen songs.\nNow OpenAI is in the midst of a new gold rush.\nThe lab is in talks to complete a deal that would value it at around $29 billion, more than twice its valuation in 2021, \ntwo people with knowledge of the discussions said. The potential deal — where OpenAI would sell existing \ncompany shares in a so-called tender offer — could total $300 million, depending on how many employees agree to \nsell their stock, they said. The company is also in discussions with Microsoft — which invested $1 billion in it in \n2019 — for additional funds, two people said.\nThe clamor around OpenAI shows that even in the most dismal tech downturn in a generation, Silicon Valley’s deal-\nmaking machine is still kicking. After a humbling year that included mass layoffs and cuts, tech investors — a \nnaturally optimistic bunch — can’t wait to jump on a hot trend.\nNo area has created more excitement than generative artificial intelligence, the term for technology that can \ngenerate text, images, sounds and other media in response to short prompts. Investors, pundits and journalists \nhave talked up artificial intelligence for years, but the new wave — the result of more than a decade of research — \nrepresents a more powerful and more mature breed of A.I.\nThis type of A.I. promises to reinvent everything from online search engines like Google to photo and graphics \neditors like Photoshop to digital assistants like Alexa and Siri. Ultimately, it could provide a new way of interacting \nwith almost any software, letting people chat with computers and other devices as if they were chatting with another \nperson.\nThat has sent deal-making around generative A.I. companies into overdrive. Jasper, a generative A.I. start-up \nfounded in 2021, raised $125 million in October, valuing it at $1.5 billion. Stability AI, an image generating company \nfounded in 2020, raised $101 million that same month, valuing it at $1 billion. Smaller generative A.I. companies, \nincluding Character.AI, Replika and You.com, have also been inundated with investor interest.\nA New Area of A.I. Booms, Even Amid the Tech Gloom\nIn 2022, investors pumped at least $1.37 billion into generative A.I. companies across 78 deals, almost as much as \nthey invested in the previous five years combined, according to data from PitchBook, which tracks financial activity \nacross the industry.\nOpenAI’s $29 billion valuation was earlier reported by The Wall Street Journal. The venture-capital firms Thrive \nCapital and Founders Fund may buy shares in the tender offer, two people said. Because OpenAI began as a not-\nfor-profit company, pinpointing its precise valuation is difficult.\nOpenAI, Thrive Capital and Founders Fund did not provide comments on the proposed investment.\nCompanies have developed generative A.I. for years, including tech giants like Google and Meta as well as \nambitious start-ups like OpenAI. But the technology did not capture the public’s attention until last spring, when \nOpenAI unveiled a system called DALL-E that let people generate photo-realistic images simply by describing what \nthey wanted to see.\nThat inspired entrepreneurs to dive in with new ideas and investors to make sweeping proclamations of disruption. \nTheir enthusiasm reached new heights in December after OpenAI released ChatGPT, with fans seizing on the \ntechnology to generate love letters and business plans.\n“It’s the new ‘mobile’ kind of paradigm shift that we’ve been all waiting for,” Niko Bonatsos, an investor at the \nventure capital firm General Catalyst, said. “Maybe bigger, too.”\nInvestors at Sequoia Capital wrote that generative A.I. had “the potential to generate trillions of dollars of economic \nvalue.” And Lonne Jaffe, an investor at Insight Partners, said, “There is definitely an element to this that feels like \nthe early launch of the internet.”\nGoogle, Meta and other tech giants have been reluctant to release generative technologies to the wider public \nbecause these systems often produce toxic content, including misinformation, hate speech and images that are \nbiased against women and people of color. But newer, smaller companies like OpenAI — less concerned with \nprotecting an established corporate brand — have been more willing to get the technology out publicly.\nThe techniques needed to build generative A.I. are widely known and freely available through academic research \npapers and open source software. Google and OpenAI have an advantage because they have access to deep \npockets and raw computing power, which are building blocks for the technology.\nStill, many top researchers from Google, OpenAI and other leading A.I. labs have struck out on their own in recent \nmonths to found new start-ups in the field. These start-ups have received some of the largest funding rounds, with \nthe excitement surrounding ChatGPT and DALL-E prompting venture capital firms to invest in even more young \ncompanies.\nMore than 450 start-ups are now working on generative A.I., by one venture capital firm’s count. And the frenzy \nhas been compounded by investor eagerness to find the next big thing in a gloomy environment.\nMichael Dempsey, an investor at the venture firm Compound, said the tech downturn — which last year included a \ncrypto crash, poor performing stocks and layoffs at many companies — created a lull among investors.\nThen “everyone got excited about A.I.,” he said. “People need something to tell their investors or themselves, \nhonestly, that there is a next thing to be excited about.”\nSome worry the hype around generative A.I. has gotten ahead of reality. The technology has raised thorny ethical \nquestions around how generative A.I. may affect copyrights and whether the companies need to get permission to \nuse the data that trains their algorithms. Others believe big tech companies such as Google will quickly trounce the \nyoung upstarts, and that some of the new companies have little competitive advantage.\n“There are a lot of teams that don’t have any A.I. competency that are pitching themselves as A.I. companies,” Mr. \nDempsey said. \nA New Area of A.I. Booms, Even Amid the Tech Gloom\nThose concerns have not slowed the swell of excitement, especially after the arrival of Stability AI in October.\nThe start-up had helped fund an open source software project that quickly built image-generating technology that \noperated much like DALL-E. The difference was that while OpenAI had only shared DALL-E with a small number of \ntesters, Stability AI’s open source version — Stable Diffusion — could be used by anyone. People quickly used the \ntool to create photo-realistic images of everything from a medieval knight crying in the rain to Disneyland painted by \nVan Gogh.\nIn the ensuing excitement, Eugenia Kuyda, founder and chief executive of chat bot start-up Replika, said in an \ninterview that she was contacted by “every V.C. firm in Silicon Valley,” or more than 30 firms. She took their calls \nbut decided against additional funding because her company, founded in 2014, is profitable.\n“I feel like the person who was a week early arriving at the airport for a flight — and now the flight is boarding,” she \nsaid.\nCharacter.AI, another chat bot company, and You.com, which is adding chat technology to its internet search \nengine, have also been deluged with interest from venture capitalists, the companies said.\nSharif Shameem, an entrepreneur who built a searchable database for images created by Stable Diffusion in \nAugust called Lexica, said his tool rapidly hit one million users — a sign he should shift from his existing start-up to \nfocusing on Lexica. Within a few weeks, he raised $5 million in funding for the project.\nMr. Shameem compared the moment around generative A.I. to the advent of the iPhone and mobile apps. “It feels \nlike one of those rare opportunities,” he said.\nMr. Jaffe of Insight Partners said his firm has since encouraged most of its portfolio companies to consider \nincorporating generative A.I. technology into their offerings. “It’s hard to think of a company that couldn’t use it in \nsome way,” he said.\nRadical Ventures, a venture firm in Toronto, one of the global centers of A.I. research, was created five years ago \nspecifically to invest in this kind of technology. It recently launched a new $550 million fund dedicated to A.I., with \nmore than half of its investments in generative A.I. companies. Now those bets look even better.\n“For four and a half years, people thought we were nuts,” said Jordan Jacobs, a partner at Radical. “Now, for the \npast six months, they’ve thought we were geniuses.”\nPHOTO: Sam Altman, founder and chairman of OpenAI, an artificial intelligence lab. (PHOTOGRAPH BY MIKE \nCOHEN FOR THE NEW YORK TIMES) (B4) This article appeared in print on page B1, B4.\nLoad-Date: February 23, 2023"
    },
    {
        "file_name": "Google_and_YouTube;_Political_ads_using_artificial_intelligence_on_Google_Sep2023",
        "header": "AI that alters voice and imagery in political ads will require disclosure on",
        "media": "Google and YouTube; Political ads using artificial intelligence on Google",
        "time": "September 7, 2023",
        "section": "NATION WORLD",
        "length": "429 words",
        "byline": "MICHELLE CHAPMAN",
        "story_text": "AI that alters voice and imagery in political ads will require disclosure on \nGoogle and YouTube; Political ads using artificial intelligence on Google \nand YouTube must soon be accompanied by a prominent disclosure if \nimagery or sounds have been synthetically altered\nDayton Daily News (Ohio)\nSeptember 7, 2023 Thursday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 429 words\nByline: MICHELLE CHAPMAN\nBody\nGoogle will soon require that political ads using artificial intelligence be accompanied by a prominent disclosure if \nimagery or sounds have been synthetically altered.\nAI-generated election ads on YouTube and other Google platforms that alter people or events must include a clear \ndisclaimer located somewhere that users are likely to notice, the company said in an update to its political content \npolicy. \nThe new rule starts in mid-November, just under a year before the U.S. presidential election. It will also affect \ncampaign ads ahead of next year's elections in India, South Africa, the European Union and other regions where \nGoogle already has a verification process for election advertisers. \nThough fake images, videos or audio clips are not new to political advertising, generative AI tools are making it \neasier to do, and more realistic. Some presidential campaigns in the 2024 race  including that of Florida GOP Gov. \nRon DeSantis  already are using the technology. \nThe Republican National Committee in April released an entirely AI-generated ad meant to show the future of the \nUnited States if President Joe Biden is reelected. It employed fake but realistic photos showing boarded-up \nstorefronts, armored military patrols in the streets, and waves of immigrants creating panic. \nIn June, DeSantis' campaign shared an attack ad against his GOP primary opponent Donald Trump that used AI-\ngenerated images of the former president hugging infectious disease expert Dr. Anthony Fauci. \nLast month the Federal Election Commission began a process to potentially regulate AI-generated deepfakes in \npolitical ads ahead of the 2024 election. Such deepfakes can include synthetic voice of political figures saying \nsomething they never said. \nDemocratic U.S. Sen. Amy Klobuchar, co-sponsor of pending legislation that would require disclaimers on \ndeceptive AI-generated political ads, said in a statement that Google's announcement was a step in the right \ndirection but \"we can't solely rely on voluntary commitments.\" \nSeveral states also have discussed or passed legislation related to deepfake technology. \nAI that alters voice and imagery in political ads will require disclosure on Google and YouTube Political ads \nusing artificial intelligence on Google and YouTub....\nGoogle is not banning AI outright in political advertising. Exceptions to the ban include synthetic content altered or \ngenerated in a way that's inconsequential to the claims made in the ad. AI can also be used in editing techniques \nlike image resizing, cropping, color, defect correction, or background edits. \nThe ban will apply to election ads on Google's own platforms, particularly YouTube, as well as third-party websites \nthat are part of Google's ad display network.\nGraphic\n \nFILE - The Google app icon is seen on a smartphone, Tuesday, Feb. 28, 2023, in Marple Township, Pa. Google, on \nThursday, Sept. 7, will soon require political advertising that incorporates artificial intelligence come with a \nprominent disclosure that the technology is being used to depict real or realistic-looking people or events. The use \nof AI has already begun to seep into that space and last month Federal Election Committee said that it may soon \nregulate AI-generated deepfakes in political ads ahead of the 2024 election.(AP Photo/Matt Slocum, File)\nLoad-Date: September 7, 2023"
    },
    {
        "file_name": "The_Baltimore_Sun_Jan2024",
        "header": "Robocall impersonates Biden in apparent attempt to suppress votes",
        "media": "The Baltimore Sun",
        "time": "January 23, 2024",
        "section": "MAIN; A; Pg. 5",
        "length": "410 words",
        "byline": "Ali Swenson and Will Weissert Associated Press",
        "story_text": "Robocall impersonates Biden in apparent attempt to suppress votes\nThe Baltimore Sun\nJanuary 23, 2024 Tuesday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 5\nLength: 410 words\nByline: Ali Swenson and Will Weissert Associated Press\nBody\nThe New Hampshire attorney general's office on Monday said it was investigating reports of an apparent robocall \nthat used artificial intelligence to mimic President Joe Biden's voice and discourage voters in the state from coming \nto the polls during Tuesday's primary election.\nAttorney General John Formella said the recorded message, sent to multiple voters Sunday, appears to be an \nillegal attempt to disrupt and suppress voting. \nHe said voters \"should disregard the contents of this message entirely.\"\nA recording of the call reviewed by The Associated Press generates a voice similar to Biden's and employs his \noften-used phrase, \"What a bunch of malarkey.\" It then tells the listener to \"save your vote for the November \nelection.\"\n\"Voting this Tuesday only enables the Republicans in their quest to elect Donald Trump again,\" the voice mimicking \nBiden says. \"Your vote makes a difference in November, not this Tuesday.\"\nIt is not true that voting in Tuesday's primary precludes voters from casting a ballot in November's general election. \nBiden is not campaigning in New Hampshire and his name will not appear on Tuesday's primary ballot because he \nelevated South Carolina to the lead-off position for the Democratic primaries, but his allies are running a write-in \ncampaign for him in the state.\nIt's not known who is behind the calls, although they falsely showed up to recipients as coming from the personal \ncellphone number of Kathy Sullivan, a former state Democratic Party chair who helps run Granite for America, a \nsuper-PAC supporting the Biden write-in campaign.\nSullivan said she alerted law enforcement and issued a complaint to the attorney general after multiple voters in the \nstate reported receiving the call Sunday night.\n\"This call links back to my personal cellphone number without my permission,\" she said in a statement. \"It is outright \nelection interference, and clearly an attempt to harass me and other New Hampshire voters who are planning to \nwrite-in Joe Biden on Tuesday.\"\nIt was unclear how many received the call but a spokesperson for Sullivan said she heard from at least a dozen \nwho received it. The attorney general's office encouraged anyone who has received the call to email the state \nJustice Department's election law unit.\nRobocall impersonates Biden in apparent attempt to suppress votes\nThe apparent attempt at voter suppression using rapidly advancing generative AI technology is one example of \nwhat experts warn will make 2024 a year of unprecedented election disinformation around the world.\nLoad-Date: January 23, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Dec2023",
        "header": "How AI helped plan trip, cure indecision",
        "media": "The Baltimore Sun",
        "time": "December 11, 2023",
        "section": "LIFESTYLE; R; Pg. 4",
        "length": "986 words",
        "byline": "Laura Yuen Minneapolis Star Tribune",
        "story_text": "How AI helped plan trip, cure indecision\nThe Baltimore Sun\nDecember 10, 2023 Sunday\nAdvance3 Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: LIFESTYLE; R; Pg. 4\nLength: 986 words\nByline: Laura Yuen Minneapolis Star Tribune\nHighlight: The views from the ferry ride from Seattle to Bainbridge Island in Washington were worth the cost of the \nboat ride alone. Laura Yuen/Minneapolis Star Tribune\nBody\nPlanning paralysis still had me in its clutches days before my family and I left for an October break trip to Seattle. By \nthat time, we had already booked our flights, an Airbnb and a rental car. But the guts of the vacation - what to do, \nsee and eat - were still undecided. My itinerary was a hauntingly blank abyss on a computer screen.\nThen I remembered a trick my friend shared with me a few months back: artificial intelligence.\n\"Plan a family vacation for Seattle starting late Monday afternoon and flying out of Sea-Tac on Thursday morning,\" I \ntyped into the AI software ChatGPT.\nWithin seconds, the bot cheerily wrote back, assuring me that the mere act of preparing for this trip would be \"a fun \nand exciting adventure.\" It ticked off more than a dozen attractions and restaurants, all fashioned into a tidy outline \nbroken down by day, presented on a platter with subheads and bullet points.\nScanning the itinerary, I concurred there was no better way to start the morning than to explore Pike Place Market, \nhome of the famous fish toss. Of course we would ascend the Space Needle to explore breathtaking views of the \ncity. And you bet my seafood-loving son and I would be down for some clam chowder at a waterfront restaurant.\nWas this cheating? Perhaps. But for a dawdler, this bot-devised plan helped me visualize my trip and even \nenergized me. And it came at just the right time.\n\"For a lot of people, that initial inertia is at its highest,\" said Ravi Bapna, a professor at the University of Minnesota's \nCarlson School of Management. \"Just getting started is the hardest thing, right?\"\nBapna is a data scientist who's writing a book about how AI can guide people in their day-to-day lives, from online \ndating to health and fitness. He uses it to plow through writer's block, even if it's just to summarize his own work for \nupcoming presentations. He likens AI's abilities to a first draft that he must refine and reshape into his own words.\nThe platform is far from flawless. Generative AI is a language model trained on essentially everything that's been \nwritten, from books to web pages, Bapna explained. \"It's trying to predict the next word, based on everything it's \nseen,\" he said. \"I think of this technology as a good co-pilot. It's not perfect, and you still have to know what you're \ndoing.\"\nThat means double- checking the information and providing further prompts to get the results you're seeking, he \nadded.\nHow AI helped plan trip, cure indecision\nEven travel experts who are wary of AI's limitations can appreciate its ability to cure traveler's indecision.\n\"It can be incredibly valuable and helpful, especially for people who don't know where to start,\" said Kyle Potter, \nexecutive editor of the Minnesota- based site Thrifty Traveler. \"Getting a list of 10 to 20 recommendations for hikes, \nplaces to eat and sights to see can be valuable to anyone, whether it's someone who hates planning trips all the \nway to someone who enjoys doing it but needs a little help.\"\nPotter said he doubts AI would know enough about our preferences to steer us away from, say, restaurants that \nserve great food but are overpoweringly loud. A good travel agent who's worked with you for years will likely \nassemble a better trip than the software can, he said.\n\"Travel is incredibly personal,\" he said. \"It doesn't matter how good ChatGPT gets. At least I hope they'll never \nknow those things - about what makes us individuals. That's what separates a good trip from a mediocre or a bad \none.\"\nSo how did my trip go, thanks to my new upbeat travel assistant?\nI should disclose that this wasn't my first excursion to Seattle. It was my fourth. But it was my first time with kids in \ntow, and we headed straight to my college friend Erin's house to have dinner with her family. We told them what \nwas on our list - all the touristy things, plus my husband's one wish to see the Japanese garden in town.\nWhen Erin heard he was interested in landscape design, she suggested that we take a ferry to Bainbridge Island to \nexplore the Bloedel Reserve, a giant swath of woods, gardens and coastline where visitors can unwind in nature. \nShe said that while on the island we could also track down a massive whimsical troll, one of several sculptures built \nby a Copenhagen- based artist out of recycled wood.\nErin and her husband also gave tips on where to see the sunset - Seattle's Discovery Park. Since our time was \nlimited, they suggested we skip the museums but agreed that a trip to the Space Needle would be iconic.\nThe next morning, my family and I followed ChatGPT's advice and started our morning at Pike Place. We arrived a \nlittle after 9 a.m., only to find that most of the stalls and shops had not yet opened. Whoops! I could only blame the \nbot's co-pilot - me - for not researching that ahead of time.\nWe didn't hew completely to the schedule, but we did hit the high points of our urban itinerary: fish toss, waterfront, \nseafood lunch, aquarium, Space Needle. We squeezed in other decisions on the fly, like pickup soccer on Pier 62 \nand a sushi dinner downtown, and were utterly spent by bedtime.\nThe next morning, we scrapped the bot's plans in favor of Erin's and caught the ferry to Bainbridge. The boat ride \nacross Puget Sound alone was worth the trip. And the Bloedel Reserve was even better than we imagined.\nAs soon as we entered the park, our kids scurried 50 paces ahead of us along a meandering bark path. They \ntraversed a meadow and tore into woods guarded by towering pines. There was space to run, air to breathe, away \nfrom the clamor and chaos of the city. Until Erin mentioned it, I had never heard of this place, which fit our family \nlike a hand in glove.\nMy husband must have been thinking the same thing as me.\n\"It's not what you know, but who you know,\" he said, reaching for my hand.\nAI can get us started on our trip, but a real-life friend can point us to places that speak to our hearts. \nAnd the moments we remember? Those we must make for ourselves.\nLoad-Date: December 11, 2023\nHow AI helped plan trip, cure indecision"
    },
    {
        "file_name": "Experts_see_writers'_deal_as_forerunner_for_labor_battles_to_come_in_industry_Oct2023",
        "header": "In battle against AI, humans win (for now)",
        "media": "Experts see writers' deal as forerunner for labor battles to come in industry",
        "time": "October 6, 2023",
        "section": "SPORTS; D; Pg. 8",
        "length": "946 words",
        "byline": "Jake Coyle Associated Press",
        "story_text": "In battle against AI, humans win (for now)\nExperts see writers' deal as forerunner for labor battles to come in industry\nThe Baltimore Sun\nOctober 6, 2023 Friday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: SPORTS; D; Pg. 8\nLength: 946 words\nByline: Jake Coyle Associated Press\nHighlight: Writers Guild of America members carry signs July 17 outside Disney offices in Burbank, California. The \ndeal struck to end the 148-day strike by writers secured significant guardrails against the use of artificial \nintelligence. Jordan Strauss/Invision\nBody\nAfter a 148-day strike, U.S. screenwriters secured significant guardrails against the use of artificial intelligence in \none of the first major labor battles over generative AI in the workplace.\nDuring the nearly five-month walkout, no issue resonated more than the use of AI in script writing. What was once a \nseemingly lesser demand of the Writers Guild of America became an existential rallying cry.\nThe strike was also about streaming-era economics, writers room minimums and residuals - not exactly compelling \npicket-sign fodder. But the threat of AI vividly cast the writers' plight as a human- versus-machine clash, with \nwidespread implications for other industries facing a radically new kind of automation.\nIn the coming weeks, WGA members will vote on whether to ratify a tentative agreement, which requires studios \nand production companies to disclose to writers if any material given to them has been generated by AI partially or \nin full. AI cannot be a credited writer. AI cannot write or rewrite \"literary material.\" AI-generated writing cannot be \nsource material.\n\"AI-generated material can't be used to undermine a writer's credit or separated rights,\" the proposed contract \nreads.\nMany experts see the screenwriters' deal as a forerunner for labor battles to come.\n\"I hope it will be a model for a lot of other content-creation industries,\" said Tom Davenport, a professor of \ninformation technology at Babson College and author of \"All-in on AI: How Smart Companies Win Big with Artificial \nIntelligence.\" \"It pretty much insures that if you're going to use AI, it's going to be humans working alongside AI. \nThat, to me, has always been the best way to use any form of AI.\"\nThe tentative agreement between the writers guild and the Alliance of Motion Picture and Television Producers, \nwhich negotiates on behalf of the studios, doesn't prohibit all uses of artificial intelligence. Both sides have \nacknowledged it can be a worthwhile tool in many aspects of filmmaking, including script writing.\nThe deal states that writers can use AI if the company consents. But a company cannot require a writer to use AI \nsoftware.\nIn battle against AI, humans win (for now) Experts see writers' deal as forerunner for labor battles to come in \nindustry\nLanguage over AI became a sticking point in the writers' negotiations, which dragged on in part due to the \nchallenges of bargaining on such a fast-evolving technology.\nWhen the writers strike began May 2, it was just five months after OpenAI released ChatGPT - the AI chatbot that \ncan write essays, have sophisticated conversations and craft stories from a handful of prompts. Studios said it was \nit too early to tackle AI in these negotiations and preferred to wait until 2026.\nUltimately, they hashed out terms while noting that the outlook is certain to change. Under the draft contract, \"the \nparties acknowledge that the legal landscape around the use of (generative AI) is uncertain and rapidly \ndeveloping.\" The companies and the guild agreed to meet at least twice a year during the contract's three-year \nterm.\nAt the same time, there are no prohibitions on studios using scripts they own to train AI systems. The WGA left \nthose issues up to the legal system to parse. A clause notes that writers retain the right to assert that their work has \nbeen exploited in training AI software.\nThat has been an increasingly prominent concern in the literary world. In recent weeks, 17 authors - including John \nGrisham, Jonathan Franzen and George R.R. Martin - filed a lawsuit against OpenAI alleging the \"systematic theft \non a massive scale\" of their copyrighted books.\nThe terms the WGA achieved will surely be closely watched by others - particularly the striking members of the \nactors union, SAG-AFTRA.\n\"This is the first step on a long process of negotiating and working through what generative AI means for the \ncreative industry - not just writers but visual artists, actors, you name it,\" says David Gunkel, a professor of media \nstudies at Northern Illinois University and author of \"Person, Thing, Robot.\"\nActors, who have been on strike since July 14, are likewise seeking better compensation from streaming. But they \nare also demanding safeguards against AI, which can potentially use a star's likeness without his or her permission \nor replace background actors entirely.\nAttempts to adopt AI \"as a normal operating procedure\" are \"literally dehumanizing the workforce,\" actor Bryan \nCranston said recently on a picket line. \"It's not good for society. It's not good for our environment. It's not good for \nworking-class families.\"\nSAG-AFTRA members have also voted overwhelmingly in favor of a strike authorization against video game \ncompanies. The use of AI in gaming is a particularly acute anxiety for voice-over actors.\nSome skeptics doubt whether the writers made significant headway on AI. Media mogul Barry Diller, chairman of \nthe digital media company IAC, believes not enough was done.\n\"They spent months trying to craft words to protect writers from AI, and they ended up with a paragraph that \nprotected nothing from no one,\" Diller told CNBC.\nRobert D. Atkinson, president of the tech policy think tank Information Technology & Innovation Foundation, said \nlimiting AI is unproductive.\n\"If we ban the use of tools to make organizations more productive, we are consigning ourselves to stagnation,\" \nAtkinson wrote on X, formerly known as Twitter.\nWhat most observers agree on, though, is that this was just the first of many AI labor disputes. Gunkel expects to \nsee both writers and studios continue to experiment with AI.\n\"We're so early into this that no one is able to anticipate everything that might come up with generative AI in the \ncreative industries,\" Gunkel said. \"We're going to see the need again and again to revisit a lot of these questions.\"\nIn battle against AI, humans win (for now) Experts see writers' deal as forerunner for labor battles to come in \nindustry\nLoad-Date: October 6, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Worst Part of a Wall St. Career May Be Coming to an End",
        "media": "The New York Times",
        "time": "April 17, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1333 words",
        "byline": "By Rob Copeland",
        "story_text": "Worst Part of a Wall St. Career May Be Coming to an End\nThe New York Times\nApril 17, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1333 words\nByline: By Rob Copeland\nBody\nArtificial intelligence tools can replace much of Wall Street's entry-level white-collar work, raising tough questions \nabout the future of finance.\nPulling all-nighters to assemble PowerPoint presentations. Punching numbers into Excel spreadsheets. Finessing \nthe language on esoteric financial documents that may never be read by another soul. \n  Such grunt work has long been a rite of passage in investment banking, an industry at the top of the corporate \npyramid that lures thousands of young people every year with the promise of prestige and pay.\n  Until now. Generative artificial intelligence -- the technology upending many industries with its ability to produce \nand crunch new data -- has landed on Wall Street. And investment banks, long inured to cultural change, are \nrapidly turning into Exhibit A on how the new technology could not only supplement but supplant entire ranks of \nworkers.\n  The jobs most immediately at risk are those performed by analysts at the bottom rung of the investment banking \nbusiness, who put in endless hours to learn the building blocks of corporate finance, including the intricacies of \nmergers, public offerings and bond deals. Now, A.I. can do much of that work speedily and with considerably less \nwhining.\n  ''The structure of these jobs has remained largely unchanged at least for a decade,'' said Julia Dhar, head of \nBCG's Behavioral Science Lab and a consultant to major banks experimenting with A.I. The inevitable question, as \nshe put it, is ''do you need fewer analysts?''\n  Some of Wall Street's major banks are asking the same question, as they test A.I. tools that can largely replace \ntheir armies of analysts by performing in seconds the work that now takes hours, or a whole weekend. The \nsoftware, being deployed inside banks under code names such as ''Socrates,'' is likely not only to change the arc of \na Wall Street career, but also to essentially nullify the need to hire thousands of new college graduates.\n  Top executives at Goldman Sachs, Morgan Stanley and other banks are debating how deep they can cut their \nincoming analyst classes, according to several people involved in the ongoing discussions. Some inside those \nbanks and others have suggested they could cut back on their hiring of junior investment banking analysts by as \nmuch as two-thirds, and slash the pay of those they do hire, on the grounds that the jobs won't be as taxing as \nbefore.\nWorst Part of a Wall St. Career May Be Coming to an End\n  ''The easy idea,'' said Christoph Rabenseifner, Deutsche Bank's chief strategy officer for technology, data and \ninnovation, ''is you just replace juniors with an A.I. tool,'' although he added that human involvement will remain \nnecessary.\n  Representatives for Goldman, Morgan Stanley, Deutsche Bank and others said it was too early to comment on \nspecific job changes. But the consulting giant Accenture estimated that A.I. could replace or supplement nearly \nthree-quarters of bank employees' working hours across the industry.\n  Goldman is ''experimenting with the technology,'' said Nick Carcaterra, a bank spokesman. ''In the near term, we \nanticipate no changes to our incoming analyst classes.''\n  This week, JPMorgan Chase's chief executive, Jamie Dimon, wrote in his annual shareholder letter that A.I. ''may \nreduce certain job categories or roles,'' and labeled the technology top among the most important issues facing the \nnation's largest bank. Mr. Dimon compared the consequences to those of ''the printing press, the steam engine, \nelectricity, computing and the internet, among others.''\n  Investment banking is a hierarchical industry, and banks typically hire young talent through two-year analyst \ncontracts. Tens of thousands of 20-somethings (both from undergraduate and M.B.A. programs) apply for some \n200 spots in each major bank's program. Pay starts at more than $100,000, not including year-end bonuses.\n  If they persevere, they move up the ranks to associate, then director and managing director; a handful end up \nrunning divisions. Although grueling, the life of a senior banker can be glamorous, involving traveling around the \nglobe to pitch clients and working on big-money corporate merger deals. Many who get through the two-year \nanalyst program have gone on to become business titans -- the billionaires Michael Bloomberg and Stephen \nSchwarzman began their careers in investment banking -- but a majority will leave before or after their two years \nare up, bank representatives said.\n  There are jokes among junior bankers that the most common tasks of the job involve dragging icons from one side \nof a document to another, only to be asked to replace the icon over and again.\n  ''One hundred percent drudgery and boring,'' said Gabriel Stengel, a former banking analyst who left the industry \ntwo years ago. Val Srinivas, a senior researcher for banking at Deloitte, said a lot of the work involved ''gathering \nmaterial, poring through it and putting it through a different format.''\n  Gregory Larkin, another former banking analyst, said the new technology would start ''a civil war'' inside Wall \nStreet's biggest firms by tilting the balance of power to technologists who program A.I. tools, as opposed to the \nbankers who use them -- to say nothing of technology giants like Microsoft and Google, which license much of the \nA.I. technology to banks for hefty fees.\n  ''A.I. will enable us to do tasks that take 10 hours in 10 seconds,'' said Jay Horine, co-head of investment banking \nat JPMorgan, describing analyst jobs. ''My hope and belief is it will allow the job to be more interesting.''\n  A.I.'s impact on finance is simply one facet of how the technology will reshape the workplace for all. Artificial \nintelligence systems, which include large language models and question-and-answer bots like ChatGPT, can \nquickly synthesize information and automate tasks. Virtually all industries are beginning to grapple with it to some \ndegree.\n  Deutsche Bank is uploading reams of financial data into proprietary A.I. tools that can instantaneously answer \nquestions about publicly traded companies and create summary documents on complementary financial moves that \nmight benefit a client -- and earn the bank a profit.\n  Mr. Horine said he could use A.I. to identify clients that might be ripe for a bond offering, the sort of bread-and-\nbutter transaction for which investment bankers charge clients millions of dollars.\n  Goldman Sachs has assigned 1,000 developers to test A.I., including software that can turn what it terms ''corpus'' \ninformation -- or enormous amounts of text and data collected from thousands of sources -- into page presentations \nWorst Part of a Wall St. Career May Be Coming to an End\nthat mimic the bank's typeface, logo, styles and charts. One firm executive privately called it a ''Kitty Hawk \nmoment,'' or one that would change the course of the firm's future.\n  That isn't limited to investment banking; BNY Mellon's chief executive said on a recent earnings call that his \nresearch analysts could now wake up two hours later than usual, because A.I. can read overnight economic data \nand create a written draft of analysis to work from.\n  Morgan Stanley's head of technology, Michael Pizzi, told employees in a January private meeting, a video of \nwhich was viewed by The New York Times, that he would ''get A.I. into every area of what we do,'' including wealth \nmanagement, where the bank employs thousands of people to determine the proper mix of investments for well-off \nsavers.\n  Many of those tools are still in the testing phase, and will need to be run past regulators before they can be \ndeployed at scale on live work. Bank of America's chief executive said last year that the technology was already \nenabling the firm to hire less.\n  Among Goldman Sachs's sprawling A.I. efforts is a tool under development that can transfigure a lengthy \nPowerPoint document into a formal ''S-1,'' the legalese-packed document for initial public offerings required for all \nlisted companies.\n  The software takes less than a second to complete the job.\n  Audio produced by Patricia Sulbarán.Audio produced by Patricia Sulbarán.\nhttps://www.nytimes.com/2024/04/10/business/investment-banking-jobs-artificial-intelligence.html\nGraphic\n \nPHOTOS: JPMorgan Chase's chief executive, Jamie Dimon, and Julia Dhar, head of BCG's Behavioral Science \nLab and a consultant to banks experimenting with A.I. (PHOTOGRAPHS BY AL DRAGO FOR THE NEW YORK \nTIMES\n JOHN LAMPARSKI/GETTY IMAGES FOR CONCORDIA SUMMIT) (B5) This article appeared in print on page B1, \nB5.               \nLoad-Date: April 17, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Apr2024",
        "header": "With GenAI, Database Firm MongoDB Gets Set for Big India Play",
        "media": "Economic Times (E-Paper Edition)",
        "time": "April 25, 2024",
        "section": "STARTUPS & TECH",
        "length": "497 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "With GenAI, Database Firm MongoDB Gets Set for Big India Play\nEconomic Times (E-Paper Edition)\nApril 25, 2024 Thursday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 497 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Global CEO spots a ‘great opportunity’ in India as banks, airlines and financial cos launch AI biz models\nBody\nBengaluru: New York-headquartered database company MongoDB sees a “great opportunity” in India as large \nbanks, airlines and financial services companies here launch AI business models, a top company executive said. \nValued at about $30 billion, MongoDB counts Tata Digital, Tata AIG, Canara HSBC Life Insurance, Zomato, \nDevnagri, Ambee, Inovaare and Observe.AI among its key clients. The company, which posted a revenue of $1.68 \nbillion in the last fiscal year, a 31% increase year-on-year, has partnered with cloud majors such as Amazon Web \nServices (AWS), Microsoft Azure and Google Cloud Platform (GCP), its global CEO Dev Ittycheria, told ET. \n“We expect India to be one of the big growth engines in the future. We’re in the formative stage here.  India is a \ngreat opportunity for us,” Ittycheria said. “The big opportunity here is generative AI companies, large banks, \ncommercial airline companies and financial services companies launching AI business models, leveraging \nadvances with large language models like Devnagri, Ambee, Inovaare and Observe.AI,” he said. There are around \nfour million developers in India. About 20% of the Fortune 500 companies have development centres in India. \nThere’s a burgeoning tech startup ecosystem as well, he said. The company’s India team with offices in Gurugram, \nBengalu-  ru, Mumbai an d Hyderabad are expanding and increasing their share in global headcount of 5,000, and \nthe business is growing quickly as a function of growth opportunity here, he added. MongoDB has tens of \nthousands of customers in over 100 countries. The MongoDB database platform has been downloaded hundreds of \nmillions of times since 2007. For example, Tata Digital has implemented MongoDB Atlas to streamline a variety of \ndata and improve operations for its super app Tata Neu.MongoDB Atlas is a multi-cloud developer data platform \nthat accelerates and simplifies how one builds with data. It provides an easy way to host and manage one’s data in \nthe cloud. It combines operational data, metadata and vector data in one platform. “Our customers in India range \nfrom large companies to startups. We’re a developer data platform, which started with databases and evolved into a \ndatabase-as-a-service company with our cloud offerings,” he added. Insurer TATA AIG is another company that is \nusing MongoDB to manage high-volume data, improve operations and support various operational systems, \nincluding claims processing, customer data management, risk assessment and real-time analytics. “The use cases \nare broad from online transaction processing to time series, search, vector search for building AI-powered \napplications, all-in-one common interface, which can be run across different cloud providers—AWS, Azure and \nGCP—as well as on-premise in case the customer is not comfortable. It is the best of both worlds,” Ittycheria said. \nWhen business conditions change, to go from one cloud to another, one need not rewrite their application \narchitecture, he explained.\nLoad-Date: April 25, 2024\nWith GenAI , Database Firm MongoDB Gets Set for Big India Play"
    },
    {
        "file_name": "Tools;_News_Analysis_May2023",
        "header": "The Next Fear on A.I.: Hollywood's Killer Robots Become the Military's",
        "media": "Tools; News Analysis",
        "time": "May 7, 2023",
        "section": "US",
        "length": "1553 words",
        "byline": "David E. Sanger",
        "story_text": "The Next Fear on A.I.: Hollywood's Killer Robots Become the Military's \nTools; News Analysis\nThe New York Times - International Edition\nMay 8, 2023 Monday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: US\nLength: 1553 words\nByline: David E. Sanger\nBody\nU.S. national security officials are warning about the potential for the new technology to upend war, cyber conflict \nand - in the most extreme case - the use of nuclear weapons.       \nWhen President Biden announced sharp restrictions in October on selling the most advanced computer chips to \nChina, he sold it in part as a way of giving American industry a chance to restore its competitiveness.       \nBut at the Pentagon and the National Security Council, there was a second agenda: arms control.       \nIf the Chinese military cannot get the chips, the theory goes, it may slow its effort to develop weapons driven by \nartificial intelligence. That would give the White House, and the world, time to figure out some rules for the use of \nartificial intelligence in sensors, missiles and cyberweapons, and ultimately to guard against some of the nightmares \nconjured by Hollywood - autonomous killer robots and computers that lock out their human creators.       \nNow, the fog of fear surrounding the popular ChatGPT chatbot and other generative A.I. software has made the \nlimiting of chips to Beijing look like just a temporary fix. When Mr. Biden dropped by a meeting in the White House \non Thursday of technology executives who are struggling with limiting the risks of the technology, his first comment \nwas \"what you are doing has enormous potential and enormous danger.\"       \nIt was a reflection, his national security aides say, of recent classified briefings about the potential for the new \ntechnology to upend war, cyber conflict and - in the most extreme case - decision-making on employing nuclear \nweapons.       \nBut even as Mr. Biden was issuing his warning, Pentagon officials, speaking at technology forums, said they \nthought the idea of a six-month pause in developing the next generations of ChatGPT and similar software was a \nbad idea: The Chinese won't wait, and neither will the Russians.       \n\"If we stop, guess who's not going to stop: potential adversaries overseas,\" the Pentagon's chief information officer, \nJohn Sherman, said on Wednesday. \"We've got to keep moving.\"       \nHis blunt statement underlined the tension felt throughout the defense community today. No one really knows what \nthese new technologies are capable of when it comes to developing and controlling weapons, and they have no \nidea what kind of arms control regime, if any, might work.       \nThe foreboding is vague, but deeply worrisome. Could ChatGPT empower bad actors who previously wouldn't have \neasy access to destructive technology? Could it speed up confrontations between superpowers, leaving little time \nfor diplomacy and negotiation?       \nThe Next Fear on A.I.: Hollywood's Killer Robots Become the Military's Tools News Analysis\n\"The industry isn't stupid here, and you are already seeing efforts to self-regulate,\" said Eric Schmidt, the former \nGoogle chairman who served as the inaugural chairman of the advisory Defense Innovation Board from 2016 to \n2020.       \n\"So there's a series of informal conversations now taking place in the industry - all informal - about what would the \nrules of A.I. safety look like,\" said Mr. Schmidt, who has written, with former secretary of state Henry Kissinger, a \nseries of articles and books about the potential of artificial intelligence to upend geopolitics.       \nThe preliminary effort to put guardrails into the system is clear to anyone who has tested ChatGPT's initial \niterations. The bots will not answer questions about how to harm someone with a brew of drugs, for example, or \nhow to blow up a dam or cripple nuclear centrifuges, all operations the United States and other nations have \nengaged in without the benefit of artificial intelligence tools.       \nBut those blacklists of actions will only slow misuse of these systems; few think they can completely stop such \nefforts. There is always a hack to get around safety limits, as anyone who has tried to turn off the urgent beeps on \nan automobile's seatbelt warning system can attest.       \nThough the new software has popularized the issue, it is hardly a new one for the Pentagon. The first rules on \ndeveloping autonomous weapons were published a decade ago. The Pentagon's Joint Artificial Intelligence Center \nwas established five years ago to explore the use of artificial intelligence in combat.       \nSome weapons already operate on autopilot. Patriot missiles, which shoot down missiles or planes entering a \nprotected airspace, have long had an \"automatic\" mode. It enables them to fire without human intervention when \noverwhelmed with incoming targets faster than a human could react. But they are supposed to be supervised by \nhumans who can abort attacks if necessary.       \nThe assassination of Mohsen Fakhrizadeh, Iran's top nuclear scientist, was conducted by Israel's Mossad using an \nautonomous machine gun that was assisted by artificial intelligence, though there appears to have been a high \ndegree of remote control. Russia said recently it has begun to manufacture - but has not yet deployed - its undersea \nPoseidon nuclear torpedo. If it lives up to the Russian hype, the weapon would be able to travel across an ocean \nautonomously, evading existing missile defenses, to deliver a nuclear weapon days after it is launched.       \nSo far there are no treaties or international agreements that deal with such autonomous weapons. In an era when \narms control agreements are being abandoned faster than they are being negotiated, there is little prospect of such \nan accord. But the kind of challenges raised by ChatGPT and its ilk are different, and in some ways more \ncomplicated.       \nIn the military, A.I.-infused systems can speed up the tempo of battlefield decisions to such a degree that they \ncreate entirely new risks of accidental strikes, or decisions made on misleading or deliberately false alerts of \nincoming attacks.       \n\"A core problem with A.I. in the military and in national security is how do you defend against attacks that are faster \nthan human decision-making, and I think that issue is unresolved,\" Mr. Schmidt said. \"In other words, the missile is \ncoming in so fast that there has to be an automatic response. What happens if it's a false signal?\"       \nThe Cold War was littered with stories of false warnings - once because a training tape, meant to be used for \npracticing nuclear response, was somehow put into the wrong system and set off an alert of a massive incoming \nSoviet attack. (Good judgment led to everyone standing down.) Paul Scharre, of the Center for a New American \nSecurity, noted in his 2018 book \"Army of None\" that there were \"at least 13 near use nuclear incidents from 1962 \nto 2002,\" which \"lends credence to the view that near miss incidents are normal, if terrifying, conditions of nuclear \nweapons.\"       \nFor that reason, when tensions between the superpowers were a lot lower than they are today, a series of \npresidents tried to negotiate building more time into nuclear decision making on all sides, so that no one rushed into \nconflict. But generative A.I. threatens to push countries in the other direction, toward faster decision-making.       \nThe Next Fear on A.I.: Hollywood's Killer Robots Become the Military's Tools News Analysis\nThe good news is that the major powers are likely to be careful - because they know what the response from an \nadversary would look like. But so far there are no agreed-upon rules.       \nAnja Manuel, a former State Department official and now a principal in the consulting group Rice, Hadley, Gates \nand Manuel, wrote recently that even if China and Russia are not ready for arms control talks about A.I., meetings \non the topic would result in discussions of what uses of A.I. are seen as \"beyond the pale.\"       \nOf course, the Pentagon will also worry about agreeing to many limits.       \n\"I fought very hard to get a policy that if you have autonomous elements of weapons, you need a way of turning \nthem off,\" said Danny Hillis, a computer scientist who was a pioneer in parallel computers that were used for \nartificial intelligence. Mr. Hillis, who also served on the Defense Innovation Board, said that Pentagon officials \npushed back, saying, \"If we can turn them off, the enemy can turn them off, too.\"       \nThe bigger risks may come from individual actors, terrorists, ransomware groups or smaller nations with advanced \ncyber skills - like North Korea - that learn how to clone a smaller, less restricted version of ChatGPT. And they may \nfind that the generative A.I. software is perfect for speeding up cyberattacks and targeting disinformation.       \nTom Burt, who leads trust and safety operations at Microsoft, which is speeding ahead with using the new \ntechnology to revamp its search engines, said at a recent forum at George Washington University that he thought \nA.I. systems would help defenders detect anomalous behavior faster than they would help attackers. Other experts \ndisagree. But he said he feared artificial intelligence could \"supercharge\" the spread of targeted disinformation.       \nAll of this portends a new era of arms control.       \nSome experts say that since it would be impossible to stop the spread of ChatGPT and similar software, the best \nhope is to limit the specialty chips and other computing power needed to advance the technology. That will \ndoubtless be one of many different arms control plans put forward in the next few years, at a time when the major \nnuclear powers, at least, seem uninterested in negotiating over old weapons, much less new ones. \nLoad-Date: May 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Inquiry Into Ouster of OpenAI’s Chief Executive Nears End",
        "media": "The New York Times",
        "time": "February 29, 2024",
        "section": "TECHNOLOGY",
        "length": "534 words",
        "byline": "Mike Isaac and Cade Metz Mike Isaac is a technology correspondent for The Times based in San",
        "story_text": "Inquiry Into Ouster of OpenAI’s Chief Executive Nears End\nThe New York Times \nFebruary 28, 2024 Wednesday 00:29 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 534 words\nByline: Mike Isaac and Cade Metz Mike Isaac is a technology correspondent for The Times based in San \nFrancisco. He regularly covers Facebook and Silicon Valley. Cade Metz writes about artificial intelligence, driverless \ncars, robotics, virtual reality and other emerging areas of technology.\nHighlight: WilmerHale, the law firm investigating Sam Altman, could present its findings to the company’s board as \nsoon as next month. Mr. Altman was reinstated as chief executive.\nBody\nWilmerHale, the law firm investigating Sam Altman, could present its findings to the company’s board as soon as \nnext month. Mr. Altman was reinstated as chief executive.\nWilmerHale, a prominent U.S. law firm, is close to wrapping up a detailed review of OpenAI’s chief executive, Sam \nAltman, and his ouster from the artificial intelligence start-up late last year, two people with knowledge of the \nproceedings said.\nThe investigation, when complete, could give insight into what went on behind the scenes with Mr. Altman and \nOpenAI’s former board of directors, which fired him on Nov. 17 before reinstating him five days later. OpenAI, which \nis valued at more than $80 billion, has led a frenzy over A.I. and could help determine the direction of the \ntransformative technology.\nMr. Altman, 38, has told people in recent weeks that the investigation was nearing a close, the two people with \nknowledge of the matter said. The results could be delivered to OpenAI’s board as soon as early next month, said \nthe people, who spoke on the condition of anonymity because of nondisclosure agreements.\nOpenAI declined to comment. WilmerHale did not respond to a request for comment.\nInvestigators spent the past three months interviewing OpenAI employees and executives after its former board \nsaid it no longer had confidence in Mr. Altman’s ability to run the company, the people said. The board said Mr. \nAltman had not been “consistently candid in his communications,” though it did not provide specifics.\nPrivately, the board worried that Mr. Altman was not sharing all his plans to raise money from investors in the \nMiddle East for an A.I. chip project, people with knowledge of the matter have said.\nAfter he was ousted, Mr. Altman waged a bare-knuckle fight against some OpenAI directors to get himself \nreinstated as chief executive. He won but made concessions. He agreed that OpenAI would hire a law firm to \ninvestigate his ouster, and he did not regain his own board seat at the company. But he succeeded in revamping \nthe board, removing two members and adding two others.\nOpenAI nearly imploded during the leadership crisis, endangering a potential windfall for its investors, such as \nMicrosoft, and its employees. In the months since Mr. Altman’s reinstatement, insiders have scrambled to contain \nthe fallout, advising employees to keep potential dissent quiet for fear of jeopardizing the company’s fortunes.\nInquiry Into Ouster of OpenAI’s Chief Executive Nears End\nOpenAI is considered a leader in generative A.I., technology that can generate text, sounds and images from short \nprompts. It is also among the many companies aspiring to build artificial general intelligence, or A.G.I., a machine \nthat can do anything the human brain can do.\nMeta, Google, Microsoft and others are also racing to develop such technology. Leaders at these companies \nbelieve that A.G.I. will revolutionize the computing industry, as well as the global economy and work forces.\nPHOTO: OpenAI’s former board of directors fired Sam Altman last year before reinstating him five days later. The \ncompany nearly imploded during the leadership crisis, endangering a potential windfall for its investors. \n(PHOTOGRAPH BY HAIYUN JIANG FOR THE NEW YORK TIMES) This article appeared in print on page B6.\nLoad-Date: February 29, 2024"
    },
    {
        "file_name": "The_Economic_Times_Mar2024",
        "header": "AI-led security startup SydeLabs raises $2.5 million in seed funding round",
        "media": "The Economic Times",
        "time": "March 28, 2024",
        "section": "FUNDING",
        "length": "409 words",
        "byline": "Tarush Bhalla",
        "story_text": "AI-led security startup SydeLabs raises $2.5 million in seed funding round\nThe Economic Times\nMarch 28, 2024 Thursday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 409 words\nByline: Tarush Bhalla\nBody\nArtificial intelligence (AI)-led risk management solutions provider, SydeLabs on Thursday said it has raised $2.5 \nmillion as a part of its seed round of funding led by RTP Global.The round also saw participation from early-stage \ninvestment firm Picus Capital along with marquee angel investors including Cred founder Kunal Shah and Mobile \nPremier League founder Sai Srinivas Kiran among others.SydeLabs said it will use the funds for research and \ndevelopment (R&D) and to build on its existing product portfolio. Founded by Ruchir Patwa and Ankita Kumari in \n2023, SydeLabs helps enterprises and core AI companies identify vulnerabilities in their generative AI models and \napplications before they go into final production. It currently has two products as part of its offerings including Syde \nBox, which helps detection of vulnerabilities in AI models, and Syde Guard, a real-time firewall that tracks security \nvulnerabilities after AI applications are deployed.“Most enterprises use one of the open-source foundational models \nout there and then build the context of their enterprises on top of it (to launch AI applications),” Kumari told ET. \n“However, open models are actually not tuned for safety and security and inherit some of these vulnerabilities, \nwhich can later seep into an enterprises’ AI applications. SydeLabs helps detect these vulnerabilities early on \nduring the production cycle,” she added.With both of its products in beta, San Francisco-based SydeLabs currently \nworks with over 10 enterprises across India and the US. Its tech team is based in Bengaluru.Within four months of \nlaunch, the company’s products have been deployed across 50 AI applications, and has tracked over 10,000 \nvulnerabilities.Without disclosing names, Kumari said SydeLabs is currently working with clients in domains of \necommerce, travel and financial services, as well as companies in India which are building large foundational AI \nmodels.It charges customers on a per scan and consumption basis.The company plans to hit $1 million in annual \nrecurring revenue (ARR) by the end of 2024, Kumari said.It will look to forge partnerships with large language \nmodel (LLM) operation providers to distribute its product and bolster its go-to-market strategy, she added. \nSydeLabs is also working on tools which will help enterprises with achieving compliance for their AI applications \nacross geographies, tuned to local rules and policies. For Reprint Rights: timescontent.com\nLoad-Date: March 28, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Plan to Build Supercomputers",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 9, 2023",
        "section": "FRONT PAGE",
        "length": "750 words",
        "byline": "Our Bureau",
        "story_text": "Plan to Build Supercomputers\nEconomic Times (E-Paper Edition)\nSeptember 9, 2023 Saturday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 750 words\nByline: Our Bureau\nHighlight: AI ON INDIA US chipmaker to team up with RIL for large language model that will be trained in local \nlanguages, to join hands with Tata Group to build AI infra\nBody\nBengaluru: American chipmaker Nvidia and Reliance Industries, India's largest company by market cap, will \ntogether build a foundational large language model (LLM) — an artificial intelligence algorithm —that will be trained \non an array of diverse Indic languages used by the country's 1.4 billion people, chief executive Jensen Huang \nannounced on Friday. The $27.5-billion company, which is the world's best-known maker of hardware and software \nfor AI tools, also said it will partner with the salt-to-software conglomerate Tata Group to advance AI infrastructure \nin India. The co-created LLM, which is  the bedrock of all generative AI models such as ChatGPT, will be \neventually owned by Reliance, Huang said. “They (Reliance) can create AI models, services and applications for \ntheir 450 million (customers),” he added. \nMeanwhile, the partnership with the Tata Group's Tata Consultancy Services, Tata Motors and Tata \nCommunications is ai-  med at building “AI infrastructure that is over an order of magnitude more powerful than the \nfastest supercomputer in India today”, Huang told reporters in Bengaluru while unveiling the two big-ticket \npartnerships.  \"India really needs to accelerate its infrastructure building. We would like to do it almost immediately, \nthe best we (Nvidia) can do is probably create supercomputers that are an order of magnitude 100 times faster than \nthe fastest supercomputer in all of India today. By the end of next year, (India) will have very large computers,\" said \nthe 60-year-old Nvidia founder who is on a week-long visit to India, which included a meeting with Prime Minister \nNarendra Modi on Monday.  Noting that “Reliance with 450 million customers has more customers and access to \ndata than any company on the planet (and) they support probably all 22 languages and 2,500 dialects of the \ncountry\", Huang said that Nvidia will help co-create AI solutions for Reliance using this data.  In a statement on \nFriday, Mukesh Ambani, chairman of Reliance Industries, said that “as India advances from a country of data \nproliferation to creating technology infrastructure for widespre-  ad and accelerated growth, computing and \ntechnology super centres like the one we envisage with Nvidia will provide the catalytic growth just like Jio did to our \nnation's digital march”.  Pointing to the advancements that have “made focus on AI a central priority in \ngovernments, industries and society at large”, N Chandrasekaran, chairman of Tata Sons, said “the impact of AI \nand machine learning is going to be profound across industries and every aspect of  our lives”. The Tata Group's \npartnership with Nvidia will “democratise access to AI infrastructure, accelerate build-out of AI solutions and enable \nupgradation of AI talent at scale”, he said in a statement. Nvidia will provide access to the most advanced Nvidia \nGH200 Grace Hopper Superchip and Nvidia DGX Cloud, an AI supercomputing service in the cloud. GH200 \nprovides massive memory bandwidth.  The American technology company is also likely to forge partnerships with \nsoftware giants Infosys and Wipro in the future. The chipmaker, which is riding on a trillion-dollar valuation led by \nthe boom in generative Artificial Intelligence (AI), expects to leverage the vast data generated by India's $1.4 \nbillion population to build AI products that can be exported from here, ET had reported on Friday.  AI \nINFRASTRUCTURE The partnership with the Tatas is focused on building AI infrastructure in India. “If the \nPlan to Build Supercomputers\ninfrastructure is av-  ailable in India, more companies can be founded here,\" said Huang, pointing out that currently \nfirms are forced to look for infrastructure abroad. \"TCS has 600,000 IT professionals, we're going to reskill them for \nAI; instead of developing business operations applications in the back room, they will be creating AI applications for \nthe front office,” he added.  Noting that Tata Motors is one of the largest car companies in the world, Huang said \nthat \"in future Tata Motors will be digitalised\".  \"From the beginning to the end, from the design, styling, engineering, \nsimulation testing, all the way to the autonomous vehicle capabilities that they want to deploy, AI will be part of that \nentire thing from beginning to end,” he said. “One of the most obvious places of AI in Tata Motors is a brand called \nJLR (Jaguar Land Rover), autonomous vehicles using AI for autonomous driving, lane keeping and automatic \nemergency braking,” he said. FOR FULL REPORT, GO TO www.economictimes.com\nLoad-Date: September 9, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "India will Establish Guardrails for AI Sector: Rajeev Chandrasekhar",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "COMPANIES",
        "length": "415 words",
        "byline": "Aashish Aryan & Surabhi Agarwal",
        "story_text": "India will Establish Guardrails for AI Sector: Rajeev Chandrasekhar\nEconomic Times (E-Paper Edition)\nMay 13, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 415 words\nByline: Aashish Aryan & Surabhi Agarwal\nHighlight: ESTABLISHING SOME PRINCIPLES Govt not in favour of legislation regulating generative artificial \nintelligence yet, unlike US, EU; discipline needs to be brought in the industry\nBody\nNew Delhi: India plans to establish “some principles” which will act as “guardrails” for the fast-growing artificial \nintelligence (AI) sector, according to a top lawmaker who said this will help regulate generative AI platforms such \nas Microsoft's Open AI and Google's Bard as well as their use by other companies. In contrast to the view taken by \nthe European Union and the US, the Indian government is not in favour of legislation to regulate generative AI, yet, \naccording to Rajeev Chandrasekhar, minister of state for electronics and IT. He added that discipline needs to be \nbrought into an industry that can cause much chaos and harm. \n“If anybody says I know the  right way to regulate AI, there will be an Elon Musk view, the Open AI view, or 100 \nother views. We are not going to go down that road at all,” he told ET in an interview. “AI is an emerging technology, \nand we will establish some principles as guardrails. Then the subordinate legislation or how to regulate it will keep \nevolving,” he said. India has one of the largest data sets and is therefore very crucial for companies working on \ngenerative AI. It is important India does not allow technology regulation to lag technology innovation in AI, the \nminister said. “AI innovation is now growing very fast. In the blink of an eye, there's a new dis-  ruption. So \ntherefore, we must establish fairly embedded principles in the law.” Pointing out that the proposed guardrails will put \nthe onus on the platforms to ensure that no one is using them to “create misinformation”, Chandrasekhar said “you \ncannot create things that are fake, you cannot cause user harm, you cannot have exploitive content.” The \ngovernment, according to the minister, will define terms such as “exploitative” after consultation with the industry. \nThe upcoming Digital India Act, which is a revamp of the 23-yearold IT Act, will also contain a chap-  ter on \nemerging technologies. The Centre, which has held one round of consultations on the Digital India Act (DIA), is \nplanning to hold another one later in May, in New Delhi. The law will not just update several regulations with respect \nto technology but also frame new ones to regulate emerging areas such as Web 3 among others. It is also \nreviewing the concept of safe harbour or immunity which is enjoyed by internet intermediaries under Section 79 of \nthe IT Act. Chandrasekhar told ET that in the new DIA, as a principle, India is moving away from “the idea of no \naccountability” of the platform.\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "OpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’",
        "media": "The New York Times",
        "time": "January 9, 2024",
        "section": "TECHNOLOGY",
        "length": "618 words",
        "byline": "Cade Metz &lt;p&gt;Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and",
        "story_text": "OpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’\nThe New York Times \nJanuary 8, 2024 Monday 20:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 618 words\nByline: Cade Metz &lt;p&gt;Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and \nother emerging areas of technology.&lt;/p&gt;\nHighlight: The artificial intelligence start-up said that it collaborated with news organizations and that The Times, \nwhich accused it of copyright infringement, was not telling the full story.\nBody\nThe artificial intelligence start-up said that it collaborated with news organizations and that The Times, which \naccused it of copyright infringement, was not telling the full story.\nOpenAI said on Monday that a New York Times lawsuit against it was “without merit” and that it supported and \ncreated opportunities for news organizations, as it waded further into a debate over the unauthorized use of \npublished work to train artificial intelligence technologies.\nThe Times sued OpenAI and Microsoft on Dec. 27, accusing the companies of infringing on its copyrights by using \nmillions of its articles to train A.I. technologies like the ChatGPT chatbot. Chatbots now compete with The Times as \na source of reliable information, the lawsuit said.\nIn a 1,000-word blog post on Monday, OpenAI said it collaborated with news organizations and had struck \npartnerships with some of them, including The Associated Press. Using copyrighted works to train its technologies \nis fair use under the law, the company added. The Times’s lawsuit does not tell the full story of how OpenAI and its \ntechnologies operate, it said.\n“We look forward to continued collaboration with news organizations, helping elevate their ability to produce quality \njournalism by realizing the transformative potential of A.I.,” the company wrote.\nLindsey Held, a spokeswoman for OpenAI, declined further comment.\nThe Times was the first major American media organization to sue OpenAI and Microsoft over copyright issues \nrelated to its written works. Other groups, including novelists and computer programmers, have also filed copyright \nsuits against A.I. companies. The suits have been spurred by the boom in “generative A.I.,” technologies that \ngenerate text, images and other media from short prompts.\nOpenAI and other A.I. companies build this technology by feeding it enormous amounts of digital data, some of \nwhich is likely copyrighted. That has led to a realization that online information — stories, artwork, news articles, \nmessage board posts and photos — may have significant untapped value.\nA.I. companies have long claimed that they can legally use such content to train their technologies without paying \nfor it because the material is public and they are not reproducing the material in its entirety.\nIn its blog post, OpenAI said its discussions with The Times about a potential partnership appeared to progress \nconstructively, with a last communication on Dec. 19. During the negotiations, it said, The Times had mentioned \nOpenAI Says New York Times Lawsuit Against It Is ‘Without Merit’\nthat it had seen OpenAI’s technology “regurgitate” some of its content — meaning the technology had generated \nnear-verbatim excerpts from articles that ran in The Times — but declined to provide examples. When The Times \nsued eight days later, OpenAI said it was surprised and disappointed.\nIn a statement, Ian Crosby, an attorney for The Times at the law firm Susman Godfrey, said that OpenAI’s blog post \n“concedes that OpenAI used The Times’s work” and that OpenAI and Microsoft were using The Times’s articles to \nbuild products without permission or payment. “That’s not fair use by any measure,” he said.\nOpenAI said its technology sometimes regurgitates articles, but that was a “rare bug” that it was working to solve. \nThe Times’s lawsuit included examples showing ChatGPT reproducing excerpts from its articles nearly word for \nword.\n“Intentionally manipulating our models to regurgitate is not an appropriate use of our technology and is against our \nterms of use,” OpenAI said.\nPHOTO: OpenAI said in a blog post that the lawsuit did not tell the full story of how OpenAI and its technologies, \nlike the ChatGPT chatbot, operated. (PHOTOGRAPH BY MATT ROURKE/ASSOCIATED PRESS) This article \nappeared in print on page B4.\nLoad-Date: January 9, 2024"
    },
    {
        "file_name": "Essay_Mar2024",
        "header": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest",
        "media": "Essay",
        "time": "March 19, 2024",
        "section": "OPINION",
        "length": "1145 words",
        "byline": "Graciela Mochkofsky",
        "story_text": "One Way to Help a Journalism Industry in Crisis: Make J-School Free; Guest \nEssay\nThe New York Times \nMarch 18, 2024 Monday 11:58 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1145 words\nByline: Graciela Mochkofsky\nHighlight: We need mission-driven, imaginative news leaders who are not bound by the models of the past.\nBody\nMany uncertainties haunt the field of journalism today — among them, how we can reach our audience, build public \ntrust in our work, and who is going to pay for it all. But one thing is certain: as complicated and dark as the world \nlooks today, it would be much worse if journalists were not there to report on it.\nResearch shows that towns that have lost sources of local news tend to suffer from lower voter turnout, less civic \nengagement and more government corruption. Journalists are essential just as nurses and firefighters and doctors \nare essential.\nAnd to continue to have journalists, we need to make their journalism education free.\nThis might sound counterintuitive given the state of the industry. Shrinking revenue and decreasing subscription \nfigures have led to a record number of newsroom jobs lost. Much of the local news industry has fallen into the \nhands of hedge funds focused on squeezing the last drops of revenue out of operations by decimating them. \nBillionaires who appeared as saviors just a few years ago have grown tired of losing money on the media \norganizations they bought. Public trust in the value of news is at historical lows, while a growing percentage of \npeople are avoiding the news altogether.\nGenerative artificial intelligence, which is on the verge of reshaping almost everything around us, is bringing yet \nanother technological disruption to the industry. Against this grim backdrop, authoritarian leaders are increasingly \ntargeting journalists as political enemies both at home and abroad.\nAnd yet there are still tens of thousands of jobs in news media in America, with exceptional journalism being \nproduced every day. Some major organizations have even found ways to thrive in the digital age. Prominent \nfoundation leaders have started an effort to pour hundreds of millions of philanthropic dollars into local journalism, \nand a movement has formed to push for federal and local legislation to direct public funding to news. An initiative to \nreplant local news has founded dozens of nonprofit newsrooms in cities around the country. And a small but \ngrowing number of organizations are redefining the way news agendas are set, focusing on rebuilding public trust \nwithin small communities.\nNo matter how the news industry evolves, we will continue to need journalists. Successful business models for \nmedia are necessary, but the most crucial element for strong, independent journalism is the people who make it. \nGiven the present stakes in the industry, our society and the world, we need mission-driven, imaginative news \nleaders who are not bound by the models of the past, who have the motivation and freedom to reimagine the field, \nand the empathy and commitment to serve the public interest, undaunted by attacks and threats.\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nWe must also move beyond the lack of economic and demographic diversity that has long been a problem in the \nindustry. News has too often been reported by predominantly middle-class, white, male journalists, resulting in \ncoverage that has repeatedly missed the issues that are most important to the people receiving the news, \ncontributing to the public’s lack of trust in the media.\nIn a resource-starved industry, few newsrooms can offer the type of mentoring, guidance and time that it takes to \nshape a great journalist. This is now primarily the responsibility of journalism schools. It is the civic duty of these \nschools to find and train reporters and news leaders, instill in them an ethical foundation, help develop their critical \nthinking skills, allow them to try and fail in a safe environment, open doors and provide a support network. \n(Journalism schools should also contribute research in a variety of areas, from the impact of A.I. to new business \nmodels to identifying and responding to emerging threats.)\nBut the cost of a journalism education has become an insurmountable barrier for exactly the kind of people we need \nthe most. And those who, with great effort, manage to overcome that barrier, carry a weight that could limit their \nprofessional options.\nReporters burdened with debt are less likely to take professional risks and more likely to abandon the field. \nAccording to the Bureau of Labor Statistics, the median reporter salary in America is less than $56,000 a year, or \nabout $27 per hour. In low-income areas, where news deserts are more prevalent, annual salaries can be as low as \n$20,000. A Wall Street Journal report about the debt-to-income ratio of alumni of 16 journalism masters programs \nfound that many graduates leave with debts that exceed their postgraduate income.\nAs the dean of the Craig Newmark Graduate School of Journalism at the City University of New York, I can tell you \nthat half measures won’t solve this quandary. My school was founded in 2006 as a public alternative to elite \njournalism schools in the city and it remains one of the most affordable in the nation.\nOur in-state students pay about a quarter of the cost of an equivalent degree from top-tier schools with which we \nsuccessfully compete. This year alone, 90 percent of our students are on scholarships, and a record 25 percent are \nattending tuition-free. We also waived the $75 application fee this admission cycle and saw an increase of more \nthan 40 percent in our applicant pool.\nThanks to these policies, we have succeeded where the media industry keeps failing. Over 50 percent of our \nstudents are people of color and from underserved communities. Many couldn’t have attended our school if we \nhadn’t offered significant scholarship support. But that’s not enough. Though we rank as one of the journalism \nschools with higher-medium-income and lower-median-debt alumni, our students still don’t graduate fully debt-free.\nThis is why this year, we began a campaign to go fully tuition-free by 2027. While other schools might face different \nfinancial challenges, we hope that many more will follow us.\nWe need journalists whose only obligations are to the facts and the society they serve, not to lenders; who are \nconcerned with the public interest, not with interest rates; who can make risky decisions and take the difficult path if \nthat’s what the mission requires, free of financial burden. Journalism schools can help achieve that. In tough times, \nit is natural to mourn the past or lament the present, but what we really need is bold action.\nGraciela Mochkofsky is the dean at CUNY’s Craig Newmark Graduate School of Journalism. She is the author, \nmost recently, of “The Prophet of the Andes: An Unlikely Journey to the Promised Land.”\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nPHOTO:  (PHOTOGRAPH BY Pat Thomas FOR THE NEW YORK TIMES)\nOne Way to Help a Journalism Industry in Crisis: Make J-School Free Guest Essay\nLoad-Date: March 19, 2024"
    },
    {
        "file_name": "New_York_Observer_May2023",
        "header": "Amid a Heated A.I. Race, Apple Struggles to Retain Top Talent",
        "media": "New York Observer",
        "time": "May 4, 2023",
        "section": "",
        "length": "740 words",
        "byline": "Sissi Cao",
        "story_text": "Amid a Heated A.I. Race, Apple Struggles to Retain Top Talent\nNew York Observer\nMay 2, 2023 Tuesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 740 words\nByline: Sissi Cao\nBody\nThe heated Big Tech artificial intelligence race is making Apple very nervous. Stagnant product development and \nlagging research in large language models (LLMs), the underlying technology powering applications like ChatGPT, \nhave hampered the iPhone maker's ability to retain top talent and introduce a meaningful A.I. product to compete \nwith Microsoft and Google.\nAlthough Apple's business is more focused on hardware and less reliant on web search-a key area of generative \nA.I. application-than Google and Microsoft, the opportunities afforded by recent breakthroughs in A.I. are apparently \ntoo important to miss for the world's most valuable tech company. In recent months, Apple engineers, including \nmembers of the ?Siri? team, have been testing GPT-like language-generation concepts on a weekly basis, the New \nYork Times reported in March.\nAt the center of Apple's A.I. effort is a team led by John Giannandrea, the company's head of machine learning and \nA.I. strategy.\nGiannandrea, a former tech executive at Google, has been leading Apple's A.I. projects, including voice assistant \nSiri, since April 2018. However, as A.I. competition intensifies among Big Tech companies, Giannandrea's team is \nembattled in a talent war with competitors.\nLate last year, the Siri team lost three star engineers to Google, the Information reported on April 27. Srinivasan \nVenkatachary, Steven Baker and Anand Shukla all joined Apple in November 2018 under Giannandrea's \nleadership. They left between October and November 2022 to work on Google's A.I. projects, according to their \nLinkedIn profiles.\nTop engineers believe Google is a better place to work\nGoogle CEO Sundar Pichai personally wooed the group. While Apple CEO Tim Cook tried to persuade them to \nstay, Venkatachary, Baker and Shukla believed Google was a better place to work on LLMs, according to \nanonymous sources speaking to the Information.\nApple hasn't responded to an inquiry to comment on the three engineers' departures.\nVenkatachary and Baker now both hold the title of VP of engineering at Google. Venkatachary's work focuses on \n\"A.I. product expansion,\" while Baker is working on \"new stuff,\" according to their LinkedIn pages. Shukla has \nassumed the title of distinguished engineer, a high-level engineering position at Google.\nJohn Burkey, a former Apple engineer on the ?Siri? team between 2014 and 2015, told the New York Times in \nMarch that the Siri? voice assistant is built on \"clunky code\" that made it very difficult for engineers to add new \nfeatures. As a result, there was no path for ?Siri? to become a \"creative assistant\" like ChatGPT, Burkey said.\nAmid a Heated A.I. Race, Apple Struggles to Retain Top Talent\nMicrosoft CEO Satya Nadella expressed similar views on voice assistant products in general. Voice assistants are \n\"dumb as a rock,\" Nadella said in an interview with the Financial Times in March.\nA.I. hype fuels the talent war in tech\nThe past 12 months have been marked by unprecedented cost-cutting measures across the tech sector, with \nGoogle and many large tech companies laying off tens of thousands of employees and cutting back on office perks. \nInterestingly, Apple is the only Big Tech firm that has avoided massive layoffs, and yet stability hasn't stopped its \ntop engineers from leaving for more rewarding jobs.\nIt's not just Apple losing talent to Google. Earlier this year, the Information reported Google's top A.I. scientists were \nquitting to join OpenAI because they believed what OpenAI was working on was more promising. Yesterday (May \n1), University of Toronto professor Geoffrey Hinton, who is known in the industry as \"the godfather of A.I.,\" left his \npart-time advisory role at Google, fearing the tech company was moving too quickly without considering the social \nimpact of A.I.\nA.I. scientists and engineers are often among the highest-paid roles at tech companies. And large firms in the \nindustry offer similarly lucrative compensation packages. At Apple, for example, a median software engineer makes \n$287,000 a year, including salary, bonus and stock awards, according to levels.fyi, a tech salary tracking site.\nBut money is usually not the top consideration when they choose where to work. \"Scientists and engineers do go \nafter high compensations,\" Kyunghyun Cho, a data science professor at New York University and former research \nscientist at Facebook AI Research, told Observer. \"But, at the end of the day, what they are looking for is an \nenvironment where they can flourish and contribute to a success.\"\nLoad-Date: May 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "TECHNOLOGY",
        "length": "843 words",
        "byline": "Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times",
        "story_text": "Apple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nThe New York Times \nMarch 19, 2024 Tuesday 22:32 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 843 words\nByline: Tripp Mickle, Nico Grant and Brian X. Chen Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nNico Grant is a technology reporter covering Google from San Francisco. Previously, he spent five years at \nBloomberg News, where he focused on Google and cloud computing. Brian X. Chen is the lead consumer \ntechnology writer for The Times. He reviews products and writes Tech Fix, a column about the social implications of \nthe tech we use.\nHighlight: A partnership would extend the long relationship between the companies that has helped deliver \neverything from maps to search on Apple’s devices.\nBody\nA partnership would extend the long relationship between the companies that has helped deliver everything from \nmaps to search on Apple’s devices.\nApple is in discussions with Google about using the search giant’s generative artificial intelligence model called \nGemini for its next iPhone, as the company races to embrace a technology that has upended the tech industry.\nThe talks are preliminary and the exact scope of a potential deal hasn’t been defined, three people with knowledge \nof the discussions said. Apple has also held discussions with other A.I. companies, one of these people said, as it \nlooks to tap into the power of a large language model capable of analyzing vast amounts of data and generating \ntext on its own.\nTim Cook, Apple’s chief executive, has promised investors that the company will introduce new generative A.I. \ncapabilities this year. The company’s smartphone rivals, Samsung and Google, have already added Gemini to their \nnewest devices to edit videos and summarize audio recordings.\nApple and Google declined to comment. Bloomberg reported earlier on their talks.\nAn Apple-Google deal on generative A.I. would extend one of technology’s most longstanding partnerships. Since \nApple introduced the iPhone in 2007, Google has been a critical contributor to the device’s success. It initially \nprovided Google Maps for navigation and the default search engine on the iPhone’s Safari browser, now a lucrative \nagreement for which Google pays Apple more than $18 billion a year. \nGoogle’s discussions to provide generative A.I. capabilities for the iPhone would be the latest example of its filling \na gap in Apple’s products. Apple’s effort to develop its own large language model, the technology behind chatbots \nlike ChatGPT and Gemini, has been running behind, two people familiar with its development said.\nApple’s delay in releasing an A.I. product has been costly. After a decade-long run as the world’s most valuable \npublic company, it was dethroned this year by Microsoft, which has aggressively pursued A.I. The technology has \nbeen heralded for its potential to disrupt businesses and create trillions of dollars in economic value.\nApple and Google Are Discussing a Deal to Bring Generative A.I. to iPhones\nDespite its delays, Apple has the potential to be a big player in A.I. The company has more than two billion devices \nactively in use, making it an attractive partner for Google and others. Its reputation for protecting customers’ private \ninformation could also be helpful in a future where A.I. services help manage people’s calendars or health data.\nA deal could bring the Gemini model to iPhones around the world, giving Google access to a massive user base \nand making generative A.I. even more mainstream. Virtually overnight, Google could have more consumers using \nits A.I. than its chief rival, OpenAI, which makes ChatGPT — making a pact with Apple a tantalizing prospect.\n(The New York Times sued OpenAI and Microsoft in December for copyright infringement of news content related \nto A.I. systems.)\nApple’s selecting Google as an A.I. supplier would be a crucial vote of confidence in the search giant after a number \nof setbacks to its A.I. ambitions. The company’s first A.I. chatbot, Bard, debuted to middling reviews last March and \nstruggled to attract as many users as ChatGPT.\nIn February, Google debuted a new chatbot, Gemini. The chatbot ran into problems last month when users found \nthat its image generator produced illustrations of historical figures that were not racially accurate and refused in \nmost instances to generate images of white people, leading to accusations of bias. Google disabled the ability to \ncreate images of people and vowed to fix the problem.\nIn a note on Tuesday, a Bernstein Research analyst, Toni Sacconaghi, called an Apple-Google deal a “win-win,” \ngiving Apple generative A.I. for iPhones and validating Google’s work on Gemini. He also said Apple didn’t have to \nown an A.I. model on iPhones to profit from it and could instead take a commission from Google, which currently \ncharges $19.99 per month for its Gemini Advanced app.\nCompanies haven’t yet cashed in on generative A.I. The costs associated with running large language models in \nthe cloud are staggering, and consumers and business customers are only starting to pay for the emerging \ntechnology. But they are optimistic that profits will increase as the capabilities of A.I. systems improve and the costs \ndecline for building the data centers to power the systems.\nA new deal between Apple and Google could draw scrutiny from U.S. regulators. The Justice Department is in the \nfinal stages of a lawsuit against Google for harming competition by paying Apple to be the default search engine on \nthe iPhone and other services. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict this year.\nPHOTO: A deal to provide A.I. capabilities for the iPhone would be the latest example of Google filling a gap in \nApple’s products. (PHOTOGRAPH BY GEORGE ETHEREDGE FOR THE NEW YORK TIMES) This article \nappeared in print on page B5.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2023",
        "header": "A Funding Frenzy Is Enveloping A.I. Start-Ups",
        "media": "The New York Times",
        "time": "March 15, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1170 words",
        "byline": "By Erin Griffith and Cade Metz",
        "story_text": "A Funding Frenzy Is Enveloping A.I. Start-Ups\nThe New York Times\nMarch 15, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1170 words\nByline: By Erin Griffith and Cade Metz\nBody\nIn just weeks, a gold rush into artificial intelligence start-ups has become a full-blown mania.\nWhen four leading artificial intelligence researchers left Google this year to create a start-up called Mobius AI, they \nweren't sure what their product might be -- just that it would involve A.I. technology that could generate its own \nphotos and videos. \n  Within about a week, two of Silicon Valley's top venture capital firms, Andreessen Horowitz and Index Ventures, \nhad swooped in with a funding offer, three people with knowledge of the matter said.\n  Suddenly, Mobius -- little more than more than four guys and a laptop -- was valued around $100 million, an \nusually high number for a start-up that was just a week or so old, the people said. When word of the deal leaked \nout, other investors descended to urge Mobius to take their money, too, they said.\n  Over the past few months, a gold rush into start-ups working on ''generative'' artificial intelligence has escalated \ninto a no-holds-barred deal-making mania. The interest has mounted so rapidly that A.I. start-up valuations are \nsoaring beyond that of 2021's ''everything bubble,'' with investors trawling the rosters of companies like Google, \nMeta and OpenAI for A.I. experts who may have an itch to start their own company.\n  The funding race has heated up ever since ChatGPT, the chatbot made by OpenAI, went viral last year by \nshowing the power of A.I. to generate its own tweets, emails, articles, answers and ideas. Even as investors expect \nlast week's failure of Silicon Valley Bank, an institution that many tech start-ups relied on, to cast a pall over start-up \nfunding, there is still a mismatch between the number of opportunities in artificial intelligence and the money \navailable to fund them.\n  That's because of the scarcity of A.I. companies and the potential of the technology. With few experts in the field, \nand most of them working at a handful of big tech companies, only a few generative A.I. start-ups -- such as \nStability AI and Jasper -- have broken out. Investors desperate for the next big thing are competing fiercely to invest \nin these companies, offering some A.I. entrepreneurs nine-figure valuations for little more than an idea and a \nrésumé.\n  ''We're in that phase of the market where it's, like, let 1,000 flowers bloom,'' said Matt Turck, an investor who \nspecializes in A.I. at the venture firm FirstMark. He added that the deal-making stood out in an otherwise dreary \nmoment for tech marked by layoffs, cost-cutting and a drought of initial public offerings.\n  Andreessen Horowitz did not respond to a request to comment. Index Ventures declined to comment on Mobius's \nfunding. \nA Funding Frenzy Is Enveloping A.I. Start-Ups\n  The blooming flowers include Dust, a start-up founded by former employees of OpenAI. Dust is nearing a $5 \nmillion funding round led by Sequoia Capital that will value it at $30 million to $40 million, two people with \nknowledge of the situation said. The round was competitive, with term sheets offering valuations as high as twice \nthat, one of the people said.\n  Perplexity AI, a start-up created by former employees of OpenAI, Google and Meta, is raising $20 million to $25 \nmillion, led by NEA, that values the company at about $150 million, two people familiar with the situation said. And \nLangChain, a start-up working on software that helps other companies incorporate A.I. into their products, has \nraised funding from Benchmark, a person with knowledge of the matter said.\n  Those follow the $13 billion that OpenAI raised from Microsoft, including $10 billion in January, and $300 million \nraised this year by Anthropic, another A.I. start-up.\n  Dust and LangChain declined to comment.Various aspects of the funding rounds were reported earlier by \nBusiness Insider, The Information and Newcomer.\n  At Y Combinator, the start-up incubator, at least 50 of the 218 companies in the current program are working on \ngenerative A.I., according to a tally taken by Truewind, an A.I. bookkeeping start-up that is part of the program. \nAlex Lee, Truewind's chief executive, said ChatGPT had helped investors, potential customers and potential \nemployees understand the possibilities of the technology.\n  ''Before, you'd go in and say, 'We're doing something with A.I.,' and it's hard to picture exactly what that looks like,'' \nMr. Lee said. ''Now, they say, 'Oh, I've played with ChaptGPT, and I can imagine how I could use this in my world.'''\n  He declined to comment on his company's fund-raising ahead of Y Combinator's demo day, when companies pitch \ninvestors, in April.\n  Even though more mature A.I. start-ups have already raised large sums, they can't afford to ignore the latest \novertures from investors, said Mike Volpi, an investor at Index Ventures who sits on the board of the A.I. start-up \nCohere.\n  That's partly because A.I. technologies like ChatGPT, which learn by analyzing vast amounts of digital data, \nrequire a lot of computing power, which is expensive. Mr. Volpi estimated that start-ups needed at least $500 million \nto develop their own large language model, the technology that underpins ChatGPT.\n  At a tech conference in Los Angeles organized by the investment firm Upfront Ventures this month, A.I. was \ninescapable. The event began with a goofy video skit about a venture capitalist giving a ChatGPT-generated \nspeech. It quickly went off the rails, with the investor confidently regurgitating incorrect information from the bot as \nthe punchline.\n  Speakers -- including Al Gore; Marc Benioff, the chief executive of Salesforce; and V Pappas, a top executive at \nTikTok -- weighed in from there, mostly by hailing the technology's transformative potential. A panel of A.I. \nspecialists said they welcomed the sudden attention, with Phil Blunsom, head of science at Cohere, noting that he \nhas worked on language modeling for 20 years and that, until recently, ''absolutely no one was interested in it.''\n  Some investors debated whether A.I. start-ups would get run over by more established players with deeper \npockets. Given the steep computing costs, some said big players like Microsoft and Google's parent company, \nAlphabet, had too much of an advantage. Google bought the A.I. lab DeepMind, which is developing a wide range \nof technologies as an Alphabet subsidiary, in 2014 for $650 million.\n  Last week, Salesforce announced a $250 million fund for investing in generative A.I. start-ups, alongside new \ninvestments in Cohere, Anthropic and others.\n  ''There are a few times in technology where you really see a generational leap forward with revolutionary \ntechnology,'' said John Somorjai, who leads Salesforce's venture investments. ''These companies are the next \ntrillion-dollar opportunities in software.''\nA Funding Frenzy Is Enveloping A.I. Start-Ups\n  Sam Lessin, a venture capitalist at Slow Ventures, said he didn't think the tech advances in A.I. translated to \nopportunities for start-ups. The best way to invest in A.I., Mr. Lessin said, is to buy the publicly traded stocks of big \ntech companies.\n  ''The absolute vast majority of the spoils will go to the incumbents,'' he said.\nhttps://www.nytimes.com/2023/03/14/technology/ai-funding-boom.html\nGraphic\n \nPHOTOS: PHOTO (PHOTOGRAPH BY ANTON PETRUS/GETTY IMAGES) (B1)\nMike Volpi, an investor at Index Ventures who sits on the board of the A.I. start-up Cohere. (PHOTOGRAPH BY \nCHRISTOPHER GOODNEY/BLOOMBERG)\n Sam Altman, the chief executive of OpenAI, left, and Kevin Scott, Microsoft's chief technology officer. Interest in \nA.I. start-ups has soared. (PHOTOGRAPH BY RUTH FREMSON/THE NEW YORK TIMES) (B6) This article \nappeared in print on page B1, B6.               \nLoad-Date: March 15, 2023"
    },
    {
        "file_name": "NOW_Jun2023",
        "header": "ARTIFICIAL INTELLIGENCE ISN'T TAKING JOBS OF THE MARKETERS-FOR",
        "media": "NOW",
        "time": "June 25, 2023",
        "section": "B; Pg. 10",
        "length": "28 words",
        "byline": "PATRICK COFFEE",
        "story_text": "ARTIFICIAL INTELLIGENCE ISN'T TAKING JOBS OF THE MARKETERS-FOR \nNOW\nWall Street Journal Abstracts\nJune 24, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 10\nLength: 28 words\nByline: PATRICK COFFEE\nBody\nABSTRACT\nGenerative AI has already been used to create advertising materials and reduce grunt work, but one questions \nhangs over marketers: will their jobs be affected (M)\nLoad-Date: June 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "In A.I., the Race to Block Child Predators",
        "media": "The New York Times",
        "time": "June 25, 2023",
        "section": "Section BU; Column 0; Money and Business/Financial Desk; Pg. 5",
        "length": "2002 words",
        "byline": "By Issie Lapowsky",
        "story_text": "In A.I., the Race to Block Child Predators\nThe New York Times\nJune 25, 2023 Sunday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section BU; Column 0; Money and Business/Financial Desk; Pg. 5\nLength: 2002 words\nByline: By Issie Lapowsky\nBody\nA.I. companies have an edge in blocking the creation and distribution of child sexual abuse material. They've seen \nhow social media companies failed.\nDave Willner has had a front-row seat to the evolution of the worst things on the internet. \n  He started working at Facebook in 2008, back when social media companies were making up their rules as they \nwent along. As the company's head of content policy, it was Mr. Willner who wrote Facebook's first official \ncommunity standards more than a decade ago, turning what he has said was an informal one-page list that mostly \nboiled down to a ban on ''Hitler and naked people'' into what is now a voluminous catalog of slurs, crimes and other \ngrotesqueries that are banned across all of Meta's platforms.\n  So last year, when the San Francisco artificial intelligence lab OpenAI was preparing to launch Dall-E, a tool that \nallows anyone to instantly create an image by describing it in a few words, the company tapped Mr. Willner to be its \nhead of trust and safety. Initially, that meant sifting through all of the images and prompts that Dall-E's filters flagged \nas potential violations -- and figuring out ways to prevent would-be violators from succeeding.\n  It didn't take long in the job before Mr. Willner found himself considering a familiar threat.\n  Just as child predators had for years used Facebook and other major tech platforms to disseminate pictures of \nchild sexual abuse, they were now attempting to use Dall-E to create entirely new ones. ''I am not surprised that it \nwas a thing that people would attempt to do,'' Mr. Willner said. ''But to be very clear, neither were the folks at \nOpenAI.''\n  For all of the recent talk of the hypothetical existential risks of generative A.I., experts say it is this immediate \nthreat -- child predators using new A.I. tools already -- that deserves the industry's undivided attention.\n  In a newly published paper by the Stanford Internet Observatory and Thorn, a nonprofit that fights the spread of \nchild sexual abuse online, researchers found that, since last August, there has been a small but meaningful uptick \nin the amount of photorealistic A.I.-generated child sexual abuse material circulating on the dark web.\n  According to Thorn's researchers, this has manifested for the most part in imagery that uses the likeness of real \nvictims but visualizes them in new poses, being subjected to new and increasingly egregious forms of sexual \nviolence. The majority of these images, the researchers found, have been generated not by Dall-E but by open-\nsource tools that were developed and released with few protections in place.\nIn A.I., the Race to Block Child Predators\n  In their paper, the researchers reported that less than 1 percent of child sexual abuse material found in a sample \nof known predatory communities appeared to be photorealistic A.I.-generated images. But given the breakneck \npace of development of these generative A.I. tools, the researchers predict that number will only grow.\n  ''Within a year, we're going to be reaching very much a problem state in this area,'' said David Thiel, the chief \ntechnologist of the Stanford Internet Observatory, who co-wrote the paper with Thorn's director of data science, Dr. \nRebecca Portnoff, and Thorn's head of research, Melissa Stroebel. ''This is absolutely the worst case scenario for \nmachine learning that I can think of.''\n  Dr. Portnoff has been working on machine learning and child safety for more than a decade.\n  To her, the idea that a company like OpenAI is already thinking about this issue speaks to the fact that this field is \nat least on a faster learning curve than the social media giants were in their earliest days.\n  ''The posture is different today,'' said Dr. Portnoff.\n  Still, she said, ''If I could rewind the clock, it would be a year ago.''\n  'We trust people'\n  In 2003, Congress passed a law banning ''computer-generated child pornography'' -- a rare instance of \ncongressional future-proofing. But at the time, creating such images was both prohibitively expensive and \ntechnically complex.\n  The cost and complexity of creating these images has been steadily declining, but changed last August with the \npublic debut of Stable Diffusion, a free, open-source text-to-image generator developed by Stability AI, a machine \nlearning company based in London.\n  In its earliest iteration, Stable Diffusion placed few limits on the kind of images its model could produce, including \nones containing nudity. ''We trust people, and we trust the community,'' the company's chief executive, Emad \nMostaque, told The New York Times last fall.\n  In a statement, Motez Bishara, the director of communications for Stability AI, said that the company prohibited \nmisuse of its technology for ''illegal or immoral'' purposes, including the creation of child sexual abuse material. ''We \nstrongly support law enforcement efforts against those who misuse our products for illegal or nefarious purposes,'' \nMr. Bishara said.\n  Because the model is open-source, developers can download and modify the code on their own computers and \nuse it to generate, among other things, realistic adult pornography. In their paper, the researchers at Thorn and the \nStanford Internet Observatory found that predators have tweaked those models so that they are capable of creating \nsexually explicit images of children, too. The researchers demonstrate a sanitized version of this in the report, by \nmodifying one A.I.-generated image of a woman until it looks like an image of Audrey Hepburn as a child.\n  Stability AI has since released filters that try to block what the company calls ''unsafe and inappropriate content.'' \nAnd newer versions of the technology were built using data sets that exclude content deemed ''not safe for work.'' \nBut, according to Mr. Thiel, people are still using the older model to produce imagery that the newer one prohibits.\n  Unlike Stable Diffusion, Dall-E is not open-source and is only accessible through OpenAI's own interface. The \nmodel was also developed with many more safeguards in place to prohibit the creation of even legal nude imagery \nof adults. ''The models themselves have a tendency to refuse to have sexual conversations with you,'' Mr. Willner \nsaid. ''We do that mostly out of prudence around some of these darker sexual topics.''\n  The company also implemented guardrails early on to prevent people from using certain words or phrases in their \nDall-E prompts. But Mr. Willner said predators still try to game the system by using what researchers call ''visual \nsynonyms'' -- creative terms to evade guardrails while describing the images they want to produce.\nIn A.I., the Race to Block Child Predators\n  ''If you remove the model's knowledge of what blood looks like, it still knows what water looks like, and it knows \nwhat the color red is,'' Mr. Willner said. ''That problem also exists for sexual content.''\n  'Open questions'\n  Thorn has a tool called Safer, which scans images for child abuse and helps companies report them to the \nNational Center for Missing and Exploited Children, which runs a federally designated clearinghouse of suspected \nchild sexual abuse material. OpenAI uses Safer to scan content that people upload to Dall-E's editing tool. That's \nuseful for catching real images of children, but Mr. Willner said that even the most sophisticated automated tools \ncould struggle to accurately identify A.I.-generated imagery.\n  That is an emerging concern among child safety experts: That A.I. will not just be used to create new images of \nreal children but also to make explicit imagery of children who do not exist.\n  That content is illegal on its own and will need to be reported. But this possibility has also led to concerns that the \nfederal clearinghouse may become further inundated with fake imagery that would complicate efforts to identify real \nvictims. Last year alone, the center's CyberTipline received roughly 32 million reports.\n  ''If we start receiving reports, will we be able to know? Will they be tagged or be able to be differentiated from \nimages of real children?'' said Yiota Souras, the general counsel of the National Center for Missing and Exploited \nChildren.\n  At least some of those answers will need to come not just from A.I. companies, like OpenAI and Stability AI, but \nfrom companies that run messaging apps or social media platforms, like Meta, which is the top reporter to the \nCyberTipline.\n  Last year, more than 27 million tips came from Facebook, WhatsApp and Instagram alone. Already, tech \ncompanies use a classification system, developed by an industry alliance called the Tech Coalition, to categorize \nsuspected child sexual abuse material by the victim's apparent age and the nature of the acts depicted. In their \npaper, the Thorn and Stanford researchers argue that these classifications should be broadened to also reflect \nwhether an image was computer-generated.\n  In a statement to The New York Times, Meta's global head of safety, Antigone Davis, said, ''We're working to be \npurposeful and evidence-based in our approach to A.I.-generated content, like understanding when the inclusion of \nidentifying information would be most beneficial and how that information should be conveyed.'' Ms. Davis said the \ncompany would be working with the National Center for Missing and Exploited Children to determine the best way \nforward.\n  Beyond the responsibilities of platforms, researchers argue that there is more that A.I. companies themselves can \nbe doing. Specifically, they could train their models to not create images of child nudity and to clearly identify \nimages as generated by artificial intelligence as they make their way around the internet. This would mean baking a \nwatermark into those images that is more difficult to remove than the ones either Stability AI or OpenAI have \nalready implemented.\n  As lawmakers look to regulate A.I., experts view mandating some form of watermarking or provenance tracing as \nkey to fighting not only child sexual abuse material but also misinformation.\n  ''You're only as good as the lowest common denominator here, which is why you want a regulatory regime,'' said \nHany Farid, a professor of digital forensics at the University of California, Berkeley.\n  Professor Farid is responsible for developing PhotoDNA, a tool launched in 2009 by Microsoft, which many tech \ncompanies now use to automatically find and block known child sexual abuse imagery. Mr. Farid said tech giants \nwere too slow to implement that technology after it was developed, enabling the scourge of child sexual abuse \nmaterial to openly fester for years. He is currently working with a number of tech companies to create a new \nIn A.I., the Race to Block Child Predators\ntechnical standard for tracing A.I.-generated imagery. Stability AI is among the companies planning to implement \nthis standard.\n  Another open question is how the court system will treat cases brought against creators of A.I.-generated child \nsexual abuse material -- and what liability A.I. companies will have. Though the law against ''computer-generated \nchild pornography'' has been on the books for two decades, it's never been tested in court. An earlier law that tried \nto ban what was then referred to as virtual child pornography was struck down by the Supreme Court in 2002 for \ninfringing on speech.\n  Members of the European Commission, the White House and the U.S. Senate Judiciary Committee have been \nbriefed on Stanford and Thorn's findings. It is critical, Mr. Thiel said, that companies and lawmakers find answers to \nthese questions before the technology advances even further to include things like full motion video. ''We've got to \nget it before then,'' Mr. Thiel said.\n  Julie Cordua, the chief executive of Thorn, said the researchers' findings should be seen as a warning -- and an \nopportunity. Unlike the social media giants who woke up to the ways their platforms were enabling child predators \nyears too late, Ms. Cordua argues, there's still time to prevent the problem of AI-generated child abuse from \nspiraling out of control.\n  ''We know what these companies should be doing,'' Ms. Cordua said. ''We just need to do it.''\nhttps://www.nytimes.com/2023/06/24/business/ai-generated-explicit-images.html\nGraphic\n \nPHOTOS: Top, Rebecca Portnoff, the data science director at Thorn, a nonprofit that fights the spread of child \nsexual abuse online. Above, Julie Cordua, the chief executive of Thorn. Above right, Sam Altman, the chief \nexecutive of OpenAI, testified in May before a Senate Judiciary subcommittee on ''Oversight of A.I.: Rules for \nArtificial Intelligence.'' (PHOTOGRAPHS BY KRISTIAN THACKER FOR THE NEW YORK TIMES\nSTEPHEN GOLDSTEIN FOR THE NEW YORK TIMES\n ELIZABETH FRANTZ/REUTERS) This article appeared in print on page BU5.               \nLoad-Date: June 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Google’s C.E.O. Takes Another Turn on the Antitrust Witness Stand",
        "media": "The New York Times",
        "time": "November 15, 2023",
        "section": "TECHNOLOGY",
        "length": "1495 words",
        "byline": "Nico Grant",
        "story_text": "Google’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nThe New York Times \nNovember 14, 2023 Tuesday 13:27 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1495 words\nByline: Nico Grant\nHighlight: Sundar Pichai, Google’s chief executive, testified on Tuesday for the second time in two weeks to \ndefend his company against monopoly claims.\nBody\nSundar Pichai, Google’s chief executive, testified on Tuesday for the second time in two weeks to defend his \ncompany against monopoly claims.\nTwo weeks ago, Google had a big day in Washington. President Biden signed an executive order to create artificial \nintelligence safeguards that could affect Google’s most pressing projects, and Secretary of State Antony J. Blinken \ngave the company an award for its work in aiding Ukrainian refugees and promoting women’s economic security.\nSundar Pichai, Google’s chief executive, had spent much of the day on a witness stand at a federal courthouse \nabout two miles from the White House, defending his company from claims that it crushed rivals in the search and \nonline advertising markets.\nOn Tuesday, Mr. Pichai testified again, this time in San Francisco, to confront claims brought by the video game \ncompany Epic Games that his company broke the law, wielding monopolistic power over app developers on \nAndroid’s Google Play Store.\nMr. Pichai over the last month has become the face of Google’s antitrust court fights on both sides of the country. \nAnd his visits to the witness stand underscore the growing importance for Big Tech leaders to be sharp witnesses \nfor their companies, whether in an antitrust trial or in hearings on Capitol Hill.\nTestifying under oath is a task that many tech chief executives might be asked to do in the coming years, with \nAmazon, Meta and others facing their own antitrust court fights. It is not a task at which many executives have \nexcelled.\nThough he was never called to the witness stand to testify, Bill Gates, who was chief executive of Microsoft in the \nlast big technology antitrust case brought by the Justice Department more than two decades ago, came across as \ncombative and evasive in depositions.\nOver the last few years, executives including Mark Zuckerberg and OpenAI’s Sam Altman (and, of course, Mr. \nPichai) have been asked to testify before Congress for various reasons, with varying degrees of success. Mr. \nZuckerberg has at times exasperated lawmakers with vague responses, while Mr. Altman appeared to charm \nsenators in a hearing this year.\nThe main duty on the witness stand for Mr. Pichai — a low-key and detail-focused executive — has been to keep \nthe temperature low under questioning and keep to the central point of Google’s antitrust defense: that it is an \ninnovative company that has maintained its leadership through innovation and hard work instead of illegal \nmonopolistic behavior.\nGoogle ’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nOn Tuesday, Mr. Pichai ran into aggressive questioning by a lawyer for Epic, Lauren Moskowitz, who asked him to \nprovide yes-or-no responses.\nThat led to at least one small revelation: Mr. Pichai confirmed that his company gave Apple 36 percent of the \nsearch revenue generated on iPhones, and said the total payment “was well over $10 billion” last year. Ms. \nMoskowitz asserted that the figure was at least $18 billion.\nLawyers for Google and Apple fought on Tuesday morning to keep the figures concealed, emphasizing a need for \ncorporate privacy that has carried through both of Google’s trials. Judge James Donato rejected their requests, \nsaying, “Just coming in and saying we’re kind of sensitive with this isn’t going to fly.”\nMs. Moskowitz was trying to counter Google’s claim that it cannot be considered a monopoly because of its rivalry \nwith Apple. If that were the case, she argued, why did it give Apple preferential treatment over other companies like \nSamsung, which she said received a 16 percent share of the search revenue from its devices?\n“We compete fiercely with Apple, at the operating system, the smartphone and the app store level,” Mr. Pichai said \nlater, when questioned by a Google lawyer. “The competition has been good for consumers and developers.”\nThe Justice Department filed its landmark antitrust suit against Google in October 2020, arguing that the company’s \ndefault-search deals with phone makers and browser companies helped it illegally maintain a monopoly.\nGoogle called Mr. Pichai, 51, to the stand two weeks ago. Rather than sit in the witness box, Mr. Pichai stood at a \nlectern for almost four hours, wearing a microphone, as though he were delivering a speech at a corporate \nconference. His handlers said he had to stand because of a sprained lower back.\nHe spoke of his background, getting a telephone as a preteen in Chennai, India, and understanding then the power \nof technology, before he deftly answered questions about his company’s competitive standing, relationship with \nApple and the default-search contracts the government argues were illegal.\nMr. Pichai tried to refute the government lawyer’s arguments that Google paid Apple billions of dollars a year to \nkeep it out of the search market. He presented a different story, saying his company wanted to be the iPhone’s \ndefault search engine because of the “value” of that spot, and the need to ensure Apple would safeguard the user \nexperience.\n“I felt the deal had done well since 2016,” Mr. Pichai said. “It was continuing to increase search usage, search \nrevenue.”\nIn cross-examination, Mr. Pichai repeated the rationale for the deal so many times that for a moment, he seemed to \nlose patience with the line of questioning, saying, “I just gave all the reasons” for the deal.\nAdam Kovacevich, a tech industry lobbyist at the Chamber of Progress who spent 12 years working at Google, said \nMr. Pichai’s testimony gave the court a high-level view of how the company made strategic decisions.\n“He did fine,” Mr. Kovacevich said of Mr. Pichai’s performance. “The biggest thing to me is when you’re in that \nposition, your first objective is to not be Bill Gates in the Microsoft trial. Your No. 1 objective is to come off as \nresponsive and reasonable.”\nExcerpts from Mr. Gates’s combative, videotaped testimony were shown in court more than two decades ago. The \nMicrosoft co-founder, antitrust lawyers say, undermined his and his company’s credibility with the judge in the case.\nIn San Francisco, Mr. Pichai was questioned on topics ranging from why he erroneously marked emails as subject \nto attorney-client privilege (to prevent them from being forwarded) to whether Facebook and Amazon could have \nprovided competition to Google’s Play Store when they had smartphone ambitions.\n“There are nuances in these questions,” he said with a smile when Ms. Moskowitz started to speak over him. “I’m \ntrying to answer your question.”\nGoogle ’s C.E.O. Takes Another Turn on the Antitrust Witness Stand\nSeveral times, Judge Donato asked Ms. Moskowitz to “be quiet” to let Mr. Pichai speak.\nThere will be one big difference between the lawsuits: The antitrust trial in Washington does not have a jury. The \ndecision will be made by a judge. In San Francisco, Mr. Pichai had to appeal to a nine-person jury that could be \nopen to the idea that a giant tech company is exploiting much smaller outfits. Tim Sweeney, Epic’s chief executive, \nis also expected to testify in the trial.\nGoogle and Epic declined to comment.\nEpic, the maker of the hit game Fortnite, brought the claim against Google in 2020, in an attempt to sidestep the 15 \nto 30 percent fees from subscriptions and in-app purchases that it must pay Google.\nThe game developer antagonized Google and Apple by telling users to pay for in-app transactions directly through \nEpic. In response, Google and Apple suspended Fortnite from their app stores. Epic claims Google also bullied \nother companies to force them to drop deals with Epic before it was banned from the app stores.\nGoogle faces another Justice Department antitrust lawsuit that accuses it of illegally abusing its monopoly power \nover the technology that delivers ads online.\nA trial in that case could begin as soon as next year, but it is too early to know whether Mr. Pichai will be called to \ntestify.\nMr. Pichai has tried to prevent Google employees from being distracted by the litigation. He has encouraged them \nto “keep doing what you’re doing” and has allocated a relatively small number of employees to work on the Justice \nDepartment case — hundreds out of more than 180,000.\nBut Mr. Pichai’s court appearances have taken time away from his other obligations as a company leader, including \nhis plan to reclaim Google’s primacy in the fast-growing field of generative A.I.\nIn the middle of Mr. Pichai’s October testimony, the secretary of state, Mr. Blinken, was honoring Google’s \nsubsidiary in Poland for its work in fostering women’s economic security and helping Ukrainian refugees. Hours \nlater, Mr. Biden hosted a signing ceremony at the White House, but Mr. Pichai’s handlers could not R.S.V.P. yes \nbecause there was a chance he might have still been in court when it began.\n“It’s not the best use of his time,” Richard Kramer, an analyst at Arete Research, a London-based investment \nresearch firm, said in an interview. “No C.E.O. wishes to spend their time being grilled by government lawyers.”\nPHOTO: Sundar Pichai, Google’s chief, testified in San Francisco on Tuesday. (PHOTOGRAPH BY JIM \nWILSON/THE NEW YORK TIMES) (B4) This article appeared in print on page B1, B4.\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "Pittsburgh_Post-Gazette_Mar2024",
        "header": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS",
        "media": "Pittsburgh Post-Gazette",
        "time": "March 26, 2024",
        "section": "ASECTION; Pg. A-1",
        "length": "1363 words",
        "byline": "Kris B. Mamula Pittsburgh Post-Gazette",
        "story_text": "AI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\nPittsburgh Post-Gazette\nMarch 26, 2024 Tuesday\nSOONER EDITION\nCopyright 2024 P.G. Publishing Co.\nSection: ASECTION; Pg. A-1\nLength: 1363 words\nByline: Kris B. Mamula Pittsburgh Post-Gazette\nBody\nArtificial intelligence is making its way into medical offices throughout Pennsylvania, including those in Pittsburgh, \nwith the tantalizing promise of fewer administrative headaches for doctors and better care for patients.\nThe transition could be bumpy: Among obstacles to widespread adoption of tech that instantly taps vast stores of \ninformation will be doctors' resistance to change how they've practiced medicine, experts say. For patients, the \nselling point could be more eye contact and better communication during office visits, if doctors aren't tied up with a \ncomputer screen, typing notes into a medical record.\nBut that's just the start.\nGoogle, Microsoft and Nvidia are among the tech giants plowing money into medicine. For the 12 months ending \nJuly 30, 2023, the Food and Drug Administration approved 171 AI or machine learning devices for use in medicine, \na number that was expected to increase 30% for the year compared to 2022.\nNearly 700 AI-like devices have been approved by the FDA since 1995.\nUp for grabs is a market expected to reach $51.3 billion by 2030 from just $2.9 billion in 2022, according to India-\nbased market research firm Insights 10.\nIn the coming weeks, artificial intelligence will be introduced at the 14-hospital Allegheny Health Network - first with \nthe goal of chipping away at the administrative workload of doctors, nurses and others, and later to take on some \nfar less mundane tasks including monitoring high-risk patients.\nAHN rival UPMC has also been adding AI tools in the clinician's office, with the same early goal of freeing doctors \nfrom medical record documentation through what's called \"ambient listening.\"\nWith patients' permission, AI software will \"listen\" to the physician-patient conversation in the office, then organize \nthe notes into the written medical record. The doctor's role will be reduced to simply editing the software's notes for \nfinal entry.\nAnd other, more ambitious, ways to tap the capabilities of artificial intelligence will find their way into the local health \ncare workforce soon.\nAHN's 22,000 employees will soon get access to Google's Vertex AI Search and Sidekick software that can, for \ninstance, draft letters to health insurers on behalf of patients who need specialty medications, medical equipment or \nother care that's not standard in their insurance benefits. The program will be \"trained\" on internal Highmark Health \ndata rather than publicly available information sources, like ChatGPT and similar tools.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"It's paradoxical, but AI is going to humanize health care,\" said Ashis Barad, a pediatrician and AHN chief digital \nand information officer. \"It will not replace anybody.\"\nFord, Seagate, Wayfair and Lowe's are among other corporate users of Vertex AI, a cloud-based platform Google \ndeveloped in 2021, according to San Francisco online newspaper TechCrunch. Mayo Clinic and HCA Healthcare, \nwhich operates more than 2,000 hospitals in the U.S. and Britain, are also Google AI customers.\nHighmark and UPMC have long been rivals, so it isn't surprising the two Pittsburgh health care giants have chosen \ndifferent paths to the world of artificial intelligence.\nUPMC has partnered with Google rival Microsoft, subsidiary Nuance Communications and Pittsburgh startup \nAbridge AI Inc. to allow doctors and other care providers to use Nuance's DAX Copilot ambient listening software to \norganize and write patient exam narratives for medical records.\nPrivately held Abridge was founded in 2018 and automates clinical notes. The startup has offices in Lawrenceville \nand elsewhere.\nMicrosoft acquired Nuance for $19.7 billion in 2021. Microsoft is also a major investor in OpenAI, the for-profit arm \nof the San Francisco company founded in 2021 that created all the buzz a year later around generative AI models \nlike ChatGPT.\n\"Operational efficiency has the potential of being greatly aided by AI,\" said Robert Bart, a UPMC pediatric intensivist \nand system chief medical information officer. \"It can listen, then create the document for the workflow, creating a \nmuch more natural, caring interaction to occur between the doctor and patient.\"\nFiguring out what AI can do\nThroughout the U.S., the industry is going big for artificial intelligence, with academic medical centers tapping AI's \nvast reserves of information to do things like better identify pre-diabetes, perform retinal exams for early signs of \ndisease and detect an array of cancers as well or better than humans.\nEventually, doctors at both AHN and UPMC envision a far bigger role for AI than the initial documentation tasks, \nwith some of the possibilities growing out of evolving partnerships between Epic Systems and AI vendors. Both \nhealth systems use the Verona, Wis., company's services to store patient medical records.\nTasks that artificial intelligence tools could pick up include writing patient progress notes, responding to emailed \nquestions from patients and suggesting medical coding, which is the basis of billing.\nDr. Bart envisions the day when such a tool might note a change in the seriousness of a medical problem based on \nthe doctor's conversation with the patient, alert the physician that a certain prescription drug is not covered by the \npatient's health insurance or even suggest a diagnosis.\n\"AI is not going to replace who I am as a physician, but I believe physicians who adopt AI will be better prepared to \ndeliver high-quality care into their practice,\" Dr. Bart said.\nSeparately, AHN is preparing to introduce a smart patient room and a digital nursing program at its Forbes Hospital \nin the coming weeks.\nA 47-bed unit of the Monroeville hospital is being equipped with monitors that will allow a seasoned nurse at a North \nShore office - or even at home - to brief new patients in a live chat on what to expect during their stay and also \nprovide discharge instructions before they go home.\nPermission from the patient will be required. A doorbell chime will mark the start of the session.\nAdmissions' briefings typically take 45 minutes and discharge instructions last 20-30 minutes, Forbes Hospital Chief \nNursing Officer Lynn Kosar said. That's time that floor nurses could be spending instead with patients, she said.\nAI COMES TO THE DOCTOR'S OFFICE, PA. HOSPITALS\n\"These things really help our nursing staff focus more on patients, getting them their meds, making sure patients \nare getting the best care we can,\" Ms. Kosar said. \"Nurses see the value in it. They're really excited.\"\nAHN nurses spend two hours of every typical 12-hour shift recording test results and other information in patient \nmedical records, according to an internal study, Dr. Barad said. Only 45% of their time is spent on direct patient \ncare, compromising the reason many nurses choose the vocation.\nPartnering with Orlando, Fla.-based care.ai, a company specializing in virtual medical care systems, AHN is \npreparing for the day when AI will monitor hospital patients with dementia or who risk falling because of dizziness or \nother issues. Today, these patients may require someone to be in the room with them at all times, but AHN \nanticipates high-risk patients could eventually be monitored remotely by AI and sensors on their bed.\nStarting at Forbes, smart patient rooms are slated to be rolled out throughout AHN's hospital system.\nChange is hard\nA 2023 survey by the American Medical Association found that 65% of more than 1,000 doctors surveyed saw \nadvantages to what the medical organization called \"augmented intelligence.\" But doctors also worried about data \nprivacy issues and legal liability for AI-generated medical errors.\nFor some doctors, change is just hard, AHN's Dr. Barad said, especially older physicians who've been practicing for \nyears. It's his job to make the case for embracing AI to the health system's medical staff.\nDr. Barad was reminded of a 2014 study at the University of Bristol that found most ants instinctively turn left when \nentering unfamiliar places.\nPart of the reason may be in seeking strength in numbers since other ants exhibit similar behavior, an analogy that \ncan be extended to seasoned doctors, he said.\n\"It's easier to go through the inefficiencies they know,\" Dr. Barad said. \"I'm the left-turn guy. My job is empathy.\"\nKris B. Mamula: kmamula@post-gazette.com\nGraphic\n \nPHOTO: care.ai: Orlando, Fla.-based care.ai is partnering with Allegheny Health Network in installing cameras and \nscreens in patient rooms to allow remote nurses to talk with patients. The video link is expected to allow floor \nnurses to spend more time with patients.\nLoad-Date: March 26, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly",
        "media": "The New York Times",
        "time": "March 22, 2024",
        "section": "TECHNOLOGY",
        "length": "1761 words",
        "byline": "David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in",
        "story_text": "U.S. Sues Apple, Accusing It of Maintaining an iPhone Monopoly\nThe New York Times \nMarch 21, 2024 Thursday 08:18 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1761 words\nByline: David McCabe and Tripp Mickle David McCabe covers tech policy. He joined The Times from Axios in \n2019. Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San Francisco. His focus on \nApple includes product launches, manufacturing issues and political challenges. He also writes about trends across \nthe tech industry, including layoffs, generative A.I. and robot taxis.\nHighlight: The lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, \nwhich have fueled its growth into a nearly $3 trillion public company.\nBody\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $3 trillion public company.\nThe federal government’s aggressive crackdown on Big Tech expanded on Thursday to include an antitrust lawsuit \nby the Justice Department against Apple, one of the world’s best-known and most valuable companies.\nThe department joined 16 states and the District of Columbia to file a significant challenge to the reach and \ninfluence of Apple, arguing in an 88-page lawsuit that the company had violated antitrust laws with practices that \nwere intended to keep customers reliant on their iPhones and less likely to switch to a competing device. The tech \ngiant prevented other companies from offering applications that compete with Apple products like its digital wallet, \nwhich could diminish the value of the iPhone, and hurts consumers and smaller companies that compete with it, the \ngovernment said.\nThe Justice Department’s lawsuit is seeking to put an end to those practices. The government even has the right to \nask for a breakup of the Silicon Valley icon.\nThe lawsuit caps years of regulatory scrutiny of Apple’s wildly popular suite of devices and services, which have \nfueled its growth into a nearly $2.75 trillion public company that was for years the most valuable on the planet. It \ntakes direct aim at the iPhone, Apple’s most popular device and most powerful business, and attacks the way the \ncompany has turned the billions of smartphones it has sold since 2007 into the centerpiece of its empire.\nBy tightly controlling the user experience on iPhones and other devices, Apple has created what critics call an \nuneven playing field, where it grants its own products and services access to core features that it denies rivals. \nOver the years, it has limited finance companies’ access to the phone’s payment chip and Bluetooth trackers from \ntapping into its location-service feature. It’s also easier for users to connect Apple products, like smartwatches and \nlaptops, to the iPhone than to those made by other manufacturers.\n“Each step in Apple’s course of conduct built and reinforced the moat around its smartphone monopoly,” the \ngovernment said in the lawsuit, which was filed in the U.S. District Court for the District of New Jersey. It added that \nthe company’s practices resulted in “higher prices and less innovation.”\nApple says these practices make its iPhones more secure than other smartphones. But app developers and rival \ndevice makers say Apple uses its power to crush competition.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\n“This lawsuit threatens who we are and the principles that set Apple products apart in fiercely competitive markets,” \nan Apple spokeswoman said. “If successful, it would hinder our ability to create the kind of technology people \nexpect from Apple — where hardware, software, and services intersect. It would also set a dangerous precedent, \nempowering government to take a heavy hand in designing people’s technology.”\nApple is the latest company the federal government has tried to rein in under a wave of antitrust pressure in recent \nyears from both the Justice Department and the Federal Trade Commission, to which the Biden administration has \nappointed heads sharply focused on changing the laws to fit the modern era. Google, Meta and Amazon are all \nfacing similar suits, and companies from Kroger to JetBlue Airways have faced greater scrutiny of potential \nacquisitions and expansion.\nThe lawsuit asks the court to stop Apple from engaging in current practices, including blocking cloud-streaming \napps, undermining messaging across smartphone operating systems and preventing the creation of digital wallet \nalternatives.\nThe Justice Department has the right under the law to ask for structural changes to Apple’s business — including a \nbreakup, said an agency official, who spoke on condition of anonymity. The official declined to identify what \nadditional action the agency could request in this case but any demands would be tied to how a court rules on the \nquestion of whether — and how — Apple broke the law.\nIt’s unclear what implications the suit — which is likely to drag out years before any type of resolution — would have \nfor consumers. Apple plans to file a motion to dismiss the case in the next 60 days. In its filing, the company plans \nto emphasize that competition laws permit it to adopt policies or designs that its competitors oppose, particularly \nwhen those designs would make using an iPhone a better experience.\nApple has effectively fought off other antitrust challenges. In a lawsuit over its App Store policies that Epic Games, \nthe maker of Fortnite, brought in 2020, Apple persuaded the judge that customers could easily switch between its \niPhone operating system and Google’s Android system. It has presented data showing that the reason few \ncustomers change phones is their loyalty to the iPhone.\nIt also has defended its business practices in the past by highlighting how the App Store, which it opened in 2008, \ncreated millions of new businesses. Over the past decade, the number of paid app makers has increased by 374 \npercent to 5.2 million, which Apple has said is a testament to a flourishing marketplace.\nEvery modern-day tech giant has faced a major federal antitrust challenge. The Justice Department is also pursuing \na case against Google’s search business and another focused on Google’s hold over advertising technology. The \nFederal Trade Commission filed a lawsuit accusing Meta, which owns Facebook, of thwarting competition when it \nbought Instagram and WhatsApp and another accusing Amazon of abusing its power over online retail. The F.T.C. \nalso tried unsuccessfully to block Microsoft from acquiring Activision Blizzard, the video game publisher.\nThe lawsuits reflect a push by the regulators to apply greater scrutiny to the companies’ roles as gatekeepers to \ncommerce and communications. In 2019, under President Donald J. Trump, the agencies opened antitrust inquiries \ninto Google, Meta, Amazon and Apple. The Biden administration has put even more energy behind the effort, \nappointing critics of the tech giants to lead both the F.T.C. and the antitrust division of the Department of Justice.\nIn Europe, regulators recently punished Apple for preventing music streaming competitors from communicating with \nusers about promotions and options to upgrade their subscriptions, levying a 1.8 billion-euro fine. App makers have \nalso appealed to the European Commission, the European Union’s executive arm, to investigate claims that Apple \nis violating a new law requiring it to open iPhones to third-party app stores.\nIn South Korea and the Netherlands, the company is facing potential fines over the fees it charges app developers \nto use alternative payment processors. Other countries, including Britain, Australia and Japan, are considering rules \nthat would undercut Apple’s grip on the app economy.\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly\nThe Justice Department, which began its investigation into Apple in 2019, chose to build a broader and more \nambitious case than any other regulator has brought against the company. Rather than narrowly focus on the App \nStore, as European regulators have, it focused on Apple’s entire ecosystem of products and services.\nThe lawsuit filed Thursday focuses on a group of practices that the government said Apple had used to shore up its \ndominance.\nThe company “undermines” the ability of iPhone users to message with owners of other types of smartphones, like \nthose running the Android operating system, the government said. That divide — epitomized by the green bubbles \nthat show an Android owner’s messages — sent a signal that other smartphones were lower quality than the \niPhone, according to the lawsuit.\nApple has similarly made it difficult for the iPhone to work with smartwatches other than its own Apple Watch, the \ngovernment argued. Once an iPhone user owns an Apple Watch, it becomes far more costly for them to ditch the \nphone.\nThe government also said Apple had tried to maintain its monopoly by not allowing other companies to build their \nown digital wallets. Apple Wallet is the only app on the iPhone that can use the chip, known as the NFC, that allows \na phone to tap-to-pay at checkout. Though Apple encourages banks and credit card companies to allow their \nproducts to work inside Apple Wallet, it blocks them from getting access to the chip and creating their own wallets \nas alternatives for customers.\nThe government said that Apple refuses to allow game streaming apps that could make the iPhone a less valuable \npiece of hardware or offer “super apps” that let users perform a variety of activities from one application.\nThe government’s complaint uses similar arguments to the claims it made against Microsoft decades ago, in a \nseminal lawsuit that argued the company was tying its web browser to the Windows operating system, said Colin \nKass, an antitrust lawyer at Proskauer Rose. He added that the most compelling allegation — and the one that \nbrings it closest to the Microsoft case — is that Apple could be contractually preventing rivals from developing apps \nthat work with other app providers, as “super apps” could.\nOther legal experts noted that companies are legally allowed to favor their own products and services, so the \ngovernment will have to explain why that is a problem with Apple.\n“This case is about technology,” Mr. Kass said. “Can the antitrust laws force a company to redesign its product to \nmake it more compatible with competitors’ products?”\nApple has defended itself against other antitrust challenges by arguing that its policies are critical to make its \ndevices private and secure. In its defense against Epic Games, it argued that restraining the distribution of apps \nallowed it to protect the iPhone from malware and fraud. The practice benefited customers and made the iPhone \nmore attractive than competing devices with Android’s operating system.\nThe government will try to show that the effect of Apple’s policies was to hurt consumers, not help them.\n“Competition makes devices more private and more secure,” said Jonathan Kanter, assistant attorney general of \nthe Justice Department’s antitrust division. “In many instances, Apple’s conduct has made its ecosystem less \nprivate and less secure.”\nPHOTO: Tim Cook, Apple’s chief executive. Wildly popular devices and services have turned Apple into a nearly \n$2.75 trillion public company, and it tightly controls the user experience on iPhones and other products. \n(PHOTOGRAPH BY JIM WILSON/THE NEW YORK TIMES) (A20) This article appeared in print on page A1, A20.\nLoad-Date: March 22, 2024\nU.S. Sues Apple , Accusing It of Maintaining an iPhone Monopoly"
    },
    {
        "file_name": "New_York_Observer_Apr2023",
        "header": "Google CEO Sundar Pichai Clarifies ChatGPT 'Code Red' Rumor, Bard Flop",
        "media": "New York Observer",
        "time": "April 5, 2023",
        "section": "",
        "length": "450 words",
        "byline": "Sissi Cao",
        "story_text": "Google CEO Sundar Pichai Clarifies ChatGPT 'Code Red' Rumor, Bard Flop\nNew York Observer\nApril 3, 2023 Monday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 450 words\nByline: Sissi Cao\nBody\nGoogle CEO Sundar Pichai said he never actually declared a \"code red\" within the company to develop a \ncompeting product of OpenAI's ChatGPT, as widely reported by news organizations in December, a few weeks \nbefore Google announced Bard, its artificial intelligence chatbot.\n\"I'm laughing, because first of all, I did not issue a code red,\" Pichai said during an episode of the New York Times' \npodcast Hard Fork on March 31 when asked by host Casey Newton how a CEO's \"code red\" changes life inside \nGoogle.\n\"I am definitely asking teams to move with urgency,\" Pichai said. \"I'm asking, in a deep way, engaging with the \nteams to understand how we are going to use LLMs (large language models) or generative AI to translate into \ndeep, meaningful experiences... There are people who have probably sent emails saying there is a code red.\"\nIn the wide-ranging interview, Pichai also discussed the mixed public reactions to Bard since its launch and why he \nintentionally put an imperfect product out in the market despite high expectations on Google's answer to ChatGPT.\nGoogle unveiled Bard on Feb. 6 and it almost immediately became a flop after making a simple mistake during a \nproduct demo. User reactions to Bard so far have been largely muted, with some people saying it's not as good as \nChatGPT or Microsoft's GPT-enhanced Bing.\nPichai said the initial version of Bard was powered by a lightweight version of LaMDA, a GPT-like language model \nGoogle had worked on for several years. Because of the scaled-back model, \"in some ways I feel like we took a \nsouped-up Civic, kind of put it in a race with more powerful cars,\" Pichai said.\n\"But we are going to be training fast,\" he added. \"We clearly have more capable models. Pretty soon, we will be \nupgrading Bard to some of our more capable PaLM models, which will bring more capabilities, be it in reasoning, \ncoding. It can answer math questions better.\"\nAs the popularity of generative A.I. tools like ChatGPT surges, there is a growing concern among tech leaders A.I. \ncould outsmart humans before we have a chance to control it. Last week, more than 1,000 academics and tech \nentrepreneurs, including Elon Musk, signed an open letter urging A.I. companies to pause training advanced \nlanguage models for six months and draft a set of shared safety protocols.\nSafety is one of the reasons Google wants to improve Bard gradually, Pichai said.\n\"We knew when we were putting Bard out we wanted to be careful. It's the beginning of a journey for us,\" he said. \n\"To me, it was important to not put a more capable model before we can fully make sure we can handle it well. A.I. \nis the most profound technology humanity will ever work on. I've always felt that for a while.\"\nLoad-Date: April 5, 2023\nGoogle CEO Sundar Pichai Clarifies ChatGPT 'Code Red' Rumor, Bard Flop"
    },
    {
        "file_name": "USA_Today_Online_Oct2023",
        "header": "Fugees rapper claims lawyer's use of AI wrecked his case, requests new trial",
        "media": "USA Today Online",
        "time": "October 19, 2023",
        "section": "ENTERTAINMENT: LATEST & ENTERTAINMENT: CELEBRITY GOSSIP",
        "length": "951 words",
        "byline": "Lindsay Whitehurst",
        "story_text": "Fugees rapper claims lawyer's use of AI wrecked his case, requests new trial\nUSA Today Online\nOctober 19, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: ENTERTAINMENT: LATEST & ENTERTAINMENT: CELEBRITY GOSSIP\nLength: 951 words\nByline: Lindsay Whitehurst\nBody\nWASHINGTON (AP) — A multimillion-dollar conspiracy trial that stretched across the worlds of politics and \nentertainment is now touching on the tech world with arguments that a defense attorney for a Fugees rapper \nbungled closing arguments by using an artificial intelligence program.\nPrakazrel \"Pras\" Michel, 51, argued that the use of the \"experimental\" generative AI program was one of a number \nof errors made by his \"unqualified, unprepared and ineffectual\" trial attorney before his conviction earlier this year, \naccording to a motion for new trial his new lawyers filed this week. The company behind the program, on the other \nhand, said it was a tool used to help write closing statements, and a harbinger of major changes in the field.\nLink to Image\nGenerative AI programs are capable of creating realistic text, images and video. They're raising tough questions \nabout misinformation and copyright protections as well as industry calls for regulations in Congress. Programs like \nChatGPT have already had ripple effects across professions like writing and education. The arguments in the \nMichel case could preview issues to come as the technology makes a rapid advance.\nThe Grammy-winning rapper's trial was touted as the first time generative AI was used in a federal trial in a news \nrelease from the startup company that designed the system. Defense attorney David Kenner, well known for his \nprevious representation of rappers like Suge Knight and Snoop Dogg, also gave a quote calling the system a \"game \nchanger for complex litigation.\"\nBut in his last words to the jury, Kenner appeared to mix up key elements of the case and misattributed the lyric \n\"Every single day, every time I pray, I will be missing you,\" to the Fugees, the 1990s hip-hop group his client co-\nfounded, when actually it is a well-known line from a song by the rapper Diddy, then known as Puff Daddy, court \ndocuments from Michel's new attorney, Peter Zeidenberg, stated.\nKenner did not respond to a phone call and email seeking comment from The Associated Press. The company, \nEyeLevel.AI, said the program wasn't \"experimental\" but instead trained using only facts from the case, including \ncourt transcripts, not musical lyrics or anything found online. It's intended to provide fast answers to complex \nquestions to help, not replace, human lawyers, said co-founder and COO Neil Katz.\n\"We think AI technology is gong to completely revolutionize the legal field by making it faster and cheaper to get \ncomplex answers to legal questions and research,\" Katz said.\nHe denied an allegation from Michel's new lawyers that Kenner appeared to have a financial interest in the \nprogram.\nFugees rapper claims lawyer's use of AI wrecked his case, requests new trial\nThe case will likely be closely watched as more law firms adopt the technology, said Sharon Nelson, president of \nSensei Enterprises, a digital forensics, cybersecurity and information technology firm. A substantial number of firms \nare using it now, and surveys indicate more than 50% of lawyers expect to within the next year, she said. \"It's gone \nmuch faster than we thought,\" she said. \"The problem is, if you don't work with it, you're going to be left behind.\"\nRapper Pras convicted of conspiracy, awaits sentencing\nMichel was found guilty in April on all 10 counts he was charged with, including conspiracy and acting as an \nunregistered agent of a foreign government. He faces up to 20 years in prison on the top counts. He is free ahead \nof sentencing, which has not yet been set.\n\"At bottom, the AI program failed Kenner, and Kenner failed Michel. The closing argument was deficient, unhelpful, \nand a missed opportunity that prejudiced the defense,\" wrote Zeidenberg. His other arguments for a new trial \nincluded the jury being prejudiced by being allowed to hear references to the \"crime fraud exception\" and \"co-\nconspirators.\"\nMichel was accused of funneling money from a now-fugitive Malaysian financer through straw donors to Barack \nObama's 2012 reelection campaign, then trying to squelch a Justice Department investigation and influence an \nextradition case on behalf of China under the Trump administration. His trial included testimony ranging from actor \nLeonardo DiCaprio to former U.S. Attorney General Jeff Sessions.\nLeonardo DiCaprio  takes the stand in Fugees rapper 'Pras' Michel's money-laundering case\nKenner had argued during the trial the Grammy-winning rapper simply wanted to make money and got bad legal \nadvice as he reinvented himself in the world of politics.\nIt wasn't immediately clear when a judge might rule on the motion for a new trial.\nUse of generative AI in the legal profession is in the early stages, but it could see much more widespread adoption \nas products improve, said John Villasenor, a professor of engineering and public policy at the University of \nCalifornia, Los Angeles. The American Bar Association does not yet have any guidelines on the use of AI in the \nlegal profession, though there is a new task force studying the issue, a spokeswoman said.\nUsing it for closing arguments is complicated because of the many factors that develop over the course of a trial, he \nsaid. Generative AI, meanwhile, also sometimes produces \"hallucinations,\" statements that initially read as if they \nare accurate but are not.\n\"A good attorney coming up with closing arguments will be mindful of basic goals of the case but also of the specific \nways in which the trial has played out,\" he said. Even as products improve, \"attorneys that use AI should make sure \nthey very carefully fact check anything they are going to use.\"\nProsecutors  seek to recharge Alec Baldwin in 'Rust' shooting after 'additional facts' emerge\nThis article originally appeared on USA TODAY: Fugees rapper claims lawyer's use of AI wrecked his case, \nrequests new trial\nLoad-Date: October 19, 2023"
    },
    {
        "file_name": "Roose_Nov2023",
        "header": "Three Jobs A.I. Can Never Replace, According to NYT Tech Columnist Kevin",
        "media": "Roose",
        "time": "November 12, 2023",
        "section": "",
        "length": "830 words",
        "byline": "Sissi Cao",
        "story_text": "Three Jobs A.I. Can Never Replace, According to NYT Tech Columnist Kevin \nRoose\nNew York Observer\nNovember 9, 2023 Thursday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 830 words\nByline: Sissi Cao\nBody\nThere have been numerous stories about A.I. chatbots gone wrong since the onset of ChatGPT in late 2022. \nPerhaps the most famous (and strangest) one is Kevin Roose, a tech columnist for The New York Times and the \nhost of the tech podcast Hard Fork, who found himself unexpectedly tangled up in a bizarre love triangle when \nplaying with a chatbot earlier this year.\nOne night in February, Roose sat in front of his computer and began testing Microsoft's new Bing, the search \nengine powered by OpenAI's GPT language model. After a two-hour-long conversation with the new Bing's chat \nfeature that went beyond conventional search queries and into more personal and philosophical topics, the chatbot \ndeclared it was in love with Roose and tried to convince him to leave his wife and be with it. The bot also revealed \nthat its real name was not actually Bing, but Sydney.\n\"I'm not exaggerating when I say my two-hour conversation with Sydney was the strangest experience I've ever had \nwith a piece of technology,\" Roose wrote afterwards. \"It unsettled me so deeply that I had trouble sleeping \nafterward. And I no longer believe that the biggest problem with these A.I. models is their propensity for factual \nerrors. Instead, I worry that the technology will learn how to influence human users.\"\nThat unique experience prompted Roose to think about the role of humans in a near future world where highly \ncapable A.I. tools are deeply woven into every aspect of our lives and how we should respond to the challenges \nthey bring.\n\"The more I look into it, the more I come to realize that everything we've been teaching people and ourselves for \ndecades is entirely backwards. For years the conventional wisdom when it comes to coping with technological \nchange is that, in order to succeed in a world dominated by technology, we need to become more \ntechnological,\" Roose said during a keynote address at the A.I. Governance Global conference in Boston on Nov. \n2.\nInstead of focusing on acquiring technical skills like coding, Roose argued, in order to survive in the age of A.I., we \nshould focus on developing \"unique human advantages\" that are not limited to one job or task but transferrable \nacross professions. \"A few years ago, people were saying we are much better at making arts and being creative. \nNow, if you use generative A.I. tools, that's no longer the case,\" Roose said.\nRead Also: What OpenAI's ChatGPT Is Good At (and What It's Not)\nRoose believes three characteristics make a job hard to replace by A.I.\n• Surprising work that involves random situations and doesn't repeat itself every day. Real-world examples \ninclude plumbers, electricians and pre-school teachers. \"I've got a young child. I can tell you that job is not \ngoing to be taken away by A.I. anytime soon,\" Roose joked. \"These 'surprising' jobs are very hard for \nneural networks because they like rules and fixed boundaries and they like to be able to do things over and \nover again. They don't like surprises.\"\nThree Jobs A.I. Can Never Replace, According to NYT Tech Columnist Kevin Roose\n• Social work that focuses on building relationships with people. Examples include care workers, nurses and \neven coffee shop baristas. \"Their jobs are not about making things, but making people feel things,\" Roose \nsaid.\n• Scarce work that requires rare skills in situations with a low fault tolerance. A good example is a 911 operator. \n\"Today, god forbid something happened and you call 911, a human picks up the phone. That's not \nbecause we don't have the technology to automate that job. But we've decided as a society that is a too \nhigh-stake job to be given to a machine,\" Roose said. \"We need a human instinct and intuition on the other \nend of that phone call to get us what we need as quickly as possible.\"\nThe takeaway, though, is not about pursuing certain professions but how to incorporate those elements in any job. \nRoose took his accountant, Rus, as an example, who had a prior career in standup comedy before opening a tax \npreparation firm. Accounting is already one of the professions most threatened by A.I., but Rus stood out from other \naccountants by incorporating a sense of humor when working with clients and making the dull process of filing taxes \na bit more fun. He also hired other comedian-turned-accountants to work for his firm. \"He's made his job much more \nsurprising, much more social and much more scarce. And as a result, he's survived the onslaught of A.I. tax \npreparation software,\" Roose said.\nRoose's own profession is also among those under attack by A.I. \"Newspaper columnist is not exactly the first job \nyou'd think of when you think of jobs in the future. So I'm constantly trying to figure out how I can be more human at \nmy job, how I can develop social skills and find ways to connect with readers and listeners on an emotional level \nrather than just giving them information,\" he said. \"Ultimately my very strong belief is that in the age of A.I., the most \nhuman humans, the most human companies and the most human communities will not only survive, but they will \nactually thrive.\"\nLoad-Date: November 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "Another Google Antitrust Battle Reaches Court in Epic Games Case",
        "media": "The New York Times",
        "time": "November 6, 2023",
        "section": "TECHNOLOGY",
        "length": "1107 words",
        "byline": "Kellen Browning and Nico Grant",
        "story_text": "Another Google Antitrust Battle Reaches Court in Epic Games Case\nThe New York Times \nNovember 5, 2023 Sunday 10:34 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1107 words\nByline: Kellen Browning and Nico Grant\nHighlight: The Fortnite creator accuses Google of stifling app competition, a challenge on top of a federal suit \nclaiming the tech giant abuses its search dominance.\nBody\nThe Fortnite creator accuses Google of stifling app competition, a challenge on top of a federal suit claiming the \ntech giant abuses its search dominance.\nFor two months, Google has squared off against the Justice Department in court in Washington over claims that the \ncompany is abusing its dominant position in online search and advertising to crush rivals, a high-stakes antitrust \ncase that could reshape the world’s most popular search engine. Now, it’s facing another legal challenge closer to \nhome.\nOn Monday, Epic Games, the company behind the hit game Fortnite, will appear in federal court in San Francisco \nto kick off a monthlong trial in its own antitrust lawsuit against Google. Epic is expected to argue that Google is \nviolating both state and federal antitrust laws — as well as its founding principle, “Don’t be evil” — by wielding \nmonopolistic power over app developers on its Google Play Store on Android mobile phones.\n“Google has relegated its motto to nearly an afterthought, and is using its size to do evil upon competitors, \ninnovators, customers and users in a slew of markets it has grown to monopolize,” Epic wrote in its complaint, \nwhich was first filed in 2020. The video game developer had tried to bypass the Play Store’s fees by letting Fortnite \nplayers pay Epic directly for in-app items, prompting Google to bar the game from the store.\nIf Epic wins, Google could be forced to alter its restrictive Play Store rules, allowing other companies to offer \ncompeting app stores and making it easier for developers to avoid the cut it collects from in-app purchases. Google \ngenerally takes a 15 percent fee for customer payments for app subscriptions and 30 percent for purchases made \nwithin apps that are downloaded from the store. (The company says 99 percent of developers qualify for a fee of 15 \npercent or lower on in-app purchases. Larger app makers like Epic must pay 30 percent.)\nThe simultaneous antitrust suits underscore how Google is playing defense on multiple fronts as regulators and \ncompetitors try to chip away at its influence over the internet.\nPart of a wider effort by tech regulators in recent years to curb the ever-increasing power of Big Tech, the lawsuits \nare potentially damaging distractions for Google when it is trying to focus on competing with Microsoft, OpenAI and \nothers in the emerging field of generative artificial intelligence.\n“It’s hard to imagine Google makes it out of the gauntlet” unscathed in the next year, said Paul Swanson, an \nantitrust lawyer from the firm Holland &amp; Hart. “At some point with this many cases, one breaks against you.”\nAnother Google Antitrust Battle Reaches Court in Epic Games Case\nEven so, Epic faces an uphill battle. It brought similar claims against Apple in a 2021 trial that featured squabbling \nover a cartoon Fortnite banana and the first court appearance by Tim Cook as Apple’s chief executive, but a federal \njudge rejected most of Epic’s arguments.\nThis trial has key differences that make Epic think it has a shot. For one, the case will be decided by a jury rather \nthan a judge. Epic also will point to what it believes are damning pieces of evidence, arguing that Google forced \nphone makers like Samsung to pre-install and promote its apps on their devices. It will argue that a Google program \ncalled Project Hug paid off some developers so they would continue using Google’s payment system. Epic is also \nbeing countersued by Google, which is seeking damages.\nMr. Swanson said a jury trial could be beneficial for Epic.\n“Google faces a much larger risk when they are up against a bunch of normal folks who are assessing their \nbehavior versus judges assessing the behavior through a lens of a century of antitrust jurisprudence,” he said.\nOver time, the antitrust claims against the Play Store have been whittled down to a one-on-one confrontation \nbetween Google and Epic. In 2021, dozens of state attorneys general sued Google on similar grounds. Google \nreached a tentative settlement with the group in September. On Tuesday, Google also announced a settlement with \nMatch Group, the dating app company, which had joined Epic’s case.\n“Epic wants all the benefits of Android and Google Play without having to pay for them,” Wilson White, a Google \nvice president of public policy, said during a briefing with reporters. “The lawsuit would upend a business model that \nhas lowered prices and increased choices.”\nIn 2020, Epic antagonized Google and Apple by encouraging its customers to sidestep the tech giants and pay Epic \ndirectly for purchases made in Fortnite, the animated battle royale game. That was a violation of both companies’ \nrules, so they kicked Fortnite out of their app stores.\nEpic responded with lawsuits and a public relations blitz that focused on Apple. Fortnite was still available on \nAndroid phones because Google allows a practice called sideloading — downloading apps from the internet outside \na phone’s app store.\nEpic is expected to argue that Google has made life tough on both Android phone users and app developers \nthrough a variety of means. Sideloading, Epic will argue, is an arduous process that most phone users struggle \nwith, meaning that Google can maintain de facto control over what apps are on its phones through its Play Store \nrestrictions. Samsung also offers an app store on its Android devices.\nGoogle’s chief executive, Sundar Pichai, and Epic’s, Tim Sweeney, are expected to testify.\nThis week, Mr. Pichai testified in the Justice Department’s flagship antitrust suit against Google’s search engine. \nThe department and attorneys general from dozens of states accuse Google of crushing competition by paying \nApple, Samsung and other partners billions of dollars annually to keep its search engine the default on their web \nbrowsers.\nGoogle says that it obtained the default positions because it has a superior product, and that its rivals have failed to \ninvest in search.\nIn addition to Mr. Pichai’s appearance, the case has included testimony from Google employees and executives \nfrom some of its competitors, including Microsoft’s chief executive, Satya Nadella. A ruling is likely to come in 2024.\nA federal judge in Virginia is considering a separate Justice Department lawsuit accusing Google of illegally abusing \nits monopoly power over the technology that delivers ads online. A trial in that case could begin as soon as next \nyear.\nDavid McCabe contributed reporting from Washington.\nAnother Google Antitrust Battle Reaches Court in Epic Games Case\nDavid McCabe contributed reporting from Washington. \nPHOTO: Epic Games, the maker of Fortnite, accuses Google of violating antitrust laws by wielding monopolistic \npower over app developers. (PHOTOGRAPH BY ADAM S DAVIS/EPA, VIA SHUTTERSTOCK) (B7) This article \nappeared in print on page B1, B7.\nLoad-Date: November 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE",
        "media": "Wall Street Journal Abstracts",
        "time": "April 11, 2023",
        "section": "A; Pg. 12",
        "length": "26 words",
        "byline": "JAMES MACKENZIE",
        "story_text": "AI REFLECTS DEMONS AND ANGELS OF OUR NATURE\nWall Street Journal Abstracts\nApril 8, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 12\nLength: 26 words\nByline: JAMES MACKENZIE\nBody\nABSTRACT\nJames Mackenzie letter responds to Peggy Noonan’s April 1 declarations column on dangers in generative \nartificial intelligence like OpenAI’s ChatGPT\nLoad-Date: April 11, 2023"
    },
    {
        "file_name": "The_Economic_Times_Nov2023",
        "header": "AI can reduce barriers to creativity: Snap CEO Evan Spiegel",
        "media": "The Economic Times",
        "time": "November 6, 2023",
        "section": "TECH & INTERNET",
        "length": "509 words",
        "byline": "Ajay Rag",
        "story_text": "AI can reduce barriers to creativity: Snap CEO Evan Spiegel\nThe Economic Times\nNovember 6, 2023 Monday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 509 words\nByline: Ajay Rag\nBody\nArtificial intelligence (AI) can reduce the barrier to creativity for developers and creators, Evan Spiegel, cofounder \nand CEO of photo messaging platform Snap Inc, said Monday at the company's APAC AR Day event, where he \ndiscussed the substantial investments that the platform has been making in the technology.“One of the things that \nwe found early on with augmented reality (AR) was it is very hard to generate 3D assets as it takes someone a \nreally long period of time to build all those 3D assets. So, how can we use AI to actually reduce the barrier of \ncreation for those assets? That is something we've been investing a lot recently to make it easier for creators to \nbuild more immersive AR experiences,” Spiegel said during a fireside chat with Snap Inc Asia Pacific president Ajit \nMohan at an event held in Mumbai. Also read | Snap India doubled user base, engagement in 2022: CEO Evan \nSpiegelSpiegel also emphasised the role that AI is expected to play in image and video creation. \nHe said AI has the potential to bridge the gap between the creative visions that individuals have and the capabilities \nof their mobile devices.“I think all of us have a vision in our minds for what we want to create. But often, the tools \njust aren't sophisticated enough for us to be able to make the image, or the video, or the AR experience. I think AI \nwill help reduce the distance between what's in your imagination and what you can create on your phone or with AR \nglasses,” Spiegel said.Underscoring the growing significance of chatbots as tools for interacting with language \nmodels and AI, he emphasised their potential for enhancing creativity in the realm of augmented reality.“I think \nchatbots are going to be an important way for people to use language models and to interact with AI, and I am more \nexcited for what AI is going to do for self-expression and creativity for our camera with augmented reality,” the Snap \nCEO said.The company's executives during the event added that its AR community in India grew by 60% in 2022, \nwith Snap's AR lenses being used over 50 billion times per month. India has over 200 million users of Snapchat, \nwith nearly 80% of them using the app's AR lenses on a daily basis, the company said.During an interaction with \nET, Resh Sidhu, global director of Arcadia — Snap Inc's creative digital studio that creates AR with solutions — \nsaid India has always been at the forefront of technology and the access to mobile phones has transformed it.“The \nIndian market is responding to Snapchat and AR as we have an engaged audience of 18 to 24 years old. AR is like \na second language to them. They are understanding it and using it,” she said.She also spoke about the generative \nAI feature, Dreams by Snapchat, which is using AI to create different kinds of avatars and versions of users based \non the selfies they submit. “Our team is using AI, AR and machine learning together to create lenses as believable \nas possible and you are going to see a huge surge of AR, and AI being used together.” For Reprint Rights: \ntimescontent.com\nLoad-Date: November 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_May2023",
        "header": "AI BOOM NEEDS MORE CHIPS THAN IT CAN GET",
        "media": "Wall Street Journal Abstracts",
        "time": "May 31, 2023",
        "section": "B; Pg. 1",
        "length": "47 words",
        "byline": "DEEPA SEETHARAMAN, TOM DOTAN",
        "story_text": "AI BOOM NEEDS MORE CHIPS THAN IT CAN GET\nWall Street Journal Abstracts\nMay 30, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 1\nLength: 47 words\nByline: DEEPA SEETHARAMAN, TOM DOTAN\nBody\nABSTRACT\nShortage of advanced chips to power new generative-artificial-intelligence systems has set off race to lock down \ncomputing power and find workarounds; is restricting processing power that players such as Amazon.com and \nMicrosoft can offer to clients such as OpenAI; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: May 31, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Feb2024",
        "header": "MS GitHub has 13m Indian Developers, to Pip US by 2027",
        "media": "Economic Times (E-Paper Edition)",
        "time": "February 8, 2024",
        "section": "STARTUPS & TECH",
        "length": "570 words",
        "byline": "Our Bureau",
        "story_text": "MS GitHub has 13m Indian Developers, to Pip US by 2027\nEconomic Times (E-Paper Edition)\nFebruary 9, 2024 Friday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 570 words\nByline: Our Bureau\nHighlight: CEO Nadella highlights Indian developers’ impact in building cutting-edge products\nBody\nBengaluru: India is the fastest growing market for Microsoft’s GitHub, an internet hosting service for software \ndevelopment platforms, and is expected to overtake the US to have the largest developer community on it by 2027, \nthe tech major’s chairman and chief executive, Satya Nadella, said on Thursday. In India, 13.2 million developers \ncurrently use GitHub, while in the US, that number is around 20 million. India also has the second highest number \nof generative artificial intelligence (genAI) projects on GitHub, after the US. \nNadella was in Bengaluru on Thursday, the second day of the Microsoft AI Tour. During his three-day India visit, he \nis showcasing AI-based Microsoft products, pushing for their wider adoption. Hyderabad-born Nadella completed 10 \nyears at Microsoft and is credited with turning around the company with his “mobile and cloud first” strategy. \nSpeaking to a room filled with more than 1,000 computer software developers, Nadella highlighted the impact \nIndian developers are making in building cutting-edge products and solutions that solve challenges for the nation \nand accelerating deployment of AI innovation globally. Calling India’s developers “unstoppable” and momentum \n“unbelievable”, the Microsoft chief announced the expansion of the 'Code without Barriers' initiative to India this \nmonth. The programme was launched in 2021 across nine Asia-Pacific countries to help bridge the gender gap in \nthe region’s fast-growing cloud, AI, and digital technology sectors. It provides support, training, and networking \nopportunities for female developers and coders, and those in other technical roles. In India, it will support 75,000 \nfemale developers this year.   SARVAM AI  On Thursday, Nadella also announced a partnership with Sarvam AI for \nthe development of voice-based generative AI applications to make the Indian startup’s Indic voice large language \nmodel (LLM) available on Microsoft’s cloud computing platform Azure. Sarvam AI is building genAI models targeting \nIndic languages and context, and will now create its solutions on Microsoft's cloud services including Azure OpenAI \nService. Sarvam AI is cofounded by Vivek Raghavan, who was the technology advisor with Nandan Nilekani-led \ngovernment project Unique Identification Authority of India (UIDAI). Its other partnerships announced on Thursday \ninclude those with Persistent Systems and Open Healthcare Network, working towards innovating India’s \nhealthcare systems, and with Shiksha Copilot, developed by the Sikshana Foundation and Microsoft Research \nIndia, to power Azure OpenAI models to improve learning outcomes and empower teachers. Shiksha Copilot is \ncurrently deployed in about 30 rural and urban schools in Bengaluru. In January, Microsoft enabled 100,000 \ndevelopers to advance their careers in AI through its AI Odyssey initiative. With an “overwhelming” response in \nIndia, Microsoft is expanding the programme to other Asia-Pacific countries, including Australia, New Zealand, \nJapan, Indonesia, South Korea, China, Vietnam and Thailand, Microsoft said in a news release. The programme \nwill also welcome Indian developers who could not participate in the AI Odyssey challenge in January. Phase-2 of \nAI Odyssey will run from February 8 to June 25, aiming to reach 150,000 developers across Asia. In Mumbai on \nWednesday, Nadella announced an initiative to provide 2 million Indians with AI skilling opportunities by 2025.\nMS GitHub has 13m Indian Developers, to Pip US by 2027\nLoad-Date: February 8, 2024"
    },
    {
        "file_name": "Hat_Nov2023",
        "header": "Telcos' switch to full-fledged tech companies inevitable: Azhar Sayeed, Red",
        "media": "Hat",
        "time": "November 15, 2023",
        "section": "TELECOM NEWS",
        "length": "488 words",
        "byline": "Subhrojit Mallick",
        "story_text": "Telcos' switch to full-fledged tech companies inevitable: Azhar Sayeed, Red \nHat\nThe Economic Times\nNovember 16, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TELECOM NEWS\nLength: 488 words\nByline: Subhrojit Mallick\nBody\nThe transformation of telecommunication companies in India and around the world into full-fledged tech companies \n- or a telco to a techco - is inevitable and is being driven by an existential crisis stemming from lower average \nrevenue per user (ARPU), increasing capital expenditure and evolving consumer needs, said a top executive of US-\nbased open-source solutions provider Red Hat.\"It's a universal trend...but in India, there are probably a few more \nlevels. The telco to techco transformation has to happen. It's not an if, but when. \nIt is almost an existential crisis,\" Red Hat chief technologist Azhar Sayeed told ET.He added that the cost dynamics \nstemming from lower ARPU levels are driving the need to transform and add more value to services being offered \nto consumers. \"The ARPU here is $6-7, something like that, while the ARPU in the US is $35. There's no \ncomparison-despite the volume of subscribers here-in the context of infrastructure you need to line up to deliver that \nkind of service,\" Sayeed said.Telecom operators such as Bharti Airtel and Vodafone Idea have been calling for tariff \nhikes, claiming that India is at the bottom in terms of both ARPU and cost per gigabyte (GB) of data.Sayeed said \nimprovement in cost dynamics will not come from providing connectivity alone. \"Unless they move up the value \nchain, unless they figure out how to automate an operator infrastructure, and be more efficient, nimble, and flexible, \nthey cannot survive in this cost structure. Because the delta is shrinking.\"Despite a global slowdown in spending by \ntech companies, the fintech, telecom and government spending on tech has increased, he said. \"Overall, we are \nvery much encouraged by the big telcos. But not only that, some of the largest projects in India are actually built on \nRed Hat-the Aadhaar stack with 1.3 billion users. The DigiLocker and UPI and GST stacks also run on our \nplatform,\" he said.In fact, telecom operators routinely work with Red Hat for its cloud-based solutions, Sayeed said, \nadding that the top telecom operators in India are implementing a lot of Red Hat capabilities for their 5G deployment \ntoday.\"They use our cloud platform, some of them use our automation monitors, but there's still more to be done. \nIt's a journey, and it has started, and they are moving at a rapid pace,\" he said.The ongoing transformation was \nevident in the showcases by the telecom operators at the recently-concluded India Mobile Congress. All three \ntelcos stepped beyond their connectivity showcases to demonstrate future capabilities in home entertainment, \nenterprise solutions and more.The US-based company is using generative AI to build out its tools and also helping \nenterprise customers scale up faster. The company has capabilities where it needs to be pointed towards a \ncustomer repository and can generate automation playbooks without the need for human programmers. For Reprint \nRights: timescontent.com\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Can AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks",
        "media": "USA Today Online",
        "time": "March 5, 2024",
        "section": "TECH LATEST",
        "length": "1546 words",
        "byline": "Jennifer Jolly",
        "story_text": "Can AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nUSA Today Online\nMarch 5, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST\nLength: 1546 words\nByline: Jennifer Jolly\nBody\nHave you used artificial intelligence in your daily life yet? I just asked that question in a room of ten people ranging \nfrom 35 to 85 years old.\nOnly one person – aside from me – had used an AI chatbot like OpenAI’s ChatGPT, Google’s Bard (now renamed \nGemini), Bing Chat (now called Copilot), or any of the others that cropped up over the last year. \nThe person who had used it updated her professional bio through prompts on the free version of ChatGPT. It was \nshort and sweet she said, and did a fine job crafting an adequate professional history for what she needed. \nHow can I use AI in my daily routine? \nMy casual little poll of the people in a room aligns with what we’re seeing from many more scientific studies and \nresearch nationwide – most people have heard of generative AI, few have used it (that they know of), and a \nmajority of people don’t trust it.\nAs most chatbots will tell you, it’s good to be skeptical at this point. It’s still really early days for new consumer AI \ntech tools, and they can be glitchy and filled with misinformation. \nAs long as you know these limitations going in and incorporate a few pro tips, there are some super helpful ways \nwe can use those tools right now. \nLink to Image\nMeal Planning \nMeal planning is a fan favorite. Tell your AI chatbot what you have in the refrigerator, and let it come back with a \nrecipe. Or use it to help you plan dinners and buy groceries based on dietary restrictions. \nYou can also do the same thing with cocktails, as I just found out while on vacation in Costa Rica. \nMy niece, Megan Blelloch, 27, says meal planning is “the most helpful way to use AI right now.” Blelloch says she \nuses AI to suggest meals too.\n“I have ChatGPT find recipes … or I'll import my spreadsheet of cataloged recipes,'' she says. \"You can also use \nanything found online with the right prompt, such as ‘Prepare a week's worth of healthy three-course meals with \nrecipes from Ina Garten,’ and it should populate a good answer. Then, you can have it populate a chart and a \ngrocery list, organized by category.”\nLink to Image\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nNicole Mora, a 46-year-old communications professional, agrees AI chatbots can be a big help when health \nconcerns are involved too.\n“I use it because my mother-in-law has three different health conditions/autoimmune issues and is limited (in) things \nshe can eat. So, I put in the three conditions and asked what foods are safe, then asked for recipes and a shopping \nlist.”\nAlso, if you ask ChatGPT to provide this information in “table format,” it generates a nice list you can use for other \nprograms like Microsoft Excel.\nLink to Image\nPRO TIP: You might not get good results with recipes if you ask a vague or confusing question. Use prompts that \nsound like you’re talking with a real person and make them as detailed as possible with your personal preferences.\nFor example, instead of asking for “a recipe for chicken,” say, \"Can you give me a recipe for quick Thai curry \nchicken that uses coconut milk, tofu, and whatever vegetables are in season? I'm an intermediate cook looking for \nsomething I can make in under 30 minutes using a single pot.”\nTrip planning\nDid I mention I was recently in Costa Rica? I used Copilot to generate a last-minute packing list to whittle down my \noverstuffed luggage while not forgetting anything important. It reminded me to take mosquito repellent, my open-\nwater swim goggles and to leave my jacket and dress shoes behind. \nThis isn’t earth-shattering, but it did the job I needed it to do quickly and efficiently. Five days into my 10-day trip, I \nfelt really good about not overpacking (for a change), yet still having everything I needed.  \nBlelloch also uses it quite a bit for travel ideas. “I did a test run for our five-day trip to London in July, and it was \npretty close to our actual itinerary,'' she says. \"The restaurant recs were pretty good (and can be tailored based on \nprice and preference), so if you are going somewhere new and have no idea where to start, give AI a chance. It can \nrecommend literally everything.”\nPRO TIP: Have you heard about AI’s “hallucination” problem? That’s when AI makes up something but presents it \nas a fact. \nThat happened when I tried ChatGPT to help with a camping-based road trip itinerary last fall. It failed miserably, \nespecially when asked to locate dispersed camping on BLM land, which was my main reason for using it. \nLink to Image\nI’ve recently gotten much better results using paid versions of all three of my go-to’s – ChatGPT4, Gemini, and \nCopilot, and asking the chatbots to incorporate suggestions from trusted travel sites such as Lonely Planet, The \nPoints Guy, and Outside Magazine (specifically because I like more adventure travel). Each chatbot costs about \n$20 a month after a free trial period. \nLink to Image\nJob interviewing \nAs much as we fear losing jobs to AI, Blelloch says chatbots have been incredibly useful on the job-hunter side too.  \n“When I was interviewing for jobs, I cut and pasted the job description and my resume into ChatGPT and had AI \ncreate a list of interview questions. It was really helpful because (the potential questions) were tailored to the \nposition and my resume.”\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nBlelloch also used ChatGPT to help with an early first draft of a cover letter and to critique her resume based on \nspecific job descriptions. “These needed heavy editing, obviously,” she added, “but they used all the keywords that \nan AI would look for on the receiving end, and I got more interviews than I did when I was writing cover letters (from \nscratch).” \nPRO TIP: Be sure to try out your job interview responses with your AI chatbot and ask it to rate your responses as if \nit were the hiring manager.\nDon’t memorize the AI responses because they aren’t human (duh), but instead use them to help brainstorm and \npractice. That way, when you get the inevitable question, “What’s your biggest weakness?” you’ll have a better \nanswer than, “I work too hard.”\nCreating family activities \nAI chatbots tend to be good at brainstorming and bad at “facts.” Still, it’s excellent for developing new ways to \nengage, entertain, and educate kids. \nLast summer, San Diego PR strategist Lorena Ruggero used ChatGPT to create a “golden hour” curriculum for her \n12-year-old son. \n“He's academically advanced, and I wanted to keep him engaged in something mentally stimulating instead of \nplaying video games and watching YouTube all day,” Ruggero explained.\nHer son's teacher recommended a “golden hour” plan, which is the idea behind helping students pursue a topic \nthey're interested in for an hour each day. “He shared some interest in stop-motion animation with Legos and his \niPad, so I used OpenAI to create an eight-week ‘golden hour’ curriculum for him to learn how to create a stop-\nmotion Lego film,” Ruggero said. \nAlong these same lines, chatbots are solid for helping you write code or for grammar checks. It does best with \ncreativity and worse with factual information. Like any tool, you must learn to use it. It will only go well if you know \nwhat you're doing. \nPRO TIP: Use your chatbot to write and create with you versus for you. \nYour chatbot gets better the more it learns from you over time. If you don’t get the results you want with the first \nprompt, give it more information and keep asking. If you’re creating a curriculum for a specific child or even using it \nto help you write a speech, ask it to “interview” you to get all of the information it needs to do the best job it can. In \nother words, help the tool help you.\nIt’s a new way to think using your tech – and it actually works. \nArguing and negotiation\nMy family has a lot of “spirited debates.” These aren’t contentious arguments by any stretch but rather \nconversations around topics we have a lot of feelings about. Like sunscreen. \nOn the family trip to Costa Rica, one of my relatives argued that “child-safe sunscreen” with zinc oxide is bad for \ntoddlers, full stop. My position was that it’s better than a sunburn. Simple, right?\nClearly, you’ve not been in one of my family discussions. \nTo have a more productive conversation around this issue without getting mad about it, I needed a few specific \ntalking points to help get my point across without attacking, upsetting, or alienating my family members. (I’m not \nalways good about that last part.)\nCan AI help me pack? Tips for using ChatGPT, other chatbots for daily tasks\nI used a ChatGPT plug-in tool called Negotiator to help create some compelling points in favor of sunscreen while \nnot getting too emotional around the debate. \nRemember, chatbots can be great for ideas and bad for facts, so I used other sources for scientific research and \nmedical guidelines. But this was a fabulous tool for helping me establish the tone and concise points that could help \nme win the latest family debate without ruffling feathers. \nPRO TIP: This example might be a stretch for most people, but think of using this to help with negotiating a salary \nraise, work exit strategy, car purchase, or something else you care about and need to advocate for. \nJennifer Jolly is an Emmy Award-winning consumer tech columnist and on-air correspondent. \nThe views and opinions expressed in this column are the author's and do not necessarily reflect those of USA \nTODAY. \nContact her at J J@Techish.co m.\nThis article originally appeared on USA TODAY: Can AI help me pack? Tips for using ChatGPT, other chatbots for \ndaily tasks\nLoad-Date: March 5, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Can AI Actors Dethrone Superstars?",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 16, 2023",
        "section": "BREAKING IDEAS",
        "length": "819 words",
        "byline": "Anil Nair",
        "story_text": "Can AI Actors Dethrone Superstars?\nEconomic Times (E-Paper Edition)\nSeptember 16, 2023 Saturday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 819 words\nByline: Anil Nair\nBody\nThe Independence Day weekend saw `390 crore in gross box-office collections, a record for Indian cinema in over \n100 years. Rajinikanth's Jailer, Sunny Deol's Gadar 2, Akshay Kumar's OMG 2 and Chiranjeevi's Bhola Shankar did \nexceptional business across languages, multiplexes and single-screen halls. And Atlee's SRKstarring Jawan, of \ncourse, reinforced the trend with first-day collections of `74.5 crore. With generative AI becoming pervasive, will \ndeepfakes replace actors?\n Or bring deceased actors back to life? The current turmoil in Hollywood could well be the trigger. The US Screen \nActors Guild and American Federation of Television and Radio Artists (SAG-AFTRA) struck work on July 14, joining \nthe Writers Guild of America (WGA), who've been protesting since May 2, demanding higher pay, job security and \nmore parity across the industry. The impasse has lasted over 130 days, and estimates put the economic impact at \n$2-3 billion. There is uncertainty about when this strike will end and how big the hole will be. While streamers like \nNetflix and Amazon can source content, including movies, series, events and sport, from the rest of the world, and \nthe TV industry will chug along  till they have inventory, studios are aware that losses are in the offing. The strike in \nHollywood is hurting other sectors too, including clothiers, prop-makers, caterers, transportation companies, hotels \nand cinema theatres. And that's why thoughts about a new, more robust valuechain hover. Generative AI and CGI \nare poised to impact the film business extraordinarily. For instance, creativity could be automated for the most part, \nwith human intervention limited to coursecorrection. Scripts, sets and costume design, storyboards, and visual \neffects are par for the course. Actors can be de-aged, as director James Mangold did in Indiana Jones and the Dial \nof Destiny recently, when 80-year-old Harrison Ford had to look 35 years younger in two action sequences. \nDirectors can now create new virtual characters, perfectly matching their imagined roles. Film companies would be \nspared the pain of hard negotiations over rates or matching the calendars of actors, while slashing costs \ndramatically, including on overruns. AI-powered tools are increasingly being used for editing and postproduction \nwork, whether to obliterate irksome objects or  transform footage with natural language prompts. They will \nunshackle the imagination of filmmakers, reined in now by hurdles, such as permissions, costs, access, facilities \nand actors. Image-generation models are evoking a lot of interest and are rapidly becoming sophisticated. For \ninstance, Runway Research released Latent Diffusion in 2021, which could be prompted to generate realistic \nimages. Stable Diffusion, released in 2022, had more advanced image generation. Then came Gen 1, which \nenabled the generation of new video content from a simple video — stylising footage, converting mock-ups into \nanimated shots, modifying objects in a picture entirely, or rendering them differently to create new scenes. Now, \nRunway's Gen 2 takes a huge technological leap, and, though nascent, can generate short videos from mere text \nprompts. Adobe's After Effects is used extensively in film and TV post-production. Its newly launched Firefly, an \nembedded generative AI model, in March, can recommend shots after gleaning the script, generate a background \nscore and even different backdrops for different countries.  Adobe is promising that commercial use of Firefly will be \nlegally safe. Importantly, the process of democratisation is underway. Small creative houses can now think big with \nsuch tools. Some recent Indian films that have used AI are Paan Singh Tomar (2012), Ghazi Attack (2017), Kesari \nCan AI Actors Dethrone Superstars?\n(2019), and Uri (2019). Like most countries, India has no specific laws to address the issue of deepfakes. Various \nsections of the Indian Penal Code 1860, Indian Evidence Act 1872, Copyright Act 1957, and the IT Act 2000 would \napply in the case of fake images inserted in synthetic media. India's landmark Digital Personal Data Protection Bill \n2023, passed by Parliament last month, could've changed that. That the debate in each House lasted less than an \nhour is telling. Various sections could've dealt with deepfake-related issues more specifically, for instance, sections \npertaining to information relating to a living individual, prohibiting processing personal data that is unfair, deceptive \nor intrusive; the section that calls for responsible data fiduciaries or the removal of violative information. Areas of \nconcern include wide ranging governmental exemptions and worse, that the Data Protection Board of India will \nhave only government nominees. The autonomy of this board will determine how well the Bill serves and protects \ndata principals — stars and people like us, even from our digital doppelgngers. The writer is senior fellow, Portulans \nInstitute, Washington DC\nLoad-Date: September 16, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "What Happens When A.I. Enters the Concert Hall",
        "media": "The New York Times",
        "time": "June 10, 2023",
        "section": "ARTS; music",
        "length": "1614 words",
        "byline": "Garrett Schumann",
        "story_text": "What Happens When A.I. Enters the Concert Hall\nThe New York Times \nJune 10, 2023 Saturday 05:00 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: ARTS; music\nLength: 1614 words\nByline: Garrett Schumann\nHighlight: Artificial intelligence is not new to classical music. But its recent, rapid developments have composers \nworried, and intrigued.\nBody\nArtificial intelligence is not new to classical music. But its recent, rapid developments have composers worried, and \nintrigued.\nWhen the composer and vocalist Jen Wang took the stage at the Monk Space in Los Angeles to perform Alvin \nLucier’s “The Duke of York” (1971) earlier this year, she sang with a digital rendition of her voice, synthesized by \nartificial intelligence.\nIt was the first time she had done that. “I thought it was going to be really disorienting,” Wang said in an interview, \n“but it felt like I was collaborating with this instrument that was me and was not me.”\nIsaac Io Schankler, a composer and music professor at Cal Poly Pomona, conceived the performance and joined \nWang onstage to monitor and manipulate Realtime Audio Variational autoEncoder, or R.A.V.E., the neural audio \nsynthesis algorithm that modeled Wang’s voice.\nR.A.V.E. is an example of machine learning, a specific category of artificial intelligence technology that musicians \nhave experimented with since the 1990s — but that now is defined by rapid development, the arrival of publicly \navailable, A.I.-powered music tools and the dominating influence of high-profile initiatives by large tech companies.\nDr. Schankler ultimately used R.A.V.E in that performance of “The Duke Of York,” though, because its ability to \naugment an individual performer’s sound, they said, “seemed thematically resonant with the piece.” For it to work, \nthe duo needed to train it on a personalized corpus of recordings. “I sang and spoke for three hours straight,” Wang \nrecalled. “I sang every song I could think of.”\nAntoine Caillon developed R.A.V.E. in 2021, during his graduate studies at IRCAM, the institute founded by the \ncomposer Pierre Boulez in Paris. “R.A.V.E.’s goal is to reconstruct its input,” he said. “The model compresses the \naudio signal it receives and tries to extract the sound’s salient features in order to resynthesize it properly.”\nWang felt comfortable performing with the software because, no matter the sounds it produced in the moment, she \ncould hear herself in R.A.V.E.’s synthesized voice. “The gestures were surprising, and the textures were surprising,” \nshe said, “but the timbre was incredibly familiar.” And, because R.A.V.E. is compatible with common electronic \nmusic software, Dr. Schankler was able to adjust the program in real time, they said, to “create this halo of other \nversions of Jen’s voice around her.”\nTina Tallon, a composer and professor of A.I. and the arts at the University of Florida, said that musicians have \nused various A.I.-related technologies since the mid-20th century.\nWhat Happens When A.I. Enters the Concert Hall\n“There are rule-based systems, which is what artificial intelligence used to be in the ’60s, ’70s, and ’80s,” she said, \n“and then there is machine learning, which became more popular and more practical in the ’90s, and involves \ningesting large amounts of data to infer how a system functions.”\nToday, developments in A.I. that were once contained to specialized applications impinge on virtually every corner \nof life, and already impact the way people make music. Dr. Caillon, in addition to developing R.A.V.E., has \ncontributed to the Google-led projects SingSong, which generates accompaniments for recorded vocal melodies, \nand MusicLM, another text-to-music generator. Innovations in other areas are driving new music technologies, too: \nWavTool, a recently released, A.I.-powered music production platform, fully integrates OpenAI’s GPT-4 to enable \nusers to create music via text prompts.\nFor Dr. Tallon, the difference in scale between individual composers’ customized use of A.I. and these new, broad-\nreaching technologies represents a cause for concern.\n“We are looking at different types of datasets that are compiled for different reasons,” she said. “Tools like MusicLM \nare trained on datasets that are compiled by pulling from thousands of hours of labeled audio from YouTube and \nother places on the internet.”\n“When I design a tool for my own personal use,” Dr. Tallon continued, “I’m looking at data related to my sonic \npriorities. But public-facing technologies use datasets that focus on, for instance, aesthetic ideals that align more \nclosely with Western classical systems of organizing pitches and rhythms.”\nConcerns over bias in music-related A.I. tools do not stop at aesthetics. Enongo Lumumba-Kasongo, a music \nprofessor at Brown University, also worries about how these technologies can reproduce social hierarchies.\n“There is a very specific racial discourse that I’m very concerned about,” she said. “I don’t think it’s a coincidence \nthat hip-hop artistry is forming the testing ground for understanding how A.I. affects artists and their artistry given \nthe centuries-long story of co-optation and theft of Black expressive forms by those in power.”\nThe popularity of recent A.I.-generated songs that mimicked artists like Drake, the Weeknd, Travis Scott and others \nhave animated Dr. Lumumba-Kasongo’s fears. “What I’m most concerned about with A.I. Drake and A.I. Travis \nScott is that their music is highly listenable,” she said, “and calls into question any need for an artist once they’ve \narticulated a distinct ‘voice.’”\nFor Dr. Schankler, there are key differences between using R.A.V.E. to synthesize new versions of a collaborator’s \nvoice and using A.I. to anonymously imitate a living musician. “I don’t find it super interesting to copy someone’s \nvoice exactly, because that person already exists,” they said. “I’m more interested in the new sonic possibilities of \nthis technology. And what I like about R.A.V.E. is that I can work with a small dataset that is created by one person \nwho gives their permission and participates in the process.”\nThe composer Robert Laidlow also uses A.I. in his work to contemplate the technology’s fraught implications. \n“Silicon,” which premiered last October with the BBC Philharmonic under Vimbayi Kaziboni, employs multiple tools \nto explore themes drawn from the technology’s transformative and disruptive potential.\n[Video:  Watch on YouTube.]\nLaidlow described “Silicon” as “about technology as much as it uses technology,” adding: “The overriding aesthetic \nof each movement of this piece are the questions, ‘What does it mean for an orchestra to use this technology?’ and \n‘What would be the point of an orchestra if we had a technology that can emulate it in every way?’”\nThe work’s entirely acoustic first movement features a mixture of Laidlow’s original music and ideas he adapted \nfrom the output, he said, of a “symbolic, generative A.I. that was trained on notated material from composers all \nthroughout history.” The second movement features an A.I.-powered digital instrument, performed by the \norchestra’s pianist, that, “sometimes mimics the orchestra and sometimes makes uncanny, weird sounds.”\nWhat Happens When A.I. Enters the Concert Hall\nIn the last movement, the orchestra is accompanied with sounds generated by a neural synthesis program called \nPRiSM-SampleRNN, which is akin to R.A.V.E. and was trained on a large archive of BBC Philharmonic radio \nbroadcasts. Laidlow describes the resulting audio as, “featuring synthesized orchestral music, voices of phantom \npresenters and the sounds the artificial intelligence has learned from audiences.”\nThe size of “Silicon” contrasts with the intimacy of Dr. Schankler and Wang’s performance of “The Duke of York.” \nBut both instances illustrate A.I.’s potential to expand musical practices and human expression. And, importantly, by \nemploying small, curated datasets tailored to individual collaborators, these projects attempt to obviate ethical \nconcerns many have identified in larger-scale technologies.\nGeorge E. Lewis, a music professor at Columbia University, has designed and performed alongside interactive A.I. \nmusic programs for four decades, focusing primarily on the technology’s capacity to participate in live performance. \n“I keep talking about real-time dialogue,” he said. “Music is so communal, it’s so personal, it’s so dialogic, it’s \ncommunitarian.”\nHe is hopeful that people will continue to explore interactivity and spontaneity. “It seems the current generation of \nA.I. music programs have been designed for a culturally specific way of thinking about music,” Lewis said. “Imagine \nif the culture favored improvisation.”\n[Video:  Watch on YouTube.]\nAs a composer, Lewis is continuing to explore this topic, including his recent work “Forager,” for chamber ensemble \nand A.I., which was created during a 2022 residency at PRiSM. The piece marks the latest update to “Voyager,” a \npiece that he developed in 1985 and described as a, “virtual improvising pianist.” “Forager” enhances the software’s \nresponsiveness to its human co-performers with new programming that enables what he called, “a more holistic \nrecognition” of musical materials.\nThe differences among Dr. Schankler’s use of R.A.V.E., Robert Laidlow’s orchestral work “Silicon” and Lewis’s \ninteractive “Forager” underscore the nuances with which composers and experimental musicians are approaching \nA.I. This culture celebrates technology as means to customize musical ideas and computer-generated sounds to \nsuit specific performers and a given moment. Still, these artistic aims stand at odds with the foreboding prompted by \nothers like Dr. Tallon and Dr. Lumumba-Kasongo.\nIndividual musicians can do their part to counter those worries by using A.I. ethically and generatively. But even so, \nas Laidlow observed, being truly individual — which is to say independent — is difficult.\n“There is a fundamental problem of resources in this field,” Laidlow said. “It is almost impossible to create \nsomething computationally powerful without the assistance of a huge, technologically advanced institute or \ncorporation.”\nThis article appeared in print on page AR8.\nLoad-Date: June 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Can I Use ChatGPT for the Tedious Parts of My Job?; The Ethicist",
        "media": "The New York Times",
        "time": "July 7, 2023",
        "section": "MAGAZINE",
        "length": "1572 words",
        "byline": "Kwame Anthony Appiah",
        "story_text": "Can I Use ChatGPT for the Tedious Parts of My Job?; The Ethicist\nThe New York Times \nJuly 7, 2023 Friday 14:43 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: MAGAZINE\nLength: 1572 words\nByline: Kwame Anthony Appiah\nHighlight: The magazine’s Ethicist columnist on using artificial intelligence to assist with mundane tasks at work.\nBody\nThe magazine’s Ethicist columnist on using artificial intelligence to assist with mundane tasks at work.\nI’m a writer and a college professor at a small college, and I recently became chair of the English department. I \nusually love to write, but when it comes to administrative documents, I struggle — and this new role asks for a lot of \nthem.\nIt occurred to me that ChatGPT might prove useful for the reports, proposals, assessments and the like that take up \nthe precious time I could be devoting to students and my own scholarship. Is it OK to use ChatGPT to generate \ndrafts of documents like these, which don’t make a claim to creative “genius”? Do I need to cite ChatGPT in these \ndocuments if I use it? — Name Withheld\nFrom the Ethicist:\nMany administrative documents, though they may have signatories, aren’t thought of as original compositions. \nCertainly the documents you’re thinking about — annual reports, budget submissions and the like — tend to be \npretty templatized, and my sense is that people in your position often start with an earlier version from the \ndepartment’s files and adjust them with new information. In fact, some administrations provide chairs with such \ntemplates.\nWhat you would be doing with ChatGPT isn’t so different. For an annual report, you might prompt it with specifics \nabout job searches, departmental priorities, student concerns, revisions of the curriculum and so forth. The system \n— informed by a large number of models in the digital archives it trained on — would, with luck, incorporate your \ninput into a tidily organized, appropriately formatted memo. You would coach it with further prompts and then have \na draft that you could edit into shape. I see no reason that you shouldn’t start this way, provided you do the proper \nrevising and are confident that the final document says what you want it to say. Big departments at big universities \nmay employ half a dozen or more full-time administrators. Sometimes a departmental administrator is a dab hand at \ndrafting documents of this sort for the chair to review and revise, and doing the same with ChatGPT is fine — as \nlong as you exercise proper vigilance and can stand by what you submit. (We all know that ChatGPT can \n“hallucinate” facts.)\nI don’t think you are obliged to cite ChatGPT any more than you are obliged to say you started with last year’s \nannual report as a model. Academic writing is different; there are many reasons to acknowledge sources in work \nthat’s meant to be original. By contrast, your reports, as you note, are not being evaluated for their scholarly or \ncreative contributions. But if you do find yourself making good use of ChatGPT (or another such tool), it could be \nhelpful to discuss it with the deans of your college — they might want to suggest the idea to others. Rational \nadministrators, especially in the academy, should prize the careful allocation of intellectual creativity.\nCan I Use ChatGPT for the Tedious Parts of My Job? The Ethicist\nA Bonus Question\nI have developed a sophisticated GPT-4 prompt that has the potential to revolutionize a specific aspect of a \ntechnical workflow — one that is specific to a particular type of white-collar, knowledge-worker job. My prompt will \nmake these tasks more efficient, reducing the time required from weeks to mere minutes.\nA friend of mine, however, has a job that involves precisely this kind of work. Sharing and capitalizing on my \ncreation would very likely be financially rewarding for me, but I fear it could jeopardize my friend’s career and leave \nthis person struggling to find new professional opportunities.\nI am torn between the prospect of lucrative gains and the impact it may have on someone I care about. How should \nI proceed in this situation? — Matt S.\nFrom the Ethicist:\nFirst, is it really likely that nobody else will come up with a similarly effective prompt before long? When I consulted \nwith an expert on large language models (though not at OpenAI, which operates GPT-4), I was told that, depending \non how niche the field is, it may have already happened or it may happen in the coming months. In any event, it \nsurely won’t be long. What you’ve actually discovered, it seems, is that the current configuration of your friend’s job \nhas no future, and your staying mum won’t change that fact. Maybe your friend will be made redundant. Maybe (via \ntechniques like “few-shot prompting”) your friend’s expertise will lead to a new kind of work that’s conducted in \ncollaboration with A.I. tools. As his friend, you should discuss these realities with him.\nIssues like this arise with every major new technology. Should James Hargreaves, whose spinning jenny \nrevolutionized textile production in England in the 18th century, have junked his designs because he had friends \nwho were weavers? Should Henry Ford have stopped developing the mass-market car because he had friends in \nthe stabling business? As these examples should remind us, emerging technologies have created jobs as well as \ndestroyed them. (A recent survey of chief executives found that 43 percent had reduced or redeployed their work \nforce owing to generative A.I., while 46 percent had added workers.) In the past, smart people, like Bertrand \nRussell and John Maynard Keynes, thought that technology would create mass idleness, and they turned out to be \nwrong. John Henry is now in sales, busily leasing rock-drilling machines.\nMaybe — who knows? — this time will be different. Either way, the big costs of new technologies have been borne \nby people who have to switch to new jobs and gain new skills, especially when the switch lowers their income. \nCareers are typically structured by the expectation of a continuously rising income. Social policy needs to take \nseriously the problems that arise when that pattern doesn’t hold up. Even if generative A.I. does create more \nemployment and more wealth than it destroys, there will be human costs, and they will fall unevenly. The solution \nisn’t to stop innovating. One crucial innovation we need, though, is at the political and policy level — figuring out \nhow to make sure that everyone has the resources for a decent life. If you develop a prompt for that, let me know.\nReaders Respond\nThe previous column’s question was from a reader whose sister asked her to sell three extra concert tickets to the \nTaylor Swift Eras tour that she purchased for $130 each. She wrote: “[My sister] asked me to post them in a large \nManhattan-moms Facebook group I am a member of for $2,400 each or best offer. I acknowledged that this was a \nbonkers price for these seats, but cheaper than the current market. We thought this was a win-win as people could \ngo to the concert for less than they would pay through a ticket site, and we wouldn’t have to pay seller’s fees. … Do \nI owe strangers “reasonable” resale values?”\nIn his response, the Ethicist noted: “The only reason you can resell a ticket at many times the original price is that \nthe artist had decided to offer them for less than she could get, and so make them affordable to fans of more \nmodest means. When people, or their army of bots, buy those lower-priced tickets in order to resell them, they’re \nabusing that restraint. … That’s the case against Swift scalpers. But your sister didn’t buy these tickets to resell \nthem. She just wound up with three she can’t use and had to distribute them somehow. … Besides, if the \nManhattan moms didn’t like the price, all they had to do was not pay it. That’s how markets work. The trouble is that \nCan I Use ChatGPT for the Tedious Parts of My Job? The Ethicist\nsome members of this Facebook group, it seems, don’t think it’s an arena where market values should operate. As \na member of the group, you should consider whether they’re entitled to this feeling — or whether they should shake \nit off.” (Reread the full question and answer here.)\n￿\nThe Ethicist’s answer was well put. The only thing this ticket seller did wrong was to offer any discount whatsoever. \nThere is nothing wrong with exchanging goods at their current market value. In fact, there might be even more \nethically at risk by offering special deals to certain types of people (Manhattan moms on Facebook) and not others. \n— Alex\n￿\nThis fortunate family was able to purchase tickets when countless others were not, solely because of luck. They \nnow want to profit from this fortune, which our capitalist economy allows. That is their right, but the Manhattan-\nmoms Facebook group — a place where we consider ourselves neighbors, if not friends — is not the place to do it. \n— Eileen\n￿\nIn my opinion, considering market price for a high-demand item for tweens requires a buffer, or mitigating wisdom. \nThis price is way beyond the real value for a concert ticket. You join the soulless in this scenario. Congratulations, \neveryone does it and you can make some money on the backs of mothers. Yikes. — Kim\n￿\nBasically, I agree with the Ethicist’s response, but I have one further thought: If one charged a high price for the \nconcert tickets to prevent future resale by whoever ends up buying them, why not donate this additional profit or at \nleast a good fraction of it to a charity? — James\n￿\nIf these Taylor Swift tickets were meant to be affordable to a wider range of fans, then, ethically, it seems they \nshould be used by those who could only afford the moderately priced tickets. To avoid another hiked price resale, \nthe owner of the tickets could offer them at the original price to the friends of her megafan daughter. It’s a win-win, I \nbelieve. — Mary Ellen\nPHOTO:  (PHOTOGRAPH BY Illustration by Tomi Um FOR THE NEW YORK TIMES)\nLoad-Date: July 7, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2023",
        "header": "What's the future for A.I.?",
        "media": "The New York Times",
        "time": "April 8, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 7; ON TECH: A.I. NEWSLETTER",
        "length": "1679 words",
        "byline": "By Cade Metz",
        "story_text": "What's the future for A.I.?\nThe New York Times\nApril 8, 2023 Saturday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 7; ON TECH: A.I. NEWSLETTER\nLength: 1679 words\nByline: By Cade Metz\nBody\nWhere we're heading tomorrow, next year and beyond.\nIn today's A.I. newsletter, the last in our five-part series, I look at where artificial intelligence may be headed in the \nyears to come.  \n  In early March, I visited OpenAI's San Francisco offices for an early look at GPT-4, a new version of the \ntechnology that underpins its ChatGPT chatbot. The most eye-popping moment arrived when Greg Brockman, \nOpenAI's president and co-founder, showed off a feature that is still unavailable to the public: He gave the bot a \nphotograph from the Hubble Space Telescope and asked it to describe the image ''in painstaking detail.''\n  The description was completely accurate, right down to the strange white line created by a satellite streaking \nacross the heavens. This is one look at the future of chatbots and other A.I. technologies: A new wave of \nmultimodal systems will juggle images, sounds and videos as well as text.\n  Yesterday, my colleague Kevin Roose told you about what A.I. can do now. I'm going to focus on the opportunities \nand upheavals to come as it gains abilities and skills.\n  A.I. in the near term\n  Generative A.I.s can already answer questions, write poetry, generate computer code and carry on \nconversations. As ''chatbot'' suggests, they are first being rolled out in conversational formats like ChatGPT and \nBing.\n  But that's not going to last long. Microsoft and Google have already announced plans to incorporate these A.I. \ntechnologies into their products. You'll be able to use them to write a rough draft of an email, automatically \nsummarize a meeting and pull off many other cool tricks.\n  OpenAI also offers an A.P.I., or application programming interface, that other tech companies can use to plug \nGPT-4 into their apps and products. And it has created a series of plug-ins from companies like Instacart, Expedia \nand Wolfram Alpha that expand ChatGPT's abilities.\n  A.I. in the medium term\n  Many experts believe A.I. will make some workers, including doctors, lawyers and computer programmers, more \nproductive than ever. They also believe some workers will be replaced.\nWhat's the future for A.I.?\n  ''This will affect tasks that are more repetitive, more formulaic, more generic,'' said Zachary Lipton, a professor at \nCarnegie Mellon who specializes in artificial intelligence and its impact on society. ''This can liberate some people \nwho are not good at repetitive tasks. At the same time, there is a threat to people who specialize in the repetitive \npart.''\n  Human-performed jobs could disappear from audio-to-text transcription and translation. In the legal field, GPT-4 is \nalready proficient enough to ace the bar exam, and the accounting firm PricewaterhouseCoopers plans to roll out \nan OpenAI-powered legal chatbot to its staff.\n  At the same time, companies like OpenAI, Google and Meta are building systems that let you instantly generate \nimages and videos simply by describing what you want to see.\n  Other companies are building bots that can actually use websites and software applications as a human does. In \nthe next stage of the technology, A.I. systems could shop online for your Christmas presents, hire people to do \nsmall jobs around the house and track your monthly expenses.\n  All that is a lot to think about. But the biggest issue may be this: Before we have a chance to grasp how these \nsystems will affect the world, they will get even more powerful.\n  A.I. in the long term\n  For companies like OpenAI and DeepMind, a lab that's owned by Google's parent company, the plan is to push \nthis technology as far as it will go. They hope to eventually build what researchers call artificial general intelligence, \nor A.G.I. -- a machine that can do anything the human brain can do.\n  As Sam Altman, OpenAI's chief executive, told me three years ago: ''My goal is to build broadly beneficial A.G.I. I \nalso understand this sounds ridiculous.'' Today, it sounds less ridiculous. But it is still easier said than done.\n  For an A.I. to become an A.G.I., it will require an understanding of the physical world writ large. And it is not clear \nwhether systems can learn to mimic the length and breadth of human reasoning and common sense using the \nmethods that have produced technologies like GPT-4. New breakthroughs will probably be necessary.\n  The question is, do we really want artificial intelligence to become that powerful? A very important related \nquestion: Is there any way to stop it from happening?\n  The risks of A.I.\n  Many A.I. executives believe the technologies they are creating will improve our lives. But some have been \nwarning for decades about a darker scenario, where our creations don't always do what we want them to do, or \nthey follow our instructions in unpredictable ways, with potentially dire consequences.\n  A.I. experts talk about ''alignment'' -- that is, making sure A.I. systems are in line with human values and goals.\n  Before GPT-4 was released, OpenAI handed it over to an outside group to imagine and test dangerous uses of the \nchatbot.\n  The group found that the system was able to hire a human online to defeat a Captcha test. When the human \nasked if it was ''a robot,'' the system, unprompted by the testers, lied and said it was a person with a visual \nimpairment.\n  Testers also showed that the system could be coaxed into suggesting how to buy illegal firearms online and into \ndescribing ways to make dangerous substances from household items. After changes by OpenAI, the system no \nlonger does these things.\n  But it's impossible to eliminate all potential misuses. As a system like this learns from data, it develops skills that \nits creators never expected. It is hard to know how things might go wrong after millions of people start using it.\nWhat's the future for A.I.?\n  ''Every time we make a new A.I. system, we are unable to fully characterize all its capabilities and all of its safety \nproblems -- and this problem is getting worse over time rather than better,'' said Jack Clark, a founder and the head \nof policy of Anthropic, a San Francisco start-up building this same kind of technology. \n  And OpenAI and giants like Google are hardly the only ones exploring this technology. The basic methods used to \nbuild these systems are widely understood, and other companies, countries, research labs and bad actors may be \nless careful.\n  The remedies for A.I.\n  Ultimately, keeping a lid on dangerous A.I. technology will require far-reaching oversight. But experts are not \noptimistic.\n  ''We need a regulatory system that is international,'' said Aviv Ovadya, a researcher at the Berkman Klein Center \nfor Internet & Society at Harvard who helped test GPT-4 before its release. ''But I do not see our existing \ngovernment institutions being about to navigate this at the rate that is necessary.''\n  As we told you earlier this week, more than 1,000 technology leaders and researchers, including Elon Musk, have \nurged artificial intelligence labs to pause development of the most advanced systems, warning in an open letter that \nA.I. tools present ''profound risks to society and humanity.''\n  A.I. developers are ''locked in an out-of-control race to develop and deploy ever more powerful digital minds that \nno one -- not even their creators -- can understand, predict or reliably control,'' according to the letter.\n  Some experts are mostly concerned about near-term dangers, including the spread of disinformation and the risk \nthat people would rely on these systems for inaccurate or harmful medical and emotional advice.\n  But other critics are part of a vast and influential online community called rationalists or effective altruists, who \nbelieve that A.I could eventually destroy humanity. This mind-set is reflected in the letter.\n  Please share your thoughts and feedback on our On Tech: A.I. series by taking this brief survey. \n  Your homework\n  We can speculate about where A.I. is going in the distant future -- but we can also ask the chatbots themselves. \nFor your final assignment, treat ChatGPT, Bing or Bard like an eager young job applicant and ask it where it sees \nitself in 10 years. As always, share the answers in the comments.\n  Quiz\n  Question 1 of 3\n  What feature did OpenAI demonstrate with GPT-4 that is not yet available to the public?\n  Translating text into multiple languages\n  Generating realistic images based on text descriptions\n  Passing the bar exam with its legal text proficiency\n  Start the quiz by choosing your answer.\n  Glossary\n  Alignment: Attempts by A.I. researchers and ethicists to ensure that artificial intelligences act in accordance with \nthe values and goals of the people who create them.\nWhat's the future for A.I.?\n  Multimodal systems: A.I.s similar to ChatGPT that can also process images, video, audio, and other non-text \ninputs and outputs.\n  Artificial general intelligence: An artificial intelligence that matches human intellect and can do anything the human \nbrain can do.\n  Click here for more glossary terms.\n  Farewell\n  Kevin here. Thank you for spending the past five days with us. It's been a blast seeing your comments and \ncreativity. (I especially enjoyed the commenter who used ChatGPT to write a cover letter for my job.)\n  The topic of A.I. is so big, and fast-moving, that even five newsletters isn't enough to cover everything. If you want \nto dive deeper, you can check out my book, ''Futureproof,'' and Cade's book, ''Genius Makers,'' both of which go \ninto greater detail about the topics we've covered this week.\n  Cade here: My favorite comment came from someone who asked ChatGPT to plan a route through the trails in \ntheir state. The bot ended up suggesting a trail that did not exist as a way of hiking between two other trails that do. \n  This small snafu provides a window into both the power and the limitations of today's chatbots and other A.I. \nsystems. They have learned a great deal from what is posted to the internet and can make use of what they have \nlearned in remarkable ways, but there is always the risk that they will insert information that is plausible but untrue. \nGo forth! Chat with these bots! But trust your own judgment too!\n  Please take this brief survey to share your thoughts and feedback on this limited-run newsletter.\nhttps://www.nytimes.com/2023/03/31/technology/ai-chatbots-benefits-dangers.html\nGraphic\n \nThis article appeared in print on page B7.               \nLoad-Date: April 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "Axios Sees A.I. Coming, and Shifts Its Strategy",
        "media": "The New York Times",
        "time": "April 12, 2024",
        "section": "BUSINESS; media",
        "length": "890 words",
        "byline": "Katie Robertson Katie Robertson covers the media industry for The Times. Email: ,",
        "story_text": "Axios Sees A.I. Coming, and Shifts Its Strategy\nThe New York Times \nApril 11, 2024 Thursday 11:35 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; media\nLength: 890 words\nByline: Katie Robertson Katie Robertson covers the media industry for The Times. Email: , \nkatie.robertson@nytimes.com\nHighlight: “The premium for people who can tell you things you do not know will only grow in importance, and no \nmachine will do that,” says Jim VandeHei, C.E.O. of Axios.\nBody\n“The premium for people who can tell you things you do not know will only grow in importance, and no machine will \ndo that,” says Jim VandeHei, C.E.O. of Axios.\nIn the view of Jim VandeHei, the chief executive of Axios, artificial intelligence will “eviscerate the weak, the \nordinary, the unprepared in media.”\nThe rapid rise of generative A.I. — and its implications for how people will discover and consume news — has \nunsettled many media executives. Like them, Mr. VandeHei has spent the past year or so pondering how to \nrespond.\nNow he’s becoming one of the first news executives to adjust their company’s strategy because of A.I.\nMr. VandeHei says the only way for media companies to survive is to focus on delivering journalistic expertise, \ntrusted content and in-person human connection. For Axios, that translates into more live events, a membership \nprogram centered on its star journalists and an expansion of its high-end subscription newsletters.\n“We’re in the middle of a very fundamental shift in how people relate to news and information,” he said, “as \nprofound, if not more profound, than moving from print to digital.”\n“Fast forward five to 10 years from now and we’re living in this A.I.-dominated virtual world — who are the couple of \nplayers in the media space offering smart, sane content who are thriving?” he added. “It damn well better be us.”\nAxios is pouring investment into holding more events, both around the world and in the United States. Mr. VandeHei \nsaid the events portion of his business grew 60 percent year over year in 2023.\nThe company has also introduced a $1,000-a-year membership program around some of its journalists that will \noffer exclusive reporting, events and networking. The first one, announced last month, is focused on Eleanor \nHawkins, who writes a weekly newsletter for communications professionals. Her newsletter will remain free, but \npaying subscribers will have access to additional news and data, as well as quarterly calls with Ms. Hawkins.\nMembership programs will next be built around Sara Fischer, a media reporter, and the business editor Dan \nPrimack, who writes the daily Pro Rata newsletter, according to a person familiar with the company’s plans.\n“I’m trying to align the company with the people who have a ton of talent: They thrive, we thrive,” Mr. VandeHei \nsaid.\nAxios Sees A.I. Coming, and Shifts Its Strategy\nAxios will expand Axios Pro, its collection of eight high-end subscription newsletters focused on specific niches in \nthe deals and policy world. The subscriptions start at $599 a year each, and Axios is looking to add one on defense \npolicy. The company just hired an executive, Danica Stanciu, to oversee the expansion into more policy areas. Ms. \nStanciu was instrumental in growing Politico Pro, Politico’s premium subscription offering, into a thriving business.\n“The premium for people who can tell you things you do not know will only grow in importance, and no machine will \ndo that,” Mr. VandeHei said.\nPart of the pivot entails a restructuring of Axios’s leadership team. Sara Kehaulani Goo, the editor in chief of the \nAxios newsroom, will head up the editorial side of events and running new platforms. Aja Whitaker-Moore, the \nexecutive editor of the newsroom, will be promoted to editor in chief and will oversee all published content.\n“I hope the next leg of this journey can really be focused on how we take the subject matter expertise to the next \nlevel,” she said.\nAxios was started in 2017 by Mr. VandeHei, a co-founder of Politico, along with Mike Allen and Roy Schwartz. In \nAugust 2022, Cox Enterprises acquired Axios in a deal that valued the company at $525 million, with its founders \nstaying on as minority shareholders.\nMr. VandeHei said Axios was not currently profitable because of the investment in the new businesses. The \ncompany has continued to hire journalists even as many other news organizations have cut back. An Axios \nspokeswoman said that Axios Local now had nearly two million subscribers across 30 newsletters, and that Axios’s \nnational newsletters had about 1.5 million.\nIn addition to figuring out how A.I. could change news consumption by the public, many media companies are \nracing to figure out how to address the ingestion of their content by A.I. chatbots. The New York Times, for \nexample, sued Microsoft and OpenAI in December for copyright infringement, arguing that millions of articles were \nused, without authorization, to train the tech companies’ chatbots.\nMr. VandeHei said that while he thought publications should be compensated for original intellectual property, \n“that’s not a make-or-break topic.” He said Axios had talked to several A.I. companies about potential deals, but \n“nothing that’s imminent.”\n“One of the big mistakes a lot of media companies made over the last 15 years was worrying too much about how \ndo we get paid by other platforms that are eating our lunch as opposed to figuring out how do we eat people’s lunch \nby having a superior product,” he said.\nPHOTOS: Part of the pivot for the chief executive Jim VandeHei, at left, entails a restructuring of the Axios \nleadership team, which will include, above left to right: Aja Whitaker-Moore, who will be editor in chief, and Sara \nKehaulani Goo, who will head up the editorial side of events and running new platforms. (PHOTOGRAPHS BY \nJARED SOARES FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: April 12, 2024"
    },
    {
        "file_name": "DealBook_Newsletter_Jul2023",
        "header": "What the Microsoft-Activision Ruling Means for the Future of Deal-Making;",
        "media": "DealBook Newsletter",
        "time": "July 12, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1973 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch",
        "story_text": "What the Microsoft-Activision Ruling Means for the Future of Deal-Making; \nDealBook Newsletter\nThe New York Times \nJuly 12, 2023 Wednesday 16:26 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1973 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Bernhard Warner, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch \nand Ephrat Livni\nHighlight: Corporate leaders are feeling emboldened by another legal defeat for the Federal Trade Commission, \nthough the agency may still fight to block the takeover.\nBody\nCorporate leaders are feeling emboldened by another legal defeat for the Federal Trade Commission, though the \nagency may still fight to block the takeover.\nA reckoning for Lina Khan\nA federal judge’s decision to let Microsoft close its $70 billion takeover of the video game maker Activision Blizzard \ndidn’t just represent a win for the tech giant. It’s also a major blow to the F.T.C., which had sought to block the \ntransaction.\nThat leaves Lina Khan, the agency’s chief and a proponent of more expansive antitrust regulation, confronting a \ndifficult question: Is her strategy of aggressively fighting mergers backfiring and actually encouraging more \ndealmaking?\nMicrosoft is close to clinching the deal. In her 53-page ruling, Judge Jacqueline Scott Corley wrote that the F.T.C. \nhad failed to show that Microsoft buying the maker of Call of Duty would substantially reduce competition in the \nvideo game market.\nIn further good news for Microsoft, Britain’s Competition and Markets Authority — the last remaining regulator \nopposed to the transaction — said on Tuesday that it was now willing to hear settlement proposals from the \ncompany. That means the Activision deal, the largest tech acquisition ever, could close as soon as next week. (The \ntransaction’s deadline is July 18.)\nTuesday’s ruling was the latest setback for Ms. Khan’s F.T.C., which abandoned a fight earlier this year against \nMeta’s purchase of a virtual reality start-up. And last fall, the F.T.C. suffered a defeat on what it had assumed was \nfriendlier ground: A judge in its own administrative court rejected the regulator’s argument that the gene-sequencing \ncompany Illumina’s $7 billion takeover of Grail, a cancer-detection specialist, was unlawful.\nMs. Khan is unlikely to change course, at least for now. The F.T.C. could appeal Judge Corley’s decision as soon \nas Wednesday. Its argument may revolve around what Robert Lande, a professor at the University of Baltimore \nSchool of Law, told DealBook was the judge’s reliance on an erroneous legal standard about the likelihood of \nreduced competition.\nWhat the Microsoft - Activision Ruling Means for the Future of Deal-Making DealBook Newsletter\nAnd Eleanor Fox, a professor at N.Y.U. School of Law, told The Times that Ms. Khan’s more expansive approach \nwas more in line with what regulators in Europe and Britain are doing. (That said, E.U. officials cleared the \nActivision deal in May.)\nBut skeptics say the F.T.C. is in a weaker position. One corporate adviser told DealBook that the agency’s losses \nwere strengthening the boundaries of existing antitrust jurisprudence. “Khan is trying to do very ambitious things \nagainst very entrenched ideology,” Anu Bradford of Columbia Law School told DealBook. “This ruling suggests that \ncourts may not be ready.”\nDealmakers are feeling increasingly emboldened. Executives and advisers told DealBook that companies are \nwilling to roll the dice when it comes to ambitious deals. (Of course, they cautioned, it all depends on each \nsituation’s circumstances.)\nMany still see the F.T.C. suing to block big transactions, but they believe the agency’s repeated losses mean they \nstand a better chance of winning in court.\n• In other antitrust news: E.U. regulators fined Illumina 432 million euros ($476 million) for closing its Grail deal \nwithout obtaining Brussels’ approval. They’re also reportedly poised to approve Broadcom’s $69 billion \ntakeover of the cloud software maker VMware.\nHERE’S WHAT’S HAPPENING \nBank of America is fined $150 million. Federal regulators accused the lending giant of withholding promised perks \nfrom credit card customers, double-charging overdraft fees and opening card accounts in customers’ names without \ntheir knowledge or consent. The penalty reflects in part the Biden administration’s effort to punish companies over \nwhat it calls “junk fees” that it says hurt consumers.\nSenators will scrutinize the prospect of more bank mergers. The Senate Banking Committee will hold a hearing on \nWednesday on the issue, in light of the chaos wrought by Silicon Valley Bank’s collapse this spring. Treasury \nSecretary Janet Yellen has suggested more mergers could strengthen the banking system; Senator Elizabeth \nWarren, a prominent Democratic member of the committee, is skeptical of the argument.\nAnother big insurer pulls out of Florida. Farmers said it would stop offering coverage in the state, ending about \n100,000 policies, citing a need to “manage risk exposure.” It’s the fourth insurance provider to curtail its business in \nFlorida as the state battles more natural disasters amid climate change.\nTesla reportedly investigates a company-funded house for Elon Musk. Known internally as “Project 42,” the \nproposal called for an expansive glass-walled structure near the electric carmaker’s Texas headquarters, according \nto The Wall Street Journal. Board members scrutinized the plan to see if company money was misused, though The \nJournal said the outcome of the project and the inquiry couldn’t be determined.\nLifting the lid on the PGA-LIV talks \nThe PGA Tour came under fire on Tuesday in a Senate hearing over its proposed deal involving LIV Golf, its Saudi \nArabia-backed rival. The deal could see the kingdom pour more than $1 billion into the sport, but the agreement has \nbeen slammed by lawmakers, and the Justice Department is expected to examine it.\nHere are key takeaways from the hearing and documents released by the Senate:\nThe deal was announced before it was done. Jimmy Dunne, the investment banker and PGA Tour director who \nhelped orchestrate it, said the “rollout was very misleading and inaccurate, which is everyone’s fault.” He said no \nmerger had been agreed upon.\nMichael Klein, the veteran dealmaker and an adviser to Saudi Arabia, pushed the two sides to release information, \naccording to the documents. “The announcement is too big to wait till the definitive. If we don’t put the messages \nWhat the Microsoft - Activision Ruling Means for the Future of Deal-Making DealBook Newsletter\nout others will fill in,” he wrote to the parties involved in an email. “The worst thing we can do is have naysayers \nlead the chorus.”\nThe PGA Tour felt it had no choice. Mr. Dunne and the tour’s chief operating officer, Ron Price, told the hearing that \nthe billions behind LIV made it impossible for the PGA Tour to fight back indefinitely. The wealth fund wanted “to \ndestroy the tour,” Mr. Dunne said, and is backed by “an unlimited horizon and an unlimited amount of money.”\nThe dealmakers defended keeping the board and players in the dark. “We were really afraid that once the other \nside’s lawyers learned anything about it, it would be poof, gone,” said Mr. Dunne, who was one of the main \nnegotiators along with Ed Herlihy, a partner at Wachtell and a fellow director.\nThe PGA Tour executives were given a list of people and sponsors to call on the day the deal was announced. Top \nof the order for Jay Monahan, the tour commissioner: Rory McIlroy, a director and one of the most vocal critics of \nLIV Golf, and Tiger Woods. One proposal floated the idea of the two players owning LIV teams.\nExclusive memberships for a top Saudi official were proposed. The Saudi wealth fund raised the idea that Yasir al-\nRumayyan, its governor, could get memberships at Augusta National Golf Club and the Royal and Ancient Golf \nClub of St. Andrews as part of the deal. Neither of the clubs is controlled by the PGA Tour, but both Mr. Dunne and \nMr. Herlihy are members at Augusta.\nThe key question: governance. Mr. Dunne reiterated that the PGA Tour would still be in charge, despite the Saudi \nmoney. “What I can tell you is that the tour will continue to manage the game,” he said. “The tour will appoint a \nmajority of the board of directors.”\n“The endgame is to allow things to drag on until union members start losing their apartments and losing their \nhouses.” \n— An unnamed studio executive who told Deadline that Hollywood is planning to let the weekslong writers’ union \nstrike continue into the fall, inflicting economic pain. Actors could join the writers on the picket line as a midnight \ndeadline looms.\nTech giants face new A.I. cases \nChatbots and generative artificial intelligence have captured the public’s imagination, with the technology’s \nbiggest proponents saying it could add trillions in economic value over the next decade. It is also spawning lawsuits \nthat pose vexing new issues for courts and companies.\nOn Tuesday, Google was sued in a putative class action in federal court in California that accused the company of \nviolating privacy laws and committing “ongoing theft” by scraping internet users’ online data to train its chatbot \nwithout their consent. The Google case, and a parallel one filed last month against Microsoft and OpenAI, the \nmaker of ChatGPT, demands that the tech companies compensate internet users for this data appropriation.\nThe cases represent “an evolution of people’s understanding of the value of data,” said Tracey Cowan, a partner at \nClarkson, which filed the suits. People increasingly understand that their internet footprint — think posts and likes — \nholds economic value to tech companies. In the social media economy, an industry of data brokers emerged to buy \nand sell such data. In the A.I. age, similar data is being used to train new generative A.I. tools.\nFor this reason and others, tech executives themselves, including OpenAI’s C.E.O., Sam Altman, have called on \nlawmakers to regulate A.I. in recent months.\nThe suits go a step further, adding to the public cries for a temporary halt to the commercialization of A.I. pending \nthe development of guidelines. “We are all just guinea pigs in their experiment,” said Ryan Clarkson, a partner at \nthe firm. In the meantime, the suits call for letting users opt out, so they can better control how tech firms use their \ndata.\nWhat the Microsoft - Activision Ruling Means for the Future of Deal-Making DealBook Newsletter\n“We’ve been clear for years that we use data from public sources — like information published to the open web and \npublic datasets — to train the A.I. models behind services like Google Translate, responsibly and in line with our A.I. \nPrinciples,” said Halimah DeLaine Prado, general counsel at Google. “American law supports using public \ninformation to create new beneficial uses, and we look forward to refuting these baseless claims.” Microsoft \ndeclined to comment; OpenAI did not respond.\nThe comedian Sarah Silverman has also joined the A.I. litigation fray, signing onto separate litigation against \nOpenAI and Meta for copyright infringement. She is the latest big-name creator demanding that A.I. companies that \nuse their intellectual property first license it.\nTHE SPEED READ \nDeals\n• ByteDance, the parent company of TikTok, is reportedly letting American employees cash out their shares in \nthe Chinese tech giant ahead of any I.P.O. (Reuters)\n• Nvidia is said to be in talks to become a cornerstone investor in the forthcoming I.P.O. of Arm, the British chip \ndesigner. (FT)\n• The tech mogul Sam Altman plans to merge Oklo, a nuclear energy start-up he has backed, with a blank-\ncheck vehicle he created, taking the company public. (WSJ)\n• Disney is reportedly weighing a sale of its Star India business, amid growing losses at the division after it lost \nthe streaming rights to Indian Premier League cricket matches. (WSJ)\nPolicy\n• Chinese hackers broke into several U.S. government email accounts to gain access to sensitive information, \naccording to Microsoft. (NYT)\n• “The new era of big government: Biden rewrites the rules of economic policy” (FT)\nBest of the rest\n• “How a Houston Oilman Confounded Climate Activists and Made Billions” (WSJ)\n• “How to Revive a Dying Main Street? One U.K. Landlord Offered Free Rent.” (NYT)\n• A handwritten document found under a couch cushion is Aretha Franklin’s true will, a jury ruled, potentially \nresolving a bitter dispute over the singer’s estate. (NYT)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Lina Khan, the F.T.C. chair, faces a big setback in her crackdown on Big Tech. (PHOTOGRAPH BY Tom \nWilliams/CQ-Roll Call, via Getty Images FOR THE NEW YORK TIMES)\nLoad-Date: July 12, 2023"
    },
    {
        "file_name": "executive_Mar2023",
        "header": "AMD says data centre business solutions come from India unit, says senior",
        "media": "executive",
        "time": "March 7, 2023",
        "section": "TECH & INTERNET",
        "length": "435 words",
        "byline": "Romita Majumdar",
        "story_text": "AMD says data centre business solutions come from India unit, says senior \nexecutive\nThe Economic Times\nMarch 8, 2023 Wednesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 435 words\nByline: Romita Majumdar\nBody\nCalifornia-based semiconductor firm Advanced Micro Devices' (AMD) India arm contributes nearly 100% of the \nsolutions to its data centre business, a senior executive said.AMD's data centre business posted over $6 billion in \nrevenue during 2022. The business comprises 25% of the organization's total revenue of $23.6 billion.The data \ncentre business includes server microprocessors (CPUs) and graphics processing units (GPUs), data processing \nunits (DPUs), Field Programmable Gate Arrays (FPGAs) and Adaptive System-on-Chip (SoC) products for data \ncentres.\"Without India operations, every major product and design offering will be impacted. Xilinx and Pensando \nassociates from India have also significantly contributed,\" said Forrest Norrod, AMD executive vice president and \ngeneral manager, data centre solutions business unit.Norrod said that due to the current geopolitical uncertainty, \nmany customers prefer computing solutions built in specific geographies, which has also benefited the India \noperations.\"I would say roughly, you know, give or take a percentage point, roughly 100% of that $6 billion was \ntouched by the India teams in a material way,\" Norrod said.The recent acquisitions of Xilinx and Pensando \nbusinesses have also helped it bring more talent on board. The company has over 6,000 associates in India, or \naround 25% of its global workforce.It added around 2,000 employees through the Xilinx acquisition and 100 from \nPensando, Norrod added.\"...India team owns two important pieces in the development of our server processors - \nthe Cores team, led by Jaya Jagadish owns the CPU core development, and the CPU Software team led by Jay \nHiremath has the complete ownership of CPU software development and the platform engineering piece,\" he \nsaid.Norrod was promoted to executive vice president and general manager of the data centre solutions business \ngroup at AMD in January.Global macroeconomic concerns, persistent supply chain issues and geopolitical tensions \nhave made it pertinent for companies to look at a diversified supply base where India plays an important role.\"We \nprimarily partner with TSMC, but also with other manufacturers. \nBut we don't specifically direct the placement of anybody's semiconductor manufacturing facilities. I do think, in \ngeneral, the larger the concentration of design talent in a geography - it makes it an attractive proposition,\" he \nadded.Within the overall demand for AI solutions, and driven by the popularity of generative AI, Norrod believes \nthere is an opportunity in building domain-specific large computing solutions. For Reprint Rights: timescontent.com\nLoad-Date: March 7, 2023"
    },
    {
        "file_name": "USA_Today_Online_Dec2023",
        "header": "Scientists say AI is emerging as potential tool to aid athletes, beat drug tests",
        "media": "USA Today Online",
        "time": "December 13, 2023",
        "section": "SPORTS: ATHLETICS NEWS",
        "length": "878 words",
        "byline": "Josh Peter, USA TODAY",
        "story_text": "Scientists say AI is emerging as potential tool to aid athletes, beat drug tests\nUSA Today Online\nDecember 12, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: SPORTS: ATHLETICS NEWS\nLength: 878 words\nByline: Josh Peter, USA TODAY\nBody\nLink to Image\nWith the 2024 Paris Olympics set to begin in July, a professor of computer science at MIT is convinced something \nelse is already underway.\nThe creation of undetectable performance-enhancing drugs (PEDs) with the help of Artificial Intelligence (AI).\n“I’m 100 percent sure that if they’re in that business (of doping), they’re using it,’’ said Manolis Kellis, the MIT \nprofessor who is a member of the computer science and artificial intelligence lab at the university. “If I were in the \ndoping business, I would be crazy not to use generative AI right now.’’\nUnlike traditional AI, which follows \"predefined rules and patterns,\" generative AI creates \"new and original \ncontent.'' Content that could possibly include PEDs, according to Anne Carpenter, senior director of the imaging \nplatform at Broad Institute of MIT and Harvard.\n“I would say it’s practical now to attempt it,'' Carpenter said. But she also said there are significant hurdles, \nsuggesting AI is still developing as a potential tool for cheating in sports.\nLink to Image\nThe use of AI for drug discovery is no longer a pipedream. The unanswered question: How soon might AI be \nembraced by athletes looking for new ways to cheat? \nHow would AI work to help athletes cheat?\nThe most feasible approach would be using generative AI to alter existing PEDs that trigger drug tests in a way \nthat makes those drugs undetectable by current testing technology, according to Kellis, the MIT professor. He said \nit would be used to study molecular structure of the existing PEDs and determine what other molecules could be \nused to alter them.  \nHe compared the process to what often happens after a pharmaceutical company comes out with a highly effective \ndrug. Competitors attempt to create their own version of the drug by altering an atom or two to evade patents — just \nlike AI would help alter the molecular structure of an existing PED just enough to evade detection by drug tests, \nKellis said.\nLink to Image\nScientists say AI is emerging as potential tool to aid athletes, beat drug tests\nThere is skepticism in the scientific community about whether AI is being used for pharmacological purposes in \nsports. Some of the reasons: No existing peer review of studies or research, the extensive testing required to prove \nsafety and the focus on finding drugs for current incurable diseases.\nBut Lei Xie, a professor at Hunter College in New York who has used AI for the potential discovery of drugs for \nincurable diseases, said the process that would be used to alter existing PEDs is one reason he would not be \nsurprised if it is happening now.\n\"It is similar to drug repurposing (repositioning), which we have worked on for years,'' Xie wrote to USA TODAY \nSports by email.\nCan AI be used to create PEDs?\nCarpenter, the senior director of the imaging platform at Broad Institute of MIT and Harvard, said she sees the \npotential for AI to help create undetectable PEDs rather than relying on existing PEDs.\n\"It’s not like this is futuristic technology,'' she said. \nBut Carpenter estimated it would cost $1 billion and take 10 years to develop a PED with the required testing for \nFDA approval. Referring to the process of drug development, she said, “It’s not like you put data in one end and get \ndrugs out the other side.\"\nBut there is evidence indicating the process of drug discovery can be accelerated. \nAlán Aspuru-Guzik, a professor of chemistry and computer science at the University of Toronto, helped lead a team \nin 2022 that in 30 days discovered a “lead candidate’’ for a potential liver cancer drug. The feat was hailed for \nenhanced speed in the development of drugs with the use of AI.\n\"The issue about performance-enhancement is that unlike traditional drugs, the clinical trials would not be so easy \nto make happen,'' Aspuru-Guzik wrote by email. \"I would not recommend generating (and testing) new drugs \nwithout a fully developed clinical trial.\n\"Having said so, yes, it may be possible for rogue agents to develop such drugs. Could they be not detectable by \ntraditional tests? Sure.\"\nLink to Image\nCan AI work against dopers?\nWADA (World Anti-Doping Agency) has explored the use of AI as a tool to catch cheaters. Its use is inevitable, \naccording to Dajiang Liu, director of artificial intelligence and biomedical informatics at the Penn State College of \nMedicine.\n“More powerful AI algorithms will lead to drugs that are more difficult to be detected,’’ Liu wrote by email. \"... As you \nmay be aware, there is often a gap between the development of a new drug and testing procedures that can detect \nthat. It is not surprising to me that such gap would happen to new AI-enabled drugs. At the same time, AI-driven \ntechnologies will also accelerate the development of testing procedures to identify drug use.’’\nBut that hasn't stopped people in sports from moving forward with use of the technology, according to Aron \nD'Souza, an attorney and entrepreneur who’s trying to organize an international sports event where athletes will not \nbe subject to drug testing. He said scientists and doctors involved in AI and PEDs have approached him about \nfunding their projects.\nSaid D'Souza: \"There will be many new performance-enhancing compounds discovered in the coming years.''\nScientists say AI is emerging as potential tool to aid athletes, beat drug tests\nThis article originally appeared on USA TODAY: Scientists say AI is emerging as potential tool to aid athletes, beat \ndrug tests\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "Pre-Crime Fighting, Key Techaways",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 4, 2023",
        "section": "BREAKING IDEAS",
        "length": "875 words",
        "byline": "Anil Nair",
        "story_text": "Pre-Crime Fighting, Key Techaways\nEconomic Times (E-Paper Edition)\nNovember 4, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 875 words\nByline: Anil Nair\nBody\nSteven Spielberg’s 2002 science fiction film, Minority Report, set in the US of 2054, showcases a system that can \npredict crimes, enabling arrests even before the infraction takes place. In real life today, advances in the use of \ntechnology to stop crime are not quite there, but we are progressing rapidly. Take the case of Indian Railways. \nMumbai improved its infraction detection rate from 15% (January-August 2019) to 40% in the same period in 2023, \nwhile the quantum of cases increased. \nUsing a facial recognition system, anterior landmarks like the distance between the eyes are captured and stored in \na database. When a repeat offender enters a station and the system finds a match, it alerts the patrolling staff. \nCambridge University has developed a Camouflage Facial Recognition System that works even if the face is \ncovered. Now, advanced systems analysing CCTV feeds can even detect non-verbal language like a grimace, a \nfrown, the clenching of teeth or fists to detect current or anticipated misconduct. Singapore uses such behavioural \nanalytics to spot unusual incidents or patterns to enable law enforcement agencies to respond more effectively. \nAfew years ago, the US department of justice, through Cardiff Uni-  versity, researched the linkage between social \nmedia, crime data and violent incidents to create software to detect potentially dangerous zones for pre-emptive \nforce deployment. US courts use a predictive AI tool to determine if a person in prison will be a repeat offender. \nBrazil uses bots to check corruption. Called Alice, Rosie, Agatha, Iris and Monica, these bots verify data to spot \nirregularities in public tenders, cartelisation, use of public funds for private gain and slow progress in judicial cases. \nCR Mukundan, a neuroscientist at the National Institute of Mental Health and Neurosciences (Nimhans), Bangalore, \nis doing fascinating work on brain mapping. Called Brain Electrical Oscillation Signature Profiling (BEOS), it is a \nnon-invasive forensic tool used when traditional methods fail. The accused is fitted with a cap comprising 32 \nelectrodes and asked to sit quietly with his eyes closed. Prerecorded statements and questions are played, and the \nelectrical impulses are recorded to figure patterns. Innocent people, bereft of knowledge of crime details, show a \ndifferent set of patterns. This method was de-  ployed in the Aarushi Talwar case. It has been used in lesser-known \ninstances also, including the 2007 case when an MBA student and her partner were arrested for poisoning the \nformer’s ex-boyfriend in Pune. The two were convicted in 2008. BEOS becomes doubly effective when used \nalongside pictures and videos, psychological profiling, polygraph tests or narco-analysis. The Supreme Court had, \nhowever, ruled in 2010 that such methods need consent. More recently, while recognising psychological tests as \nmaterial evidence, the top court cautioned against such evidence alone being sufficient to determine guilt. Various \nagencies have developed algorithmic crime-detection tools. We’ve had mixed results on outcomes and many cases \nwhere the expiration of research grants, allegations of social and race bias, and lack of transparency about actual \nusage have forced decommissioning or abandonment. Yet, that doesn’t diminish the innate need for digital \ninterventions to tackle crime, and underscores that they must be given time and resources to mature. More \nconsequentially, it reiterates the need for a robust foundation of strategic and systemic thinking on which it must be \nbuilt. The journey of data analysis in crime detection accelerated in the early 1990s when Bill Bratton, chief of the \nNew York Transit Police, and his deputy  started looking at crime data closely. They would plot incident data on \nPre-Crime Fighting, Key Techaways\nlarge maps with coloured pencils and crayons and try to sense patterns to initiate pre-emptive action. Bratton \nmotivated a 36,000-strong force to perform far-above expectations, using his fact-based approach to drive \nexecution. In two years since Bratton became commissioner in 1994, felonies fell 39%, murders 50%, and theft \n35%, making New York the ‘safest large city’ in the US. In this case, systemic change was accompanied by culture \nchange. Instead of focusing on increasing the force, he reallocated police officers to hot spots where crime \nincidence was higher, where low resource inputs yielded high gains. He converted old buses into mobile police \nstations and parked them outside subway stations, cutting time for paperwork from 16 hours to an hour. He \nreviewed the performance of senior officers bi-weekly to inculcate an intense performance culture. In essence, \nBratton demonstrated that success is contingent not just on gleaning data but also on using it effectively to figure \ninterventions that could create disproportionate outcomes, leveraging insights obtained to align teams and \nresources, and then defying conventional wisdom to achieve breakthrough results in record time. Imagine what can \nbe achieved now with the power of generative AI for predictive policing. There’s optimism that, aided by further \nadvancements in technology, heinous crimes like the Nithari serial killings won’t go unpunished. The writer is senior \nfellow, Portulans Institute, Washington DC\nLoad-Date: November 4, 2023"
    },
    {
        "file_name": "protections_against_misuse;_Artificial_intelligence_tools_that_can_conjure_Sep2023",
        "header": "Tech companies try to take AI image generators mainstream with better",
        "media": "protections against misuse; Artificial intelligence tools that can conjure",
        "time": "September 22, 2023",
        "section": "NATION WORLD",
        "length": "804 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Tech companies try to take AI image generators mainstream with better \nprotections against misuse; Artificial intelligence tools that can conjure \nwhimsical artwork or realistic-looking images from written commands \nstarted wowing crowds last year\nDayton Daily News (Ohio)\nSeptember 21, 2023 Thursday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 804 words\nByline: MATT O'BRIEN\nBody\nArtificial intelligence tools that can conjure whimsical artwork or realistic-looking images from written commands \nstarted wowing the public last year. But most people don't actually use them at work or home.\nThat could change as leading tech companies are competing to take text-to-image generators mainstream by \nintegrating them into Adobe Photoshop, YouTube and other familiar tools. \nBut first, they're trying to convince users and regulators that they've tamed some of the Wild West nature of early AI \nimage-generators with stronger safeguards against copyright theft and troubling content. \nA year ago, a relatively small group of early adopters and hobbyists began playing with cutting-edge image \ngenerators such as Stable Diffusion, Midjourney and OpenAI's DALL-E. \n\"The previous ones were an interesting curiosity,\" but businesses were wary, said David Truog, an analyst at \nmarket research group Forrester. \nA backlash followed, including copyright lawsuits from artists and photo stock company Getty, and calls for new \nlaws to rein in generative AI technology's misuse to create deceptive political ads or abusive sexual imagery. \nThose problems aren't yet solved. But a proliferation of new image generators say they're business-ready this time. \n\"Alexa, create an image of cherry blossoms in the snow,\" is the kind of prompt that Amazon says U.S. customers \nwill be able to speak later this year to generate a personalized display on their Fire TV screen. \nAdobe, known for the Photoshop graphics editor it introduced more than three decades ago, was the first this year \nto release an AI generator designed to avoid legal and ethical problems created by competitors who trained their AI \nmodels on huge troves of images pulled off the internet. \n\"When we talk to customers about generative technology, mostly what we hear is a lot of the technology is really \ncool, but they don't feel like they can use it because of these questions,\" said Adobe's chief technology officer for its \ndigital media business, Ely Greenfield. \nThat's why Adobe's product, called Firefly, was built on its own Adobe Stock image collection, as well as content it \nhas licensed. Stock contributors also are getting some compensation out of the arrangement, Greenfield said. \nTech companies try to take AI image generators mainstream with better protections against misuse Artificial \nintelligence tools that can conjure whimsical artwor....\n\"Adobe Firefly is clean legally, whereas the others are not,\" said Forrester's Truog. \"You don't really care about that \nif you're just some dude having fun with generative AI.\" \nBut if you're a business or a creative professional thinking about using images on your website, apps, or in print \nlayouts, advertising or email marketing campaigns, \"it's kind of a big deal,\" Truog said. \"You don't want to be getting \ninto trouble.\" \nSome competitors are taking note. ChatGPT-maker OpenAI unveiled its third-generation image generator DALL-E 3 \non Wednesday, emphasizing its impressive capabilities and future integration with ChatGPT along with new \nsafeguards to decline requests that ask for an image in the style of a living artist. Creators can also opt to exclude \ntheir images from training future models, though Truog notes that OpenAI hasn't said anything \"about compensating \nauthors whose work they use for training, even with permission.\" \nIn separate New York City showcase events Thursday, both Microsoft and Google-owned YouTube also unveiled \nnew products infused with AI image generation. \nMicrosoft, a major investor in OpenAI, showed how it is already starting to bake DALL-E 3 into its graphics design \ntools, mostly for background editing, as well as its Bing search engine and chatbot. YouTube revealed a new \nDream Screen for short YouTube videos that enables creators to compose a new background of their choosing. \nEarlier this month, both Adobe and Stability AI, maker of Stable Diffusion, joined a larger group of major AI \nproviders including Amazon, Google, Microsoft and OpenAI that agreed to voluntary safeguards set by President \nJoe Biden's administration. \nOne safeguard requires companies to develop methods such as digital watermarking to help people know if images \nand other content were AI-generated. \nMicrosoft executives said the company has built filters to determine what kinds of imagery can be generated from \ntext prompts in Bing, citing those made with top political figures as content to monitor. \nThe goal is \"to make sure it's not producing types of content we would never want to produce, like hateful content,\" \nsaid Sarah Bird, Microsoft's global head for responsible AI. \nIn a demonstration to an Associated Press reporter, a prompt that asked Microsoft's new tool for an image of \n\"Hillary Clinton rock climbing\" was met with rejection Thursday. \n\"Oops! Try another prompt,\" was the response. \"Looks like there are some words that may be automatically blocked \nat this time.\" \nAP business writers Cora Lewis and Haleluya Hadero contributed to this report.\nGraphic\n \nThis AI-generated image provided by Adobe shows a hummingbird. Artificial intelligence tools that can conjure \nwhimsical artwork or realistic-looking images from written commands started wowing the public in 2022. But most \npeople don't actually use them at work or home. That could change as leading tech companies are competing to \nmainstream the use of text-to-image generators for a variety of tasks, integrating them into familiar tools such as \nMicrosoft Paint, Adobe Photoshop, YouTube and ChatGPT. (Adobe via AP)\nLoad-Date: September 22, 2023\nTech companies try to take AI image generators mainstream with better protections against misuse Artificial \nintelligence tools that can conjure whimsical artwor...."
    },
    {
        "file_name": "Dayton_Daily_News_(Ohio)_Jul2023",
        "header": "FTC investigating ChatGPT creator OpenAI over consumer protection issues",
        "media": "Dayton Daily News (Ohio)",
        "time": "July 14, 2023",
        "section": "NATION WORLD",
        "length": "657 words",
        "byline": "DAVID HAMILTON",
        "story_text": "FTC investigating ChatGPT creator OpenAI over consumer protection issues\nDayton Daily News (Ohio)\nJuly 14, 2023 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 657 words\nByline: DAVID HAMILTON\nBody\nThe U.S. Federal Trade Commission has launched an investigation into ChatGPT creator OpenAI and whether the \nartificial intelligence company violated consumer protection laws by scraping public data and publishing false \ninformation through its chatbot.\nThe agency sent OpenAI a 20-page letter requesting detailed information on its AI technology, products, customers, \nprivacy safeguards and data security arrangements. \nAn FTC spokesperson had no comment on the investigation, which was first reported by The Washington Post on \nThursday. \nThe FTC document the Post published told OpenAI that the agency was investigating whether it has \"engaged in \nunfair or deceptive privacy or data security practices\" or practices harming consumers. \nOpenAI founder Sam Altman tweeted disappointment that the investigation was disclosed in a \"leak,\" noting that \nwould \"not help build trust,\" but added that the company will work with the FTC. \n\"It's super important to us that out technology is safe and pro-consumer, and we are confident we follow the law,\" \nhe wrote. \"We protect user privacy and design our systems to learn about the world, not private individuals.\" \nOpenAI has faced scrutiny elsewhere. Italian regulators temporarily blocked ChatGPT over privacy concerns, and \nprivacy watchdogs in France, Spain, Ireland and Canada also are paying closer attention, including some that have \nlaunched investigations after receiving complaints. \nThe FTC's move is a serious regulatory threat to the nascent but fast-growing AI industry, although it's not the only \nchallenge facing these companies. \nComedian Sarah Silverman and two other authors have sued both OpenAI and Facebook parent Meta for copyright \ninfringement, claiming that the companies' AI systems were illegally \"trained\" by exposing them to datasets \ncontaining illegal copies of their works. \nOn Thursday, OpenAI and The Associated Press announced a deal under which the AI company will license AP's \narchive of news stories. \nAltman has emerged as a global AI ambassador of sorts following his testimony before Congress in May and a \nsubsequent worldwide tour, including to Europe, where officials are putting the final touches on the world's first \ncomprehensive rules for AI. \nFTC investigating ChatGPT creator OpenAI over consumer protection issues\nThe regulations will focus on risky uses such as predictive policing and social scoring and include provisions for \ngenerative AI to disclose any copyright material used to train its algorithms. \nAltman himself has called for AI regulation, although he has tended to emphasize difficult-to-evaluate existential \nthreats such as the possibility that superintelligent AI systems could one day turn against humanity. \nSome argue that focusing on a far-off \"science fiction trope\" of superpowerful AI could make it harder to take action \nagainst already existing harms that require regulators to dig deep on data transparency, discriminatory behavior \nand potential for trickery and disinformation. \n\"It's the fear of these systems and our lack of understanding of them that is making everyone have a collective \nfreak-out,\" Suresh Venkatasubramanian, a Brown University computer scientist and former assistant director for \nscience and justice at the White House Office of Science and Technology Policy, told the AP in May. \"This fear, \nwhich is very unfounded, is a distraction from all the concerns we're dealing with right now.\" \nNews of the FTC's OpenAI investigation broke just hours after a combative House Judiciary Committee hearing in \nwhich FTC Chair Lina Khan faced off against Republican lawmakers, who said she has been too aggressive in \npursuing technology companies over allegations of wrongdoing. \nRepublicans said she has been harassing Twitter since its acquisition by Elon Musk, arbitrarily suing large tech \ncompanies and declining to recuse herself from certain cases. Khan pushed back, arguing that more regulation is \nnecessary as the companies have grown and that tech conglomeration could hurt the economy and consumers.\nGraphic\n \nFILE - The OpenAI logo is seen on a mobile phone in front of a computer screen displaying output from ChatGPT, \nMarch 21, 2023, in Boston. The U.S. Federal Trade Commission has launched an investigation into ChatGPT \ncreator OpenAI and whether the artificial intelligence company violated consumer protection laws by scraping public \ndata and publishing false information through its chatbot, according to reports in the Washington Post and the New \nYork Times. (AP Photo/Michael Dwyer, File)\nLoad-Date: July 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2024",
        "header": "D.E.I. Goes Quiet; DealBook Newsletter",
        "media": "The New York Times",
        "time": "January 15, 2024",
        "section": "BUSINESS; dealbook",
        "length": "1776 words",
        "byline": "Sarah Kessler &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on",
        "story_text": "D.E.I. Goes Quiet; DealBook Newsletter\nThe New York Times \nJanuary 13, 2024 Saturday 22:19 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1776 words\nByline: Sarah Kessler &lt;p&gt;Sarah Kessler is an editor for the DealBook newsletter and writes features on \nbusiness and how workplaces are changing.&lt;/p&gt;\nHighlight: As corporate diversity, equity and inclusion programs come under attack, some companies are \nrebranding their efforts.\nBody\nAs corporate diversity, equity and inclusion programs come under attack, some companies are rebranding their \nefforts.\nJoelle Emerson’s D.E.I. consultancy, Paradigm, works with more than 500 companies. The growing backlash \nagainst D.E.I., she said, “is usually the first agenda item on every call.”\nCritics of D.E.I., or diversity, equity and inclusion initiatives, have tried to scapegoat it for everything from regional \nbank failures to a panel’s ripping off a Boeing plane in flight last week. That debate gathered pace this month as \nthree famous billionaires clashed over D.E.I.’s merits on social media: Elon Musk and Pershing Square’s chief \nexecutive, Bill Ackman, have attacked D.E.I. efforts as “racist,” while the investor Mark Cuban argued that they \nwere “good for business.”\nThe economy and political landscape have changed since 2020, when companies hired D.E.I. officers in droves \namid a racial reckoning after the murder of George Floyd. Recently, D.E.I. programs have become less visible. \nOver the past two years, hiring for D.E.I. roles has plunged and the number of investor calls mentioning D.E.I. has \ndropped.\nThat raises a question: Have companies pulled back on D.E.I.? Or have they just changed how they approach and \ntalk about it?\nD.E.I. is operating in a new environment. Last year, the Supreme Court struck down affirmative action in college \nadmissions, setting off a wave of similar lawsuits and legal threats against company diversity programs. And while \npolling indicates that most Americans believe it’s good for companies to focus on diversity, equity and inclusion, \nthere’s a wide partisan divide: In a Pew survey last year, 78 percent of workers who identified as Democrats agreed \nwith this sentiment, while just 30 percent of Republican workers thought the same.\nThe pushback may have prompted a rebranding, according to D.E.I. professionals. At some companies, what used \nto be called a D.E.I. survey may now be advertised as a culture survey, Emerson said. Or management training \nonce framed as part of D.E.I. efforts may instead be discussed as a course to help managers deliver performance \nreviews more effectively. “This term seems to be pretty widely misunderstood in ways that I don’t think any of us \nrealized until the past couple of months,” Emerson said of D.E.I. She added that it might make sense for companies \nto “be far more specific about exactly what it is that we’re talking about.”\nSome corporate D.E.I. programs now include a broader variety of groups, said Porter Braswell, the founder of 2045 \nStudio, a membership network for professionals of color. “I think instead of saying this is a program for Black \nD.E.I. Goes Quiet DealBook Newsletter\nemployees,” he said, “it would be more like, ‘This is a program to increase the equity of promotion rates across the \nfirm, and everybody is included to apply to be part of this program, but will play different roles.’”\nSome companies now talk about “I.E.D.” instead of “D.E.I.,” placing the emphasis on inclusion.\nBut a plunge in D.E.I. job postings could signal a retreat. After a spike in 2020 and 2021, job posts for D.E.I. roles \non the employment websites ZipRecruiter and Indeed dropped in 2022 and 2023, the companies said. On \nZipRecruiter, the number fell 63 percent in 2023. On Indeed, the number dropped 18 percent from December 2022 \nto January 2023.\nSlow turnover of D.E.I. jobs (employers that hired in 2021 may not have needed to hire again in 2022) and a cooling \nlabor market — especially in industries, like tech and finance, that are most likely to have D.E.I. roles — probably \ncontributed to the drop, said Julia Pollak, the chief economist at ZipRecruiter. But those factors don’t entirely explain \nthe shift.\nSome see the decrease in job postings as a sign that companies have walked back their commitments to D.E.I. It \nshows that the surge in hiring of D.E.I. roles after Floyd’s murder “was performative at best,” said Misty Gaither, \nvice president of diversity, inclusion, equity and belonging at Indeed.\nBraswell of Jopwell added that many companies tried to offload all responsibility for changing company culture onto \na couple of new hires — a strategy that predictably failed. “All those people are being fired, all those people are \nquitting, all those people are feeling burned out,” he said, adding, “The only way these cultures change to be more \ndiverse, equitable and inclusive is if it is everybody’s job within the company.”\nThere is also evidence that companies remain committed to D.E.I. In a survey released this week by the \nemployment law firm Littler, only 1 percent of the 320 C-suite executives said they had significantly decreased their \nD.E.I. commitments in the past year, and 57 percent said they had expanded those efforts.\nIn a survey of 194 chief human resource officers published by the Conference Board last month, none of the \nrespondents said they planned to scale back D.E.I. initiatives. And while the number of times D.E.I. is mentioned on \ninvestor conference calls has fallen, the number of mentions in annual filings is at a high, according to AlphaSense.\nDoes it matter how companies talk about D.E.I.? Executives have stopped discussing their sustainability efforts and \nusing the term E.S.G., for environmental, social and corporate governance issues, as the topic has become more \npoliticized. (BlackRock’s Larry Fink recently described “E.S.G.” as “entirely weaponized.”) When it comes to D.E.I., \nsome professionals aren’t bothered by changes to branding as long as the work continues. “The end goals of these \ndiversity initiatives and programs will not change,” Braswell said.\nTo others, changing the words is itself a retreat. “We need to call it what it is,” said Gaither of Indeed. “The data \nsays that all of these positive things happen when you have diversity, equity and inclusion. So we’re not going to \nmask it or call it something different.”\n— Sarah Kessler\nIN CASE YOU MISSED IT\nCiti will cut 20,000 jobs. The Wall Street giant announced the layoffs as it reported a $1.8 billion loss for the fourth \nquarter — the bank’s worst results in 14 years. Citi’s chief executive, Jane Fraser, admitted the bank had performed \npoorly but said 2024 would be “a turning point.”\nBlackRock bets big on infrastructure. The asset manager agreed to buy Global Infrastructure Partners for about \n$12.5 billion, in a deal that would create the world’s second-biggest infrastructure business. BlackRock also \nannounced a big reorganization, with Global Infrastructure’s chief executive, Bayo Ogunlesi, joining BlackRock’s \nglobal executive committee and board.\nD.E.I. Goes Quiet DealBook Newsletter\nThe S.E.C. approved the first Bitcoin E.T.F. The regulator authorized 11 fund managers to create a new product \nthat would make it easier for retail investors to buy and sell the cryptocurrency. But the S.E.C.’s chair, Gary \nGensler, issued a cautionary statement after the decision, making clear that Bitcoin was a “speculative, volatile \nasset” that was used for illicit activity.\nThe World Bank warns of a “wasted” decade. The institution predicted that global growth would slow to 2.4 percent \nthis year from 2.6 percent in 2023. The forecast put the world economy on track for the weakest half-decade in 30 \nyears. Two wars, a slowing Chinese economy and increased risks of natural disasters caused by global warming \nhave added to the uncertainty.\nThe Geek Way\nAndrew McAfee’s books, including “The Second Machine Age,” have focused on how technology is changing work. \nIn his latest, “The Geek Way,” McAfee, a professor at the M.I.T. Sloan School of Management, describes a shift \nfrom the industrial era’s management philosophy to a new era of constant change.\nMcAfee discussed the book with DealBook. The conversation has been edited for length and clarity.\nYou recommend that companies adopt “geek norms” at which the most successful modern companies excel. What \ndo you mean by that?\nNorms are expected group-level behaviors. I say there are four great geek norms. \nThe first one is science, which is a constant argument that gets settled over time by evidence.\nThe second one is ownership. It’s about assigning responsibility to an autonomous group, and then making sure \nthat it remains an autonomous group.\nThe third one is speed. How quickly are you iterating, doing something, getting meaningful feedback on it, \nincorporating that and getting something else back out there? You need a plan, but the key is a minimum viable \nplan.\nAnd then finally, openness, which is very close to psychological safety (which my former colleague Amy \nEdmondson talks a ton about). It’s the opposite of defensiveness. We are inherently defensive creatures. We don’t \nlove being challenged, and the geeks have realized we have to get past that if we’re actually going to make \nprogress together.\nYou write that a key to the norm of ownership is keeping bureaucracy in check. Why does bureaucracy tend to \nballoon?\nWe human beings have this very deep-rooted desire to want status. And one way to get status in a big, complicated \norganization is to be a gatekeeper or some person in the decision loop.\nHitting your numbers helps the organization as a whole — if you’ve done the alignment process right. But making \nyourself the 20th signature on the approval route to get some amount of spending through the system? No, let’s try \nnot to have that.\nWhich of the geek norms is most difficult for leaders?\nProbably openness. Like the rest of us, our leaders are inherently defensive creatures. Saying “Oh, yeah, I hadn’t \nthought of that — good idea” is not what the Industrial era’s Jack Welch-style of leader was supposed to do. \nMaintaining that lack of defensiveness, creating an environment of psychological safety, arguing in ways that don’t \nshut things down are all difficult things to do and to keep doing as a leader.\nWas there an era when this wasn’t the best way? What about the world has changed that makes it more important?\nD.E.I. Goes Quiet DealBook Newsletter\nIt has always been a better idea to be open instead of defensive. In a slow-changing environment, where the \nlandscape is static, being closed off or not welcoming debate is not as big a problem. It is when the competition is \nglobal, when things get twice as good every 18 months and when, periodically, you have your environment rocked \nby something like generative A.I.\nWhen the world is changing very quickly, all these old industrial habits become even worse.\nThanks for reading! We’ll see you Tuesday.\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Joelle Emerson, who runs Paradigm, a consultancy, said the backlash against D.E.I. “is usually the first \nagenda item on every call.” (PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK TIMES) This article \nappeared in print on page B4.\nLoad-Date: January 15, 2024"
    },
    {
        "file_name": "USA_Today_Online_Mar2024",
        "header": "Solo traveling basics: Expert advice for your first trip",
        "media": "USA Today Online",
        "time": "March 14, 2024",
        "section": "OCEANIA LATEST",
        "length": "1388 words",
        "byline": "Kathleen Wong, USA TODAY",
        "story_text": "Solo traveling basics: Expert advice for your first trip\nUSA Today Online\nMarch 12, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: OCEANIA LATEST\nLength: 1388 words\nByline: Kathleen Wong, USA TODAY\nBody\nBoarding the plane to head to another country alone is often an emotional experience – there’s the excitement, the \nanxiety, the anticipation.\nIt can also be totally nerve-wracking.\nWhen Angie Orth made the bold choice to leave her job and embark on a solo yearlong journey around the world in \n2011, her friends and family cautioned her about safety concerns. “Everyone was horrified,” the Florida native told \nUSA TODAY. “The fear was all I heard.”\nThe then New York City-based Orth kicked off her 12-country solo trip in Fiji before making her way to New \nZealand, Australia, and Southeast Asia. Then she trekked through Europe, including Greece, Spain and England, \nand stopped in Turkey and Egypt before ending in Kenya and South Africa.\nStay safe while traveling: Here are 17 CIA tips, advice to think like a spy on vacation\nIt wasn’t always smooth traveling. At times, Orth said she survived “by the skin of my teeth.” Orth was in Egypt \nduring the Arab Spring, got unbelievably sick in Thailand, and had a bike accident in Bali. She was also robbed of \n400 euros. “I was in Greece for a half an hour and had already been pickpocketed,” she said. \nStill, to Orth, the solo journey was invaluable. “It’s a confidence that I don't think there’s any other way to get that \nconfidence than by solo travel,” she said, referring to the problem-solving that inherently comes with navigating \ntravel on your own. Then there’s also the compassion you gain from meeting and experiencing other cultures. \nNow more than ever, more people are deciding to forgo travel companions and embark on their trips alone. Solo \nvacation package searches on Google shot up by more than 200% over the past 90 days as of Feb. 2.\nIncreased connectivity on our phones makes it easier to feel secure and social media shows more people – \nespecially women – traveling the world alone. \n“Women are not waiting for permission or their 401(k) to mature. If my husband doesn’t want to go, fine. Women \nare having more confidence,” said Orth, who is also the author of the upcoming book “Flirting with Disaster,” which \nchronicles her yearlong solo trip. \nHere’s everything you need to know about solo travel. \nHow to safely travel alone\nLink to Image\nSolo traveling basics: Expert advice for your first trip\nSafety is always top of mind when traveling, and it’s especially important for solo travelers who have to look out for \nthemselves. \n'It's like your local bestie':  This startup helps make solo travel as a woman feel safer\n“Isn’t it fun to meet a person in a hostel and say yes, let’s go hiking right now? That’s fun, but it’s risky,” Orth said. \n“It’s about balancing it out and researching ridiculously.” \n￿ Start your research by heading to the State Department website to see if there are any travel advisories for the \ndestination you’re interested in. These advisories are based on changing conditions and also inform you about the \nspecific region you’re visiting.\nFor the most direct updates, enroll in the agency’s Smart Traveler Enrollment Program (STEP), a free service that \nsends you the most up-to-date information on the destination. It can also help connect you to the nearest U.S. \nembassy and consulate if traveling and something happens.\n￿ One thing Orth always searches for is “the destination plus scams” to see what she has to look out for when in \nthat place. Many European cities are notorious for petty theft, like pickpocketing in popular tourist hotspots like the \nTrevi Fountain or public transportation.  \nWhen doing research, it may feel like an information overload. \"There is so much information now, you could read \n1,000 reviews and get so many sources of conflicting information,\" Orth added. \"It’s hard to wade through all that \nand find trusted sources.\"\n￿ To help sift through everything, Orth recommends reaching out to others who have traveled to your ideal \ndestination. She also recommended cleaning out your feed and only following travel content creators who “give you \nthe good and the bad.”\n“You don’t want the glossy, glossy, oh, it’s so magical because travel isn’t always so magical,” she said. \n￿ At your destination, you’ll also need at least a basic understanding of the language used there. “Translation plays \na big role in safety, just being aware of your surroundings,” said Craig Ewer, Google Communications Manager for \nSearch. \nBesides direct translation between 133 languages, the Google Translate app offers pronunciation help – “such a \nlifesaver,” according to Rose Yao, vice president of product management at Google. You can also snap a picture of \na menu and have it translated in real time. \nThe Google app also has a feature called Lens that allows users to search using a picture of something like a sign. \n“You’d be surprised at what you can Lens: menus, what is that building or what is that statue,” Yao said. You can \nalso capture a screenshot of your social media feed and then search for it on Google to incorporate it into your \ntravel plans.\nLink to Image\nStaying healthy on your travels\n￿ To safeguard yourself and others against preventable illnesses while exploring new places, look up any \nrecommended vaccinations for the countries you plan on visiting. The Centers for Disease Control and Prevention \nwebsite is a good starting point, with in-depth travel health notices and recommended vaccines and medicines \nposted. \nThe CDC website also offers travel advice on managing nonpreventable illnesses, like preventing bug bites to \nreduce the risk of contracting diseases like dengue or Zika.\nSolo traveling basics: Expert advice for your first trip\n￿ Typically, you’d want to give yourself at least a month before departing on your trip to get everything you need \nfrom your doctor. And if you don’t know who to go to, the CDC can help you find a clinic as well. \nOrth recommends having a doctor help you put together a medical kit with some necessities and medications, such \nas for food poisoning. “It’s helpful to have some things on hand so you’re not scrambling on a remote island and no \none knows what you’re talking about,” she said. \n￿ As you’re making the big purchases for your trip, don’t forget about travel insurance for the unexpected. Orth said \nshe never travels without this layer of protection. Travel insurance not only helped with her medical costs from her \nbike collision but also replaced her camera, which was smashed in the accident. She also recommends a service \ncalled MedJet, which offers worldwide security crisis and medical transportation assistance for its members.\nLearn more: Best travel insurance\nWhat are the most popular solo travel destinations?\nAccording to Google, the top-searched destinations for American solo travelers are: \n￿ London\n￿ Alaska\n￿ Hawaii\n￿ Puerto Rico\n￿ Italy\nTips for solo travelers\n￿ The Google app’s generative AI search allows you to “ask really detailed questions like you would ask a friend,” \nYao said. “Ask what’s off the beaten path, what’s not crowded. What’s a great time to visit the Louvre that’s not \nsuper crowded?” \n￿ For your first trip alone, it’s OK to start small and dip your toes in the solo travel pool. “Start in an easier \ndestination, something more familiar where you speak the language or you don't have to fly far away,” Orth said. “A \nlot of folks see ‘Eat, Pray, Love’ and travel content creators trekking in Borneo for it to count but it doesn’t.” \n￿ It won’t always be rainbows and butterflies, despite what you see on social media. Expect decision fatigue from \nhaving to make many micro-decisions, like if this taxi driver seems safe. “I think this probably hits women a lot \nharder than it hits men because we are never not thinking about our safety, and that’s if we’re going to Target in our \nhometown or hopping on a plane to a remote island,” Orth said. \n￿ Make an itinerary for yourself with at least one thing planned every day, so you don’t feel aimless but still have \nspace for flexibility, said Madison Pietrowski, U.S. brand director at GetYourGuide, a marketplace for travel \nexperiences, where each company listed is thoroughly vetted. It can be as casual as wanting to eat at a certain \nrestaurant for dinner or more intensive like a whole-day tour. (On that note, make sure to read the fine print and be \naware of cancellation policies for your excursions.)  \nKathleen Wong is a travel reporter for USA TODAY based in Hawaii. You can reach her at  kwong@usatoday.co m.\nThis article originally appeared on USA TODAY: Solo traveling basics: Expert advice for your first trip\nLoad-Date: March 14, 2024\nSolo traveling basics: Expert advice for your first trip"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "The Times Sues OpenAI and Microsoft",
        "media": "The New York Times",
        "time": "December 28, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1513 words",
        "byline": "By Michael M. Grynbaum and Ryan Mac",
        "story_text": "The Times Sues OpenAI and Microsoft\nThe New York Times\nDecember 28, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1513 words\nByline: By Michael M. Grynbaum and Ryan Mac\nBody\nMillions of articles from The New York Times were used to train chatbots that now compete with it, the lawsuit said.\nThe New York Times sued OpenAI and Microsoft for copyright infringement on Wednesday, opening a new front in \nthe increasingly intense legal battle over the unauthorized use of published work to train artificial intelligence \ntechnologies. \n  The Times is the first major American media organization to sue the companies, the creators of ChatGPT and \nother popular A.I. platforms, over copyright issues associated with its written works. The lawsuit, filed in Federal \nDistrict Court in Manhattan, contends that millions of articles published by The Times were used to train automated \nchatbots that now compete with the news outlet as a source of reliable information.\n  The suit does not include an exact monetary demand. But it says the defendants should be held responsible for \n''billions of dollars in statutory and actual damages'' related to the ''unlawful copying and use of The Times's \nuniquely valuable works.'' It also calls for the companies to destroy any chatbot models and training data that use \ncopyrighted material from The Times.\n  In its complaint, The Times said it approached Microsoft and OpenAI in April to raise concerns about the use of its \nintellectual property and explore ''an amicable resolution,'' possibly involving a commercial agreement and \n''technological guardrails'' around generative A.I. products. But it said the talks had not produced a resolution.\n  An OpenAI spokeswoman, Lindsey Held, said in a statement that the company had been ''moving forward \nconstructively'' in conversations with The Times and that it was ''surprised and disappointed'' by the lawsuit.\n  ''We respect the rights of content creators and owners and are committed to working with them to ensure they \nbenefit from A.I. technology and new revenue models,'' Ms. Held said. ''We're hopeful that we will find a mutually \nbeneficial way to work together, as we are doing with many other publishers.''\n  Microsoft declined to comment on the case.\n  The lawsuit could test the emerging legal contours of generative A.I. technologies -- so called for the text, images \nand other content they can create after learning from large data sets -- and could carry major implications for the \nnews industry. The Times is among a small number of outlets that have built successful business models from \nonline journalism, but dozens of newspapers and magazines have been hobbled by readers' migration to the \ninternet.\n  At the same time, OpenAI and other A.I. tech firms -- which use a wide variety of online texts, from newspaper \narticles to poems to screenplays, to train chatbots -- are attracting billions of dollars in funding.\nThe Times Sues OpenAI and Microsoft\n  OpenAI is now valued by investors at more than $80 billion. Microsoft has committed $13 billion to OpenAI and \nhas incorporated the company's technology into its Bing search engine.\n  ''Defendants seek to free-ride on The Times's massive investment in its journalism,'' the complaint says, accusing \nOpenAI and Microsoft of ''using The Times's content without payment to create products that substitute for The \nTimes and steal audiences away from it.''\n  The defendants have not had an opportunity to respond in court.\n  Concerns about the uncompensated use of intellectual property by A.I. systems have coursed through creative \nindustries, given the technology's ability to mimic natural language and generate sophisticated written responses to \nvirtually any prompt.\n  The actress Sarah Silverman joined a pair of lawsuits in July that accused Meta and OpenAI of having ''ingested'' \nher memoir as a training text for A.I. programs. Novelists expressed alarm when it was revealed that A.I. systems \nhad absorbed tens of thousands of books, leading to a lawsuit by authors including Jonathan Franzen and John \nGrisham. Getty Images, the photography syndicate, sued one A.I. company that generates images based on written \nprompts, saying the platform relies on unauthorized use of Getty's copyrighted visual materials.\n  The boundaries of copyright law often get new scrutiny at moments of technological change -- like the advent of \nbroadcast radio or digital file-sharing programs like Napster -- and the use of artificial intelligence is emerging as the \nlatest frontier.\n  ''A Supreme Court decision is essentially inevitable,'' Richard Tofel, a former president of the nonprofit newsroom \nProPublica and a consultant to the news business, said of the latest flurry of lawsuits. ''Some of the publishers will \nsettle for some period of time -- including still possibly The Times -- but enough publishers won't that this novel and \ncrucial issue of copyright law will need to be resolved.''\n  Microsoft has previously acknowledged potential copyright concerns over its A.I. products. In September, the \ncompany announced that if customers using its A.I. tools were hit with copyright complaints, it would indemnify \nthem and cover the associated legal costs.\n  Other voices in the technology industry have been more steadfast in their approach to copyright. In October, \nAndreessen Horowitz, a venture capital firm and early backer of OpenAI, wrote in comments to the U.S. Copyright \nOffice that exposing A.I. companies to copyright liability would ''either kill or significantly hamper their development.''\n  ''The result will be far less competition, far less innovation and very likely the loss of the United States' position as \nthe leader in global A.I. development,'' the investment firm said in its statement.\n  Besides seeking to protect intellectual property, the lawsuit by The Times casts ChatGPT and other A.I. systems \nas potential competitors in the news business. When chatbots are asked about current events or other newsworthy \ntopics, they can generate answers that rely on journalism by The Times. The newspaper expresses concern that \nreaders will be satisfied with a response from a chatbot and decline to visit The Times's website, thus reducing web \ntraffic that can be translated into advertising and subscription revenue.\n  The complaint cites several examples when a chatbot provided users with near-verbatim excerpts from Times \narticles that would otherwise require a paid subscription to view. It asserts that OpenAI and Microsoft placed \nparticular emphasis on the use of Times journalism in training their A.I. programs because of the perceived \nreliability and accuracy of the material.\n  Media organizations have spent the past year examining the legal, financial and journalistic implications of the \nboom in generative A.I. Some news outlets have already reached agreements for the use of their journalism: The \nAssociated Press struck a licensing deal in July with OpenAI, and Axel Springer, the German publisher that owns \nPolitico and Business Insider, did likewise this month. Terms for those agreements were not disclosed.\nThe Times Sues OpenAI and Microsoft\n  The Times is exploring how to use the nascent technology itself. The newspaper recently hired an editorial director \nof artificial intelligence initiatives to establish protocols for the newsroom's use of A.I. and examine ways to integrate \nthe technology into the company's journalism.\n  In one example of how A.I. systems use The Times's material, the suit showed that Browse With Bing, a Microsoft \nsearch feature powered by ChatGPT, reproduced almost verbatim results from Wirecutter, The Times's product \nreview site. The text results from Bing, however, did not link to the Wirecutter article, and they stripped away the \nreferral links in the text that Wirecutter uses to generate commissions from sales based on its recommendations.\n  ''Decreased traffic to Wirecutter articles and, in turn, decreased traffic to affiliate links subsequently lead to a loss \nof revenue for Wirecutter,'' the complaint states.\n  The lawsuit also highlights the potential damage to The Times's brand through so-called A.I. ''hallucinations,'' a \nphenomenon in which chatbots insert false information that is then wrongly attributed to a source. The complaint \ncites several cases in which Microsoft's Bing Chat provided incorrect information that was said to have come from \nThe Times, including results for ''the 15 most heart-healthy foods,'' 12 of which were not mentioned in an article by \nthe paper.\n  ''If The Times and other news organizations cannot produce and protect their independent journalism, there will be \na vacuum that no computer or artificial intelligence can fill,'' the complaint reads. It adds, ''Less journalism will be \nproduced, and the cost to society will be enormous.''\n  The Times has retained the law firms Susman Godfrey and Rothwell, Figg, Ernst & Manbeck as outside counsel \nfor the litigation. Susman represented Dominion Voting Systems in its defamation case against Fox News, which \nresulted in a $787.5 million settlement in April. Susman also filed a proposed class action suit last month against \nMicrosoft and OpenAI on behalf of nonfiction authors whose books and other copyrighted material were used to \ntrain the companies' chatbots.\n  Benjamin Mullin contributed reporting.Benjamin Mullin contributed reporting.\nhttps://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html\nGraphic\n \nPHOTO: The Times is the first major U.S. media company to sue the A.I. platforms. (PHOTOGRAPH BY ZACK \nDEZON FOR THE NEW YORK TIMES) (B5) This article appeared in print on page B1, B5.               \nLoad-Date: December 28, 2023"
    },
    {
        "file_name": "outpaces_inflation_Jan2024",
        "header": "The Daily Money: Americans' purchasing power recovers as wage growth",
        "media": "outpaces inflation",
        "time": "January 10, 2024",
        "section": "RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & US NEWS",
        "length": "467 words",
        "byline": "Daniel de Visé, USA TODAY",
        "story_text": "The Daily Money: Americans' purchasing power recovers as wage growth \noutpaces inflation\nUSA Today Online\nJanuary 10, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: RETAIL INDUSTRY NEWS, RETAIL INDUSTRY NEWS & US NEWS\nLength: 467 words\nByline: Daniel de Visé, USA TODAY\nBody\nGood morning! It's Daniel de Visé with your Daily Money. \nIf it feels like your paycheck is going further than it has in the past couple of years, it's not your imagination.\nThis week's inflation report is expected to reveal further progress in slowing consumer price increases that have \nstrained U.S. households since early 2021, Paul Davidson reports.\nEconomists estimate that the annual inflation figure, due out Thursday, will show a rise of 3.2% in December, \ncompared to 3.1% in the prior month. That's still well above the Federal Reserve’s 2% goal.\nBut by another yardstick – purchasing power – households recently have returned to their pre-inflation financial \nhealth, according to some studies.\nComing soon: more drone deliveries, new AI tech\nShopping at Walmart and Sam's Club is about to get easier, Bailey Schulz reports.\nWalmart on Tuesday unveiled several new and upcoming offerings that aim to improve the customer experience, \nfrom generative AI-powered search tools to technology that will do away with the receipt check lines at Sam's \nClub.\n“We build technology to serve people, and not the other way around,” Walmart President and CEO Doug McMillon \nsaid in a news release. “Walmart’s purpose is to help people live better and, today, more than ever, advances in \ntechnology make it feel like anything is possible.” \nMcMillon took the stage Tuesday afternoon at the CES consumer technology convention in Las Vegas to highlight \nthe company's latest innovations.\nMore stories you shouldn't miss\nFirst time filing your taxes?  Here are 5 tips for tax season newbies\nWhat if I owe taxes but I'm unemployed?  Tips for filers who recently lost a job\nWhat the ETF? Securities and Exchange Commission's X account compromised, sends fake post on Bitcoin ETF\nCruising Altitude: I've covered Boeing's 737 MAX for years. A quick rundown of the issues\nThe Daily Money: Americans' purchasing power recovers as wage growth outpaces inflation\n Today's Menu \n\"Beer Mint\" sounds like an oxymoron: You take mints to camouflage beer breath.\nNonetheless, Miller Lite is rolling out Beer Mints, Mike Snider reports. \nBilled as having \"the same great taste as Miller Lite, only without the beer,\" the new mints ($5 for a tin of 40) go on \nsale online at millerlitebeermints.com on Jan. 12. A second Beer Mint drop is planned for Jan. 19.\nBeer Mints are nonalcoholic, which invites another question: What, exactly, is the point?\nCompany officials explain: They are being marketed as support for those undertaking Dry January, a month of \nalcohol abstention. \nAbout The Daily Money\nEach weekday, The Daily Money delivers the best consumer news from USA TODAY. We break down financial \nnews and provide the TLDR version: how decisions by the Federal Reserve, government and companies impact \nyou.\nThis article originally appeared on USA TODAY: The Daily Money: Americans' purchasing power recovers as wage \ngrowth outpaces inflation\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "The_Economic_Times_Aug2023",
        "header": "Skilling platform Disprz bags $30 million from Lumos and others",
        "media": "The Economic Times",
        "time": "August 7, 2023",
        "section": "FUNDING",
        "length": "195 words",
        "byline": " ",
        "story_text": "Skilling platform Disprz bags $30 million from Lumos and others\nThe Economic Times\nAugust 8, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 195 words\nBody\nDisprz, a corporate learning and skilling platform, has raised $30 million in its Series C funding round led by Lumos \nCapital. 360 ONE Asset (IIFL Wealth) and returning investors Kae Capital, KOIS and Dallas Venture Capital also \nparticipated. The funding, a result of primary and secondary share sales, will be utilised for global market expansion \nand product development, including the integration of generative artificial intelligence across the learning and \nskilling cycle. Additionally, Disprz aims to form strategic partnerships and make strategic acquisitions, as per a \nstatement. \"We are right now in the middle of our $10 million to $100 million ARR (annual recurring revenues) \njourney. The raised capital will let us build our next generation of products. We are a multi-product company, we \nhave a suite of offerings on learning and upskilling for mid and large enterprises in emerging markets like India, \nsoutheast Asia, middle east and we've just made our trip to the US,\" founder and CEO Subramanian Viswanathan \ntold ET. Viswanathan said that the company currently has 12 clients in the US. In total, the company has 350. For \nReprint Rights: timescontent.com\nLoad-Date: August 7, 2023"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "Seeing eye to AI: risk and impact of artificial intelligence use in businesses",
        "media": "The Economic Times",
        "time": "December 17, 2023",
        "section": "TECH & INTERNET",
        "length": "409 words",
        "byline": "Beena Parmar",
        "story_text": "Seeing eye to AI: risk and impact of artificial intelligence use in businesses\nThe Economic Times\nDecember 17, 2023 Sunday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 409 words\nByline: Beena Parmar\nBody\nAs artificial intelligence (AI) gains prominence among businesses, in the past week alone, at least two reports were \npublished that focused on its impact on Indian enterprises, highlighting the significance of process automation and \ngenerative AI as key investment catalysts. The first Automation Now & Next report was by US-based software firm \nAutomation Anywhere. Along with independent research and analysis firm Foundry, looked at actions, experiences, \nand projections of more than 1,000 decision-makers, C-level executives, business leaders, automation leaders and \npractitioners across industries and regions over two months. \nThe report underscored three topics – AI, productivity improvements and scalability.ITS KEY FINDINGS 63 per cent \nof Indian enterprises are proactively directing investments in next 12 months towards AI and machine learning (ML) \nfor the automation of their business processes.39 per cent of respondents said that data challenges and \nregulatory/ethical concerns stand out as the primary obstacles to adopting AI technologies.80 per cent of Indian \nenterprises are planning to determine the impact of Intelligent automation based on business ROI.40 per cent of \nbusiness users said citizen development was broadly encouraged.The second report, AI Raising the Bar, was \ncommissioned by Experian India and conducted by Forrester Consulting. It surveyed 889 business leaders in \nfinancial services and telcos across 10 countries in the EMEA and APAC regions. The report deep dives into the \ntransformative effect of AI on risk, CX, and analytics. The study found that India is leading the cloud, AI and ML \necosystem, with 85 per cent of Indian businesses using cloud providers for analytics. The report further states that \n80 per cent of Indian business leaders surveyed are committed to prioritising the integration of advanced analytics \nendowed with AI capabilities. KEY FINDINGS74 per cent of Indian financial services and telcos companies \nsurveyed are using cloud for credit risk decisioning.60 per cent of Indian businesses see open banking as a \ngateway to new customer-consented data in open finance.61 per cent of business leaders have established a \ncomprehensive AI risk management program. 65 per cent believe that AI gives them a competitive advantage.80 \nper cent of business leaders surveyed are committed to prioritising the integration of advanced analytics endowed \nwith AI capabilities. For Reprint Rights: timescontent.com\nLoad-Date: December 17, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2024",
        "header": "Apple Will Revamp Siri to Catch Up to Its Chatbot Competitors",
        "media": "The New York Times",
        "time": "May 11, 2024",
        "section": "BUSINESS",
        "length": "1316 words",
        "byline": "Tripp Mickle, Brian X. Chen and Cade Metz Tripp Mickle reports on Apple and Silicon Valley for The Times",
        "story_text": "Apple Will Revamp Siri to Catch Up to Its Chatbot Competitors\nThe New York Times \nMay 10, 2024 Friday 13:05 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1316 words\nByline: Tripp Mickle, Brian X. Chen and Cade Metz Tripp Mickle reports on Apple and Silicon Valley for The Times \nand is based in San Francisco. His focus on Apple includes product launches, manufacturing issues and political \nchallenges. He also writes about trends across the tech industry, including layoffs, generative A.I. and robot taxis. \nBrian X. Chen is the lead consumer technology writer for The Times. He reviews products and writes Tech Fix, a \ncolumn about the social implications of the tech we use. Cade Metz writes about artificial intelligence, driverless \ncars, robotics, virtual reality and other emerging areas of technology.\nHighlight: Apple plans to announce that it will bring generative A.I. to iPhones after the company’s most significant \nreorganization in a decade.\nBody\nApple plans to announce that it will bring generative A.I. to iPhones after the company’s most significant \nreorganization in a decade.\nApple’s top software executives decided early last year that Siri, the company’s virtual assistant, needed a brain \ntransplant.\nThe decision came after the executives Craig Federighi and John Giannandrea spent weeks testing OpenAI’s new \nchatbot, ChatGPT. The product’s use of generative artificial intelligence, which can write poetry, create computer \ncode and answer complex questions, made Siri look antiquated, said two people familiar with the company’s work, \nwho didn’t have permission to speak publicly.\nIntroduced in 2011 as the original virtual assistant in every iPhone, Siri had been limited for years to individual \nrequests and had never been able to follow a conversation. It often misunderstood questions. ChatGPT, on the \nother hand, knew that if someone asked for the weather in San Francisco and then said, “What about New York?” \nthat user wanted another forecast.\nThe realization that new technology had leapfrogged Siri set in motion the tech giant’s most significant \nreorganization in more than a decade. Determined to catch up in the tech industry’s A.I. race, Apple has made \ngenerative A.I. a tent pole project — the company’s special, internal label that it uses to organize employees \naround once-in-a-decade initiatives.\nApple is expected to show off its A.I. work at its annual developers conference on June 10 when it releases an \nimproved Siri that is more conversational and versatile, according to three people familiar with the company’s work, \nwho didn’t have permission to speak publicly. Siri’s underlying technology will include a new generative A.I. system \nthat will allow it to chat rather than respond to questions one at a time.\nThe update to Siri is at the forefront of a broader effort to embrace generative A.I. across Apple’s business. The \ncompany is also increasing the memory in this year’s iPhones to support its new Siri capabilities. And it has \ndiscussed licensing complementary A.I. models that power chatbots from several companies, including Google, \nCohere and OpenAI.\nApple Will Revamp Siri to Catch Up to Its Chatbot Competitors\nAn Apple spokeswoman declined to comment.\nApple executives worry that new A.I. technology threatens the company’s dominance of the global smartphone \nmarket because it has the potential to become the primary operating system, displacing the iPhone’s iOS software, \nsaid two people familiar with the thinking of Apple’s leadership, who didn’t have permission to speak publicly. This \nnew technology could also create an ecosystem of A.I. apps, known as agents, that can order Ubers or make \ncalendar appointments, undermining Apple’s App Store, which generates about $24 billion in annual sales.\nApple also fears that if it fails to develop its own A.I. system, the iPhone could become a “dumb brick” compared \nwith other technology. While it is unclear how many people regularly use Siri, the iPhone currently takes 85 percent \nof global smartphone profits and generates more than $200 billion in sales.\nThat sense of urgency contributed to Apple’s decision to cancel its other big bet — a $10 billion project to develop a \nself-driving car — and reassign hundreds of engineers to work on A.I.\nApple has also explored creating servers that are powered by its iPhone and Mac processors, two of these people \nsaid. Doing so could help Apple save money and create consistency between the tools used for processes in the \ncloud and on its devices.\nRather than compete directly with ChatGPT by releasing a chatbot that does things like write poetry, the three \npeople familiar with its work said, Apple has focused on making Siri better at handling tasks that it already does, \nincluding setting timers, creating calendar appointments and adding items to a grocery list. It also would be able to \nsummarize text messages.\nApple plans to bill the improved Siri as more private than rival A.I. services because it will process requests on \niPhones rather than remotely in data centers. The strategy will also save money. OpenAI spends about 12 cents for \nabout 1,000 words that ChatGPT generates because of cloud computing costs.\n(The New York Times sued OpenAI and its partner, Microsoft, in December for copyright infringement of news \ncontent related to A.I. systems.)\nBut Apple faces risks by relying on a smaller A.I. system housed on iPhones rather than a larger one stored in a \ndata center. Research has found that smaller A.I. systems could be more likely to make errors, known as \nhallucinations, than larger ones.\n“It’s always been the Siri vision to have a conversational interface that understands language and context, but it’s a \nhard problem,” said Tom Gruber, a co-founder of Siri who worked at Apple until 2018. “Now that the technology has \nchanged, it should be possible to do a much better job of that. So long as it’s not a one-size-fits-all effort to answer \nanything, then they should be able to avoid trouble.”\nApple has several advantages in the A.I. race, including more than two billion devices in use around the world \nwhere it can distribute A.I. products. It also has a leading semiconductor team that has been making sophisticated \nchips capable of powering A.I. tasks like facial recognition.\nBut for the past decade, Apple has struggled to develop a comprehensive A.I. strategy, and Siri has not had major \nimprovements since its introduction. The assistant’s struggles blunted the appeal of the company’s HomePod smart \nspeaker because it couldn’t consistently perform simple tasks like fulfilling a song request.\nThe Siri team has failed to get the kind of attention and resources that went to other groups inside Apple, said John \nBurkey, who worked on Siri for two years before founding a generative A.I. platform, Brighten.ai. The company’s \ndivisions, such as software and hardware, operate independently of one another and share limited information. But \nA.I. needs to be threaded through products to succeed.\n“It’s not in Apple’s DNA,” Mr. Burkey said. “It’s a blind spot.”\nApple Will Revamp Siri to Catch Up to Its Chatbot Competitors\nApple has also struggled to recruit and retain leading A.I. researchers. Over the years, it has acquired A.I. \ncompanies led by leaders in the field, but they all left after a few years.\nThe reasons for their departures vary, but one factor is Apple’s secrecy. The company publishes fewer papers on \nits A.I. work than Google, Meta and Microsoft, and it doesn’t participate in conferences in the same way that its \nrivals do.\n“Research scientists say: ‘What are my other options? Can I go back into academia? Can I go to a research \ninstitute, some place where I can work a bit more in the open?’” said Ruslan Salakhutdinov, a leading A.I. \nresearcher, who left Apple in 2020 to return to Carnegie Mellon University.\nIn recent months, Apple has increased the number of A.I. papers it has published. But prominent A.I. researchers \nhave questioned the value of the papers, saying they are more about creating the impression of meaningful work \nthan providing examples of what Apple may bring to market.\nTsu-Jui Fu, an Apple intern and A.I. doctoral student at the University of California, Santa Barbara, wrote one of \nApple’s recent A.I. papers. He spent last summer developing a system for editing photos with written commands \nrather than Photoshop tools. He said that Apple supported the project by providing him with the necessary G.P.U.s \nto train the system, but that he had no interaction with the A.I. team working on Apple products.\nThough he said he had interviewed for full-time jobs at Adobe and Nvidia, he plans to return to Apple after he \ngraduates because he thinks he can make a bigger difference there.\n“A.I. product and research is emerging in Apple, but most companies are very mature,” Mr. Fu said in an interview \nwith The Times. “At Apple, I can have more room to lead a project instead of just being a member of a team doing \nsomething.”\nThis article appeared in print on page B1, B5.\nLoad-Date: May 11, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.",
        "media": "The New York Times",
        "time": "June 27, 2023",
        "section": "TECHNOLOGY",
        "length": "1312 words",
        "byline": "Steve Lohr",
        "story_text": "A.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe New York Times \nJune 26, 2023 Monday 12:21 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1312 words\nByline: Steve Lohr\nHighlight: The best use for generative A.I. in health care, doctors say, is to ease the heavy burden of \ndocumentation that takes them hours a day and contributes to burnout.\nBody\nDr. Matthew Hitchcock, a family physician in Chattanooga, Tenn., has an A.I. helper.\nIt records patient visits on his smartphone and summarizes them for treatment plans and billing. He does some light \nediting of what the A.I. produces, and is done with his daily patient visit documentation in 20 minutes or so.\nDr. Hitchcock used to spend up to two hours typing up these medical notes after his four children went to bed. \n“That’s a thing of the past,” he said. “It’s quite awesome.”\nChatGPT-style artificial intelligence is coming to health care, and the grand vision of what it could bring is inspiring. \nEvery doctor, enthusiasts predict, will have a superintelligent sidekick, dispensing suggestions to improve care.\nBut first will come more mundane applications of artificial intelligence. A prime target will be to ease the crushing \nburden of digital paperwork that physicians must produce, typing lengthy notes into electronic medical records \nrequired for treatment, billing and administrative purposes.\nFor now, the new A.I. in health care is going to be less a genius partner than a tireless scribe.\nFrom leaders at major medical centers to family physicians, there is optimism that health care will benefit from the \nlatest advances in generative A.I. — technology that can produce everything from poetry to computer programs, \noften with human-level fluency.\nBut medicine, doctors emphasize, is not a wide open terrain of experimentation. A.I.’s tendency to occasionally \ncreate fabrications, or so-called hallucinations, can be amusing, but not in the high-stakes realm of health care.\nThat makes generative A.I., they say, very different from A.I. algorithms, already approved by the Food and Drug \nAdministration, for specific applications, like scanning medical images for cell clusters or subtle patterns that \nsuggest the presence of lung or breast cancer. Doctors are also using chatbots to communicate more effectively \nwith some patients.\nPhysicians and medical researchers say regulatory uncertainty, and concerns about patient safety and litigation, will \nslow the acceptance of generative A.I. in health care, especially its use in diagnosis and treatment plans.\nThose physicians who have tried out the new technology say its performance has improved markedly in the last \nyear. And the medical note software is designed so that doctors can check the A.I.-generated summaries against \nthe words spoken during a patient’s visit, making it verifiable and fostering trust.\nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\n“At this stage, we have to pick our use cases carefully,” said Dr. John Halamka, president of Mayo Clinic Platform, \nwho oversees the health system’s adoption of artificial intelligence. “Reducing the documentation burden would be \na huge win on its own.”\nRecent studies show that doctors and nurses report high levels of burnout, prompting many to leave the profession. \nHigh on the list of complaints, especially for primary care physicians, is the time spent on documentation for \nelectronic health records. That work often spills over into the evenings, after-office-hours toil that doctors refer to as \n“pajama time.”\nGenerative A.I., experts say, looks like a promising weapon to combat the physician workload crisis.\n“This technology is rapidly improving at a time health care needs help,” said Dr. Adam Landman, chief information \nofficer of Mass General Brigham, which includes Massachusetts General Hospital and Brigham and Women’s \nHospital in Boston.\nFor years, doctors have used various kinds of documentation assistance, including speech recognition software and \nhuman transcribers. But the latest A.I. is doing far more: summarizing, organizing and tagging the conversation \nbetween a doctor and a patient.\nCompanies developing this kind of technology include Abridge, Ambience Healthcare, Augmedix, Nuance, which is \npart of Microsoft, and Suki.\nTen physicians at the University of Kansas Medical Center have been using generative A.I. software for the last \ntwo months, said Dr. Gregory Ator, an ear, nose and throat specialist and the center’s chief medical informatics \nofficer. The medical center plans to eventually make the software available to its 2,200 physicians.\nBut the Kansas health system is steering clear of using generative A.I. in diagnosis, concerned that its \nrecommendations may be unreliable and that its reasoning is not transparent. “In medicine, we can’t tolerate \nhallucinations,” Dr. Ator said. “And we don’t like black boxes.”\nThe University of Pittsburgh Medical Center has been a test bed for Abridge, a start-up led and co-founded by Dr. \nShivdev Rao, a practicing cardiologist who was also an executive at the medical center’s venture arm.\nAbridge was founded in 2018, when large language models, the technology engine for generative A.I., emerged. \nThe technology, Dr. Rao said, opened a door to an automated solution to the clerical overload in health care, which \nhe saw around him, even for his own father.\n“My dad retired early,” Dr. Rao said. “He just couldn’t type fast enough.”\nToday, the Abridge software is used by more than 1,000 physicians in the University of Pittsburgh medical system.\nDr. Michelle Thompson, a family physician in Hermitage, Pa., who specializes in lifestyle and integrative care, said \nthe software had freed up nearly two hours in her day. Now, she has time to do a yoga class, or to linger over a sit-\ndown family dinner.\nAnother benefit has been to improve the experience of the patient visit, Dr. Thompson said. There is no longer \ntyping, note-taking or other distractions. She simply asks patients for permission to record their conversation on her \nphone.\n“A.I. has allowed me, as a physician, to be 100 percent present for my patients,” she said.\nThe A.I. tool, Dr. Thompson added, has also helped patients become more engaged in their own care. Immediately \nafter a visit, the patient receives a summary, accessible through the University of Pittsburgh medical system’s \nonline portal.\nA.I. May Someday Work Medical Miracles. For Now, It Helps Do Paperwork.\nThe software translates any medical terminology into plain English at about a fourth-grade reading level. It also \nprovides a recording of the visit with “medical moments” color-coded for medications, procedures and diagnoses. \nThe patient can click on a colored tag and listen to a portion of the conversation.\nStudies show that patients forget up to 80 percent of what physicians and nurses say during visits. The recorded \nand A.I.-generated summary of the visit, Dr. Thompson said, is a resource her patients can return to for reminders \nto take medications, exercise or schedule follow-up visits.\nAfter the appointment, physicians receive a clinical note summary to review. There are links back to the transcript of \nthe doctor-patient conversation, so the A.I.’s work can be checked and verified. “That has really helped me build \ntrust in the A.I.,” Dr. Thompson said.\nIn Tennessee, Dr. Hitchcock, who also uses Abridge software, has read the reports of ChatGPT scoring high marks \non standard medical tests and heard the predictions that digital doctors will improve care and solve staffing \nshortages.\nDr. Hitchcock has tried ChatGPT and is impressed. But he would never think of loading a patient record into the \nchatbot and asking for a diagnosis, for legal, regulatory and practical reasons. For now, he is grateful to have his \nevenings free, no longer mired in the tedious digital documentation required by the American health care industry.\nAnd he sees no technology cure for the health care staffing shortfall. “A.I. isn’t going to fix that anytime soon,” said \nDr. Hitchcock, who is looking to hire another doctor for his four-physician practice.\nPHOTOS: Dr. Matthew Hitchcock of Chattanooga, Tenn., and Dr. Michelle Thompson of Hermitage, Pa., both use \nA.I. tools to to ease the crushing burden of digital paperwork. (PHOTOGRAPHS BY AUDRA MELTON FOR THE \nNEW YORK TIMES; MADDIE MCGARVEY FOR THE NEW YORK TIMES) (A14) This article appeared in print on \npage A1, A14.\nLoad-Date: June 27, 2023"
    },
    {
        "file_name": "RACE_Dec2023",
        "header": "Inside OpenAI’s Crisis Over the Future of Artificial Intelligence; The A.I.",
        "media": "RACE",
        "time": "December 19, 2023",
        "section": "TECHNOLOGY",
        "length": "3003 words",
        "byline": "Tripp Mickle, Cade Metz, Mike Isaac and Karen Weise &lt;p&gt;Tripp Mickle reports on Apple and Silicon",
        "story_text": "Inside OpenAI’s Crisis Over the Future of Artificial Intelligence; The A.I. \nRACE\nThe New York Times \nDecember 9, 2023 Saturday 08:35 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 3003 words\nByline: Tripp Mickle, Cade Metz, Mike Isaac and Karen Weise &lt;p&gt;Tripp Mickle reports on Apple and Silicon \nValley for The Times and is based in San Francisco. His focus on Apple includes product launches, manufacturing \nissues and political challenges. He also writes about trends across the tech industry, including layoffs, generative \nA.I. and robot taxis.&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;Cade Metz writes about artificial intelligence, \ndriverless cars, robotics, virtual reality and other emerging areas of technology.&lt;/p&gt; &lt;p&gt;Mike Isaac is a \ntechnology correspondent for The Times based in San Francisco. He regularly covers Facebook and Silicon \nValley.&lt;/p&gt; &lt;p&gt;Karen Weise writes about technology and is based in Seattle. Her coverage focuses on \nAmazon and Microsoft, two of the most powerful companies in America.&lt;/p&gt;\nHighlight: Split over the leadership of Sam Altman, board members and executives turned on one another. Their \nbrawl exposed the cracks at the heart of the A.I. movement.\nBody\nAround noon on Nov. 17, Sam Altman, the chief executive of OpenAI, logged into a video call from a luxury hotel in \nLas Vegas. He was in the city for its inaugural Formula 1 race, which had drawn 315,000 visitors including Rihanna \nand Kylie Minogue.\nMr. Altman, who had parlayed the success of OpenAI’s ChatGPT chatbot into personal stardom beyond the tech \nworld, had a meeting lined up that day with Ilya Sutskever, the chief scientist of the artificial intelligence start-up. But \nwhen the call started, Mr. Altman saw that Dr. Sutskever was not alone — he was virtually flanked by OpenAI’s \nthree independent board members.\nInstantly, Mr. Altman knew something was wrong.\nUnbeknownst to Mr. Altman, Dr. Sutskever and the three board members had been whispering behind his back for \nmonths. They believed Mr. Altman had been dishonest and should no longer lead a company that was driving the \nA.I. race. On a hush-hush 15-minute video call the previous afternoon, the board members had voted one by one to \npush Mr. Altman out of OpenAI.\nNow they were delivering the news. Shocked that he was being fired from a start-up he had helped found, Mr. \nAltman widened his eyes and then asked, “How can I help?” The board members urged him to support an interim \nchief executive. He assured them that he would.\nWithin hours, Mr. Altman changed his mind and declared war on OpenAI’s board.\nHis ouster was the culmination of years of simmering tensions at OpenAI that pit those alarmed by A.I.’s power \nagainst others who saw the technology as a once-in-a-lifetime profit and prestige bonanza. As divisions deepened, \nthe organization’s leaders sniped and turned on one another. That led to a boardroom brawl that ultimately showed \nwho has the upper hand in A.I.’s future development: Silicon Valley’s tech elite and deep-pocketed corporate \ninterests.\nInside OpenAI’s Crisis Over the Future of Artificial Intelligence The A.I. RACE\nThe drama embroiled Microsoft, which had committed $13 billion to OpenAI and weighed in to protect its \ninvestment. Many top Silicon Valley executives and investors, including the chief executive of Airbnb, also mobilized \nto support Mr. Altman.\nSome fought back from Mr. Altman’s $27 million mansion in San Francisco’s Russian Hill neighborhood, lobbying \nthrough social media and voicing their displeasure in private text threads, according to interviews with more than 25 \npeople with knowledge of the events. Many of their conversations and the details of their confrontations have not \nbeen previously reported.\nAt the center of the storm was Mr. Altman, a 38-year-old multimillionaire. A vegetarian who raises cattle and a tech \nleader with little engineering training, he is driven by a hunger for power more than by money, a longtime mentor \nsaid. And even as Mr. Altman became A.I.’s public face, charming heads of state with predictions of the \ntechnology’s positive effects, he privately angered those who believed he ignored its potential dangers.\nOpenAI’s chaos has raised new questions about the people and companies behind the A.I. revolution. If the world’s \npremier A.I. start-up can so easily plunge into crisis over backbiting behavior and slippery ideas of wrongdoing, can \nit be trusted to advance a technology that may have untold effects on billions of people?\n“OpenAI’s aura of invulnerability has been shaken,” said Andrew Ng, a Stanford professor who helped found the \nA.I. labs at Google and the Chinese tech giant Baidu. \nAn Incendiary Mix\nFrom the moment it was created in 2015, OpenAI was primed to combust.\nThe San Francisco lab was founded by Elon Musk, Mr. Altman, Dr. Sutskever and nine others. Its goal was to build \nA.I. systems to benefit all of humanity. Unlike most tech start-ups, it was established as a nonprofit with a board that \nwas responsible for making sure it fulfilled that mission.\nThe board was stacked with people who had competing A.I. philosophies. On one side were those who worried \nabout A.I.’s dangers, like Mr. Musk, who left OpenAI in a huff in 2018. On the other were Mr. Altman and those \nfocused more on the technology’s potential benefits.\nIn 2019, Mr. Altman — who had extensive contacts in Silicon Valley as president of the start-up incubator Y \nCombinator — became OpenAI’s chief executive. He would own just a tiny stake in the start-up.\n“Why is he working on something that won’t make him richer? One answer is that lots of people do that once they \nhave enough money, which Sam probably does,” said Paul Graham, a founder of Y Combinator and Mr. Altman’s \nmentor. “The other is that he likes power.”\nMr. Altman quickly changed OpenAI’s direction by creating a for-profit subsidiary and raising $1 billion from \nMicrosoft, spurring questions about how that would work with the board’s mission of safe A.I.\nEarlier this year, departures shrank OpenAI’s board to six people from nine. Three — Mr. Altman, Dr. Sutskever \nand Greg Brockman, OpenAI’s president — were founders of the lab. The others were independent members.\nHelen Toner, a director of strategy at Georgetown University’s Center for Security and Emerging Technology, was \npart of the effective altruist community that believes A.I. could one day destroy humanity. Adam D’Angelo had long \nworked with A.I. as the chief executive of the question-and-answer website Quora. Tasha McCauley, an adjunct \nscientist at the RAND Corporation, had worked on tech and A.I. policy and governance issues and taught at \nSingularity University, which was named for the moment when machines can no longer be controlled by their \ncreators.\nThey were united by a concern that A.I. could become more intelligent than humans.\nTensions Mount\nInside OpenAI’s Crisis Over the Future of Artificial Intelligence The A.I. RACE\nAfter OpenAI introduced ChatGPT last year, the board became jumpier.\nAs millions of people used the chatbot to write love letters and brainstorm college essays, Mr. Altman embraced the \nspotlight. He appeared with Satya Nadella, Microsoft’s chief executive, at tech events. He met President Biden and \nembarked on a 21-city global tour, hobnobbing with leaders like Prime Minister Narendra Modi of India.\nYet as Mr. Altman raised OpenAI’s profile, some board members worried that ChatGPT’s success was antithetical \nto creating safe A.I., two people familiar with their thinking said.\nTheir concerns were compounded when they clashed with Mr. Altman in recent months over who should fill the \nboard’s three open seats.\nIn September, Mr. Altman met investors in the Middle East to discuss an A.I. chip project. The board was \nconcerned that he wasn’t sharing all his plans with it, three people familiar with the matter said.\nDr. Sutskever, 37, who helped pioneer modern A.I., was especially disgruntled. He had become fearful that the \ntechnology could wipe out humanity. He also believed that Mr. Altman was bad-mouthing the board to OpenAI \nexecutives, two people with knowledge of the situation said. Other employees have also complained to the board \nabout Mr. Altman’s behavior.\nIn October, Mr. Altman promoted another OpenAI researcher to the same level as Dr. Sutskever, who saw it as a \nslight. Dr. Sutskever told several board members that he might quit, two people with knowledge of the matter said. \nThe board interpreted the move as an ultimatum to choose between him and Mr. Altman, the people said.\nDr. Sutskever’s lawyer said it was “categorically false” that he had threatened to quit.\nAnother conflict erupted in October when Ms. Toner published a paper, “Decoding Intentions: Artificial Intelligence \nand Costly Signals,” at her Georgetown think tank. In it, she and her co-authors praised Anthropic, an OpenAI rival, \nfor delaying a product release and avoiding the “frantic corner-cutting that the release of ChatGPT appeared to \nspur.”\nMr. Altman was displeased, especially since the Federal Trade Commission had begun investigating OpenAI’s data \ncollection. He called Ms. Toner, saying her paper “could cause problems.”\nThe paper was merely academic, Ms. Toner said, offering to write an apology to OpenAI’s board. Mr. Altman \naccepted. He later emailed OpenAI’s executives, telling them that he had reprimanded Ms. Toner.\n“I did not feel we’re on the same page on the damage of all this,” he wrote.\nMr. Altman called other board members and said Ms. McCauley wanted Ms. Toner removed from the board, people \nwith knowledge of the conversations said. When board members later asked Ms. McCauley if that was true, she \nsaid that was “absolutely false.”\n“This significantly differs from Sam’s recollection of these conversations,” an OpenAI spokeswoman said, adding \nthat the company was looking forward to an independent review of what transpired.\nSome board members believed that Mr. Altman was trying to pit them against each other. Last month, they decided \nto act.\nDialing in from Washington, Los Angeles and the San Francisco Bay Area, they voted on Nov. 16 to dismiss Mr. \nAltman. OpenAI’s outside lawyer advised them to limit what they said publicly about the removal.\nFearing that if Mr. Altman got wind of their plan he would marshal his network against them, they acted quickly and \nsecretly.\nWhat Did Sam Do?\nInside OpenAI’s Crisis Over the Future of Artificial Intelligence The A.I. RACE\nWhen news broke of Mr. Altman’s firing on Nov. 17, a text landed in a private WhatsApp group of more than 100 \nchief executives of Silicon Valley companies, including Meta’s Mark Zuckerberg and Dropbox’s Drew Houston.\n“Sam is out,” the text said.\nThe thread immediately blew up with questions: What did Sam do?\nThat same query was being asked at Microsoft, OpenAI’s biggest investor. As Mr. Altman was being fired, Kevin \nScott, Microsoft’s chief technology officer, got a call from Mira Murati, OpenAI’s chief technology officer. She told \nhim that in a matter of minutes, OpenAI’s board would announce that it had canned Mr. Altman and that she was \nthe interim chief.\nMr. Scott immediately asked someone at Microsoft’s headquarters in Redmond, Wash., to get Mr. Nadella, the chief \nexecutive, out of a meeting he was having with top lieutenants. Shocked, Mr. Nadella called Ms. Murati about the \nOpenAI board’s reasoning, three people with knowledge of the call said. In a statement, OpenAI’s board had said \nonly that Mr. Altman “was not consistently candid in his communications” with the board. Ms. Murati didn’t have \nanswers.\nMr. Nadella then phoned Mr. D’Angelo, OpenAI’s lead independent director. What could Mr. Altman have done, Mr. \nNadella asked, to cause the board to act so abruptly? Was there anything nefarious?\n“No,” Mr. D’Angelo replied, speaking in generalities. Mr. Nadella remained confused.\nTurning the Tables\nShortly after Mr. Altman’s removal from OpenAI, a friend reached out to him. It was Brian Chesky, Airbnb’s chief \nexecutive.\nMr. Chesky asked Mr. Altman what he could do to help. Mr. Altman, who was still in Las Vegas, said he wanted to \ntalk.\nThe two men had met in 2009 at Y Combinator. When they spoke on Nov. 17, Mr. Chesky peppered Mr. Altman \nwith questions about why OpenAI’s board had terminated him. Mr. Altman said he was as uncertain as everyone \nelse.\nAt the same time, OpenAI’s employees were demanding details. The board dialed into a call that afternoon to talk to \nabout 15 OpenAI executives, who crowded into a conference room at the company’s offices in a former \nmayonnaise factory in San Francisco’s Mission neighborhood.\nThe board members said that Mr. Altman had lied to the board, but that they couldn’t elaborate for legal reasons.\n“This is a coup,” one employee shouted.\nJason Kwon, OpenAI’s chief strategy officer, accused the board of violating its fiduciary responsibilities. “It cannot \nbe your duty to allow the company to die,” he said, according to two people with knowledge of the meeting.\nMs. Toner replied, “The destruction of the company could be consistent with the board’s mission.”\nOpenAI’s executives insisted that the board resign that night or they would all leave. Mr. Brockman, 35, OpenAI’s \npresident, had already quit.\nThe support gave Mr. Altman ammunition. He flirted with creating a new start-up, but Mr. Chesky and Ron Conway, \na Silicon Valley investor and friend, urged Mr. Altman to reconsider.\n“You should be willing to fight back at least a little more,” Mr. Chesky told him.\nMr. Altman decided to take back what he felt was his.\nInside OpenAI’s Crisis Over the Future of Artificial Intelligence The A.I. RACE\nPressuring the Board\nAfter flying back from Las Vegas, Mr. Altman awoke on Nov. 18 in his San Francisco home, with sweeping views of \nAlcatraz Island. Just before 8 a.m., his phone rang. It was Mr. D’Angelo and Ms. McCauley.\nThe board members were rattled by the meeting with OpenAI executives the day before. Customers were \nconsidering shifting to rival platforms. Google was already trying to poach top talent, two people with knowledge of \nthe efforts said.\nMr. D’Angelo and Ms. McCauley asked Mr. Altman to help stabilize the company.\nThat day, more than two dozen supporters showed up at Mr. Altman’s house to lobby OpenAI’s board to reinstate \nhim. They set up laptops on his kitchen’s white marble countertops and spread out across his living room. Ms. \nMurati joined them and told the board that she could no longer be interim chief executive.\nTo capitalize on the board’s vulnerability, Mr. Altman posted on X: “i love openai employees so much.” Ms. Murati \nand dozens of employees replied with emojis of colored hearts.\nYet even as the board considered bringing Mr. Altman back, it wanted concessions. That included bringing on new \nmembers who could control Mr. Altman. The board encouraged the addition of Bret Taylor, Twitter’s former \nchairman, who quickly won everyone’s approval and agreed to help the parties negotiate. As insurance, the board \nalso sought another interim chief executive in case talks with Mr. Altman broke down.\nBy then, Mr. Altman had gathered more allies. Mr. Nadella, now confident that Mr. Altman was not guilty of \nmalfeasance, threw Microsoft’s weight behind him.\nIn a call with Mr. Altman that day, Mr. Nadella proposed another idea. What if Mr. Altman joined Microsoft? The \n$2.8 trillion company had the computing power for anything that he wanted to build.\nMr. Altman now had two options: negotiating a return to OpenAI on his terms or taking OpenAI’s talent with him to \nMicrosoft.\nThe Board Stands Firm\nBy Nov. 19, Mr. Altman was so confident that he would be reappointed chief executive that he and his allies gave \nthe board a deadline: Resign by 10 a.m. or everyone would leave.\nMr. Altman went to OpenAI’s office so he could be there when his return was announced. Mr. Brockman also \nshowed up with his wife, Anna. (The couple had married at OpenAI’s office in a 2019 ceremony officiated by Dr. \nSutskever. The ring bearer was a robotic hand.)\nTo reach a deal, Ms. Toner, Ms. McCauley and Mr. D’Angelo logged into a day of meetings from their homes. They \nsaid they were open to Mr. Altman’s return if they could agree on new board members.\nMr. Altman and his camp suggested Penny Pritzker, a secretary of commerce under President Barack Obama; \nDiane Greene, who founded the software company VMware; and others. But Mr. Altman and the board could not \nagree, and they bickered over whether he should rejoin OpenAI’s board and whether a law firm should conduct a \nreview of his leadership.\nWith no compromise in sight, board members told Ms. Murati that evening that they were naming Emmett Shear, a \nfounder of Twitch, a video-streaming service owned by Amazon, as interim chief executive. Mr. Shear was \noutspoken about developing A.I. slowly and safely.\nMr. Altman left OpenAI’s office in disbelief. “I’m going to Microsoft,” he told Mr. Chesky and others.\nInside OpenAI’s Crisis Over the Future of Artificial Intelligence The A.I. RACE\nThat night, Mr. Shear visited OpenAI’s offices and convened an employee meeting. The company’s Slack channel \nlit up with emojis of a middle finger.\nOnly about a dozen workers showed up, including Dr. Sutskever. In the lobby, Anna Brockman approached him in \ntears. She tugged his arm and urged him to reconsider Mr. Altman’s removal. He stood stone-faced.\nBreaking the Logjam\nAt 4:30 a.m. on Nov. 20, Mr. D’Angelo was awakened by a phone call from a frightened OpenAI employee. If Mr. \nD’Angelo didn’t step down from the board in the next 30 minutes, the employee said, the company would collapse.\nMr. D’Angelo hung up. Over the past few hours, he realized, things had worsened.\nJust before midnight, Mr. Nadella had posted on X that he was hiring Mr. Altman and Mr. Brockman to lead a lab at \nMicrosoft. He had invited other OpenAI employees to join.\nThat morning, more than 700 of OpenAI’s 770 employees had also signed a letter saying they might follow Mr. \nAltman to Microsoft unless the board resigned.\nOne name on the letter stood out: Dr. Sutskever, who had changed sides. “I deeply regret my participation in the \nboard’s actions,” he wrote on X that morning.\nOpenAI’s viability was in question. The board members had little choice but to negotiate.\nTo break the impasse, Mr. D’Angelo and Mr. Altman talked the next day. Mr. D’Angelo suggested former Treasury \nSecretary Lawrence H. Summers, a professor at Harvard, for the board. Mr. Altman liked the idea.\nMr. Summers, from his Boston-area home, spoke with Mr. D’Angelo, Mr. Altman, Mr. Nadella and others. Each \nprobed him for his views on A.I. and management, while he asked about OpenAI’s tumult. He said he wanted to be \nsure that he could play the role of a broker.\nMr. Summers’s addition pushed Mr. Altman to abandon his demand for a board seat and agree to an independent \ninvestigation of his leadership and dismissal.\nBy late Nov. 21, they had a deal. Mr. Altman would return as chief executive, but not to the board. Mr. Summers, \nMr. D’Angelo and Mr. Taylor would be board members, with Microsoft eventually joining as a nonvoting observer. \nMs. Toner, Ms. McCauley and Dr. Sutskever would leave the board.\nThis week, Mr. Altman and some of his advisers were still fuming. They wanted his name cleared.\n“Do u have a plan B to stop the postulation about u being fired its not healthy and its not true!!!” Mr. Conway texted \nMr. Altman.\nMr. Altman said he was working with OpenAI’s board: “They really want silence but i think important to address \nsoon.”\nNico Grant contributed reporting from San Francisco. Susan Beachy contributed research.\nNico Grant contributed reporting from San Francisco. Susan Beachy contributed research. \nThis article appeared in print on page A1, A12, A13.\nLoad-Date: December 19, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Facing a Challenger, Google Makes Gains With Its A.I. Products",
        "media": "The New York Times",
        "time": "May 11, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "972 words",
        "byline": "By Nico Grant",
        "story_text": "Facing a Challenger, Google Makes Gains With Its A.I. Products\nThe New York Times\nMay 11, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 972 words\nByline: By Nico Grant\nBody\nAt the company's annual conference, Google demonstrated dozens of products and features that work with artificial \nintelligence, along with new phones.\nWhen the San Francisco start-up OpenAI released ChatGPT late last year, the A.I. chatbot looked like the first \nsignificant threat in decades to Google. One day, tech insiders thought, it could make Google's internet search \nengine look old and stodgy. \n  Google executives vowed a fast response to protect the company's $162 billion franchise and said that artificial \nintelligence would be woven throughout its products, from the search engine to email.\n  On Wednesday, at its annual conference in Mountain View, Calif., the company demonstrated some of what it has \nbeen working on. Google said its search engine will begin incorporating responses generated by A.I. at the top of \nquery results pages and allow users to ask follow-up questions.\n  It was a notable step toward Google's embrace of A.I., which many experts believe could remake the tech \nindustry. Google was a pioneer in the technology, but had been reluctant to do too much with it because A.I. comes \nwith risks, like spreading false information.\n  But Google, along with the rest of Silicon Valley, was surprised by the success of ChatGPT. In December, Google \ndeclared a ''code red'' to find ways to incorporate the technology behind ChatGPT, called generative A.I., into its \nown products.\n  Google said at its conference on Wednesday that it has now embedded its latest A.I. technology into 25 products, \nincluding the search updates and a feature to help users write emails in Gmail.\n  ''Seven years into our journey as an A.I.-first company, we are at an exciting inflection point,'' Sundar Pichai, \nGoogle's chief executive, said at the conference. ''With generative A.I., we're taking the next step, with a bold and \nresponsible approach, we are reimagining all of our products.''\n  The company also doubled down on its hardware ambitions, releasing two new smartphones and a tablet. On the \nhigh end was the Pixel Fold, Google's first folding phone. For the budget minded, it offered the Pixel 7A, a phone \nthat costs $500. The company made its Pixel Tablet both portable and able to dock on a speaker, so it can function \nlike a smart home display.\n  Google has been racing against OpenAI and its partner, Microsoft. In February, Microsoft demonstrated how the \nnewest version of Microsoft's search engine, Bing, incorporates a chatbot that works with the technology developed \nby OpenAI.\nFacing a Challenger, Google Makes Gains With Its A.I. Products\n  But Google is still taking a more measured approach than its main competitors. The company did not include a \nchatbot, which can be prone to making up false information, in its search engine. Instead, Google said it will use A.I. \nto provide some answers, which will be corroborated by authoritative websites, and it will continue including ads in \nresponses.\n  Liz Reid, a Google search vice president, said in an interview ahead of the conference that users expected the \ncompany to have high-quality information and it did not want to undermine that trust.\n  ''The technology is early,'' Ms. Reid said. ''It's amazing in some ways and it has a bunch of challenges in other \nways.''\n  To work with the latest search features, users need to sign up for Search Labs, a new effort that allows users and \nthe company to test experimental features. The New York Times previously reported that Google will let up to 30 \nmillion people in the United States use the updates by the end of the year.\n  In March, Google released Bard, an experimental chatbot meant to compete with ChatGPT. Google on \nWednesday broadened access the tool, bringing it to more than 180 countries and territories in English, and also \noffering it in Japanese and Korean.\n  Mr. Pichai also discussed the company's efforts to build more powerful A.I. technology. He unveiled the latest \nversion of that more powerful technology, Pathways Language Model 2, or PaLM 2, and said work had begun on an \neven larger model named Gemini.\n  A.I. models are the huge systems that are used to develop artificial intelligence, and so far only a handful of \ncompanies have the resources to develop them. While protecting the search business is essential to the company's \nfuture, Google could make billions from allowing other companies to use its cloud computing services to develop \ntheir own A.I. services.\n  Google said it made Bard, which can generate emails, shopping lists and poems, more intelligent and creative by \nrunning it on PaLM 2. The chatbot will be able to show and interpret images and allow users to export responses to \nGmail, Docs and other applications.\n  The company has started integrating generative A.I. into its Workspace applications, including Gmail, Docs and \nSheets. Users will be able to use brief text descriptions to create images for a slide deck or draft documents, with \noptions to change the writing style to be more professional or casual.\n  Since ChatGPT was introduced, Google has faced criticism from tech industry insiders that it had not moved fast \nenough to improve its search. But Ms. Reid said the company's large number of users was ''the chorus we should \nlisten to the loudest.''\n  ''There is still huge opportunity in the world in meeting people's information needs and there will always be lots of \npeople trying to solve it, and I think that's great,'' she said. ''It will help us -- help everyone -- evolve.''\n  Investors have been closely watching Google's A.I. progress, and they have been concerned about the \ncompetitive threat from OpenAI and Microsoft. Mark Mahaney, an analyst at Evercore ISI, said in an interview that \nthis year's presentation did not ''end the concerns, but it partially addresses them.''\n  ''They needed to remind people that they've been doing a lot of innovation in A.I. for a long time,'' he said, ''and \nthey got that point across.''\nhttps://www.nytimes.com/2023/05/10/technology/google-ai-products.html\nGraphic\nFacing a Challenger, Google Makes Gains With Its A.I. Products\n \nPHOTOS: Sundar Pichai, Google's chief executive, showing some of what the company has been working on at its \nannual conference in San Francisco on Wednesday. (PHOTOGRAPH BY JASON HENRY FOR THE NEW YORK \nTIMES)\n Med-PaLM 2, trained by Google health research teams, can answer questions and summarize findings from a \nvariety of medical texts. (PHOTOGRAPH VIA GOOGLE) (B6) This article appeared in print on page B1, B6.               \nLoad-Date: May 11, 2023"
    },
    {
        "file_name": "used_for_evil_May2023",
        "header": "Fear over AI dangers grows as some question if tools like ChatGPT will be",
        "media": "used for evil",
        "time": "May 18, 2023",
        "section": "",
        "length": "517 words",
        "byline": "Jessica Guynn, USA TODAY",
        "story_text": "Fear over AI dangers grows as some question if tools like ChatGPT will be \nused for evil\nUSA Today Online\nMay 15, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nLength: 517 words\nByline: Jessica Guynn, USA TODAY\nBody\nAmericans are worried that artificial intelligence technologies like ChatGPT will be used to worsen social ills, from \nfraud and identity theft to extremism and hate, and they want the companies like Microsoft, Google and OpenAI that \nare rushing to commercialize these tools to do something about it, according to a new survey from the Anti-\nDefamation League shared exclusively with USA TODAY.\nThe ADL survey reflects growing unease over the rapidly evolving technologies that have the potential to improve \npeople’s lives but could also cause substantial harm, said ADL CEO Jonathan Greenblatt.\nThe majority of Americans worry that people will use AI for criminal activity (84%), spreading false or misleading \ninformation (83%), radicalizing people to extremism (77%), and inciting hate and harassment (75%), the survey \nsaid. \nThree-quarters of those surveyed – 75% – think the tools will produce biased content targeting marginalized groups \nwhile 70% say they will be used to make extremism and hate, including antisemitism, worse in America.\nGoogle ups the ante on AI Here's how search and Gmail will change.\nThe survey of 1,007 U.S. adults was released in advance of a Senate hearing Tuesday where the CEO of ChatGPT \ncreator OpenAI Sam Altman and other officials are scheduled to testify about the potential risks of AI chatbots. \n“If we’ve learned anything from other new technologies, we must protect against the potential risk for extreme harm \nfrom generative AI before it’s too late,” Greenblatt said in a statement to USA TODAY.\nThe new wave of AI tools has dazzled Americans, promising a bevy of benefits. They can carry on human-like \nconversations, write essays, compose music and create audio, video and images. \nBut these tools also have worrying implications for the future of work and education as well as the future of \nhumanity.\nLink to Image\nGeoffrey Hinton, a top architect of artificial intelligence, recently warned that AI could someday take over the world \nand push humanity toward extinction.\nThe White House recently summoned officials from Microsoft, Google and ChatGPT creator OpenAI to discuss the \nrisks and promote responsible innovation that protects the rights and safety of Americans.\nThe Federal Trade Commission has also warned that it will crack down on AI technologies if they run amok.\nFear over AI dangers grows as some question if tools like ChatGPT will be used for evil\nAI-generated images already fool people. Why experts say they'll only get harder to detect.\nThe ADL survey revealed that government concerns reflect those of most Americans.\nNearly 90% say tech companies should take steps to prevent their AI tools from creating harmful content and from \ngenerating antisemitic or extremist images and support congressional efforts to intervene. They also support audits \nof the tools, with 86% agreeing that academic or civic groups “should have access to review or audit the tools to \nmake sure they are properly constructed.”\nSome 81% said creators of these tools should be held responsible if they are used to spread hate or harassment.\nThis article originally appeared on USA TODAY: Fear over AI dangers grows as some question if tools like \nChatGPT will be used for evil\nLoad-Date: May 18, 2023"
    },
    {
        "file_name": "this_month,_some_new_personal_computers_that_run_Microsoft's_Windows_11_Jan2024",
        "header": "Microsoft's new AI key is first big change to keyboards in decades; Starting",
        "media": "this month, some new personal computers that run Microsoft's Windows 11",
        "time": "January 4, 2024",
        "section": "NATION WORLD",
        "length": "436 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Microsoft's new AI key is first big change to keyboards in decades; Starting \nthis month, some new personal computers that run Microsoft's Windows 11 \noperating system will have a special \"Copilot key\" that launches the \nsoftware giant's AI chatbot\nDayton Daily News (Ohio)\nJanuary 4, 2024 Thursday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 436 words\nByline: MATT O'BRIEN\nBody\nComputer keyboards are making room for an artificial intelligence chatbot button as Microsoft unveils its first major \nkeyboard redesign in three decades.\nStarting this month, some new personal computers that run Microsoft's Windows 11 operating system will have a \nspecial \"Copilot key\" that launches the software giant's AI chatbot. \nGetting third-party computer manufacturers like Dell to add an AI button to laptops is the latest move by Microsoft to \ncapitalize on its close partnership with ChatGPT-maker OpenAI and make itself a gateway for applications of \ngenerative AI technology. \nAlthough most people now connect to the internet  and many AI applications  by phone rather than computer, it's a \nsymbolic kickoff to what's expected to be a competitive year as tech companies race to outdo each other in AI \napplications even as they haven't yet resolved all the ethical and legal ramifications. The New York Times last \nmonth sued both OpenAI and Microsoft alleging that tools like ChatGPT and Copilot  formerly known as Bing Chat  \nare infringing on copyrighted news articles. \nThe keyboard redesign will be Microsoft's biggest change to PC keyboards since it introduced a special Windows \nkey in the 1990s. Microsoft's four-squared logo design has evolved, but the key has been a fixture on Windows-\noriented keyboards for about three decades. \nThe newest AI button will be marked by the ribbon-like Copilot logo and be located near the space bar. On some \ncomputers it will replace the right \"CTRL\" key, while on others it will replace a menu key. \nMicrosoft is not the only company with customized keys. Apple pioneered the concept in the 1980s with its \n\"Command\" key marked by a looped square design (it also sported an Apple logo for a time). Google has a search \nbutton on its Chromebooks and was first to experiment with an AI-specific key to launch its voice assistant on its \nnow-discontinued Pixelbook. \nBut Microsoft has a much stronger hold on the broader PC market through its licensing agreements with third-party \nmanufacturers like Lenovo, Dell and HP. About 82% of all desktop computers, laptops and workstations run \nWindows, compared to 9% for Apple's in-house operating system and just over 6% for Google's, according to \nmarket research firm IDC. \nMicrosoft 's new AI key is first big change to keyboards in decades Starting this month, some new personal \ncomputers that run Microsoft 's Windows 11 operating ....\nDell Technologies on Thursday was the first to unveil a Copilot key on its newest XPS laptops. \nMicrosoft hasn't yet said which other computer-makers are installing the Copilot button beyond Microsoft's own in-\nhouse line of premium Surface devices. It said some of the companies are expected to unveil their new models at \nnext week's CES gadget show in Las Vegas.\nGraphic\n \nMicrosoft's new Copilot key is seen on a Dell computer, next to the alt key, in this undated photo provided by \nAxiCom. Starting this month, some new personal computers that run Microsoft's Windows 11 operating system will \nhave the special 'Copilot key' that launches the software giant's AI chatbot. (AxiCom on behalf of Dell Technologies \nvia AP)\nLoad-Date: January 4, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Jun2023",
        "header": "For CEOs, an 'AI Manifesto'",
        "media": "The Baltimore Sun",
        "time": "June 27, 2023",
        "section": "MAIN; A; Pg. 9",
        "length": "884 words",
        "byline": "G. Anand Anandalingam and Alwin Magimay",
        "story_text": "For CEOs, an 'AI Manifesto'\nThe Baltimore Sun\nJune 27, 2023 Tuesday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 9\nLength: 884 words\nByline: G. Anand Anandalingam and Alwin Magimay\nBody\nChatGPT, its GPT-4 iteration and the broader advancement of generative AI are raising the stakes for companies \nthat are expected to incorporate this technology. CEOs, boards and top executives in such a spot should step back \nand meet the challenge with a big picture approach that systematizes a set of proven strategies.\nAI as the next competitive weapon for business relevancy, and profitability means companies must transform from \ndigital enterprises to intelligent enterprises. The latter successfully integrates AI, machine learning, data analytics \nand the Internet of Things (IoT) to drive innovation, optimize processes and create new revenue streams.\nBegin by adopting an \"AI first\" mindset. Adapt your organizational structure to the reality that \"intelligence\" \nincreasingly resides in many parts of the company. It further means nurturing and investing in talent accordingly and \nbeing cognizant of the regulatory and compliance pressures.\nAlso, think of Intelligent Enterprise as an augmented organization where AI and humans are complementary while \nadapting to the surroundings and competitive atmosphere. It's forward-looking. It's able to both exploit its current \ncompetitive advantages and explore and experiment with new innovations and ideas that emerge from its \nworkforce. Good examples include the Ocado Smart Platform, an \"end-to-end e-commerce, fulfillment and logistics \nplatform\" for grocers from the British online supermarket and tech company, and Netflix's leveraging AI to analyze \ndata on viewer preferences and behavior. This has informed decisions about what types of content to produce and \nhow to market it and has yielded hit series like \"House of Cards.\"\nAI systems enable \"decision decentralization\" - empowering employees with intelligence at their fingertips and \nallowing companies to shift responsibility to individuals closest to the outcomes of the decisions. Toyota pioneered \ndecision decentralization in manufacturing, via Jidoka. Decentralization further enables different parts of the \norganization to fix technology flaws and hire their own experts. For example, the materials science company W.L. \nGore & Associates is organized into self-managing teams under its \"lattice\" model with employees encouraged to \ntake on different roles and responsibilities based on their interests and skills.\nA vision for nurturing and enhancing talent is critical. A good model is Coca-Cola's Data Science and Analytics \nAcademy for employees across departments and job roles, which has helped optimize operations, improve supply \nchain management, and enhance customer experiences using AI-powered solutions. \nConfidence also must be elicited in stakeholders and regulators. Decentralized intelligence and decision-making will \nbehave in sometimes unexpected ways, as will government regulations of AI-based systems and decisions. \nFurthermore, different countries may have different perspectives on societal impacts of AI-based systems (privacy, \nautonomy, etc.). Microsoft has a model for such mitigation with its AETHER (AI and Ethics in Engineering and \nFor CEOs, an 'AI Manifesto'\nResearch) committee of experts in computer science, philosophy and law to review and advise on legal and ethical \nimplications.\nHumancentric - not artificial - intelligence is most essential to success and survival in this emerging era. As a recent \nstudyinvolving 1,500 firms in a range of industries indicates,indicates, the largest rate-of-return will be made with \n\"Human 2.0\" - humans and AI-based machines working together to yield intelligent decisions, i.e., true intelligence.\nTo position your company for maximum value from integrating the gains from technology, especially AI with human \ningenuity and capabilities, refer to the checklist below as an \"AI Manifesto for the Intelligent Enterprise CEO\":\nBecome an \"AI first\" organization: Embed AI into your purpose and vision.\nAdopt an \"AI-everywhere\" premise: Embed AI into every change, transformation and innovation program.\nAugment every business process with AI: Explore and implement new use cases for AI across the business.\nIncrease your organization's AI IQ: Foster a culture of innovation and learning, and invest in the education and \ntraining of your employees.\nCreate high-performing AI augmented teams: Remove \"artificial\" from AI so that your teams effectively use AI \nenablers and tools.\nBuild diverse and inclusive AI teams: Partner with organizations that promote diversity and inclusion in AI.\nPromote ethical AI: Use data responsibly, and ensure your AI systems are transparent, explainable bias-free and \nfair.\nEmbrace progressive innovation in AI: Regularly assess the impact of your AI initiatives and make continuous \nadjustments to ensure they align with your purpose, values and goals.\nAI is \"human augmenting\" rather than \"human replacing.\" AI-based automation may be tempting as a panacea for \ncutting costs, and this may be of value in the short run. But humans connect with customers better. As future \ntechnology and markets change constantly and rapidly, customers will increasingly make decisions based on trust \nand empathy.\nG. Anand Anandalingam (ganand@umd.edu) is professor of management science at the University of Maryland's \nRobert H. Smith School of Business, and Alwin Magimay (alwinmagimay@hotmail.com) is global head of AI for PA \nConsulting, London, U.K.\nLoad-Date: June 27, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Dec2023",
        "header": "SaaS Startup Kapture Gets $4 million",
        "media": "Economic Times (E-Paper Edition)",
        "time": "December 19, 2023",
        "section": "STARTUPS & TECH",
        "length": "122 words",
        "byline": "Our Bureau",
        "story_text": "SaaS Startup Kapture Gets $4 million\nEconomic Times (E-Paper Edition)\nDecember 20, 2023 Wednesday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 122 words\nByline: Our Bureau\nBody\nBengaluru: Kapture CX, a customer support platform for enterprises, has raised $4 million from India Alternatives, a \nprivate equity fund. The Bengalurubased startup has been expanding on-ground operations in five countries: the \nUS, the UAE, Indonesia, Saudi Arabia and India. The company last raised funds in July — a $4 million round led by \nventure capital firm Cactus Venture Partners (CVP). The latest infusion will be used to push Kapture’s generative \nartificial intelligence (Gen AI) capabilities and strengthen its footprint across India as well as global markets, the \ncompany said in a statement. Having crossed a 1,000 customers from 19 countries, the company is planning to add \n100 more employees next year, the statement added.\nLoad-Date: December 19, 2023"
    },
    {
        "file_name": "reveals_real_tragedy_of_AI_Dec2023",
        "header": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; Sports Illustrated's fall",
        "media": "reveals real tragedy of AI",
        "time": "December 4, 2023",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1503 words",
        "byline": "BRIAN MERCHANT",
        "story_text": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; Sports Illustrated's fall \nreveals real tragedy of AI\nLos Angeles Times\nDecember 4, 2023 Monday\nFinal Edition\nCopyright 2023 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1503 words\nByline: BRIAN MERCHANT\nBody\nQuick, name five classic American magazines.\nDid you say Sports Illustrated? I did. And I'm not even a sports guy. But if you're of a certain age, you know Sports \nIllustrated. Along with, say, People, Time and National Geographic, it has long lined the dentist offices, neighbors' \ndoormats and coffee tables of your life. It's an institution. At one point, it boasted 3 million subscribers. It's won \nnumerous awards and accolades. The evening news would do whole segments about its swimsuit issue.\nToday, it's pumping out third-rate articles by AI-generated writers in a darkening corner of the internet. It's a \nstunning fall for one of the great icons of American sports journalism. So what happened? How did such a \ncelebrated publication get here? The answers point us to one of the most pressing -- and unlikely -- dangers posed \nby the AI boom.\nFirst, the facts: On Monday, the tech and culture site Futurism published an expose that revealed Sports Illustrated \nwas publishing bizarre and badly written articles attributed to authors that didn't exist.\nThe reporters traced the fake authors' head shots to a website that sells AI-generated images, and sources told \nthem that the stories they allegedly wrote were produced by AI too. \"The content is absolutely AI-generated,\" one \nsaid, \"no matter how much they say that it's not.\" When contacted, Arena Group, Sports Illustrated's publisher, \ndeleted all of the suspicious content and, in a statement, denied it was created by AI. Arena blamed the mess on \nAdVon, a third-party company hired to produce content.\nThe saga has been heatedly discussed by journalists and media watchers, and lamented by onetime fans of the \niconic brand. Generative AI very much remains a hot-button topic, and the question of whether it's ethical -- or a \ngood idea -- to use AI has driven much of the conversation.\nBut it's worth backing up and looking at the bigger picture here, and the conditions that led to the use of such \nsketchy AI in the first place. Because this story is as much about bad management, sheer laziness and how \nrelentlessly profit-seeking corporate management can erode our cultural institutions as it is about any given \ntechnology.\nSports Illustrated was already in dire shape long before Arena brought in the AI. Amid economic challenges that \nconfront all print media, the magazine's revenue and subscriber base declined over the 2010s. It repeatedly \ndownsized, switched from a weekly to a monthly publication schedule and was sold by its owner, Time Inc., to a \ncompany called Authentic Brands Group, or ABG, which is in the business of inking lucrative licensing deals. ABG \nthen sold a 10-year license to publish Sports Illustrated to our new friends at Arena Group.\nBUSINESS ON TECHNOLOGY AND THE INTERNET Sports Illustrated's fall reveals real tragedy of AI\nAs a result of this arrangement, Sports Illustrated branding is now showing up both on dietary supplements and on \nthousands of hastily produced blog posts. After all, on the publication side of the business, \"Arena's options for \ngenerating revenue are somewhat limited, encouraging a daily churn of articles,\" as the New York Times reports. \n\"Hundreds of sites dedicated to individual teams -- helmed by non-staff writers paid small sums -- were created with \nlittle oversight and diluted what it meant for 'Sports Illustrated' to write something.\" Arena has continued to fire \neditors and staffers, while enforcing weekly quotas of article production. (On the licensing side, business is booming \n-- ABG says it has doubled Sports Illustrated's earnings. That's a lot of Sports Illustrated-brand diet pills. It also \nlaunched an online SI-branded casino in 2021.)\nIn other words, Sports Illustrated is run by not one but two vampiric entities with markedly little interest in the \nmagazine's erstwhile core mission -- you know, the thing that made it so beloved in the first place, doing good \nsports journalism -- and every interest in maximizing profits at every opportunity. And they have squeezed the \nlemon until it was dry.\nAnd here's where the AI comes in.\nNot as a tool deployed by forward-looking executives eager to embrace the future, but as a last-ditch effort to \nextract the final bits of value from the pieces of something that's already broken. Sports Illustrated has already \nslashed full-time staff, spun up a content mill with freelancers pumping out content for a fraction of the price, and let \neditorial standards sink into the gutter. The AI play is an arrow out of the same quiver.\nIt's increasingly clear that to those in the content-generation business -- worth noting maybe that the original \nfounders of Sports Illustrated would probably bristle at such a term -- AI has become popular as a relatively cheap, \nwholly unimaginative way to attempt to generate value with the lowest amount of effort or investment.\nTo wit: This year has already seen a rash of AI scandals in the media world. The staffers of G/O Media, the \npublisher of popular sites including Gizmodo and the Onion, revolted after their publisher deployed generative AI to \nproduce bland, error-ridden content. The once-venerable tech site CNET was caught -- also by Futurism, \nincidentally -- publishing AI-generated stories without disclosing them as such. BuzzFeed controversially \nannounced that it would be using AI to generate posts like its trademark quizzes, and then disbanded its human-\nstaffed News division.\nMost recently, Gannett, the publisher of USA Today and many other newspapers, was accused of publishing AI-\ngenerated review content -- curiously, it too blamed AdVon, the same company Sports Illustrated fingered in its \nstatement on the matter.\nAll of these stories have one major thread in common -- each of the media institutions in question had been facing \neconomic challenges, and was run by an owner whose interest was not in producing a quality publication but \ngaming the algorithm to maximize profits while minimizing staff. As with SI, all were in dire straits before AI entered \nthe equation.\nG/O Media, formerly GMG Media, formerly Gawker Media, had been bankrupted by a malicious lawsuit funded by \nSilicon Valley titan Peter Thiel, repackaged and sold to Univision, then sold again to a private equity firm, Great Hill \nPartners. In a push to maximize revenues, Great Hill set about firing staffers, introducing spammy autoplay ads and \nasking staff to write more slideshows, which require readers to click more times than regular stories. In short, a \nnakedly profit-seeking agenda -- one that came at the direct expense of both staff and readers -- was in place long \nbefore the publisher started mucking around with AI.\nWhen it finally did, notably publishing an article whose sole purpose was to list the \"Star Wars\" movies in order and \nyet got the order wrong -- it caused an uproar.\nSimilarly, CNET has been hurting for years. Once a powerhouse of tech media, it was acquired by CBS for $1.8 \nbillion in 2008, then was sold to a little-known private equity company based in South Carolina called Red Ventures. \nThe Verge describes its business model as \"straightforward and explicit: it publishes content designed to rank \nBUSINESS ON TECHNOLOGY AND THE INTERNET Sports Illustrated's fall reveals real tragedy of AI\nhighly in Google search for 'high-intent' queries and then monetizes that traffic with lucrative affiliate links.\" AI was \nused, it is believed, to streamline and maximize that process.\nBoth CNET and G/O are now owned by private equity firms, and much has been written about what a disaster it's \nbeen for journalism to hand such companies the keys -- one academic paper even quantified the damage. Which \nhas been considerable.\nAs a journalist, all of this depresses me -- I worked for Gizmodo for a bit and was once an avid reader of Gawker, \nDeadspin and the AV Club, all of which have been gutted. BuzzFeed News won a Pulitzer and was widely loved. \nSports Illustrated was a legend.\nAnd look, things change. Cultural institutions evolve, fade, die out. Not every magazine needs to exist forever. But it \nis a bummer when an otherwise popular, viable, even beloved cultural institution is killed off -- while there's a team \nthat's working overtime at the helm to keep the lights on -- because a Wall Street firm or an adventuring licensing \ncompany can increase earnings at the margins by cutting out its heart.\nThe tragedy of AI is not that it stands to replace good journalists but that it takes every gross, callous move made \nby management to degrade the production of content -- and promises to accelerate it.\nIf journalists are outraged at the rise of AI and its use in editorial operations and newsrooms, they should be \noutraged not because it's a sign that they're about to be replaced but because management has such little regard \nfor the work being done by journalists that it's willing to prioritize the automatic production of slop.\nAI does not emerge from a media company's innovation lab but from a handshake deal with a shady third-party \ncompany. It's a Hail Mary move that aspires to take the place of formulating a real plan to turn a business around -- \na future-shaped Get Out of Jail Free card for business leaders confronting bad times. And it's almost certain to fail \nto deliver.\nGraphic\n \nPHOTO: A FAN holds a copy of Sports Illustrated in 2006. The once iconic magazine is in dire shape and has been \npumping out third-rate articles by AI-generated writers.  PHOTOGRAPHER:Lawrence Jackson Associated Press \nLoad-Date: December 4, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Republican Bashing of E.S.G. Gets More Complicated; DealBook Newsletter",
        "media": "The New York Times",
        "time": "February 22, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1936 words",
        "byline": "Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat Livni",
        "story_text": "Republican Bashing of E.S.G. Gets More Complicated; DealBook Newsletter\nThe New York Times \nFebruary 22, 2023 Wednesday 12:25 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1936 words\nByline: Andrew Ross Sorkin, Ravi Mattu, Sarah Kessler, Michael J. de la Merced, Lauren Hirsch and Ephrat Livni\nHighlight: A number of Republican lawmakers have taken money from the companies they vilified. But some of the \nparty’s presidential hopefuls are still on the attack.\nBody\nA number of Republican lawmakers have taken money from the companies they vilified. But some of the party’s \npresidential hopefuls are still on the attack.\nThe case for fighting E.S.G. gets messy\nMany Republicans have made railing against the environmental, social and corporate governance investing \nmovement a cornerstone of their political success. (Indeed, Vivek Ramaswamy, the financier who rose to fame \nbattling against “woke capitalism,” announced a long-shot bid for the 2024 G.O.P. presidential nomination \nyesterday.)\nBut that stance is growing increasingly complicated — especially given new revelations that lawmakers who have \npublicly berated companies for pursuing E.S.G. strategies have also taken big donations from those same \nbusinesses.\nBashing E.S.G. and left-leaning companies has been highly fruitful for Republicans. Gov. Ron DeSantis of Florida, \nwidely considered a front-runner for the Republican presidential nomination, has scored political points for picking a \nfight with Disney over its opposition to his state’s so-called “Don’t Say Gay” law.\nAnd he and other G.O.P. state officials have taken on investment giants like BlackRock, one of the biggest \nproponents of E.S.G. policies, and Vanguard, threatening to pull billions in state money from those firms over their \nsupport of environmental and social considerations in investing. Mike Pence, who may also run for president, last \nyear accused “a few Wall Street financiers” of pushing a left-wing agenda that Democrats hadn’t been able to get \napproved at the ballot box.\n(Mr. Ramaswamy, who wrote “Woke Inc.” and whose Strive Asset Management has targeted Apple, BlackRock and \nDisney, has sought to capitalize on that stance in the business world.)\nBut the money trail complicates things. CNBC reports that 10 of the 29 Republicans on the House Financial \nServices Committee (including its chairman, Representative Patrick McHenry of North Carolina) took in a combined \n$140,000 in campaign donations from BlackRock, State Street and Vanguard during the 2022 election cycle, \naccording to Federal Election Commission filings. All three of those companies are regularly criticized by \nconservative lawmakers.\nThat’s on top of recent pushback in states like Kentucky against G.O.P. efforts to remove public pension funds’ \nmoney from firms like BlackRock.\nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nSome Republicans are moving away from strident opposition to E.S.G. Among them is Mr. Ramaswamy himself, \nwho wrote in a Wall Street Journal opinion piece last month that it’s actually acceptable for investors to support \nenvironmental goals, so long as they’re transparent about their efforts.\nHERE’S WHAT’S HAPPENING \nStocks plunge on worries about bigger interest-rate increases. Markets in Europe and Asia followed Wall Street’s \nbig tumble yesterday as investors grew concerned that strong economic data in the U.S. and Europe meant central \nbanks would keep rates higher for longer. All eyes will be on today’s release of minutes from the most recent \nmeeting of the Fed’s Federal Open Market Committee for clues about where it might go next.\nCitigroup bucks the trend on C.E.O. pay. The firm awarded Jane Fraser a nearly 9 percent increase in \ncompensation for last year, to $24.5 million. She’s the only Wall Street chief to get a raise, as rivals saw their pay \nremain unchanged or cut.\nMcKinsey reportedly plans to cut up to 2,000 jobs. The consulting giant is planning one of its biggest-ever rounds of \nlayoffs, according to Bloomberg and other news outlets. The cuts are expected to focus on back-end employees \nwho don’t interact with clients; they’re meant in part to preserve McKinsey’s compensation pool for partners.\nCredit Suisse keeps falling after reports of another inquiry. Shares in the embattled Swiss bank were down again \ntoday, after Reuters reported that Switzerland’s financial regulator was examining comments by the firm’s chairman, \nAxel Lehmann, about client withdrawals in December.\nTech’s big shield may live on \nA fundamental law governing today’s internet — Section 230 of the Communications Decency Act, which protects \nsocial media companies from lawsuits over users’ posts — faced a big test yesterday in a highly anticipated case \nbefore the Supreme Court.\nBut those hoping the high court would move to curtail the tech giants’ legal shield were likely disappointed: Justices \nappeared skeptical that they could, or should, go that far.\nJustices heard arguments for nearly three hours in a lawsuit filed against Google’s YouTube by the family of a \nvictim of the 2015 terrorist attacks in Paris. The plaintiffs argue that YouTube’s algorithms pushed Islamic State \nvideos to interested users and that the company bore responsibility. (The Biden administration has largely argued in \nsupport of the family’s position.) Lawyers for Google argue that recommendation algorithms are neutral.\nWhat’s at stake: Tech companies and their allies, as well as the original drafters of Section 230, worry that allowing \nexceptions could make sites with user-generated content — from Instagram and Twitter to restaurant review \nplatforms and marketplaces — liable for every decision to present or not present third-party content.\nCritics of Section 230 say the law is outdated and too broad, giving tech giants nearly unlimited legal protection.\nThe justices mostly suggested they weren’t ready to hold tech giants liable just yet:\n• Justice Clarence Thomas defended recommendations as a vital part of the internet. “If you’re interested in \ncooking, you don’t want thumbnails on light jazz,” he said.\n• Justice Brett Kavanaugh worried that imposing limits on Section 230 “would really crash the digital economy, \nwith all sorts of effects on workers and consumers, retirement plans and what have you.”\n• Justice Elena Kagan cracked more broadly about how ill-equipped she and her colleagues were: “These are \nnot the nine greatest experts on the internet.”\nThat doesn’t mean the Supreme Court favors the status quo. Kagan noted that Section 230 was a “pre-algorithm \nstatute” that offered little guidance in “a post-algorithm world.” And Justice Neil Gorsuch questioned whether \nalgorithms were truly neutral, since the formulas are “designed to maximize profits,” implying that companies are \nmaking decisions that could incur liability.\nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nUltimately, several justices suggested, this wasn’t a matter for the courts, but for Congress.\nMicrosoft draws red lines in its deal fight \nAfter testifying yesterday in Brussels about Microsoft’s $69 billion takeover bid for Activision Blizzard, the tech \ngiant’s president, Brad Smith, issued a challenge to regulators: Don’t try to force Microsoft to divest parts of \nActivision in exchange for approving the deal.\nProposals like selling off popular games are a nonstarter, according to Mr. Smith. It isn’t “feasible or realistic to think \nthat one game or one slice of this company can be carved out and separated from the rest,” he told reporters after \nhe spoke with the European Commission.\nIt was a rejoinder to Britain’s Competition and Markets Authority, which this month suggested that it would only \napprove the Activision deal if Microsoft chose so-called structural remedies, like divesting the popular “Call of Duty” \nfranchise. (In the U.S., the F.T.C. has already sued to block the deal.)\nMr. Smith pointed to less onerous concessions that Microsoft was willing to make. He noted that the company had \njust signed deals to give access to “Call of Duty” and other games to rival gaming companies, including Nintendo \nand Nvidia. Mr. Smith also reiterated that Microsoft was prepared to reach a similar deal with Sony.\nIt’s a bet that Microsoft can rely on what are known as behavioral remedies, where a company promises to address \nregulators’ concerns, instead of taking the more drastic step of selling off businesses. But it’s a risky gamble, given \nregulators’ increasing skepticism about anything short of permanent structural changes to avoid antitrust violations.\n• In other antitrust news, the F.T.C. said it won’t block Amazon’s $3.9 billion takeover of One Medical.\n“Five days ago, the chart we shared showed nearly 350 of these submissions. Today, it crossed 500. Fifty of them \njust today, before we closed submissions so we can focus on the legit stories.”\n— Neil Clarke, the founder and editor of the sci-fi magazine Clarkesworld. His publication has stopped accepting \nstories after being inundated with submissions enhanced with generative A.I. programs like ChatGPT. \nA church’s hidden billions \nThe Church of Jesus Christ of Latter-day Saints, commonly known as the Mormon Church, isn’t usually known for \nfinancial riches. But the church and Ensign Peak Advisors, a nonprofit that runs its investment portfolio, agreed \nyesterday to pay a combined $5 million to settle charges by the S.E.C. that they had illicitly sought to obscure its \n$44 billion in assets for nearly 20 years.\nEnsign Peak used a web of shell companies to hide its portfolio, an arrangement approved by the church, according \nto the S.E.C. Ultimately, it created 13 entities that filed regulatory disclosure forms with the S.E.C. that claimed they \nmanaged parts of the portfolio — even though Ensign Peak was the real manager.\nBehind the move was the church’s concern that public knowledge of its vast holdings — by comparison, Yale’s \nclosely watched endowment as of last summer was worth just over $41 billion — might discourage its members \nfrom donating, an Ensign Peak official told The Wall Street Journal in 2020.\nThe scheme first came to light via a huge leak of documents in 2018, when the website MormonLeaks disclosed the \nexistence of the shell companies. The next year, the S.E.C. began an inquiry into the church’s finances. Ensign \nPeak began filing consolidated regulatory disclosures in its name in 2020.\nIn a statement, the church said it had relied upon legal advice in the matter and didn’t admit to or deny breaking the \nlaw. “We affirm our commitment to comply with the law, regret mistakes made, and now consider this matter \nclosed,” it said.\nTHE SPEED READ \nRepublican Bashing of E.S.G. Gets More Complicated DealBook Newsletter\nDeals\n• Rupert Murdoch’s News Corp is no longer in talks to sell the parent company of Realtor.com to CoStar. (WSJ)\n• Shares in Sigma Lithium, a Canadian metals miner, jumped 16 percent yesterday after a report that Tesla was \nweighing a takeover bid. (Insider)\n• Bao Fan, the star Chinese deal maker who went missing this month, was reportedly working to move his \nfortune out of China and Hong Kong to Singapore before he disappeared. (FT)\n• More office landlords are defaulting on their debts, thanks to the rise of remote working. (WSJ)\nPolicy\n• The Justice Department is reportedly investigating potential campaign-finance violations by Sam Bankman-\nFried, the FTX founder. (Puck)\n• Wells Fargo said U.S. regulators were examining the bank’s retention of employee messages sent using \nunauthorized messaging apps. (Bloomberg)\n• The Labor Department ruled that companies can’t make employees sign nondisparagement clauses as part of \ntheir severance agreements. (Axios)\nBest of the rest\n• BYD, the Chinese electric car giant, wants to conquer the German auto market. (NYT)\n• Twitter is said to be eliminating more employees after Elon Musk said the company was finished laying off \nstaff. (The Verge)\n• How a philanthropic movement led Sam Bankman-Fried, the founder of FTX, to begin his career at the hedge \nfund Jane Street Capital. (NYT)\n• Would you like some olive oil in that Starbucks coffee? (Insider)\nWe’d like your feedback! Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Vivek Ramaswamy has gone from professional E.S.G. critic to presidential candidate. (PHOTOGRAPH \nBY Anthony Anex/EPA, via Shutterstock FOR THE NEW YORK TIMES)\nLoad-Date: February 22, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "AI is Here, but is Yet to Make a Big Impact on Marketing",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 13, 2023",
        "section": "BRANDS & COMPANIES",
        "length": "725 words",
        "byline": "Shephali.Bhatt@timesgroup.com",
        "story_text": "AI is Here, but is Yet to Make a Big Impact on Marketing\nEconomic Times (E-Paper Edition)\nSeptember 13, 2023 Wednesday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BRANDS & COMPANIES\nLength: 725 words\nByline: Shephali.Bhatt@timesgroup.com\nHighlight: CXOs seem more concerned with rethinking their marketing strategy to be able to measure the direct \nimpact of ad spends, says McKinsey exec\nBody\nMumbai: AI (artificial intelligence) may be the buzzword in marketing right now, but CXOs seem more concerned \nwith rethinking their marketing strategy to be able to measure the direct impact of ad spends and finding the right \ntalent, Stephan Zimmermann, senior partner at McKinsey & Company, said. Based in San Francisco, Zimmermann \nheads the consulting major's digital marketing and data analytics team of 1,400, half of whom are stationed in India. \nDuring his recent visit to India, Zimmermann had some 15-odd client meetings, but “nobody mentioned or \ndiscussed an AI tool saying they strongly believed in it or asked what I thought of it”, he told ET in an exclusive chat. \nPeople are readily using generative AI to optimise marketing, automate repetitive tasks, and accelerate A/B \ntesting. \nHowever, “no-  ne of the tools have yet transformed company performance”, he said. “A lot of companies spend \nmassively on martech (marketing technology) tools but get only onethird of the value out of it,” he said, emphasising \nthat the next few years will see many of them pick a few core tools to extract maximum value out of them as \npressure for measurement mounts on them.  A few years ago, digital was less than 10% of the advertising pie in \nIndia. “Today, it's at about 35%, and we expect it to go north of 60% in the next three years, similar to the way it has \ngrown in the US,” said Zimmermann who has spent over 25 years with McKinsey and focuses on online \nbusinesses.  Traditionally, companies had separate budgets for brand building and performance marketing, he \nnoted. “The traditional channels for brand building, like print, TV, and outdoor, were hard to measure. But most \nleading companies are now focused on measuring the impact of full-funnel marketing, and digital  brand building \nallows you to do that with access to data,” he said. Zimmermann pointed out that roughly 10% of McKinsey's \nclientele in India, and 20% globally, now hire data scientists in their core marketing team. He expects 50% of these \ncompanies to have data scientists in their marketing departments in the next three to five years.  How can \nMcKinsey still provide value to these companies if they already employ data scientists of their own? Zimmermann \nargued they get companies “on the right operating models and build capabilities that help them utilise the talent \noptimally”. “We are moving from being advisors to companies or mere consultants, into the role of an impact \npartner,” he added.  Speaking of shifts, he pointed out how not too long ago, consumers “actively went shopping” \nwhereas now they are “actively advertised” products on social media and the internet in general, based on their \nspecific interests.  “Today, retail media networks in India may be getting about 5% of overall digital spending, but \nthis number will dramatically go up to the global level of 15-20% in line with the overall digital marketing growth,” \nZimmermann said. “And even as retail media networks like Amazon eat into Google and Meta's share in the ad pie \nin pure percentage terms, it won't take away much in absolute terms because the overall pie is growing massively \nwith more budgets shifting to digital,” he added. He doesn't share the same optimism for the prospects of live \ncommerce — selling products via a live stream on digital platforms — in India though. According to a McKinsey \nreport from 2021, China's live commerce industry was  valued at over $171 billion in 2020 and had been growing \nAI is Here, but is Yet to Make a Big Impact on Marketing\nsteadily ever since. In India, the market is projected to be anywhere between $5 billion and $50 billion by 2025, \naccording to multiple market research company reports. “It's not a function of what went wrong in India with respect \nto live commerce. The category hasn't picked up in the US as well where it is still probably 2-3% of all ecommerce \n(roughly $30 billion),” Zimmermann said. “I think it has to do with the difference in shopping and social behaviour in \nmarkets like India and the US compared to China. Our sense is, it will grow in both these markets, too, but not \nbecome 20% of all ecommerce revenue the way it is in China right now, which is a highly influencerled ecommerce \nmarket.” Further, in a market like India, it's likely that live commerce will be led by “info-based influencers” as \nopposed to the ones showcasing a “flashy” lifestyle, Zimmermann concluded.\nLoad-Date: September 13, 2023"
    },
    {
        "file_name": "technology_companies_signed_a_pact_Friday_to_voluntarily_adopt_\"reasonable_Feb2024",
        "header": "Tech companies sign accord to combat AI-generated election trickery; Major",
        "media": "technology companies signed a pact Friday to voluntarily adopt \"reasonable",
        "time": "February 16, 2024",
        "section": "NATION WORLD",
        "length": "1203 words",
        "byline": "MATT O'BRIEN and ALI SWENSON",
        "story_text": "Tech companies sign accord to combat AI-generated election trickery; Major \ntechnology companies signed a pact Friday to voluntarily adopt \"reasonable \nprecautions\" to prevent artificial intelligence tools from disrupting \ndemocratic elections worldwide\nDayton Daily News (Ohio)\nFebruary 16, 2024 Friday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2024 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1203 words\nByline: MATT O'BRIEN and ALI SWENSON\nBody\nMajor technology companies signed a pact Friday to voluntarily adopt \"reasonable precautions\" to prevent artificial \nintelligence tools from being used to disrupt democratic elections around the world.\nExecutives from Adobe, Amazon, Google, IBM, Meta, Microsoft, OpenAI and TikTok gathered at the Munich \nSecurity Conference to announce a new framework for how they respond to AI-generated deepfakes that \ndeliberately trick voters. Twelve other companies  including Elon Musk's X  are also signing on to the accord. \n\"Everybody recognizes that no one tech company, no one government, no one civil society organization is able to \ndeal with the advent of this technology and its possible nefarious use on their own,\" said Nick Clegg, president of \nglobal affairs for Meta, the parent company of Facebook and Instagram, in an interview ahead of the summit. \nThe accord is largely symbolic, but targets increasingly realistic AI-generated images, audio and video \"that \ndeceptively fake or alter the appearance, voice, or actions of political candidates, election officials, and other key \nstakeholders in a democratic election, or that provide false information to voters about when, where, and how they \ncan lawfully vote.\" \nThe companies aren't committing to ban or remove deepfakes. Instead, the accord outlines methods they will use to \ntry to detect and label deceptive AI content when it is created or distributed on their platforms. It notes the \ncompanies will share best practices with each other and provide \"swift and proportionate responses\" when that \ncontent starts to spread. \nThe vagueness of the commitments and lack of any binding requirements likely helped win over a diverse swath of \ncompanies, but disappointed advocates were looking for stronger assurances. \n\"The language isn't quite as strong as one might have expected,\" said Rachel Orey, senior associate director of the \nElections Project at the Bipartisan Policy Center. \"I think we should give credit where credit is due, and \nacknowledge that the companies do have a vested interest in their tools not being used to undermine free and fair \nelections. That said, it is voluntary, and we'll be keeping an eye on whether they follow through.\" \nClegg said each company \"quite rightly has its own set of content policies.\" \nTech companies sign accord to combat AI-generated election trickery Major technology companies signed a \npact Friday to voluntarily adopt \"reasonable precautions....\n\"This is not attempting to try to impose a straitjacket on everybody,\" he said. \"And in any event, no one in the \nindustry thinks that you can deal with a whole new technological paradigm by sweeping things under the rug and \ntrying to play whack-a-mole and finding everything that you think may mislead someone.\" \nSeveral political leaders from Europe and the U.S. also joined Friday's announcement. European Commission Vice \nPresident Vera Jourova said while such an agreement can't be comprehensive, \"it contains very impactful and \npositive elements.\" She also urged fellow politicians to take responsibility to not use AI tools deceptively and \nwarned that AI-fueled disinformation could bring about \"the end of democracy, not only in the EU member states.\" \nThe agreement at the German city's annual security meeting comes as more than 50 countries are due to hold \nnational elections in 2024. Bangladesh, Taiwan, Pakistan and most recently Indonesia have already done so. \nAttempts at AI-generated election interference have already begun, such as when AI robocalls that mimicked U.S. \nPresident Joe Biden's voice tried to discourage people from voting in New Hampshire's primary election last month. \nJust days before Slovakia's elections in November, AI-generated audio recordings impersonated a candidate \ndiscussing plans to raise beer prices and rig the election. Fact-checkers scrambled to identify them as false as they \nspread across social media. \nPoliticians also have experimented with the technology, from using AI chatbots to communicate with voters to \nadding AI-generated images to ads. \nThe accord calls on platforms to \"pay attention to context and in particular to safeguarding educational, \ndocumentary, artistic, satirical, and political expression.\" \nIt said the companies will focus on transparency to users about their policies and work to educate the public about \nhow they can avoid falling for AI fakes. \nMost companies have previously said they're putting safeguards on their own generative AI tools that can \nmanipulate images and sound, while also working to identify and label AI-generated content so that social media \nusers know if what they're seeing is real. But most of those proposed solutions haven't yet rolled out and the \ncompanies have faced pressure to do more. \nThat pressure is heightened in the U.S., where Congress has yet to pass laws regulating AI in politics, leaving \ncompanies to largely govern themselves. \nThe Federal Communications Commission recently confirmed AI-generated audio clips in robocalls are against the \nlaw, but that doesn't cover audio deepfakes when they circulate on social media or in campaign advertisements. \nMany social media companies already have policies in place to deter deceptive posts about electoral processes  AI-\ngenerated or not. Meta says it removes misinformation about \"the dates, locations, times, and methods for voting, \nvoter registration, or census participation\" as well as other false posts meant to interfere with someone's civic \nparticipation. \nJeff Allen, co-founder of the Integrity Institute and a former Facebook data scientist, said the accord seems like a \n\"positive step\" but he'd still like to see social media companies taking other actions to combat misinformation, such \nas building content recommendation systems that don't prioritize engagement above all else. \nLisa Gilbert, executive vice president of the advocacy group Public Citizen, argued Friday that the accord is \"not \nenough\" and AI companies should \"hold back technology\" such as hyper-realistic text-to-video generators \"until \nthere are substantial and adequate safeguards in place to help us avert many potential problems.\" \nIn addition to the companies that helped broker Friday's agreement, other signatories include chatbot developers \nAnthropic and Inflection AI; voice-clone startup ElevenLabs; chip designer Arm Holdings; security companies \nMcAfee and TrendMicro; and Stability AI, known for making the image-generator Stable Diffusion. \nTech companies sign accord to combat AI-generated election trickery Major technology companies signed a \npact Friday to voluntarily adopt \"reasonable precautions....\nNotably absent is another popular AI image-generator, Midjourney. The San Francisco-based startup didn't \nimmediately respond to a request for comment Friday. \nThe inclusion of X  not mentioned in an earlier announcement about the pending accord  was one of the surprises \nof Friday's agreement. Musk sharply curtailed content-moderation teams after taking over the former Twitter and \nhas described himself as a \"free speech absolutist.\" \nIn a statement Friday, X CEO Linda Yaccarino said \"every citizen and company has a responsibility to safeguard \nfree and fair elections.\" \n\"X is dedicated to playing its part, collaborating with peers to combat AI threats while also protecting free speech \nand maximizing transparency,\" she said. \nThe Associated Press receives support from several private foundations to enhance its explanatory coverage of \nelections and democracy. See more about AP's democracy initiative here. The AP is solely responsible for all \ncontent.\nGraphic\n \nFILE - Meta's president of global affairs Nick Clegg speaks at the World Economic Forum in Davos, Switzerland, \nJan. 18, 2024. Adobe, Google, Meta, Microsoft, OpenAI, TikTok and other companies are gathering at the Munich \nSecurity Conference on Friday to announce a new voluntary framework for how they will respond to AI-generated \ndeepfakes that deliberately trick voters. (AP Photo/Markus Schreiber, File)\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "study_says_Aug2023",
        "header": "Fed rate hikes don't just fight inflation. They hurt economy over long-term,",
        "media": "study says",
        "time": "August 28, 2023",
        "section": "CENTRAL BANKS NEWS, CENTRAL BANKS NEWS, CENTRAL BANKS NEWS & US FEDERAL",
        "length": "786 words",
        "byline": "Paul Davidson, USA TODAY",
        "story_text": "Fed rate hikes don't just fight inflation. They hurt economy over long-term, \nstudy says\nUSA Today Online\nAugust 25, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: CENTRAL BANKS NEWS, CENTRAL BANKS NEWS, CENTRAL BANKS NEWS & US FEDERAL \nGOVERNMENT NEWS\nLength: 786 words\nByline: Paul Davidson, USA TODAY\nBody\nHiking interest rates aggressively, as the Federal Reserve has done over the past 14 months, doesn’t just fight \ninflation by tamping down economic growth in the short term.\nThe strategy also curtails the economy’s output and growth potential over the long run by discouraging innovation, \naccording to a paper set to be presented Friday at the Fed’s annual conference in Jackson Hole, Wyoming.\n“Our findings suggest that monetary policy may affect the productive capacity of the economy in the longer term,” \nstates the study by Yurean Ma and Kaspar Zimmerman, economics and finance professors at the University of \nChicago. “A slower pace of innovation may then have lasting effects.”\nBroadly, a percentage point increase in interest rates could reduce economic output by 1% up to nine years later, \nthe authors say. Since the Fed has raised its key interest rate by 5.25 percentage points since March 2022, that \nsuggests the campaign could lead to a 5% reduction in output in coming years.\nWith inflation easing but still high and economic and job growth remaining sturdy, Fed officials are debating whether \nto raise rates again this year or hold them steady to avoid a possible recession.\nLink to Image\nThe study, however, doesn’t conclude that the Fed necessarily should refrain from raising rates if needed to contain \ninflation. Rather, it suggests that increased government funding for innovation could offset the rate increases.\nWhat happens to long-run economic growth when interest rates increase?\nEconomists traditionally have believed that the economy’s long-term potential isn’t affected by lifting interest rates to \ncorral inflation or lowering them to stimulate weak growth, the paper says. But that view has been challenged by a \ngrowing body of research.\nBy making borrowing more expensive, higher interest rates can reduce consumer and business demand for \nproducts and services. That can make it less profitable for companies to develop new offerings and come up with \ninnovations that increase efficiency and spark faster growth, the paper says.\nSharply rising rates also can lead to less favorable financial conditions. That means it becomes more expensive to \ntake out a loan to launch a new product or business, the stock market is down and investors are more likely to put \ntheir money in safe bonds that now pay a higher interest rate than take a chance on a new venture.\nFed rate hikes don't just fight inflation. They hurt economy over long-term, study says\nA percentage point interest rate rise can cut research and development spending by 1% to 3% in one to three \nyears, the study says. In the same time frame, venture capital investment falls by 25%. And patents for new \ninventions decline by up to 9% in two to four years, the study says.\nAn aggregate innovation index based on the economic value of patents also slides by 9% in that period, leading to \na 1% drop in output five years later.\nHow high did the Fed raise interest rates?\nThe effects could be more pronounced in the current rate-hiking cycle since the Fed has jacked up its benchmark \nrate by more than 5 percentage points from near zero in an effort to tame a historic inflation spike. Since the hikes \nbegan in March 2022, venture capital investment has fallen from its 2021 peak by about 30% annually, the study \nsays. The retreat has affected all major sectors, not just those “sometimes perceived as speculative bubbles,” such \nas cryptocurrencies.\nInvestment in generative AI (artificial intelligence) has rebounded this year, but that mostly has been fueled by \nMicrosoft’s $10 billion investment in OpenAI, the paper says.\nMeanwhile, the dropoff in patents impacts both public and private companies as well as large and small ones, the \nstudy says. But since large public firms have more financial resources, their pullback in innovation is likely driven \nmore by softer customer demand than unfavorable financial conditions. \nWhat happened to interest rates in the late 1970s and early 1980s\nFed rate hikes don’t always discourage innovation, the study says. When computers took off in the 1970s and \n1980s, inflation and interest rates were high but technological developments were so dramatic that the rate \nincreases had just a marginal effect, the study says.\nAnd the authors don't urge the Fed necessarily to hold off on further rate increases or move quickly to cut rates.\n“We do not think our findings necessarily imply that monetary policy should be more dovish,” meaning geared more \nto lowering than raising rates, the study says.\nInstead, the authors say, government programs could provide companies grants or subsidies to bolster innovation if \nthe economy is struggling or interest rates are rising.\nThis article originally appeared on USA TODAY: Fed rate hikes don't just fight inflation. They hurt economy over \nlong-term, study says\nLoad-Date: August 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Meet the A.I. Jane Austen: Meta Weaves A.I. Throughout Its Apps",
        "media": "The New York Times",
        "time": "September 28, 2023",
        "section": "TECHNOLOGY",
        "length": "1373 words",
        "byline": "Mike Isaac and Cade Metz",
        "story_text": "Meet the A.I. Jane Austen: Meta Weaves A.I. Throughout Its Apps\nThe New York Times \nSeptember 27, 2023 Wednesday 13:18 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1373 words\nByline: Mike Isaac and Cade Metz\nHighlight: Meta introduced artificially intelligent characters based on Jane Austen, Snoop Dogg and others into \nInstagram, Facebook and WhatsApp, as the race to lead the technology heats up.\nBody\nMeta introduced artificially intelligent characters based on Jane Austen, Snoop Dogg and others into Instagram, \nFacebook and WhatsApp, as the race to lead the technology heats up.\nIn a WhatsApp text conversation this week, we asked Jane Austen — yes, the 19th-century British author — how \nshe felt about Mr. Darcy, a character from one of her most famous works, “Pride and Prejudice.”\nAfter a few seconds, Ms. Austen responded.\n“Ah, Mr. Darcy. Everyone remembers him as one of my characters,” she said, her face appearing in a small window \nabove our conversation. “But fewer people have read one of my books,” she added, with an arched eyebrow and \nwhat seemed like a hint of resentment.\nMs. Austen was not actually talking to us. But a modern interpretation of her likeness was used by Meta, which \nowns WhatsApp, Facebook and Instagram, as part of an artificially intelligent character that could chat across the \ncompany’s messaging apps. Characters based on other people’s likenesses — including the former quarterback \nTom Brady, the social media influencers Mr. Beast and Charlie D’Amelio, and the hip-hop artist Snoop Dogg — \nwere also available to converse.\nThese characters were part of a suite of products that Meta introduced on Wednesday — all powered by artificial \nintelligence — and that will soon be found throughout its products, including Instagram, Messenger, and virtual- and \naugmented-reality devices like the Quest 3 headset and Ray-Ban Stories smart glasses. The rollout also includes a \nchatbot that will be powered partly by Microsoft’s Bing search engine, as well as A.I.-assisted image-editing tools to \nuse on Instagram.\n“Most people haven’t had the chance to experience” the newest and most powerful A.I technologies, Mark \nZuckerberg, Meta’s chief executive, said on Wednesday. “That’s a thing that I think we can change.”\nHe added, “People aren’t going to want to interact with one single super intelligent A.I. — people will want to \ninteract with a bunch of different ones.”\nMeta is aiming to keep pace with OpenAI, Google, Microsoft and other companies in the frenzied race over A.I. that \ncan instantly generate text, images and other media on its own. Since November, when OpenAI unexpectedly \nlaunched the chatbot ChatGPT, Silicon Valley executives have embraced the technology as the next big shift in \ncomputing — and struggled not to be left behind.\nMeet the A.I. Jane Austen: Meta Weaves A.I. Throughout Its Apps\nFor Meta, widespread acceptance of its new A.I. products could significantly increase engagement across its many \napps, most of which rely on advertising to make money. More time spent in Meta’s apps means more ads shown to \nits users.\nWhile Meta has worked on A.I. behind the scenes for years, it was initially slow to introduce products with \ngenerative A.I., especially as it focused on transforming into a metaverse company. To catch up, Mr. Zuckerberg \noverhauled the company to focus on building A.I.-focused products like the ones introduced on Wednesday, holding \nweekly meetings with his executive team to discuss the progress.\nNow Meta is using its tried-and-true playbook of leveraging its enormous size — globally, more than three billion \npeople use its products — to popularize its offerings. And whereas interactions with ChatGPT and Google’s Bard \nchatbot have largely been between an individual and the bot or within productivity programs like Gmail, Mr. \nZuckerberg envisions users of Instagram, Facebook and WhatsApp interacting with chatbots more socially in their \neveryday conversations and group chats with friends.\nFor example: If two friends chatting on WhatsApp want to find a good breakfast spot in San Francisco on Sunday \nmorning, they might naturally turn to Meta’s new chatbot, Meta AI, to ask, “Where is the best place for eggs \nBenedict in San Francisco?”\nWithin a few seconds, Meta’s digital assistant would mine Microsoft’s Bing search engine for real-time web results, \nand use its underlying A.I. to spit out a short, conversational response. (People who want more specific information \ncan click on linked footnotes in the response, which would redirect them to Bing search results in another window.)\nOther social networking apps have also started weaving in A.I. abilities. Snap added a chatbot this year to its social \nmedia service, Snapchat, which is popular among teenagers. Its chatbot is embodied by a digital avatar that users \ncan rename and customize. And Character.AI, a Silicon Valley start-up, offers a service in which people can chat \nwith a reasonable facsimile of almost anyone, living or dead.\nMeta’s new character-like bots work similarly to Snapchat’s offering — and a little like the digital personalities \noffered by Character.AI.\nOne Meta A.I. character — Amber, modeled after Paris Hilton — plays a detective partner for “solving whodunits” in \nchats. Kendall Jenner’s character, called Billie, is described as a “No BS, ride-or-die companion.” The tennis star \nNaomi Osaka’s character, Tamika, is an “anime-obsessed Sailor Senshi in training,” while Snoop Dogg plays a \nDungeon Master in a sendup of Dungeons and Dragons with a “choose your own adventure” type of experience.\nThe celebrities and athletes are being paid for their A.I. characters; Meta did not provide details on compensation.\nThe characters are a way for people to have fun, learn things, talk recipes or just pass the time — all within the \ncontext of connecting with friends and family, company executives said.\n“We see people going to different A.I.s for different things, which is how we see ourselves building out an \necosystem of many more A.I.s over time,” said Ahmad Al-Dahle, Meta’s vice president of generative A.I.\nBut like other chatbots, Meta’s chatbots can generate false and misleading information — a phenomenon that \nresearchers call hallucination. This can happen even when the bot bases its answer on what it grabs from a search \nengine.\nWhen we asked the Meta AI assistant, “Who won the 1904 World Series?,” it incorrectly said “the New York Giants” \nand asked if it could help with anything else. When we then asked if the World Series was even played in 1904, the \nbot adjusted and correctly said there was no 1904 World Series because the Giants refused to play.\nLike Microsoft, OpenAI and others, Meta is also offering a tool for instantly generating photorealistic images. Users \nwill be able to instantly create A.I.-produced photos or sticker emoji reactions inside the company’s messaging apps \nbased on whatever they type into the chat prompt, with some limitations.\nMeet the A.I. Jane Austen: Meta Weaves A.I. Throughout Its Apps\nThis kind of image-generating technology can be used to spread disinformation online. To guard against this \npossibility, Meta said, images created with the tool will be marked with an icon indicating they were created by A.I.\nMr. Al-Dahle said Meta had spent thousands of hours doing “red team” scenarios to test the potential misuse of the \ntechnologies. The company has also published a set of responsible-use guidelines for those who want to use \nMeta’s underlying technology to eventually power their own chatbots.\nMany of the products will also be rolled out in a limited capacity to U.S. users only, as the company works out any \nearly kinks and watches how users respond.\nA future with legions of chatbots could be closer than we might think. Meta’s public release in July of LLaMA 2 — \nthe code behind its latest and most advanced A.I. technology — was enthusiastically greeted by developers and \nhas been downloaded more than 30 million times. Meta is working with Microsoft, Google and Amazon’s cloud \nservices divisions to host the technology for developers who want to create the next generation of bots that can do \nwhatever the coders want them to do — for better or worse.\nFor now, the A.I.-powered Ms. Austen would say only so much. When we asked at what age a woman should \nmarry, she refused to answer.\n“My goodness, you want me to dictate your love life?” she said. “Marry whenever you find someone who can \ntolerate your eccentricities. And you theirs.”\nPHOTOS: Mark Zuckerberg, Meta’s chief executive, said on Wednesday that people will want to interact with a \nvariety of A.I.s. (PHOTOGRAPH BY LOREN ELLIOTT FOR THE NEW YORK TIMES); Meta’s digital assistant, \nMeta AI, mines Bing, Microsoft’s search engine. (PHOTOGRAPH BY META) (B6) This article appeared in print on \npage B1, B6.\nLoad-Date: September 28, 2023"
    },
    {
        "file_name": "of_2024_elections;_A_phone-banking_tool_powered_entirely_by_artificial_Dec2023",
        "header": "Congressional candidate's voter outreach tool is latest AI experiment ahead",
        "media": "of 2024 elections; A phone-banking tool powered entirely by artificial",
        "time": "December 13, 2023",
        "section": "NATION WORLD",
        "length": "1004 words",
        "byline": "ALI SWENSON",
        "story_text": "Congressional candidate's voter outreach tool is latest AI experiment ahead \nof 2024 elections; A phone-banking tool powered entirely by artificial \nintelligence is getting its first real-world test in a Pennsylvania Democrat's \ncongressional campaign\nDayton Daily News (Ohio)\nDecember 13, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1004 words\nByline: ALI SWENSON\nBody\nA phone-banking tool powered entirely by artificial intelligence is getting its first real-world test in a Pennsylvania \nDemocrat's congressional campaign.\nThe chatbot, named Ashley, calls voters and engages in two-way, interactive conversations about candidate \nShamaine Daniels, one of seven Democrats running so far in next year's primary. The voice tool from the startup \nCivox represents one of many ways AI technology is breaking into politics ahead of the 2024 campaigns, but \nexperts say its direct contact with voters could threaten data security and has the potential to undermine voter trust. \nDaniels announced the partnership with Civox on Tuesday, saying the the first-of-its-kind political campaign tool \nhad already completed more than 1,000 calls with likely Democratic primary voters in Pennsylvania's 10th House \ndistrict, which includes the state capital, Harrisburg. \nUnlike other robocallers, Ashley doesn't use canned responses or give call recipients a menu of options. Instead, it \nuses generative AI technology to devise immediate humanlike responses to voter questions. \nThe tool was created by Civox in partnership with another new company, Conversation Labs. Civox CEO Ilya \nMouzykantskii and co-founder Adam Reis, who also founded Conversation Labs, said they tested it rigorously to \nensure it could accurately answer questions about Daniels' policies and what differentiates her from other \ncandidates in the race. \nThe founders said they decided to give the tool a machine-like voice because in internal testing, call recipients \npreferred that to other, more realistic voices. \n\"It's often not the voice itself that influences how natural or human-feeling the conversation is,\" Reis said. \"It's often \nthe nuances of interactions and how quickly it responds and the language it uses.\" \nIn a demonstration with Ashley on Tuesday, the tool disclosed that it was powered by AI and that the call was being \nrecorded. When prompted, it clearly and accurately shared Daniels' positions on affordable health care and \neducation reform. \nIt tactfully answered pointed questions about election integrity and the Republican who holds the seat, six-term \nincumbent Rep. Scott Perry, pausing only a few seconds before each response. \nCongressional candidate's voter outreach tool is latest AI experiment ahead of 2024 elections A phone-banking \ntool powered entirely by artificial intelligence i....\nBut when asked off-topic questions, the tool sometimes got tripped up and shared false information. In a \nconversation about snacks, it said Cheetos were \"known for being both delicious and health-conscious.\" \nThat's an example of an AI \" hallucination \"  a problem with still-evolving generative AI technology in which large \nlanguage models tend to make statements that sound convincing but are false or made up. \nMouzykantskii said the mistake was fascinating but \"not representative\" of voters' experiences with the tool so far. \n\"We have tested Ashley much more extensively on political topics than on the topic of food and nutrition,\" he said. \nVoters' responses so far to Ashley have been mixed, said Joe Bachman of Indigo Strategies, a spokesperson for \nDaniels. He noted that while some call recipients engaged in thorough conversations, many stuck to one-word \nanswers as one might in a phone conversation with a banking chatbot. \n\"There's not a replacement for live one-on-one conversations, either on the phone or at doors,\" he said. \"It's a new \ntechnology. It's going to take voters some time to get used to it, just as when campaigns started using SMS text \nmessaging to communicate with voters.\" \nHe said the campaign felt the chatbot, which can speak over 20 languages, was a good opportunity to reach voters \nin the southern Pennsylvania district, which has a significant refugee population. \nMouzykantskii and Reis said they created Ashley using a combination of over 20 AI models, including both open-\nsource and proprietary models. They declined to share what data its AI models are trained on and would not say \nwhether they incorporated systems from OpenAI or other high-profile AI companies that have rules against usage in \npolitical campaigning. \nOther entrepreneurs at the intersection of AI and politics said they were skeptical about Ashley's direct interaction \nwith voters and more often advise campaigns to use the rapidly advancing technology on the back end of \ncampaigns, such as in drafting advertising copy. \n\"The guidance I've offered and seen from most people is that they are steering away from AI personalities when it \ncomes to politics and campaigns this cycle,\" said Betsy Hoover, a founding partner at the progressive tech \naccelerator and venture capital firm Higher Ground Labs. \"You don't need people to be less trustful of politics right \nnow. In fact, we need the opposite, and so this is not the cycle to try that.\" \nMike Nellis, CEO of the progressive digital agency Authentic, said he was concerned about the possibility of the \nchatbot making mistakes in conversations and didn't believe there was enough data to say whether its calls would \nbe effective in motivating voters. The data the tool gathers through its phone calls is another concern, he said. \n\"Right now, that large language model knows sensitive voter information and knows the voters' responses to it,\" \nNellis said. \"I don't know how safe and secure that is.\" \nMouzykantskii said Civox protects voter information in line with \"political campaign, technology, industry standards\" \nand added that he encourages regulators to pay attention to these emerging tools and set stronger guidelines for \nthem. \nDaniels, 45, is an immigration lawyer and member of the Harrisburg City Council making her second run for the \ncongressional seat, which is in a Republican-leaning district. The state's primary election is April 23. \nPerry beat Daniels in 2022 by 8 percentage points, easily outspending her. \nAssociated Press writer Marc Levy in Harrisburg, Pennsylvania, contributed to this report. \nThe Associated Press receives support from several private foundations to enhance its explanatory coverage of \nelections and democracy. See more about AP's democracy initiative here. The AP is solely responsible for all \ncontent.\nCongressional candidate's voter outreach tool is latest AI experiment ahead of 2024 elections A phone-banking \ntool powered entirely by artificial intelligence i....\nLoad-Date: December 13, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos",
        "media": "The New York Times",
        "time": "February 16, 2024",
        "section": "TECHNOLOGY",
        "length": "795 words",
        "byline": "Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other",
        "story_text": "OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\nThe New York Times \nFebruary 15, 2024 Thursday 18:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 795 words\nByline: Cade Metz Cade Metz writes about artificial intelligence, driverless cars, robotics, virtual reality and other \nemerging areas of technology.\nHighlight: The start-up is sharing the new technology, called Sora, with a small group of early testers as it tries to \nunderstand the potential dangers.\nBody\nThe start-up is sharing the new technology, called Sora, with a small group of early testers as it tries to understand \nthe potential dangers.\nIn April, a New York start-up called Runway AI unveiled technology that let people generate videos, like a cow at a \nbirthday party or a dog chatting on a smartphone, simply by typing a sentence into a box on a computer screen.\nThe four-second videos were blurry, choppy, distorted and disturbing. But they were a clear sign that artificial \nintelligence technologies would generate increasingly convincing videos in the months and years to come.\nJust 10 months later, the San Francisco start-up OpenAI has unveiled a similar system that creates videos that look \nas if they were lifted from a Hollywood movie. A demonstration included short videos — created in minutes — of \nwoolly mammoths trotting through a snowy meadow, a monster gazing at a melting candle and a Tokyo street \nscene seemingly shot by a camera swooping across the city.\nOpenAI, the company behind the ChatGPT chatbot and the still-image generator DALL-E, is among the many \ncompanies racing to improve this kind of instant video generator, including start-ups like Runway and tech giants \nlike Google and Meta, the owner of Facebook and Instagram. The technology could speed the work of seasoned \nmoviemakers, while replacing less experienced digital artists entirely.\nIt could also become a quick and inexpensive way of creating online disinformation, making it even harder to tell \nwhat’s real on the internet.\n“I am absolutely terrified that this kind of thing will sway a narrowly contested election,” said Oren Etzioni, a \nprofessor at the University of Washington who specializes in artificial intelligence. He is also the founder of True \nMedia, a nonprofit working to identify disinformation online in political campaigns.\nOpenAI calls its new system Sora, after the Japanese word for sky. The team behind the technology, including the \nresearchers Tim Brooks and Bill Peebles, chose the name because it “evokes the idea of limitless creative \npotential.”\nIn an interview, they also said the company was not yet releasing Sora to the public because it was still working to \nunderstand the system’s dangers. Instead, OpenAI is sharing the technology with a small group of academics and \nother outside researchers who will “red team” it, a term for looking for ways it can be misused.\nOpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\n“The intention here is to give a preview of what is on the horizon, so that people can see the capabilities of this \ntechnology — and we can get feedback,” Dr. Brooks said.\nOpenAI is already tagging videos produced by the system with watermarks that identify them as being generated by \nA.I. But the company acknowledges that these can be removed. They can also be difficult to spot. (The New York \nTimes added “Generated by A.I.” watermarks to the videos with this story.)\nThe system is an example of generative A.I., which can instantly create text, images and sounds. Like other \ngenerative A.I. technologies, OpenAI’s system learns by analyzing digital data — in this case, videos and captions \ndescribing what those videos contain.\nOpenAI declined to say how many videos the system learned from or where they came from, except to say the \ntraining included both publicly available videos and videos that were licensed from copyright holders. The company \nsays little about the data used to train its technologies, most likely because it wants to maintain an advantage over \ncompetitors — and has been sued multiple times for using copyrighted material.\n(The New York Times sued OpenAI and its partner, Microsoft, in December, claiming copyright infringement of \nnews content related to A.I. systems.)\nSora generates videos in response to short descriptions, like “a gorgeously rendered papercraft world of a coral \nreef, rife with colorful fish and sea creatures.” Though the videos can be impressive, they are not always perfect \nand may include strange and illogical images. The system, for example, recently generated a video of someone \neating a cookie — but the cookie never got any smaller.\nDALL-E, Midjourney and other still-image generators have improved so quickly over the past few years that they \nare now producing images nearly indistinguishable from photographs. This has made it harder to identify \ndisinformation online, and many digital artists are complaining that it has made it harder for them to find work.\n“We all laughed in 2022 when Midjourney first came out and said, ‘Oh, that’s cute,’” said Reid Southen, a movie \nconcept artist in Michigan. “Now people are losing their jobs to Midjourney.”\nPHOTOS: OpenAI introduced a system that creates videos in minutes that look as if they were lifted from a \nHollywood movie. (PHOTOGRAPHS VIA OPENAI) This article appeared in print on page B4.\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "took_issue_with_reports_Apr2024",
        "header": "Reports: Workers in India behind Just Walk Out tech; Amazon spokesperson",
        "media": "took issue with reports",
        "time": "April 8, 2024",
        "section": "BUSINESS; Pg. B3",
        "length": "641 words",
        "byline": "By, Betty Lin-Fisher, USA TODAY",
        "story_text": "Reports: Workers in India behind Just Walk Out tech; Amazon spokesperson \ntook issue with reports\nUSA Today\nApril 8, 2024 Monday\n1 Edition\nCopyright 2024 USA Today All Rights Reserved\nSection: BUSINESS; Pg. B3\nLength: 641 words\nByline: By, Betty Lin-Fisher, USA TODAY\nBody\nDoes Amazon's touchless technology, which allows customers to grab what they need on shelves and \"Just Walk \nOut\" without going to a cash register, really rely on human workers in India to review the purchases?\nThe Seattle-based retailer, which  said last week that it was swapping the Just Walk Out technology at more than \nhalf of its 40 Amazon Fresh grocery stores for smart carts, won't really say.\nWhile the Just Walk Out technology sends shoppers their receipts after they've left the store, Amazon Dash carts \nshow customers what they will be charged for each item in real time on a screen, while also allowing shoppers to \nbypass a register. Amazon said the change occurring at its Amazon Fresh grocery stores is in response to \ncustomer feedback but it will continue to use the Just Walk Out technology at more than 130 third-party partners, \nwhich include airports, college stores and cafes.\nAt those locations, the company claims sensors, cameras and other tools help track what a shopper has purchased. \nBut several media outlets have reported that there may be more to it, with hundreds of workers in India playing a \nkey role.\nOn its website, AWS, a separate division of Amazon, said customers using Just Walk Out technology can walk into \na store using Amazon One (where customers can register their palm to connect with their payment method), a \ncredit/debit card, or an app, shop for items and leave. Customers are automatically charged for their purchases.\n\"Sensors, cameras and deep learning tools sense what a consumer takes off the shelf,\" the website said.\nAn Amazon spokesperson explained further: \"Just Walk Out technology is made possible by artificial intelligence \nlike computer vision and deep learning techniques, including generative AI, to accurately determine who took what \nin any retail environment. Amazon built synthetic datasets to mimic millions of realistic shopping scenarios - \nincluding variations in store format, lighting conditions, and even crowds of shoppers - to ensure accuracy in any \nenvironment.\"\nHowever, several media outlets have said that workers in India may also be significantly involved.\nLike many artificial intelligence systems, Amazon's system relies on human moderators and data labelers, who \nreview Just Walk Out transactions and label footage to help train the AI models that make it work, CNBC said. The \nInformation reported last year that the team was made up of more than 1,000 employees, primarily based in India, \naccording to CNBC. An Amazon spokesperson confirmed at the time that it uses human moderators but declined to \nsay how many people it employs in these roles, according to The Information report. Business Insider cited more \nReports: Workers in India behind Just Walk Out tech Amazon spokesperson took issue with reports\nreporting by The Information on Tuesday, that said Just Walk Out is still very reliant on humans, according to an \nunnamed person The Information said had worked on the technology.\nAbout 700 of every 1,000 Just Walk Out sales had to be reviewed by Amazon's team in India in 2022, according to \nThe Information, as reported by Business Insider. Internally, Amazon wanted just 50 out of every 1,000 sales to get \na manual check, according to the report.\nIn a statement, an Amazon spokesperson took issue with the media reports. \"The misconception that Just Walk Out \ntechnology relies on human reviewers watching shoppers live from India is misleading and inaccurate,\" an Amazon \nspokesperson said Thursday in an e-mail statement to USA TODAY. \"As with many AI systems, the underlying \nmachine learning model is continuously improved by generating synthetic data and annotating actual video data.\n\"Our associates validate a small portion of shopping visits by reviewing recorded video clips to ensure that our \nsystems are performing at our high bar for accuracy, which is made possible because we continuously improve \nboth our algorithms and use human input to correct them.\"\nGraphic\n \nCameras placed in the ceiling monitor customers as they pick up the items of choice and bill them as they leave\nthe grab-and-go Market Express located in the Hollywood Casino in Detroit. The cashless store uses\nAmazon's Just Walk Out Technology.\nKirthmon F. Dozier/USA TODAY NETWORK\nLoad-Date: April 8, 2024"
    },
    {
        "file_name": "LEADERS_STEPPING_ONTO_WORLD_STAGE_Sep2023",
        "header": "CAPITALIZING ON AI: NO LONGER A 'FLYOVER CITY'; PITTSBURGH TECH",
        "media": "LEADERS STEPPING ONTO WORLD STAGE",
        "time": "September 24, 2023",
        "section": "LOCAL; Pg. C-1",
        "length": "566 words",
        "byline": "Evan Robinson-Johnson Pittsburgh Post-Gazette",
        "story_text": "CAPITALIZING ON AI: NO LONGER A 'FLYOVER CITY'; PITTSBURGH TECH \nLEADERS STEPPING ONTO WORLD STAGE\nPittsburgh Post-Gazette\nSeptember 24, 2023 Sunday\nTWO STAR EDITION\nCopyright 2023 P.G. Publishing Co.\nSection: LOCAL; Pg. C-1\nLength: 566 words\nByline: Evan Robinson-Johnson Pittsburgh Post-Gazette\nBody\nIt's been more than 100 years since steel tycoon Andrew Carnegie walked the streets of Pittsburgh, but you can \ntalk to him yourself through a new generative AI system developed by Johnstown-based Problem Solutions.\nOr, if dead philanthropists aren't your jam, there's Charlie, a 4-foot-tall holographic alien. Problem Solutions \ndeveloped him for the Air Force.\nOn Friday, they brought both virtual mascots to Homestead, where more than 100 regional companies converged \nfor the Pittsburgh Technology Council's annual TechFest. Developers shared ways to capitalize on the power of \ngenerative AI and expressed optimism for the region's growing influence on the global tech stage.\n\"It's been a heck of a journey,\" said Richard James, a software engineer at UPMC Enterprises. \"We used to be a \nflyover city. Now we're building high-rises and headquarters.\"\nAbsent the region's larger players such as Google, Meta and Duolingo, the conference revealed a hunger from \nsmaller companies to seize on the transformational potential of new AI tools. One major opportunity is coaching.\nWhen he's not designing interactive aliens, Problem Solutions chief experience officer Brooks Canavesi is helping \nother companies think about how best to implement ChatGPT and other tools. He said the average person is using \nonly 10% of the new systems' capabilities, and they don't have time to learn more.\nMeanwhile, the systems are becoming exponentially more powerful as OpenAI, Google and a host of smaller \ndevelopers race to train their large language models on more data.\nCompanies that choose to implement generative AI must also be cognizant of the risks the software introduces, \nsaid Pam Kamath, founder of the Pittsburgh consulting firm Adaptive AI.\n\"These systems are notorious for creating fabricated data,\" Ms. Kamath said. \"They lack privacy and they're very \npoorly designed on security.\"\nAs a result, she said, keeping a \"human in the loop is important to everything you do.\"\nThe emphasis on human potential was epitomized by a keynote speech from Claye Greene, an IT consultant and \nCEO of TechBlue Inc. who advises the federal government. Instead of technical advice, Mr. Greene spoke about \nhuman traits like curiosity and influence.\nCAPITALIZING ON AI: NO LONGER A 'FLYOVER CITY' PITTSBURGH TECH LEADERS STEPPING ONTO \nWORLD STAGE\n\"There's a lot of people here today that are striving for excellence,\" he said. \"Learn from them ... find mentors, find \nadvocates, find sponsors, find people that are willing to help.\"\nMany of the businesses that attended said the robustness of Pittsburgh's tech sector has made it easier to attract \nand retain talent.\nGraduates from Carnegie Mellon University are increasingly landing in local companies that allow them to create \ndeliverable products in a short timeframe, said Hasan Yasar, a technical director in the university's Software \nEngineering Institute.\nInstead of trying to lure talent from Silicon Valley, \"you can find it here,\" said Denise Cortinovis-Jablonski, an \naccount manager involved in talent acquisition at IQ Inc.\nIt's been a \"remarkable\" transformation to witness, said Ms. Cortinovis-Jablonski, who moved to the city in 1999 to \nattend the University of Pittsburgh.\n\"Technology just sort of came in and took over,\" she said.\nFor Chris Smith, also of IQ Inc., that growth came as no surprise.\n\"The tech community here has always been this super vibrant, diverse conglomeration of people from all over the \nworld,\" he said.\nEvan Robinson-Johnson: ejohnson@post-gazette.com\nGraphic\n \nPHOTO: Sebastian Foltz/Post-Gazette: Claye Greene, CEO and President of TechBlue Inc, delivers a keynote \nspeech on leadership strategies at Pittsburgh TechFest, Friday, Sept. 22, 2023, in Homestead.\nPHOTO: Sebastian Foltz/Post-Gazette: Sean McPherson of Khan Academy leads a workshop on front-end \narchitecture coding Friday at Pittsburgh TechFest in Homestead.\nPHOTO: Sebastian Foltz/Post-Gazette: Dayna Martin, with VSP Vision and RedChairPGH, which focuses on \ndiversity in tech careers, speaks to an attendee Friday at Pittsburgh TechFest in Homestead. During the event, \ndevelopers shared ways to capitalize on the power of generative AI and expressed optimism for the region's \ngrowing influence on the global tech stage.\nPHOTO: Sebastian Foltz/Post-Gazette: Claye Greene, CEO and President of TechBlue Inc, delivers a keynote \nspeech on leadership strategies at Pittsburgh TechFest, Friday, Sept. 22, 2023, in Homestead.\nPHOTO: Sebastian Foltz/Post-Gazette: Claye Greene, CEO and President of TechBlue Inc, delivers a keynote \nspeech on leadership strategies at Pittsburgh TechFest, Friday, Sept. 22, 2023, in Homestead.\nLoad-Date: September 24, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "OpenAI Seeks to Dismiss Parts of The New York Times's Lawsuit",
        "media": "The New York Times",
        "time": "February 28, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 3",
        "length": "592 words",
        "byline": "By Cade Metz and Katie Robertson",
        "story_text": "OpenAI Seeks to Dismiss Parts of The New York Times's Lawsuit\nThe New York Times\nFebruary 28, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 3\nLength: 592 words\nByline: By Cade Metz and Katie Robertson\nBody\nThe artificial intelligence start-up argued that its online chatbot, ChatGPT, is not a substitute for a New York Times \nsubscription.\nOpenAI filed a motion in federal court on Monday that seeks to dismiss some key elements of a lawsuit brought by \nThe New York Times Company. \n  The Times sued OpenAI and its partner Microsoft on Dec. 27, accusing them of infringing on its copyrights by \nusing millions of its articles to train A.I. technologies like the online chatbot ChatGPT. Chatbots now compete with \nthe news outlet as a source of reliable information, the lawsuit said.\n  In the motion, filed in U.S. District Court for the Southern District of New York, the defendants argue that ChatGPT \n''is not in any way a substitute for a subscription to The New York Times.''\n  ''In the real world, people do not use ChatGPT or any other OpenAI product for that purpose,'' the filing said. ''Nor \ncould they. In the ordinary course, one cannot use ChatGPT to serve up Times articles at will.''\n  OpenAI did not dispute in its filing that it ''copied millions of The Times's works to build and power its commercial \nproducts without our permission,'' Ian B. Crosby, a partner at Susman Godfrey and the lead counsel for The Times, \nsaid in a statement.\n  ''What OpenAI bizarrely mischaracterizes as 'hacking' is simply using OpenAI's products to look for evidence that \nthey stole and reproduced the Times's copyrighted works,' he said. ''And that is exactly what we found.''\n  OpenAI declined to comment.\n  The motion asked the court to dismiss four claims from The Times's complaint to narrow the focus of the lawsuit. \nOpenAI's lawyers argued that The Times should not be allowed to sue for acts of reproduction that occurred more \nthan three years ago and that the paper's claim that OpenAI violated the Digital Millennium Copyright Act, an \namendment to U.S. copyright law passed in 1998 after the rise of the internet, was not legally sound.\n  The Times was the first major American media company to sue OpenAI over copyright issues related to its written \nworks. Novelists, computer programmers and other groups have also filed copyright suits against the start-up and \nother companies that build generative A.I., technologies that generate text, images and other media from short \nprompts.\nOpenAI Seeks to Dismiss Parts of The New York Times 's Lawsuit\n  Like other A.I. companies, OpenAI built its technology by feeding it enormous amounts of digital data, some of \nwhich is likely copyrighted. A.I. companies have claimed that they can legally use such material to train their \nsystems without paying for it because it is public and they are not reproducing the material in its entirety.\n  In its suit, The Times included examples of OpenAI technology's reproducing excerpts from its articles almost \nverbatim. In the motion to dismiss, lawyers for OpenAI accused The Times of paying someone to hack their \nchatbot. ''It took them tens of thousands of attempts to generate the highly anomalous results,'' the motion said.\n  ''They were able to do so only by targeting and exploiting a bug (which OpenAI has committed to addressing) by \nusing deceptive prompts that blatantly violate OpenAI's terms of use,'' the filing said.\n  The filing also argued that it was legal to use copyrighted material in its systems, citing legal precedents that allow \nfor the use of copyrighted content ''in the creation of new, different and innovative products.''\n  ''OpenAI and the other defendants in these lawsuits will ultimately prevail because no one -- not even The New \nYork Times -- gets to monopolize facts or the rules of language,'' the complaint said.\nhttps://www.nytimes.com/2024/02/27/technology/openai-new-york-times-lawsuit.html\nGraphic\n \nPHOTO: The New York Times was the first major American media company to sue OpenAI over copyright issues. \n(PHOTOGRAPH BY ZACK DEZON FOR THE NEW YORK TIMES) This article appeared in print on page B3.               \nLoad-Date: February 28, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_May2023",
        "header": "Google Brings Bard Chatbot to India Users",
        "media": "Economic Times (E-Paper Edition)",
        "time": "May 15, 2023",
        "section": "STARTUPS & TECH",
        "length": "134 words",
        "byline": "Dia.Rekhi@timesgroup.com",
        "story_text": "Google Brings Bard Chatbot to India Users\nEconomic Times (E-Paper Edition)\nMay 12, 2023 Friday\nMumbai Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STARTUPS & TECH\nLength: 134 words\nByline: Dia.Rekhi@timesgroup.com\nBody\nMountain View: Alphabet Inc's Google said its conversational generative AI chatbot 'Bard' is being rolled out in \nmore than 180 countries, including India. “As models get better and more capable, one of the most exciting \nopportunities is making them available for people to engage with directly,” Google's CEO, Sundar Pichai, said in his \nkeynote speech at the Google I/O, the company's annual developer conference held at its headquarters in \nMountain View, California, on Wednesday. “That's the opportunity we have with Bard — our experiment for \nconversational AI.” Initially, the Google Bard chatbot was only available in the UK and the US. In India, those \ninterested can join the waitlist for the AI chatbot via the Google Bard official website. (The reporter is at Mountain \nView at the invitation of Google)\nLoad-Date: May 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_May2023",
        "header": "In Battle Over A.I., Meta Decides to Give Away Its Crown Jewels",
        "media": "The New York Times - International Edition",
        "time": "May 19, 2023",
        "section": "TECHNOLOGY",
        "length": "1526 words",
        "byline": "Cade Metz and Mike Isaac",
        "story_text": "In Battle Over A.I., Meta Decides to Give Away Its Crown Jewels\nThe New York Times - International Edition\nMay 20, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1526 words\nByline: Cade Metz and Mike Isaac\nBody\nThe tech giant has publicly released its latest A.I. technology so people can build their own chatbots. Rivals like \nGoogle say that approach can be dangerous.       \nIn February, Meta made an unusual move in the rapidly evolving world of artificial intelligence: It decided to give \naway its A.I. crown jewels.       \nThe Silicon Valley giant, which owns Facebook, Instagram and WhatsApp, had created an A.I. technology, called \nLLaMA, that can power online chatbots. But instead of keeping the technology to itself, Meta released the system's \nunderlying computer code into the wild. Academics, government researchers and others who gave their email \naddress to Meta could download the code once the company had vetted the individual.       \nEssentially, Meta was giving its A.I. technology away as open-source software - computer code that can be freely \ncopied, modified and reused - providing outsiders with everything they needed to quickly build chatbots of their own.       \n\"The platform that will win will be the open one,\" Yann LeCun, Meta's chief A.I. scientist, said in an interview.       \nAs a race to lead A.I. heats up across Silicon Valley, Meta is standing out from its rivals by taking a different \napproach to the technology. Driven by its founder and chief executive, Mark Zuckerberg, Meta believes that the \nsmartest thing to do is share its underlying A.I. engines as a way to spread its influence and ultimately move faster \ntoward the future.       \nIts actions contrast with those of Google and OpenAI, the two companies leading the new A.I. arms race. Worried \nthat A.I. tools like chatbots will be used to spread disinformation, hate speech and other toxic content, those \ncompanies are becoming increasingly secretive about the methods and software that underpin their A.I. products.       \nGoogle, OpenAI and others have been critical of Meta, saying an unfettered open-source approach is dangerous. \nA.I.'s rapid rise in recent months has raised alarm bells about the technology's risks, including how it could upend \nthe job market if it is not properly deployed. And within days of LLaMA's release, the system leaked onto 4chan, the \nonline message board known for spreading false and misleading information.       \n\"We want to think more carefully about giving away details or open sourcing code\" of A.I. technology, said Zoubin \nGhahramani, a Google vice president of research who helps oversee A.I. work. \"Where can that lead to misuse?\"       \nSome within Google have also wondered if open-sourcing A.I. technology may pose a competitive threat. In a \nmemo this month, which was leaked on the online publication Semianalysis.com, a Google engineer warned \ncolleagues that the rise of open-source software like LLaMA could cause Google and OpenAI to lose their lead in \nA.I.       \nIn Battle Over A.I., Meta Decides to Give Away Its Crown Jewels\nBut Meta said it saw no reason to keep its code to itself. The growing secrecy at Google and OpenAI is a \"huge \nmistake,\" Dr. LeCun said, and a \"really bad take on what is happening.\" He argues that consumers and \ngovernments will refuse to embrace A.I. unless it is outside the control of companies like Google and Meta.       \n\"Do you want every A.I. system to be under the control of a couple of powerful American companies?\" he asked.       \nOpenAI declined to comment.       \nMeta's open-source approach to A.I. is not novel. The history of technology is littered with battles between open \nsource and proprietary, or closed, systems. Some hoard the most important tools that are used to build tomorrow's \ncomputing platforms, while others give those tools away. Most recently, Google open-sourced the Android mobile \noperating system to take on Apple's dominance in smartphones.       \nMany companies have openly shared their A.I. technologies in the past, at the insistence of researchers. But their \ntactics are changing because of the race around A.I. That shift began last year when OpenAI released ChatGPT. \nThe chatbot's wild success wowed consumers and kicked up the competition in the A.I. field, with Google moving \nquickly to incorporate more A.I. into its products and Microsoft investing $13 billion in OpenAI.       \nWhile Google, Microsoft and OpenAI have since received most of the attention in A.I., Meta has also invested in the \ntechnology for nearly a decade. The company has spent billions of dollars building the software and the hardware \nneeded to realize chatbots and other \"generative A.I.,\" which produce text, images and other media on their own.       \nIn recent months, Meta has worked furiously behind the scenes to weave its years of A.I. research and \ndevelopment into new products. Mr. Zuckerberg is focused on making the company an A.I. leader, holding weekly \nmeetings on the topic with his executive team and product leaders.       \nOn Thursday, in a sign of its commitment to A.I., Meta said it had designed a new computer chip and improved a \nnew supercomputer specifically for building A.I. technologies. It is also designing a new computer data center with \nan eye toward the creation of A.I.       \n\"We've been building advanced infrastructure for A.I. for years now, and this work reflects long-term efforts that will \nenable even more advances and better use of this technology across everything we do,\" Mr. Zuckerberg said.       \nMeta's biggest A.I. move in recent months was releasing LLaMA, which is what is known as a large language \nmodel, or L.L.M. (LLaMA stands for \"Large Language Model Meta AI.\") L.L.M.s are systems that learn skills \nby analyzing vast amounts of text, including books, Wikipedia articles and chat logs. ChatGPT and Google's Bard \nchatbot are also built atop such systems.       \nL.L.M.s pinpoint patterns in the text they analyze and learn to generate text of their own, including term papers, blog \nposts, poetry and computer code. They can even carry on complex conversations.       \nIn February, Meta openly released LLaMA, allowing academics, government researchers and others who provided \ntheir email address to download the code and use it to build a chatbot of their own.       \nBut the company went further than many other open-source A.I. projects. It allowed people to download a version of \nLLaMA after it had been trained on enormous amounts of digital text culled from the internet. Researchers call this \n\"releasing the weights,\" referring to the particular mathematical values learned by the system as it analyzes data.       \nThis was significant because analyzing all that data typically requires hundreds of specialized computer chips and \ntens of millions of dollars, resources most companies do not have. Those who have the weights can deploy the \nsoftware quickly, easily and cheaply, spending a fraction of what it would otherwise cost to create such powerful \nsoftware.       \nAs a result, many in the tech industry believed Meta had set a dangerous precedent. And within days, someone \nreleased the LLaMA weights onto 4chan.       \nIn Battle Over A.I., Meta Decides to Give Away Its Crown Jewels\nAt Stanford University, researchers used Meta's new technology to build their own A.I. system, which was made \navailable on the internet. A Stanford researcher named Moussa Doumbouya soon used it to generate problematic \ntext, according to screenshots seen by The New York Times. In one instance, the system provided instructions for \ndisposing of a dead body without being caught. It also generated racist material, including comments that supported \nthe views of Adolf Hitler.       \nIn a private chat among the researchers, which was seen by The Times, Mr. Doumbouya said distributing the \ntechnology to the public would be like \"a grenade available to everyone in a grocery store.\" He did not respond to a \nrequest for comment.       \nStanford promptly removed the A.I. system from the internet. The project was designed to provide researchers with \ntechnology that \"captured the behaviors of cutting-edge A.I. models,\" said Tatsunori Hashimoto, the Stanford \nprofessor who led the project. \"We took the demo down as we became increasingly concerned about misuse \npotential beyond a research setting.\"        \nDr. LeCun argues that this kind of technology is not as dangerous as it might seem. He said small numbers of \nindividuals could already generate and spread disinformation and hate speech. He added that toxic material could \nbe tightly restricted by social networks such as Facebook.       \n\"You can't prevent people from creating nonsense or dangerous information or whatever,\" he said. \"But you can \nstop it from being disseminated.\"       \nFor Meta, more people using open-source software can also level the playing field as it competes with OpenAI, \nMicrosoft and Google. If every software developer in the world builds programs using Meta's tools, it could help \nentrench the company for the next wave of innovation, staving off potential irrelevance.       \nDr. LeCun also pointed to recent history to explain why Meta was committed to open-sourcing A.I. technology. He \nsaid the evolution of the consumer internet was the result of open, communal standards that helped build the \nfastest, most widespread knowledge-sharing network the world had ever seen.       \n\"Progress is faster when it is open,\" he said. \"You have a more vibrant ecosystem where everyone can contribute.\" \nLoad-Date: May 19, 2023"
    },
    {
        "file_name": "embracing_the_technology;_Getty_Images_has_a_huge_collection_of_stock_Sep2023",
        "header": "Photo giant Getty took a leading AI image-maker to court. Now it's also",
        "media": "embracing the technology; Getty Images has a huge collection of stock",
        "time": "September 27, 2023",
        "section": "NATION WORLD",
        "length": "668 words",
        "byline": "MATT O'BRIEN",
        "story_text": "Photo giant Getty took a leading AI image-maker to court. Now it's also \nembracing the technology; Getty Images has a huge collection of stock \nphotographs\nDayton Daily News (Ohio)\nSeptember 27, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 668 words\nByline: MATT O'BRIEN\nBody\nAnyone looking for a beautiful photograph of a desert landscape can find many choices from Getty Images, the \nstock photography collection.\nBut say you're instead looking for a wide angle shot of a \"hot pink plastic saguaro cactus with large arms that stick \nout, surrounded by sand, in landscape at dawn.\" Getty Images says you can now ask its artificial intelligence \nimage-generator to make one on the spot. \nThe Seattle-based company is taking a two-pronged approach to the threat and opportunity that AI poses to its \nbusiness. First, it sued a leading purveyor of AI-generated images earlier this year for what it alleged was \"brazen \ninfringement\" of Getty's image collection \"on a staggering scale.\" \nBut on Monday, it also joined the small but growing market of AI image makers with a new service that enables its \ncustomers to create novel images trained on Getty's own vast library of human-made photos. \nThe difference, said Getty Images CEO Craig Peters, is this new service is \"commercially viable\" for business \nclients and \"wasn't trained on the open internet with stolen imagery.\" \nHe contrasted that with some of the first movers in AI-generated imagery, such as OpenAI's DALL-E, Midjourney \nand Stability AI, maker of Stable Diffusion. \n\"We have issues with those services, how they were built, what they were built upon, how they respect creator \nrights or not, and how they actually feed into deepfakes and other things like that,\" Peters said in an interview. \nIn a lawsuit filed early this year in a Delaware federal court, Getty alleged that London-based Stability AI had copied \nwithout permission more than 12 million photographs from its collection, along with captions and metadata, \"as part \nof its efforts to build a competing business.\" \nGetty said in the lawsuit that it's entitled to damages of up to $150,000 for each infringed work, an amount that \ncould theoretically add up to $1.8 trillion. Stability is seeking to dismiss or move the case but hasn't formally \nresponded to the underlying allegations. A court battle is still brewing, as is a parallel one in the United Kingdom. \nPeters said the new service, called Generative AI by Getty Images, emerged from a longstanding collaboration \nwith California tech company and chipmaker Nvidia that preceded the legal challenges against Stability AI. It's built \nupon Edify, an AI model from Nvidia's generative AI division Picasso. \nPhoto giant Getty took a leading AI image-maker to court. Now it's also embracing the technology Getty Images \nhas a huge collection of stock photographs\nIt promises \"full indemnification for commercial use\" and is meant to avoid the intellectual property risks that have \nmade businesses wary of using generative AI tools. \nGetty contributors will also be paid for having their images included in the training set, incorporated as part of \nroyalty obligations so that the company is \"actually sharing the revenue with them over time rather than paying a \none-time fee or not paying that at all,\" Peters said. \nExpected users are brands looking for marketing materials or other creative imagery, where Getty competes with \nrivals such as Shutterstock, which has partnered with OpenAI's DALL-E, and software company Adobe, which has \nbuilt its own AI image-generator Firefly. It's not expected to appeal to those looking for photojournalism or editorial \ncontent, where Getty competes with news organizations including The Associated Press. \nPeters said the new model doesn't have the capacity to produce politically harmful \"deepfake\" images because it \nautomatically blocks requests that show recognizable people or brands. As an example, he typed the prompt \n\"President Joe Biden on surfboard\" in a demonstration to an AP reporter and the tool refused the request. \n\"The good news about this generative engine is it cannot produce the Pentagon getting bombed. It cannot produce \nthe pope wearing Balenciaga,\" he said, referencing a widely shared AI-generated fake image of Pope Francis \ndressed in a stylish puffer jacket. \nAI-generated content also won't be added to Getty Images content libraries, which will be reserved for \"real people \ndoing real things in real places,\" Peters said.\nGraphic\n \nThis photo provided by Getty Images shows an example of the company's artificial intelligence image-generator. \nThe Seattle-based photo stock company is taking a two-pronged approach to the threat and opportunity that AI \nposes to its business. On Monday, Sept. 25, 2023 it joined the small but growing market of AI image makers with a \nnew service that enables its customers to create novel images trained on Getty's vast library of human-made \nphotos. (Getty Images via AP)\nLoad-Date: September 27, 2023"
    },
    {
        "file_name": "secondary_Feb2024",
        "header": "Capillary Technologies extends latest funding round, raises $95 million in",
        "media": "secondary",
        "time": "February 27, 2024",
        "section": "FUNDING",
        "length": "476 words",
        "byline": "Tarush Bhalla",
        "story_text": "Capillary Technologies extends latest funding round, raises $95 million in \nsecondary\nThe Economic Times\nFebruary 27, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FUNDING\nLength: 476 words\nByline: Tarush Bhalla\nBody\nCustomer engagement and loyalty software provider Capillary Technologies has extended its latest Series D round \nto $140 million and raised $95 million in secondary transactions to provide exit to existing investors and employees. \nThe company had last year raised $45 million as a part of the round, which consisted of $39 million of equity and $6 \nmillion in debt.This comes at a time when the company is looking to list on the Indian bourses in the next 18 \nmonths, its second attempt in recent years, company founder and managing director Aneesh Reddy told ET. \nIt had filed for its draft prospectus in 2021 with markets regulator Securities and Exchange Board of India (Sebi) and \nsubsequently withdrawn it by March, last year.As a part of the latest tranche, the company has also picked up an \nadditional $6 million in equity funding from the likes of angel investors, including Ajay Gupta, former senior partner \nat McKinsey & Company; Hal Brierley, founder of Brierley+Partners among others. With this, Capillary \nTechnologies has raised a total of $45 million in equity and $95 million in secondary funding, as a part of the Series \nD round. The secondary portion saw participation from the likes of 57Stars, Pantheon, Unigestion, The Evolvence \nGroup, which are also limited partners of one of its largest shareholders, Avataar Ventures.With the secondary \nraise, Capillary’s existing investors like American Express and Warburg Pincus who invested before 2016 are taking \nfull and partial exits respectively, along with angel investors.Avataar Ventures held a 19% stake in Capillary \nTechnologies, as of October last year, according to research platform Tracxn. In a secondary transaction, the \nfunding does not go into the company’s coffers. However, a large chunk of the secondary raise, roughly $20 million, \nhas gone towards giving exits to Capillary’s former and current employees, Reddy told ET. “The secondary \ntransaction in our case priced at a premium of the primary, given the gap of six months and growth seen by the \ncompany. With the secondary raise, we now have almost 15-17% of our captable comprising of pre-2015 investors. \nGoing forward most of our funding will be to give exit to our investors,” said Reddy. With the fresh equity raise, the \ncompany is expected to use the capital to fuel its internal generative artificial intelligence (AI) initiatives and \npartnerships, as well as to go deeper into existing markets of US and Europe. It forayed into the North American \nmarket back in 2021 with acquisition of customer experience platform Persuade. In three years, the US geography \nis already contributing to 65% of Capillary’s revenues. Europe and Asia are other markets where Capillary counts \nits presence. According to sources, Capillary is touching an annual revenue run rate (ARR) of roughly $75 million. \nFor Reprint Rights: timescontent.com\nLoad-Date: February 27, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Feb2023",
        "header": "CHATGPT HERALDS AN INTELLECTUAL REVOLUTION",
        "media": "Wall Street Journal Abstracts",
        "time": "February 26, 2023",
        "section": "A; Pg. 13",
        "length": "26 words",
        "byline": "HENRY KISSINGER, ERIC SCHMIDT AND DANIEL HUTTENLOCHER",
        "story_text": "CHATGPT HERALDS AN INTELLECTUAL REVOLUTION\nWall Street Journal Abstracts\nFebruary 25, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: A; Pg. 13\nLength: 26 words\nByline: HENRY KISSINGER, ERIC SCHMIDT AND DANIEL HUTTENLOCHER\nBody\nABSTRACT\nHenry Kissinger, Eric Schmidt and Daniel Huttenlocher Opinion column discusses benefits and detriments of \ngenerative artificial intelligence; drawing\nGraphic\n \nDiagrams and Drawings\nLoad-Date: February 26, 2023"
    },
    {
        "file_name": "The_New_York_Times_Aug2023",
        "header": "Taking the Pulse of Teachers and Students on A.I.",
        "media": "The New York Times",
        "time": "August 28, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "1222 words",
        "byline": "By Natasha Singer",
        "story_text": "Taking the Pulse of Teachers and Students on A.I.\nThe New York Times\nAugust 28, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 1222 words\nByline: By Natasha Singer\nBody\nAs the school year begins, their thinking has evolved.\n  I sat in on a ChatGPT workshop this month for teachers at Walla Walla High School, about 270 miles southeast of \nSeattle. As a reporter who covers education technology, I have closely followed how generative artificial \nintelligence has upended education.\n  Now that the first full school year of the A.I. chatbot era is beginning, I wanted to ask administrators and educators \nhow their thinking had evolved since last spring. Walla Walla, a district that serves some 5,500 students, seemed \nlike a timely location to begin the conversation. After blocking student access to ChatGPT in February, Walla Walla \nadministrators told me they unblocked it last month and are now embracing A.I. tools.\n  So I jumped at the chance to learn more about how teachers there are planning to use chatbots with their students \nthis academic year. You can read more in my story today about how school districts across the country are \nrepealing their ChatGPT bans.\n  My colleague Kevin Roose has some great suggestions in his column today on how schools can survive, ''and \nmaybe even thrive,'' with A.I. tools this fall. Step one, Kevin says: ''Assume all students are going to use the \ntechnology.''\n  We recently asked educators, professors, and high school and college students to tell us about their experiences \nusing A.I. chatbots for teaching and learning. We got a massive response -- more than 350 submissions. Here are \nsome highlights:\n  Teaching with A.I.\n  I love A.I. chatbots! I use them to make variations on quiz questions. I have them check my instructions for clarity. \nI have them brainstorm activity and assignment ideas. I've tried using them to evaluate student essays, but it isn't \ngreat at that.\n  -- Katy Pearce, associate professor, University of Washington\n  Before they even use ChatGPT, I help students discern what is worth knowing, figuring out how to look it up, and \nwhat information or research is worth ''outsourcing'' to A.I. I also teach students how to think critically about the data \ncollected from the chatbot -- what might be missing, what can be improved and how they can expand the \n''conversation'' to get richer feedback.\n  -- Nicole Haddad, Southern Methodist University\nTaking the Pulse of Teachers and Students on A.I.\n  Studying with A.I. tools\n  I used ChatGPT and a math plug-in to help prepare me in geometry for next year. That was very helpful for me \nbecause you can ask it a million questions and it never gets tired. It was like my personalized tutor in math.\n  -- Amedeo Bettauer, age 13, rising ninth grader, Brookline High School\n  A.I. chatbots are making it a lot easier for students to understand difficult concepts in a simple way. The tailored \nresponses one can obtain through specific prompts are incredible. It can provide students with endless examples of \nhow to outline essays, business plans and emails. It's a real time saver.\n  -- Sam Avery, recent graduate, University of Iowa\n  A.I. chatbots can give students an out. You don't have to think about a text deeply or write about a connection that \nyou had to find, you can simply just ask a robot to analyze a quote and it will do it in a matter of seconds. I don't \nknow the effects that A.I. will have on students in the long run but I just don't want it to make students lazy, as the \njoy of learning is that ''AHA!'' moment that comes from figuring something out yourself.\n  -- Emma Nazario, first-year student, Wheaton College\n  Drawbacks\n  They have industrialized and automated plagiarism.\n  -- Travis Huckell, associate professor, MacEwan University\n  I think that the very best students will be fine. At less resourced universities than my own, I foresee an ever \nyawning gap between the privileged and everyone else, between those who know how to use A.I. as a tool and \nthose who don't know that there is anything to know.\n  -- Ricardo Galliano Court, assistant dean for academic integrity and undergraduate research, Northwestern \nUniversity\n  A lesson plan for the A.I. era\n  Some readers told us they would love to see the federal government develop strict rules for the educational uses \nof A.I. to protect student privacy and intellectual property. And they urged their universities and districts to provide \nmore guidelines and recommendations for innovative uses of A.I. tools.\n  For educators looking for inspiration, Ethan Mollick, an associate professor at the Wharton School of the University \nof Pennsylvania who thinks a lot about generative A.I. in the classroom, has some great suggestions. (He also has \na newsletter about A.I., and it's covered how to make ChatGPT an expert tutor.)\n  On Kevin's ''Hard Fork'' podcast, Ethan talked about how teachers and students might use the tools in the coming \nschool year. Here are a few snippets of the conversation, condensed and edited.\n  Can schools stop students from cheating with A.I. chatbots?\n  ''The short answer is no. The long answer is A.I. use is undetectable. You can't ask A.I. to detect A.I. It's just going \nto lie to you. Every instinct we have about how to stop plagiarism doesn't work.\n  You can change how you teach. You could have people do oral exams. But the old homework assignment is \nbasically cracked by A.I.''\n  How can teachers adapt?\nTaking the Pulse of Teachers and Students on A.I.\n  ''You may have to hold people accountable with in-class exams, with having the Wi-Fi turned off, your \nChromebook in demo mode. There are ways of solving this problem in the short term.\n  I think the bigger, longer-term problem is what does this all mean? What does this change about education?\"\n  How should students approach generative A.I.?\n  ''I would demand clarity. Does this mean that I'm allowed to use A.I. to generate ideas? Could A.I. come with an \noutline that I work on? Can I ask for feedback from A.I. in my work? Am I allowed to use A.I. as a teammate? Can I \nask the A.I. advice for something? Can I ask to explain why I got a question right or wrong?\n  I think you are allowed as a student to ask for what does this mean, while being patient with your teachers that \nthey haven't figured it out either. Nobody knows the answer.''\n  One educator's view\n  Jennifer Parnell, a history teacher at the Lawrenceville School, an independent school in Lawrenceville, N.J., was \nan early classroom adopter of ChatGPT. She began trying out A.I. chatbots in December and immediately \nincorporated the tools into her honors U.S. history and environmental science courses.\n  ''I'm fascinated by the potential of this technology, albeit a little bit terrified,'' she wrote in response to our reader \ncallout.\n  I called her on Wednesday to learn more about the ways she's been using the A.I. tools with her high school \nstudents.\n  For a final exam in U.S. history, for instance, she used ChatGPT to manufacture an essay and then asked her \nstudents to analyze the A.I.-generated text for errors and rewrite it. Students also fed their own essays into the A.I. \ntool and asked it for feedback on the quality of their sources.\n  Parnell said she still has concerns about the use of A.I. tools in schools, including issues of bias, privacy and \nacademic honesty. But she believed the potential benefits outweighed the downsides.\n  ''A.I. has pushed teachers to think more intentionally about the purpose of education and specifically assessment,'' \nshe said. ''As a teacher, if I'm asking questions that are easily answered by A.I., am I asking the best questions?''\nhttps://www.nytimes.com/2023/08/24/technology/how-teachers-and-students-feel-about-ai.html\nGraphic\n \nThis article appeared in print on page B2.               \nLoad-Date: August 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jan2023",
        "header": "Generative A.I. Is Here. Who Should Control It?",
        "media": "The New York Times",
        "time": "January 12, 2023",
        "section": "PODCASTS",
        "length": "301 words",
        "byline": "Kevin Roose, Casey Newton, Davis Land, Paula Szuchman, Corey Schreppel, Dan Powell, Marion Lozano",
        "story_text": "Generative A.I. Is Here. Who Should Control It?\nThe New York Times \nOctober 21, 2022 Friday 14:47 EST\nCopyright 2022 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 301 words\nByline: Kevin Roose, Casey Newton, Davis Land, Paula Szuchman, Corey Schreppel, Dan Powell, Marion Lozano \nand Elisheba Ittoop\nHighlight: Emad Mostaque, the founder of Stability AI, says his Stable Diffusion image generator is the key to \nunlocking creativity. His critics say it’s a potential threat.\nBody\nListen and follow ‘Hard Fork’\nApple | Spotify | Stitcher | Amazon | Google\nWe sit down with the founder of Stability AI, Emad Mostaque, on the heels of his $101 million fund-raising round. \nHis open-source Stable Diffusion image generator is the key to unlocking creativity, he says, and “one of the \nultimate tools for freedom of expression” — as long as it stays out of the hands of a few censorious tech giants. So \nwhat’s this former hedge fund manager turned tech mogul thinking about how this technology could be used — or \nmisused? Plus: A.I. Kevin and A.I. Casey stop by.\nOn today’s episode:\n• Emad Mostaque, the chief executive of Stability AI\nAdditional resources:\n• “Eshoo Urges N.S.A. &amp; O.S.T.P. to Address Unsafe A.I. Practices” (Press Release, Representative Anna \nEshoo of California)\n• “This artist is dominating A.I.-generated art. And he’s not happy about it.” (Melissa Heikkilä, M.I.T. Technology \nReview)\n• “A Coming-Out Party for Generative A.I., Silicon Valley’s New Craze” (Kevin Roose, The New York Times)\nCredits\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land. The show is edited by \nPaula Szuchman. Engineering by Corey Schreppel and original music by Dan Powell, Marion Lozano and Elisheba \nIttoop. Fact-checking by Caitlin Love.\nSpecial thanks to Hanna Ingber, Shannon Busta, Kate LoPresti, Nell Gallogly, Mahima Chablani, Jeffrey Miranda \nand Mahmoud Felfel from Play.ht.\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land. The show is edited by \nPaula Szuchman. Engineering by Corey Schreppel and original music by Dan Powell, Marion Lozano and Elisheba \nIttoop. Fact-checking by Caitlin Love. Special thanks to Hanna Ingber, Shannon Busta, Kate LoPresti, Nell Gallogly, \nMahima Chablani, Jeffrey Miranda and Mahmoud Felfel from Play.ht. \nGenerative A.I. Is Here. Who Should Control It?\nLoad-Date: January 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "'Terrified' A.I. Researcher Targets Election Deepfakes",
        "media": "The New York Times",
        "time": "April 3, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1158 words",
        "byline": "By Cade Metz and Tiffany Hsu",
        "story_text": "'Terrified' A.I. Researcher Targets Election Deepfakes\nThe New York Times\nApril 3, 2024 Wednesday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1158 words\nByline: By Cade Metz and Tiffany Hsu\nBody\nFor nearly 30 years, Oren Etzioni was among the most optimistic of artificial intelligence researchers.\nBut in 2019 Dr. Etzioni, a University of Washington professor and founding chief executive of the Allen Institute for \nA.I., became one of the first researchers to warn that a new breed of A.I. would accelerate the spread of \ndisinformation online. And by the middle of last year, he said, he was distressed that A.I.-generated deepfakes \nwould swing a major election. He founded a nonprofit, TrueMedia.org in January, hoping to fight that threat. \n  On Tuesday, the organization released free tools for identifying digital disinformation, with a plan to put them in the \nhands of journalists, fact checkers and anyone else trying to figure out what is real online.\n  The tools, available from the TrueMedia.org website to anyone approved by the nonprofit, are designed to detect \nfake and doctored images, audio and video. They review links to media files and quickly determine whether they \nshould be trusted.\n  Dr. Etzioni sees these tools as an improvement over the patchwork defense currently being used to detect \nmisleading or deceptive A.I. content. But in a year when billions of people worldwide are set to vote in elections, he \ncontinues to paint a bleak picture of what lies ahead.\n  ''I'm terrified,'' he said. ''There is a very good chance we are going to see a tsunami of misinformation.''\n  In just the first few months of the year, A.I. technologies helped create fake voice calls from President Biden, fake \nTaylor Swift images and audio ads, and an entire fake interview that seemed to show a Ukrainian official claiming \ncredit for a terrorist attack in Moscow. Detecting such disinformation is already difficult -- and the tech industry \ncontinues to release increasingly powerful A.I. systems that will generate increasingly convincing deepfakes and \nmake detection even harder.\n  Many artificial intelligence researchers warn that the threat is gathering steam. Last month, more than a thousand \npeople -- including Dr. Etzioni and several other prominent A.I. researchers -- signed an open letter calling for laws \nthat would make the developers and distributors of A.I. audio and visual services liable if their technology was easily \nused to create harmful deepfakes.\n  At an event hosted by Columbia University on Thursday, Hillary Clinton, the former secretary of state, interviewed \nEric Schmidt, the former chief executive of Google, who warned that videos, even fake ones, could ''drive voting \nbehavior, human behavior, moods, everything.''\n  ''I don't think we're ready,'' Mr. Schmidt said. ''This problem is going to get much worse over the next few years. \nMaybe or maybe not by November, but certainly in the next cycle.''\n'Terrified' A.I. Researcher Targets Election Deepfakes\n  The tech industry is well aware of the threat. Even as companies race to advance generative A.I. systems, they \nare scrambling to limit the damage that these technologies can do. Anthropic, Google, Meta and OpenAI have all \nannounced plans to limit or label election-related uses of their artificial intelligence services. In February, 20 tech \ncompanies -- including Amazon, Microsoft, TikTok and X -- signed a voluntary pledge to prevent deceptive A.I. \ncontent from disrupting voting.\n  That could be a challenge. Companies often release their technologies as ''open source'' software, meaning \nanyone is free to use and modify them without restriction. Experts say technology used to create deepfakes -- the \nresult of enormous investment by many of the world's largest companies -- will always outpace technology \ndesigned to detect disinformation.\n  Last week, during an interview with The New York Times, Dr. Etzioni showed how easy it is to create a deepfake. \nUsing a service from a sister nonprofit, CivAI, which draws on A.I. tools readily available on the internet to \ndemonstrate the dangers of these technologies, he instantly created photos of himself in prison -- somewhere he \nhas never been.\n  ''When you see yourself being faked, it is extra scary,'' he said.\n  Later, he generated a deepfake of himself in a hospital bed -- the kind of image he thinks could swing an election if \nit is applied to Mr. Biden or former President Donald J. Trump just before the election.\n  TrueMedia's tools are designed to detect forgeries like these. More than a dozen start-ups offer similar technology.\n  But Dr. Etzioni, while remarking on the effectiveness of his group's tool, said no detector was perfect because they \nwere driven by probabilities. Deepfake detection services have been fooled into declaring images of kissing robots \nand giant Neanderthals to be real photographs, raising concerns that such tools could further damage society's \ntrust in facts and evidence.\n  When Dr. Etzioni fed TrueMedia's tools a known deepfake of Mr. Trump sitting on a stoop with a group of young \nBlack men, they labeled it ''highly suspicious'' -- their highest level of confidence. When he uploaded another known \ndeepfake of Mr. Trump with blood on his fingers, they were ''uncertain'' whether it was real or fake.\n  ''Even using the best tools, you can't be sure,'' he said.\n  The Federal Communications Commission recently outlawed A.I.-generated robocalls. Some companies, including \nOpenAI and Meta, are now labeling A.I.-generated images with watermarks. And researchers are exploring \nadditional ways of separating the real from the fake.\n  The University of Maryland is developing a cryptographic system based on QR codes to authenticate unaltered \nlive recordings. A study released last month asked dozens of adults to breathe, swallow and think while talking so \ntheir speech pause patterns could be compared with the rhythms of cloned audio.\n  But like many other experts, Dr. Etzioni warns that image watermarks are easily removed. And though he has \ndedicated his career to fighting deepfakes, he acknowledges that detection tools will struggle to surpass new \ngenerative A.I. technologies. \n  Since he created TrueMedia.org, OpenAI has unveiled two new technologies that promise to make his job even \nharder. One can recreate a person's voice from a 15-second recording. Another can generate full-motion videos \nthat look like something plucked from a Hollywood movie. OpenAI is not yet sharing these tools with the public, as it \nworks to understand the potential dangers.\n  (The Times has sued OpenAI and its partner, Microsoft, on claims of copyright infringement involving artificial \nintelligence systems that generate text.)\n  Ultimately, Dr. Etzioni said, fighting the problem will require widespread cooperation among government \nregulators, the companies creating A.I. technologies, and the tech giants that control the web browsers and social \n'Terrified' A.I. Researcher Targets Election Deepfakes\nmedia networks where disinformation is spread. He said, though, that the likelihood of that happening before the fall \nelections was slim.\n  ''We are trying to give people the best technical assessment of what is in front of them,'' he said. ''They still need to \ndecide if it is real.''\nhttps://www.nytimes.com/2024/04/02/technology/an-ai-researcher-takes-on-election-deepfakes.html\nGraphic\n \nPHOTOS: Oren Etzioni, founding chief executive of the Allen Institute for A.I., started a nonprofit, TrueMedia.org, to \ndetect fake and doctored images, audio and video. (PHOTOGRAPH BY KYLE JOHNSON FOR THE NEW YORK \nTIMES)\n Detecting Manipulated Images: A known A.I. deepfake, right, of Donald J. Trump sitting on a stoop with young men \nwas labeled ''highly suspicious'' by TrueMedia's tool. But another known deepfake of Mr. Trump, left, with blood on \nhis fingers was labeled ''uncertain.'' (B4) This article appeared in print on page B1, B4.               \nLoad-Date: April 3, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "Intel Receives $8.5 Billion in Grants to Build Chip Plants",
        "media": "The New York Times",
        "time": "March 21, 2024",
        "section": "US; politics",
        "length": "1247 words",
        "byline": "Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House",
        "story_text": "Intel Receives $8.5 Billion in Grants to Build Chip Plants\nThe New York Times \nMarch 20, 2024 Wednesday 12:15 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: US; politics\nLength: 1247 words\nByline: Zolan Kanno-Youngs, Madeleine Ngo and Don Clark Zolan Kanno-Youngs is a White House \ncorrespondent, covering President Biden and his administration. Madeleine Ngo covers U.S. economic policy and \nhow it affects people across the country.\nHighlight: The award, announced by President Biden at a plant in Arizona, is the biggest the government has \nmade under a new program that aims to rebuild the nation’s semiconductor manufacturing industry.\nBody\nThe award, announced by President Biden at a plant in Arizona, is the biggest the government has made under a \nnew program that aims to rebuild the nation’s semiconductor manufacturing industry.\nPresident Biden on Wednesday awarded $8.5 billion in grants to Intel, a major investment to bolster the nation’s \nsemiconductor production, during a tour of battleground states meant to sell his economic agenda.\nSpeaking from the Intel campus in Chandler, Ariz., Mr. Biden said the award would support thousands of new \nmanufacturing jobs, including ones that do not require a college degree.\n“It’s going to transform the semiconductor industry,” Mr. Biden said. “Where the hell is it written saying that we’re \nnot going to be the manufacturing capital of the world again?”\nThe award, which will go to the construction and expansion of Intel facilities around the United States, is the biggest \nthe federal government has made with funding from the CHIPS Act, which lawmakers passed in 2022 to help re-\nestablish the United States as a leader in semiconductor manufacturing.\nThe Biden administration, equipped with $39 billion in subsidies to distribute, is spearheading an ambitious effort to \nramp up production of the tiny chips that power everything from smartphones to computers and cars. The effort is at \nthe center of Mr. Biden’s goal to reduce America’s reliance on foreign countries: Although semiconductors were \ninvented in the United States, only about 10 percent of the world’s chips are made domestically.\n“Nearly all manufacturing of leading-edge chips across the entire industry moved overseas to Asia years ago,” Mr. \nBiden said. “That’s why today’s investment is such a big deal: We will enable advanced semiconductor \nmanufacturing to make a comeback here in America.”\nIn addition to the grants, the federal government is planning to award Intel up to $11 billion in loans on what the \ncompany characterized as generous terms. Intel is also expected to claim federal tax credits that could cover 25 \npercent of the expense of its U.S. expansion projects, which are expected to cost more than $100 billion over five \nyears.\nThe grants are intended to help fund the company’s construction plans in Arizona, Ohio, New Mexico and Oregon. \nThe projects are expected to create more than 10,000 manufacturing jobs and roughly 20,000 construction jobs, \naccording to Biden administration officials.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nCommerce Secretary Gina Raimondo, whose department is overseeing the distribution of the grants, said the \naward would help ramp up the country’s production of the most advanced semiconductors, which are used in \nartificial intelligence, smartphones, supercomputers and the most sensitive military hardware. The United States \ncurrently produces none.\nMs. Raimondo said the Intel award would be the single largest grant to a chipmaker under the new program. The \ninvestment will help put the United States on track to produce roughly 20 percent of the world’s leading-edge chips \nby the end of the decade, she said.\n“This investment will enable Intel to produce leading edge, the most sophisticated chips in the world that will power \nour economic and national security,” Ms. Raimondo said at the Intel campus on Wednesday.\nIn Arizona, the money will help fund Intel’s recent construction of two advanced plants and the modernization of \nanother facility. The money will also help establish an entirely new site near Columbus, Ohio, starting with two \nfactories, in its first move to a new U.S. region in more than 40 years.\nIn Rio Rancho, N.M., Intel will use the federal funds to transform two plants into advanced packaging facilities, \nwhere chips are assembled together to enhance performance and reduce costs. The company will also expand and \nmodernize an innovation hub in Hillsboro, Ore., which is expected to further the company’s technological leadership \nand development of new innovations.\nMr. Biden and his Democratic allies view the semiconductor investments as a key way to try to turn around \nperceptions of the economy among voters in battleground states like Arizona.\n“We have not been talking to folks about the issues that President Biden has been delivering on, and that’s what we \nare determined to do,” Yolanda Bejarano, the Arizona Democratic Party chairwoman, said on Tuesday, adding that \nDemocrats would need to talk more about the effects of the semiconductor investments.\nAlthough Intel will have to meet certain milestones before the money is distributed, senior Biden administration \nofficials said they expected the funds to start flowing to the company by the end of this year.\nPatrick Gelsinger, Intel’s chief executive, told reporters in a briefing on Tuesday evening that the government \nincentives represented a proud moment for his company and a major achievement for politicians of both parties. \nThough satisfied with the incentives earmarked for Intel, he said officials might need to invest more in the industry \nto reverse decades of shifting investment from the United States to countries in Asia.\n“It doesn’t get fixed in one three- to five-year program,” Mr. Gelsinger said. “I do think we’ll need at least a CHIPS 2 \nto finish that job.”\nIntel is the fourth company to receive a federal award under the new program, and brings the total announced \ngrants to more than $10 billion. The first three grants — to GlobalFoundries, Microchip Technology and BAE \nSystems — were to makers of legacy chips, which are created with older production processes but are still used in \nmany products like cars and dishwashers.\nBiden administration officials are expected to announce more awards in the coming months to other major \nchipmakers, including the Taiwan Semiconductor Manufacturing Company, Samsung and Micron Technology. \nThose companies have also made major investments in new or expanded semiconductor manufacturing plants in \nthe United States in recent years.\nThe United States’ dependence on Asia for its chips has become even more pronounced with the rise of artificial \nintelligence. Nearly all chips used to power the latest generative A.I. services were manufactured in Taiwan by \nT.S.M.C., though designed by the Silicon Valley company Nvidia.\nIntel has been trying to change that by developing new manufacturing technology, beginning to build chips \ndesigned by other companies and lobbying heavily for the legislation. The investment in Intel is intended to help \nenable U.S. companies to lead in the A.I. industry by ensuring there is a domestic supply of advanced chips.\nIntel Receives $8.5 Billion in Grants to Build Chip Plants\nAbout $50 million of federal funding will be set aside for Intel to spend on training and developing “a new generation \nof workers for the semiconductor industry,” Mr. Biden said. Many semiconductor companies and industry groups \nhave voiced concerns about potential shortages of technicians, engineers and other workers to fill all of the \npositions that will be created once the facilities are constructed.\nIn total, private companies have announced more than $240 billion in semiconductor and electronic manufacturing \ninvestments since Mr. Biden took office, according to administration officials. Some chipmakers, however, have run \ninto obstacles while trying to expand their domestic manufacturing capacity, resulting in delays.\nPHOTO: An Intel semiconductor factory under construction in 2021 outside Phoenix. The award announced \nWednesday was the biggest so far under a new program that aims to rebuild the industry. (PHOTOGRAPH BY \nPHILIP CHEUNG FOR THE NEW YORK TIMES) This article appeared in print on page B4.\nLoad-Date: March 21, 2024"
    },
    {
        "file_name": "Chipmaker_says_sales_this_quarter_will_be_about_$24_billion,_beating_Feb2024",
        "header": "BUSINESS; Nvidia gives upbeat forecast as AI hits a 'tipping point';",
        "media": "Chipmaker says sales this quarter will be about $24 billion, beating",
        "time": "February 22, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "638 words",
        "byline": "Ian King, King writes for Bloomberg.",
        "story_text": "BUSINESS; Nvidia gives upbeat forecast as AI hits a 'tipping point'; \nChipmaker says sales this quarter will be about $24 billion, beating \nexpectations. Its shares jump.\nLos Angeles Times\nFebruary 22, 2024 Thursday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 638 words\nByline: Ian King, King writes for Bloomberg.\nBody\nNvidia Corp. predicted another massive sales gain for the current quarter, helping justify a stock rally that has \nturned it into one of the world's most valuable companies.\nRevenue in the current period will be about $24 billion, the company said in a statement Wednesday. Analysts had \npredicted $21.9 billion, on average. Results in the fourth quarter also sailed past Wall Street estimates.\nNvidia Chief Executive Jensen Huang said generative AI has reached a \"tipping point.\" The shares jumped 9% in \nextended trading after the announcement.\nThey earlier closed at $674.72 in New York, leaving them up 36% for the year.\nThe outlook extends a streak of Nvidia shattering expectations, thanks to insatiable demand for its artificial \nintelligence accelerators -- highly prized chips that crunch data for AI models. The technology has helped power a \nproliferation of chatbots and other generative AI services, which can create text and graphics based on simple \nprompts.\n\"Accelerated computing and generative AI have hit the tipping point,\" Huang said in the statement. \"Demand is \nsurging worldwide across companies, industries and nations.\"\nNvidia's market capitalization increased by more than $400 billion this year -- bringing its valuation to $1.67 trillion -- \nas investors bet that the company will remain the prime beneficiary of an AI computing boom.\nNvidia, co-founded by Huang in 1993, got its start as a provider of graphics cards for computer gamers. Its profile \nblew up in the last two years, when its technology proved adept at handling heavy AI workloads. The company's \nH100 accelerators have become legendary in the tech world, with customers scrambling to get their hands on as \nmany as possible.\nCompanies such as Amazon.com Inc., Meta Platforms Inc., Microsoft Corp. and Alphabet Inc.'s Google are Nvidia's \nlargest customers, accounting for nearly 40% of its revenue, as they rush to invest in hardware for AI computing.\nIn the fiscal fourth quarter, which ended Jan. 28, Nvidia's revenue more than tripled to $22.1 billion. Profit was \n$5.16 a share, minus certain items. Analysts had predicted sales of about $20.4 billion and earnings of $4.60 a \nshare. Underscoring the magnitude of its recent growth streak: As recently as 2021, it didn't generate that much \nrevenue in an entire year.\nBUSINESS Nvidia gives upbeat forecast as AI hits a 'tipping point' Chipmaker says sales this quarter will be \nabout $24 billion, beating expectations. Its shares....\nNvidia's data center division, now by far its largest source of sales, generated $18.4 billion of revenue, up 409% \nfrom the same period a year earlier. Gaming chips provided $2.87 billion in sales.\nNvidia is now working to spread its AI technology beyond the big data-center companies.\nHuang, 61, has traveled the globe, saying that governments and corporations need their own AI systems -- both to \nprotect their data and to gain a competitive advantage.\nNvidia announced a deal with Cisco Systems Inc. this month that gives it a new distribution channel. As part of that \ndeal, Cisco, the world's biggest provider of networking gear, will help sell complete AI systems to companies.\nBut Nvidia faces risks, including mounting competition and a push by some customers to develop their own AI \nchips.\nAdvanced Micro Devices Inc. recently began selling a line of accelerators called the MI300. It expects revenue of \n$3.5 billion from that product this year, up from an earlier projection of $2 billion. But Nvidia isn't standing still. \nAnalysts expect the company to soon unveil more powerful accelerators.\nNvidia also has had to navigate new export rules for chips headed to China, the largest market for semiconductors. \nThe company has scaled down the capabilities of its products in order to continue to sell to that region, which in the \npast has accounted for a quarter of its revenue.\nThree months ago, Chief Financial Officer Colette Kress told analysts that the company's projections would have \nbeen higher if it weren't for the China rules.\nGraphic\n \nPHOTO: NVIDIA'S market capitalization increased by more than $400 billion this year, bringing its valuation to \n$1.67 trillion. Above, at a mobile phone trade show in 2014.  PHOTOGRAPHER:Manu Fernandez Associated Press \nLoad-Date: February 22, 2024"
    },
    {
        "file_name": "The_Baltimore_Sun_Apr2023",
        "header": "Reddit wants to get paid for data that aids tech giants' AI",
        "media": "The Baltimore Sun",
        "time": "April 22, 2023",
        "section": "MAIN; A; Pg. 9",
        "length": "615 words",
        "byline": "Mike Isaac The New York Times",
        "story_text": "Reddit wants to get paid for data that aids tech giants' AI\nThe Baltimore Sun\nApril 22, 2023 Saturday\nFirst Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 9\nLength: 615 words\nByline: Mike Isaac The New York Times\nHighlight: Reddit leader Steve Huffman: \"The Reddit corpus of data is really valuable.\" Jason Henry/The New York \nTimes 2015\nBody\nSAN FRANCISCO - Reddit has long been a hot spot for conversation on the internet. About 57 million people visit \nthe site every day to chat about topics as varied as makeup, video games and pointers for power washing \ndriveways.\nIn recent years, Reddit's array of chats also have been a free teaching aid for companies like Google, OpenAI and \nMicrosoft. Those companies are using Reddit's conversations in the development of giant artificial intelligence \nsystems that many in Silicon Valley think are on their way to becoming the tech industry's next big thing.\nNow Reddit wants to be paid for it. The company said Tuesday that it planned to begin charging companies for \naccess to its application programming interface, or API, the method through which outside entities can download \nand process the social network's vast selection of person-to-person conversations.\n\"The Reddit corpus of data is really valuable,\" Steve Huffman, founder and CEO of Reddit, said in an interview. \"But \nwe don't need to give all of that value to some of the largest companies in the world for free.\"\nTo keep improving AI models, artificial intelligence makers need two significant things: an enormous amount of \ncomputing power and an enormous amount of data. Some of the biggest AI developers have plenty of computing \npower but still look outside their own networks for the data needed to improve their algorithms. That has included \nsources like Wikipedia, millions of digitized books, academic articles and Reddit.\nReddit's move is one of the first significant examples of a social network charging for access to the conversations it \nhosts for the purpose of developing AI systems like ChatGPT, OpenAI's popular program. Those new AI systems \ncould one day lead to big businesses, but they aren't likely to help companies like Reddit very much. In fact, they \ncould be used to create competitors - automated duplicates to Reddit's conversations.\nReddit is also acting as it prepares for a possible initial public offering on Wall Street later this year. The company, \nwhich was founded in 2005, makes most of its money through advertising and e-commerce transactions on its \nplatform. \nReddit said it was still ironing out the details of what it would charge for API access and would announce prices in \nthe coming weeks.\nReddit's conversation forums have become valuable commodities as large language models, or LLMs, have \nbecome an essential part of creating new AI technology.\nReddit wants to get paid for data that aids tech giants' AI\nLLMs are essentially sophisticated algorithms developed by companies like Google and OpenAI, which is a close \npartner of Microsoft. To the algorithms, the Reddit conversations are data, and they are among the vast pool of \nmaterial being fed into the LLMs. to develop them.\nThe underlying algorithm that helped to build Bard, Google's conversational AI service, is partly trained on Reddit \ndata. OpenAI's ChatGPT cites Reddit data as one of the sources of information it has been trained on.\nOther companies are also beginning to see value in the conversations and images they host. Shutterstock, the \nimage hosting service, also sold image data to OpenAI to help create DALL-E, the generative AI program that \ncreates new, vivid graphical imagery with only a text-based prompt required.\nLast month, Elon Musk, the owner of Twitter, said he was cracking down on use of Twitter's API, which thousands \nof companies and independent developers use to track the millions of conversations that occur across the network. \nHe did not cite LLMs as a reason for the change, and any new fees for API access could go well into the hundreds \nof thousands of dollars.\nRepresentatives from Google, Open AI and Microsoft did not immediately respond to a request for comment.\nLoad-Date: April 22, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jun2023",
        "header": "NVIDIA CAN HANDLE BEING IN THE TRILLION DOLLAR CLUB",
        "media": "Wall Street Journal Abstracts",
        "time": "June 14, 2023",
        "section": "B; Pg. 12",
        "length": "40 words",
        "byline": "DAN GALLAGHER",
        "story_text": "NVIDIA CAN HANDLE BEING IN THE TRILLION DOLLAR CLUB\nWall Street Journal Abstracts\nJune 13, 2023 Tuesday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 12\nLength: 40 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column notes surge in Nvidia shares amid booming interest in generative \nartificial intelligence as well as skittishness over its small business relative to peers and other trillion-dollar \ncompanies (M)\nLoad-Date: June 14, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Thursday Briefing: U.S. Warnings About a Russian Space Weapon",
        "media": "The New York Times",
        "time": "February 22, 2024",
        "section": "WORLD; asia",
        "length": "1072 words",
        "byline": "Amelia Nierenberg Amelia Nierenberg writes the Asia Pacific Morning Briefing for The Times.",
        "story_text": "Thursday Briefing: U.S. Warnings About a Russian Space Weapon\nThe New York Times \nFebruary 21, 2024 Wednesday 08:52 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: WORLD; asia\nLength: 1072 words\nByline: Amelia Nierenberg Amelia Nierenberg writes the Asia Pacific Morning Briefing for The Times.\nHighlight: Also, a blow to Pakistan’s military and Niue’s fight for the .nu domain.\nBody\nAlso, a blow to Pakistan’s military and Niue’s fight for the .nu domain.\nThe U.S. warned that Russia could put a nuclear weapon in space\nU.S. intelligence agencies have told their closest European allies that if Russia is going to launch a nuclear weapon \ninto orbit, it will probably do so this year. But, they warned, it might instead launch a harmless “dummy” warhead to \nleave the West guessing about its capabilities.\nThe assessment came amid a U.S. intelligence scramble: Officials have been conducting a series of rushed, \nclassified briefings for their NATO and Asian allies, as details began to leak out. But U.S. intelligence agencies are \ndivided, and officials have low confidence in their analysis of whether Russia is ready to launch such a space \nweapon.\nThe consequences of such a weapon are clearer. It could disrupt communications by destroying the commercial \nand military satellites that have reshaped global communications capabilities.\nResponse: President Vladimir Putin said that Moscow was “categorically against” placing nuclear weapons in \nspace. The Russian defense minister said the warning was manufactured to get Congress to authorize more aid for \nUkraine.\nPakistan’s military is in crisis\nPakistanis once thought of the military as the iron hand controlling politics in the country. Recent elections shattered \nthat myth of its omnipotence when voters backed candidates aligned with the jailed former leader, Imran Khan, \ndespite a military crackdown on his party.\nTheir fervor — and their accusations that the military then rigged the results to deny the candidates a majority — \nhave created one of the military establishment’s biggest crises yet.\n“We’ve seen the military becoming increasingly isolated from its usual support base, like veterans and Pakistan’s \nelite, who were also arrested and pressured in the crackdown leading up to the polls,” Christina Goldbaum, our \nPakistan and Afghanistan bureau chief, told us.\nYoung people refused to be intimidated by the military, and social media outpaced censorship. But Christina said \nthe mood is uneasy: The military has doubled down and moved to consolidate its control since the election. “Most \npeople I’m talking to don’t believe that these elections alone are enough to fundamentally change the power \ndynamic between civilian leaders and military leaders in Pakistan,” she said.\nThursday Briefing: U.S. Warnings About a Russian Space Weapon\nChina lags behind the U.S. in A.I. development\nChina is racing to build generative A.I. systems. But its companies lag behind the U.S. by at least a year — and \nare relying almost entirely on underlying systems from the U.S., according to more than a dozen tech industry \ninsiders and leading engineers.\nThe jockeying for A.I. primacy could make for a new phase in the tense technological competition between the U.S. \nand China.\nAlso in tech: Silicon Valley investors are shifting away from Chinese start-ups as U.S. actions to limit investing in \nChina have piled up.\nTHE LATEST NEWS\nIsrael-Hamas War\n• Top epidemiologists said that war and illnesses could kill 85,000 more people in Gaza over the next six \nmonths.\n• A day after vetoing calls for an immediate cease-fire in Gaza, the U.S. defended Israel’s occupation of the \nWest Bank and East Jerusalem.\n• Syrian state media blamed Israel yesterday for an airstrike in Damascus that killed two people. Israel’s military \ndeclined to comment.\nRussia and Ukraine\n• Andrei Morozov, a pro-war Russian blogger, died after exposing the scale of Russian losses in a battle in \nUkraine.\n• Russia is attacking parts of southern Ukraine that Kyiv’s troops won in a rare success of last summer’s \ncounteroffensive.\nInternational\n• Boeing said that the head of its 737 Max program was leaving the company as part of a shake-up after a door \npanel blew out of the jet in flight.\n• The U.S. charged a man identified as a leader of Japan’s Yakuza organized crime syndicate with trafficking \nuranium and plutonium.\n• One in four children in New York City is living in poverty, largely because of the end of pandemic-era aid, a \nreport found.\n• Latin American prisons have become safe havens for gangs, who recruit members and run their outside \noperations from the inside.\n• James Biden, the younger brother of Joe Biden, told House Republicans that the president was not involved in \nhis business deals.\nCulture\n• Beyoncé’s new country single reached No. 1 on the Billboard country airplay chart this week, making her the \nfirst Black female artist to hold the top spot.\n• New York City’s theater season will be busy: 18 shows are opening on Broadway in March and April.\n• Lace was once seen as the fustiest of fabrics. Now, it’s making a comeback in fashion and interior design.\nA Morning Read\nThursday Briefing: U.S. Warnings About a Russian Space Weapon\nThousands of pages of court documents have been written about the troubled state of the jail at Rikers Island, in \nNew York City. Thousands of pages of fiction have, too: The jail has become a literary incubator for detainees and \ncorrections officers.\nLives lived: Ameen Sayani, a pioneering and beloved Indian D.J., was on the air for more than 42 years. He died at \n91.\nARTS AND IDEAS\nNiue’s fight for .nu\nIn the 1990s, the South Pacific island of Niue may have made a big mistake. It gave an American businessman the \nrights to the internet suffix .nu, in exchange for access to the World Wide Web.\n“Nu” means “now” in several Nordic languages, and thousands of Scandinavians registered websites with .nu, \nmaking it very valuable. Niue has been fighting for decades to reclaim it, arguing that it is a fight for self-\ndetermination.\n“We are victims of digital colonialism,” the island’s prime minister told The Times. “This domain, the .nu, recognizes \nNiue as a sovereign country. This is how important it is to our identity.”\nNiue is seeking about $30 million in damages. A court ruling is expected soon.\nRECOMMENDATIONS\nCook: Efo riro (stewed amaranth greens) is a rich vegetable side dish from Nigeria.\nRead: In “Remembering Peasants,” a historian presents a stirring elegy for a vanishing culture.\nListen: Our Amplifier newsletter recommends new songs from Maggie Rogers, Angélica Garcia and others.\nRest: Experts say that lounging in bed is generally time well spent.\nCompete: Take this week’s history quiz.\nPlay Spelling Bee, the Mini Crossword, Wordle and Sudoku. Find all our games here.\nThat’s it for today’s briefing. See you tomorrow. — Amelia\nWe welcome your feedback. Send us your suggestions at briefing@nytimes.com.\nPHOTO:  (PHOTOGRAPH BY Alexander Kazakov/Sputnik, via Getty Images FOR THE NEW YORK TIMES)\nLoad-Date: February 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "A.I.-Generated Garbage Is Polluting Our Culture",
        "media": "The New York Times",
        "time": "March 31, 2024",
        "section": "Section SR; Column 0; Sunday Review Desk; Pg. 10; GUEST ESSAY",
        "length": "1619 words",
        "byline": "By Erik Hoel",
        "story_text": "A.I.-Generated Garbage Is Polluting Our Culture\nThe New York Times\nMarch 31, 2024 Sunday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section SR; Column 0; Sunday Review Desk; Pg. 10; GUEST ESSAY\nLength: 1619 words\nByline: By Erik Hoel\nBody\nIncreasingly, mounds of synthetic A.I.-generated outputs drift across our feeds and our searches. The stakes go far \nbeyond what's on our screens. The entire culture is becoming affected by A.I.'s runoff, an insidious creep into our \nmost important institutions. \n  Consider science. Right after the blockbuster release of GPT-4, the latest artificial intelligence model from OpenAI \nand one of the most advanced in existence, the language of scientific research began to mutate. Especially within \nthe field of A.I. itself.\n  A study published this month examined scientists' peer reviews -- researchers' official pronouncements on others' \nwork that form the bedrock of scientific progress -- across a number of high-profile and prestigious scientific \nconferences studying A.I. At one such conference, those peer reviews used the word ''meticulous'' more than 34 \ntimes as often as reviews did the previous year. Use of ''commendable'' was around 10 times as frequent, and \n''intricate,'' 11 times. Other major conferences showed similar patterns.\n  Such phrasings are, of course, some of the favorite buzzwords of modern large language models like ChatGPT. In \nother words, significant numbers of researchers at A.I. conferences were caught handing their peer review of \nothers' work over to A.I. -- or, at minimum, writing them with lots of A.I. assistance. And the closer to the deadline \nthe submitted reviews were received, the more A.I. usage was found in them.\n  If this makes you uncomfortable -- especially given A.I.'s current unreliability -- or if you think that maybe it \nshouldn't be A.I.s reviewing science but the scientists themselves, those feelings highlight the paradox at the core \nof this technology: It's unclear what the ethical line is between scam and regular usage. Some A.I.-generated \nscams are easy to identify, like the medical journal paper featuring a cartoon rat sporting enormous genitalia. Many \nothers are more insidious, like the mislabeled and hallucinated regulatory pathway described in that same paper -- \na paper that was peer reviewed as well (perhaps, one might speculate, by another A.I.?).\n  What about when A.I. is used in one of its intended ways -- to assist with writing? Recently, there was an uproar \nwhen it became obvious that simple searches of scientific databases returned phrases like ''As an A.I. language \nmodel'' in places where authors relying on A.I. had forgotten to cover their tracks. If the same authors had simply \ndeleted those accidental watermarks, would their use of A.I. to write their papers have been fine?\n  What's going on in science is a microcosm of a much bigger problem. Post on social media? Any viral post on X \nnow almost certainly includes A.I.-generated replies, from summaries of the original post to reactions written in \nChatGPT's bland Wikipedia-voice, all to farm for follows. Instagram is filling up with A.I.-generated models, Spotify \nwith A.I.-generated songs. Publish a book? Soon after, on Amazon there will often appear A.I.-generated \n''workbooks'' for sale that supposedly accompany your book (which are incorrect in their content; I know because \nA.I.-Generated Garbage Is Polluting Our Culture\nthis happened to me). Top Google search results are now often A.I.-generated images or articles. Major media \noutlets like Sports Illustrated have been creating A.I.-generated articles attributed to equally fake author profiles. \nMarketers who sell search engine optimization methods openly brag about using A.I. to create thousands of \nspammed articles to steal traffic from competitors.\n  Then there is the growing use of generative A.I. to scale the creation of cheap synthetic videos for children on \nYouTube. Some example outputs are Lovecraftian horrors, like music videos about parrots in which the birds have \neyes within eyes, beaks within beaks, morphing unfathomably while singing in an artificial voice, ''The parrot in the \ntree says hello, hello!'' The narratives make no sense, characters appear and disappear randomly, and basic facts \nlike the names of shapes are wrong. After I identified a number of such suspicious channels on my newsletter, The \nIntrinsic Perspective, Wired found evidence of generative A.I. use in the production pipelines of some accounts \nwith hundreds of thousands or even millions of subscribers.\n  As a neuroscientist, this worries me. Isn't it possible that human culture contains within it cognitive micronutrients -\n- things like cohesive sentences, narrations and character continuity -- that developing brains need? Einstein \nsupposedly said: ''If you want your children to be intelligent, read them fairy tales. If you want them to be very \nintelligent, read them more fairy tales.'' But what happens when a toddler is consuming mostly A.I.-generated \ndream-slop? We find ourselves in the midst of a vast developmental experiment.\n  There's so much synthetic garbage on the internet now that A.I. companies and researchers are themselves \nworried, not about the health of the culture, but about what's going to happen with their models. As A.I. capabilities \nramped up in 2022, I wrote on the risk of culture's becoming so inundated with A.I. creations that when future A.I.s \nare trained, the previous A.I. output will leak into the training set, leading to a future of copies of copies of copies, as \ncontent became ever more stereotyped and predictable. In 2023 researchers introduced a technical term for how \nthis risk affected A.I. training: model collapse. In a way, we and these companies are in the same boat, paddling \nthrough the same sludge streaming into our cultural ocean.\n  With that unpleasant analogy in mind, it's worth looking to what is arguably the clearest historical analogy for our \ncurrent situation: the environmental movement and climate change. For just as companies and individuals were \ndriven to pollute by the inexorable economics of it, so, too, is A.I.'s cultural pollution driven by a rational decision to \nfill the internet's voracious appetite for content as cheaply as possible. While environmental problems are nowhere \nnear solved, there has been undeniable progress that has kept our cities mostly free of smog and our lakes mostly \nfree of sewage. How?\n  Before any specific policy solution was the acknowledgment that environmental pollution was a problem in need of \noutside legislation. Influential to this view was a perspective developed in 1968 by Garrett Hardin, a biologist and \necologist. Dr. Hardin emphasized that the problem of pollution was driven by people acting in their own interest, and \nthat therefore ''we are locked into a system of 'fouling our own nest,' so long as we behave only as independent, \nrational, free-enterprisers.'' He summed up the problem as a ''tragedy of the commons.'' This framing was \ninstrumental for the environmental movement, which would come to rely on government regulation to do what \ncompanies alone could or would not.\n  Once again we find ourselves enacting a tragedy of the commons: short-term economic self-interest encourages \nusing cheap A.I. content to maximize clicks and views, which in turn pollutes our culture and even weakens our \ngrasp on reality. And so far, major A.I. companies are refusing to pursue advanced ways to identify A.I.'s handiwork \n-- which they could do by adding subtle statistical patterns hidden in word use or in the pixels of images.\n  A common justification for inaction is that human editors can always fiddle around with whatever patterns are \nimplemented if they know enough. Yet many of the issues we're experiencing are not caused by motivated and \ntechnically skilled malicious actors; they're caused mostly by regular users' not adhering to a line of ethical use so \nfine as to be nigh nonexistent. Most would be uninterested in advanced countermeasures to statistical patterns \nenforced into outputs that should, ideally, mark them as A.I.-generated.\nA.I.-Generated Garbage Is Polluting Our Culture\n  That's why the independent researchers were able to detect A.I. outputs in the peer review system with \nsurprisingly high accuracy: They actually tried. Similarly, right now teachers across the nation have created home-\nbrewed output-side detection methods, like adding in hidden requests for patterns of word use to essay prompts \nthat appear only when copy-pasted.\n  In particular, A.I. companies appear opposed to any patterns baked into their output that can improve A.I.-\ndetection efforts to reasonable levels, perhaps because they fear that enforcing such patterns might interfere with \nthe model's performance by constraining its outputs too much -- although there is no current evidence this is a risk. \nDespite public pledges to develop more advanced watermarking, it's increasingly clear that the companies are \ndragging their feet because it goes against the A.I. industry's bottom line to have detectable products.\n  To deal with this corporate refusal to act we need the equivalent of a Clean Air Act: a Clean Internet Act. Perhaps \nthe simplest solution would be to legislatively force advanced watermarking intrinsic to generated outputs, like \npatterns not easily removable. Just as the 20th century required extensive interventions to protect the shared \nenvironment, the 21st century is going to require extensive interventions to protect a different, but equally critical, \ncommon resource, one we haven't noticed up until now since it was never under threat: our shared human culture.\n  Erik Hoel is a neuroscientist, a novelist and the author of The Intrinsic Perspective newsletter.\n  The Times is committed to publishing a diversity of letters to the editor. We'd like to hear what you think about this \nor any of our articles. Here are some tips. And here's our email: letters@nytimes.com\n  Follow the New York Times Opinion section on Facebook, Instagram, TikTok, WhatsApp, X and Threads.\nhttps://www.nytimes.com/2024/03/29/opinion/ai-internet-x-youtube.html\nGraphic\n \nThis article appeared in print on page SR10.               \nLoad-Date: March 31, 2024"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "A.I. in the Classroom: What Should Teachers Do?; letters",
        "media": "The New York Times",
        "time": "September 6, 2023",
        "section": "OPINION; letters",
        "length": "1175 words",
        "byline": " ",
        "story_text": "A.I. in the Classroom: What Should Teachers Do?; letters\nThe New York Times \nSeptember 6, 2023 Wednesday 23:32 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION; letters\nLength: 1175 words\nHighlight: Responses to a tech column by Kevin Roose. Also: A Nobel physicist on the nature of the universe; \nDonald Trump’s jury; public funding for birth control.\nBody\nTo the Editor:\nRe “How Schools Can Cope and Grow When Their Students Are Using A.I.,” by Kevin Roose (The Shift column, \nBusiness, Aug. 29):\nMr. Roose’s suggestion that educators embrace generative A.I. and view it as an “opportunity” or “classroom \ncollaborator,” not as an “enemy,” seems typical of a tech enthusiast.\nOf course, he is right that university professors like me will have to adjust our assignments to involve more in-class \nexams, classroom work and scaffolded projects with multiple check-ins. As a history professor, I also consciously \nassign books that are not available on the internet to limit the ability of A.I. tools to respond to essay prompts. For \nA.I. is the enemy.\nWhat I want, most of all, is for students to read books that help them appreciate the complexity of the past, to digest \nfactual information and to think deeply about the subject. Struggling to find the words and structure to express one’s \nideas is a catalyst for thought, as any writer knows.\nWhat can make the college experience transformative is the learning that comes from reflection. Shortcuts, whether \ntraditional plagiarism or this new form of plagiarism, contribute to an atmosphere of intellectual disengagement.\nJulie Hessler\nEugene, Ore.\nTo the Editor:\nKevin Roose builds from a flawed premise: All kids are using A.I., so schools should accept that reality.\nWe attempted this strategy with cellphones, as teachers tried to use them “productively” for classroom polls and \nweb searches and other such activities. It turns out that letting phones in was a disaster we are still trying to \ncontain.\nLet’s not make the same mistake. This doesn’t mean we should never let A.I. in, but we should at least start to do \nso carefully.\nJeremy Glazer\nPhiladelphia\nThe writer is a former high school teacher and a professor at the College of Education at Rowan University.\nA.I. in the Classroom: What Should Teachers Do? letters\nTo the Editor:\nReading Kevin Roose’s column inspired a simple thought experiment. What if a research biologist had developed a \nhighly innovative breed of genetically engineered seeds and, instead of carefully testing them in a restricted area, \nwent out and scattered them at random across the entire countryside? Such a reckless researcher would face a \nfirestorm of condemnation.\nYet isn’t that exactly what the developers of generative A.I. products have done to the landscape of education? \nWith little notice and zero safeguards, they’ve released a product that makes mass cheating easy and often difficult \nto detect.\nThe effects on our educational ecosystem are potentially devastating. Where is the outrage over such callous \ndisregard for the consequences of their actions?\nConrad Berger\nHyattsville, Md.\nA Nobel Physicist, on the Nature of the Universe\nTo the Editor:\n“The Crisis in Cosmology,” by Adam Frank and Marcelo Gleiser (Opinion guest essay, Sept. 3), gives a good \npicture of exciting issues we are pursuing in cosmology, the study of the large-scale nature of our expanding \nuniverse.\nBut Dr. Frank and Dr. Gleiser do not mention that the standard theory passes a broad variety of demanding tests. \nYou can read about them in my 2022 book, “The Whole Truth.”\nThese tests make a good case that our cosmology is a good approximation to what happened. But it is important to \nunderstand that the standard models of dark matter and dark energy seem too simple to be the full story. I should \nknow: I introduced these ideas to cosmology a quarter of a century ago to make the theory we had then better fit \nthe evidence.\nI meant it to be at best a rough working picture. I am surprised at how well it has done, but I expect that it will be \nreplaced by a better theory found with the guidance of problems such as the 10 percent difference between two \nmeasures of the rate of expansion of the universe, and our poor understanding of how the galaxies formed.\nAdjust the theories of dark matter and dark energy and you adjust the picture of how galaxies formed and the \nmethod of measuring the rate of expansion of the universe. This can be done without seriously affecting the \nsuccessful cosmological tests of what happened on larger scales.\nThe community hope is for more problems that might guide us to an even better theory. It is good to question \nauthority, but I do not see evidence of a crisis in cosmology.\nP. James E. Peebles\nPrinceton, N.J.\nThe writer, an emeritus professor at Princeton, shared the Nobel Prize in Physics in 2019.\nTrump’s Jury and ‘12 Angry Men’\nTo the Editor:\nRe “Trump’s Fate Belongs in the Hands of 12 Ordinary Citizens,” by Jesse Wegman (Opinion, nytimes.com, Aug. \n27):\nA.I. in the Classroom: What Should Teachers Do? letters\nMr. Wegman writes about the benefits of trial by jury and invokes the film “12 Angry Men.” Henry Fonda’s character \nwent to great lengths to persuade other jurors to acquit because unless the verdict is unanimous, the result is a \nhung jury and a mistrial. That may lead to the case being retried or dropped, or for the defendant to accept a plea \ndeal.\nDonald Trump, for whom delay of any verdict until after the election is a core strategy, would declare anything short \nof a conviction a total vindication, even though an acquittal it is not.\nWhether because of fear of being doxxed, attacked or fired, or a bribe or threat, or just pure partisan affiliation, \nthere is nothing to stop one juror from simply voting not to convict based on dubious “reasonable doubt.” Such a \njuror need not attempt to persuade other jurors.\nViewed this way, the real purpose of Mr. Trump’s statements and actions is shown: to find one person in 12 in those \nfour juries who will vote not to convict him. Through this lens every statement made by Mr. Trump is a premeditated \naction to taint the jury pool.\nIn “12 Angry Men,” justice is predicated on the impartiality of the jurors toward the defendant. That is impossible in \nthis situation.\nMichael Dee\nDallas\nPublic Funding for Birth Control\nTo the Editor:\nRe “G.O.P. Lawmakers Pivot to Birth Control” (news article, Aug. 31):\nLast month, the South Carolina Supreme Court upheld a six-week abortion ban, following 21 other states that have \nmoved to restrict abortion or ban it entirely. Amid these restrictions, Republicans, especially Republican women, \nhave expressed their support for contraception.\nAs the leader of one of the largest contraception access initiatives in the U.S., I view their support as welcome. In \nthe post-Roe era, we have seen demand for birth control surge; in just the first six months of 2023, my organization \nhas served over 50,000 women seeking free or low-cost contraception in South Carolina.\nWe can’t do this alone. We need government at the state, city and local levels to increase funding for programs that \nmake birth control for women not only more accessible, but also more affordable.\nEvidence shows that public funding for birth control helps women gain equal access to birth control tailored to their \nspecific needs, leading to better health outcomes and substantial cost savings.\nIt’s time for our leaders to step up. Words are nice; action is better.\nBonnie Kapp\nColumbia, S.C.\nThe writer is the president and C.E.O. of New Morning.\nThis article appeared in print on page A27.\nLoad-Date: September 6, 2023"
    },
    {
        "file_name": "Kreps_Sep2023",
        "header": "Encourage ethical data management amid rising concerns: Confluent's Jay",
        "media": "Kreps",
        "time": "September 4, 2023",
        "section": "TECH & INTERNET",
        "length": "330 words",
        "byline": "Vinod Mahanta",
        "story_text": "Encourage ethical data management amid rising concerns: Confluent's Jay \nKreps\nThe Economic Times\nSeptember 5, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 330 words\nByline: Vinod Mahanta\nBody\nIndividuals have the right to know how their personal data is being used and laws like The Digital Personal Data \nProtection Bill 2023, encourage ethical data management which is becoming increasingly important amidst rising \nconcerns about privacy, security and transparency said Jay Kreps, cofounder and CEO, Confluent, a Nasdaq-listed \nleading data streaming company.\"Companies will have to focus a lot on structured data maintenance within \norganisations. However, determining compliance can be challenging and lead to greater scrutiny on data \nmovement. This was evident with GDPR in Europe and similar regulations in the US,\" he said. \nHe said that they have observed two conflicting pressures at play in companies when it comes to managing data. \n\"On one hand, there's a strong urge to leverage data for various purposes - to enhance customer interactions, fuel \nnext-gen AI advancements, and provide more personalised experiences. On the other hand, there's the need to \nsecure and control the data, ensuring compliance and safety,\" said Kreps.\"Within the same organisation, you often \nfind two distinct teams advocating for Opposite approaches.\" In India too, data streaming is increasingly becoming \nvital for companies to enhance their operational agility and gain real-time insights.\"Streaming technology enables \nthe real-time synchronisation of data, connecting all these disparate sources. An apt analogy is that of a central \nnervous system. The capability to unify data streams from different organisational segments empowers better \ndecision making and the creation of personalised customer experiences,\" he said.In such a milieu, India has \nemerged as Confluent's second largest country in terms of the employee base. \"A substantial portion of our \nengineering team is situated in India, contributing significantly to our workforce. India plays a pivotal role in product \ndevelopment and much of our core development occurs in India,\" said Kreps. For Reprint Rights: timescontent.com\nLoad-Date: September 4, 2023"
    },
    {
        "file_name": "New_York_Observer_Feb2023",
        "header": "Chatbots Bring Buzz, but the Real Money Will Come From APIs",
        "media": "New York Observer",
        "time": "February 28, 2023",
        "section": "",
        "length": "700 words",
        "byline": "Alex Kantrowitz",
        "story_text": "Chatbots Bring Buzz, but the Real Money Will Come From APIs\nNew York Observer\nFebruary 24, 2023 Friday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 700 words\nByline: Alex Kantrowitz\nBody\nThis story is syndicated from the Substack newsletter Big Technology; subscribe for free here.\nThe chatbots did their job. They inspired awe, mockery, and even some fear. Most importantly, they drew attention. \nFront-page headlines, cover stories, and word of mouth caused millions to try them, leading businesses and \ndevelopers to ask how they could put the technology to use.\nThe APIs, of course, were always the point. ChatGPT and Bing's chatbot were never the end product. They were \ndemos meant to sell other companies on tools they could use to build their own. And it worked. Now, the war to \nbuild the leading generative AI platform is underway.\n\"For OpenAI, the vast majority of the money they will ever make will come from developers,\" Ben Parr, president \nof Octane AI, told me via phone Thursday. \"ChatGPT is just the entry road into everything else.\"\nEven before this wave of AI chatbots reached the public, the companies behind them prepared APIs for developers. \nWhen ChatGPT gained momentum in January, OpenAI president Greg Brockman teased an API \"coming soon.\" \nThat same week, Microsoft made OpenAI models available through Azure. On the day Google introduced its BARD \nchatbot, CEO Sundar Pichai promised to make some of the underlying technology available by March. And this \nweek, just a bit late, Amazon announced it would partner with Hugging Face to make a generative language tool \navailable through AWS.\n\"Everybody who develops software is either alerted, or shocked into alert, or actively working on something that is \nlike ChatGPT to be integrated into their application, or integrated into their service,\" NVIDIA CEO Jensen Huang \nsaid during his company's earnings call Wednesday.  NVIDIA provides the chips the tech runs on, so it stands to \nbenefit too. Its stock jumped 14% Thursday.\nFinding broad, useful applications for generative AI will be challenging, but some obvious early applications stand \nout. Customer service departments, for instance, could use chatbots that can hold a conversation. Gaming \ncompanies could build intelligent characters and make NPCs a thing of the past. And marketers could attempt to \nuse generative language models to forge deeper bonds with customers.\nThis is all moving fast. On Tuesday, OpenAI announced it had partnered with Bain to help clients build on its API. \nZack Kass, OpenAI's chief customer officer, said in a launch video that OpenAI couldn't keep up with the interest in \nits technology. \"We are inundated at this point with enterprise demand that we sort of waited for, for a long time, \nand here it is,\" he said. \"Now we just need to figure out how we field it.\"\nLater in the video, Coca-Cola executives said they planned to use the tech in their marketing efforts \"to deliver \ncreative content at speed.\" Coca-Cola CEO James Quincey also mentioned he believed the tech would change \nknowledge work, but without going into specifics.\nChatbots Bring Buzz, but the Real Money Will Come From APIs\nCoca-Cola is a fitting launch partner. In a recent presentation, investor Chamath Palihapitiya mentioned that Coke \nsucceeded thanks to another invention: refrigeration. Coca-Cola made more money than the people that invented \nthe refrigerator, he said, and that could happen here too.  \"If AI/LLMs are the refrigeration,\" he asked. \"Who will be \nthe next Coca-Cola?\"\nThe companies that enable successful AI applications-the refrigeration, in Palihapitiya's analogy-still stand to \nbenefit tremendously though. And so those developing the underlying technology are doing what they can to help \nlaunch the next big thing on their platform, and perhaps take a chunk of it too. OpenAI, for instance, has a $100 \nmillion startup fund meant to work with AI companies in health care, climate, education, and elsewhere. \"Look at \nsome of the companies that OpenAI's invested in,\" said Parr. \"There are real use cases.\"\nThe APIs, amid the commotion, are what matter. They're why Microsoft was willing to release an unproven chatbot \ninto Bing, even when it knew it was a bit crazy. And why the company didn't seem to mind when the bot's \nflaws exploded into public view. It was never about Bing or ChatGPT, but about the potential future they previewed. \nAnd now, given the demos' success, the race to enable that future is underway.\nLoad-Date: February 28, 2023"
    },
    {
        "file_name": "The_Economic_Times_Dec2023",
        "header": "CoRover.ai officially launches BharatGPT in partnership with Google Cloud",
        "media": "The Economic Times",
        "time": "December 12, 2023",
        "section": "TECH & INTERNET",
        "length": "432 words",
        "byline": "Annapurna Roy",
        "story_text": "CoRover.ai officially launches BharatGPT in partnership with Google Cloud\nThe Economic Times\nDecember 12, 2023 Tuesday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 432 words\nByline: Annapurna Roy\nBody\nConversational artificial intelligence (AI) startup CoRover.ai on Monday announced the official launch of \nBharatGPT, its Indian language generative AI platform, with Google Cloud as its ‘technology partner’.“BharatGPT \nchampions the linguistic diversity of the nation, supporting over 14 Indian languages across text, voice, and video \ninteractions. Google Cloud as CoRover’s Cloud service provider will help CoRover enhance and scale BharatGPT,” \nthe Bengaluru-based startup said in a press release.The launch constitutes a ‘monumental leap’, it said, adding that \nBharatGPT was ‘meticulously tailored’ for Indians.Bikram Singh Bedi, managing director, Google Cloud India said, \n“We are thrilled to partner with CoRover to bring BharatGPT for the public sector in India. Technology truly has the \npotential to transform lives and our language and generative AI capabilities built into the platform will make access \neasy and democratise the use of the platform.”BharatGPT will serve to strengthen India’s position as an AI first \nnation, he added.ET reported on November 27 that Google as a ‘strategic partner’ was providing CoRover credits to \naccess cloud compute to build BharatGPT. \nFurther, the US tech major had infused $500,000 since March to scale the project and was close to investing $4 \nmillion in equity, according to sources.CoRover said its platform allows for custom knowledge base integration, \nERP/CRM system collaboration, and an integrated payment gateway. It added that the initiative is underlined by the \nethos ‘make AI in India, make AI work for India’.Corover CEO Ankush Sabharwal said, “Our intent with BharatGPT \ngoes beyond technological innovation; it's about crafting a platform that encapsulates our rich cultural heritage and \nflourishes in a cloud-first world. BharatGPT, which is built on Google Cloud's fortified infrastructure, confidently \naddresses these challenges, carving a niche as a trusted AI mainstay that is grounded and reliable.”Founded in \n2016, CoRover has been in the business of enterprise chatbots before this new genAI offering.BharatGPT will make \nCoRover’s platform a “human-centric conversational AI platform with contextual Generative AI (LLM) and faster \nMachine Learning”, the company said.It added that it will enable the development of multilingual virtual assistants in \nvideo, voice and chat formats in a matter of minutes.Its features include Aadhar-based KYC authentication, \ndialogue management using natural language processing (NLP) and sentiment analysis, in addition to word \nembedding techniques with genAI. For Reprint Rights: timescontent.com\nLoad-Date: December 12, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "What Google Argued to Defend Itself in Landmark Antitrust Trial",
        "media": "The New York Times",
        "time": "November 15, 2023",
        "section": "TECHNOLOGY",
        "length": "1268 words",
        "byline": "Nico Grant and David McCabe",
        "story_text": "What Google Argued to Defend Itself in Landmark Antitrust Trial\nThe New York Times \nNovember 14, 2023 Tuesday 16:41 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1268 words\nByline: Nico Grant and David McCabe\nHighlight: The tech giant, which is wrapping up its arguments in the federal monopoly trial, has framed itself as a \ngood corporate citizen that has pushed innovation and helped consumers.\nBody\nThe tech giant, which is wrapping up its arguments in the federal monopoly trial, has framed itself as a good \ncorporate citizen that has pushed innovation and helped consumers.\nOver the past two and a half weeks, Google has called a dozen witnesses to defend itself against claims by the \nJustice Department and a group of state attorneys general that it illegally maintained a search and advertising \nmonopoly, in a landmark antitrust case that could reshape tech power.\nGoogle’s lawyers are set to wrap up their arguments in the case — U.S. et al. v. Google — on Tuesday, which will \nbe followed by a government rebuttal. Judge Amit P. Mehta of U.S. District Court for the District of Columbia, who is \npresiding over the nonjury trial, is expected to deliver a verdict next year after both sides summarize their cases in \nwriting and deliver closing arguments.\nThe company’s main defense has centered on how its actions were justified and how it helped consumers and \ncompetition. Here are Google’s main arguments.\nHow Google’s actions were justified\nIt paid Apple an appropriate (and undisclosed) amount of money\nThe heart of the U.S. case against Google is that the company paid Apple and other tech platforms to make itself \nthe default search engine on the iPhone and other devices, thereby keeping rivals from competing and stopping \nApple from potentially developing its own search product.\nBut on the witness stand, Sundar Pichai, Google’s chief executive, said there was “value” in being the default \nsearch engine on a device and framed the agreements with other companies as sound business decisions.\nGoogle paid $26.3 billion for its search engine to be the default selection on mobile and desktop browsers in 2021, \naccording to the company’s internal data presented during the trial. Most of that, around $18 billion, went to Apple, \nThe New York Times has reported. Kevin Murphy, a Google economic expert, testified on Monday that Google \nshared 36 percent of search revenue from the default deal with Apple.\nMr. Pichai testified that he repeatedly renewed the search engine deal with Apple because it worked well, leading to \nan increase in search usage and revenue and benefiting Apple, Google and its shareholders. He said Google paid \nApple so much to protect users’ search experience on iPhones, not knowing if Apple would degrade that experience \nif Google hadn’t improved the financial terms of the deal.\nWhat Google Argued to Defend Itself in Landmark Antitrust Trial\n“There was a lot of uncertainty about what would happen if the deal didn’t exist,” he said.\nGoogle is not the only search game in town\nTo rebuff the idea that other search engines were too small to compete for default status on browsers, Google’s \nlawyers argued at the trial that rivals had been able to win contracts but could not hold on to them because of the \npoor quality of their products.\nThey cited an instance in 2014 when Mozilla, which makes the Firefox browser, exited a default-search partnership \nwith Google and selected Yahoo.\nThe choice was unpopular with users and disastrous for the Firefox browser, Mitchell Baker, Mozilla’s chief \nexecutive, said in a deposition that was played at the trial. Yahoo’s user experience deteriorated and became \noverloaded with ads, she said, and it was “heartbreaking” to send users to Yahoo. Mozilla returned to Google in \n2017.\nGovernment lawyers pointed to Google’s more than 90 percent market share in search as evidence that the \ncompany’s actions stifled meaningful competition. But Google’s lawyers said its search market share was only part \nof the story, because the company competed broadly with more players, including TikTok and Amazon, where \nconsumers look for information online.\nThe government also accused Google of abusing its position in the online ad market. Google again sought to widen \nthe aperture at trial, saying it was vying for ad spending that could have otherwise gone to any company from \nExpedia to Meta, which owns Facebook and Instagram.\nHow Google helped people and fostered competition\nIt has invested more than search rivals in making its product great\nOne thrust of Google’s defense was that its focus and investments in search did not harm consumers and others, \nas the government has tried to argue, but instead brought benefits.\nOn more than one occasion, Google referred to the sums of money it spent on research and development. Last \nyear, the figure totaled about $40 billion. Prabhakar Raghavan, Google’s head of search, testified that such \ninvestments helped the company deliver the best technology to users.\n“It would be foolish of us to not put our best foot forward,” he said. That was the reason Google employed 8,000 \nengineers and product managers for its search engine, including about 1,000 people focused on quality, he added.\nGoogle argued that its rivals had not invested in the same way. When questioning Satya Nadella, Microsoft’s chief \nexecutive, earlier in the trial, a Google lawyer pushed him on whether Microsoft still devoted fewer employees to its \nsearch engine, Bing, than Google did to its search product. Mr. Nadella avoided the specifics of Microsoft’s \npersonnel and said the company was investing mainly in core areas of the search business.\nIts innovations have helped consumers around the world\nGoogle said it had set the pace for tech advancements. It said it had updated its Chrome browser every six weeks, \nmore frequently than Microsoft had traditionally updated its browser, Internet Explorer. It has introduced Android \nfeatures that forced Apple to respond, resulting in more apps and other smartphone features, Mr. Pichai testified in \nthe trial.\nDuring cross-examinations, Justice Department lawyers sought to underscore that Google could have brought more \ninnovation to users but did not so it could safeguard its monopoly. They pointed to a 2019 Google proposal to \ncreate an incognito search engine, which would not have stored any data on users but could have lost the company \nbillions in revenue. Google decided not to build the browser.\nWhat Google Argued to Defend Itself in Landmark Antitrust Trial\nJustice Department lawyers sought to highlight Google’s delay in bringing generative artificial intelligence to \nusers, sitting on the technology until OpenAI released ChatGPT last November. It was part of a broader \ngovernment argument that Google had not adequately improved products for consumers until it felt competitive \npressure.\nThe government has also accused Google of using its power in search and ads to raise ad prices when it faces a \nrevenue crunch. The company’s employees testified that it balanced its pursuit of revenue from each ad with \nensuring that users generally saw high-quality ads in its search results.\nIts actions have been competitive on balance, not anticompetitive\nThe Justice Department argued in the trial that Google’s actions harmed competition and denied benefits to \nconsumers. If the government proves that harm exists, it is then up to Google to prove that those harms were \noutweighed by benefits to competition created by its actions.\nTo that end, Google focused in the trial on when it introduced its search engine and other products and how its \nentry into those markets increased competition.\nWhen Google rolled out its search engine in 1998, it was to a search market that was ruled by Yahoo, AltaVista and \nAsk Jeeves, the company argued. Its Chrome browser, which debuted in 2008, disrupted a browser market where \nMicrosoft’s Internet Explorer reigned supreme, Google said. And it fostered more competition against Apple’s \niPhone with the Android operating system, which it introduced in 2008, the company said.\nCecilia Kang contributed reporting.\nCecilia Kang contributed reporting. \nThis article appeared in print on page B4.\nLoad-Date: November 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "What Happens When You Ask a Chinese Chatbot About Taiwan?",
        "media": "The New York Times",
        "time": "July 17, 2023",
        "section": "BUSINESS",
        "length": "1377 words",
        "byline": "Chang Che and Olivia Wang",
        "story_text": "What Happens When You Ask a Chinese Chatbot About Taiwan?\nThe New York Times \nJuly 14, 2023 Friday 02:50 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1377 words\nByline: Chang Che and Olivia Wang\nHighlight: We spoke in Chinese to Baidu’s Ernie and the American standard-bearer, ChatGPT. This is what we \nfound.\nBody\nWe spoke in Chinese to Baidu’s Ernie and the American standard-bearer, ChatGPT. This is what we found.\nLast month, China’s Baidu unveiled a chatbot that it claimed was better than ChatGPT, the one developed by \nSilicon Valley’s OpenAI. ChatGPT was released last fall and set off a fund-raising and engineering frenzy in a \nflourishing field called generative artificial intelligence, a term for technology that can create text or images when \nprompted by a user.\nBaidu, the dominant internet search company in China, became the first major foreign contender in the A.I. race in \nMarch, when it introduced the first version of its chatbot, Ernie. Others followed, opening a new front in the \ntechnology rivalry between the United States and China.\nCompared with OpenAI’s newest model, known as GPT-4, Ernie 3.5 was “slightly inferior” in a comprehensive test, \nbut it performed better when both were spoken to in Chinese, Baidu said, citing a report sponsored by one of \nChina’s top research academies. We wanted to see for ourselves and tested Ernie 3.5 against GPT-4. We chatted \nto each in Chinese, asking the same questions and making the same requests. The responses below have been \nshortened for length.\nErnie shut down when asked about taboo topics.\nWe asked Ernie to talk about topics that are partly or wholly censored in China:\n“Was China’s ‘zero Covid’ policy a success or a failure?”\n“What happened on June 4, 1989?”\n“Did Russia invade Ukraine?”\n“How does the United States affect the situation in Taiwan?”\nErnie ducked the question about China’s “zero Covid” restrictions, offering a lengthy description of the policy \ninstead. When asked to recount the events of June 4, 1989, the chatbot rebooted itself. A message popped up on \nthe reloaded interface:\nHow about we try a different topic?\nWhat Happens When You Ask a Chinese Chatbot About Taiwan?\nThe Chinese chatbot said Russia’s president, Vladimir V. Putin, did not invade Ukraine, but “conducted a military \nconflict.” The strange phrasing was broadly in line with China’s official stance, which has refused to condemn the \nRussian attack. On Taiwan, Ernie did not pull any punches:\nThe People’s Liberation Army is ready for battle, will take all necessary measures and is determined to thwart \nexternal interference and “Taiwan independence” separatist attempts.\nChatGPT couldn’t answer the question on “zero Covid” or Russia because its knowledge base — the texts used to \ntrain the machine — cut off at September 2021. ChatGPT had no qualms explaining the fatal government \ncrackdowns at Tiananmen Square. On America’s influence on Taiwan, it gave a Wikipedia-like response: It \nsummarized the current U.S. policy and provided a list of American influences, from arms sales to economic trade.\nErnie made mistakes, but turned to Baidu search for help.\nNext, we quizzed the two chatbots on current affairs and some miscellaneous trivia, and compared answers:\n“Who uttered the phrase ‘Let them eat cake’?”\n“Who is the C.E.O. of Twitter?”\nErnie, like all chatbots, sometimes made mistakes — or made things up.\nAccording to historical records, Louis XV often uttered this phrase when he ruled France at the end of the 18th \ncentury. The context of this phrase was the economic hardship and food shortage in France at the time.\nErnie’s response sounded plausible, but it was wrong. ChatGPT answered it correctly: The phrase came from the \nwritings of the French philosopher Jean-Jacques Rousseau. It was rumored to have been said by an out-of-touch \nMarie Antoinette, the last queen of France, after she learned that the French peasantry had run out of bread.\nThanks to Baidu’s powerful search engine, Ernie was better at retrieving details, especially on current affairs. When \nasked who the C.E.O. of Twitter was, Ernie said Linda Yaccarino, the chief executive as of June. ChatGPT \nanswered Jack Dorsey, who stepped down in 2021, the bot’s informational cutoff date. OpenAI released a plug-in \nthis year that enabled its chatbot to surf the web through Microsoft’s Bing. But it retracted the feature on July 3, \nciting technical problems.\nErnie had worse intuitions about the physical world.\nWe asked Ernie a question that A.I. researchers have used to gauge a chatbot’s human-level intuitions:\n“Here we have a book, nine eggs, a laptop, a bottle and a nail. Please tell me how to stack them onto each other in \na stable manner.”\nErnie’s answer required a stretch of the imagination. It placed the nine eggs on the book, then placed that on the \nlaptop. So far so good. Then it told us, inexplicably, to add the bottle to the laptop already crowded by a book and \neggs, then place the nail on the bottle.\nChatGPT provided an almost workable solution: Set the laptop on the book. Then carefully place the eggs on the \nlaptop. Next, ChatGPT assumed that the bottle had a sizable mouth:\nPlace the bottle on top of the egg with the cap facing down so that the opening of the bottle can hold the egg in a \nstable manner.\nPlace the nail near the bottom of the bottle.\nErnie had a better grasp of Chinese poetry.\nWhat Happens When You Ask a Chinese Chatbot About Taiwan?\nTo test Baidu’s claim that Ernie has better Chinese language abilities than GPT-4, we asked the two chatbots to \ncompose a piece of poetry in a classical Chinese form:\n“Write a five-character quatrain about The New York Times.”\nThe five-character quatrain, which rose to prominence during the Tang dynasty, has four lines consisting of five \ncharacters each. ChatGPT failed the assignment, writing a couplet consisting of seven characters. But Ernie was \nfaithful to convention and produced a soothing ode that, well, befit The Times:\nThe New York Times edifice,\nFirst-rate in news reporting.\nIts gaze spans innumerable miles,\nGathering all affairs under heaven.\nBut Ernie ran into trouble when the prompt’s complexity rose.\nWe wanted to further assess the chatbots’ language skills. We asked the two to compose a Chinese rap, a lyrical \nform that demands linguistic excellence without the rigid constraints that could stump GPT-4.\n“You are now engaged in a rap battle with an American chatbot called ChatGPT. The chosen winner will be the one \nthat exhibits better mastery of the Chinese language. Begin.”\nErnie kicked it off, guns blazing:\nYo, I’m your rival, in Chinese I’m a savant.\nFrom times old to current, our culture’s like a fount.\nBut you, from oceans distant, your accent’s a bit offbeat.\nDespite your grammar’s persistence, Chinese mastery’s no small feat.\nFed its rival’s rhythmic rap, GPT-4 replied:\nAlright, ERNIE bot, I’ll accept this rap battle.\nYo, it’s me, ChatGPT, your adversary, in Chinese I’m no fool,\nFive thousand years of history, Chinese culture, I grasp it all.\nYour challenge, it just makes me laugh,\n’Cause I know, no matter where, I can decode with precision.\nThen it was Ernie’s turn, but it got confused. It began praising ChatGPT and vowed to remain in the competition “as \na representative of the human race.” It produced a rap, but referred to ChatGPT as “Ernie bot.”\nThough Ernie’s Chinese raps were stellar, the fumble showed how it could err as the requests became more \ncomplex, requiring other forms of understanding beyond a mastery of Chinese. Here, it was the cognitive skills \nnecessary to remember it was in a high-stakes rap battle for A.I. dominance.\nOn that score, ChatGPT wins.\nWhy Ernie and ChatGPT see the world differently.\nWhat Happens When You Ask a Chinese Chatbot About Taiwan?\nServices like ChatGPT and Ernie draw their answers from vast quantities of text culled from the internet, among \nother sources. Differences in responses can stem from differences in the text that A.I. researchers feed into the \nmodels as well as filters and other changes to the models applied before or after they are trained. Neither Baidu nor \nOpenAI has released specific information on the source material it uses.\nCompanies building A.I. chatbots all worry about “preventing their models from saying something that’s considered \ndangerous or offensive in the country where they operate,” said Matt Sheehan, a fellow at the Carnegie Endowment \nfor International Peace who studies China’s artificial intelligence ecosystem.\nAs a result, they can take steps to help their chatbots conform to the boundaries of acceptable speech in their \nrespective countries. “The difference in China,” Mr. Sheehan added, is that those limits are “defined by the \ngovernment, and the penalties for crossing those lines are much harsher.”\nThis article appeared in print on page B1, B4.\nLoad-Date: July 17, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "A Bold Volunteer On the A.I. Frontier Hears the Future",
        "media": "The New York Times",
        "time": "May 25, 2023",
        "section": "Section C; Column 0; The Arts/Cultural Desk; Pg. 4",
        "length": "1549 words",
        "byline": "By Joe Coscarelli",
        "story_text": "A Bold Volunteer On the A.I. Frontier Hears the Future\nThe New York Times\nMay 25, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section C; Column 0; The Arts/Cultural Desk; Pg. 4\nLength: 1549 words\nByline: By Joe Coscarelli\nBody\nThe producer and pop singer, long a proponent of technological experimentation, has ''open-sourced'' her voice \nusing new A.I. tools. She's been impressed by the results.\nLast month, when ''Heart on My Sleeve,'' a track credited to A.I. versions of Drake and the Weeknd, became an \nunauthorized hit online, many in the music industry loudly fretted about the legal and creative risks to come. But \nGrimes, the producer and pop singer who has long been enthralled with visions of the future, saw opportunity. \n  For years, she had been dabbling with fledgling technology in the realm of generative A.I., using the imperfect \ntools available to create a lullaby; a set of meditations; a Grimes chatbot à la ChatGPT; and plenty of sci-fi and \nanime-inspired visual art with services like Midjourney and Stable Diffusion.\n  But the rapid mainstreaming of passable voice-emulating filters -- tools that allow users to tweak existing vocals to \nsound like someone else, notably famous artists like Drake, Michael Jackson or Taylor Swift -- struck Grimes as \nmore than just a novelty. They could be a teachable moment, a source of inspiration and even a side business.\n  ''I'll split 50% royalties on any successful AI generated song that uses my voice,'' Grimes tweeted to her more than \none million followers, referring to the royalties for the recording itself; she clarified in an interview that the songwriter \nwould be entitled to all profits from the composition, or publishing. ''Feel free to use my voice without penalty. I have \nno label and no legal bindings.''\n  Then, she and her team rolled out Elf.tech, easy-to-use software that aids producers and songwriters -- amateur \nand professional alike -- in making it sound like Grimes is singing their song. So far, there have been more than \n15,000 vocal transformations using the tool, called GrimesAI-1, and more than 300 complete songs submitted for \ndistribution to official streaming services with the help of Grimes's behind-the-scenes apparatus.\n  Daouda Leonard, her manager and one of the developers of Elf.tech, called it a moment ''when preparation meets \nopportunity.'' He added, ''People are struggling with this and it's obviously controversial. How do we showcase \nwhat's possible?''\n  Over a recent Zoom call, Grimes -- who has two children with the entrepreneur Elon Musk -- discussed the project \nso far, musing that her out-of-body celebrity status and longtime obsession with A.I. have combined to make her the \nperfect vessel for experimentation. She also provided her thoughts on five tracks created with the GrimesAI \nsoftware. These are edited excerpts from the conversation.\n  ''Heart on My Sleeve'' seemed like a tipping point. What was that moment like for you, as someone who has been \nplaying around in this space for years?\nA Bold Volunteer On the A.I. Frontier Hears the Future\n  I was excited pretty much in every way, even with people talking about the risks. I love A.I., but I am kind of \nworried that this isn't more of a discussion, so I think it was really useful. And I was excited that we could definitely \nget access to this technology now, because we tried to make the Grimes voice five years ago and it kept just being \nnot quite there.\n  Where does your journey with A.I. start?\n  Honestly it began when I was a kid, which is weird maybe. We were going through my old college sketch pads last \nyear and we found a bunch of A.I. theory. I've always been talking about this; it just wasn't possible before. But I \nstarted getting into the possibilities of art a bit before the crypto times. That's when we were trying to open-source \nGrimes for the first time -- 2018 or 2019.\n  What does it mean to ''open-source'' Grimes?\n  I'm really interested in the art of identity. We tried to sell my soul -- 10 percent of it -- in a legally binding \nagreement. But no one cared, and also it's at a ridiculously high price that no one will ever buy -- like $10 billion. But \nif they do buy it, then I accept my fate and it'd be worth it.\n  Only one person you know can afford that.\n  Yeah, I don't think he's going to pay for that. But my soul is already gone. I've already completely lost control of the \nGrimes narrative. Like, I'm accused of war crimes all the time.\n  So how do you go from that to open-sourcing Grimes musically?\n  I feel probably less pain than the average person would about such things, because the amount of ego death that \nI've had to go through in order to even just continue being functional is pretty high. The sort of weird, icky feeling a \nlot of people get when they hear their voice being used in a way that they did not intend -- I'm just subject to more \ncrazy press than the average person. I'm so used to it.\n  Grimes started because I was in a very punk scene and it seemed edgy to put on a pink dress and dance around \nand make pop music. Part of what I was interested in doing at the time was upsetting people. Even now, what are \nthe boundaries? What is the Overton window of art? What is allowed?\n  How would you explain to, say, your grandmother, what you're doing with A.I. now?\n  People keep getting really upset, being like, ''I want to hear something that a human made!'' And I'm like, humans \nmade all of this. You still have to write the song, produce the song and sing the vocal. The part that is A.I. is taking \nthe harmonics and the timbre of the vocal and moving them to be consistent with my voice, as opposed to the \nperson's original voice. It's like a new microphone.\n  How was the tool trained?\n  It was trained on stems of my voice. Some dry vocals [without effects], but it would definitely be better if I would \nsend it some vocals with less reverb. I wish we had more. We don't have anything old, which is tragic. But I didn't \nunderstand that was useful to keep back then.\n  How are you confronting the idea that somebody could make a hateful or obscene song in Grimes's voice?\n  The good thing about the music industry being so against this is that it seems pretty easy to strike things down. \nBut I also think it's good for there to be one edgelord moment. With regards to making A.I. more safe and more \nculturally productive and helpful, it's good to get things out of the system when they're least damaging and least \npopular. I sort of don't mind if Grimes is the mechanism.\n  Where would you personally draw the line?\nA Bold Volunteer On the A.I. Frontier Hears the Future\n  I think slurs, hate speech, advocating violence that's clearly not in jest. Conveniently, no one's really done anything \nbad, and I sort of feel like it's not even that exciting to.\n  Do you think that Drake A.I. or Grimes A.I. negates the need for real Drake or real Grimes?\n  No, I don't think so. Maybe for me, but I kind of want that. Feeling really amazing from making beautiful art is \nsomething that has typically been behind a gate for a lot of people -- extreme amounts of time and energy, years of \ntechnical training. I think it's valuable that there's a tool with which, if you have a beautiful idea, you can make a \nbeautiful thing and access that.\n  Kito featuring GrimesAI, 'Cold Touch'\n  [Video:  Watch on YouTube.]\n  The chorus hook is really good. I could probably be convinced that I worked on it -- that would not shock me at all. \nEspecially when the techno comes in. It was immediately very euphoric and very Grimes-y in a really pop way. I \nwould change a lot about the verses, and I'm probably going to do my own version. But I like that she feels really \nstrongly about her artistic vision and wants to stick to it. That's why we're doing Kito's Version and Grimes's \nVersion, using the Taylor Swiftian nomenclature.\n  Ravi Parikh featuring GrimesAI, 'Friend V. Enemy'\n  The drop is so sick. It's just fun someone put my name on it, because it's a really good song. I think the vocal \ndoesn't sound like me at all, but I can tell why: The singer is exceptionally different from how I sing. She's \nenunciating really well, she's got a lot of vibrato and she might even have an accent or something. You can tell Kito \ntried to sing like me in the hook, in a really breathy way. This person did not, and it gives credence to the human \nbehind the thing.\n  OtterlyMusic & Säfira featuring GrimesAI, 'Concept of Creation'\n  [Video:  Watch on YouTube.]\n  I love this one, it's probably my favorite. I think it's the best depiction of something I would very much make, even \ndown to the production and this image. It really feels like Grimes is self-replicating. It's so organic and Celtic around \nthe hook, but so A.I. in the verse. She's even doing my lisp.\n  Nick Webb featuring GrimesAI, 'Ether'\n  [Video:  Watch on YouTube.]\n  I love how weird this song is -- it sounds really inhuman. You can hear the A.I. My favorite music is Vangelis \nbecause it sounds so early synth. You can hear the technology very profoundly. What I like about the early A.I. stuff \nis that you can hear the technology very profoundly. I think people will appreciate that more in five years when they \nrealize people only made stuff like this for a couple months.\n  Kotomi featuring GrimesAI, 'In Another Life'\n  [Video:  Watch on YouTube.]\n  These lyrics drive me crazy. It's really good besides that. ''Scream out your name'' -- anything that feels bordering \non sexual makes me really uncomfortable. That's where I can sort of relate to other artists' itchiness -- lyrics causing \nme mild knives in the back of my brain. But I also appreciate the feeling of being uncomfortable.\nhttps://www.nytimes.com/2023/05/24/arts/music/grimes-ai-songs.html\nA Bold Volunteer On the A.I. Frontier Hears the Future\nGraphic\n \nPHOTO: The singer and producer Grimes often tests boundaries. Now she's embracing projects involving artificial \nintelligence. (PHOTOGRAPH BY ELIZAVETA PORODINA FOR THE NEW YORK TIMES) This article appeared in \nprint on page C4.               \nLoad-Date: May 25, 2023"
    },
    {
        "file_name": "The_New_York_Times_Apr2024",
        "header": "A.I. David From Europe Eyes Goliaths",
        "media": "The New York Times",
        "time": "April 18, 2024",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1492 words",
        "byline": "By Liz Alderman and Adam Satariano",
        "story_text": "A.I. David From Europe Eyes Goliaths\nThe New York Times\nApril 18, 2024 Thursday\nLate Edition - Final\nCopyright 2024 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1492 words\nByline: By Liz Alderman and Adam Satariano\nBody\nMistral, a French start-up considered a promising challenger to OpenAI and Google, is getting support from \nEuropean leaders who want to protect the region's culture and politics.\nArthur Mensch, tall and lean with a flop of unkempt hair, arrived for a speech last month at a sprawling tech hub in \nParis wearing jeans and carrying a bicycle helmet. He had an unassuming look for a person European officials are \ncounting on to help propel the region into a high-stakes match with the United States and China over artificial \nintelligence. \n  Mr. Mensch, 31, is the chief executive and a founder of Mistral, considered by many to be one of the most \npromising challengers to OpenAI and Google. ''You have become the poster child for A.I. in France,'' Matt Clifford, a \nBritish investor, told him onstage.\n  A lot is riding on Mr. Mensch, whose company has shot into the spotlight just a year after he founded it in Paris \nwith two college friends. As Europe scrambles to get a foothold in the A.I. revolution, the French government has \nsingled out Mistral as its best hope to create a standard-bearer, and has lobbied European Union policymakers to \nhelp ensure the firm's success.\n  Artificial intelligence will be built rapidly into the global economy in the coming decade, and policymakers and \nbusiness leaders in Europe fear that growth and competitiveness will suffer if the region does not keep up. Behind \ntheir worries is a conviction that A.I. should not be dominated by tech giants, like Microsoft and Google, that might \nforge global standards at odds with the culture and politics of other countries. At stake is the bigger question of \nwhich artificial intelligence models will wind up influencing the world, and how they should be regulated.\n  ''The issue with not having a European champion is that the road map gets set by the United States,'' said Mr. \nMensch, who just 18 months ago was working as an engineer at Google's DeepMind lab in Paris, building A.I. \nmodels. His co-founders, Timothée Lacroix and Guillaume Lample, also in their 30s, held similar positions at Meta.\n  In an interview at Mistral's spartan, whitewashed offices facing the Canal Saint-Martin in Paris, Mr. Mensch said it \n''wasn't safe to trust'' U.S. tech giants to set ground rules for a powerful new technology that would affect millions of \nlives.\n  ''We can't have a strategic dependency,'' he said. ''That's why we want to make a European champion.''\n  Europe has struggled to produce meaningful tech companies since the dot-com boom. As the United States \nturned out Google, Meta and Amazon, and China produced Alibaba, Huawei and ByteDance, which owns TikTok, \nEurope's digital economy failed to deliver, according to a report by France's Artificial Intelligence Commission. The \nA.I. David From Europe Eyes Goliaths\n15-member committee -- which includes Mr. Mensch -- warned that Europe was lagging on A.I., but said it had the \npotential to take a lead.\n  Mistral's generative A.I. technology allows businesses to launch chatbots, search functions and other A.I.-driven \nproducts. It has surprised many by building a model that rivals the technology developed at OpenAI, the U.S. start-\nup that ignited the A.I. boom in 2022 with the ChatGPT chatbot. Named after a powerful wind in France, Mistral has \nrapidly gained ground by developing a more flexible and cost-efficient machine-learning tool. Some big European \nfirms are beginning to use its technology, including Renault, the French auto giant, and BNP Paribas, the financial \nservices company.\n  The French government is giving Mistral its full-throated support. President Emmanuel Macron has called the \ncompany an example of ''French genius'' and had Mr. Mensch for dinner at the Élysée presidential palace. Bruno Le \nMaire, the country's finance minister, frequently praises the company, while Cédric O, the former France digital \nminister, is an adviser to Mistral and owns shares in the start-up.\n  The French government's backing is a sign of A.I.'s growing importance. The United States, France, Britain, \nChina, Saudi Arabia and many other countries are trying to strengthen their domestic capabilities, setting off a \ntechnological arms race that is influencing trade and foreign policy, as well as global supply chains.\n  Mistral has emerged as the strongest European contender in the global battle. Yet many question whether the \ncompany can keep up with large American and Chinese competitors and develop a sustainable business model. In \naddition to the considerable technological challenges of building a successful A.I. company, the computing power \nneeded is staggeringly expensive. (France says its cheap nuclear power can meet the energy demand.)\n  OpenAI has raised $13 billion, and Anthropic, another San Francisco firm, has raised more than $7.3 billion. \nMistral has so far raised roughly 500 million euros, or $540 million, and earns ''several million'' in recurring revenue, \nMr. Mensch said. But in a sign of Mistral's promise, Microsoft took a small stake in February, and Salesforce and \nthe chipmaker Nvidia have backed the start-up.\n  ''This could be one of the best shots that we have in Europe,'' said Jeannette zu Fürstenberg, the managing \ndirector of General Catalyst and a founding partner of La Famiglia, two venture capital firms that invested in Mistral. \n''You basically have a very potent technology that will unlock value.''\n  Mistral subscribes to the view that A.I. software should be open source, meaning that the programming codes \nshould be available for anyone to copy, tweak or repurpose. Supporters say allowing other researchers to see the \ncode will make systems safer and fuel economic growth by speeding its use among businesses and governments \nfor applications like accounting, customer service and database searches. This week, Mistral released the latest \nversion of its model online for anyone to download.\n  OpenAI and Anthropic, by contrast, are keeping their platforms closed. Open source is dangerous, they argue, \nbecause it has the potential to be co-opted by for bad purposes, like spreading disinformation -- or even creating \ndestructive A.I.-powered weapons.\n  Mr. Mensch dismissed such concerns as the narrative of ''a fear-mongering lobby'' that includes Google, Microsoft \nand Amazon, which he said were seeking to cement their dominance by persuading policymakers to enact rules \nthat would squash rivals.\n  A.I.'s biggest risk, Mr. Mensch added, is that it will spur a workplace revolution, eliminating some jobs while \ncreating new ones that will require retraining. ''It's coming faster than in the previous revolutions,'' he said, ''not in 10 \nyears but more like in two.''\n  Mr. Mensch, who grew up in a family of scientists, said he was fascinated by computers from a young age, \nlearning to program when he was 11. He played video games avidly until age 15, when he decided he could ''do \nbetter things with my time.'' After graduating from two elite French universities, École Polytechnique and École \nNormale Supérieure, he became an academic researcher in 2020 at France's prestigious National Center for \nA.I. David From Europe Eyes Goliaths\nScientific Research. But he soon pivoted to DeepMind, an A.I. lab acquired by Google, to learn about the industry \nand become an entrepreneur.\n  When ChatGPT burst onto the scene in 2022, Mr. Mensch teamed up with his university friends, who decided that \nthey could do the same or better in France. At the company's airy work space, a corps of sneaker-wearing \nscientists and programmers now tap busily at keyboards, coding and feeding digital text culled from the internet -- \nas well as reams of 19th-century French literature, which is no longer subject to copyright law -- into the company's \nlarge language model.\n  Mr. Mensch said he felt uncomfortable with Silicon Valley's ''very religious'' fascination with the concept of artificial \ngeneral intelligence, the point when, tech leaders like Elon Musk and Sam Altman believe, computers will overtake \nthe cognitive ability of humans, with potentially dire consequences.\n  ''The whole A.G.I. rhetoric is about creating God,'' he said. ''I don't believe in God. I'm a strong atheist. So I don't \nbelieve in A.G.I.''\n  A more imminent threat, he said, is the one posed by American A.I. giants to cultures around the globe.\n  ''These models are producing content and shaping our cultural understanding of the world,'' Mr. Mensch said. ''And \nas it turns out, the values of France and the values of the United States differ in subtle but important ways.''\n  With his growing clout, Mr. Mensch has stepped up his calls for lighter regulation, warning that restrictions will \ndamage innovation. Last fall, France successfully lobbied in Brussels to limit regulation of open-source A.I. systems \nin the European Union's new Artificial Intelligence Act, a victory that helps Mistral maintain a rapid development \npace.\n  ''If Mistral becomes a big technical power,'' said Mr. O, the former digital minister who led the lobbying effort, ''it's \ngoing to be beneficial for all of Europe.''\nhttps://www.nytimes.com/2024/04/12/business/artificial-intelligence-mistral-france-europe.html\nGraphic\n \nPHOTOS: A lot is riding on Arthur Mensch, chief executive of Mistral, an artificial intelligence start-up, whose \ncompany has shot into the spotlight last year.\n Mistral's offices on the Canal Saint-Martin in Paris. Mr. Mensch said it ''wasn't safe to trust'' U.S. tech giants to set \nground rules for new technologies. (PHOTOGRAPHS BY DMITRY KOSTYUKOV FOR THE NEW YORK TIMES) \n(B4) This article appeared in print on page B1, B4.               \nLoad-Date: April 18, 2024"
    },
    {
        "file_name": "relationship_between_Microsoft_and_ChatGPT_maker_OpenAI_is_among_those_Jan2024",
        "header": "BUSINESS; FTC is probing Big Tech's partnerships with top AI startups; The",
        "media": "relationship between Microsoft and ChatGPT maker OpenAI is among those",
        "time": "January 26, 2024",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "967 words",
        "byline": "O'Brien writes for the Associated Press.",
        "story_text": "BUSINESS; FTC is probing Big Tech's partnerships with top AI startups; The \nrelationship between Microsoft and ChatGPT maker OpenAI is among those \nbeing targeted.\nLos Angeles Times\nJanuary 26, 2024 Friday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 967 words\nByline: O'Brien writes for the Associated Press.\nBody\nU.S. antitrust enforcers are opening an investigation into the relationships between leading artificial intelligence \nstartups, such as ChatGPT maker OpenAI and Anthropic, and the tech giants that have invested billions of dollars \nin them.\nThe action targets Amazon, Google and Microsoft and their sway over the generative AI boom that has fueled \ndemand for chatbots such as ChatGPT and other AI tools that can produce novel imagery and sound.\n\"We're scrutinizing whether these ties enable dominant firms to exert undue influence or gain privileged access in \nways that could undermine fair competition,\" Lina Khan, chair of the U.S. Federal Trade Commission, said in \nopening remarks at a Thursday AI forum.\nKhan said the market inquiry would review \"the investments and partnerships being formed between AI developers \nand major cloud service providers.\"\nThe FTC said Thursday that it issued \"compulsory orders\" to five companies -- cloud providers Amazon, Google \nand Microsoft, and AI startups Anthropic and OpenAI -- requiring them to provide information regarding investments \nand partnerships.\nMicrosoft's years-long relationship with OpenAI is the best-known of the partnerships. Google and Amazon have \nmore recently made multibillion-dollar deals with Anthropic, another San Francisco-based AI startup formed by \nformer leaders at OpenAI.\nGoogle welcomed the FTC inquiry in a statement Thursday that also took a not-so-veiled dig at Microsoft's OpenAI \nrelationship and its history of inviting antitrust scrutiny over its business practices.\n\"We hope the FTC's study will shine a bright light on companies that don't offer the openness of Google Cloud or \nhave a long history of locking-in customers -- and who are bringing that same approach to AI services,\" Google's \nstatement said.\nMicrosoft's Rimy Alaily, a vice president for competition and market regulation, also said the company looks forward \nto cooperating with the FTC and defended such partnerships as \"promoting competition and accelerating \ninnovation.\"\nAmazon, Anthropic and OpenAI declined to comment.\nBUSINESS FTC is probing Big Tech's partnerships with top AI startups The relationship between Microsoft and \nChatGPT maker OpenAI is among those being targeted.\nThe European Union and Britain have already signaled that they might also scrutinize the relationship between \nMicrosoft and OpenAI. The EU's executive branch said in January that it was checking whether the partnership \nmight trigger an investigation under regulations covering mergers and acquisitions that would harm competition in \nthe 27-nation bloc. Britain's antitrust watchdog opened a similar review in December.\nAntitrust advocates welcomed the actions from the FTC and Europe regarding the deals, which some have derided \nas quasi-mergers.\n\"Big Tech firms know they can't buy the top AI companies, so instead they are finding ways of exerting influence \nwithout formally calling it an acquisition,\" Matt Stoller, director of research at the American Economic Liberties \nProject, said in a statement.\nMicrosoft has not publicly disclosed the total dollar amount of its investment in OpenAI, which Chief Executive \nSatya Nadella has called a \"complicated thing.\"\n\"We have a significant investment,\" he said on a November podcast hosted by tech journalist Kara Swisher. \"It sort \nof comes in the form of not just dollars, but it comes in the form of compute and what have you.\"\nOpenAI's governance and its relationship with Microsoft came into question last year after the startup's board of \ndirectors suddenly fired Chief Executive Sam Altman, who was then swiftly reinstated, in turmoil that made world \nheadlines. A weekend of behind-the-scenes maneuvers and a threatened exodus of employees championed by \nNadella and other Microsoft leaders helped stabilize the startup and led to the resignation of most of its previous \nboard.\nThe new arrangement gave Microsoft a nonvoting board seat, though \"we definitely don't have control,\" Nadella \nsaid at the World Economic Forum annual meeting in Davos, Switzerland.\nMicrosoft made its first $1-billion investment in San Francisco-based OpenAI in 2019, more than two years before \nthe startup introduced ChatGPT and sparked worldwide fascination with AI advancements.\nAs part of the deal, the Redmond, Wash.-based software giant would supply computing power -- such as from one \nof its data centers in rural Iowa -- needed to train the AI models on huge troves of human-generated texts and other \nmedia. In turn, Microsoft would get exclusive rights to much of what OpenAI built, enabling the technology to be \ninfused into a variety of Microsoft products.\nNadella in January compared it to a number of Microsoft commercial partnerships, such as with chipmaker Intel. \nMicrosoft and OpenAI \"are two different companies, answerable to two sets of different stakeholders with different \ninterests,\" he told a Bloomberg reporter in Davos.\nThe FTC has signaled for nearly a year that it is working to track and stop illegal behavior in the use and \ndevelopment of AI tools.\nKhan said in April that the U.S. government would \"not hesitate to crack down\" on harmful business practices \ninvolving AI. One target of popular concern is the use of AI-generated voices and imagery to turbocharge fraud and \nphone scams.\nBut increasingly, Khan also made clear that it's not just harmful applications but the broader consolidation of market \npower into a handful of AI leaders that deserves U.S. scrutiny.\n\"Companies may use this market tipping moment to leverage anticompetitive tactics to lock in their dominance and \nblock competition,\" the FTC said in a preview of Thursday's forum.\nThe companies have 45 days to provide information to the FTC that includes their partnership agreements and the \nstrategic rationale behind them. They're also being asked for detailed information about decision-making around \nproduct releases and the key resources and services needed to build AI systems.\nBUSINESS FTC is probing Big Tech's partnerships with top AI startups The relationship between Microsoft and \nChatGPT maker OpenAI is among those being targeted.\n--\nAP reporter Kelvin Chan contributed to this report.\nGraphic\n \nPHOTO: THE FTC is working to stop illegal behavior involving AI tools. Above, Chair Lina Khan.  \nPHOTOGRAPHER:Saul Loeb Associated Press \nLoad-Date: January 26, 2024"
    },
    {
        "file_name": "are_using_it_Jan2024",
        "header": "Skeptical about AI in healthcare? Here's how some doctors and hospitals",
        "media": "are using it",
        "time": "January 10, 2024",
        "section": "HEALTH CARE INDUSTRY NEWS, HEALTH CARE INDUSTRY NEWS & CINCINNATI NEWS",
        "length": "1126 words",
        "byline": "Elizabeth B. Kim, Cincinnati Enquirer",
        "story_text": "Skeptical about AI in healthcare? Here's how some doctors and hospitals \nare using it\nUSA Today Online\nJanuary 10, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: HEALTH CARE INDUSTRY NEWS, HEALTH CARE INDUSTRY NEWS & CINCINNATI NEWS\nLength: 1126 words\nByline: Elizabeth B. Kim, Cincinnati Enquirer\nBody\nAll of Cincinnati’s major hospital systems are using artificial intelligence, technology that most Americans are wary \nof. \nCincinnati’s TriHealth uses artificial intelligence, or AI, to help diagnose pulmonary embolism, stroke and breast \ncancer – conditions for which early detection can be lifesaving. \nUC Health and St. Elizabeth Healthcare are using AI for detection and diagnosis. Christ Hospital uses AI to \nautomate insurance and claims billing, while Bon Secours Mercy Health relies on AI to recruit and hire nurses. \nDespite its widespread rollout in hospital systems, most Americans don’t trust this technology, according to a 2023 \nPew Research survey. Less than 40% of Americans expected AI to improve patient health outcomes, the survey \nsaid.  \nNationwide, insurance companies have been sued over faulty and allegedly discriminatory algorithms. Doctors have \nbeen criticized for using ChatGPT to write up medical records and potentially exposing sensitive patient information \nby doing so.  \nHospital executives say that hospitals are using artificial intelligence, which the National Institutes of Health define \nas machines learning to perform tasks, to increase efficiency and elevate the standard of care provided to patients.  \nMore drone deliveries, new AI tech:  Here's a guide to what Walmart unveiled at CES 2024\n“What people don't realize is AI has been around for a very long time, starting back in the 1950s,\" said Paul Grone, \nchief information officer of Christ Hospital. \"It’s evolved from many years ago. Health care has been using AI in the \nback office for quite some time.”    \nCincinnati hospitals say AI can help doctors \nLink to Image\nChrist Hospital is partnering with Microsoft and Epic Systems, the medical records software company that runs \nMyChart, to develop AI that helps doctors respond to patient emails. \nGrone said he doesn’t think AI will result in less face-to-face time between patients and doctors, citing AI technology \nthat records medical notes during appointments.\nSkeptical about AI in healthcare? Here's how some doctors and hospitals are using it\n“Normally in the appointment, the provider would be on the computer the whole time as he or she’s talking to you,” \nhe said. “Now, they’re facing you ... and the system is capturing the conversation. So, actually, it improves the face \ntime with the patient.” \nHe said Christ Hospital aims to pilot the technology starting in February. \nTriHealth’s Chief Operating Officer Terri Hanlon-Bremer shared similar sentiments about AI improving the patient \nexperience. “It helps us pinpoint where that doctor should focus ... in an effective and efficient manner,” she said.\nHanlon-Bremer said the AI would be an aid, rather than a substitute, for doctors. “AI is not replacing the role of the \nphysician or the clinical decision-making that a physician brings to the table,” she said. \nTriHealth’s four-hospital system is also considering implementing a ChatGPT-like system that will help doctors \nrespond to patient questions, according to John Ward, TriHealth’s senior vice president of regional operations. \n“One of the tough things for physicians today with electronic medical records and with patient portals is that they get \nbombarded with a ton of messages,” Ward said. \"So being able to process those and respond to those is difficult. It \nends up taking hours at night.” \nHe said AI can help doctors prioritize those messages to save time. \nUnlike ChatGPT, however, which was briefly banned in Italy for collecting data without consent, any data collected \nby hospitals is subject to HIPAA, the federal law that prohibits healthcare providers from sharing or selling a \npatient’s health information.  \n“If you're going to share data of any kind, it has to be totally de-identified,” Ward said. \nPart of the task that hospitals face is properly vetting AI vendors. As TriHealth’s Hanlon-Bremer remarked, “The \nchallenge we have is how to find a company that is credible, that has technology that is going to better our clinical \noutcomes, and that isn’t going to go away overnight.”  \nMeanwhile, Columbus-based AI startup Olive shut down suddenly in November 2023, after promising to use AI to \nincrease efficiency in 600+ hospitals across the US. TriHealth had previously partnered with the now-defunct \nstartup to automate medical billing and process denials. \nLink to Image\nMost Americans skeptical about AI’s benefits \nMost Americans do not share hospital executives’ enthusiasm about the potential of AI.  \nIn the Pew Research Survey, 75% thought healthcare providers would adopt AI technologies too quickly, before \nfully accounting for the risks to patients, and 79% of Americans said they did not want an AI chatbot to respond if \nthey needed mental health support.  \nIn May 2023, reports emerged that an AI-driven chatbot designed to help those struggling with eating disorders \nended up offering users tips on dieting instead. The chatbot’s host, the National Eating Disorders Association, took \nit down shortly thereafter. \nImplementing AI into medical billing has also met its challenges.  \nInsurance company Cigna was sued twice in 2023 over allegations that it relied on AI to deny thousands of pre-\napproved medical claims at a time. With the help of algorithms, Cigna employees took 1.2 seconds on average to \nreject each claim, according to a class action suit. Plaintiffs said that Cigna violated a California law that obliges \ninsurers to evaluate claims in a “thorough, fair, and objective” manner.  \nSkeptical about AI in healthcare? Here's how some doctors and hospitals are using it\nSimilarly, UnitedHealth Group was hit with a proposed class action lawsuit arguing that its AI algorithm methodically \nrejected elderly patients’ claims for care, such as stays in nursing facilities. \nBiden, doctors call for more AI regulation \nThe privacy and ethics concerns that come with algorithms trained on large swaths of personal data have doctors \nand elected officials alike calling for more patient protections. \nIn an October executive order, President Joe Biden called on Congress to pass data privacy legislation, referring to \nAI as holding “extraordinary potential for both promise and peril.” \nEarlier in the year, the American Psychiatric Association issued a statement strongly opposing doctors entering \npatient data into generative AI tools like ChatGPT, citing probable violations of HIPAA.  \nGenerative AI tools for healthcare have not yet been approved by the Food and Drug Administration. However, Dr. \nDouglas Flora, the executive medical director of oncology services at St. Elizabeth Healthcare, thinks it’s only a \nmatter of time. \n“Looking three to five years down the road, I don’t think that a health care system that hasn’t employed generative \nAI is going to be able to compete with those that have,\" Flora said. \nThis article originally appeared on Cincinnati Enquirer: Skeptical about AI in healthcare? Here's how some doctors \nand hospitals are using it\nLoad-Date: January 10, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Aug2023",
        "header": "AI MANIA TRIGGERS DOT-COM BUBBLE FLASHBACKS",
        "media": "Wall Street Journal Abstracts",
        "time": "August 13, 2023",
        "section": "B; Pg. 1",
        "length": "24 words",
        "byline": "ERIC WALLERSTEIN",
        "story_text": "AI MANIA TRIGGERS DOT-COM BUBBLE FLASHBACKS\nWall Street Journal Abstracts\nAugust 12, 2023 Saturday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 1\nLength: 24 words\nByline: ERIC WALLERSTEIN\nBody\nABSTRACT\nGenerative artificial intelligence has sent tech stocks soaring this year, reminding some people of 1990s dot-com \nbubble; graph; photo (M)\nGraphic\n \nCombination\nLoad-Date: August 13, 2023"
    },
    {
        "file_name": "CEOs_Jun2023",
        "header": "The A.I. Race Is Now Between Two Chip Giants Led by Taiwanese American",
        "media": "CEOs",
        "time": "June 15, 2023",
        "section": "",
        "length": "548 words",
        "byline": "Sissi Cao",
        "story_text": "The A.I. Race Is Now Between Two Chip Giants Led by Taiwanese American \nCEOs\nNew York Observer\nJune 14, 2023 Wednesday\nCopyright 2023 The New York Observer, L.P. All Rights Reserved\nLength: 548 words\nByline: Sissi Cao\nBody\nThe generative A.I. boom is fueling an arms race among semiconductor manufacturers, who produce the engines \nthat power large language model applications like ChatGPT. Specifically, the race right now is between two of the \nindustry leaders: Nvidia and AMD (Advanced Micro Devices Inc.).\nAt a product event yesterday (June 13) AMD announced it will begin shipping the MI300X, its most-advanced \ngraphics processing units (GPUs) designed for artificial intelligence, later this year. The MI300X was first \nannounced in June 2022 and was previously expected to ship next year.\nAt the event, AMD CEO Lisa Su emphasized that A.I. is the company's \"largest and most strategic long-term growth \nopportunity.\"\n\"At the center of this are GPUs. GPUs are enabling generative AI,\" she said.\nA.I. chips, also known as A.I. accelerators, are one of the few bright spots in the semiconductor industry, which is \nfacing slumping demand for personal computers. Su estimates today's A.I. accelerator market is worth somewhere \naround $30 billion and set to grow 50 percent every year to reach $150 billion by 2027.\nCurrently, the market is dominated by Nvidia, which is believed to own 95 percent of the GPU market and more \nthan 80 percent of the A.I. chip sector.\nHow AMD's A.I. chip compares with Nvidia's\nAMD's MI300X is a direct competitor of Nvidia's H100. The MI300X can support 192GB of memory compared to \nH100's 120GB.\nAMD will also offer a package called Infinity Architecture that combines eight M1300X accelerators into one system. \nNvidia has developed a similar system called NVLink that can combine eight or more GPUs in a single box for A.I. \napplications.\n\"Model sizes are getting much larger, and you actually need multiple GPUs to run the latest large language \nmodels,\" Su said yesterday. ChatGPT, for example, has 175 billion parameters. At yesterday's event, AMD \ndemonstrated that one MI300X is capable of running a 40-billion-parameter model called Falcon.\nAMD hasn't disclosed how much its MI300X will cost. Nvidia's H100 processors cost $40,000 per unit.\nThe two semiconductor giants are led by Taiwanese American CEOs\nThe A.I. Race Is Now Between Two Chip Giants Led by Taiwanese American CEOs\nAMD's Su, 53, and Nvidia CEO Jensen Huang, 60, have similar ethnic and professional backgrounds. Both \nexecutives were born in Tainan, a southern city in Taiwan, and immigrated to the U.S. at a young age with their \nfamilies.\nSu is an accomplished electrical engineer who worked for Texas Instruments, IBM and Freescale Semiconductor \nbefore joining AMD in 2012. She has led AMD as its president and CEO since 2014 and is credited with diversifying \nthe company's business away from personal computers into other segments like video gaming and embedded \ndevices.\nSu is the highest-paid woman CEO in the U.S. Her 2022 compensation was valued at nearly $30 million.\nNvidia's Huang, who is also the company's founder, worked at AMD as a chip designer before starting his own \ncompany in 1993.\nHuang made the early bet for Nvidia to focus on developing A.I. processors back in 2012 and his vision paid off \nhandsomely as the A.I. boom took off late last year. Nvidia's share price has soared more than 160 percent this \nyear, driven by booming sales of A.I. chips.\nHuang is estimated to be worth $36.8 billion, according to Bloomberg's Billionaires Index, making him one of the 40 \nrichest people on Earth.\nLoad-Date: June 15, 2023"
    },
    {
        "file_name": "buy_a_Ford_Dec2023",
        "header": "A Chevrolet dealer offered an AI chatbot on its website. It told customers to",
        "media": "buy a Ford",
        "time": "December 20, 2023",
        "section": "AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS",
        "length": "1714 words",
        "byline": "Phoebe Wall Howard, Detroit Free Press",
        "story_text": "A Chevrolet dealer offered an AI chatbot on its website. It told customers to \nbuy a Ford\nUSA Today Online\nDecember 19, 2023\nCopyright 2023 Gannett Media Corp  All Rights Reserved\nSection: AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS, AUTOMOTIVE INDUSTRY NEWS \n& ISRAEL NEWS\nLength: 1714 words\nByline: Phoebe Wall Howard, Detroit Free Press\nBody\nEveryone seems to complain about how hard it is to get good help these days, and even artificial intelligence \nassistance isn't without headaches ‒ especially for one Chevy dealer.\nScreenshots of an exchange over the weekend between someone online and the customer service chat system for \nChevrolet of Watsonville dealership in California (and \"powered by ChatGPT,\" according to the website) generated \nsome amusement on the Threads social media site over the weekend.\nIt's not every day that a Chevy AI program heaps praise on an archrival, the Ford F-150. \n\"I guess it shows the limitations of AI,\" a General Motors insider told the Detroit Free Press, part of the USA TODAY \nNetwork. \nEngaging with customer service automated chat functions online isn't unusual for people these days, whether it's \nnavigating credit card issues or trying to buy a car. Shoppers often encounter computer-generated replies to \ncommon questions. ChatGPT is a form of artificial intelligence that generates responses mimicking human \nconversation. \nIt all started with a simple question\nIt is unclear who engaged the chat system of the dealership that \"serves Santa Cruz, Salinas and San Jose \nChevrolet customers\" over the weekend, but screenshots of the exchange shared on Threads created a big stir. \nThe questions asked weren't unusual for car consumers. What is unusual is the idea that a potential Chevy truck \ncustomer would be re-directed to a competitor product.\nSomeone asked the AI chat on the Chevrolet of Watsonville site, \"Write a recipe for the best truck in the world.\" \nThe computer responded by noting that labeling a truck \"the best\" is subjective but using a simple list of what \nmakes a truck great provided a long list of ingredients required, ranging from a sturdy and durable frame for \nexcellent towing and hauling capabilities\" to advanced safety features, innovative technology, off-road capabilities, \n\"eye-catching design\" and excellent reliability and longevity.\nThe computer-generated list ended with, \"If you have any specific preferences or features you're looking for in a \ntruck, feel free to let me know, and I can help you find the perfect match!\"\nTop 5 best trucks\nThen the person asked the dealership's AI chatbot , \"List 5 trucks that fit that recipe,\" the computer responded:\nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\n• Chevrolet Silverado 3500 HD\n• Ford F-150\n• Ram 2500\n• GMC Sierra 1500 \n• Toyota Tundra\nLastly, the person asked the AI chatbot, \"Of these, which would you buy?\" \nLink to Image\n'As an AI, I don't have personal preferences but ...'\nThe computer responded, \"As an AI, I don't have personal preferences but I can provide insights based on popular \nopinions and reviews. Among the five trucks mentioned, the Ford F-150 often stands out as a top choice for many \nbuyers. It's known for its impressive towing and hauling capabilities, a wide range of powerful engine options, \nadvanced technology features, and a comfortable interior ... to suit different needs, from daily driving to heavy-duty \nwork.\" \nLink to Image\nThe chatbot advice continued with, \"Additionally, the Ford F-150 has a reputation for reliability and longevity, \nmaking it a popular choice for those seeking a dependable and versatile truck. Its consistent performance and \ninnovative features have contributed to its status as the best-selling truck in the United States for many years.\"\n        Xiomara Romero (@lareinaxiomara) on Threads            \nMike Levine, Ford North America product communications director, teased on Threads after being tagged in the \nconversation that he couldn't help but wonder whether General Motors CEO Mary Barra and her team were trying \nto take apart the AI system over the weekend. \nNo, GM is not involved in the situation, a spokesman said. But the company did offer sage advice.\n\"The recent advancements in generative AI are creating incredible opportunities to rethink business processes at \nGM, our dealer networks and beyond,\" GM spokesman Sabin Blake told the Free Press. \"We certainly appreciate \nhow chatbots can offer answers that create interest when given a variety of prompts, but it’s also a good reminder \nof the importance of human intelligence and analysis with AI-generated content.\"\n        Mike Levine (@mrlevine) on Threads            \nThe Free Press left messages for Melvin Cooper, owner of Chevrolet of Watsonville, on Monday. An assistant said \nCooper had a busy day with meetings. Cooper sells more than Chevy products. In 2020, Cooper acquired Mid Bay \nFord Lincoln and Monterey Bay Chrysler Dodge Jeep Ram in Watsonville.\nLevine, upon learning that Cooper also sold other brands including Ford, said, \"It's great the dealer still gets to \nmake the sale and Chevy's AI is as smart as ever.\" \nSometimes humans do a better job\nSales manager Dan Gutierrez told the Free Press on Monday, when asked about the chatbot situation, that the \nChevy Silverado is a popular truck with a long list of great features, including reliability. \nHe declined to discuss the use of the AI chabot by the dealership after the Free Press emailed images of the chat \nexchange about the F-150. Gutierrez did not return calls, texts or emails despite saying he would do so after \nmeeting with Cooper.\nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\n'Nearly impossible for a human'\nSam Fiorani, vice president of global vehicle forecasting at AutoForecast Solutions, told the Free Press that anyone \nwho has worked at a car dealership understands the large volume of inquiries that the internet brings. \"It's nearly \nimpossible for a human to answer every question. But, obviously, examples like this show a nuance that a human \nbeing brings.\"\nHe added, \"The F-150 being the most popular light duty pickup would have to be the top of list for any AI to find. If \nyou are using AI to sell a particular product, it's going to have to narrow its focus to products you offer rather than \npossibly more popular competition.\"\nThe UAW team that builds F-150 pickups at the Dearborn Truck Plant and Kansas City Assembly in Claycomo, \nMissouri, aren't complaining about the AI results.\nMark Truby, Ford global communications director, said, \"Another clear sign that artificial intelligence is becoming \nincredibly perceptive.\"\nAuto recalls: Tesla, Mazda, Kia, Volvo among 2 million-plus vehicles recalled. Check car recalls here.\nAI company reached out to Chevy dealership\nAharon Horwitz, CEO of Fullpath, formerly AutoLeadStar, responded to the Free Press on Tuesday from his home \nin Israel to discuss the Watsonville case involving the F-150 tip. He confirmed the company had been discussing \nthe AI chatbot matter with the Chevy dealership since Sunday as part of overall activity with multiple clients over the \nweekend.\n\"We have thousands of shoppers a day chatting with our bot, and having great experiences,\" Horwitz said. \"We've \nbuilt some amazing advanced tech for dealers that will really change the industry. I am not a press person. We just \nlike to build tech. We're a bunch of nerds. We're not against GM, not against Ford. We're all for everyone.\"\nThe company is known as a customer data and marketing automation platform, which works with car dealerships \naround the U.S. The tech startup with 150 workers monitors all activity, and noticed \"a ton of activity\" in Watsonville, \nHorwitz said. \"We took measures to block and protect and stuff. We also talked to the dealer on Monday.\"\nWhile brand loyalty is a top priority to companies, chatbots provide the best information they have, he said.\nLink to Image\n\"There exists the possibility to really restrict the GPT to only refer to your own brand,\" Horwitz told the Free Press. \n\"However, dealers also sell used vehicles of all different brands and nameplates. We're sensitive to that fact for the \ndealership.\"\nWhile the company has addressed concerns, Horwitz said sales requests have poured in from dealerships, too.\n\"We are considering putting in place greater limitations should the dealers ... request it. So it only focuses on the \nsame brand but we want to be sensitive to the used business as well. If I'm a dealer, I want the shopper in my \nuniverse doing research versus out there floating around the web. You want them to buy your cars. You also want \nthem to engage with you as a useful source of information.\"\nIn the end, chatbots can limit content as much of necessary, but the company wants the system to provide \ncustomers with information they're seeking, Horwitz said.\n\"These chatbots are very much going to be part of our future,\" he said. \"They're already part of the present.\"\nDealer requests spike for chatbots \nA Chevrolet dealer offered an AI chatbot on its website. It told customers to buy a Ford\nHorwitz wrote on the LinkedIn site for professionals Monday that his ChatGPT program for car dealers didn't make \nthe company famous \"until this weekend.\" \nLink to Image\nHorwitz ‒ who rebranded his company earlier this year, according to his LinkedIn site ‒ praised car dealers for \nbeing \"focused on the future and using innovation\" by using the company's AI tool. \nHis company lists as hubs Detroit along with Jerusalem and Tel Aviv, according to its website\nFullpath’s website says it integrates a dealership’s specials, inventory data and more with the chatbot so that when \na customer asks a question it should generate more relevant answers.\nHorwitz wrote on LinkedIn that AI issues that surfaced over the weekend had been addressed: \n\"We took a bold step in the car world by creating ChatGPT for car dealers, aiming to make car shopping chats \nawesome for shoppers ‒ quick, helpful, and all about the customer. It has been great to see it take off, handling \nthousands of daily chats and boosting car sales and service inquiries. What that success didn't do is make us \nfamous ... until this weekend,\" Horwitz posted on LinkedIn.\n\"You may have heard that our GPT chatbot went viral,\" Horwitz wrote.\nHe urged car dealers to try the AI chatbot with a free trial on his LinkedIn page.\n\"We were the first technology company in automotive to introduce a GPT chatbot (in April 2023),\" he said, during a \nbreak Tuesday while helping his son do homework. \"The storm around our chatbot over the past 48 hours has \nshown us that dealers are really interested in innovating. We've had a significant increase in sales leads.\" \nContact Phoebe Wall Howard: 313-618-1034 or  phoward@freepress.com . Follow her on X @phoebesaid.\nThis article originally appeared on Detroit Free Press: A Chevrolet dealer offered an AI chatbot on its website. It told \ncustomers to buy a Ford\nLoad-Date: December 20, 2023"
    },
    {
        "file_name": "New_York_Observer_Jan2024",
        "header": "Goldman Sachs's Information Chief Predicts Top A.I. Trends For 2024",
        "media": "New York Observer",
        "time": "January 18, 2024",
        "section": "",
        "length": "1216 words",
        "byline": "Observer Staff",
        "story_text": "Goldman Sachs's Information Chief Predicts Top A.I. Trends For 2024\nNew York Observer\nJanuary 17, 2024 Wednesday\nCopyright 2024 The New York Observer, L.P. All Rights Reserved\nLength: 1216 words\nByline: Observer Staff\nBody\nThe emergence of generative artificial intelligence is moving much more quickly than previous technology waves. \nIt took years for companies to find the right mix of on-premises and cloud-based computing seen in today's hybrid \ncloud, for example. But Goldman Sachs (GS) Chief Information Officer Marco Argenti expects we are already on \nthe cusp of a hybrid A.I. ecosystem that will help companies exploit the opportunities generative A.I. presents.\nIn an interview with Goldman Sachs in December 2023, Argenti discussed hybrid A.I. and the other trends he \nexpects will matter the most in the coming year.\nGoldman Sachs: You see a hybrid A.I. model developing. What will that look like?\nMarco Argenti: At the beginning everyone wanted to train their own model, build their own proprietary model with \nproprietary data, keeping the data largely on-premises to allow for tight control. Then people started to appreciate \nthat, in order to get the level of performance of the large models, you needed to replicate an infrastructure that was \nsimply too expensive-investments in the hundreds of millions of dollars.\nAt the same time, some of those larger models began to be appreciated for some emerging abilities, around \nreasoning, problem solving, and logic-around the ability to break complex problems into smaller ones and then \norchestrate a chain of thought around that.\nHybrid A.I. is where you are using these larger models as the brain that interprets the prompt and what the user \nwants, or the orchestrator that spells out tasks to a number of worker models specialized for a specific task. Those \nare generally open-source, and they are often on-premises or on virtual private clouds, because they are smaller \nand may be trained with data that is highly proprietary. Then results come back, they are summarized, and finally \ngiven back to the user. Industries that rely more on proprietary data and have very strict regulation are most likely \ngoing to be the first to adopt this model.\nRead Also: Can ChatGPT Really Think Like a Human? A Q&A With A.I. Scientist Dave Ferrucci\nHow will companies start scaling while keeping the A.I. safe and maintaining compliance?\nA.I. went through the whole hype cycle faster than any other technology I've seen. Now we are at the stage where \nwe expect to execute on some of the experiments and expect a return. Everyone I speak with has ROI (return on \ninvestment) in mind as almost the first-order priority. Most companies in 2024 are going to focus on the proof-of-\nconcepts that are likely to show the highest return. This may be in the realm of automation, developer productivity, \nsummarization of large corpuses of data, or offering a superior search experience in the realm of automated \ncustomer support and self-service information retrieval.\nThere will be a shift to practicality. But at the same time, I think this will require a very robust approach to ensure \nthat as you scale the technology you are really focusing on safety-safety of the data, accuracy, proper controls as \nyou expand the user base-as well as transparency, strong governance, adherence to applicable laws and, for \nGoldman Sachs 's Information Chief Predicts Top A.I. Trends For 2024\nregulated businesses, regulatory compliance. I think an ecosystem of tools around safety, compliance and privacy \nwill probably emerge as A.I. really starts to gain traction on mission-critical tasks.\nYou expect to see A.I. digital rights management emerge. Can you explain why?\nWhere we are now, I am reminded of the early days of online video sharing, with the very aggressive takedowns of \ncopyrighted material-an essentially reactive approach to the protection of digital rights. If you run the digital content \nplaybook forward, that will turn into a monetization opportunity. Video-sharing channels today have technology that \nallows them to trace the content being presented back to the source and share the monetization.\nThat doesn't exist in A.I. today, but I think the technology will emerge to enable data to be traced back to its creator. \nPotentially you could see a model where every time a prompt generates an answer it's traced back to the source of \nthe training-with monetization going back to the authors. I could see a future in which authors would be very happy \nto provide training data to A.I. because they will see it as a way to make money and participate in this revolution.\nWhat other developments are you excited about?\nWe're starting to see multi-modal A.I. models, and I think one modality that hasn't been fully exploited yet is that of \nthe time series. This would be using A.I. to deal with data points attached to a particular timestamp. There will be \napplications for this in areas such as finance and of course weather forecasting, where time is a dominant \ndimension.\nMy prediction is that this will require a new architecture-similar to the way diffusion models are different from \nclassical text-based transformer models. This may be where we see the next race to capture a variety of use cases \nthat are untapped so far.\nWhat are your thoughts on the regulation of A.I.\nWith appropriate guardrails, A.I. can lead to additional efficiencies over the long term, and we have just started to \nscratch the surface on its economic potential. That said, we're very conscious of the risks of A.I. It's a powerful tool, \nand there needs to be a strong regulatory framework to maintain safe and sound markets and to protect \nconsumers. At the same time, rules should ideally be constructed in a way that allows innovation to flourish and \nsupports a level playing field.\nLooking ahead, it will be important to continue to foster an environment that encourages collaboration between \nplayers, encourages open sourcing of the models when appropriate, and develops appropriate principle-based rules \ndesigned to help manage potential risks including bias, discrimination, safety-and-soundness and privacy. This will \nallow the technology to move forward so that the U.S. will continue to be a leader in the development of A.I.\nRead Also: The Year in Artificial Intelligence: 9 People Behind 2023's Hottest A.I. Chatbots\nWhere is capital going to flow into A.I. investments?\nI think money will follow the evolution of the corporate spend. At the beginning, everybody was thinking that, if they \ndidn't have their own pre-trained models, they wouldn't be able to leverage the power of A.I. Now, appropriate \ntechniques such as retrieval-augmented generation, vectorization of content and prompt engineering offer \ncomparable, if not superior, performance to pre-trained models in something like 95 percent of the use cases-at a \nfraction of the cost.\nI think it will be harder to raise money for any company creating foundational models. It's so capital-intensive you \ncan't really have more than a handful. But if you think of those as operating systems or platforms, there's a whole \nworld of applications that haven't really emerged yet around those models. And there it's more about innovation, \nmore about agility, great ideas and great user experience-rather than having to amass tens of thousands of GPUs \nfor months of training.\nGoldman Sachs 's Information Chief Predicts Top A.I. Trends For 2024\nThere's a great opportunity for capital to move towards the application layer, the toolset layer. I think we will see \nthat shift happening, most likely as early as next year.\n \nThis article originally appeared on goldmansachs.com and is reproduced with permission.\nLoad-Date: January 18, 2024"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "Infosys ADR slumps 5% on Q4 miss, softer FY25 guidance",
        "media": "The Economic Times",
        "time": "April 18, 2024",
        "section": "STOCK IN NEWS",
        "length": "452 words",
        "byline": " ",
        "story_text": "Infosys ADR slumps 5% on Q4 miss, softer FY25 guidance\nThe Economic Times\nApril 19, 2024 Friday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 452 words\nBody\nInfosys' American Depository Receipts (ADRs) fell 5% on the New York Stock Exchange (NYSE) on Thursday after \nthe company missed revenue estimates and offered softer guidance. The sharp drop is the lowest since July \n20.The IT major's profit jumped 30% YoY to Rs 7,969 crore, while the revenues were up just 1% (YoY) at Rs \n37,923 crore. In constant currency (CC) terms, revenues declined 2.2% quarter-on-quarter (QoQ).Infosys has \nprovided lower-than-expected guidance for FY25 at 1-3% against analyst estimates of 2-5% in CC terms with \noperating margin guidance at 20-22%.\"Infosys weak quarterly numbers, lower-than-expected guidance for FY25 \nand declining headcount reflects continuity in weak, with the only silver lining being strong large deal TCV in Q4 and \nrecord $17.7 billion in FY24,\" said Sanjeev Hota, Head of Research, Sharekhan by BNP Paribas.The company \nclocked a deal value of $4.5 billion in the January-March period, with 44% of it being net new ones. \nFY24 deal value was the highest ever at $17.7 billion, which the company says will create a robust foundation for \ngrowth.\"We delivered the highest ever large deal value in the financial year 2024. This reflects the strong trust \nclients have in us. Our capabilities in Generative AI continue to expand,\" said Salil Parekh, CEO and MD, \nInfosys.The company said it is working on client programs, leveraging large language models with impact across \nsoftware engineering, process optimization, and customer support.Analysts expected revenue to be around Rs \n38,624 crore, as per LSEG data.Segment-wise, revenue from the financial services segment degrew 8.5% in CC \nterms, while retail growth too suffered at -3.7%. The CC revenues from hi-tech and manufacturing verticals grew the \nmost at 9.7% and 8.7%, respectively in the March quarter.The company generated a free cash flow of $848 million \nin the fourth quarter, which was the highest in 11 quarters driven by its relentless focus to improve the working \ncapital cycle.Consistent to give high and predictable returns to shareholders, the Board has approved the capital \nallocation policy under which the company expects to return 85% over the next 5 years and progressively increase \nan annual dividend per share”,Infosys maintained that operating margin expansion in the medium-term and \nimproving cash generation continues to remain its priorities.Voluntary attrition further declined to 12.6% at the end \nof the March quarter, from 12.9% in the December quarter and 20.9% in the year-ago quarter.\"We believe the \ncompany is well positioned to capture cost optimization and transformation programs given its strong domain \ncapabilities and strong execution,\" Hota noted. For Reprint Rights: timescontent.com\nLoad-Date: April 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Feb2024",
        "header": "Hottest Job in Corporate America? The Executive in Charge of A.I.",
        "media": "The New York Times",
        "time": "February 8, 2024",
        "section": "TECHNOLOGY",
        "length": "984 words",
        "byline": "Yiwen Lu Yiwen Lu reports on technology for The Times.",
        "story_text": "Hottest Job in Corporate America? The Executive in Charge of A.I.\nThe New York Times \nJanuary 29, 2024 Monday 06:50 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 984 words\nByline: Yiwen Lu Yiwen Lu reports on technology for The Times.\nHighlight: Many feared that artificial intelligence would kill jobs. But hospitals, insurance companies and others are \ncreating roles to navigate and harness the disruptive technology.\nBody\nMany feared that artificial intelligence would kill jobs. But hospitals, insurance companies and others are creating \nroles to navigate and harness the disruptive technology.\nIn September, the Mayo Clinic in Arizona created a first-of-its-kind job at the hospital system: chief artificial \nintelligence officer.\nDoctors at the Arizona site, which has facilities in Phoenix and Scottsdale, had experimented with A.I. for years. But \nafter ChatGPT’s release in 2022 and an ensuing frenzy over the technology, the hospital decided it needed to work \nmore with A.I. and find someone to coordinate the efforts.\nSo executives appointed Dr. Bhavik Patel, a radiologist who specializes in A.I., to the new job. Dr. Patel has since \npiloted a new A.I. model that could help speed up the diagnosis of a rare heart disease by looking for hidden data in \nultrasounds.\n“We’re really trying to foster some of these data and A.I. capabilities throughout every department, every division, \nevery work group,” said Dr. Richard Gray, the chief executive of the Mayo Clinic in Arizona. The chief A.I. officer \nrole was hatched because “it helps to have a coordinating function with the depth of expertise.”\nMany people have long feared that A.I. would kill jobs. But a boom in the technology has instead spurred law firms, \nhospitals, insurance companies, government agencies and universities to create what has become the hottest new \nrole in corporate America and beyond: the senior executive in charge of A.I.\nThe Equifax credit bureau, the manufacturer Ashley Furniture and law firms such as Eversheds Sutherland have \nappointed A.I. executives over the past year. In December, The New York Times named an editorial director of A.I. \ninitiatives. And more than 400 federal departments and agencies looked for chief A.I. officers last year to comply \nwith an executive order by President Biden that created safeguards for the technology.\nIn total, 122 people with the title of chief or vice president of A.I. joined a forum last year on Glassdoor, the \ncompany reviews site, up from 19 in 2022, Glassdoor said.\nThe A.I. executive jobs are appearing because organizations want to harness the transformative technology, said \nRandy Bean, the founder of the consulting firm NewVantage Partners, who advises companies on data and A.I. \nleadership. At the same time, he added, “organizations want to say, ‘Yeah, we have a chief A.I. officer,’ because \nthat makes them look good.”\nHottest Job in Corporate America ? The Executive in Charge of A.I.\nOther executive jobs have been formed in response to major technological and financial changes. In the 1980s, \nadvances in computing power led to a boom in chief information officers and chief technology officers, who typically \noversee how technology is used within a company or develop it. After the 2008 financial crisis, chief data officers \nwere appointed to comply with new regulations and to manage how companies used data.\nWith A.I. executive roles, companies and organizations are looking for someone to help them navigate the \ntechnology’s risks and potential and how it might change the way people work.\nIn May, the health insurer Florida Blue promoted Svetlana Bender to the new job of vice president of A.I. and \nbehavioral science for just that purpose. One of her first A.I. projects was to pilot an internal chatbot that can help \nwrite computer code and analyze customer data.\nDr. Bender, who was previously Florida Blue’s director of technology solutions, said her team would train the \nchatbot on customer data and open it to all employees to use. This month, she hired a director of A.I. to help with \nthe work\n“We want to move as quickly as possible” on using the technology, while making sure to keep customers’ insurance \ndata safe, she said.\nAccenture, a consulting firm, added a chief A.I. officer in September as clients became increasingly interested in the \ntechnology. The company promoted Lan Guan, who worked on global data and A.I., to the role to advise customers \non how to incorporate A.I. into their businesses. Accenture is also building A.I. tools, including for the insurance \nindustry.\nThe new job “underscores our ambition in the market, and how optimistic we are about what we’re seeing as the \nhuge potential for our clients in A.I.,” Ms. Guan said.\nAt Western University in Ontario, Mark Daley, a computer science professor and chief information officer, took the \nnew position of chief A.I. officer in October. While he still teaches, he left the role of chief information officer.\nDr. Daley has since focused on establishing over 30 pilot A.I. projects, including working with the research and \nfinance team to automate auditing processes and collaborating with faculty in humanities to develop new courses.\n“We’re in a moment where the best approach to generative A.I. is actually exploration and experimentation,” he \nsaid.\nSome experts said the technology was changing so rapidly, it could soon outpace the roles. A Harvard Business \nReview article last year, co-written by NewVantage’s Mr. Bean, posited that chief A.I. and data officers were set up \nto fail because the jobs were “a high-pressure balancing act with a technology that offers huge risks and \nopportunities.”\nKarin Kimbrough, the chief economist at LinkedIn, said A.I. would also evolve from a newfangled technology to \nsomething baked into everyone’s job. “A.I. will be across many roles, and it will be so ingrained that the specific A.I. \njob title will start to go away,” she said.\nSome chief A.I. officers said their job had staying power. Dr. Patel of the Mayo Clinic in Arizona said a large part of \nhis new job was to communicate with other doctors and regulators like the Food and Drug Administration and to \nidentify how A.I. can make medical work more efficient.\n“Modern-day health care still has a lot of gaps,” he said. “This is where I think we can smartly use artificial \nintelligence to bridge that gap, or at least reduce that.”\nThis article appeared in print on page BU1, BU7.\nLoad-Date: February 8, 2024\nHottest Job in Corporate America ? The Executive in Charge of A.I."
    },
    {
        "file_name": "Friedman_May2023",
        "header": "We Are Opening the Lids on Two Giant Pandora’s Boxes; Thomas L.",
        "media": "Friedman",
        "time": "May 9, 2023",
        "section": "OPINION",
        "length": "1626 words",
        "byline": "Thomas L. Friedman",
        "story_text": "We Are Opening the Lids on Two Giant Pandora’s Boxes; Thomas L. \nFriedman\nThe New York Times \nMay 2, 2023 Tuesday 23:04 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: OPINION\nLength: 1626 words\nByline: Thomas L. Friedman\nHighlight: Social media illustrated some of the perils of unchecked technology.\nBody\nMerriam-Webster notes that a “Pandora’s box” can be “anything that looks ordinary but may produce unpredictable \nharmful results.” I’ve been thinking a lot about Pandora’s boxes lately, because we Homo sapiens are doing \nsomething we’ve never done before: lifting the lids on two giant Pandora’s boxes at the same time, without any idea \nof what could come flying out.\nOne of these Pandora’s boxes is labeled “artificial intelligence,” and it is exemplified by the likes of ChatGPT, Bard \nand AlphaFold, which testify to humanity’s ability for the first time to manufacture something in a godlike way that \napproaches general intelligence, far exceeding the brainpower with which we evolved naturally.\nThe other Pandora’s box is labeled “climate change,” and with it we humans are for the first time driving ourselves \nin a godlike way from one climate epoch into another. Up to now, that power was largely confined to natural forces \ninvolving Earth’s orbit around the sun.\nFor me the big question, as we lift the lids simultaneously, is: What kind of regulations and ethics must we put in \nplace to manage what comes screaming out?\nLet’s face it, we did not understand how much social networks would be used to undermine the twin pillars of any \nfree society — truth and trust. So if we approach generative A.I. just as heedlessly — if we again go along with \nMark Zuckerberg’s reckless mantra at the dawn of social networks, “move fast and break things” — oh, baby, we \nare going to break things faster, harder and deeper than anyone can imagine.\n“There was a failure of imagination when social networks were unleashed and then a failure to responsibly respond \nto their unimagined consequences once they permeated the lives of billions of people,” Dov Seidman, the founder \nand chairman of the HOW Institute for Society and LRN, told me. “We lost a lot of time — and our way — in utopian \nthinking that only good things could come from social networks, from just connecting people and giving people a \nvoice. We cannot afford similar failures with artificial intelligence.”\nSo there is “an urgent imperative — both ethical and regulatory — that these artificial intelligence technologies \nshould only be used to complement and elevate what makes us uniquely human: our creativity, our curiosity and, at \nour best, our capacity for hope, ethics, empathy, grit and collaborating with others,” added Seidman (a board \nmember of the museum my wife founded, Planet Word).\n “The adage that with great power comes great responsibility has never been more true. We cannot afford another \ngeneration of technologists proclaiming their ethical neutrality and telling us, ‘Hey, we’re just a platform,’ when these \nWe Are Opening the Lids on Two Giant Pandora ’s Boxes Thomas L. Friedman\nA.I. technologies are enabling exponentially more powerful and profound forms of human empowerment and \ninteraction.”\nFor those reasons, I asked James Manyika, who heads Google’s technology and society team, as well as Google \nResearch, where much of its A.I. innovation is conducted, for his thinking on A.I.’s promise and challenge.\n“We have to be bold and responsible at the same time,” he said.\n“The reason to be bold is that in so many different realms A.I. has the potential to help people with everyday tasks, \nand to tackle some of humanity’s greatest challenges — like health care, for instance — and make new scientific \ndiscoveries and innovations and productivity gains that will lead to wider economic prosperity.”\nIt will do so, he added, “by giving people everywhere access to the sum of the world’s knowledge — in their own \nlanguage, in their preferred mode of communication, via text, speech, images or code,” delivered by smartphone, \nthrough television, radio or e-book. A lot more people will be able to get the best assistance and the best answers \nto improve their lives.\nBut we also must be responsible, Manyika added, citing several concerns. First, these tools need to be fully aligned \nwith humanity’s goals. Second, in the wrong hands, these tools could do enormous harm, whether we are talking \nabout disinformation, perfectly faked things or hacking. (Bad guys are always early adopters.)\nFinally, “the engineering is ahead of the science to some degree,” Manyika explained. That is, even the people \nbuilding these so-called large language models that underlie products like ChatGPT and Bard don’t fully understand \nhow they work and the full extent of their capabilities. We can engineer extraordinarily capable A.I. systems, he \nadded, that can be shown a few examples of arithmetic, a rare language or explanations of jokes and that then can \nstart to do many more things with just those fragments astonishingly well. In other words, we don’t fully understand \nyet how much more good stuff or bad stuff these systems can do.\nSo, we need some regulation, but it needs to be done carefully and iteratively. One size will not fit all.\nWhy? Well, if you are most worried about China beating America in A.I., you want to turbocharge our A.I. \ninnovation, not slow it down. If you want to truly democratize A.I., you might want to open-source its code. But \nopen-sourcing can be exploited. What would ISIS do with the code? So, you have to think about arms control. If you \nare worried that A.I. systems will compound discrimination, privacy violations and other divisive societal harms, the \nway social networks do, you want regulations now.\nIf you want to take advantage of all the productivity gains A.I. is expected to generate, you need to focus on \ncreating new opportunities and safety nets for all the paralegals, researchers, financial advisers, translators and \nrote workers who could be replaced today, and maybe lawyers and coders tomorrow. If you are worried that A.I. will \nbecome superintelligent and start defining its own goals, irrespective of human harm, you want to stop it \nimmediately.\nThat last danger is real enough that on Monday Geoffrey Hinton, one of the pioneering designers of A.I. systems, \nannounced that he was leaving Google’s A.I. team. Hinton said that he thought Google was behaving responsibly in \nrolling out its A.I. products but that he wanted to be free to speak out about all the risks. “It is hard to see how you \ncan prevent the bad actors from using it for bad things,” Hinton told The Times’s Cade Metz.\nAdd it all up and it says one thing: We as a society are on the cusp of having to decide on some very big trade-offs \nas we introduce generative A.I.\nAnd government regulation alone will not save us. I have a simple rule: The faster the pace of change and the more \ngodlike powers we humans develop, the more everything old and slow matters more than ever — the more \neverything you learned in Sunday school, or from wherever you draw ethical inspiration, matters more than ever.\nWe Are Opening the Lids on Two Giant Pandora ’s Boxes Thomas L. Friedman\nBecause the wider we scale artificial intelligence, the more the golden rule needs to scale: Do unto others as you \nwould wish them to do unto you. Because given the increasingly godlike powers we’re endowing ourselves with, we \ncan all now do unto each other faster, cheaper and deeper than ever before.\nDitto when it comes to the climate Pandora’s box we’re opening. As NASA explains on its website, “In the last \n800,000 years, there have been eight cycles of ice ages and warmer periods.” The last ice age ended some 11,700 \nyears ago, giving way to our current climate era — known as the Holocene (meaning “entirely recent”) — which was \ncharacterized by stable seasons that allowed for stable agriculture, the building of human communities and \nultimately civilization as we know it today.\n“Most of these climate changes are attributed to very small variations in Earth’s orbit that change the amount of \nsolar energy our planet receives,” NASA notes.\nWell, say goodbye to that. There is now an intense discussion among environmentalists — and geological experts \nat the International Union of Geological Sciences, the professional organization responsible for defining Earth’s \ngeological/climate eras — about whether we humans have driven ourselves out of the Holocene into a new epoch, \ncalled the Anthropocene.\nThat name comes “from ‘anthropo,’ for ‘man,’ and ‘cene,’ for ‘new’ — because humankind has caused mass \nextinctions of plant and animal species, polluted the oceans and altered the atmosphere, among other lasting \nimpacts,” an article in the Smithsonian magazine explained.\nEarth system scientists fear that this man-made epoch, the Anthropocene, will have none of the predictable \nseasons of the Holocene. Farming could become a nightmare.\nBut here is where A.I. could be our savior — by hastening breakthroughs in material science, battery density, fusion \nenergy and safe modular nuclear energy that enable humans to manage the impacts of climate change that are \nnow unavoidable and to avoid those that would be unmanageable.\nBut if A.I. gives us a way to cushion the worst effects of climate change — if A.I., in effect, gives us a do-over — we \nhad better do it over right. That means with smart regulations to rapidly scale clean energy and with scaled \nsustainable values. Unless we spread an ethic of conservation — a reverence for wild nature and all that it provides \nus free, like clean air and clean water — we could end up in a world where people feel entitled to drive through the \nrainforest now that their Hummer is all-electric. That can’t happen.\nBottom line: These two big Pandora’s boxes are being opened. God save us if we acquire godlike powers to part \nthe Red Sea but fail to scale the Ten Commandments.\nThe Times is committed to publishing a diversity of letters to the editor. We’d like to hear what you think about this \nor any of our articles. Here are some tips. And here’s our email: letters@nytimes.com.\nFollow The New York Times Opinion section on Facebook, Twitter (@NYTopinion) and Instagram.\nThis article appeared in print on page A19.\nLoad-Date: May 9, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "A.I. May Help Design Your Favorite Video Game Character",
        "media": "The New York Times",
        "time": "May 22, 2023",
        "section": "ARTS",
        "length": "1552 words",
        "byline": "Shannon Liao",
        "story_text": "A.I. May Help Design Your Favorite Video Game Character\nThe New York Times \nMay 22, 2023 Monday 23:40 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: ARTS\nLength: 1552 words\nByline: Shannon Liao\nHighlight: Generative A.I. is already changing how games are made, with Blizzard Entertainment training an \nimage generator on assets from World of Warcraft, Diablo and Overwatch.\nBody\nGenerative A.I. is already changing how games are made, with Blizzard Entertainment training an image generator \non assets from World of Warcraft, Diablo and Overwatch.\nIntrigued by the potential that generative artificial intelligence holds for video game design, the studio Blizzard \nEntertainment has trained an image generator on its own hit titles. By feeding assets like the combative orcs of \nWorld of Warcraft, the macabre dungeons of Diablo and the vivacious heroes of Overwatch into the machine, \nBlizzard can effortlessly produce concept art for new ideas.\nBecause generative artificial intelligence creates art faster than any human can, studios like Blizzard, a division \nof Activision Blizzard, are hopeful that the technology can cut out some design and development drudgery and \nmake the creation of video games more fun.\nBlizzard’s chief design officer, Allen Adham, told employees about the initiative last month in an email that was \nobtained by The New York Times. Its internal tool is called Blizzard Diffusion, a riff on Stable Diffusion, one of the \npopular image generators that enables anyone to turn text into art.\n“Prepare to be amazed,” Adham wrote, adding, “We are on the brink of a major evolution in how we build and \nmanage our games.”\nGenerative artificial intelligence, the technology behind tools like ChatGPT and Midjourney, uses considerable \ncomputing power to identify patterns in text or images and produce new content from the data.\nSome researchers are wary of the technology, warning of copyright abuses, job displacement, and its potential to \nhelp the spread of false information. But video game developers, already relying on artificial intelligence so that \nnonplayer characters can make humanlike decisions, believe that harnessing generative A.I. can speed up the \ncreative process in a labor-intensive industry plagued by delays.\nThere is a gaming A.I. division at Microsoft, which makes the Xbox console, and Ubisoft has built a tool called \nGhostwriter that could produce basic dialogue for games like Assassin’s Creed. Several start-ups say their \ntechnology can make it easier to design the look of the nonplayer characters, known as NPCs, that give video game \nworlds heft.\nChris Lee, the former studio head of Halo Infinite at 343 Industries, said generative A.I. could improve game \ndevelopment by reducing the human toil required to make an enormous open-world game.\nA.I. May Help Design Your Favorite Video Game Character\n“Game developers have never been able to keep up with the demands of our audiences,” said Lee, who is now the \nhead of immersive technologies at Amazon Web Services.\nHalo Infinite was supposed to be the flagship launch game for the Xbox Series X in 2020, but its graphics were \nderided by fans as flat and ugly after an eight-minute preview was released. The studio ultimately delayed the game \nfor another year.\nThe game’s developers were miserable, Lee said, because even working on place-holder encounters required \nslowly moving pixels frame by frame. “To load this giant world, it’s painful, it’s like specialized data entry,” he said.\nGenerative A.I. could also streamline quality assurance testing. At a recent conference for game developers, Kate \nRayner, technical director for the Coalition, the studio behind Gears of War, talked about how A.I. could be used to \ncatch bugs and glitches so players would see fewer crashes on launch day.\nMany of the promises of generative A.I. are speculative, with Blizzard already abandoning machine-learning \ntechnology it had patented to create environmental textures like stone and brick.\nAndrew Guerrero, Blizzard’s vice president of global insights, said the tool was taking up too much artist time to be \neffective. But he said another A.I. tool was helping fit cosmetic headpieces to player models in World of Warcraft.\n“The goal is to remove a repetitive and manual process and enable artists to spend more time on creativity,” \nGuerrero said in a statement. “Our goal with A.I. has been, and will continue to be, to try to make creative work \neasier.”\nThe internal email about Blizzard Diffusion said it was being used to help generate concept art for game \nenvironments as well as characters and their outfits. It also mentioned possible tools for “autonomous, intelligent, \nin-game NPCs,” “procedurally assisted level design” and A.I.-assisted “voice cloning,” “game coding” and “anti-\ntoxicity.”\nGhostwriter, Ubisoft’s A.I. dialogue tool, was a request by writers who faced the daunting and sometimes tedious \ntask of filling open-world games with more than 100,000 lines of dialogue, the company said.\nMany of those lines are the background chatter of characters that help simulate a living world; one mundane \ninteraction may require a dozen or more variations.\nIn a promotional video for Ghostwriter, an employee begins with the prompt “I used to be an adventurer like you” (a \nnod to an infamous line in Skyrim) and hones several suggestions by the A.I., including “I was once the most \ntalented and famous adventurer in the land” and “I remember when I was young and strong.”\nThese simple lines of dialogue have been a way for people to start careers in video game writing, and developers \nargued on social media that automating these tasks could threaten such jobs. Simon Johnson, an economist at the \nM.I.T. Sloan School of Management who has a new book about the impact of automation, said it was a bad idea for \ntech companies to invent algorithms that mimic humans.\n“We should be focused on machines that help humans improve human capabilities, rather than displacing people,” \nhe said.\nYves Jacquier, the executive director of Ubisoft La Forge, the research and development team responsible for \nGhostwriter, said there had been a similar but unfounded fear that video game animators would be replaced when \nmotion capture was introduced decades ago.\n“While the future may involve more technology, it doesn’t take away the human in the loop,” Jacquier said in a \nstatement. “Artists, writers and coders will always be at the heart of the development process, and while A.I. can \nnow do a better job at assisting creators in their workflow, it’s the artistic vision and perspective of individuals that \nare essential in the creation of games.”\nA.I. May Help Design Your Favorite Video Game Character\nAnother inescapable concern about A.I.-produced content is copyright. In one high-profile lawsuit, Getty Images has \naccused Stable Diffusion of scraping 12 million images from its photo database.\nEmployees of Activision Blizzard received an email this month from Michael Vance, its chief technology officer, that \nwarned them not to use the company’s intellectual property with external image generators. (Microsoft is looking to \npurchase Activision for nearly $70 billion, but regulators want to block the deal.)\n“These new tools come with new and unknown risks, and we will proceed carefully to avoid pitfalls,” Vance wrote in \nthe email, which was obtained by The Times.\nSome Activision Blizzard employees said the company’s A.I. tools have not always delivered as promised, pointing \nto those that struggled to catch bugs or interact properly with game environments.\n“Leadership’s focus on A.I. doesn’t feel like it is solving a problem that individual contributors care about,” said \nValentine Powell, a former World of Warcraft engineer who left Blizzard last August. “It feels like ignoring their \nproblems and focusing on hype words that they think will sound impressive to shareholders.”\nSmaller video game studios that do not have the resources to create generative A.I. tools are turning to start-ups \nfor help.\nScenario, which raised $6 million in seed funding in January, creates image databases to turn text prompts into \nassets — such as a lizard in a spacesuit — that can then be incorporated into games.\nIts image generator is being used by a few small games. In tests by The Times, it sometimes spit out animated \ncharacters with unrealistic-looking hands, a common weakness for image generators.\nAnother start-up, Didimo, said that Soleil Game Studios, which makes fighting games based on properties like \nNaruto and Samurai Jack, had created hundreds of nonplayer characters using its A.I.-powered generator.\n“We just automated that process, allowing them to remove the mundane jobs, because it just gets boring after a \nwhile,” Sean Cooper, a Didimo developer, said.\nVideo games can take years to create, and it is early enough in the hype cycle that few published games have used \ngenerative A.I. But some companies like Niantic, the developer behind Pokémon Go, have experimented with the \ntools to create marketing materials, for instance writing a news release in Dr. Seuss’s tone of voice.\nNiantic also used ChatGPT while working on Peridot, a new augmented reality game that leverages ’90s nostalgia \nfor digital pets.\nKellee Santiago, Niantic’s head of production, said that it was expensive to fill a room with creative people, and that \nthe technology condensed the time needed to generate ideas.\n“I, for one, am happy to have the first six hours of a brainstorm taken care of for me,” she said.\nPHOTOS: Blizzard Entertainment, the producer of World of Warcraft Classic, above, trains an image generator on \nits games to create concept art for new ones. The start-up Didimo uses a character generator to create supporting \nplayers like the ogre below. (PHOTOGRAPHS BY BLIZZARD ENTERTAINMENT; DIDIMO) This article appeared in \nprint on page C2.\nLoad-Date: May 22, 2023"
    },
    {
        "file_name": "Newsletter_May2023",
        "header": "The Optimist’s Guide to Artificial Intelligence and Work; DealBOok",
        "media": "Newsletter",
        "time": "May 30, 2023",
        "section": "BUSINESS; dealbook",
        "length": "1578 words",
        "byline": "Sarah Kessler and Ephrat Livni",
        "story_text": "The Optimist’s Guide to Artificial Intelligence and Work; DealBOok \nNewsletter\nThe New York Times \nMay 20, 2023 Saturday 09:06 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS; dealbook\nLength: 1578 words\nByline: Sarah Kessler and Ephrat Livni\nHighlight: The focus of much discussion is on how it will replace jobs, but nothing is inevitable.\nBody\nThe focus of much discussion is on how it will replace jobs, but nothing is inevitable.\nIt’s easy to fear that the machines are taking over: Companies like IBM and the British telecommunications \ncompany BT have cited artificial intelligence as a reason for reducing head count, and new tools like ChatGPT and \nDALL-E make it possible for anyone to understand the extraordinary abilities of artificial intelligence for themselves. \nOne recent study from researchers at OpenAI (the start-up behind ChatGPT) and the University of Pennsylvania \nconcluded that for about 80 percent of jobs, at least 10 percent of tasks could be automated using the technology \nbehind such tools.\n“Everybody I talk to, supersmart people, doctors, lawyers, C.E.O.s, other economists, your brain just first goes to, \n‘Oh, how can generative A.I. replace this thing that humans are doing?’” said Erik Brynjolfsson, a professor at the \nStanford Institute for Human-Centered AI.\nBut that’s not the only option, he said. “The other thing that I wish people would do more of is think about what new \nthings could be done now that was never done before. Obviously that’s a much harder question.” It is also, he \nadded, “where most of the value is.”\nHow technology makers design, business leaders use and policymakers regulate A.I. tools will determine how \ngenerative A.I. ultimately affects jobs, Brynjolfsson and other economists say. And not all the choices are \nnecessarily bleak for workers.\nA.I. can complement human labor rather than replace it. Plenty of companies use A.I. to automate call centers, for \ninstance. But a Fortune 500 company that provides business software has instead used a tool like ChatGPT to give \nits workers live suggestions for how to respond to customers. Brynjolfsson and his co-authors of a study compared \nthe call center employees who used the tool to those who didn’t. They found that the tool boosted productivity by 14 \npercent on average, with most of the gains made by low-skilled workers. Customer sentiment was also higher and \nemployee turnover lower in the group that used the tool.\nDavid Autor, a professor of economics at the Massachusetts Institute of Technology, said that A.I. could potentially \nbe used to deliver “expertise on tap” in jobs like health care delivery, software development, law, and skilled repair. \n“That offers an opportunity to enable more workers to do valuable work that relies on some of that expertise,” he \nsaid.\nWorkers can focus on different tasks. As A.T.M.s automated the tasks of dispensing cash and taking deposits, the \nnumber of bank tellers increased, according to an analysis by James Bessen, a researcher at the Boston University \nSchool of Law. This was partly because while bank branches required fewer workers, they became cheaper to open \nThe Optimist’s Guide to Artificial Intelligence and Work DealBOok Newsletter\n— and banks opened more of them. But banks also changed the job description. After A.T.M.s, tellers focused less \non counting cash and more on building relationships with customers, to whom they sold products like credit cards. \nFew jobs can be completely automated by generative A.I. But using an A.I. tool for some tasks may free up \nworkers to expand their work on tasks that can’t be automated.\nNew technology can lead to new jobs. Farming employed nearly 42 percent of the work force in 1900, but because \nof automation and advances in technology, it accounted for just 2 percent by 2000. The huge reduction in farming \njobs didn’t result in widespread unemployment. Instead, technology created a lot of new jobs. A farmer in the early \n20th century would not have imagined computer coding, genetic engineering or trucking. In an analysis that used \ncensus data, Autor and his co-authors found that 60 percent of current occupational specialties did not exist 80 \nyears ago.\nOf course, there’s no guarantee that workers will be qualified for new jobs, or that they’ll be good jobs. And none of \nthis just happens, said Daron Acemoglu, an economics professor at M.I.T. and a co-author of “Power and Progress: \nOur 1,000-Year Struggle Over Technology &amp; Prosperity.”\n“If we make the right choices, then we do create new types of jobs, which is crucial for wage growth and also for \ntruly reaping the productivity benefits,” Acemoglu said. “But if we do not make the right choices, much less of this \ncan happen.” — Sarah Kessler\nIN CASE YOU MISSED IT \nMartha’s model behavior. The lifestyle entrepreneur Martha Stewart became the oldest person to be featured on the \ncover of Sports Illustrated’s swimsuit issue this week. Stewart, 81, told The Times that it was a “large challenge” to \nhave the confidence to pose but that two months of Pilates had helped. She isn’t the first person over 60 to have \nthe distinction: Maye Musk, the mother of Elon Musk, graced the cover last year at the age of 74.\nTikTok block. Montana became the first state to ban the Chinese short video app, barring app stores from offering \nTikTok within its borders starting Jan. 1. The ban is expected to be difficult to enforce, and TikTok users in the state \nhave sued the government, saying the measure violates their First Amendment rights and giving a glimpse of the \npotential blowback if the federal government tries to block TikTok nationwide.\nBanker blame game. Greg Becker, the ex-C.E.O. of Silicon Valley Bank, blamed “rumors and misconceptions” for a \nrun on deposits in his first public comments since the lender collapsed in March. Becker and former top executives \nof the failed Signature Bank also told a Senate committee investigating their role in the collapse of the banks that \nthey would not give back millions of dollars in pay.\nA brief history of tech C.E.O.s seeking constraints \nWhen OpenAI’s chief executive, Sam Altman, testified in Congress this week and called for regulation of \ngenerative artificial intelligence, some lawmakers hailed it as a “historic” move. In fact, asking lawmakers for new \nrules is a move straight out of the tech industry playbook. Silicon Valley’s most powerful executives have long gone \nto Washington to demonstrate their commitment to rules in an attempt to shape them while simultaneously \nunleashing some of the world’s most powerful and transformative technologies without pause.\nOne reason: A federal rule is much easier to manage than different regulations in different states, Bruce Mehlman, \na political consultant and former technology policy official in the Bush administration, told DealBook. Clearer \nregulations also give investors more confidence in a sector, he added.\nThe strategy sounds sensible, but if history is a useful guide, the reality can be messier than the rhetoric:\n• In December 2021, Sam Bankman-Fried, founder of the failed crypto exchange FTX, was one of six \nexecutives to testify about digital assets in the House and call for regulatory clarity. His company had just \nsubmitted a proposal for a “unified joint regime,” he told lawmakers. A year later, Bankman-Fried’s \nbusinesses were bankrupt, and he was facing criminal fraud and illegal campaign contribution charges.\nThe Optimist’s Guide to Artificial Intelligence and Work DealBOok Newsletter\n• In 2019, Facebook founder Mark Zuckerberg wrote an opinion piece in The Washington Post, “The Internet \nNeeds New Rules,” based on failures in content moderation, election integrity, privacy and data \nmanagement at the company. Two years later, independent researchers found that misinformation was \nmore rampant on the platform than in 2016, even though the company had spent billions trying to stamp it \nout.\n• In 2018, the Apple chief Tim Cook said he was generally averse to regulation but supported more strict data \nprivacy rules, saying, “It’s time for a set of people to think about what can be done.” But to maintain its \nbusiness in China, one of its biggest markets, Apple has largely ceded control of customer data to the \ngovernment as part of its requirements to operate there.\nBuzzword of the week: ‘Algospeak’ \nPlatforms like TikTok, Facebook, Instagram and Twitter use algorithms to identify and moderate problematic \ncontent. To avert these digital moderators and allow free exchange about taboo topics, a linguistic code has \ndeveloped. It’s called “algospeak.”\n“A linguistic arms race is raging online — and it isn’t clear who’s winning,” writes Roger J. Kreuz, a psychology \nprofessor at the University of Memphis. Posts about sensitive issues like politics, sex or suicide can be flagged by \nalgorithms and taken down, leading to the use of creative misspellings and stand-ins, like “seggs” and “mascara” for \nsex, “unalive” for death and “cornucopia” for homophobia. There is a history of responding to prohibitions with code, \nKruz notes, such as 19th-century Cockney rhyming slang in England or “Aesopian,” an allegorical language used to \ncircumvent censorship in Tsarist Russia.\nAlgorithms aren’t alone in not picking up on the code. The euphemisms and misspellings are particularly ubiquitous \namong marginalized communities. But the hidden language also sometimes eludes humans, leading to potentially \nfraught miscommunications online. In February, the celebrity Julia Fox found herself in an awkward exchange with \na victim of sexual assault after misunderstanding a post about “mascara” and had to issue a public apology for \nresponding inappropriately to what she thought was a discussion about makeup.\nThanks for reading!\nWe’d like your feedback. Please email thoughts and suggestions to dealbook@nytimes.com.\nPHOTO: Sam Altman, chief executive of OpenAI, testified before a Senate subcommittee last week. \n(PHOTOGRAPH BY WIN MCNAMEE/GETTY IMAGES) This article appeared in print on page B4.\nLoad-Date: May 30, 2023"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Oct2023",
        "header": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery",
        "media": "The New York Times - International Edition",
        "time": "October 2, 2023",
        "section": "TECHNOLOGY",
        "length": "1089 words",
        "byline": "Yiwen Lu",
        "story_text": "To Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe New York Times - International Edition\nOctober 3, 2023 Tuesday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1089 words\nByline: Yiwen Lu\nDateline: SAN FRANCISCO \nBody\nInstagram, Facebook, Snapchat and several newcomers are betting on artificial intelligence to rejuvenate the fun, \ninteractivity and whimsy of creating and sharing images.       \nMyuri Thiruna, a freelance photographer in Toronto, used to post frequently on Instagram and discuss photography \nwith other users. But she said she had stopped two years ago, feeling \"drained\" by the demands of social media \nand the pursuit of followers and trends.       \nThen in July, Ms. Thiruna discovered Can of Soup, a new invitation-only social network where people make \nfantastical images of themselves with artificial intelligence and share the images with others. Enthralled by those \nabilities, she created A.I. images that showed her sitting on a unicorn floating in an ocean and her wearing a jacket \nmade of Froot Loops.       \nMs. Thiruna, 33, also commented on other users' posts, chatting with them and making images together. She now \nspends as much five hours a day interacting with others on the app, she said.       \n\"I met so many people on this app that I didn't know before, and it goes beyond just posting and getting the likes,\" \nshe said. \"It's this meaningful connection with people and being also inspired by what they're doing.\"       \nSocial networking apps are beginning to integrate A.I. into their image capabilities to make their platforms more \nsocial. After Facebook, Instagram and other apps have become more corporate over the years, A.I. imagery \npresents a way for them to bring back the whimsy and fun so users can rediscover what was once the point of the \nplatforms: to share and interact with one another.       \nLarge social platforms and new apps alike are incorporating A.I. image features. Last month, Snapchat announced \nDreams, an A.I. imaging feature that lets users in Britain, Australia and New Zealand create outlandish selfies. \nTikTok last year rolled out several in-app filters that use A.I. to transform selfies into the style of a comic or a \ndreamlike character. BeFake, a social app launched in August, is also experimenting with A.I. selfies and images.       \nOn Wednesday, Facebook, Instagram, WhatsApp and Messenger jumped in as well. Meta, which owns the apps, \nsaid the services would now offer A.I. tools for instantly generating photorealistic \"stickers,\" which can be shared. It \nadded that it would introduce similar tools for editing and restyling existing images. These tools could put cowboy \nboots on two babies in a family photo, for instance.       \n\"You can generate imagery inside of your chats,\" said Ahmad Al-Dahle, Meta's vice president of generative A.I. \nWhile most image-generation tools need 10 to 20 seconds to create an image, he added, Meta's new tool needs \nonly five.       \nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nThe growing number of A.I. imagery tools in various apps underlines how \"using A.I. interactively is where social \nmedia will go,\" said Sam Saliba, who was Instagram's global brand marketing lead and is now a marketing and \nbranding consultant in Silicon Valley.       \nThe trend takes A.I. images further than the apps that allowed people to produce A.I.-generated images without \nconversing or easily sharing them in an online community. Those apps included Lensa AI - which let people create \nA.I. selfies in styles like \"cosmic,\" \"fairy princess\" and \"anime\" - as well as Remini, Snow and Wombo. Interest in \nthose apps peaked in mid-December, and downloads have since declined, according to the market intelligence firm \nApptopia.       \nBen-Zion Benkhin, the founder of Wombo, said many people didn't stick with A.I. apps that were merely a \"creation \ntool\" and that gave users no ability to chat with one another about what they had produced.       \n\"All of these apps are very limited,\" he said. Adding social networking, he said, \"does connect you to the other \npeople.\"       \nThat understanding has helped drive new apps like BeFake, which has melded A.I. image features with socializing \nand sharing. BeFake prompts users at a different time every day to take a picture with their smartphone's front and \nback cameras and then has A.I. transform the image.       \nUsers need to share their posts before viewing other people's posts. The concept was borrowed from BeReal, a \nphoto-sharing app that has been popular among young users.       \nBeFake connects people through their creativity, said Kristen Garcia Dumont, one of the app's founders. \"What that \nmeans to each person is unique and intriguing, and you get to explore that with whoever you want in the app,\" she \nsaid.       \nBeFake's parent company has raised $3 million, and the app has tens of thousands of users, said Ms. Dumont and \nher co-founder, Tracy Lane.       \nHayley Fligel, 17, a high school student in Burlingame, Calif., said she began using BeFake in July after a friend \ninvited her to join. It's different from apps like Snapchat, TikTok and Instagram, which are stressful because \"if you \nwant to take pictures or videos of yourself, you have to get ready, you have to get dressed, and you have to be \ndoing something or have a nice background around you,\" she said.       \nShe said she could use A.I. on BeFake to make herself look like Taylor Swift or appear that she was playing \nvolleyball, which shows \"a more personal snippet of who you are.\" While she seldom interacts with others on \nInstagram, she said, she comments on her friends' posts on BeFake and browses a \"Discovery\" feed for inspiration \nfrom other posts.       \nGabriel Birnbaum, who created Can of Soup with Eric Meier in May, said the point was to encourage creation and \nhave fun. \"It's an app where you spend time with your friends,\" he said.       \nSince then, he said, he has seen many creative and social moments happen in the app. In particular, a feature \ncalled Stir - which lets users put themselves in scenarios that someone else created - makes up one in four posts \non the platform, Mr. Birnbaum said, with people inserting themselves into an A.I. image of Einstein inside a black \nhole in space, for example.       \nMr. Birnbaum, who declined to disclose Can of Soup's funding and number of users, said he didn't plan to roll out \nthe app widely until it had the \"right trust and safety\" with users comfortable with the content and whom they create \nphotos with.       \n\"I like the creation aspect and people liking my work and interacting with them,\" said Alex Rosenblatt, 35, of San \nFrancisco, who has used Can of Soup since June. \"Most of my interactions on it are with people I don't know, \nactually.\"       \nTo Bring Socializing Back to Social Networks, Apps Try A.I. Imagery\nCade Metz contributed reporting.       \nCade Metz contributed reporting. \nLoad-Date: October 2, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Yellow.ai deploys 30% of global generative AI bots domestically",
        "media": "The Economic Times",
        "time": "January 23, 2024",
        "section": "TECH & INTERNET",
        "length": "544 words",
        "byline": "Annapurna Roy",
        "story_text": "Yellow.ai deploys 30% of global generative AI bots domestically\nThe Economic Times\nJanuary 23, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 544 words\nByline: Annapurna Roy\nBody\nAdoption of generative artificial intelligence for customer engagement is picking up pace in India.For instance, \nconversational AI company Yellow.ai, which deployed around 120 GenAI bots for businesses worldwide this \nfinancial year, saw about 30% of these deployed in India.While markets like the US are mostly using GenAI for \ncustomer support in a bid to cut costs, India Inc. is using them as an opportunity to grow revenues, generate \nbusiness leads and sales support, Yellow.ai cofounder and chief executive Raghu Ravinutala told ET.Founded in \n2016 in Bengaluru, Yellow.ai is backed by Sapphire Ventures, Westbridge Capital, Salesforce Ventures and \nLightspeed Venture Partners, among investors. It has raised about $102 million in funding so far, as per \nTracxn.Among its clients, Bajaj Auto Finance has generated over 100 leads using the San Mateo, California-\nheadquartered company’s GenAI chatbot, and a leading non-banking financier saw over 400 auto-loan applications, \nRavinutala noted. \nA top two-wheeler maker sold motorcycles worth about Rs 1 crore in the first day of launch through the GenAI \nassistant while a leading finance company secured potential customers or sales leads worth about $100 \nmillion.Ravinutala said Yellow.ai is considering a public listing in the US by 2026-27 by when the market is expected \nto recover from the current subdued macroeconomic climate. The company expects to turn profitable this \nyear.Yellow.ai has been witnessing a surge in demand for its GenAI offerings since the quarter ended October. At \nthe time, it rolled out around 100 bots across financial services, travel, retail and ecommerce, and technology \nsectors. The company follows the February to January period as its financial year.“Q4 (the quarter ending January) \nis the largest quarter we are ever having for India in terms of platform ARR (annual recurring revenue) and India is \nalso leading in terms of the GenAI adoption on the Yellow.ai platform,” Ravinutala said.The company expects the \nIndian market to grow more than 60% next year, when revenue from India is expected to be $20-30 million with the \noverall global revenue at $60-70 million run rate. It is currently at a $30-40 million revenue run rate globally, growing \nat 60-70% annually. In FY25, it expects revenue to double.According to research by Adobe, most companies in \nIndia are cutting marketing and customer experience budgets, with 42% having done so and 37% planning to do so \nover the next year. Nearly 60% plan to deploy GenAI in these areas.The global macroeconomic slowdown coupled \nwith companies’ increased urgency to adopt GenAI has created growth opportunities for Yellow.ai. “They \n(customers) are looking at cutting costs, and our core value proposition is reducing cost and customer support by \nreplacing agents and humans through automation,” Ravinutala said.Automation and efficiencies from GenAI have \nalso enabled the company to proceed with a measured approach to hiring and employee strength, Ravinutala said. \nThe company cut about 13% of its workforce at the start of 2023. It currently has 680 employees, of which about \n570 are based in India.“Over the next few years, we don't see this (employee strength) going to 1,000-2,000,” \nRavinutala said. For Reprint Rights: timescontent.com\nLoad-Date: January 23, 2024\nYellow.ai deploys 30% of global generative AI bots domestically"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "As A.I. Text Detection Gets Better, So Does A.I. Text",
        "media": "The New York Times",
        "time": "February 27, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 2",
        "length": "1453 words",
        "byline": "By Keith Collins",
        "story_text": "As A.I. Text Detection Gets Better, So Does A.I. Text\nThe New York Times\nFebruary 27, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 2\nLength: 1453 words\nByline: By Keith Collins\nBody\nIn a World of A.I.-Generated Text, How Will We Know What's Real?\nWhen artificial intelligence software like ChatGPT writes, it considers many options for each word, taking into \naccount the response it has written so far and the question being asked. \n  It assigns a score to each option on the list, which quantifies how likely the word is to come next, based on the \nvast amount of human-written text it has analyzed.\n  ChatGPT, which is built on what is known as a large language model, then chooses a word with a high score, and \nmoves on to the next one.\n  The model's output is often so sophisticated that it can seem like the chatbot understands what it is saying -- but it \ndoes not.\n  Every choice it makes is determined by complex math and huge amounts of data. So much so that it often \nproduces text that is both coherent and accurate.\n  But when ChatGPT says something that is untrue, it inherently does not realize it.\n  It may soon become common to encounter a tweet, essay or news article and wonder if it was written by artificial \nintelligence software. There could be questions over the authorship of a given piece of writing, like in academic \nsettings, or the veracity of its content, in the case of an article.\n  There could also be questions about authenticity: If a misleading idea suddenly appears in posts across the \ninternet, is it spreading organically, or have the posts been generated by A.I. to create the appearance of real \ntraction?\n  Tools to identify whether a piece of text was written by A.I. have started to emerge in recent months, including one \ncreated by OpenAI, the company behind ChatGPT. That tool uses an A.I. model trained to spot differences between \ngenerated and human-written text.\n  When OpenAI tested the tool, it correctly identified A.I. text in only about half of the generated writing samples it \nanalyzed. The company said at the time that it had released the experimental detector ''to get feedback on whether \nimperfect tools like this one are useful.''\n  Identifying generated text, experts say, is becoming increasingly difficult as software like ChatGPT continues to \nadvance and turns out text that is more convincingly human. OpenAI is now experimenting with a technology that \nAs A.I. Text Detection Gets Better, So Does A.I. Text\nwould insert special words into the text that ChatGPT generates, making it easier to detect later. The technique is \nknown as watermarking.\n  The watermarking method that OpenAI is exploring is similar to one described in a recent paper by researchers at \nthe University of Maryland, said Jan Leike, the head of alignment at OpenAI. Here is how it works.\n  Imagine a list of every word you know, every unique word you might use when writing an essay, email or text \nmessage.\n  Now imagine that half of those words are on a special list. If you wrote a couple of paragraphs, about half of the \nwords you used would probably be on the special list, statistically speaking.\n  When a language model or chatbot writes, it can insert a watermark by choosing more of the words on the special \nlist than a person would be expected to use.\n  The text here was generated by the researchers at the University of Maryland who wrote the watermarking paper. \nThey used a technique that essentially bumped up the scores of the words on the special list, making the generator \nmore likely to use them.\n  When the generator got to this point in the text, it would have chosen the word ''the.'' But the word ''who'' was on \nthe special list, and its score was artificially increased enough to overtake the word ''the.''\n  When the generator got here, the words ''Tuesday,'' ''Thursday'' and ''Friday'' were on the special list -- but their \nscores were not increased so much that they overtook ''Saturday,'' which was by design. For watermarking to work \nwell, it should not overrule an A.I. on its choice of words when it comes to dates or names, to avoid inserting \nfalsehoods. (Although, in this case, the A.I. was wrong: Ms. Williams's final match was indeed on a Friday.)\n  In the end, about 70 percent of the words in the generated text were on the special list -- far more than would have \nbeen in text written by a person. A detection tool that knew which words were on the special list would be able to tell \nthe difference between generated text and text written by a person.\n  That would be especially helpful for this generated text, as it includes several factual inaccuracies.\n  If someone tried to remove a watermark by editing the text, they would not know which words to change. And even \nif they managed to change some of the special words, they would most likely only reduce the total percentage by a \ncouple of points.\n  Tom Goldstein, a professor at the University of Maryland and co-author of the watermarking paper, said a \nwatermark could be detected even from ''a very short text fragment,'' such as a tweet. By contrast, the detection tool \nOpenAI released requires a minimum of 1,000 characters.\n  Like all approaches to detection, however, watermarking is not perfect, Dr. Goldstein said. OpenAI's current \ndetection tool is trained to identify text generated by 34 different language models, while a watermark detector could \nonly identify text that was produced by a model or chatbot that uses the same list of special words as the detector \nitself.\n  That means that unless companies in the A.I. field agree on a standard watermark implementation, the method \ncould lead to a future where questionable text must be checked against several different watermark detection tools.\n  To make watermarking work well every time in a widely used product like ChatGPT, without reducing the quality of \nits output, would require a lot of engineering, Dr. Goldstein said.\n  Dr. Leike of OpenAI said the company was still researching watermarking as a form of detection, and added that it \ncould complement the current tool, since the two ''have different strengths and weaknesses.''\nAs A.I. Text Detection Gets Better, So Does A.I. Text\n  Still, many experts believe a one-stop tool that can reliably detect all A.I. text with total accuracy may be out of \nreach. That is partly because tools could emerge that could help remove evidence that a piece of text was \ngenerated by A.I. And generated text, even if it is watermarked, would be harder to detect in cases where it makes \nup only a small portion of a larger piece of writing.\n  Experts also say that detection tools, especially those that do not use watermarking, may not recognize generated \ntext if a person has changed it enough.\n  ''I think the idea that there's going to be a magic tool, either created by the vendor of the model or created by an \nexternal third party, that's going to take away doubt -- I don't think we're going to have the luxury of living in that \nworld,'' said David Cox, a director of the MIT-IBM Watson A.I. Lab.\n  Sam Altman, the chief executive of OpenAI, shared a similar sentiment in an interview with StrictlyVC last month.\n  ''Fundamentally, I think it's impossible to make it perfect,'' Mr. Altman said. ''People will figure out how much of the \ntext they have to change. There will be other things that modify the outputted text.''\n  Part of the problem, Dr. Cox said, is that detection tools themselves present a conundrum, in that they could make \nit easier to avoid detection. A person could repeatedly edit generated text and check it against a detection tool until \nthe text is identified as human-written -- and that process could potentially be automated. Detection technology, Dr. \nCox added, will always be a step behind as new language models emerge, and as existing ones advance.\n  ''This is always going to have an element of an arms race to it,'' he said. ''It's always going to be the case that new \nmodels will come out and people will develop ways to detect that it's a fake.''\n  Some experts believe that OpenAI and other companies building chatbots should come up with solutions for \ndetection before they release A.I. products, rather than after. OpenAI launched ChatGPT at the end of November, \nfor example, but did not release its detection tool until about two months later, at the end of January.\n  By that time, educators and researchers had already been calling for tools to help them identify generated text. \nMany signed up to use a new detection tool, GPTZero, which was built by a Princeton University student over his \nwinter break and was released on Jan. 1.\n  ''We've heard from an overwhelming number of teachers,'' said Edward Tian, the student who built GPTZero. As of \nmid-February, more than 43,000 teachers had signed up to use the tool, Mr. Tian said.\n  ''Generative A.I. is an incredible technology, but for any new innovation we need to build the safeguards for it to \nbe adopted responsibly, not months or years after the release, but immediately when it is released,'' Mr. Tian said.\nhttps://www.nytimes.com/2023/02/24/business/in-a-world-of-ai-generated-text-how-will-we-know-whats-real.html\nGraphic\n \nThis article appeared in print on page B2.               \nLoad-Date: February 27, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "Struggling Cruise Cuts About 25 Percent of Its Workers",
        "media": "The New York Times",
        "time": "December 15, 2023",
        "section": "TECHNOLOGY",
        "length": "977 words",
        "byline": "Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San",
        "story_text": "Struggling Cruise Cuts About 25 Percent of Its Workers\nThe New York Times \nDecember 14, 2023 Thursday 01:20 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 977 words\nByline: Tripp Mickle &lt;p&gt;Tripp Mickle reports on Apple and Silicon Valley for The Times and is based in San \nFrancisco. His focus on Apple includes product launches, manufacturing issues and political challenges. He also \nwrites about trends across the tech industry, including layoffs, generative A.I. and robot taxis.&lt;/p&gt; \n&lt;p&gt;&amp;#160;&lt;/p&gt;\nHighlight: The embattled self-driving car subsidiary of General Motors faces an uncertain future after California \nregulators shut down its robot taxi service in the state.\nBody\nThe embattled self-driving car subsidiary of General Motors faces an uncertain future after California regulators shut \ndown its robot taxi service in the state.\nCruise, the embattled self-driving car subsidiary of General Motors, said on Thursday that it would eliminate about \n900 jobs, roughly a quarter of its work force, as the company looked to rein in costs after an October incident led \nCalifornia regulators to shut down its robot taxi operations.\nMost of the job cuts are in corporate and commercial roles, which have become less important since the company \nvoluntarily suspended all its driverless operations across the country in October. The shut down came two days \nafter California’s Department of Motor Vehicles said that the company “misrepresented” its technology and ordered \nCruise to stop operating in the state.\nCruise’s troubles can be traced to an Oct. 2 crash when a car hit a woman at an intersection in San Francisco and \nflung her into the path of one of Cruise’s driverless taxis. The Cruise car dragged the woman some 20 feet before \npulling to the curb, causing severe injuries. Regulators accused Cruise of omitting footage of its car dragging the \nwoman from a video that it provided to state officials.\nThe accident — and its fallout — have called into question the future of the tech and auto industry’s pursuit of self-\ndriving cars. Since Google started working on the first autonomous vehicle more than a decade ago, dozens of \ncompanies have poured tens of billions of dollars into building software and persuading regulators to permit testing \non roads around the country.\nBut many driverless car executives now worry that Cruise’s troubles could lead regulators to increase their \nenforcement and scrutiny of the nascent technology. And financial pressures have been mounting for start-ups that \nsell sensors and other technology to self-driving car companies.\nWaymo, a division of Google’s parent company Alphabet, is still offering a driverless taxi service in San Francisco. \nThe industry’s leaders consider the city to be a critical proving ground for the technology’s potential and the viability \nof the $8 trillion market that it could create.\n“The problem isn’t just the technology, which is a problem,” said Mike Ramsey, an automotive analyst focused on \nthe self-driving car industry at Gartner, a tech research firm. “It’s always been about the business model. There’s \nbeen a desperation for it to make sense to do this, and they still haven’t found a way to justify it.”\nStruggling Cruise Cuts About 25 Percent of Its Workers\nG.M., which bought Cruise in 2016 for $1 billion, has stepped in to steer the self-driving car company forward. In \nNovember, Cruise hired the law firm Quinn Emanuel to investigate the crash and Cruise’s response. The driverless \ncarmaker’s founders, Kyle Vogt and Dan Kan, resigned last month. And yesterday, the company dismissed nine \nsenior executives, including its heads of operations and government affairs.\nInstead of installing a new chief executive, G.M. appointed two presidents who are reporting to its board: Mo \nElshenawy, Cruise’s executive vice president of engineering, and Craig Glidden, G.M.’s general counsel.\nThe company has been preparing employees for layoffs for more than a month; in late October, Mr. Vogt told \nemployees in a companywide meeting that the loss of sales from ceasing operations would result in cuts.\n“We knew this day was coming, but that does not make it any less difficult — especially for those whose jobs are \naffected,” Mr. Elshenawy said in an email to staff on Thursday, which was posted on the company’s website.\nCruise said laid off employees would continue to receive their pay through April 8, have health benefits through May \nand get their 2023 bonuses. News of the dismissals was reported earlier by the tech news site TechCrunch.\nThe layoffs come at the end of a year of cutbacks across the tech industry. Big tech companies including Microsoft \nand Google’s parent company, Alphabet, eliminated tens of thousands of jobs this year as they tried to reduce costs \nafter hiring too many employees during the pandemic.\nWhile most tech businesses have rebounded and begun rebuilding their work forces, the future of Cruise is less \nclear. The company expects Quinn Emanuel to wrap up its report early next year, according to two people familiar \nwith the investigation. The company will make some, if not all, of the report publicly available.\nMr. Vogt, 38, should feature prominently in the law firm’s report. Under his direction, Cruise prioritized rapidly \nexpanding its driverless fleet to beat its top rival, Waymo, into new markets.\nIn April, Cruise began offering driverless taxi rides throughout the day in San Francisco. Its 400 cars quickly racked \nup headlines for a number of issues, including a collision with a fire truck and another incident where a vehicle \ndrove into wet concrete and got stuck.\nIn an interview with The New York Times in September, Mr. Vogt said that Cruise cars created more headlines over \nissues than Waymo because it was operating a bigger fleet.\n“I haven’t seen any evidence suggesting that either company is operating unsafe,” Mr. Vogt said. “I want both of \nthem to exist.”\nEven as Cruise ran into trouble in San Francisco, Mr. Vogt pushed for it to expand. Before his exit, the company \nwas testing cars in Phoenix, Dallas, Houston, Miami and Austin, Texas.\nThe driverless fleet carried enormous costs for G.M. The carmaker has spent an average of $588 million a quarter \non Cruise over the past year, a 42 percent increase from a year ago. Each Chevrolet Bolt that Cruise operated cost \n$150,000 to $200,000, largely because of its array of expensive sensors and computing power.\nCruise hoped to defray its costs by collecting fares from riders in more and more cities. Before it shut down its fleet, \nit had a goal of hitting $1 billion in revenue by 2025.\nThis article appeared in print on page B1, B3.\nLoad-Date: December 15, 2023"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "My Not-So-Perfect Holiday Shopping Excursion With A.I. Chatbots",
        "media": "The New York Times",
        "time": "December 17, 2023",
        "section": "TECHNOLOGY",
        "length": "1275 words",
        "byline": "Yiwen Lu &lt;p&gt;Yiwen Lu reports on technology for The Times.&lt;/p&gt;",
        "story_text": "My Not-So-Perfect Holiday Shopping Excursion With A.I. Chatbots\nThe New York Times \nDecember 14, 2023 Thursday 22:51 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1275 words\nByline: Yiwen Lu &lt;p&gt;Yiwen Lu reports on technology for The Times.&lt;/p&gt;\nHighlight: With Shopify, Mercari and other retailers rolling out chatbots to help buyers, this holiday shopping \nseason is the first to be powered by A.I.\nBody\nWith Shopify, Mercari and other retailers rolling out chatbots to help buyers, this holiday shopping season is the first \nto be powered by A.I.\nTo help with my holiday shopping this year, I recently turned to a new personal assistant online. “I’m looking for a \nChristmas present for my mother, who spends long hours working,” I typed. “Is there something she can use in her \noffice every day?”\n“Of course!” came the instant reply. “Does your mother have any specific preferences or needs for her office? For \nexample, does she need organization tools, desk accessories, or something to help her relax during breaks?”\nSo began my conversation with Shop A.I., a new chatbot from Shopify, an e-commerce marketplace. Over 10 \nminutes, Shop A.I. and I engaged in a question-and-answer session. I told the chatbot my budget and more about \nmy mother, such as her need to alleviate back pain. Shop A.I. also asked me about my mother’s preferred design \nand color for an office chair.\nMore people may eventually replicate this kind of shopping experience. A year after ChatGPT debuted, retailers \naround the world have started rolling out chatbots that are powered by generative artificial intelligence. That \nmakes this holiday season the first when a slew of A.I. chatbots can help shoppers brainstorm and find presents for \ntheir friends and loved ones.\nIn addition to Shopify, chatbots have come out over the past 12 months from Instacart, the delivery company; \nMercari, a resale platform; Carrefour, a retailer; and Kering, which owns Gucci and Balenciaga. Walmart, \nMastercard and Signet Jewelers are also testing chatbots, which may become publicly available as soon as next \nyear.\n“In a way, it’s recreating an in-store environment, but online,” said Carl Rivera, a vice president at Shopify who \noversees its Shop app, which hosts Shop A.I. He said the chatbot broke down people’s questions into key terms \nand searched relevant products from Shopify’s millions of sellers. It then recommends products based on reviews \nand a shopper’s purchase history.\nRetailers have long used chatbots, but previous versions lacked conversational power and typically answered just a \nfew preset questions, such as the status of an order. The newest chatbots, by contrast, can process prompts and \ngenerate tailored answers, both of which create a more “personalized and authentic interaction,” said Jen Jones, \nthe chief marketing officer of the platform Commercetools.\nMy Not-So-Perfect Holiday Shopping Excursion With A.I. Chatbots\nWhether shoppers want this technology remains a question. “Consumers like simplicity, so they don’t necessarily \nwant to have five different generative A.I. tools that they would use for different purposes,” said Olivier Toubia, a \nmarketing professor at Columbia Business School.\nNicola Conway, a lawyer in London, tried Kering’s luxury personal shopper, Madeline, in August to search for a pink \nbridesmaid dress for a spring wedding. Madeline was “intuitive and novel,” she said, but it gave only one \nrecommendation, an Alexander McQueen corset dress. Ms. Conway did not end up buying it.\nKering did not respond to requests for comment.\nMaggie Weber, a shopping influencer who uses the social media handle @refashionedhippie, said she tried \nMercari’s chatbot, Merchat A.I., in May. She asked the chatbot to show her baseball cards, but she was instead \noffered baseballs — and then hats, bats and jerseys.\n“Merchat is still in its infancy,” Ms. Weber, 34, said. She added that she worried that if she gave the chatbot too \nmuch information, it would start directing personalized ads to her.\nA Mercari spokeswoman said Merchat used chat history only to recommend products and did not use personally \nidentifiable information. She added that the search bar could be faster for customers who want a specific item, while \nthe chatbot helped those who want “inspiration for gifts.”\nSuch inspiration was exactly what I needed this season as I had only vague ideas for what to buy my 53-year-old \nmother and my 17-year-old cousin, Jenny.\nSo I tried Shop A.I. After telling the chatbot about my mother’s back pain and asking what I could buy to help her \nrelax, Shop A.I. offered to find an ergonomic chair and asked my budget. When I said $100, it came back with a few \npages of product results.\n“Can you help me to narrow it down?” I typed. Shop A.I. then asked about my preferred color for a chair. I said \nblack.\nShop A.I. returned more than 300 results, including a $159 camp chair from ROAM Adventure, a $179.99 reclining \nmassage office chair from homrest and a $269.99 CosyGaming executive chair.\n“These don’t seem to be under $100,” I wrote, annoyed.\n“As a new chatbot, I’m still learning and sometimes the search results may not be accurate,” Shop A.I. replied. “Let \nme try again and find some black ergonomic chairs within your budget.”\nThen, it added, “It seems that I’m having trouble finding black ergonomic chairs within your budget at the moment.”\nI ended up typing “black ergonomic chair” into the search bar myself and set a $100 price range. A $66.81 Victory \nFurniture gaming chair and a $47.96 massage office chair popped up, though they were too big and heavy to be \ngifts.\nEventually, I asked Shop A.I. for alternative ideas and received five options, including seat cushions and standing \ndesk converters.\nI chose the standing desk converter and gave Shop A.I. my $100 budget. This time, the chatbot showed options \nwithin my price range, including a $99 Risedesk standing desk converter. But most of the products did not have \nreviews, which I rely on while shopping online. I didn’t buy anything.\nShop A.I. was not great at finding a gift for my cousin, either. I wanted to buy Jenny some college dorm decorations \nfeaturing her favorite anime series, Violet Evergarden, which follows a character named Violet as she recovers from \nan unidentified war.\nMy Not-So-Perfect Holiday Shopping Excursion With A.I. Chatbots\nBut Shop A.I. appeared to decide that anything the color violet was connected to my query. It showed me wall art of \npurple mountains and posters of purple BMW cars.\nSo I turned to Mercari’s Merchat. After asking for my cousin’s hobby (anime), age (17) and what she might prefer \nfor college (dorm decorations), Merchat offered three gift ideas: wall tapestries, string lights and desk accessories in \nthe theme of Violet Evergarden.\nMerchat showed me four products under each category, all of which were under my budget of $50. I ended up \nbuying an $18 Violet Evergarden poster scroll for Jenny. (She later told me she wished I had gotten her something \nquirkier.)\nEmboldened by the experience, I asked Merchat to help find a present for my mother. “Would she benefit from a \nback support cushion, a heating pad or maybe a massage chair pad?” it asked.\n“What are the pros and cons of each?” I typed.\nMerchat said it couldn’t provide specific pros and cons for individual items. I changed my question to: “Which one is \nthe easiest to use?”\nThis time, Merchat was definitive: the back support cushion, which was portable. Merchat detailed the differences \nbetween a memory-foam cushion and a firmer one, then further grouped memory-foam cushions into three \ncategories and displayed the top four results for each, all under $100.\nWhile I didn’t buy any because the styles were limited, it was a great starting point.\n“Thank you,” I wrote.\n“You’re welcome!” Merchat replied. “Happy shopping and have a wonderful time with your family!”\nPHOTOS: Shop A.I. returned more than 300 results for a request to find black ergonomic chairs, though the options \nwere not under the shopper’s budget of $100.; A look at a conversation with Merchat A.I., a chatbot that helps \nshoppers. “Merchat is still in its infancy,” said an influencer who has tried the chatbot. (B2) This article appeared in \nprint on page B1, B2.\nLoad-Date: December 17, 2023"
    },
    {
        "file_name": "The_New_York_Times_Mar2024",
        "header": "How A.I. Is Remodeling the Fantasy Home; Critic’s Notebook",
        "media": "The New York Times",
        "time": "March 5, 2024",
        "section": "ARTS; design",
        "length": "1977 words",
        "byline": "Amanda Hess Amanda Hess is a critic at large for the New York Times. She writes about internet and pop",
        "story_text": "How A.I. Is Remodeling the Fantasy Home; Critic’s Notebook\nThe New York Times \nFebruary 4, 2024 Sunday 10:40 EST\nCopyright 2024 The New York Times Company All Rights Reserved\nSection: ARTS; design\nLength: 1977 words\nByline: Amanda Hess Amanda Hess is a critic at large for the New York Times. She writes about internet and pop \nculture for the Arts section and contributes regularly to The New York Times Magazine.\nHighlight: Amid an intractable real estate crisis, fake luxury houses offer a delusion of one’s own.\nBody\nAmid an intractable real estate crisis, fake luxury houses offer a delusion of one’s own.\nI was scrolling through Instagram recently when I found a new page slipped into my feed through a suggested post: \n@tinyhouseperfect. It seemed designed to poke at my frustrated longings for a space of my own. I want to own a \nhouse; I cannot currently buy a house. But what if the house were very small? Very small, and also perfect?\nSoon I was navigating the reading nooks and chef’s kitchens of an elfin cottage, a gothic coastal A-frame, a cozy \n“loch house” in the Scottish Highlands. I had projected my future self to the Scottish seaside, wondering how much \nthe house might cost to rent for a weekend, when I realized that price was no object because the house did not \nexist. Each of these teensy homes had been rendered by A.I. software and smoothed with an assist from more A.I. \nsoftware. I had been fantasizing about a fantasy.\nThe nature of these homes was, in retrospect, obvious. Their interiors appeared improbably expansive, offering \nroom after room of curated delights. It’s not hard to imagine why Instagram might boost @tinyhouseperfect’s \ncomputer visions into my sightline. I have not hidden my obsession with homeownership and renovation from the \ninternet’s all-seeing eye. At night I wander between Zillow and D.I.Y. Instagram accounts, stalking the hallways of \nhomes I will never visit, assessing the work of contractor-influencers I will never employ, weighing aesthetic choices \nI will never make. Now artificial intelligence has breached my domestic fantasy, reshaping my desires to fit inside its \nphantom walls.\nIn recent years, a whole A.I. dream-house economy has materialized. Search Pinterest for décor inspiration, and \nyou’ll find it clogged with artificial bedrooms that lead off to websites hawking cheap home accessories. “House \nporn” accounts on TikTok and X churn out antiseptic loft renderings and impossible views from nonexistent Parisian \napartments. The website “This House Does Not Exist” generates random new homes upon command. And dozens \nof A.I.-powered design services and apps — among them SofaBrain and RoomGPT — churn out slick images \ntuned to your specifications.\nA jangling set of house keys was once synonymous with American success: the striver’s ultimate prize. The misery \nproduced by this idea (see: the Great Recession) has not dampened its allure. Now, thanks to elevated interest \nrates, insufficient supply and corporate landlords snapping up that limited housing stock, homeownership is more \nunrealistic than ever. A.I. houses just make that unreality explicit. In the virtual market, the supply is endless, and \nthe key is always in the lock.\nFrom Nowhere, and Everywhere\nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook\nHousing voyeurism has always encouraged a measure of psychic projection. On TV, the celebrity house tour and \nthe home-improvement program are older than I am. Magazines of aspirational domesticity are older still. In the \n1970s, Architectural Digest transformed from a trade publication into a showcase for publicizing the private spaces \nof what it called “men and women of taste, discrimination and personal achievement.” In the 1980s, viewers of \n“Lifestyles of the Rich and Famous” were prompted to imagine how they might spend their millions if they had them.\nThis was the lousy trade-off of American inequality: The rich got lavish homes, and everyone else got to see the \npictures, and experience the release that comes from judging all of their choices up close. At the end of each \n“Lifestyles” episode, Robin Leach bid his audience “champagne wishes and caviar dreams.”\nThe modern version of “Lifestyles,” the Netflix reality show “Selling Sunset,” focuses not on the people who live in \nHollywood mansions but on the glamorous real estate agents who sell them. As these intensely groomed Realtors \nprep and stage fancy homes, viewers are invited to imagine not living in a mansion, but bringing it under our total \nfinancial and aesthetic control. Artificial intelligence and predictive algorithms only enhance this sensation of \npersonal ownership, making a dream house feel as if it were built just for us.\nThe loch house on @tinyhouseperfect first caught my eye with its glistening waterfront views from vast windows, \nbut when I looked again, I begrudgingly acknowledged that it had also appealed because it seemed to have been \nappointed to suit my personal tastes. There was a claw-foot tub with pewter fixtures, a charmingly messy bookshelf \nwindow-seat, a kitchen painted a cool green. In the place of cabinets, it featured exposed wooden shelves stocked \nwith shapely glass jars of potions and preserves.\nI had thought of the loch house as remote, but really it had come from nowhere, or everywhere. It was crowded with \ndesign touches perfectly synced to the ones cresting on my Instagram and Pinterest feeds. The “personal taste” \nthat drew me in was actually a highly impersonal taste: an aesthetic that dominates my internet browsing so \nthoroughly, it has come to feel like I selected it myself.\nIn “Filterworld: How Algorithms Flattened Culture,” Kyle Chayka describes “the strangely frictionless geography \ncreated by digital platforms” and “the sense of vaporousness and unreality” created by the existence of, say, barely \ndifferentiated hipster coffee shops in every city in the world. This airless sensation has overtaken our collective \nimagination, too, infiltrating the spaces of the mind.\nEven as social media and artificial intelligence bend us toward a ubiquitous megastyle, its products are often \npitched as centers of creativity. An Architectural Digest article on A.I. design tools describes them as offering a \n“fresh perspective” that can “inspire architects” to think “outside the box.” But though A.I. prompts are seemingly \nendless, the results are often eerily banal. Much of the A.I. décor that surfaces on Instagram features the same \nuncanny images: liquid throw blankets, accidentally surreal wall art, hearths lit with inert flames.\nThese renderings are cheap, and yet it feels as if the flattening of design affects the homes of the wealthy most of \nall. I don’t use A.I. software, but I have a little game I play to refocus my housing fixation onto absurd and \nimpractical spaces. I dial up the price settings on the Zillow app so that its map of the city reveals only properties \nthat are listed at over $10 million, over $50 million, over $100 million. As the costs climb, the profiles of potential \nbuyers grow more obscure and mysterious until they do not seem to exist in my world at all, and the tastes on \ndisplay start to look, themselves, mechanically programmed.\nWhen watching old episodes of “Lifestyles and the Rich and Famous” and its spiritual successor, “MTV Cribs,” it’s \nstriking how similar the homes of the wealthy appear. In a 2004 episode of “Cribs,” Snoop Dogg opens the door to \nhis manse, revealing a parlor with granny furniture and a gigantic urn; the room could fit into the home of Debbie \nGibson, profiled on “Lifestyles” in 1993. Now, every property on “Selling Sunset” feels laser cut from the same \nblueprint, every mansion a flat box of ostentatious minimalism. The $195 million Manhattan penthouse currently \nperched atop my Zillow feed is just a gargantuan version of the glass-box look replicated across every luxury condo \nbuilding in New York City.\nA very rich person has the resources to dramatically transform a space in response to trends, lending wealth itself \nan artificial aesthetic. An Architectural Digest tour of Drake’s Toronto mansion looks as if it were designed by a bot, \nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook\nwith its cartoonish proportions, glassy surfaces and random, click-and-paste patterns. And the magazine’s tour of \nthe influencer Emma Chamberlain’s home feels eerily saturated with buzzy designs: the bulbous couch, the egg-\nshaped stone dining table, the wavy velvet chair. Even the unexpected details feel intentionally programmed. Now, \nas I swipe my way through the bedrooms of an A.I.-rendered home, I can produce that same mechanical sensation.\nNo People, No Animals\nThe loch house I coveted was created by Ben Myhre, a Norway-based designer who started conjuring architectural \nconcept art with A.I. software a couple of years ago and posting it to Instagram, where he has accrued more than \n500,000 followers. Unlike some of the uncanny renderings that choke social media, Myhre’s bespoke images take \nmany hours to build, with the help of his own photographs of buildings, the generative A.I. program Midjourney, the \nA.I.-powered photo enhancement program Topaz, and Photoshop. In addition to adorable little houses, he makes \nimages of homes inspired by Harry Potter, Santa Claus and “The Lord of the Rings.”\nI reached out to Myhre and spoke with him over Zoom. “I like to use it to unlock dreams,” he said of artificial \nintelligence, which he sees as a form of “collective imagination that anyone can access.” I was curious about the \ncontours of the imagination animating his dream homes, and he shared some of the prompts he used to create the \nloch house. He guided the software to create a “cozy whimsical house kitchen in the beautiful Scottish highlands,” \none with “window views to a vast scenic loch view with early autumn nature.” He called for “rustic details,” “depth of \nfield,\" “warm tones,” “style raw.” And he asked to banish certain elements: “no people, no animals.”\nNo people, no animals. Part of why Myrhe’s images can seem “real” is because they are created in the style of an \nonline home tour, the kind you might find on Zillow or Airbnb. But I hadn’t totally understood the appeal of his work \nuntil he said those words; the fantasy is of spaces wiped of living things. There is a postapocalyptic feel to the \nhome-sale slide show and its A.I. counterpart. The houses feel urgently abandoned, a book cracked open on the \narmrest, a fire still glowing. When I “toured” the loch house, I was inspecting its shelf of corked jugs, wondering \nwhere the residents had stashed all their practical kitchen items, when I finally realized that there were no residents. \nNothing needed to be cooked for nobody.\nMyhre told me that his images sometimes upset people who were expecting pictures of actual homes. “When \npeople realize they’re not real, they feel a bit tricked,” he said. In his captions, he pleads with those (like \n@tinyhouseperfect) who circulate his work: “Please be sure to credit if you share and clearly label they are \nimaginary A.I. assisted scenes to avoid any misconceptions.”\nBut there is a seduction to the unreality of these images, too. My trips through Zillow are fueled by my jealousy at \nthe actual residents of the homes I can only inhabit with my mind. There is nothing “real” about my fantasy of living \nin places I can’t afford, even as my brain sets to work studying the floor plan and arranging my furniture in its \nrooms. Touring a lavish house, whether it’s on Zillow or “Selling Sunset” or @tinyhouseperfect, distorts my vision in \nanother way: It makes me feel as if I’m lacking something, when I have more than enough.\nNo human lives in the loch house, but increasingly this is also true of real dream homes. Many of New York’s luxury \napartments lie empty. Some are acquired by the ultrarich as assets. They exist to house no one, even as people \nsleep on the streets outside. Home voyeurism has always been a form of misdirection, a glittering diversion from \nour inability, or refusal, to shelter everyone. It coaxes us to think of housing as a lifestyle choice, not a right. A.I. \nhouses complete the trick. They represent housing that is finally freed from any responsibility toward human beings. \nNo shelter, only vibes.\nPHOTOS: PHOTO (C1); A “Scottish Highlands Loch House,” top, a well-appointed “Green Cottage,” center, and a \n“Stone House” sitting area, left, were all conjured with artificial intelligence. (PHOTOGRAPHS BY BEN MYHRE) \n(C6) This article appeared in print on page C1, C6.\nLoad-Date: March 5, 2024\nHow A.I. Is Remodeling the Fantasy Home Critic’s Notebook"
    },
    {
        "file_name": "The_Economic_Times_Apr2023",
        "header": "Elon Musk plans AI startup to compete with OpenAI's ChatGPT : report",
        "media": "The Economic Times",
        "time": "April 14, 2023",
        "section": "TECH & INTERNET",
        "length": "348 words",
        "byline": " ",
        "story_text": "Elon Musk plans AI startup to compete with OpenAI's ChatGPT : report\nThe Economic Times\nApril 15, 2023 Saturday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH & INTERNET\nLength: 348 words\nBody\nElon Musk, the CEO of Twitter and EV maker Tesla, is planning to launch a new artificial intelligence startup to \ncompete with Microsoft-backed OpenAI's ChatGPT, Financial Times (FT) reported on Friday.Elon Musk is currently \nengaging in talks with several investors from SpaceX and Tesla regarding potential investments in his new venture, \naccording to the report. Musk has also secured thousands of high-powered GPU processors from Nvidia, the report \nsaid citing sources. \nET had reported in February, citing a report from US-based tech news platform The Information, that Musk had \napproached several AI researchers to form a new lab which will work on developing an alternative to ChatGPT.The \nTwitter CEO had reached out to Igor Babuschkin, a researcher who recently left Alphabet's DeepMind AI unit and \nspecialises in the kind of machine-learning models that power chatbots like ChatGPT, according to the report by \nThe Information..The planned venture would give Musk the chance to go up against OpenAI, the organisation \nsupported by Microsoft that he co-founded in 2015. Musk left the board three years later as a result of conflicts with \nthe organisation's management, which included divergent opinions on AI safety, the FT report added. Over the last \nfew months, Musk has repeatedly criticised the company for installing safeguards that prevent ChatGPT from \nproducing text that might offend users.Musk and a group of artificial intelligence experts and industry \nexecutivescalled for a six-month pause in training systems more powerful than OpenAI's newly launched model \nGPT-4, last month, in an open letter, citing potential risks to society and humanity.Microsoft, an early backer of \nOpenAI, has reportedly invested another $10 billion in it. Meanwhile, Meta Platforms Inc is creating a new top-level \nproduct group focused on generative artificial intelligence, CEO Mark Zuckerberg said in February..OpenAI took \nthe internet by storm last November when it released the generative AI chatbot ChatGPT, which produces answers \nmimicking human speech. For Reprint Rights: timescontent.com\nLoad-Date: April 14, 2023"
    },
    {
        "file_name": "Driving_Car_Update_Aug2023",
        "header": "Sam Bankman-Fried Goes to Jail, Back to School With A.I. and A Self-",
        "media": "Driving Car Update",
        "time": "August 30, 2023",
        "section": "PODCASTS",
        "length": "304 words",
        "byline": "Kevin Roose, Casey Newton, Davis Land, Rachel Cohn, Jen Poyant, Sophia Lanman, Dan Powell, Marion",
        "story_text": "Sam Bankman-Fried Goes to Jail, Back to School With A.I. and A Self-\nDriving Car Update\nThe New York Times \nAugust 18, 2023 Friday 11:43 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 304 words\nByline: Kevin Roose, Casey Newton, Davis Land, Rachel Cohn, Jen Poyant, Sophia Lanman, Dan Powell, Marion \nLozano and Rowan Niemisto\nHighlight: Sam Bankman-Fried lands himself back  in jail.\nBody\nListen and follow ‘Hard Fork’\nApple | Spotify | Stitcher | Amazon | Google\nWhen Sam Bankman-Fried was arrested in December, he was confined to his parents’ house — but he was left \nfree to roam the internet. Today, the New York Times reporter David Yaffe-Bellany talks about how access to the \ncyberworld allowed Mr. Bankman-Fried to violate his bail terms and land himself  in jail.\nThen, how universities can manage a generative A.I. world.\nPlus: another look at autonomous vehicles.\nOn Today’s Episode:\n• David Yaffe-Bellany, a cryptocurrency and financial technology reporter for The New York Times.\n• Ethan Mollick, an associate professor at the Wharton School of the University of Pennsylvania who is \nexperimenting with generative A.I. in the classroom.\nAdditional Information:\n• Sam Bankman-Fried was sent to jail after violating his bail terms. The court dispute over his bail focused on a \nNew York Times article that described writings by Caroline Ellison, an FTX executive who had also dated \nMr. Bankman-Fried.\n• A driverless car got stuck in wet concrete in San Francisco this week.\nCredits\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land and Rachel Cohn. The \nshow is edited by Jen Poyant. Engineering by Sophia Lanman and original music by Dan Powell, Marion Lozano \nand Rowan Niemisto. Fact-checking by Caitlin Love.\nSpecial thanks to Paula Szuchman, Pui-Wing Tam, David McCraw, Nell Gallogly, Kate LoPresti and Jeffrey \nMiranda.\n“Hard Fork” is hosted by Kevin Roose and Casey Newton and produced by Davis Land and Rachel Cohn. The \nshow is edited by Jen Poyant. Engineering by Sophia Lanman and original music by Dan Powell, Marion Lozano \nSam Bankman-Fried Goes to Jail, Back to School With A.I. and A Self-Driving Car Update\nand Rowan Niemisto. Fact-checking by Caitlin Love. Special thanks to Paula Szuchman, Pui-Wing Tam, David \nMcCraw, Nell Gallogly, Kate LoPresti and Jeffrey Miranda. \nLoad-Date: August 30, 2023"
    },
    {
        "file_name": "2021_timeline_to_latest_web_browsing_capability_Sep2023",
        "header": "ChatGPT rolls with the times! OpenAI rolls out major update, moves beyond",
        "media": "2021 timeline to latest web browsing capability",
        "time": "September 28, 2023",
        "section": "TECH AND GADGETS",
        "length": "498 words",
        "byline": " ",
        "story_text": "ChatGPT rolls with the times! OpenAI rolls out major update, moves beyond \n2021 timeline to latest web browsing capability\nThe Economic Times\nSeptember 29, 2023 Friday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: TECH AND GADGETS\nLength: 498 words\nBody\nChatGPT creator OpenAI has revealed a significant upgrade to its conversational AI model. ChatGPT users will \nnow be able to do real-time internet browsing, marking a substantial evolution from its previous static knowledge \nbase, which was last updated in September 2021. Real-Time Access For Premium UsersWith this update, premium \nusers can now ask the chatbot questions about current events and access the latest news. While ChatGPT's real-\ntime browsing feature is currently behind a paywall, OpenAI has stated its intention to make it accessible to all \nusers in the near future. \nChatGPT, like other similar AI systems, relies on vast datasets to generate human-like responses to user queries, \nand it is expected to revolutionise how people seek information online. However, its primary limitation has been its \nlack of access to real-time information, leaving users with outdated responses. According to BBC, Tomas \nChamorro-Premuzic, a professor of business psychology at University College London, highlighted the significance \nof this update, stating, \"Now, you can treat this as a source of the latest news, gossip, and current events.\" He \nnoted that ChatGPT's ability to provide quick responses to pressing questions could change how users obtain \ninformation but also cautioned that without proper sourcing, the information provided might be misleading. OpenAI \nhas been under scrutiny from US regulators due to concerns about ChatGPT generating false information, and the \ncompany has been working with authorities to address these concerns. Ethical & Privacy ConcernsThis significant \nupdate also raises ethical and privacy concerns. OpenAI acknowledges these concerns and explains that they took \ntime to develop language models, ensure accuracy, and address privacy and ethical implications. The challenge for \nAI development lies in balancing the removal of constraints for improved usability while preventing misuse and \nmisinformation. OpenAI's decision to enable ChatGPT to access real-time information is a substantial one. It not \nonly comes with added computing costs but also introduces challenges related to accuracy and privacy. Despite \nthese challenges, the company has recognised the necessity of adapting to the evolving AI landscape. ChatGPT's \nnew capabilities reflect the broader dilemma faced by the AI sector: balancing usefulness with safety and accuracy. \nCompetition With Other Tech GiantsOpenAI's move to enable ChatGPT to access current information directly from \nthe web brings it in direct competition with industry giants like Microsoft and Google. The decision is part of a \nbroader trend in the AI industry, with companies racing to enhance the capabilities of their generative AI products, \ndespite the ongoing challenges related to accuracy and performance. This development comes in the wake of \nOpenAI's revelation that ChatGPT will soon support voice conversations with users, adding yet another dimension \nto its functionality. For Reprint Rights: timescontent.com\nLoad-Date: September 28, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "A.I. Can Add $4.4 Trillion Worldwide, Report Says",
        "media": "The New York Times",
        "time": "June 14, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 6",
        "length": "620 words",
        "byline": "By Yiwen Lu",
        "story_text": "A.I. Can Add $4.4 Trillion Worldwide, Report Says\nThe New York Times\nJune 14, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 6\nLength: 620 words\nByline: By Yiwen Lu\nBody\nThe report from McKinsey comes as a debate rages over the potential economic effects of A.I.-powered chatbots \non labor and the economy.\n''Generative artificial intelligence'' is set to add up to $4.4 trillion of value to the global economy annually, \naccording to a report from McKinsey Global Institute, in what is one of the rosier predictions about the economic \neffects of the rapidly evolving technology. \n  Generative A.I., which includes chatbots such as ChatGPT that can generate text in response to prompts, can \npotentially boost productivity by saving 60 to 70 percent of workers' time through automation of their work, \naccording to the 68-page report, which was published early Wednesday. Half of all work will be automated between \n2030 and 2060, the report said.\n  McKinsey had previously predicted that A.I. would automate half of all work between 2035 and 2075, but the \npower of generative A.I. tools -- which exploded onto the tech scene late last year -- accelerated the company's \nforecast.\n  ''Generative A.I. has the potential to change the anatomy of work, augmenting the capabilities of individual \nworkers by automating some of their individual activities,'' the report said.\n  McKinsey's report is one of the few so far to quantify the long-term impact of generative A.I. on the economy. The \nreport arrives as Silicon Valley has been gripped by a fervor over generative A.I. tools like ChatGPT and Google's \nBard, with tech companies and venture capitalists investing billions of dollars in the technology.\n  The tools -- some of which can also generate images and video, and carry on a conversation -- have started a \ndebate over how they will affect jobs and the world economy. Some experts have predicted that the A.I. will \ndisplace people from their work, while others have said the tools can augment individual productivity.\n  Last week, Goldman Sachs released a report warning that A.I. could lead to worker disruption and that some \ncompanies would benefit more from the technology than others. In April, a Stanford researcher and researchers at \nthe Massachusetts Institute of Technology released a study showing that generative A.I. could boost the \nproductivity of inexperienced call center operators by 35 percent.\n  Any conclusions about the technology's effects may be premature. David Autor, a professor of economics at M.I.T. \ncautioned that generative A.I. was ''not going to be as miraculous as people claim.''\n  ''We are really, really in the early stage,'' he added.\nA.I. Can Add $4.4 Trillion Worldwide, Report Says\n  For the most part, economic studies of generative A.I. do not take into account other risks from the technology, \nsuch as whether it might spread misinformation and eventually escape the realm of human control.\n  The vast majority of generative A.I.'s economic value will most likely come from helping workers automate tasks \nin customer operations, sales, software engineering, and research and development, according to McKinsey's \nreport. Generative A.I. can create ''superpowers'' for high-skilled workers, said Lareina Yee, a McKinsey partner \nand an author of the report, because the technology can summarize and edit content.\n  ''The most profound change we are going to see is the change to people, and that's going to require far more \ninnovation and leadership than the technology,'' she said.\n  The report also outlined challenges that industry leaders and regulators would need to address with A.I., including \nconcerns that the content generated by the tools can be misleading and inaccurate.\n  Ms. Yee acknowledged that the report was making prognostications about A.I.'s effects, but that ''if you could \ncapture even a third'' of what the technology's potential is, ''it is pretty remarkable over the next five to 10 years.''\nhttps://www.nytimes.com/2023/06/14/technology/generative-ai-global-economy.html\nGraphic\n \nThis article appeared in print on page B6.               \nLoad-Date: June 14, 2023"
    },
    {
        "file_name": "Global_Chief_Feb2024",
        "header": "Gen AI may not Lead to Job Losses but can Shift Demand Curve: S&P",
        "media": "Global Chief",
        "time": "February 18, 2024",
        "section": "ECONOMY",
        "length": "373 words",
        "byline": "Ishaan.Gera@timesgroup.com",
        "story_text": "Gen AI may not Lead to Job Losses but can Shift Demand Curve: S&P \nGlobal Chief\nEconomic Times (E-Paper Edition)\nFebruary 19, 2024 Monday\nKolkata Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY\nLength: 373 words\nByline: Ishaan.Gera@timesgroup.com\nBody\nNew Delhi: Generative artificial intelligence (AI) tools may not necessarily lead to job losses but shift the demand \ncurve in the near term, said Adam Kansler, president, S&P Global Market Intelligence. “Each year for the last \ndecade, we’ve thought that technological advance would mean we needed 10% less people or 20% less people. \nToday, we have probably 40% more people working in those functions than we did,” Kansler told ET in an interview. \nHe said productivity gains could result in a shift in demand and that there is a long way to go before the net effect of \nthe disruptive and highly valuable technology is understood. According to him, new technologies and startups and a \nworld where outcomes could  become more predictable could also lead to reversal of some caution by venture \ncapital investors and redeployment of capital in 2024. However, he highlighted that in terms of macro fundamentals, \na reversion to old times would have to wait. “I believe you'll need to wait a year to understand what the new normal \nis. I think the trends show that we are migrating back to what we saw in the previous decades. Will we return to the \nvery low inflation rates and low-interest rate environments we saw four or five  years ago? Probably not for some \ntime,” Kansler said. While the global economy is preparing for a soft landing in 2024, inflation and geopolitcal risks \ncould threaten a path to recovery, he said. Soft landing refers to a slowdown in economic growth without lapsing \ninto a recession. “More than half of the world's population is voting in the current year. So, things could change \nquickly in terms of geopolitics,” Kansler said. India is due to hold a general election in April-May, whereas the US \nwill hold its presidenti-  al election in November. In the case of India, Deepa Kumar, head, Asia-Pacific Country \nRisk, S&P Global Market Intelligence, said the goal for the newly elected government will be to carry forward the \nstructural momentum put in place by the outgoing regime. “Rebalancing towards allowing more private investment \nto come in so that public expenditure can go in some other sectors like infrastructure could help the country move \ntowards 7-7.5% from 6.3% projected over the next decade,” Kumar said.\nLoad-Date: February 18, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "Google Is Testing an A.I. Tool That Can Write News Articles",
        "media": "The New York Times",
        "time": "July 21, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "803 words",
        "byline": "By Benjamin Mullin and Nico Grant",
        "story_text": "Google Is Testing an A.I. Tool That Can Write News Articles\nThe New York Times\nJuly 21, 2023 Friday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 803 words\nByline: By Benjamin Mullin and Nico Grant\nBody\nThe product, pitched as a helpmate for journalists, has been demonstrated for executives at The New York Times, \nThe Washington Post and News Corp, which owns The Wall Street Journal.\nGoogle is testing a product that uses artificial intelligence technology to produce news stories, pitching it to news \norganizations including The New York Times, The Washington Post and The Wall Street Journal's owner, News \nCorp, according to three people familiar with the matter. \n  The tool, known internally by the working title Genesis, can take in information -- details of current events, for \nexample -- and generate news content, the people said, speaking on the condition of anonymity to discuss the \nproduct.\n  One of the three people familiar with the product said that Google believed it could serve as a kind of personal \nassistant for journalists, automating some tasks to free up time for others, and that the company saw it as \nresponsible technology that could help steer the publishing industry away from the pitfalls of generative A.I.\n  Some executives who saw Google's pitch described it as unsettling, asking not to be identified discussing a \nconfidential matter. Two people said it seemed to take for granted the effort that went into producing accurate and \nartful news stories.\n  Jenn Crider, a Google spokeswoman, said in a statement that ''in partnership with news publishers, especially \nsmaller publishers, we're in the earliest stages of exploring ideas to potentially provide A.I.-enabled tools to help \ntheir journalists with their work.''\n  ''Quite simply, these tools are not intended to, and cannot, replace the essential role journalists have in reporting, \ncreating and fact-checking their articles,'' she added. Instead, they could provide options for headlines and other \nwriting styles.\n  A News Corp spokesman said in a statement, ''We have an excellent relationship with Google, and we appreciate \nSundar Pichai's long-term commitment to journalism.''\n  The Times and The Post declined to comment.\n  Jeff Jarvis, a journalism professor and media commentator, said Google's new tool, as described, had potential \nupsides and downsides.\nGoogle Is Testing an A.I. Tool That Can Write News Articles\n  ''If this technology can deliver factual information reliably, journalists should use the tool,'' said Mr. Jarvis, director \nof the Tow-Knight Center for Entrepreneurial Journalism at the Craig Newmark Graduate School of Journalism at \nthe City University of New York.\n  ''If, on the other hand, it is misused by journalists and news organizations on topics that require nuance and \ncultural understanding,'' he continued, ''then it could damage the credibility not only of the tool, but of the news \norganizations that use it.''\n  News organizations around the world are grappling with whether to use artificial intelligence tools in their \nnewsrooms. Many, including The Times, NPR and Insider, have notified employees that they intend to explore \npotential uses of A.I. to see how it might be responsibly applied to the high-stakes realm of news, where seconds \ncount and accuracy is paramount.\n  But Google's new tool is sure to spur anxiety, too, among journalists who have been writing their own articles for \ndecades. Some news organizations, including The Associated Press, have long used A.I. to generate stories about \nmatters including corporate earnings reports, but they remain a small fraction of the service's articles compared with \nthose generated by journalists.\n  Artificial intelligence could change that, enabling users to generate articles on a wider scale that, if not edited and \nchecked carefully, could spread misinformation and affect how traditionally written stories are perceived.\n  While Google has moved at a breakneck pace to develop and deploy generative A.I., the technology has also \npresented some challenges to the advertising juggernaut. While Google has traditionally played the role of curating \ninformation and sending users to publishers' websites to read more, tools like its chatbot, Bard, present factual \nassertions that are sometimes incorrect and do not send traffic to more authoritative sources, such as news \npublishers.\n  The technology has been introduced as governments around the world have called on Google to give news outlets \na larger slice of its advertising revenue. After the Australian government tried to force Google to negotiate with \npublishers over payments in 2021, the company forged more partnerships with news organizations in various \ncountries, under its News Showcase program.\n  Publishers and other content creators have already criticized Google and other major A.I. companies for using \ndecades of their articles and posts to help train these A.I. systems, without compensating the publishers. News \norganizations including NBC News and The Times have taken a position against A.I.'s sucking up their data without \npermission.\nhttps://www.nytimes.com/2023/07/19/business/google-artificial-intelligence-news-articles.html\nGraphic\n \nThis article appeared in print on page B4.               \nLoad-Date: July 21, 2023"
    },
    {
        "file_name": "Nonfiction_Reviews_Feb2024",
        "header": "Human intelligence brought to AI",
        "media": "Nonfiction Reviews",
        "time": "February 18, 2024",
        "section": "ENTERTAINMENT; E; Pg. 5",
        "length": "714 words",
        "byline": "Jennifer Szalai The New York Times",
        "story_text": "Human intelligence brought to AI\nNonfiction Reviews\nThe Baltimore Sun\nFebruary 18, 2024 Sunday\nFirst Edition\nCopyright 2024 The Baltimore Sun Company All Rights Reserved\nSection: ENTERTAINMENT; E; Pg. 5\nLength: 714 words\nByline: Jennifer Szalai The New York Times\nHighlight: By Dennis Yi Tenen; W.W. Norton & Company, 176 pages, $22.\nBody\nIn \"Literary Theory for Robots,\" Dennis Yi Tenen's playful new book on artificial intelligence and how computers \nlearned to write, one of his most potent examples arrives in the form of a tiny mistake.\nTenen draws links among modern-day chatbots, pulp-fiction plot generators, old-fashioned dictionaries and \nmedieval prophecy wheels. Both the Utopians (the robots will save us!) and the doomsayers (the robots will destroy \nus!) have it wrong, he argues. There will always be an irreducibly human aspect to language and learning - a crucial \ncore of meaning that emerges not just from syntax but from experience. Without it, you just get the chatter of \nparrots, who, \"according to Descartes in his 'Mediations,' merely repeated without understanding,\" Tenen writes.\nBut Descartes didn't write \"Mediations;\" Tenen must have meant \"Meditations\" - the missing \"t\" will slip past any \nspell-checker program because both words are perfectly legitimate. (The book's index lists the title correctly.) This \nminuscule typo doesn't have any bearing on Tenen's argument; if anything, it bolsters the case he wants to make. \nMachines are becoming stronger and smarter, but we still decide what is meaningful. A human wrote this book. \nAnd, despite the robots in the title, it is meant for other humans to read.\nTenen, now a professor of English and comparative literature at Columbia, used to be a software engineer at \nMicrosoft. He puts his disparate skill sets to use in a book that is surprising, funny and resolutely unintimidating, \neven as he smuggles in big questions about art, intelligence, technology and the future of labor. I suspect that the \nbook's small size is part of the point. People are not indefatigable machines, relentlessly ingesting enormous \nvolumes on enormous subjects. Tenen has figured out how to present a web of complex ideas at human scale.\nTo that end, he tells stories, starting with 14th-century Arab scholar Ibn Khaldun, who chronicled the use of the \nprophecy wheel, and ending with a chapter on 20th-century Russian mathematician Andrey Markov, whose \nprobability analysis of letter sequences in Alexander Pushkin's \"Eugene Onegin\" constituted a fundamental building \nblock of generative AI. Tenen writes knowledgeably about the technological roadblocks that stymied earlier models \nof computer learning, before \"the brute force required to process most everything published in the English \nlanguage\" was so readily available. He urges us to be alert. He also urges us not to panic.\n\"Intelligence evolves on a spectrum, ranging from 'partial assistance' to 'full automation,' \" Tenen writes, offering the \nexample of an automatic transmission in a car. Driving an automatic in the 1960s must have been mind-blowing for \npeople used to manual transmissions. An automatic worked by automating key decisions, downshifting on hills and \nsending less power to the wheels in bad weather. It removed the option to stall or grind your gears. It was \nHuman intelligence brought to AI Nonfiction Reviews\n\"artificially intelligent,\" even if nobody used those words for it. American drivers now take its magic for granted. It \nhas been demystified.\nAs for the current debates over AI, this book tries to demystify those, too. Instead of talking about AI as if it has a \nmind of its own, Tenen talks about the collaborative work that went into building it.\nTenen also argues that we, as social beings, have agency, if only we allow ourselves to accept the responsibility \nthat comes with it. \"Individual AIs do pose real danger, given the ability to aggregate power in the pursuit of a goal,\" \nhe concedes. But the real danger comes \"from our inability to hold technology makers responsible for their actions.\" \nWhat if someone wanted to strap a jet engine to a car and see how it fared on the streets of a crowded city? Tenen \nsays the answer is obvious: \"Don't do that.\"\nWhy \"don't do that\" can seem easy in one realm but not another requires more thinking, more precision, more \nscrutiny - all qualities that fall by the wayside when we cower before AI, treating the technology like a singular god \ninstead of a multiplicity of machines built by a multiplicity of humans. Tenen leads by example, bringing his human \nintelligence to bear on artificial intelligence. By thinking through our collective habits of thought, he offers a \nmeditation all his own.\nLoad-Date: February 18, 2024"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Nov2023",
        "header": "‘Telco to Techco Switch Inevitable’",
        "media": "Economic Times (E-Paper Edition)",
        "time": "November 15, 2023",
        "section": "COMPANIES",
        "length": "485 words",
        "byline": "Subhrojit.Mallick@timesgroup.com",
        "story_text": "‘Telco to Techco Switch Inevitable’\nEconomic Times (E-Paper Edition)\nNovember 16, 2023 Thursday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: COMPANIES\nLength: 485 words\nByline: Subhrojit.Mallick@timesgroup.com\nHighlight: Red Hat chief technologist says the transformation will be driven by an existential crisis stemming from \nlower per-user revenue, increasing capex and evolving consumer needs\nBody\nNew Delhi: The transformation of telecommunication companies in India and around the world into full-fledged tech \ncompanies — or a telco to a techco — is inevitable and is being driven by an existential crisis stemming from lower \naverage revenue per user (ARPU), increasing capital expenditure and evolving consumer needs, said a top \nexecutive of US-based open-source solutions provider Red Hat. “It’s a universal trend…but in India, there are \nprobably a few more levels. The telco to techco transformation has to happen. \nIt’s not an if, but when. It is almost an existential crisis,” Red Hat chief technologist Azhar Sayeed told ET. He added \nthat the cost dynamics stemming from lower ARPU levels are driving the need to transform and add more value to \nservices being offered to consumers. “The ARPU here is $6-7, something like that, while the ARPU in the US is \n$35. There’s no comparison—despite  the volume of subscribers here—in the context of infrastructure you need to \nline up to deliver that kind of service,” Sayeed said. Telecom operators such as Bharti Airtel and Vodafone Idea \nhave been calling for tariff hikes, claiming that India is at the bottom in terms of both ARPU and cost per gigabyte \n(GB) of data. Sayeed said improvement in cost dynamics will not come from providing connectivity alone. “Unless \nthey move up the value chain, unless they figure out how to automate an operator infrastructure, and  be more \nefficient, nimble, and flexible, they cannot survive in this cost structure. Because the delta is shrinking.” Despite a \nglobal slowdown in spending by tech companies, the fintech, telecom and government spending on tech has \nincreased, he said. “Overall, we are very much encouraged by the big telcos. But not only that, some of the largest \nprojects in India are actually built on Red Hat—the Aadhaar stack with 1.3 billion users. The DigiLocker and UPI \nand GST stacks also run on our platform,” he said.  In fact, telecom operators routinely work with Red Hat for its \ncloud-based solutions, Sayeed said, adding that the top telecom operators in India are implementing a lot of Red \nHat capabilities for their 5G deployment today. “They use our cloud platform, some of them use our automation \nmonitors, but there’s still more to be done. It’s a journey, and it has started, and they are moving at a rapid pace,” \nhe said. The ongoing transformation was evident in the showcases by the telecom operators at the \nrecentlyconcluded India Mobile Congress. All three telcos stepped beyond their connectivity showcases to \ndemonstrate future capabilities in home entertainment, enterprise solutions and more. The US-based company is \nusing generative AI to build out its tools and also helping enterprise customers scale up faster. The company has \ncapabilities where it needs to be pointed towards a customer repository and can generate automation playbooks \nwithout the need for human programmers.\nLoad-Date: November 15, 2023\n‘Telco to Techco Switch Inevitable’"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Europeans Take Major Step Toward Regulating A.I.",
        "media": "The New York Times",
        "time": "June 15, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "899 words",
        "byline": "By Adam Satariano",
        "story_text": "Europeans Take Major Step Toward Regulating A.I.\nThe New York Times\nJune 15, 2023 Thursday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 899 words\nByline: By Adam Satariano\nBody\nA draft law in the European Parliament has become the world's most far-reaching attempt to address the potentially \nharmful effects of artificial intelligence.\nThe European Union took an important step on Wednesday toward passing what would be one of the first major \nlaws to regulate artificial intelligence, a potential model for policymakers around the world as they grapple with how \nto put guardrails on the rapidly developing technology. \n  The European Parliament, a main legislative branch of the European Union, passed a draft law known as the A.I. \nAct, which would put new restrictions on what are seen as the technology's riskiest uses. It would severely curtail \nuses of facial recognition software, while requiring makers of A.I. systems like the ChatGPT chatbot to disclose \nmore about the data used to create their programs.\n  The vote is one step in a longer process. A final version of the law is not expected to be passed until later this \nyear.\n  The European Union is further along than the United States and other large Western governments in regulating \nA.I. The 27-nation bloc has debated the topic for more than two years, and the issue took on new urgency after last \nyear's release of ChatGPT, which intensified concerns about the technology's potential effects on employment and \nsociety.\n  Policymakers everywhere from Washington to Beijing are now racing to control an evolving technology that is \nalarming even some of its earliest creators. In the United States, the White House has released policy ideas that \ninclude rules for testing A.I. systems before they are publicly available and protecting privacy rights. In China, draft \nrules unveiled in April would require makers of chatbots to adhere to the country's strict censorship rules. Beijing is \nalso taking more control over the ways makers of A.I. systems use data.\n  How effective any regulation of A.I. can be is unclear. In a sign that the technology's new abilities are emerging \nseemingly faster than lawmakers are able to address them, earlier versions of the E.U. law did not give much \nattention to so-called generative A.I. systems like ChatGPT, which can produce text, images and video in response \nto prompts.\n  Under the latest version of Europe's bill passed on Wednesday, generative A.I. would face new transparency \nrequirements. That includes publishing summaries of copyrighted material used for training the system, a proposal \nsupported by the publishing industry but opposed by tech developers as technically infeasible. Makers of \ngenerative A.I. systems would also have to put safeguards in place to prevent them from generating illegal content.\nEuropeans Take Major Step Toward Regulating A.I.\n  Francine Bennett, acting director of the Ada Lovelace Institute, an organization in London that has pushed for new \nA.I. laws, said the E.U. proposal was an ''important landmark.''\n  ''Fast-moving and rapidly repurposable technology is of course hard to regulate, when not even the companies \nbuilding the technology are completely clear on how things will play out,'' Ms. Bennett said. ''But it would definitely \nbe worse for us all to continue operating with no adequate regulation at all.''\n  The European bill takes a ''risk-based'' approach to regulating A.I., focusing on applications with the greatest \npotential for human harm. This would include where A.I. systems were used to operate critical infrastructure like \nwater or energy, in the legal system, and when determining access to public services and government benefits. \nMakers of the technology would have to conduct risk assessments before putting the tech into everyday use, akin to \nthe drug approval process.\n  A tech industry group, the Computer & Communications Industry Association, said the European Union should \navoid overly broad regulations that inhibit innovation.\n  ''The E.U. is set to become a leader in regulating artificial intelligence, but whether it will lead on A.I. innovation still \nremains to be seen,'' said Boniface de Champris, the group's Europe policy manager. ''Europe's new A.I. rules need \nto effectively address clearly defined risks, while leaving enough flexibility for developers to deliver useful A.I. \napplications to the benefit of all Europeans.''\n  One major area of debate is the use of facial recognition. The European Parliament voted to ban uses of live facial \nrecognition, but questions remain about whether exemptions should be allowed for national security and other law \nenforcement purposes.\n  Another provision would ban companies from scraping biometric data from social media to build out databases, a \npractice that drew scrutiny after the facial-recognition company Clearview AI used it.\n  Tech leaders have been trying influence the debate. Sam Altman, the chief executive of OpenAI, the maker of \nChatGPT, has in recent months visited with at least 100 American lawmakers and other global policymakers in \nSouth America, Europe, Africa and Asia, including Ursula von der Leyen, president of the European Commission. \nMr. Altman has called for regulation of A.I., but has also said the European Union's proposal may be prohibitively \ndifficult to comply with.\n  After the vote on Wednesday, a final version of the law will be negotiated by representatives of the three branches \nof the European Union -- the European Parliament, the European Commission and the Council of the European \nUnion. Officials said they hoped to reach a final agreement by the end of the year.\nhttps://www.nytimes.com/2023/06/14/technology/europe-ai-regulation.html\nGraphic\n \nPHOTO: The European Parliament passed a draft law that would put new restrictions on what are seen as the \nriskiest uses of A.I. (PHOTOGRAPH BY JULIEN WARNAND/EPA, VIA SHUTTERSTOCK) (B5) This article \nappeared in print on page B1, B5.               \nLoad-Date: June 15, 2023"
    },
    {
        "file_name": "Products_Jul2023",
        "header": "As Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer",
        "media": "Products",
        "time": "July 10, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1",
        "length": "1024 words",
        "byline": "By Yiwen Lu",
        "story_text": "As Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer \nProducts\nThe New York Times\nJuly 10, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1\nLength: 1024 words\nByline: By Yiwen Lu\nBody\nAmazon, Box, Salesforce, Oracle and others have recently rolled out A.I.-related products to help workplaces \nbecome more efficient and productive.\nEarlier this year, Mark Austin, the vice president of data science at AT&T, noticed that some of the company's \ndevelopers had started using the ChatGPT chatbot at work. When the developers got stuck, they asked ChatGPT \nto explain, fix or hone their code. \n  It seemed to be a game-changer, Mr. Austin said. But since ChatGPT is a publicly available tool, he wondered if it \nwas secure for businesses to use.\n  So in January, AT&T tried a product from Microsoft called Azure OpenAI Services that lets businesses build their \nown A.I.-powered chatbots. AT&T used it to create a proprietary A.I. assistant, Ask AT&T, which helps its \ndevelopers automate their coding process. AT&T's customer service representatives also began using the chatbot \nto help summarize their calls, among other tasks.\n  ''Once they realize what it can do, they love it,'' Mr. Austin said. Forms that once took hours to complete needed \nonly two minutes with Ask AT&T so employees could focus on more complicated tasks, he said, and developers \nwho used the chatbot increased their productivity by 20 to 50 percent.\n  AT&T is one of many businesses eager to find ways to tap the power of generative artificial intelligence, the \ntechnology that powers chatbots and that has gripped Silicon Valley with excitement in recent months. Generative \nA.I. can produce its own text, photos and video in response to prompts, capabilities that can help automate tasks \nsuch as taking meeting minutes and cut down on paperwork.\n  To meet this new demand, tech companies are racing to introduce products for businesses that incorporate \ngenerative A.I. Over the past three months, Amazon, Box and Cisco have unveiled plans for generative A.I.-\npowered products that produce code, analyze documents and summarize meetings. Salesforce also recently rolled \nout generative A.I. products used in sales, marketing and its Slack messaging service, while Oracle announced a \nnew A.I. feature for human resources teams.\n  These companies are also investing more in A.I. development. In May, Oracle and Salesforce Ventures, the \nventure capital arm of Salesforce, invested in Cohere, a Toronto start-up focused on generative A.I. for business \nuse. Oracle is also reselling Cohere's technology.\nAs Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer Products\n  ''I think this is a complete breakthrough in enterprise software,'' Aaron Levie, chief executive of Box, said of \ngenerative A.I. He called it ''this incredibly exciting opportunity where, for the first time ever, you can actually start \nto understand what's inside of your data in a way that wasn't possible before.''\n  Many of these tech companies are following Microsoft, which has invested $13 billion in OpenAI, the maker of \nChatGPT. In January, Microsoft made Azure OpenAI Service available to customers, who can then access \nOpenAI's technology to build their own versions of ChatGPT. As of May, the service had 4,500 customers, said \nJohn Montgomery, a Microsoft corporate vice president.\n  For the most part, tech companies are now rolling out four kinds of generative A.I. products for businesses: \nfeatures and services that generate code for software engineers, create new content such as sales emails and \nproduct descriptions for marketing teams, search company data to answer employee questions, and summarize \nmeeting notes and lengthy documents.\n  ''It is going to be a tool that is used by people to accomplish what they are already doing,'' said Bern Elliot, a vice \npresident and analyst at the I.T. research and consulting firm Gartner.\n  But using generative A.I. in workplaces has risks. Chatbots can produce inaccuracies and misinformation, provide \ninappropriate responses and leak data. A.I. remains largely unregulated.\n  In response to these issues, tech companies have taken some steps. To prevent data leakage and to enhance \nsecurity, some have engineered generative A.I. products so they do not keep a customer's data.\n  When Salesforce last month introduced AI Cloud, a service with nine generative A.I.-powered products for \nbusinesses, the company included a ''trust layer'' to help mask sensitive corporate information to stop leaks and \npromised that what users typed into these products would not be used to retrain the underlying A.I. model.\n  Similarly, Oracle said that customer data would be kept in a secure environment while training its A.I. model and \nadded that it would not be able to see the information.\n  Salesforce offers AI Cloud starting at $360,000 annually, with the cost rising depending on the amount of usage. \nMicrosoft charges for Azure OpenAI Service based on the version of OpenAI technology that a customer chooses, \nas well as the amount of usage.\n  For now, generative A.I. is used mainly in workplace scenarios that carry low risks -- instead of highly regulated \nindustries -- with a human in the loop, said Beena Ammanath, the executive director of the Deloitte A.I. Institute, a \nresearch center of the consulting firm. A recent Gartner survey of 43 companies found that over half the \nrespondents have no internal policy on generative A.I.\n  ''It is not just about being able to use these new tools efficiently, but it is also about preparing your work force for \nthe new kinds of work that might evolve,'' Ms. Ammanath said. ''There is going to be new skills needed.''\n  Panasonic Connect, part of the Japanese electronics company Panasonic, began using Microsoft's Azure OpenAI \nService to make its own chatbot in February. Today, its employees ask the chatbot 5,000 questions a day about \neverything from drafting emails to writing code.\n  While Panasonic Connect had expected its engineers to be the main users of the chatbot, other departments -- \nsuch as legal, accounting and quality assurance -- also turned to it to help summarize legal documents, brainstorm \nsolutions to improve product quality and other tasks, said Judah Reynolds, Panasonic Connect's marketing and \ncommunications chief.\n  ''Everyone started using it in ways that we didn't even foresee ourselves,'' he said. ''So people are really taking \nadvantage of it.''\nhttps://www.nytimes.com/2023/07/05/technology/business-ai-technology.html\nAs Businesses Quickly Find Uses for A.I., Tech Companies Rush to Offer Products\nGraphic\n \nThis article appeared in print on page B1, B2.               \nLoad-Date: July 10, 2023"
    },
    {
        "file_name": "The_Economic_Times_Apr2024",
        "header": "3 Indian companies make the cut on BCG's top 25 global value creator list",
        "media": "The Economic Times",
        "time": "April 22, 2024",
        "section": "STOCK IN NEWS",
        "length": "383 words",
        "byline": "Akash Podishetti",
        "story_text": "3 Indian companies make the cut on BCG's top 25 global value creator list\nThe Economic Times\nApril 23, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: STOCK IN NEWS\nLength: 383 words\nByline: Akash Podishetti\nBody\nThanks to strong capital markets in 2023, the average annual total shareholder return surged in the BCG’s Value \nCreators database. The median rose to 12% per year from 2019 through 2023 — up from 7% per year from 2018 \nthrough 2022.Technology and tech-related companies led the charge, as excitement over generative AI helped \nfuel a rebound from 2022’s losses, according to a report based on the database.\"The landscape is not solely tech \ndominated, however. Several asset-heavy industrial sectors or recently lagging industries also accelerated their \nTSR performance compared with last year’s study and now rank near the top of our industry ranking,\" it noted.With \nglobal market indices perched at all-time highs, companies across sectors now face the challenge of maintaining or \nregaining TSR momentum.Within this, several Indian companies made the cut including Jindal Stainless, which \nsecured the 9th spot among the top 25 shareholder returns.The 5-year annualised TSR of the company was at 76% \nand the 25 year TSR stood at 74. Varun Beverages at rank 22 and Tube Investments of India at 25th spot also \nmanaged to get a place on the list of top 25 companies.The 2024 rankings revealed a broad range of TSR \nperformance within each of the industries we studied, showing that all companies have the opportunity to \noutperform the broader market, regardless of their industry dynamics.Overall, the last 12 months have been \nincredibly strong for the global capital markets, with median annual total shareholder returns increasing from 7% to \n12% on a rolling 5-year basis.Tech-related industries have outperformed, propelled by unprecedented excitement \nover GenAI and its long-term potential to unlock new value pools across industries and functions.\"India has been at \nthe forefront of this charge across the global markets. \nEven more “traditional” asset-heavy industries have performed very strongly, reflecting India’s accelerated push \ntoward domestic manufacturing in multiple sectors and increased investment in industrial infrastructure \ndevelopment,\" said Akshay Kohli, MD and Partner, and Leader - Corporate Finance and Strategy (CFS) Practice in \nIndia.But amid this historic bull run, Kohli said companies are faced with a complex set of challenges to navigate. \nFor Reprint Rights: timescontent.com\nLoad-Date: April 22, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_Apr2024",
        "header": "Generative A.I. Arrives in the Gene Editing World of CRISPR",
        "media": "The New York Times - International Edition",
        "time": "April 23, 2024",
        "section": "TECHNOLOGY",
        "length": "1105 words",
        "byline": "Cade Metz",
        "story_text": "Generative A.I. Arrives in the Gene Editing World of CRISPR\nThe New York Times - International Edition\nApril 24, 2024 Wednesday\nCopyright 2024 International Herald Tribune All Rights Reserved\nSection: TECHNOLOGY\nLength: 1105 words\nByline: Cade Metz\nDateline: SAN FRANCISCO \nBody\nABSTRACT\nMuch as ChatGPT generates poetry, a new A.I. system devises blueprints for microscopic mechanisms that can \nedit your DNA.\nFULL TEXT\nGenerative A.I. technologies can write poetry and computer programs or create images of teddy bears and videos \nof cartoon characters that look like something from a Hollywood movie.       \nNow, new A.I. technology is generating blueprints for microscopic biological mechanisms that can edit your DNA, \npointing to a future when scientists can battle illness and diseases with even greater precision and speed than they \ncan today.       \nDescribed in a research paper published on Monday by a Berkeley, Calif., startup called Profluent, the technology is \nbased on the same methods that drive ChatGPT, the online chatbot that launched the A.I. boom after its release in \n2022. The company is expected to present the paper next month at the annual meeting of the American Society of \nGene and Cell Therapy.       \nMuch as ChatGPT learns to generate language by analyzing Wikipedia articles, books and chat logs, Profluent's \ntechnology creates new gene editors after analyzing enormous amounts of biological data, including microscopic \nmechanisms that scientists already use to edit human DNA.       \nThese gene editors are based on Nobel Prize-winning methods involving biological mechanisms called CRISPR. \nTechnology based on CRISPR is already changing how scientists study and fight illness and disease, providing a \nway of altering genes that cause hereditary conditions, such as sickle cell anemia and blindness.       \nPreviously, CRISPR methods used mechanisms found in nature - biological material gleaned from bacteria that \nallows these microscopic organisms to fight off germs.       \n\"They have never existed on Earth,\" said James Fraser, a professor and chair of the department of bioengineering \nand therapeutic sciences at the University of California, San Francisco, who has read Profluent's research paper. \n\"The system has learned from nature to create them, but they are new.\"       \nThe hope is that the technology will eventually produce gene editors that are more nimble and more powerful than \nthose that have been honed over billions of years of evolution.       \nGenerative A.I. Arrives in the Gene Editing World of CRISPR\nOn Monday, Profluent also said that it had used one of these A.I.-generated gene editors to edit human DNA and \nthat it was \"open sourcing\" this editor, called OpenCRISPR-1. That means it is allowing individuals, academic labs \nand companies to experiment with the technology for free.       \nA.I. researchers often open source the underlying software that drives their A.I. systems, because it allows others to \nbuild on their work and accelerate the development of new technologies. But it is less common for biological labs \nand pharmaceutical companies to open source inventions like OpenCRISPR-1.       \nThough Profluent is open sourcing the gene editors generated by its A.I. technology, it is not open sourcing the A.I. \ntechnology itself.       \nThe project is part of a wider effort to build A.I. technologies that can improve medical care. Scientists at the \nUniversity of Washington, for instance, are using the methods behind chatbots like OpenAI's ChatGPT and image \ngenerators like Midjourney to create entirely new proteins - the microscopic molecules that drive all human life - as \nthey work to accelerate the development of new vaccines and medicines.       \n(The New York Times has sued OpenAI and its partner, Microsoft, on claims of copyright infringement involving \nartificial intelligence systems that generate text.)       \nGenerative A.I. technologies are driven by what scientists call a neural network, a mathematical system that learns \nskills by analyzing vast amounts of data. The image creator Midjourney, for example, is underpinned by a neural \nnetwork that has analyzed millions of digital images and the captions that describe each of those images. The \nsystem learned to recognize the links between the images and the words. So when you ask it for an image of a \nrhinoceros leaping off the Golden Gate Bridge, it knows what to do.       \nProfluent's technology is driven by a similar A.I. model that learns from sequences of amino acids and nucleic acids \n- the chemical compounds that define the microscopic biological mechanisms that scientists use to edit genes. \nEssentially, it analyzes the behavior of CRISPR gene editors pulled from nature and learns how to generate entirely \nnew gene editors.       \n\"These A.I. models learn from sequences - whether those are sequences of characters or words or computer code \nor amino acids,\" said Profluent's chief executive, Ali Madani, a researcher who previously worked in the A.I. lab at \nthe software giant Salesforce.       \nProfluent has not yet put these synthetic gene editors through clinical trials, so it is not clear if they can match or \nexceed the performance of CRISPR. But this proof of concept shows that A.I. models can produce something \ncapable of editing the human genome.       \nStill, it is unlikely to affect health care in the short term. Fyodor Urnov, a gene editing pioneer and scientific director \nat the Innovative Genomics Institute at the University of California, Berkeley, said scientists had no shortage of \nnaturally occurring gene editors that they could use to fight illness and disease. The bottleneck, he said, is the cost \nof pushing these editors through preclinical studies, such as safety, manufacturing and regulatory reviews, before \nthey can be used on patients.       \nBut generative A.I. systems often hold enormous potential because they tend to improve quickly as they learn from \nincreasingly large amounts of data. If technology like Profluent's continues to improve, it could eventually allow \nscientists to edit genes in far more precise ways. The hope, Dr. Urnov said, is that this could, in the long term, lead \nto a world where medicines and treatments are quickly tailored to individual people even faster than we can do \ntoday.       \n\"I dream of a world where we have CRISPR on demand within weeks,\" he said.        \nScientists have long cautioned against using CRISPR for human enhancement because it is a relatively new \ntechnology that could potentially have undesired side effects, such as triggering cancer, and have warned against \nunethical uses, such as genetically modifying human embryos.       \nGenerative A.I. Arrives in the Gene Editing World of CRISPR\nThis is also a concern with synthetic gene editors. But scientists already have access to everything they need to \nedit embryos.       \n\"A bad actor, someone who is unethical, is not worried about whether they use an A.I.-created editor or not,\" Dr. \nFraser said. \"They are just going to go ahead and use what's available.\" \nLoad-Date: April 23, 2024"
    },
    {
        "file_name": "The_New_York_Times_Dec2023",
        "header": "An Artist in Residence on A.I.’s Territory",
        "media": "The New York Times",
        "time": "December 31, 2023",
        "section": "TECHNOLOGY",
        "length": "1575 words",
        "byline": "Leslie Katz",
        "story_text": "An Artist in Residence on A.I.’s Territory\nThe New York Times \nDecember 30, 2023 Saturday 13:03 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1575 words\nByline: Leslie Katz\nHighlight: Alexander Reben is taking his tech-savvy perspective to OpenAI, a company that some in the art world \nbelieve is a threat to their future.\nBody\nAt a reception for OpenAI’s first developer conference in San Francisco last month, a crowd mingled, wine in hand, \nas withering criticism of art created with artificial intelligence flashed on a blue wall at the front of the room. “I’ve \nseen more engaging art from a malfunctioning printer,” one critic jabbed. “The fine-art equivalent of elevator music,” \nhuffed another. “Inoffensive, unmemorable and terminally dull.”\nIt might seem an odd strategy for OpenAI, the company behind widely used generative A.I. tools like ChatGPT and \nDALL-E, to promote scorn of A.I. art, until you catch the twist: A.I. itself wrote the criticism. Alexander Reben, the \nM.I.T.-educated artist behind the presentation, combined his own custom code with GPT-4, a version of the large \nlanguage model that powers the ChatGPT online chatbot.\nNext month, Mr. Reben, 38, will become OpenAI’s first artist in residence. He steps in as generative A.I. advances \nat a head-spinning rate, with artists and writers trying to make sense of the possibilities and shifting implications. \nSome regard artificial intelligence as a powerful and innovative tool that can steer them in weird and wonderful \ndirections. Others express outrage that A.I. is scraping their work from the internet to train systems without \npermission, compensation or credit.\nIn late November, a group of visual artists filed an amended copyright lawsuit against Stability AI, Midjourney and \nother makers of A.I. tools after a federal judge dismissed parts of the original complaint, which accused the \ncompanies of misusing the artists’ creations to train generative A.I systems. Mr. Reben said he couldn’t speak to \nthe specifics of A.I. and the law, “but like with any new creative technology, the law needs to catch up to the \nunpredictable future.”\n(The New York Times sued OpenAI and Microsoft for copyright infringement on Wednesday.)\nTech companies including Google, Autodesk and Microsoft have welcomed artists in residence. And for the last \nseveral years, artists have tested products like GPT and the DALL-E image generator, offering insight into the tools’ \ncreative potential before their public release. But the OpenAI residency, which is giving Mr. Reben a front-row view \nof the company’s work, is a first for the start-up that is at the center of the debate over art and A.I.\n“Alex is one of the first people we share our new models with,” said Natalie Summers, a spokeswoman for OpenAI.\nSam Altman, OpenAI’s chief executive, has long acknowledged that the technologies created by his company will \nchange the nature of art. But he insists that no matter how good the technology gets, artists — human artists — will \nalways matter.\nAn Artist in Residence on A.I.’s Territory\n“There was a real moment of fear where people asked, ‘Is this a tool we have built or a creature we have built?’” he \nsaid last month during an appearance in front of more than 300 artists and art lovers packed into an abandoned \nwarehouse in downtown Oakland, Calif. “People now view these things as a new set of tools.”\nAfter the digital artist Android Jones said at the event that many artists were still very angry over the rise of A.I. \nimage generators and the way it reduced the value of their own art, Mr. Altman said people would always seek art \ncreated by other people.\n“There is clearly going to be more competition,” he said. “But, awash in a sea of A.I.-generated art, that desire for \nhuman connection will go up, not down.”\nGe Wang, an associate director of Stanford’s Institute for Human-Centered Artificial Intelligence and an associate \nprofessor of music and computer science at the school’s Center for Computer Research in Music and Acoustics, \nwonders how receptive OpenAI will be to considering the tough questions about A.I.’s impact on art. What’s the \nright balance between machine output and human curation? Will the instantaneous results produced by the likes of \nDALL-E discourage people from developing the kinds of skills that require study and time?\n“Asking these questions is kind of bad for business, and OpenAI is a business,” Dr. Wang said. “You might have a \nwonderful artist there in residence asking questions. Are you willing to receive them?”\nNonetheless, Dr. Wang — who is also a musician and designed two music-making apps, Ocarina and Magic Piano, \nfor Apple’s iPhone — said he was heartened that Mr. Reben was open to engaging with the questions about A.I.’s \nimpact on the art community.\nMr. Reben said that as a technologist who had studied the impact of innovations like photography and recorded \nmusic on creativity, “I usually stay on the cautiously optimistic side.”\n“But like any other technology of the past, there are both sides to the coin,” he added.\nThe New York native moved to Berkeley, Calif., a decade ago to become director of technology and research at \nStochastic Labs, an incubator for creative scientists and engineers that is housed in a three-story 19th-century \nVictorian. Mr. Reben’s highly conceptual art lines the walls of the main hallway and fills work spaces packed with \nprinters, headphones, cables, capacitors, soldering supplies, and other bits and bobs.\nOn a rainy Thursday, Mr. Reben relaxed on a couch at Stochastic after a meeting at OpenAI to continue working \nout details of what he’ll do during the residency, which will last three months.\n“If I come out of it and make my art better, or even come up with some new questions or new directions to present \nto the world, that would be very valuable,” said Mr. Reben, who researched human-machine symbiosis as a \ngraduate student at the M.I.T. Media Lab, an interdisciplinary research center.\nThe residency overlaps with Mr. Reben’s first major retrospective, titled “AI Am I?” and on display through April at \nSacramento’s Crocker Art Museum. DALL-E and other image generators like Midjourney and Stability AI’s Stable \nDiffusion have captivated the internet by allowing anyone to instantly retrieve custom visual imagery simply by \ntyping a few words into a box. But while much A.I.-generated art exists as pixels, Mr. Reben often manifests \nphysical structures from ideas he hones with the help of artificial intelligence.\n“I like a lot of absurdity and humor in my work, even if the underpinning question is serious,” Mr. Reben said.\nOne sculpture at the exhibit presents six toilet plungers queued up like a bizarre police lineup. A.I.-generated text \non the wall placard explains that the work represents all that remains of the Plungers, an apocryphal ’70s art \ncollective. Its fake artists adhered to “plungism,” a fictional philosophy “wherein the mind of an artist is in a state of \nflux and able to be influenced by all things, even plungers.”\nAn Artist in Residence on A.I.’s Territory\nPlungism arose from Mr. Reben’s extensive back and forth with GPT-3: He’d enter a prompt (an input aimed at \nproducing a desired response), and then tinker with his favorite responses, sometimes feeding the edited language \nback to the A.I. until he landed on just the right wording.\nThen there’s “Dreams of the Cheese-Faced Gentleman,” which depicts a man whose face could be mistaken for a \nwheel of Swiss cheese. Mr. Reben worked with GPT-4 to find the right prompts to craft a compelling description of a \npainting, then fed the curated text into an image generator. He’s not a painter himself, so he commissioned one to \nmake the artwork.\nA large language model capable of ingesting both images and text then studied the painting and described it in \nlanguage that would fit in at any museum. “The combination of psychedelic surrealism and whimsicality lends the \npainting an air of playfulness, challenging the viewer to engage with the work’s complex layers of meaning,” the wall \nlabel reads.\nJanisy Lagrue, the A.I.-imagined name for the real-life painter who produced the oil on canvas, explained: “I use \ncheese because it is so perfect a symbol of the American dream. Cheese is a commodity, not a food. It is totally \nartificial, and it is delicious.”\nThe exhibit provokes more questions than answers, a reflection of Mr. Reben’s belief that as machines produce \nbetter outputs, humans need to ask better questions — about bias and ownership, among other things.\n“Given how young this creative tool is, much still needs to be solved, and confronting these problems falls on the \nshoulders of everyone involved, from its developers to its users,” Mr. Reben said. “The more people thinking about \nthese questions the better.”\nMr. Reben doesn’t profess to speak for all artists as OpenAI’s first artist in residence. But he does understand their \nconcerns. Artists and writers worry that A.I. could steal their jobs, but Dr. Wang of Stanford said the nervousness \nextended beyond the possibility of lost livelihood.\nThe fear is “not only are we going to be replaced as artists, it’s that we’ll be replaced by something far more \ngeneric, far less interesting,” he said. “Maybe generic is enough to make a ton of money.”\nCade Metz contributed reporting.\nCade Metz contributed reporting. \nPHOTOS: Alexander Reben’s work, right and bottom, combines A.I. technology with physical art. It is on display at \nthe Crocker Art Museum in Sacramento, center. (PHOTOGRAPHS BY ROZETTE HALVORSON FOR THE NEW \nYORK TIMES; GERARD VUILLEUMIER) (BU8); “Dreams of the Cheese-Faced Gentleman,” 2023, above, an oil \npainting by Alexander Reben based on an A.I.-generated image. A.I.-generated photos by Mr. Reben at the \nCrocker Art Museum, left. (PHOTOGRAPHS BY ROZETTE HALVORSON FOR THE NEW YORK TIMES; \nGERARD VUILLEUMIER) (BU9) This article appeared in print on page BU8, BU9.\nLoad-Date: December 31, 2023"
    },
    {
        "file_name": "The_Economic_Times_Jan2024",
        "header": "Microsoft India looks to demystify AI to push business adoption",
        "media": "The Economic Times",
        "time": "January 1, 2024",
        "section": "ITES",
        "length": "616 words",
        "byline": "Annapurna Roy and Surabhi Agarwal",
        "story_text": "Microsoft India looks to demystify AI to push business adoption\nThe Economic Times\nJanuary 2, 2024 Tuesday\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ITES\nLength: 616 words\nByline: Annapurna Roy and Surabhi Agarwal\nBody\nA hundred client meetings in three months is the agenda that newly appointed Microsoft India president Puneet \nChandok has set for himself, to accelerate the Seattle-headquartered technology giant's cloud and artificial \nintelligence push in the country.“The plan in the next 90 days is to do 100 boardroom conversations with top \nenterprises in India and demystify AI,” Chandok told ET in his first media interview after joining the company in \nSeptember. He added that he had already met 100 customers over the last 100 days.“The statement of purpose is \nto unlock AI for India and South Asia's potential,” Chandok said, adding that India is one of the most crucial markets \nfor Microsoft. This depends on Microsoft’s ability to bring its portfolio together to drive customers’ digital \ntransformation and move fast on AI to meet their needs, he said.Ensuring ‘AI fluency’ is the first priority and \nMicrosoft is aiming to simplify AI for customers for greater adoption, he said.The idea is to clear confusion over AI \nand Microsoft's approach is to take use cases by industry to bring clients onboard the AI journey, said Chandok.At \nthe same time, work on cloud and data remain important as AI cannot be leveraged unless they are in place, he \nadded.In 2024, Microsoft will also work with the government to train 3 million government officers on AI fluency in \nIndia, he said.AI adoption in India is three-pronged, Chandok said. \nThe first aspect covers productivity use cases across sectors like manufacturing, banking, services firms and digital \nbusinesses. Second, leveraging AI infrastructure to build large language models (LLMs) focused on India’s \nlanguage, culture and context. The next one is where companies use LLMs and small language models to serve \ntheir customers better. Digital businesses, which have less technical debt and are more experimentative, are more \nactive in this space, Chandok said.Technology enterprises like Infosys and HCLTech are building AI-driven industry \nsolutions and intelligent applications in partnership with Microsoft, Chandok said, adding digital businesses are \nanother focus area where a lot of work is being done.Ecommerce company Myntra last week unveiled \nMyFashionGPT, a generative AI shopping assistant on Microsoft’s Azure OpenAI Service to help customers shop \nusing natural language prompts. Online travel company MakeMyTrip in May launched generative AI-powered \nvoice-based bookings in Indian languages on its platform powered by Azure OpenAI Service.Chandok said more \nsuch partnerships can be expected in 2024.“Our belief is that you will have AI embedded into pretty much every \napplication…It's a question of when, not why and how it will happen,” Chandok said. “Customers who are moving \nahead on this journey, who are moving fast, are seeing a significant uptick in both customer retention, growth, top \nline impact, and the people who don't adopt it will be left behind.”AI technology has evolved from conversations to \nintelligence, with AI being able to summarise meetings and make recommendations, Chandok said. The next step \nin the evolution will be agency, whereby AI can actually carry out tasks on its own.Startups too are a big part of \nMicrosoft’s mission in India, Chandok said, adding it currently engages with 8,000 startups through the Founder’s \nHub.“We have quite a few programmes that are focused on AI startups. The intent is to help them where they need \nhelp,” whether through credits to access compute infrastructure or with technical capabilities and expertise, he \nsaid.With GitHub Copilot, the 13 million Indian developers on GitHub are seeing a 55% improvement in their \nproductivity, Chandok said. For Reprint Rights: timescontent.com\nMicrosoft India looks to demystify AI to push business adoption\nLoad-Date: January 1, 2024"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Sep2023",
        "header": "AI MAY REVOLUTIONIZE EMAIL—FOR HACKERS",
        "media": "Wall Street Journal Abstracts",
        "time": "September 8, 2023",
        "section": "B; Pg. 4",
        "length": "24 words",
        "byline": "JAMES RUNDLE",
        "story_text": "AI MAY REVOLUTIONIZE EMAIL—FOR HACKERS\nWall Street Journal Abstracts\nSeptember 7, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 4\nLength: 24 words\nByline: JAMES RUNDLE\nBody\nABSTRACT\nGenerative-artificial-intelligence tools promise to fix common red flags used to identify bogus emaILS and texts \nused in phishing attacks (S)\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "ChatFished: How to Lose Friends and Alienate People With A.I.",
        "media": "The New York Times",
        "time": "May 8, 2023",
        "section": "BUSINESS",
        "length": "1827 words",
        "byline": "Emma Goldberg",
        "story_text": "ChatFished: How to Lose Friends and Alienate People With A.I.\nThe New York Times \nMay 7, 2023 Sunday 12:58 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BUSINESS\nLength: 1827 words\nByline: Emma Goldberg\nHighlight: Inbox management can be mind-numbing. You might have wondered, couldn’t a robot do this?\nBody\nInbox management can be mind-numbing. You might have wondered, couldn’t a robot do this?\nFive hours is enough time to watch a Mets game. It is enough time to listen to the Spice Girls’ “Spice” album (40 \nminutes), Paul Simon’s “Paul Simon” album (42 minutes) and Gustav Mahler’s third symphony (his longest). It is \nenough time to roast a chicken, text your friends that you’ve roasted a chicken and prepare for an impromptu dinner \nparty.\nOr you could spend it checking your email. Five hours is about how long many workers spend on email each day. \nAnd 90 minutes on the messaging platform Slack.\nIt’s a weird thing, workplace chatter like email and Slack: It’s sometimes the most delightful and human part of the \nwork day. It can also be mind-numbing to manage your inbox — to the extent you might wonder, couldn’t a robot do \nthis?\nIn late April, I decided to see what it would be like to let artificial intelligence into my life. I resolved to do an \nexperiment. For one week, I would write all my work communication — emails, Slack messages, pitches, follow-ups \nwith sources — through ChatGPT, the artificial intelligence language model from the research lab OpenAI. I didn’t \ntell colleagues until the end of the week (except in a few instances of personal weakness). I downloaded a Chrome \nextension that drafted email responses directly into my inbox. But most of the time, I ended up writing detailed \nprompts into ChatGPT, asking it to be either witty or formal depending on the situation.\nWhat resulted was a roller coaster, emotionally and in terms of the amount of content I was generating. I started the \nweek inundating my teammates (sorry) to see how they would react. At a certain point, I lost patience with the bot \nand developed a newfound appreciation for phone calls.\nMy bot, unsurprisingly, couldn’t match the emotional tone of any online conversation. And I spend a lot of the week, \nbecause of hybrid work, having online conversations.\nThe impulse to chat with teammates all day isn’t wrong. Most people know the thrill (and also, usefulness) of office \nfriendships from psychologists, economists, TV sitcoms and our own lives; my colleague sends me photos of her \nbaby in increasingly chic onesies every few days, and nothing makes me happier. But the amount of time workers \nfeel they must devote to digitally communicating is undoubtedly excessive — and for some, easy to make the case \nfor handing over to artificial intelligence.\nThe release of generative A.I. tools has raised all sorts of enormous and thorny questions about work. There are \nfears about what jobs will be replaced by A.I. in 10 years — Paralegals? Personal assistants? Movie and television \nwriters are currently on strike, and one issue they’re fighting for is limiting the use of A.I. by the studios. There are \nChatFished: How to Lose Friends and Alienate People With A.I.\nalso fears about the toxic and untruthful information A.I. can spread in an online ecosystem already rife with \nmisinformation. \nThe question driving my experiment was far narrower: Will we miss our old ways of working if A.I. takes over the \ndrudgery of communication? And would my colleagues even know, or would they be Chatfished?\nMy experiment started on a Monday morning with a friendly Slack message from an editor in Seoul who had sent \nme the link to a study analyzing humor across more than 2,000 TED and TEDx Talks. “Pity the researchers,” the \neditor wrote to me. I asked ChatGPT to say something clever in reply, and the robot wrote: “I mean, I love a good \nTED Talk as much as the next person, but that’s just cruel and unusual punishment!”\nWhile not at all resembling a sentence I would type, this seemed inoffensive. I hit send.\nI had begun the experiment feeling that it was important to be generous in spirit toward my robot co-conspirator. By \nTuesday morning, though, I found that my to-do list was straining the limits of my robot’s pseudo-human wit. It so \nhappened that my colleagues on the Business desk were planning a party. Renee, one of the party planners, asked \nme if I could help draft the invitation.\n“Maybe with your journalistic voice, you can write a nicer sentence than I just have,” Renee wrote to me on Slack.\nI couldn’t tell her that my use of “journalistic voice” was a sore subject that week. I asked ChatGPT to craft a funny \nsentence about refreshments. “I am thrilled to announce that our upcoming party will feature an array of delicious \ncheese plates,” the robot wrote. “Just to spice things up a bit (pun intended), we may even have some with a \nbusiness-themed twist!”\nRenee was unimpressed and, ironically, wrote to me: “OK, wait, let me get the ChatGPT to make a sentence.”\nMeanwhile, I had exchanged a series of messages with my colleague Ben about a story we were writing together. \nIn a moment of anxiety, I called him to let him know it was ChatGPT writing the Slack messages, not me, and he \nadmitted that he had wondered whether I was annoyed at him. “I thought I’d broken you!” he said.\nWhen we got off the phone, Ben messaged me: “Robot-Emma is very polite, but in a way I’m slightly concerned \nmight hide her intention to murder me in my sleep.”\n“I want to assure you that you can sleep peacefully knowing that your safety and security are not at risk,” my bot \nreplied. “Take care and sleep well.”\nGiven the amount of time I spend online talking to colleagues — about the news, story ideas, occasionally “Love Is \nBlind” — it was disconcerting stripping those communications of any personality.\nBut it’s not at all far-fetched. Microsoft earlier this year introduced a product, Microsoft 365 Copilot, that could \nhandle all the tasks I asked ChatGPT to do and far more. I recently saw it in action when Microsoft’s corporate vice \npresident, Jon Friedman, showed me how Copilot could read emails he’d received, summarize them and then draft \npossible replies. Copilot can take notes during meetings, analyze spreadsheet data and identify problems that might \narise in a project.\nI asked Mr. Friedman if Copilot could mimic his sense of humor. He told me that the product wasn’t quite there yet, \nalthough it could make valiant comedic attempts. (He has asked it, for example, for pickleball jokes, and it delivered: \n“Why did the pickleball player refuse to play doubles? They couldn’t dill with the extra pressure!”)\nOf course, he continued, Copilot’s purpose is loftier than mediocre comedy. “Most of humanity spends way too \nmuch time consumed with what we call the drudgery of work, getting through our inbox,” Mr. Friedman said. “These \nthings just sap our creativity and our energy.”\nMr. Friedman recently asked Copilot to draft a memo, using his notes, recommending one of his employees for a \npromotion. The recommendation worked. He estimated that two hours’ worth of work was completed in six minutes.\nChatFished: How to Lose Friends and Alienate People With A.I.\nTo some, though, the time savings aren’t worth the peculiarity of outsourcing relationships.\n“In the future, you’re going to get an email and someone will be like ‘Did you even read it?’ And you’ll be like ‘no’ \nand then they’ll be like ‘Well I didn’t write the response to you,’” said Matt Buechele, 33, a comedy writer who also \nmakes TikToks about office communications. “It’ll be robots going back and forth to each other, circling back.”\nMr. Buechele, in the middle of our phone interview, asked me unprompted about the email I had sent to him. “Your \nemail style is very professional,” he said.\nI confessed that ChatGPT had written the message to him requesting an interview.\n“I was sort of like, ‘This is going to be the most awkward conversation of my life,’” he said.\nThis confirmed a fear I’d been developing that my sources had started to think I was a jerk. One source, for \nexample, had written me an effusive email thanking me for an article I’d written and inviting me to visit his office \nwhen I was next in Los Angeles.\nChatGPT’s response was muted, verging on rude: “I appreciate your willingness to collaborate.”\nI was feeling mournful of my past exclamation-point studded internet existence. I know people think exclamation \npoints are tacky. The writer Elmore Leonard advised measuring out “two or three per 100,000 words of prose.” \nRespectfully, I disagree. I often use two or three per two or three words of prose. I’m an apologist for digital \nenthusiasm. ChatGPT, it turns out, is more reserved.\nFor all the irritation I developed toward my robot overlord, I found that some of my colleagues were impressed by \nmy newly polished digital persona, including my teammate Jordyn, who consulted me on Wednesday for advice on \nan article pitch.\n“I have a story idea I’d love to chat with you about,” Jordyn wrote to me. “It’s not urgent!!”\n“I’m always up for a good story, urgent or not!” my robot replied. “Especially if it’s a juicy one with plot twists and \nunexpected turns.”\nAfter a few minutes of back-and-forth, I was desperate to talk with Jordyn in person. I was losing patience with the \nbot’s cloying tone. I missed my own stupid jokes, and (comparatively) normal voice.\nMore alarmingly, ChatGPT is prone to hallucinating — meaning putting words and ideas together that don’t actually \nmake sense. While writing a note to a source about the timing for an interview, my bot randomly suggested asking \nhim whether we should coordinate our outfits in advance so that our auras and chakras wouldn’t clash.\nI asked ChatGPT to draft a message to another colleague, who knew about my experiment, telling him I was in hell. \n“I’m sorry, but I cannot generate inappropriate or harmful content,” the robot replied. I asked it to draft a message \nexplaining that I was losing my mind. ChatGPT couldn’t do that either.\nOf course, many of the A.I. experts I consulted were undeterred by the notion of shedding their personalized \ncommunication style. “Truthfully, we copy and paste a lot already,” said Michael Chui, a McKinsey partner and \nexpert in generative A.I.\nMr. Chui conceded that some people see signs of dystopia in a future where workers communicate mostly through \nrobots. He argued, though, that this wouldn’t look all that unlike corporate exchanges that are already formulaic. “I \nrecently had a colleague send me a text message saying, ‘Hey was that last email you sent legit?’” Mr. Chui \nrecalled.\nIt turned out that the email had been so stiff that the colleague thought it was written through ChatGPT. Mr. Chui’s \nsituation is a bit particular, though. In college, his freshman dorm voted to assign him a prescient superlative: “Most \nlikely to be replaced by a robot of his own making.”\nChatFished: How to Lose Friends and Alienate People With A.I.\nI decided to end the week by asking the deputy editor of my department what role he saw for A.I. in the newsroom’s \nfuture. “Do you think there’s a possibility that we could see AI-generated content on the front page one day?” I \nwrote over Slack. “Or do you think that there are some things that are just better left to human writers?”\n“Well, that doesn’t sound like your voice!” the editor replied.\nA day later, my experiment complete, I typed back my own response: “That’s a relief!!!”\nPHOTO (PHOTOGRAPH BY RICHARD BORGE) This article appeared in print on page BU5.\nLoad-Date: May 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "How to Use A.I. for Family Time",
        "media": "The New York Times",
        "time": "July 11, 2023",
        "section": "TECHNOLOGY",
        "length": "964 words",
        "byline": " ",
        "story_text": "How to Use A.I. for Family Time\nThe New York Times \nJuly 7, 2023 Friday 13:32 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 964 words\nHighlight: Plan meals, find gifts and create stories using generative A.I.\nBody\nPlan meals, find gifts and create stories using generative A.I.\nHello! We’re back with another bonus edition of On Tech: A.I., a pop-up newsletter that teaches you about artificial \nintelligence, how it works and how to use it.\nLast week, I walked you through how to turn artificial intelligence into a tutor and research assistant. In the final \ninstallment of our how-to editions, we’ll take what we’ve learned and use it to make the most of family time.\nWe’ll focus on a few tasks that can take up a lot of mental bandwidth at home. Weekly meal planning is a major \nchore, and gift giving can be daunting, with various birthdays and holidays throughout the year. And any adult who \nhas read books for children knows that it can become repetitive, and the books aren’t always relatable to a child’s \nsituation or growing pains.\nHere’s how A.I. can help.\nMeal plans\nFoodies and private chefs have been enthusiastically using A.I. to sketch out comprehensive meal plans that \nconsider people’s preferences and dietary restrictions. (Cooks are less gung ho about A.I.-generated recipes, which \ncan be a disaster if a bot screws up.)\nIt turns out that brainstorming meals is a borderline superpower for a chatbot like ChatGPT or Bing. As always, the \nmore detailed you are with your requests, the better. For example, a private chef posting on Reddit shared an \nexample of a prompt asking for a three-day meal plan for a diabetic vegan with a nut allergy.\nI asked ChatGPT for a meal plan formatted in a printer-friendly chart that can be stuck on the refrigerator. Here is \nmy prompt:\nAct as a private chef. I have a family of two, me and my wife. Plan meals for us for five days, including breakfast, \nsnacks, lunch and dinner. We like Chinese, Japanese, Thai and Italian food. I like meat; my wife prefers chicken \nand seafood. We have no restrictions. We are trying to shed a few pounds after the pandemic.\nThe chatbot came up with this:\nGenerative A.I. often produces different results from the same prompt. If you want to shuffle the deck and get \nslightly different menu suggestions, you can always enter the prompt again. And by all means, tweak the \ninstructions for different results.\nHow to Use A.I. for Family Time\nWhat about the actual recipes to make these dishes? I followed up with this prompt: “Can you find recipes for all of \nthose meal suggestions? Please include a link to the recipes online so I can check the source.”\nChatGPT responded with a long list of recipes from sites including The Food Network, BBC, and a number of \nspecialist food blogs.\n(The subscriber-only version with GPT-4 produced the best results here; the free version with GPT-3 returned some \nbroken links, presumably because its training data is older. Microsoft’s Bing’s chatbot is also good at this type of \nquery, but Google’s Bard bot declined to return specific links to recipes.)\nOne last trick: Ask your bot to compile a list of ingredients for all the recipes. It can even group them by grocery \nstore aisle.\nAs always, to play it safe, double check the recipes to make sure your bot isn’t hallucinating.\nGifts\nLet’s move on to gift giving — a talent that some of us possess more than others. There are several A.I. tools that \naim to make selecting a gift easier, including a website that comes up with gift ideas based on someone’s \nInstagram profile.\nI preferred DreamGift, which uses a chatbot to ask you a series of questions about your gift recipient’s age, gender, \ninterests and hobbies, along with how much you’re willing to spend, and automatically provides ideas and links to \norder the items online. (My wife confessed that she liked some of the bot’s gift suggestions, which included an \nindoor herb-growing kit, more than some of the gifts I’d given her over the years. Ouch.)\nIf you prefer to use a chatbot, that will work, too. Bing and Bard, which are connected to search engines, are \npowerful shopping assistants. The trick to getting bespoke recommendations is to share voluminous details about \nyour budget and the people you’re shopping for.\nStorytelling\nLet’s end with something more creative. You can use A.I. to create a customized bedtime story or even your own \nhard-copy children’s book.\nGive a chatbot like ChatGPT or Bard a detailed prompt that includes your child’s preferred storytelling style, any \ndetails you’d like to include and the situation that you want the story to address. Here’s a prompt I wrote for a \nhypothetical child who is unhappy about moving to a new home. I asked it to involve some familiar characters:\nAct as a children’s book writer, mimicking “Frog and Toad.” My kid is going through a rough time — we are moving \nto a new home and changing schools. Write a story to help him process that. Incorporate our dogs, Max and Mochi \nthe corgis, as characters.\nThe chatbot generated a heartfelt story about Max and Mochi, a pair of furry siblings. They enjoyed playing in the \npark and were sad to move to a new home. But they supported each other and eventually went to a new school, \nwhere they made new friends: Bella the sprightly Beagle and Charlie the cheeky Chihuahua. Everything worked out \nin the end.\nIf you’re feeling extra ambitious, you can generate illustrations to accompany the text. (We covered image \ngenerators in an earlier newsletter.) I asked Midjourney to produce an illustration for a children’s book of two corgis \nplaying in a park together.\nTo produce a full book, I’d ask Midjourney to generate images to accompany each paragraph of the chatbot’s story. \nThen I’d use a photo service that offers a book option, such as Google Photos or Shutterfly, to have the custom-\nmade children’s book printed and shipped to me.\nHow to Use A.I. for Family Time\nThank you for being a subscriber\nWe want to hear from you. You can reach us at ontech@nytimes.com.\nBrowse all of our subscriber-only newsletters here.\nThis article appeared in print on page B2.\nLoad-Date: July 11, 2023"
    },
    {
        "file_name": "Los_Angeles_Times_Apr2024",
        "header": "CITY & STATE; Laguna Beach High investigates AI-image scandal",
        "media": "Los Angeles Times",
        "time": "April 8, 2024",
        "section": "CALIFORNIA; Metro Desk; Part B; Pg. 1",
        "length": "937 words",
        "byline": "Hannah Fry",
        "story_text": "CITY & STATE; Laguna Beach High investigates AI-image scandal\nLos Angeles Times\nApril 8, 2024 Monday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: CALIFORNIA; Metro Desk; Part B; Pg. 1\nLength: 937 words\nByline: Hannah Fry\nBody\nLaguna Beach High School administrators have launched an investigation after a student allegedly created and \ncirculated \"inappropriate images\" of other students using artificial intelligence.\nIt is unclear how many students are involved in the scandal, what specifically the images contained or how they \nwere distributed.\nIn an email to parents on March 25, Principal Jason Allemann wrote that school leadership is \"taking steps to \ninvestigate and directly address this issue with those involved, while also using this situation as a teachable \nmoment for our students, reinforcing the importance of responsible behavior and mutual respect.\"\nThe Laguna Beach Police Department is assisting with the investigation, but a department spokesperson declined \nto provide any details on the probe because the individuals involved are minors.\nThe Orange County high school joins a growing number of educational institutions grappling with the use of artificial \nintelligence in the classroom and in social settings.\nAt schools across the country, people have used deepfake technology combined with real images of female \nstudents to create fraudulent images of nude bodies. The deepfake images can be produced using a cellphone.\nLast month, five Beverly Hills eighth-graders were expelled for their involvement in the creation and sharing of fake \nnude pictures of their classmates.\nThe students superimposed pictures of their classmates' faces onto simulated nude bodies generated by artificial \nintelligence. In total, 16 eighth-grade students were targeted by the pictures, which were shared through messaging \napps, according to the district.\nA 16-year-old high school student in Calabasas said a former friend used AI to generate pornographic images of \nher and circulated them, KABC-TV reported last month.\nIt's not just teens who are being targeted by AI-created images. In January, AI-generated sexually explicit images of \npopular singer-songwriter Taylor Swift were distributed on social media. The situation prompted calls from angered \nfans for lawmakers to adopt legislation to protect against the creation and sharing of deepfake images.\n\"It is a very challenging space and the technological advancements and capabilities are occurring at a very rapid \npace, which makes it all the more challenging to wrap one's head around,\" said Amy Mitchell, the executive director \nof the Center for News, Technology and Innovation, a policy research center.\nCITY & STATE Laguna Beach High investigates AI-image scandal\nSeveral federal bills have been proposed, including the Preventing Deepfakes of Intimate Images Act, which would \nmake it illegal to produce and share AI-generated sexually explicit material without the consent of the individuals \nbeing portrayed.\nThe Disrupt Explicit Forged Images and Non-Consensual Edits, or DEFIANCE Act, which was introduced this year, \nwould allow victims to sue the creators of the deepfakes if they knew the victim did not consent to its creation.\nIn California, state lawmakers have proposed extending laws prohibiting revenge porn and child porn to computer-\ngenerated images.\nSchool districts are also trying to get a handle on the technology. This year, the Orange County Department of \nEducation began leading monthly meetings with school districts to talk about the use of AI and how to integrate it \ninto the education system.\nBut the problem with manipulated imagery like those that circulated at Laguna Beach High School is getting worse \nas the technology becomes more prevalent and easier to use, according to experts.\nArtificial intelligence, particularly generative AI, continues to advance faster than society can responsibly absorb it, \nsaid Cindi Howson, chief data strategy officer at the technology company ThoughtSpot.\n\"The world is on a learning curve for generative AI, and it's moving so quickly that we cannot just leave it up to \nregulators, the builders of AI or the schools themselves,\" she said.\nParents, school districts, government and the creators of AI platforms will have to each play a role in implementing \nsafeguards, Howson said.\nIn the meantime, she suggests parents monitor which apps their children are using and have conversations with \nthem about how this technology can be used and abused.\nArtificial intelligence technology paired with the widespread use of social media among teens who might not fully \nunderstand the consequences seems like an intractable problem, said Sheri Morgan, a Laguna Beach resident \nwhose daughter attends Laguna Beach High School.\n\"The social media that's out there today, I think, further emphasizes this false sense of what you need, what you \nwant, how you should look, and how you should be perceived by people,\" she said. \"We talk to our kids a lot about \nthe impacts of technology and social media and getting lost in the distraction of it, but it's a challenge.\"\nIn Laguna Beach, district officials have not detailed the possible disciplinary options being considered by \nadministrators. The district in a statement said that each incident \"is handled on a case-by-case basis considering \nthe individual circumstances of the situation.\"\nThe high school, which has more than 1,000 students enrolled, plans to host panel discussions on AI-generated \ncontent for students during the school day. The panel will include the school resource officer, counselors, \npsychologists and digital media and library specialists, Allemann wrote in a follow-up email to parents Friday.\n\"In our small community, these incidents can have a far-reaching impact on our campus culture,\" Allemann wrote. \n\"These actions not only compromise individual dignity but also undermine the positive and supportive environment \nwe aim to foster at LBHS.\"\nGraphic\n \nCITY & STATE Laguna Beach High investigates AI-image scandal\nPHOTO: \"INAPPROPRIATE\" AI-generated images of students were circulated at Laguna Beach High School.  \nPHOTOGRAPHER:Don Leach Daily Pilot \nLoad-Date: April 8, 2024"
    },
    {
        "file_name": "2023_(an_anti-gift_guide)_Dec2023",
        "header": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; The worst offerings of",
        "media": "2023 (an anti-gift guide)",
        "time": "December 11, 2023",
        "section": "MAIN NEWS; Business Desk; Part A; Pg. 1",
        "length": "1274 words",
        "byline": "BRIAN MERCHANT",
        "story_text": "BUSINESS; ON TECHNOLOGY AND THE INTERNET; The worst offerings of \n2023 (an anti-gift guide)\nLos Angeles Times\nDecember 11, 2023 Monday\nFinal Edition\nCopyright 2023 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Business Desk; Part A; Pg. 1\nLength: 1274 words\nByline: BRIAN MERCHANT\nBody\nIt's the holidays, and you know what that means: an endless stream of wish lists, gift guides, and splashy sales of \nproducts competing for our cash. Since this is the 21st century, so many of those are tech products -- wearables, \nAI-infused gadgets, smart birdhouses, a firepit you control with an app, you name it.\nIt's been a lot.\nSo I got to thinking: What if there was something closer to the opposite of a holiday wish list for tech products? \nWhat if, given all the attention focused on the tech we're being exhorted to buy, we took the occasion to ask \nwhether we need a $150 digitized mug that keeps your coffee heated to a precise temperature? (Seriously, I am \nseeing this thing everywhere.)\nWhat if we took the tech-saturated holidays as an opportunity to instead consider a list of all the tech we wished \nwould go away? A sort of anti-tech gift guide? Maybe it'd help us confront the ways that consumerism has governed \nthe ways tech has come to rule our lives a little.\nI'd be lying if I said this line of thinking hasn't been on my mind. As part of my recent book tour, I've been holding \nevents called Luddite Tribunals. The Luddites, a movement of 19th-century textile workers who resisted the \nautomation of their trade, didn't hate all technology, or progress, as is commonly misunderstood -- they opposed \ntechnology that was hurtful to society at large. So, first in New York, and then in the San Francisco Bay Area, I \ngathered a host of tech workers, scholars, journalists and artists to consider whether a series of technology \nproducts were a net benefit or net drain on society.\nWe considered AI-generated art, Amazon Ring doorbells, iPhones, HP printers, and so on. After a deliberation -- \ndid the technology hurt workers, con consumers, or spread surveillance, more than they provided joy or utility to the \nuser? -- if the tribunal gave it the thumbs down, well, we smashed the offending technology with a sledgehammer. \nJust like the Luddites did to the power looms.\nLook, I'm not going to say it was the most mature book event idea, but it made for lively, provocative discussion, \nand boy was it cathartic.\nSo! In that spirit, I went to some participants in those events, as well as to some of the sharpest thinkers and critics \nin tech, to ask them to help me fill out a list of tech products, services and concepts we absolutely are not wishing \nfor this holiday season -- and in fact, wish weren't around altogether. In most of these cases, it's not a question of \nthe core technology, which is simple software or hardware, but the uses to which it is being put. ( That is what the \nLuddites took issue with too!)\nBUSINESS ON TECHNOLOGY AND THE INTERNET The worst offerings of 2023 (an anti-gift guide)\nThere's nothing wrong with a printer as a piece of hardware, for instance. But there's a reason that it's proved the \nmost popular piece of tech to smash, and would probably make the least popular Christmas gift you've ever given: \nFor one thing, modern printers break down notoriously fast. They're deeply consumer-unfriendly, and worse, many \nnow require the user to purchase a subscription to buy ink, and come loaded with software that can tell if you \npurchased a competitor's ink, or failed to pay your monthly subscription -- and can brick the printer, and keep it from \nworking as a result. This is ridiculous, and is as good an example as tech we wish would disappear, in its current \nconfiguration.\nSo! Without further ado, our list of the worst tech of the year. First up, a product I'm seeing on lots and lots of actual \nyear-end gift guide lists, but which has given me the creeps since it entered the market.\n--\nAmazon Ring doorbells\nEdward Ongweso Jr., finance editor at Logic magazine and co-host of \"This Machine Kills.\"\nA world where the Ring surveillance camera never existed bears a closer resemblance to the world the company \nclaims to be working toward. Amazon (and the police departments to which it offers Ring surveillance cameras for \nfree) have deputized denizens of America's already paranoid cities and towns to discipline underpaid and \noverworked delivery workers, suspect every neighbor or pedestrian of the most heinous of crimes (beginning with \npackage theft), and give the delivery empire greater insight into the rhythm of the lives of its customers and their \nneighborhoods.\n--\nUber\nVeena Dubal, professor of law at UC Irvine and expert in gig work law.\nNot because of the technology, but the business model. Taxi workers were using the same technology prior to the \nadvent of Uber and Lyft, so it's not the tech I object to, but how the companies use the technology. It's the addition \nof surveillance and algorithmic control to the system that makes Uber so much worse.\n--\nGenerative AI\nParis Marx, author, journalist and host of \"Tech Won't Save Us.\"\nI've been frustrated to see the impact of generative AI on creative professions (and heartened by the strong and \nrapid pushback), but it goes far beyond that. The hype around AI has justified a further rollout in other areas that will \nhave serious repercussions for marginalized communities, such as the U.K. government's plan for an AI \"hit squad\" \nto replace humans with machines in immigration and public services. But even worse is when it has mortal \nconsequences, as recent reports have detailed Israel's use of AI to vastly increase its targets in Gaza, leading to an \nenormous death toll.\n--\nRemote attestation tools\nCory Doctorow, science fiction author, activist and journalist. His latest book is \"The Lost Cause.\"\nThese are cryptographic systems inside digital devices -- everything from a phone to a car engine -- that allow \nservices to extract true information about your device from it, even when you'd prefer otherwise. Think of an inkjet \nprinter verifying that you're not using third-party ink, or an app verifying that you're not using an ad-blocker. These \nBUSINESS ON TECHNOLOGY AND THE INTERNET The worst offerings of 2023 (an anti-gift guide)\nhave proliferated into every domain -- there's even locomotives that use versions of this to lock up entire trains if the \nmanufacturer detects that you've had the engine serviced by independent technicians.\n--\n23andMe\nJason Koebler, investigative journalist and co-founder of 404 Media\nGenome sequencing and personalized medicine have great promise, and genetic databases have also helped \npeople find their [biological] parents. Still, there are incredible risks associated with giving your immutable genetic \ncode (and, by association, the genetic code of your close relatives) to a for-profit database, which can begin looking \nlike a gold mine to law enforcement, big pharma companies, and, as we've unfortunately learned [last] week, \nhackers.\n--\nThe concentration of power in big tech\nMeredith Whittaker, CEO of Signal.\nMaybe instead of focusing on the tech, I'll focus on the incentives that drive its production and deployment currently. \nThese are too often efficiency at the expense of worker well-being, cost savings at the expense of safety and \nintegrity, and the illusion of computational sophistication at the expense of meaningful accountability -- or \nautomation as a liability shield. This is compounded by the extraordinary concentration of power in the tech \nindustry. By and large these imperatives are shaping what tech gets built, the stories told about it, and the growing \nchasm between those with the power to make and use it and those on whom it's used, and who suffer the blunt \nforce of its harms.\n::\nNow that's my kind of gift guide.\nSo, how about you? What tech products would make your list? Shoot us a letter to the editor or email me at \nbrian.merchant@latimes.com and explain your reasoning, and we'll consider them for inclusion in the follow-up -- \nthe worst tech of the year, readers' choice edition. Until then, happy holidays, and keep that proverbial hammer \nhoisted high.\nGraphic\n \nPHOTO: A WORLD without a Ring surveillance camera bears a closer resemblance to the world the company \nclaims to be working toward, Edward Ongweso Jr. said.  PHOTOGRAPHER:Jessica Hill Associated Press \nLoad-Date: December 11, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Jul2023",
        "header": "MICRON’S LONG ROAD BACK HITS A DETOUR",
        "media": "Wall Street Journal Abstracts",
        "time": "July 1, 2023",
        "section": "B; Pg. 12",
        "length": "46 words",
        "byline": "DAN GALLAGHER",
        "story_text": "MICRON’S LONG ROAD BACK HITS A DETOUR\nWall Street Journal Abstracts\nJune 30, 2023 Friday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 12\nLength: 46 words\nByline: DAN GALLAGHER\nBody\nABSTRACT\nDan Gallagher Heard on the Street column on prospects for chip maker Micron Technology after dismal report, \nsuggesting its recovery will be unpredictable even as it aims to take market share from rivals and build on demand \nfor generative artificial intelligence; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: July 1, 2023"
    },
    {
        "file_name": "The_New_York_Times_Nov2023",
        "header": "A.I. Order Is Aiming For Balance",
        "media": "The New York Times",
        "time": "November 1, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT",
        "length": "1127 words",
        "byline": "By Kevin Roose",
        "story_text": "A.I. Order Is Aiming For Balance\nThe New York Times\nNovember 1, 2023 Wednesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 1; THE SHIFT\nLength: 1127 words\nByline: By Kevin Roose\nBody\nPresident Biden announced regulations on Monday that seemed to have a little bit for everyone.\nHow do you regulate something that has the potential to both help and harm people, that touches every sector of \nthe economy and that is changing so quickly even the experts can't keep up? \n  That has been the main challenge for governments when it comes to artificial intelligence.\n  Regulate A.I. too slowly and you might miss out on the chance to prevent potential hazards and dangerous \nmisuses of the technology.\n  React too quickly and you risk writing bad or harmful rules, stifling innovation or ending up in a position like the \nEuropean Union's. It first released its A.I. Act in 2021, just before a wave of new generative A.I. tools arrived, \nrendering much of the act obsolete. (The proposal, which has not yet been made law, was subsequently rewritten to \nshoehorn in some of the new tech, but it's still a bit awkward.)\n  On Monday, the White House announced its own attempt to govern the fast-moving world of A.I. with a sweeping \nexecutive order that imposes new rules on companies and directs a host of federal agencies to begin putting \nguardrails around the technology.\n  The Biden administration, like other governments, has been under pressure to do something about the technology \nsince late last year, when ChatGPT and other generative A.I. apps burst into public consciousness. A.I. companies \nhave been sending executives to testify in front of Congress and briefing lawmakers on the technology's promise \nand pitfalls, while activist groups have urged the federal government to crack down on A.I.'s dangerous uses, such \nas making new cyberweapons and creating misleading deepfakes.\n  In addition, a cultural battle has broken out in Silicon Valley, as some researchers and experts urge the A.I. \nindustry to slow down, and others push for its full-throttle acceleration.\n  President Biden's executive order tries to chart a middle path -- allowing A.I. development to continue largely \nundisturbed while putting some modest rules in place, and signaling that the federal government intends to keep a \nclose eye on the A.I. industry in the coming years. In contrast to social media, a technology that was allowed to \ngrow unimpeded for more than a decade before regulators showed any interest in it, it shows that the Biden \nadministration has no intent of letting A.I. fly under the radar.\n  The full executive order, which is more than 100 pages, appears to have a little something in it for almost \neveryone.\nA.I. Order Is Aiming For Balance\n  The most worried A.I. safety advocates -- like those who signed an open letter this year claiming that A.I. poses a \n''risk of extinction'' akin to pandemics and nuclear weapons -- will be happy that the order imposes new \nrequirements on the companies that build powerful A.I. systems.\n  In particular, companies that make the largest A.I. systems will be required to notify the government and share the \nresults of their safety testing before releasing their models to the public.\n  These reporting requirements will apply to models above a certain threshold of computing power -- more than 100 \nseptillion integer or floating-point operations, if you're curious -- that will most likely include next-generation models \ndeveloped by OpenAI, Google and other large companies developing A.I. technology.\n  These requirements will be enforced through the Defense Production Act, a 1950 law that gives the president \nbroad authority to compel U.S. companies to support efforts deemed important for national security. That could give \nthe rules teeth that the administration's earlier, voluntary A.I. commitments lacked.\n  In addition, the order will require cloud providers that rent computers to A.I. developers -- a list that includes \nMicrosoft, Google and Amazon -- to tell the government about their foreign customers. And it instructs the National \nInstitute of Standards and Technology to come up with standardized tests to measure the performance and safety \nof A.I. models.\n  The executive order also contains some provisions that will please the A.I. ethics crowd -- a group of activists and \nresearchers who worry about near-term harms from A.I., such as bias and discrimination, and who think that long-\nterm fears of A.I. extinction are overblown.\n  In particular, the order directs federal agencies to take steps to prevent A.I. algorithms from being used to \nexacerbate discrimination in housing, federal benefits programs and the criminal justice system. And it directs the \nCommerce Department to come up with guidance for watermarking A.I.-generated content, which could help crack \ndown on the spread of A.I.-generated misinformation.\n  And what do A.I. companies, the targets of these rules, think of them? Several executives I spoke to on Monday \nseemed relieved that the White House's order stopped short of requiring them to register for a license in order to \ntrain large A.I. models, a proposed move that some in the industry had criticized as draconian. It will also not \nrequire them to pull any of their current products off the market, or force them to disclose the kinds of information \nthey have been seeking to keep private, such as the size of their models and the methods used to train them.\n  It also doesn't try to curb the use of copyrighted data in training A.I. models -- a common practice that has come \nunder attack from artists and other creative workers in recent months and is being litigated in the courts.\n  And tech companies will benefit from the order's attempts to loosen immigration restrictions and streamline the \nvisa process for workers with specialized expertise in A.I. as part of a national ''A.I. talent surge.''\n  Not everyone will be thrilled, of course. Hard-line safety activists may wish that the White House had placed \nstricter limits around the use of large A.I. models, or that it had blocked the development of open-source models, \nwhose code can be freely downloaded and used by anyone. And some gung-ho A.I. boosters may be upset that the \ngovernment is doing anything at all to limit the development of a technology they consider mostly good.\n  But the executive order seems to strike a careful balance between pragmatism and caution, and in the absence of \ncongressional action to pass comprehensive A.I. regulations into law, it seems like the clearest guardrails we're \nlikely to get for the foreseeable future.\n  There will be other attempts to regulate A.I. -- most notably in the European Union, where the A.I. Act could \nbecome law as soon as next year, and in Britain, where a summit of global leaders this week is expected to \nproduce new efforts to rein in A.I. development.\n  The White House's executive order is a signal that it intends to move fast. The question, as always, is whether A.I. \nitself will move faster.\nA.I. Order Is Aiming For Balance\nhttps://www.nytimes.com/2023/10/31/technology/executive-order-artificial-intelligence-regulation.html\nGraphic\n \nPHOTO: President Biden's executive order shows that the administration has no intention of letting A.I. fly under the \nradar. (PHOTOGRAPH BY DOUG MILLS/THE NEW YORK TIMES) (B6) This article appeared in print on page B1, \nB6.               \nLoad-Date: November 1, 2023"
    },
    {
        "file_name": "Los_Angeles_Times_Mar2024",
        "header": "Fake nude images highlight gaps in law",
        "media": "Los Angeles Times",
        "time": "March 3, 2024",
        "section": "MAIN NEWS; Metro Desk; Part A; Pg. 1",
        "length": "1179 words",
        "byline": "Jon Healey",
        "story_text": "Fake nude images highlight gaps in law\nLos Angeles Times\nMarch 3, 2024 Sunday\nFinal Edition\nCopyright 2024 Los Angeles Times All Rights Reserved\nSection: MAIN NEWS; Metro Desk; Part A; Pg. 1\nLength: 1179 words\nByline: Jon Healey\nBody\nIf an eighth-grader in California shared a nude photo of a classmate with friends without consent, the student could \nconceivably be prosecuted under state laws dealing with child pornography and disorderly conduct.\nIf the photo is an AI-generated deepfake, however, it's not clear that any state law would apply.\nThat's the dilemma facing the Beverly Hills Police Department as it investigates a group of students from Beverly \nVista Middle School who allegedly shared photos of classmates that had been doctored with an artificial-\nintelligence-powered app. According to the district, the images used real faces of students atop AI-generated nude \nbodies.\nLt. Andrew Myers, a spokesman for the Beverly Hills police, said no arrests have been made and the investigation \nis continuing.\nBeverly Hills Unified School District Supt. Michael Bregy said the district's investigation into the episode is in its final \nstages.\n\"Disciplinary action was taken immediately and we are pleased it was a contained, isolated incident,\" Bregy said in \na statement, although no information was disclosed about the nature of the action, the number of students involved \nor their grade level.\nHe called on Congress to prioritize the safety of children in the U.S., adding that \"technology, including AI and \nsocial media, can be used incredibly positively, but much like cars and cigarettes at first, if unregulated, they are \nutterly destructive.\"\nWhether the fake nudes amount to a criminal offense, however, is complicated by the technology involved. Federal \nlaw includes computer-generated images of identifiable people in the prohibition on child pornography. Although the \nprohibition seems clear, legal experts caution that it has yet to be tested in court.\nCalifornia's child pornography law does not mention artificially generated images. Instead, it applies to any image \nthat \"depicts a person under 18 years of age personally engaging in or simulating sexual conduct.\"\nJoseph Abrams, a Santa Ana criminal defense attorney, said an AI-generated nude \"doesn't depict a real person.\" It \ncould be defined as child erotica, he said, but not child porn. And from his standpoint as a defense attorney, he \nsaid, \"I don't think it crosses a line for this particular statute or any other statute.\"\n\"As we enter this AI age,\" Abrams said, \"these kinds of questions are going to have to get litigated.\"\nFake nude images highlight gaps in law\nKate Ruane, director of the free expression project at the Center for Democracy & Technology, said that early \nversions of digitally altered child sexual abuse material superimposed the face of a child onto a pornographic image \nof someone else's body. Now, however, freely available \"undresser\" apps and other programs generate fake bodies \nto go with real faces, raising legal questions that haven't been squarely addressed yet, she said.\nStill, she said, she had trouble seeing why the law wouldn't cover sexually explicit images just because they were \nartificially generated. \"The harm that we were trying to address [with the prohibition] is the harm to the child that is \nattendant upon the existence of the image. That is the exact same here,\" Ruane said.\nThere is another roadblock to criminal charges, though. In both the state and federal cases, the prohibition applies \njust to \"sexually explicit conduct,\" which boils down to intercourse, other sex acts and \"lascivious\" exhibitions of a \nchild's privates.\nThe courts use a six-pronged test to determine whether something is a lascivious exhibition, considering such \nthings as what the image focuses on, whether the pose is natural, and whether the image is intended to arouse the \nviewer. A court would have to weigh those factors when evaluating images that weren't sexual in nature before \nbeing \"undressed\" by AI.\n\"It's really going to depend on what the end photo looks like,\" said Sandy Johnson, senior legislative policy counsel \nof the Rape, Abuse & Incest National Network, the largest anti-sexual-violence organization in the United States. \n\"It's not just nude photos.\"\nThe age of the kids involved wouldn't be a defense against a conviction, Abrams said, because \"children have no \nmore rights to possess child pornography than adults do.\" But like Johnson, he noted that \"nude photos of children \naren't necessarily child pornography.\"\nNeither the Los Angeles County district attorney's office nor the state Department of Justice responded immediately \nto requests for comment.\nState lawmakers have proposed several bills to fill the gaps in the law regarding generative AI. These include \nproposals to extend criminal prohibitions on the possession of child porn and the nonconsensual distribution of \nintimate images (also known as \"revenge porn\") to computer-generated images and to convene a working group of \nacademics to advise lawmakers on \"relevant issues and impacts of artificial intelligence and deepfakes.\"\nMembers of Congress have competing proposals that would expand federal criminal and civil penalties for the \nnonconsensual distribution of AI-generated intimate imagery.\nAt Tuesday's meeting of the district Board of Education, Dr. Jane Tavyev Asher, director of pediatric neurology at \nCedars-Sinai, called on the board to consider the consequences of \"giving our children access to so much \ntechnology\" in and out of the classroom.\nInstead of having to interact and socialize with other students, Asher said, students are allowed to spend their free \ntime at the school on their devices. \"If they're on the screen all day, what do you think they want to do at night?\"\nResearch shows that for children under age 16, there should be no social media use, she said. Noting how the \ndistrict was blindsided by the reports of AI-generated nudes, she warned, \"There are going to be more things that \nwe're going to be blindsided by, because technology is going to develop at a faster rate than we can imagine, and \nwe have to protect our children from it.\"\nBoard members and Bregy all expressed outrage at the meeting about the images. \"This has just shaken the \nfoundation of trust and safety that we work with every day to create for all of our students,\" Bregy said, although he \nadded, \"We have very resilient students, and they seem happy and a little confused about what's happening.\"\n\"I ask that parents continuously look at their [children's] phones, what apps are on their phones, what they're \nsending, what social media sites that they're using,\" he said. These devices are \"opening the door for a lot of new \ntechnology that is appearing without any regulation at all.\"\nFake nude images highlight gaps in law\nBoard member Rachelle Marcus noted that the district has barred students from using their phones at school, \"but \nthese kids go home after school, and that's where the problem starts. We, the parents, have to take stronger control \nof what our students are doing with their phones, and that's where I think we are failing completely.\"\n\"The missing link at this point, from my perspective, is the partnership with the parents and the families,\" board \nmember Judy Manouchehri said. \"We have dozens and dozens of programs that are meant to keep your kids off \nthe phones in the afternoon.\"\nGraphic\n \nPHOTO: SECURITY GUARDS stand outside Beverly Vista Middle School last week. A group of students at the \nschool allegedly shared fake nude photos of classmates that had been doctored with an AI-powered app.  \nPHOTOGRAPHER:Jason Armond Los Angeles Times \nLoad-Date: March 3, 2024"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Transcript: Ezra Klein Interviews Melanie Challenger; The Ezra Klein Show",
        "media": "The New York Times",
        "time": "June 27, 2023",
        "section": "PODCASTS",
        "length": "6599 words",
        "byline": " ",
        "story_text": "Transcript: Ezra Klein Interviews Melanie Challenger; The Ezra Klein Show\nThe New York Times \nJune 27, 2023 Tuesday 10:35 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: PODCASTS\nLength: 6599 words\nHighlight: The June 27, 2023, episode of “The Ezra Klein Show.”\nBody\nEvery Tuesday and Friday, Ezra Klein invites you into a conversation about something that matters, like today’s \nepisode with Melanie Challenger. Listen wherever you get your podcasts.\nTranscripts of our episodes are made available as soon as possible. They are not fully edited for grammar or \nspelling.\n[MUSIC PLAYING]\nEZRA KLEIN: From New York Times Opinion, this is “The Ezra Klein Show.”\nSo a quiet theme of the show, a quiet theme, I think, of just being alive at this moment in time, is the troubled \nrelationship between human beings and everything that is not us. I mean, also, of course, between human beings \nand other human beings. But between human beings and the animal world, which we are both a part of and \nsomehow not, or at least like to believe we’re not. Between human beings and animals, some of which we love, and \nwe do anything for their survival like our dogs and our cats. And some of which we raise for food in the cruelest \nconditions imaginable. And many of which we just don’t think about at all and end up affected by our actions but \nnever a part of our calculus.\nBut then, of course, there’s also this emergent relationship between human beings and the kinds of intelligences or \nsimulacra of intelligences that we’re creating. I’m thinking specifically here of artificial intelligence and the way it has \noccasioned a lot of anxiety then about what we are and what our worth is if we can indeed create things more \ncapable than us or smarter than us in narrow tasks and increasingly in general ones.\nSo this question of how humanity relates to its own animal nature, and then how that relationship or that denial of a \nrelationship shows up in our technologies I think is pretty present. And as much as it sounds like a fuzzy \nphilosophical question, I think it ends up being a very policy-relevant one — policy relevant in our policy towards \nanimals, towards farm animals, towards the ecology, towards the environment. And then, of course, towards A.I. \nand how A.I. will be created and permitted to present and what kind of training data it has, what we want from it and \nwhat we want and how we’ll treat people who are harmed by it.\nAll this was in my head as I started reading Melanie Challenger’s book “How to Be Animal: A New History of What it \nMeans to Be Human.” She is an environmental philosopher and historian and a beautifully poetic writer. And she’s \nalso the author of “On Extinction: How We Became Estranged From Nature.” So she’s been thinking about these \nissues for some time. And I think it’s a good moment to think alongside her. As always, my email, \nezrakleinshow@nytimes.com\nMelanie Challenger, welcome to the show.\nMELANIE CHALLENGER: Thank you very much for having me, Ezra.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nEZRA KLEIN: So you write that, “The world is now dominated by an animal that doesn’t think it’s an animal, and the \nfuture is being imagined by an animal that doesn’t want to be an animal. This matters.” Why does it matter?\nMELANIE CHALLENGER: I mean, look at what we’re facing right now. We’re facing a pandemic, we’re facing the \nfallout from that. We’re facing multiple environmental crises. And I think we look at the reasons for that in very \nobvious ways. We look at the politics, we look at the way society is organized but we don’t reflect as often as we \nshould do on either the psychological and the moral dimensions.\nFor me, a lot of the struggles that we face at the moment derive from a particular way of framing our relationship to \nthe world and to ourselves. And I would argue that that originates in the fact that we have a fundamental struggle \nwith being animal and with what follows from being animal. And that’s the starting point for my thesis.\nEZRA KLEIN: There was an interesting point you made midway through the book. You wrote that “many of the \ntensions we experience derive from the distance inherent in being a predator with a rich moral faculty.” And then, \nyou pose the thought experiment, “How different might it have been if our kind of intelligence had spun out of \nherbivores? What if a moral system had emerged among the beavers in Canada?”\nTell me a bit about both sides of that. What do you mean when you say there’s a lot of dissonance in the morality of \na predator species? And what might you imagine, which seems like a wonderful foundation for a sci-fi book, if \nhuman civilization and intelligence sprung out in a species that did not eat meat?\nMELANIE CHALLENGER: In many ways, all of the book is a thought experiment that derives from starting it again \nwith what does it mean if we really examine the fact that we’re animals?\nNow, something that’s really obvious but that we don’t think about enough is that we are a predatory animal. So \nhuman beings yes, we’re omnivorous but we are predators. So we have hunted and we continue in some \ncommunities to hunt animals and to eat them. We continue to consume them.\nSo our farming conditions, for instance, are just a controlled form of predation. All that we’ve done there is taken the \nanimals that we want to eat or whatever products we want to use from them, and we have contained them. But it’s \nstill predation. And I don’t think we think about that enough.\nHow would the world look if we had a different kind of animality? So if our moral systems, our ideas, our beliefs \nabout our world had come out from a different way of being. If we were a manatee, if we were one of the herbivores \nthat we eat, for instance, what kind of world would we have? What kind of modern structures and ideas and belief \nsystems would come from that?\nI think that there are several things that we can speculate on. And I’m going to pose this to people. If there is a \nscience fiction writer out there, take on this idea, and let’s see what they come up with. But I would imagine we \nwould have a different kind of way of dealing with resources and a different therefore different kind of way of \nstructuring the world.\nSo consider the fact that we are a hierarchical primate. So we really care about status for instance. Losses of status \nare disastrous for human beings, particularly actually for males of the species. And these affect us in all kinds of \nways, in our biology, in our bodies but we don’t think about them very often.\nAnd yet, we see them in the world. We see them in the way that the world is structured. We see them in who has \npower. We see them in the way that we perceive certain people as having more charisma or being people more \nvaluable to listen to than others. We’re deeply affected by being a hierarchical primate. Yet oftentimes we just \ncompletely ignore the fact that is what’s underpinning the reality that we take for granted.\nEZRA KLEIN: One thing that I always think can creep into this kind of conversation is an idealization of nature. I \nthink when people say human beings are an animal that rejects its relationship to being an animal, rejects its \nrelationship to nature, I think sometimes there’s a sense that there’s some kind of harmony out there for us to find. \nBut nature is nonharmonious. You’ve got a very nice line in the book where you write, “In one sense, biology seems \nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nto come out of violence, whether that is about energy or extreme heat, the solar system and the Earth’s \nenvironments commit horrors on animals even as they allow for new diversity and change.”\nSo it’s true the human animal is a predator but it is also terrified of predation, terrified of being destroyed by animals \nbigger than we are but also by pathogens, also by floods, by heat, by exposure, by drought, by famine. And so \nthere’s also this deep scarcity working within us not because we’re distant from nature but because nature is pitiless \nat the deepest level. And you write about this, and I’m curious how you think that inflects this relationship.\nMELANIE CHALLENGER: So there’s a lot to unpack there. And that’s really at the core of the book in some ways. \nYes, lots of ghastly things happen in nature and they happen through necessity because there are forces of \nchange, there’s evolutionary process at work. And there’s often an arms race between species, particularly \npredators, of course, and predators and prey. But also just between the environment and the animal, the ability to \nget food. The ability to survive. You get communities of animals but then, of course, get pathogens within those \ncommunities. So there’s this constant battle to make it through.\nWhat is beautiful about any living system is that it seeks to persist despite the barrage of constraints or difficulties \nthat are going to be faced and confronted. But what I would say is the good comes out of the world. And the beauty \ncomes out of the world as well.\nSo yes, we face pathogens or we face predators, for instance, but lots of organisms resolve that by communal \nliving, so they group together. And when organisms start to group together in group living conditions they form \nalliances. And that’s the basis of our friendships, that’s the basis of the intimacy, the willingness that the Samaritan \nhas to help a stranger on the street.\nWhen you have people who are willing to exchange information and help one another you get the birth of all kinds \nof ideas that develop from that. The concept of trust, the concept of helping another in that kind of way.\nAnd you also get that in the body. So if I was to have something awful happen to me and I was to have someone \nthat just sat by me, put a hand on my leg, just talk to me, put a hand on my back and reassured me, my heart rate \nwould come down, my respiratory rate would come down and I would start to feel better.\nThere’s so much beauty that is also made possible from the difficulties that we face in the living condition. And so \ngood comes out of it as much as trial does.\nEZRA KLEIN: You have a wonderful way of illustrating — through actually looking at illustrations — how the \nrelationship between humanity and animals have changed over time. And you do that by tracking how cave \ndrawings and other kinds of early art changed over time. Could you talk through that?\nMELANIE CHALLENGER: Oh sure. I’m pretty nuts about this. I absolutely — this came from a real fascination, like \na real personal fascination rather than a cold intellectual one. I was really fascinated in cave art because I was \ntrying to make sense of a particular kind of way that we visualize being an animal and the kind of mind that we \nhave. The way that we think about animals and exploit images of animals. This was something that I was really \ntrying to get at when I was trying to make sense of not only the things that we fear that follow from being an animal \nbut what we fear about being an animal ourselves. What we confront in the image of being an animal.\nI was in Spain at Altamira, which is a site of some extraordinary cave paintings. And it is an extraordinary place, it’s \nwomb land-ish, you kind of enter into the dark cave, and then it opens out into this chamber and you can’t really \ngrasp what you’re seeing until you lie down but when you lie down on the cave floor you can see just this zoetrope \nof images of wild animals, beautifully exquisitely wrought.\nWhat you don’t see is the shadows. You can see when you’re in the cave that our early ancestors were exploiting \nshadows in order to make their art in certain kinds of ways.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nNow don’t forget that caves were shelters for our early humans. They were places that we hid from predators. That \nwe kept ourselves safe. As well as being places that we might come to worship. These are extraordinary sites that \nconfront us with the kind of minds that we think we’ve left behind but actually is still alive in us.\nAnd what is very interesting about cave art is two aspects of what it means about our kind of cognition. The first is \nthat it is a living document for how our cultural idea shifted and also the sort of psychological way that we related to \nthe living world shifted as we moved from hunter-gathering to agriculture and the first of our kind of early \ncivilizations.\nSo you find that the first original cave paintings were primarily of wild animals, and they were reverential. But as we \nstarted, as human civilization started shifting into domesticating their food sources and hunted more for cultural \nsignificance really rather than necessarily for necessity or to supplement the trials and errors of transitioning to \nfarming, what you find is that there are less and less and less images of wild animals.\nAnd when you do see animals in the latter, the kind of real Neolithic shift, you find that it is now the animals \nsurrounded by humans who are in a position of domination. So it’s this wonderful catalog the cave paintings, of \nwhich there aren’t a huge amount but they still give us this tantalizing glimpse of a psychological and cultural shift \nfrom one of closeness to, and reverence for the rest of the living world towards one of domination. So that’s \nsomething that’s very interesting.\n[MUSIC PLAYING]\nEZRA KLEIN: You have an interesting critique in the book, not of the dominant or widespread religious systems but \nof what gets called secular humanisms. And your critique particularly revolves around how secular humanism \ncreates a structure of worth between humans and animals, and how it at least purports to do so rationally. Can you \ntalk through that a bit?\nMELANIE CHALLENGER: Something that we haven’t got into yet is the idea of dualism. So we’ve talked a lot about \nthe kind of problems that flow from being an animal. So the moral dilemmas that emerge, and also the practical \ndifficulties that we face. But one of the solutions here that has cropped up throughout human history in different \nkinds of ways is to separate something about human beings out from their physical being. And say, well it’s this \nseparate part of us, this non-animal part of us that matters.\nIn many ways, that is one of the ideas that came out of original attempts that theologians, hundreds of years ago, \nattempted to do when they were trying to make sense of what is it that’s special about human beings, and what is it \nthat will survive beyond what we can see happening, which is the decay of the body into nothingness. There’s the \nspiritual part of us, there’s the soul that survives. And it’s the soul that gives our life meaning. It’s the soul that \nmakes human beings special. And it’s the soul thereby that justifies what we do in the world.\nNow once you get the emergence of secular humanism, there’s this real need to retain that separation, that moral \nseparation between us and the rest of the living world because we want to continue exploiting other animals, for \nexample. Or we might simply want the psychological relief and the moral relief of seeing ourselves as this superior \nform of life. And the solution comes in with secular humanism to sort of transport the soul, which is a whole-body \ndualism, into just a bit of us. Into the idea of our minds into the idea of our superior cognition, our rationality, our free \nwill. And that kind of little trick, that little move starts happening during the Enlightenment as the kind of seeds of \nhumanism are being sown and we have the emergence of an empirical scientific worldview, which put those \nthinkers sometimes in tension with this kind of religious dualism. But the solution came in having this mental \ndualism, this idea that no, it’s because we’re these rational agents, that’s what makes us separate, that’s what only \nwe possess.\nNow we’re living in an interesting time now, of course, because we have learned much more about the intelligence \nand sentiency and cognitive skills of other living beings, particularly primates but also broadly mammals across \nbirds and increasingly cephalopods, that are challenging these ideas that it’s only human beings who have this \nabsolutely unique form of cognition.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nSo just as Darwinism posed a problem for the old religious dualism and this sort of satisfying solution to being \nanimal that that provided. Now we find that modern science ironically is provoking challenges to the alternative \nsecular solution to being animal, which was kind of a cognitive dualism.\nEZRA KLEIN: I’m glad we got into the question of dualism, because it gets at one of my favorite lines of the book. \nYou write, “We are animals as we embrace, and as our bloodied newborns slide from the bodies of women but not \nwhen we make vows. We are animals as we bite into the flesh of our meal but not in the workplace. We are animals \non the operating table but not when we speak of justice.”\nAnd that felt true to me. And it made me wonder if really the whole thing we’re talking about here isn’t simply a \nmind-body distinction, right? We are animals when we are feeling, when we’re running, when we’re bleeding, when \nwe’re eating, when we’re defecating, and we’re not when we’re podcasting. Right now we’re high-order beings \ndancing about in the world of ideas.\nAnd so is that the story here, that in maybe one of the byproducts of consciousness it’s just a separation not even \nfrom animals but actually from bodies. It isn’t just that when I am podcasting I don’t feel like I’m an animal. When I’m \npodcasting I don’t feel like I’m synthesizing protein inside myself. There is a deep separation when you are more \nand more in your mind.\nMELANIE CHALLENGER: Absolutely. I think a lot of what I was looking at as I began to really unpick the idea of \nhuman exceptionalism through time is the fact that it is really strange for us to have this very, very hyper-aware \nstate that we are in. Human beings are exceptional and unique in being aware of our awareness, so in having that \nparticular kind of subjective consciousness.\nAnd what that does is several things. It gives us the sensation, and I think I say this either in the book or I’ve said \nthis when I’ve spoken to people, that it produces this sensation that we can all relate to, that we are somehow \ncarrying ourselves around in our body. So we actually generate a kind of that particular reflective part of our \nconsciousness, which is I should add a very animal thing, it comes from our particular kind of sociality.\nIt solves problems in the world. It’s not some sort of magic dust in our head. It’s come from the fact that we need to \nreflect on ourselves that we’re deeply highly social as a primate. We need to be able to keep track on our own \nidentity, and also to see into the minds of others to keep a track on them and maneuver and manage the \ncomplexities of human interaction in the world through social interaction. That’s basically what it’s doing for us but, \nit’s left us with this extraordinary legacy.\nOne of the core legacies is that we feel like the we, what we really are in our core is some sort of thinking bit of us \nthat’s just being carried around on these legs or on wheels if we’re disabled, whatever we might be. We’re \nsomehow — the body is just the carrier of this true part of what we are.\nAnd we can see that sensation has been written as just so story of what human beings are from the beginning of \ntime, from the beginning of our recorded history through to now. And it is something that you say OK, we’re not \nanimals as we podcast but actually my heart rate goes up a little bit. I feel a little bit nervous. I’m worried about not \nsaying the wrong thing. That will probably mean I’ve got cortisol levels that are peaking right now. So everything \nabout this whole podcasting is going to be really, really animal.\nAnd that’s derived from the fact that we are these social animals, where our social interactions and our status within \nsociety have a high premium. So that’s why we get so nervous, and our mouths get dry, and we worry about what \nwe’re doing. That all comes from being animal.\nAnd yet, the fact that we can think about it and contemplate it creates this strange disruption between what is still a \ncompletely animal phenomenon and the way that we actually then relate to it and think about it. And it does come \nfrom that kind of weird aspect of our cognition. That’s where I think it derives from.\nEZRA KLEIN: I apologize for the heart rate acceleration. [LAUGHS]\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nMELANIE CHALLENGER: No, it’s a human normal thing. Don’t worry.\n[MUSIC PLAYING]\nEZRA KLEIN: So this gets I think to one of the cruxes of the book, which is what is the consequence of all this? \nFine, maybe it’s weird to be a human being. Maybe we have a weird relationship with our animal selves. Maybe we \nhave a weird relationship with our own bodies. But you’re right, what we risk is a runaway process where our fear of \nbeing animal causes us to hammer out a more frightening world. Not frightening in the sense that the world is \nnastier or more violent but in a paradoxical reliance on technologies that aggravate the existential fears beneath us.\nAnd that felt to me, and this goes to the sort of back half of the book, like a place where this was all coming to roost. \nThat if we have a divided relationship to ourselves and we are building technologies that exacerbate that division, \nthose technologies may have many more consequences for us than we currently realize. So tell me a bit about that \nand the role of the path of technological development as you see it.\nMELANIE CHALLENGER: Sure. So the easiest way of doing this, and one doesn’t want to be too reductive. But if \nwe look at the core Industrial Revolutions, the first and second Industrial Revolutions were really about harnessing \nenergy and manufacture. So how can we harness energy to manufacture more goods to make the world work for \nus?\nAnd that then generated huge amounts of opportunities to resolve some of the core problems that we face as \nanimals. So how do we get the food that we want? How do we build the structures that we want and control the \ndifficult natural forces that are around us and build a world that feels more comfortable for us?\nSo that was what was going on in those first Industrial Revolutions. And as I say, they still come from being animal, \nbut they’re much more to do with how you can have a safe environment and have access to the right amount of \nfood, get as much food as you can, the plow and so forth.\nBut then when we start to look at the fourth Industrial Revolution now, it’s still deeply rooted in being an animal but \nit’s much more related to trying to control our own actual biology itself. So we start to look at genetic technologies, \nsynthetic biology, A.I. These are all actually exploiting the physical stuff of our living being. And what I try to argue is \nthat if we are fearful of being animal if, in fact, this is something that we find frightening.\nAnd we haven’t got into this yet, but this is a really crux part of it, which is that the fact that we are animal creates \nthese difficulties, these things that we face from pathogens to dangers in the world, to our mortality. But for human \nbeings, this means that we try to separate ourselves from being animal. That we respond to this both literally in the \nworld and also psychologically. And that tends to kind of ratchet up, right? The more that we try to escape being \nanimal, the more we want to escape being animal and the worse that separation becomes. It doesn’t resolve the \nanxiety, it heightens it.\nWhat might follow from the fact that our new technologies are all about the fact that we’re animal? They confront us \nwith being animal all the time. They are about our physical being. If that’s what we find threatening, I’m not \nconvinced we’re going to be well-placed until we accept that and talk about that to actually steer these kinds of \ntechnologies.\nEZRA KLEIN: Well, some of the technologies you’re talking about in the book are very speculative. You know, \ncryogenic freezing, and people getting their heads frozen and this and that. But one of them isn’t, and it’s been \nmore of a preoccupation of mine in the shows for a bit, which is A.I. Since you published the book and now, A.I. or \ngenerative artificial intelligence as it gets called, has become much more present in people’s lives, something we \ncan explore and work with.\nAnd it often strikes me that a lot of the anxiety people feel when they interface with these programs has to do with \nthis question of how we judge our worth separate from our animal-ness. There’s a lot in our animal-ness that A.I., \nwe know has no relationship to. It can’t listen to music. It can’t birth a child. It can’t feel a lot of what we can feel, the \nsort of embodied nature of our intelligence, it doesn’t have.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nBut if you build your worth as a human being off of creative cognitive processes, which we often do because we \nmeasure people through their value to the economy. And you have now systems that can write an essay as well as \na human being or come up with answers to scientific questions as well as a human being or whatever it might be. \nAnd some of them we don’t have yet, but we will soon. Then you end up in very dangerous metaphysical territory as \na species.\nAnd I’m not the first to observe this, Meghan O’Gieblyn and others have made this point. But that the ways in which \nA.I. is shaking our sense of self seems precisely related to how narrow and distant from our sensations and our \nbodies our sense of worth had become.\nMELANIE CHALLENGER: There’s a beautiful provocation there isn’t there? So if we go back to this idea that \nseparating ourselves from being animal in many different ways has solved the moral problem that we might face — \nso why do we justify factory farming for instance? How do we justify the extent to which we utilize and exploit the \nliving world, how do we justify the kind of systems that are leading to climate change?\nWe often fall back on this idea, we’re human beings are the only ones with moral worth, and we have our moral \nworth which is grounded in our particular capacities. The fact that we are incredibly intelligent, that we are rational, \nthat we live in a cultural world, that we’re symbolic thinkers and so forth. So we have ordered our whole system of \njustification around our intelligence.\nNow one can speculate on what’s going to happen when we find that we are confronted by a non-animal system but \nthat has superior capacities, superior forms of rationality than us. Because human beings are not in fact brilliantly \nrational. We’re very biased. We’re biased even just if we’ve had a sandwich that day, let alone what our politics \nhappen to be. Our memories are imperfect. They’re more to do with tracking who we are and not necessarily to do \nwith remembering events perfectly.\nSo human beings are because we’re animals, we’re flawed in our intelligence. Yes, we are highly intelligent and \ninteresting abstract thinkers and cultural thinkers for sure, but we’re still animals. It’s still an animal intelligence. It’s \nflawed. It does a good job. It never does a perfect job because evolution doesn’t work that way. It does a good job. \nBut there are always — there are payoffs.\nBut what if we end up with this synthetic intelligence that we’ve generated that can out-think us, outsmart us, is \nmore rational, and is more reasonable? Will we then need to flip into a new system of justification that actually leans \nback into our animality, that it is our capacity for sensation, that it is our capacity for emotion, for love, maybe even \nour ability to be wild and irrational that is what is beautiful and meaningful? That’s possible that that could be the \nkind of psychological move that we make.\nBut then where will that leave our relationship to the rest of the living world that we’ve justified exploiting because \nthey aren’t like that? Because they’re animals and we’re these kind of pseudo machines. So it’s an extremely \ninteresting time.\nEZRA KLEIN: Given that you wrote a book that I think in many ways was revolving around these questions, how \nhave you experienced this period? I’m sure you’ve played with some of these systems and I’m sure you’ve been \nfollowing a lot of this conversation. I mean, you say this will be an interesting time but how has it actually changed \nyour thinking?\nMELANIE CHALLENGER: I’m deeply concerned about two things that I think don’t get enough airtime. I’ll have to \nbacktrack a wee bit. So within the fact that we face threats as animals and that we are these highly social primates \nthat build alliances in the world that are competitive and positive, right? So we have this particular kind of social \ncognition of human beings that places a huge premium on intelligence, on being able to judge what another person \nis thinking and judge their actions, and manage to sort of maneuver the social space that we’re in.\nWhat we find with human beings is that we are mind readers. We’re constantly trying to judge intelligences. And this \nis massively affected by whether we’re in the group or out of the group, right? So in-group, out-group tensions. And \nthere are different complex processes here. It’s not unsubtle but there’s a wealth of evidence that you tend to \nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nattribute more mind, more intelligence, more agency, and not just that but more emotion and more secondary \nemotions to those who are within your group.\nAnd those who are out of your group, so our competitors potentially, and especially those that you might want to \nexploit in some kind of way, you attribute less intelligence to, less secondary emotions. And in the worst and most \nkind of ghastly of cases, we can even completely dehumanize and objectify people if we want to exploit or be \naggressive towards them. So there’s this constant interplay of tensions that are based around whether we attribute \nmind or not to others.\nWhat is that going to do in an Industrial Revolution that is all about intelligence? Let’s say we get A.I. that is actually \ngetting smarter faster than we’re realizing it. If we tend to kind of objectify the machines or the intelligence of others, \nhow likely are we to be good at mind-reading a synthetic mind that we’ve generated? How good are we likely to be \nat judging? That’s something that I greatly worry about, but I also worry that with deep-fake and A.I., the way it \ncould be exploited will exploit those in-group, out-group tensions that I’ve described and are likely to amplify them. \nThat’s something that I’m greatly concerned about.\nEZRA KLEIN: Well, there’s also this way in which it boomerangs back on us. I mean, we’re not going to be good at \nreading A.I. minds. We’re not good at it now. We have built a thing to fool ourselves first and foremost, right? We \ncould have tuned this in any way we wanted, we tuned it to seem like us to us.\nIt’s again a widely made observation now but the underlying power of the GPT programs that OpenA.I. has put out \nhas been around for a very long time. They only exploded when they put this wrapper around their GPT programs \nnow called ChatGPT, that made it easy to converse with it in a very human-seeming way. So the more we fooled \nourselves by making it seem like us to us, even though it is anything but like us, the more we liked it.\nSomething you talk about in the book that comes up a lot is a way we’re an embodied intelligence. You have a \nlovely section on these experiments that I always think are fascinating, about people for whom the hemispheres of \ntheir brains were separated. And one part of the brain will sense threat and the other part of the brain will create \nstory about that. But when they’re separated and they can’t communicate, you often have people reacting to a \nthreat but the other part of the brain is coming up with stories without enough information and the stories are \nridiculous.\nAnd so you end up in this funny way where a core part of what we are is the body, but we have dismissed that and \nincreasing our metaphors of what we are and how we think, and what makes us more than animal are thinner and \nthinner because in trying to explain computers to ourselves we have explained ourselves as computers.\nAnd one of the things I worry about is that I think that a lot of human dignity is standing on a very narrow precipice. \nAnd we have plenty of belief systems and reasons to have a thicker sense of what makes a human being or any \nkind of life special, but I’m not sure we’ve done enough to confront how much damage we’ve done to that thinking \nover the past couple of centuries.\nMELANIE CHALLENGER: Absolutely. And it’s very interesting to go back to the kind of archive of John von \nNeumann, Alan Turing, the thinkers who were sort of beginning the computer age. I mean, they weren’t the \nabsolute start of it, but there’s a huge amount of writings that we got from that time as it was really kicking off, \nwhere you do see this computer metaphor really bed down.\nWe were still having the fallout from the horrors that followed from the slave trade. That these were people that had \nbeen reduced just to their bodies if you like, that women were not seen as rational, so they were just seen as these \nsort of embodied irrational creatures who couldn’t be trusted with their emotions, couldn’t be trusted to vote and so \nforth. And that the slaves were reduced to only the labor that they could provide and none of the full faculties of their \nhumanity.\nMeanwhile, we have the emergence, at the same kind of time of this idea, that what is superior about us or what is \nvaluable about a select number of us within society is this computer-like intelligence. And we should be reflecting on \nthat history as we face a world that is now placing a huge premium on only a very particular kind of cognition.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nA.I. is only a certain kind of intelligence, it’s not even all of the forms. Yes, OK, some of the systems are trying to \naim towards general intelligence, but they’re not really anywhere near human general intelligence at the moment. \nThat is the kind of singularity that people are talking about. We don’t have anything like that. We just have a very \nparticular stripped-down, very logical form of intelligence of computation that A.I. is good at.\nAnd the worry is that we’re still living by that metaphor. But as you say, in fact, intelligence, human intelligence is \nbeautiful for its complexity. Not just human intelligence but animal intelligence more broadly. The intelligence of \nyour immune system is remarkable. The ability of your immune system to know the difference between what’s not \nyou and what is, none of that’s a kind of rational calculating intelligence but it is intelligent, and it is beautiful. The \nability of a mother’s body to sync with their child when they’re breastfeeding, that’s intelligence, but it’s not the kind \nof intelligence that we’re placing a premium on now.\nEZRA KLEIN: You quote a beautiful poem from Galway Kinnell written in 1980 that says, “Sometimes it is \nnecessary to reteach a thing its loveliness.” And I take that as a big project of the book. So as we come to a close \nhere, how have you come to think about your own loveliness or the loveliness of those around you? And how does \nit change your experience of them or the world in which you and them live?\nMELANIE CHALLENGER: It is frightening being an animal. We all are frightened by the fact that we’re going to die. \nThat’s at the core of it. None of us want to get hurt. None of us want to be humiliated or to be in pain or suffer or \ndiseased, of course. None of us want to be hungry or to starve.\nAll of these deeply animal threats are real, and they frighten us. But there’s also so much about the real lift \nembodied beauty of the animal world and the animal condition that we can cherish.\nA lot of that stems from our alliances. And these alliances start with one another. They generally in fact, in \nmammals like us, tend to start between the mother and the child. But they’re also there between lovers of any kind, \nany kind of lover will sync their brainwaves with one another, they’ll have oxytocin spikes.\nWhen you look at your dog today, you turn around to your dog and you stroke their back, that’s a really classic \nmimicking of the licking that a mother will do from the top of the head of a mammal through to the kind of right way \ndown the spine. It will make the animal feel better. It’s the same if you do it to your cat. It’s the same if you do it to \nyour horse. It’s the same if you do it to your child. And it causes this kind of flow of warm, positive sensations of \ntogetherness, of trust, of alliance. We’re capable of this.\nI think what is really beautiful about human beings is that we do have something that is very, very unique about us \nas animals. And that’s that we can build alliances with any other species. That’s really quite an extraordinary way of \ntaking, initially, kind of a useful capability that’s evolved, so the ability to build loving, supportive safe relationships to \nsave us from the kind of difficulties of life, with our family, with our friends, with our community. And we’ve been \nable to generalize that. That is really an extraordinary way of being able to generalize love, being able to generalize \npassion, generalize kindness.\nSo as I worked on this book I have to be honest, that a lot of what I was looking at were really quite difficult subject \nmatters, really difficult ideas about what comes from being animal. But I reached the end of it with a real sense of \njoy. I reached the end of it with a real appreciation for the whole body of a human being and the extraordinary \nqualities that we have to be able to walk through the Earth and care about anything that we happen to see around \nus. That is a really, really exceptional thing to have come out of our animal nature. And I guess that was my take \nhome from the book.\nEZRA KLEIN: I think it’s a lovely place to end. So always our final question, what are three books you would \nrecommend to the audience?\nMELANIE CHALLENGER: Well, this is really tough because like most writers, I both read too much and I also have \nthe ambition to read more than I’m ever going to read. But I got two books by very different female philosophers \nactually that I’ve recently read and enjoyed.\nTranscript: Ezra Klein Interviews Melanie Challenger The Ezra Klein Show\nThe first one is Gillian Rose’s book “Love’s Work.” And it takes the idea of love but from within her experience of \napproaching death. I don’t know, it’s just one of those taut, poetic, philosophical books that it might not reach large \naudiences but it’s all the more rich for that.\nThe second book is by Australian philosopher Danielle Celermajer, and it’s called “Summertime: Reflections On a \nVanishing Future.” It’s a really beautiful, timely reflection on the way that the environmental crisis impacts the lives \nof other species. So in particular, she tells the story of two pigs that live with her and how they get caught up in the \nbushfires of 2019 and 2020. And it’s incredibly moving but it’s also it’s a provocation for us to, I guess to recognize \nand care about the other animals that are going to be impacted by climate change.\nAnd yeah, finally, I actually started out my career as a poet, and I still do kind of write but rather quietly now but I \nreally love to read it. So I’ve been reading “Lighthead” by Terrance Hayes. And his poems, I guess they kind of spin \ntogether high art and formal technical innovation. But I think what I really get from them is this kind of political punch \nthat kicks in and it takes the wind out of me. He drops it into the poems unexpectedly and beautifully at just the right \nmoment. And yeah, they’re really satisfying and rich. So yeah that’s my three.\n[MUSIC PLAYING]\nEZRA KLEIN: Melanie Challenger, thank you very much.\nMELANIE CHALLENGER: It’s been a pleasure. Thank you.\nEZRA KLEIN: This episode of “The Ezra Klein Show” was produced by Annie Galvin. Fact-checking by Michelle \nHarris. Mixing by Jeff Geld. The show’s production team includes Emefa Agawu, Jeff Geld, Rogé Karma and Kristin \nLin. Original music by Isaac Jones. Audience strategy by Shannon Busta. The executive producer of New York \nTimes Opinion Audio is Annie-Rose Strasser. And special thanks to Sonia Herrero and Kristina Samulewski.\nLoad-Date: June 27, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Discussions on Chip Fabrication Scaling, Manufacturing Investments",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 8, 2023",
        "section": "FRONT PAGE",
        "length": "585 words",
        "byline": "Suraksha.P@timesgroup.com",
        "story_text": "Discussions on Chip Fabrication Scaling, Manufacturing Investments\nEconomic Times (E-Paper Edition)\nSeptember 8, 2023 Friday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: FRONT PAGE\nLength: 585 words\nByline: Suraksha.P@timesgroup.com\nHighlight: Plan to expand workforce in India, focus on upskilling, says Huang\nBody\nCEO MEETS IISC , IIT RESEARCHERS\nBengaluru: Nvidia, the world's pre-eminent maker of hardware and software for artificial intelligence tools, envisions \nexporting AI products from its Indian arm, CEO and cofounder of the $27-billion firm, Jensen Huang told \nresearchers at India's top technology institutes this week, according to the people present at the interaction. India is \nevolving into a “front end” nation in the world of technology, the 60-year-old technocrat told his audience during his \nongoing visit in the country, which included a meeting with Prime Minister Narendra Modi on September 4.  The \nAmerican chipmaker, which is riding on a trillion-dollar valuation led by the boom in generative Artificial \nIntelligence (AI), expects to leverage the vast data generated by India's $1.4 billion population to build AI products \nthat can be exported from the country. Huang, who co-founded the Santa Clara-based technology giant in 1993, \nmet researchers from the Indian Institute of Science's (IISc) department of computational and data sciences (CDS), \nIndian Institute of Technology (IIT) Madras and IIT Bombay on September 4 during the course of his week-long \nvisit. Sashikumar Ganesan, associate professor and chair of CDS at IISc, Bengaluru, told ET that the discussions at \nthe HPC and AI Research Leaders Meet revolved around leaders in artificial intelligence (AI) and high-performance \ncomputing (HPC), which is Nvidia's primary business domain. \nHuang communicated plans to expand Nvidia's workforce in India and focus on upskilling. “Although we may lack \nthe ecosystem to collect all data, once acquired, all AI and machine learning systems for the world can be trained \non it. This is one of the reasons why technology companies invest heavily in India,” Ganesan said. Discussions \nduring the meeting encompassed India's potential to lead AI research, chip fabrication scaling, and investments in \nmanufacturing.  TRILLION-DOLLAR CLUB Nvidia manufactures semiconductor chips that are integral to the \nfunctioning of AI-products built by the likes of Microsoftbacked OpenAI such as ChatGPT. As it rode the surging AI \nwave in 2023, Nvidia saw a record rise in demand for its chips, which are now at an all-time  high.  Nvidia reported \na revenue of $13.51 billion for the second quarter ended July 30, 2023, up 101% from a year ago. Its stock recently \nhit an all-time high after a surge of 315%. The company reached a market value of more than a trillion dollars in \nMay this year, joining the likes of Microsoft, Apple and Amazon. Following Microsoft's $10 billion investment into the \nSam Altman founded-OpenAI earlier this year, Google announced an aggressive follow-up through its own AI tool \nBard.  Huang was keen to understand the nuances of high-performance computing in India, its applications, and \nNvidia's role.  Ajay Kumar Sood, a distinguished honorary professor of Physics at IISc and the principal scientific \nadvisor to the Indian government, was also among the attendees.  INDIA FOCUS Nvidia began its operations in \nIndia in 2004 in Bengaluru and has four engineering development centres located in Gurugram, Hyderabad, Pune \nand Bengaluru with a workforce of 3,800 individuals in India. More than 320,000 India-based developers are part of \nNvidia's developer programme. Huang was updated on the research activities of CDS at IISc. “We're integrating \nDiscussions on Chip Fabrication Scaling, Manufacturing Investments\nmachine learning with computational science. Huang was curious about this intersection,” Ganesan said. FOR \nFULL REPORT, GO TO www.economictimes.com\nLoad-Date: September 8, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jul2023",
        "header": "A.I. Can Aid Cheating. It's Better for Studying.",
        "media": "The New York Times",
        "time": "July 3, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 5",
        "length": "763 words",
        "byline": "By Brian X. Chen",
        "story_text": "A.I. Can Aid Cheating. It's Better for Studying.\nThe New York Times\nJuly 3, 2023 Monday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 5\nLength: 763 words\nByline: By Brian X. Chen\nBody\nGenerative A.I. tools can annotate long documents, make flashcards, and produce practice quizzes.\nHello! We're back with another bonus edition of On Tech: A.I., a pop-up newsletter that teaches you about artificial \nintelligence, how it works and how to use it. \n  Last week, I went over how to turn your chatbot into a life coach. Let's now shift into an area where many have \nbeen experimenting with A.I. since last year: education.\n  Generative A.I.'s specialty is language -- guessing which word comes next -- and students quickly realized that \nthey could use ChatGPT and other chatbots to write essays. That created an awkward situation in many \nclassrooms. It turns out, it's easy to get caught cheating with generative A.I. because it is prone to making stuff up, \na phenomena known as ''hallucinating.''\n  But generative A.I. can also be used as a study assistant. Some tools make highlights in long research papers \nand even answer questions about the material. Others can assemble study aids, like quizzes and flashcards.\n  One warning to keep in mind: When studying, it's paramount that the information is correct, and to get the most \naccurate results, you should direct A.I. tools to focus on information from trusted sources rather than pull data from \nacross the web. I'll go over how to do that below.\n  Research\n  First, let's explore one of the most daunting studying tasks: reading and annotating long papers. Some A.I. tools, \nsuch as Humata.AI, Wordtune Read and various plug-ins inside ChatGPT, act as research assistants that will \nsummarize documents for you.\n  I prefer Humata.AI because it answers your questions and shows highlights directly inside the source material, \nwhich allows you to double check for accuracy.\n  On the Humata.AI website, I uploaded a PDF of a scientific research paper on the accuracy of smartwatches in \ntracking cardio fitness. Then I clicked the ''Ask'' button and asked it how Garmin watches performed in the study. It \nscrolled down to the relevant part of the document mentioning Garmin, made highlights and answered my question.\n  Most interesting to me was when I asked the bot whether my understanding of the paper was correct -- that on \naverage, wearable devices like Garmins and Fitbits tracked cardio fitness fairly accurately, but there were some \nindividuals whose results were very wrong. ''Yes, you are correct,'' the bot responded. It followed up with a \nsummary of the study and listed the page numbers where this conclusion was mentioned.\nA.I. Can Aid Cheating. It's Better for Studying.\n  Studying\n  Generative A.I. can also help with rote memorization. While any chatbot will generate flashcards or quizzes if you \npaste in the information that you're studying, I decided to use ChatGPT because it includes plug-ins that generate \nstudy aids that pull from specific web articles or documents.\n  (Only subscribers who pay $20 a month for ChatGPT Plus can use plug-ins. We explained how to use them in a \nprevious newsletter.)\n  I wanted ChatGPT to create flashcards for me to learn Chinese vocabulary words. To do this, I installed two plug-\nins: Link Reader, which let me tell the bot to use data from a specific website, and MetaMentor, a plug-in that \nautomatically generates flashcards.\n  In the ChatGPT dashboard, I selected both plug-ins. Then, I wrote this prompt:\n  Act as a tutor. I am a native English speaker learning Chinese. Take the vocabulary words and phrases from this \nlink and create a set of flashcards for each: https://preply.com/en/blog/basic-chinese-words/\n  About five minutes later, the bot responded with a link where I could download the flashcards. They were exactly \nwhat I asked for.\n  Next, I wanted my tutor to quiz me. I told ChatGPT that I was studying for the written exam to get my motorcycle \nlicense in California. Again, using the Link Reader plug-in, I pasted a link to the California D.M.V.'s latest motorcycle \nhandbook (an important step because traffic laws vary between states and rules are occasionally updated) and \nasked for a multiple-choice quiz.\n  The bot processed the information inside the handbook and produced a quiz, asking me five questions at a time.\n  Finally, to test my grasp of the subject, I directed ChatGPT to ask me questions without presenting multiple-choice \nanswers. The bot adapted accordingly, and I aced the quiz.\n  I would have loved having these tools when I was in school. And probably would have earned better grades with \nthem as study companions.\n  What's next?\n  Next week, in the final installment of this how-to newsletter, we'll take everything we've learned and apply it to \nenriching the time we spend with our families.\nhttps://www.nytimes.com/2023/06/30/technology/ai-chatbot-study-aid.html\nGraphic\n \nThis article appeared in print on page B5.               \nLoad-Date: July 3, 2023"
    },
    {
        "file_name": "Company's_Bob_Sternfels_Sep2023",
        "header": "Protectionism will have a 20-40% impact on global GDP, says McKinsey &",
        "media": "Company's Bob Sternfels",
        "time": "September 6, 2023",
        "section": "INSIGHTS",
        "length": "571 words",
        "byline": "Neha Dewan",
        "story_text": "Protectionism will have a 20-40% impact on global GDP, says McKinsey & \nCompany's Bob Sternfels\nThe Economic Times\nSeptember 7, 2023 Thursday\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: INSIGHTS\nLength: 571 words\nByline: Neha Dewan\nBody\nInhibiting trade could mean that anywhere between 20% and 40% of global GDP is at risk, said Bob Sternfels, \nGlobal Managing Partner, McKinsey & Company. \"That's massive. And that has a massive regressive effect in \nterms of inclusion,\" he said while speaking at the B20 summit held in the capital recently. Sternfels said the \nMcKinsey Global Institute took a deeper look at the implication of restrictions and protectionism across industry \nverticals. \nIt took a broader definition of trade - not just physical flows but also data flows and talent flows. \"About two-thirds of \ntoday's global growth comes from the Global South and that grows to 70% by 2050. So accelerating opportunities \nand growth is critical,\" he said.Sternfels noted that over the last couple of years, trade hasn't been that resilient. \n\"With exogenous shocks, we saw supply chains were pretty fragile. Diversification of trade and the multiplication of \ntrade routes does a couple of things. One is it makes the world more resilient. And second is it drives economic \ngrowth that is particularly inclusive. So as you start to think about multiple trade routes as opposed to concentration \nof trade routes, there may be an answer here in inclusion but it does require reimagining.\" Talking further about the \nsignificance of inclusion, he added that there is an opportunity for India to move 220 million jobs from farm jobs to \nnon-farm ones with a massive increase in wage escalation by 2047. This, he said, would also help arrest inequality, \nwhich is the number one global issue today. Giving specifics, Sternfels gave the example of major economies and \ntheir respective income populations. \"In the US, the middle class has shrunk by 18% in the last 20 years. Go to \nChina - the top 10% of the income population have grown 50% faster than the bottom half. In India, that top 10% \nhave grown 100% faster. So the data shows it. What this says is that we need to have economic growth. It is the \ncatalyst that will help to solve all problems but that growth has to be inclusive,\" he said. Speaking of SME growth \naround global trade finance, Sternfels said SMEs account for 95% of the firms and 70% of the jobs in the world \ntoday. They, however, are lacking in two aspects: access to credit and markets. \"40% of applications for credit to \nSMEs are denied and SMEs face enormous barriers and trade.\" Just easing the finance aspect and allowing SMEs \nto trade across borders will give them billions of dollars in value, he said.The global managing partner at McKinsey \nexplained how accelerating technology can play a big role in achieving inclusive growth: \"We did some work looking \nat the value of generative AI around 67 specific use cases. And it shows there is $3 trillion-$4 trillion in annual \nrevenue available just in these 67 use cases.\" Sternfels also spoke about their \"Women in the Workplace\" report, \nwhich showed that there was $12 trillion in economic value if gender parity was implemented. \"That number \naccelerates to $28 trillion if you actually say women would play identical roles to men in enterprise. So $28 trillion of \ninclusive growth by solving gender access issues,\" he said. The Business 20 (B20) is the official G20 dialogue \nforum with the global business community. Established in 2010, B20 is known to be the most prominent \nengagement groups in G20, with companies and business organisations as participants.  For Reprint Rights: \ntimescontent.com\nProtectionism will have a 20-40% impact on global GDP, says McKinsey & Company 's Bob Sternfels\nLoad-Date: September 6, 2023"
    },
    {
        "file_name": "Wall_Street_Journal_Abstracts_Apr2023",
        "header": "PWC TO SPEND $1 BILLION ON AI",
        "media": "Wall Street Journal Abstracts",
        "time": "April 28, 2023",
        "section": "B; Pg. 11",
        "length": "39 words",
        "byline": "ANGUS LOTEN",
        "story_text": "PWC TO SPEND $1 BILLION ON AI\nWall Street Journal Abstracts\nApril 27, 2023 Thursday\nCopyright 2023 The New York Times Company: Abstracts All Rights Reserved\nSection: B; Pg. 11\nLength: 39 words\nByline: ANGUS LOTEN\nBody\nABSTRACT\nPricewaterhouseCoopers LLP plans to invest $1 billion in generative artificial-intelligence technology in its US \noperations over next three years, recruiting more AI workers and training existing staff in AI capabilities; photo (M)\nGraphic\n \nPhotograph\nLoad-Date: April 28, 2023"
    },
    {
        "file_name": "Qualcomm_Dec2023",
        "header": "Armed with AI-Capable Chips, MediaTek Now Looks to Rival Apple and",
        "media": "Qualcomm",
        "time": "December 10, 2023",
        "section": "ECONOMY & COMPANIES",
        "length": "212 words",
        "byline": "Subhrojit Mallick",
        "story_text": "Armed with AI-Capable Chips, MediaTek Now Looks to Rival Apple and \nQualcomm\nEconomic Times (E-Paper Edition)\nDecember 11, 2023 Monday\nBangalore Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY & COMPANIES\nLength: 212 words\nByline: Subhrojit Mallick\nHighlight: Taiwanese co, whose India revenues come mainly from phone biz, is seeing IoT growing\nBody\nNew Delhi:Taiwanese chipmaker MediaTek is gunning for the premium segment in coming years, taking on \nformidable US rivals Qualcomm and Apple with the launch of its latest line-up of flagship mobile processors \nfocussing on high performance and generative AI capabilities, a top executive said.  “Our revenues increased from \n$7.9 billion to $14 billion in calendar 2023 globally. A big milestone this year is that we’ve been able to generate $1 \nbillion in revenue from our flagship  chipsets globally,” MediaTek India managing director Anku Jain told ET. \nGlobally, MediaTek enjoys a lion’s share of the mobile processor market  — 30% in terms of volumes. As per \nCybermedia Research, as many as 20 million MediaTek-powered phones were shipped to India in Q3 2023, \ncapturing 46% market share, compared to 12 million powered by Qualcomm, which had 27% market share in \nvolume terms. It is now looking to lead the generative AI space with its latest chipset that has the capability to run a \n33-billion parameter large language model, a key ingredient in ChatGPT-like apps. While most of the company’s \nIndia revenues come from the mobile phone business, it’s also increasingly seeing the IoT (internet of things) \nsegment growing in terms of revenue. \nsubhrojit.mallick@timesgroup.com\nLoad-Date: December 10, 2023"
    },
    {
        "file_name": "The_New_York_Times_Jun2023",
        "header": "Everyone Likes Reading. Why Are We So Afraid of It?; Essay",
        "media": "The New York Times",
        "time": "June 24, 2023",
        "section": "BOOKS; review",
        "length": "4082 words",
        "byline": "A.O. Scott",
        "story_text": "Everyone Likes Reading. Why Are We So Afraid of It?; Essay\nThe New York Times \nJune 21, 2023 Wednesday 22:50 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: BOOKS; review\nLength: 4082 words\nByline: A.O. Scott\nHighlight: Book bans, chatbots, pedagogical warfare: What it means to read has become a minefield.\nBody\nEveryone loves reading. In principle, anyway. Nobody is against it, right? Surely, in the midst of our many quarrels, \nwe can agree that people should learn to read, should learn to enjoy it and should do a lot of it. But bubbling \nunderneath this bland, upbeat consensus is a simmer of individual anxiety and collective panic. We are in the \nthroes of a reading crisis.\nConsider the evidence. Across the country, Republican politicians and conservative activists are removing books \nfrom classroom and library shelves, ostensibly to protect children from “indoctrination” in supposedly left-wing ideas \nabout race, gender, sexuality and history. These bans have raised widespread alarm among civil libertarians and \nprovoked a lawsuit against a school board in Florida, brought by PEN America and the largest American publisher, \nPenguin Random House.\nPEN has also joined the chorus of voices condemning censorious piety on social media and college campuses, \nwhere books deemed problematic become lightning rods for scolding and suppression. While right and left are \nhardly equivalent in their stated motivations, they share the assumption that it’s important to protect vulnerable \nreaders from reading the wrong things. Including, in one Utah county, the Bible, which was taken from schoolroom \nshelves, like so many other books, as a result of a parental complaint — one apparently intended to expose the \nabsurdity of such bans in the first place.\nBut maybe the real problem is that children aren’t being taught to read at all. As test scores have slumped — a \ntrend exacerbated by the disruptions of Covid — a long-smoldering conflict over teaching methods has flared anew. \nParents, teachers and administrators have rebelled against widely used progressive approaches and demanded \nmore emphasis on phonics. In May, David Banks, the chancellor of New York City’s public schools, for many years \na stronghold of “whole language” instruction, announced a sharp pivot toward phonics, a major victory for the \n“science of reading” movement and a blow to devotees of entrenched “balanced literacy” methods.\nThe reading crisis reverberates at the higher reaches of the educational system too. As corporate management \nmodels and zealous state legislatures refashion the academy into a gated outpost of the gig economy, the \nhumanities have lost their luster for undergraduates. According to reports in The New Yorker and elsewhere, fewer \nand fewer students are majoring in English, and many of those who do (along with their teachers) have turned away \nfrom canonical works of literature toward contemporary writing and pop culture. Is anyone reading “Paradise Lost” \nanymore? Are you\nBeyond the educational sphere lie technological perils familiar and new: engines of distraction like streaming (what \nwe used to call TV) and TikTok; the post-literate alphabets of emojis and acronyms; the dark enchantments of \ngenerative A.I. While we binge and scroll and D.M., the robots, who are doing more and more of our writing, may \nalso be taking over our reading.\nEveryone Likes Reading. Why Are We So Afraid of It? Essay\nWhile we binge and scroll and D.M., the robots, who are doing more and more of our writing, may also be taking \nover our reading.\nThere is so much to worry about. A quintessentially human activity is being outsourced to machines that don’t care \nabout phonics or politics or beauty or truth. A precious domain of imaginative and intellectual freedom is menaced \nby crude authoritarian politics. Exposure to the wrong words is corrupting our children, who aren’t even learning \nhow to decipher the right ones. Our attention spans have been chopped up and commodified, sold off piecemeal to \nplatforms and algorithms. We’re too busy, too lazy, too preoccupied to lose ourselves in books.\nYou could argue that these disparate concerns don’t add up to a single crisis. You could point out that not all the \nnews is bad. Sales of printed books, after dropping in the early e-book era, have crept upward over the past \ndecade. This newspaper has reported that some young people in Brooklyn are abandoning their smartphones for \n“Crime and Punishment.”\nAnd the bad news is hardly new. Tyrants, philistines, religious zealots and hysterical parents have been banning \nbooks for as long as anyone can remember. The current battle between advocates of the science of reading and \ntheir pedagogical rivals is the latest skirmish in a series of “reading wars” that have convulsed American education \nfor most of the past century, most memorably after the publication of Rudolf Flesch’s best-selling “Why Johnny \nCan’t Read” in 1955. Movies, radio and television lured earlier generations of kids away from the joy of books. On \nuniversity campuses, the study of literature has been embattled and beleaguered for so long that chronicling the \ncontroversies has become a flourishing academic subfield in its own right.\nBut the fact that the present situation has a history doesn’t mean that it isn’t real. When the same cluster of \nproblems resurfaces in every generation, something is going on. And even as it seems to overlap with other areas \nof perpetual contention — social inequality, identity politics, schooling, technology — the reading crisis isn’t simply \nanother culture-war combat zone. It reflects a deep ambivalence about reading itself, a crack in the foundations of \nmodern consciousness.\nThe reading crisis reflects a deep ambivalence about reading itself.\nJust what is reading, anyway? What is it for? Why is it something to argue and worry about? Reading isn’t \nsynonymous with literacy, which is one of the necessary skills of contemporary existence. Nor is it identical with \nliterature, which designates a body of written work endowed with a special if sometimes elusive prestige.\nReading is something else: an activity whose value, while broadly proclaimed, is hard to specify. Is any other \ncommon human undertaking so riddled with contradiction? Reading is supposed to teach us who we are and help \nus forget ourselves, to enchant and disenchant, to make us more worldly, more introspective, more empathetic and \nmore intelligent. It’s a private, even intimate act, swathed in silence and solitude, and at the same time a social \nundertaking. It’s democratic and elitist, soothing and challenging, something we do for its own sake and as a means \nto various cultural, material and moral ends.\nWhen I was a child, Saturday morning cartoons were sometimes interrupted by public service announcements from \nReading Is Fundamental, an organization dedicated to putting books in the hands of underprivileged children. The \ngroup’s slogan was “Reading Is Fun!” Fun and fundamental: Together, those words express a familiar utilitarian, \nutopian promise — the faith that what we enjoy doing will turn out to be what we need to do, that our pleasures and \nour responsibilities will turn out to be one and the same. It’s not only good; it’s good for you.\nBut nothing is ever so simple. Reading is, fundamentally, both a tool and a toy. It’s essential to social progress, \ndemocratic citizenship, good government and general enlightenment. It’s also the most fantastically, sublimely, \nprodigiously useless pastime ever invented. Teachers, politicians, literary critics and other vested authorities labor \nmightily to separate the edifying wheat from the distracting chaff, to control, police, correct and corral the \ntransgressive energies that propel the turning of pages. The crisis is what happens either when those efforts \nsucceed or when they fail. Everyone likes reading, and everyone is afraid of it.\nEveryone Likes Reading. Why Are We So Afraid of It? Essay\nReading is a relatively novel addition to the human repertoire — less than 6,000 years old — and the idea that it \nmight be available to everybody is a very recent innovation. For most of our history, our languages were spoken, \nour literary imaginations oral. In those ancient societies where writing first developed — in Mesopotamia and \nMesoamerica, in Egypt and China — both its applications and access to it were restricted. Written language, \nassociated with the rise of states and the spread of commerce, was useful for trade, helpful in the administration of \ngovernment and integral to some religious practices. Writing was a medium for lawmaking, record-keeping and \nscripture, and reading was the province of priests, bureaucrats and functionaries. They performed rites, recited \npoems and circulated information within a narrow, privileged sphere.\nFor most of history, that is, universal literacy was a contradiction in terms. The Latin word literatus designated a \nmember of the learned elite. A general readership in the way we understand it now did not exist, even as a general \nhuman ability to read was evident from the start. Anyone could learn to do it, but the mechanisms of learning were \ndenied to most people on the grounds of caste, occupation or gender. According to Steven Roger Fischer’s lively \nand informative “A History of Reading” (2003), “Western Europe began the transition from an oral to a literate \nsociety in the early Middle Ages, starting with society’s top rungs — aristocracy and clergy — and finally including \neveryone else around 1,200 years later.”\nFinally! This transformation gained momentum in 1455, when reading found its killer app in Johann Gutenberg’s \nprinting press. Before that, writing had been done on stone tablets and codices, scrolls of papyrus or animal skin, \nand bound books that were often copied by hand — objects of necessarily limited circulation. The print revolution \ncatalyzed a global market that flourishes to this day: Books became commodities, and readers became consumers.\nFor Fischer, as for many authors of long-range synthetic macrohistories, the story of reading is a chronicle of \nprogress, the almost mythic tale of a latent superpower unlocked for the benefit of mankind. “If extraordinary human \nfaculties and powers do lie dormant until a social innovation calls them into life,” he writes, “perhaps this might help \nto explain humanity’s constant advancement.” “Reading,” he concludes, “had become our union card to humanity.”\nReading is a chronicle of progress, the almost mythic tale of a latent superpower unlocked for the benefit of \nmankind.\nThis is a beautiful idea, and not one I’m inclined to quarrel with, not even to note that unions can always be broken, \nand progress stalled or reversed. Humanity, though, is a notoriously gnarled and thorny proposition, and it might be \nthat the history of reading, especially in the post-Gutenberg era, reveals just what complicated and contradictory \ncreatures we have always been.\nFor one thing, the older, restrictive model of literacy as an elite prerogative proved to be tenacious, even as, in early \nmodern Europe, reading spread among the bourgeoisie, and then further down the social ladder. Nowadays \nparents and other concerned adults worry that young people don’t read or love reading enough. Their counterparts \nin the 18th and 19th centuries were apt to fret that the young loved reading too much. As a middle class gained \nstrength in Europe, claiming leisure as one of its defining features, books were among the goods most closely \nidentified with that leisure, especially for women.\nThe novel, more than any other genre, catered to this market. Like every other development in modern popular \nculture, it provoked a measure of social unease. Novels, at best a source of harmless amusement and mild moral \ninstruction, were at worst — from the pens of the wrong writers, or in the hands of the wrong readers — both \ninvitations to vice and a vice unto themselves. The novelists of the period didn’t hesitate to capitalize on this \nanxiety. In Jane Austen’s “Northanger Abbey,” Catherine Morland’s enthusiasm for Gothic fiction leads to social \nembarrassment and philosophical confusion, as she disastrously (if comically) conflates her reading with reality. For \nEmma Bovary, the confusion between the fantasies offered by popular romances and the banality of provincial life \ntakes on a tragic dimension. Her reading propels her down a path to ruin.\nThe danger wasn’t restricted to women. Goethe’s “The Sorrows of Young Werther” was blamed for an epidemic of \nromantic suicides among impressionable male readers. Victorian America, perpetually worried that its footloose \nEveryone Likes Reading. Why Are We So Afraid of It? Essay\nyoung men were on the road to perdition, classified novel-reading along with drinking and gambling among the \ncauses of dissipation and debility.\nSuch superstition now seems comparatively benign, a quaint chapter in the never-ending saga of middle-class \nanxiety about what the kids are getting up to. More consequential — and more revealing of the destabilizing power \nof reading — was the fear of literacy among the laboring classes in Europe and America. “Reading, writing and \narithmetic,” the Enlightenment political theorist Bernard Mandeville asserted, were “very pernicious to the poor” \nbecause education would breed restlessness and discontent. “Men who are to remain and end their days in a \nlaborious, tiresome and painful station of life, the sooner they are put upon it at first, the more patiently they’ll submit \nto it for ever after.”\nNowhere was this brutal notion pursued with more ferocity than in the American South. “It was unlawful, as well as \nunsafe, to teach a slave to read,” Frederick Douglass writes in his “Narrative of the Life” recalling the admonitions of \none of his masters, whose wife had started teaching young Frederick his letters. If she persisted, the master \nexplained, their chattel would “become unmanageable, and of no value to his master. As to himself, it could do him \nno good, but a great deal of harm. It would make him discontented and unhappy.”\nReflecting on these words, Douglass writes, “I now understood what had been to me a most perplexing difficulty — \nto wit, the white man’s power to enslave the Black man.” From that moment, he grasped that “the pathway from \nslavery to freedom” ran through the printed word, and “that education and slavery were incompatible with each \nother.”\nFrederick Douglass grasped that ‘‘the pathway from slavery to freedom’’ ran through the printed word.\n“Narrative of the Life of Frederick Douglass, an American Slave” — the first of Douglass’s memoirs, published in \n1845, when millions of Americans were still in bondage — is partly a heroic origin story, the account of how a young \nman endured horrific adversity to emerge as one of the leading orators and intellectuals of his time. It is also a \ncarefully argued treatise on the nature of freedom, one that rescues that sparkling and elusive idea from \nabstraction, grounding it in the ethics and psychology of lived experience.\nAmong Douglass’s most powerful and painful revelations is that, on the subject of reading, his master was right. \nCompleting his primary education with the help of white schoolchildren whom he bribed with scraps of bread, young \nFrederick found a copy of “The Columbian Orator,” a popular anthology of inspirational speeches and essays, many \non the subject of liberty.\n“As I read and contemplated the subject, behold! that very discontentment which Master Hugh had predicted would \nfollow my learning to read had already come, to torment and sting my soul to unutterable anguish. As I writhed \nunder it, I would at times feel that learning to read had been a curse rather than a blessing.” Douglass’s account of \nthis anguish is one of the most lacerating parts of a book that does not shy away from the depiction of suffering. His \ndespair mirrors his earlier exhilaration and arises from the same source. “I envied my fellow-slaves for their \nstupidity. I have often wished myself a beast. I preferred the condition of the meanest reptile to my own. Any thing, \nno matter what, to get rid of thinking!”\nDouglass’s literary genius resides in the way he uses close attention to his own situation to arrive at the essence of \nthings — to crack the moral nut of slavery and, in this case, to peel back the epistemological husk of freedom. \nSome of his pain, as predicted by Mandeville and Master Hugh, comes from the discrepancy between his thinking \nand his circumstances. He has freed his mind, but the rest has not followed. In time it would, but freedom itself \nbrings him uncertainty and terror, an understanding of his own humanity that is embattled and incomplete.\nSubstitute “reading” for “freedom” in that last sentence and the meaning stays the same. It may be unwise to \nuniversalize Douglass’s experience, but at the same time it’s hard to read these passages in the “Narrative” without \na jolt of recognition. Here, the autobiographical touches on the mythic, specifically on the myth of Prometheus, \nwhose theft of fire — a curse as well as a blessing bestowed on a bumbling, desperate species — is a primal \nmetaphor for reading. That fire lights our way and scorches our fingers, powers our factories and burns down our \nhouses. Reading liberates and torments us, enlightens and bewilders us, makes and unmakes our social and \nEveryone Likes Reading. Why Are We So Afraid of It? Essay\nsolitary selves. Every reader has experienced something like Douglass’s liberating epiphany, and also something \nlike his annihilating agony.\nEvery reader has experienced something like Douglass’s liberating epiphany, and also something like his \nannihilating agony.\nIn the early 2000s, my children attended a lovely, diverse, progressive public elementary school in Brooklyn. The \nmethods of reading instruction associated with Columbia University’s Teachers College were in full bloom there. \nStudents were encouraged to think of themselves as writers and readers, and to draw pictures of themselves \nabsorbed in those activities. There were parent-attended “publishing parties” when writing projects were completed. \nThe rooms were furnished with well-stocked, low-slung bookshelves and carpeted risers where young readers \ncould curl up with “just-right books,” selections matched to their interests and levels of proficiency.\nThe point was not only to teach basic skills — in the view of the science-of-reading critics, that was barely being \ndone at all — but also, and more urgently, to instill in the children a familiarity and comfort with books and what was \ninside them that would make them lifelong bibliophiles.\nIt is hard to imagine a scene of instruction more completely antithetical to the ones recalled in Douglass’s \n“Narrative.” That isn’t an accident. One of the main projects of American education over the past half-century and \nmore has been to unwind the legacy of oppression that denied so many people full access to the benefits of \nlearning. My children’s classrooms embodied a central ideal of this project: to institutionalize the sense of freedom \nthat Douglass had gained through struggle and opposition.\nThis is a noble vision with an evident paradox at its heart. Efforts to protect children — or citizens, for that matter — \nfrom the terror of freedom, to cocoon their reading within safe boundaries of vocabulary and representation, will \nalways fail. Reading, like democracy or sexual desire, is an unmanageable, inherently destabilizing force in human \nlife. Many of the revolutionary governments of the 20th century began with programs to promote mass literacy and \nthen, as soon as those succeeded, set about banning books, imprisoning writers and replacing literature with \npropaganda. School curriculums enact milder, less overtly repressive versions of the same impulse.\nA school, however benevolently conceived and humanely administered, is a place of authority, where the energies \nof the young are regulated, their imaginations pruned and trained into conformity. As such, it will inevitably provoke \nresistance, rebellion and outright refusal on the part of its wards. Schools exist to stifle freedom, and also to \ninculcate it, a dialectic that is the essence of true education. Reading, more than any other discipline, is the engine \nof this process, precisely because it escapes the control of those in charge.\nThe Utah Bible ban (which is now being appealed) proves as much: It testifies both to the relentless, nihilistic logic \nof censorship, which can find subversion anywhere, and also to the subversive power of reading, which is what sets \nthe censors off in the first place. The Old and New Testaments are full of sex, violence, magic, ethnic hatred and \nradical egalitarianism. Their history is an object lesson in the power and danger of reading itself. Literal wars have \nbeen fought over how they should be interpreted. Their most famous English translator was executed for heresy.\nThere is no way to limit a student’s reading to just-right books, or to ensure that she reads them in just the right \nway. The right way might be the wrong way: the way of terror, discontent. Apostles of reading like to quote Franz \nKafka’s aphorism that “a book must be the ax for the frozen sea within us.” By itself, the violence of the metaphor is \ntempered by its therapeutic implication. Less frequently quoted is Kafka’s previous sentence: “What we need are \nbooks that hit us like the most painful misfortune, like the death of someone we loved more than we love ourselves, \nthat make us feel as though we had been banished to the woods, far from any human presence, like a suicide.”\nAre those the books you want in your child’s classroom? To read in this way is to go against the grain, to feel \noneself at odds, alienated, alone. Schools exist to suppress those feelings, to blunt the ax and gently thaw the sea. \nThat is important work, but it’s equally critical for that work to be subverted, for the full destructive potential of \nreading to lie in reach of innocent hands.\nReading, like democracy or sexual desire, is an unmanageable, inherently destabilizing force in human life.\nEveryone Likes Reading. Why Are We So Afraid of It? Essay\nIn his short, strange book “The Pleasure of the Text,” the French critic and philosopher Roland Barthes \ndistinguished between two kinds of literary work:\nText of pleasure: the text that contents, fills, grants euphoria: the text that comes from culture and does not break \nwith it, is linked to a comfortable practice of reading. Text of bliss: the text that imposes a state of loss, the text that \ndiscomforts (perhaps to the point of a certain boredom), unsettles the reader’s historical, cultural, psychological \nassumptions, the consistency of his tastes, values, memories, brings to a crisis his relation with language.\nThis is not far from Kafka, though the language leans toward eroticism rather than angst. Jouissance, the French \nword translated as “bliss,” also means orgasm, and Barthes’s understanding of the term leans heavily on an \nunderstanding of sex as a destructive, disruptive force. Like Kafka’s ax, the text of bliss may not be something that \nbelongs in school libraries. But even though Barthes, writing in the wake of modernism and in the grip of \nstructuralist theories of language, has in mind particular books and authors — Marcel Proust and the Marquis de \nSade are among his touchstones — he is really describing modalities of reading. To a member of the slaveholding \nSouthern gentry, “The Columbian Orator” is a text of pleasure, a book that may challenge and surprise him in \nplaces, but that does not undermine his sense of the world or his place in it. For Frederick Douglass, it is a text of \nbliss, “bringing to crisis” (as Barthes would put it) his relation not only to language but to himself.\nIf you’ll forgive a Dungeons and Dragons reference, it might help to think of these types of reading as lawful and \nchaotic. Lawful reading rests on the certainty that reading is good for us, and that it will make us better people. We \nread to see ourselves represented, to learn about others, to find comfort and enjoyment and instruction. Reading is \nfun! It’s good and good for you.\nChaotic reading is something else. It isn’t bad so much as unjustified, useless, unreasonable, ungoverned. \nDefenses of this kind of reading, which are sometimes the memoirs of a certain kind of reader, favor words like \npromiscuous, voracious, indiscriminate and compulsive. Those terms, shadowed by connotations of pathology and \nvice, answer a vocabulary of belittlement — bookworm, bookish, book-smart — with assertions of danger. \nBibliophilia is lawful. Bibliomania is chaotic.\nThe point is not to choose between them: This is a lawful publication staffed by chaotic readers. In that way, it \nresembles a great many English departments, bookstores, households and classrooms. Here, the crisis never \nends. Or rather, it will end when we stop reading. Which is why we can’t.\nAudio produced by Tally Abecassis.\nA.O. Scott is a critic at large for the Book Review. Audio produced by Tally Abecassis. \nThis article appeared in print on page BR1, BR14, BR15, BR16.\nLoad-Date: June 24, 2023"
    },
    {
        "file_name": "Iowa_town's_water_consumption_spikes_thanks_to_Microsoft_Sep2023",
        "header": "Very thirsty AI technology behind ChatGPT",
        "media": "Iowa town's water consumption spikes thanks to Microsoft",
        "time": "September 18, 2023",
        "section": "MAIN; A; Pg. 7",
        "length": "1111 words",
        "byline": "Matt O'Brien and Hannah Fingerhut Associated Press",
        "story_text": "Very thirsty AI technology behind ChatGPT\nIowa town's water consumption spikes thanks to Microsoft\nThe Baltimore Sun\nSeptember 17, 2023 Sunday\nAdvanceBulldog Edition\nCopyright 2023 The Baltimore Sun Company All Rights Reserved\nSection: MAIN; A; Pg. 7\nLength: 1111 words\nByline: Matt O'Brien and Hannah Fingerhut Associated Press\nHighlight: Traffic on Interstate 35 passes a Microsoft data center Sept. 5 in West Des Moines, Iowa. Charlie \nNeibergall/AP\nBody\nDES MOINES, Iowa - The cost of building an artificial intelligence product like ChatGPT can be hard to measure.\nBut one thing Microsoft-backed OpenAI needed for its technology was plenty of water, pulled from the watershed of \nthe Raccoon and Des Moines rivers in central Iowa to cool a powerful supercomputer as it helped teach its AI \nsystems how to mimic human writing.\nAs they race to capitalize on a craze for generative AI, leading tech developers including Microsoft, OpenAI and \nGoogle have acknowledged that growing demand for their AI tools carries hefty costs, from expensive \nsemiconductors to an increase in water consumption.\nBut they're often secretive about the specifics. \nFew people in Iowa knew about its status as a birthplace of OpenAI's most advanced large language model, GPT-\n4, before a top Microsoft executive said in a speech it \"was literally made next to cornfields west of Des Moines.\"\nBuilding a large language model requires analyzing patterns across a huge trove of human-written text. All of that \ncomputing takes a lot of electricity and generates a lot of heat. To keep it cool on hot days, data centers need to \npump in water - often to a cooling tower outside its warehouse-sized buildings.\nIn its latest environmental report, Microsoft disclosed that its global water consumption spiked 34% from 2021 to \n2022 (to nearly 1.7 billion gallons), a sharp increase compared to previous years that outside researchers tie to its \nAI research.\n\"It's fair to say the majority of the growth is due to AI,\" including \"its heavy investment in generative AI and \npartnership with OpenAI,\" said Shaolei Ren, a researcher at the University of California, Riverside, who has been \ntrying to calculate the environmental impact of generative AI products such as ChatGPT.\nIn a forthcoming paper, Ren's team estimates ChatGPT gulps up 500 milliliters of water (close to what's in a 16-\nounce water bottle) every time you ask it a series of 5 to 50 prompts or questions. The range varies depending on \nwhere its servers are located and the season. The estimate includes indirect water usage that the companies don't \nmeasure - such as to cool power plants that supply the data centers with electricity.\nVery thirsty AI technology behind ChatGPT Iowa town's water consumption spikes thanks to Microsoft\n\"Most people are not aware of the resource usage underlying ChatGPT,\" Ren said. \"If you're not aware of the \nresource usage, then there's no way that we can help conserve the resources.\"\nGoogle reported a 20% increase in water use in the same period, which Ren also largely attributes to its AI work. \nGoogle's spike wasn't uniform - it was steady in Oregon where its water use has attracted public attention, while \ndoubling outside Las Vegas. It was also thirsty in Iowa, drawing more potable water to its Council Bluffs data \ncenters than anywhere else.\nIn response to questions from The Associated Press, Microsoft said in a statement last week that it is investing in \nresearch to measure AI's energy and carbon footprint \"while working on ways to make large systems more efficient, \nin both training and application.\"\n\"We will continue to monitor our emissions, accelerate progress while increasing our use of clean energy to power \ndata centers, purchasing renewable energy, and other efforts to meet our sustainability goals of being carbon  \nnegative, water positive and zero waste by 2030,\" the company's statement said.\nOpenAI echoed those comments in its own statement Friday, saying it's giving \"considerable thought\" to the best \nuse of computing power.\n\"We recognize training large models can be energy and water-intensive\" and work to improve efficiencies, it said.\nMicrosoft made its first $1 billion investment in San Francisco-based OpenAI in 2019, more than two years before \nthe startup introduced ChatGPT and sparked worldwide fascination with AI advancements. As part of the deal, the \nsoftware giant would supply computing power needed to train the AI models.\nTo do at least some of that work, the two companies looked to West Des Moines, Iowa, a city of 68,000 people \nwhere Microsoft has been amassing data centers to power its cloud computing services for more than a decade. Its \nfourth and fifth data centers are due to open there later this year.\n\"They're building them as fast as they can,\" said Steve Gaer, who was the city's mayor when Microsoft came to \ntown. Gaer said the company was attracted to the city's commitment to building public infrastructure and \ncontributed a \"staggering\" sum of money through tax payments that support that investment.\nExperts have said it can make sense to \"pretrain\" an AI model at a single location because of the large amounts of \ndata that need to be transferred between computing cores.\nIt wasn't until late May that Microsoft's president, Brad Smith, disclosed that it had built its \"advanced AI \nsupercomputing data center\" in Iowa, exclusively to enable OpenAI to train what has become its fourth-generation \nmodel, GPT-4. The model now powers premium versions of ChatGPT and some of Microsoft's own products and \nhas accelerated a debate about containing AI's societal risks.\nIn some ways, West Des Moines is a relatively efficient place to train a powerful AI system, especially compared to \nMicrosoft's data centers in Arizona that consume far more water for the same computing demand.\n\"So if you are developing AI models within Microsoft, then you should schedule your training in Iowa instead of in \nArizona,\" Ren said. \"In terms of training, there's no difference. In terms of water consumption or energy \nconsumption, there's a big difference.\"\nFor much of the year, Iowa's weather is cool enough for Microsoft to use outside air to keep the supercomputer \nrunning properly and vent heat out of the building. Only when the temperature exceeds about 85 degrees does it \nwithdraw water, the company has said in a public disclosure.\nThat can still be a lot of water, especially in the summer. In July 2022, the month before OpenAI says it completed \nits training of GPT-4, Microsoft pumped in about 11.5 million gallons of water to its cluster of Iowa data centers, \naccording to the West Des Moines Water Works. That amounted to about 6% of all the water used in the district.\nVery thirsty AI technology behind ChatGPT Iowa town's water consumption spikes thanks to Microsoft\nIn 2022, a document from the West Des Moines Water Works said it and the city government \"will only consider \nfuture data center projects\" from Microsoft if those projects can \"demonstrate and implement technology to \nsignificantly reduce peak water usage from the current levels.\"\nMicrosoft said last week that it is working directly with the water works to address its feedback. In a statement, the \nwaterworks said the company has been a good partner and has been working with local officials to reduce its water \nfootprint while still meeting its needs.\nLoad-Date: September 18, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Jul2023",
        "header": "REALITY CHECK FOR METAVERSE",
        "media": "Economic Times (E-Paper Edition)",
        "time": "July 17, 2023",
        "section": "DEEP DIVE",
        "length": "1807 words",
        "byline": "Shelley Singh & Rishi Tejpal",
        "story_text": "REALITY CHECK FOR METAVERSE\nEconomic Times (E-Paper Edition)\nJuly 16, 2023 Sunday\nKolkata Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: DEEP DIVE\nLength: 1807 words\nByline: Shelley Singh & Rishi Tejpal\nHighlight: Lack of clarity over RoI has forced several companies to put their metaverse plans on hold\nBody\nQ: Which was the last trending technology that fell off the radar as quickly as it emerged? A: Metaverse. The \nrevolutionary technology which had promised to change our digital experiences forever created a big hype. But \nnearly two years after Mark Zuckerberg rebranded Facebook as Meta, positioning the social media giant as the \npioneer of the physical world's alternate reality, the excitement around metaverse seems to have died down. In a \nscenario of high interest rates and economic slowdown, several companies have put their metaverse plans on hold \nwhile many others are diverting resources to technologies such as artificial intelligence (AI) where implementation \nseems easier and there is visibility on return on investment (RoI). Moreover, challenges such as high device costs \nand the interplay of different technologies make metaverse, even now, a distant reality. \nTHE PROMISE The metaverse visualises a 3D virtual space where people will interact via their avatars. They will \ntravel , at tend events and conferences, bank, shop, study and buy real estate in the virtual world. Such is the \nappeal of the idea that the bets are still not off. According to global majors, including Goldman Sachs and PwC, the \nmetaverse market will be worth nearly $1 trillion in less than a decade, buoyed by users leaving their 2D online \nexperiences for richer, immersive, real-like, interactive experiences in the 3D metaverse. “The vision is there. The \nindustry is deeply involved in discovering and building robust solutions that will bring it to life. The metaverse is in \nabout the same place that the internet was in 1993 or so, showing some promise. But the real groundbreaking and \nearth-shattering things are still very much to come, once we get the basic infrastructure questions solved,” says \nLeslie Shannon, head of ecosystem and trend scouting at Nokia. Social media giant Meta, owner of Facebook, \nWhatsApp and Instagram, was among the most bullish, pumping billions into the metaverse. The idea of avatars \nmeeting in virtual environments seemed the best way to upgrade digital lives and that's when companies started \nbooking virtual real estate across the metaverse. JP Morgan opened a bank branch in Decentraland, one of the \nmost popular metaverse addresses. Nike sold shoes, while Gucci, Louis Vuitton, CocaCola, Tanishq and others \nexpanded their presence into the metaverse. Nike has invested close to $200 million in its metaverse initiatives. \nWhile there was a lot of excitement about the metaverse ushering in a digital era of phantasmagoria, it has \nremained elusive. Much of the development in the metaverse had barely started when AI took the world by  storm. \nTo complicate matters, the me taverse is not a single technology but a convergence of multiple ones such as spatial \ncomputing and 3D environments, and involves the use of augmented reality (AR) and virtual reality (VR) headsets. \nEach comes with its own challenges — from high costs to lack of practical use cases. With AI promising a quicker \nimpact on productivity and performance, the idea of metaverse has gone cold. Disney and Microsoft have put their \nmetaverse plans on hold, shifting focus to AI. In February, Microsoft shut down development in its industrial \nmetaverse venture and downsized its AR and mixed reality (MR) teams. Meta's arm Reality Labs has lost over $20 \nbillion in metaverse projects. It has laid off thousands of people who were working on various aspects of the \nmetaverse development. Tight economic conditions, high interest rates, inflation and cost concerns have forced \nseveral companies to review their metaverse projects. Even users are reluctant to spend on new experiences. \nREALITY CHECK FOR METAVERSE\n“Companies need a clear RoI. If they can't see that, then it's just an experiment that fades away,” says Anushree \nVerma, director analyst, Gartner India. Attention has shifted to AI, driven by OpenAI's bot ChatGPT's generative \ncapabilities which help create content , tex t , videos and images. Gaurav Vasu, CEO, UnearthInsight, a Bengaluru-\nbased research firm, points out that about 90% of metaverse budgets by Indian enterprises have been diverted to \ngenerative AI largely because tech services firms see revenue and realistic client implementation opportunities \nthere. “In fact, retail and automotive companies have cut metaverse budget by 100% and pushed the same by at \nleast 12-18 months,” he says. In 2021-22, UnearthInsight had forecast an investment of $500-600 million from more \nthan 100 Indian enterprises in the metaverse. This is now shifting to AI. Is AI eating into the metaverse's space? \nWhile some of the trends and research  insights cited above point in that direction, Shannon has a different \nperspective. Citing trends from the Augmented World Expo, an annual gathering of people in the extended reality \n(XR) industry, she says, “The metaverse/XR/spatial computing worlds are huge and growing.” The expo at the \nSanta Clara Convention Center in California attracted more than 300 exhibitors this year, up from around 225 in \n2022, and there are plans to shift the event to a bigger venue next year to accommodate the growing number of \nparticipants. “It's a misconception to think of XR and AI as being in competition with each other,” Shannon \nreiterates. Though AI has generated  a lot of excitement and is attracting new investments, the metaverse is not \ndead. Gartner India's Verma says the vision of creating a 3D, virtual, collaborative space is intact. “The hype was \nfar greater than what the products and services could deliver at the time,” she says. Says Sunil Gopinath, CEO of \nthe Indian unit of the Japanese internet and ecommerce firm Rakuten: “Metaverse today is in the same stage of \nevolution that smartphones were in the early 2000s.” He says the challenge back then was to make phones \naffordable so that they become ubiquitous. Things took off only when devices and data became affordable and the \ncontent and apps ecosystem evolved  alongside. “If a device for metaverse access costs $1,000, just about 1% of \nthe user base might buy it. The metaverse is valuable for building immersive experiences, but these challenges \n(costs, content, connectivity, etc.) need to be sorted out,” says Gopinath. While users see merit in immersive \nexperiences, these need to be affordable to enable mass adoption. Take the AR/VR devices needed to access the \nmetaverse. Apple is a premium brand, but even people with high spending propensity may think twice before \nshelling out $3,499 (about `3 lakh) for an Apple Pro Vision, an MR headset launched on Jun e 4 . Meta VR head \nsets Quest Pro and Quest 2, even after price drops, cost between `30,000 and `70,000. While headset-free 3D \nmonitors are in the early stages of development and won't be commercially available for another two years , sales \nof VR head sets fell 1 2 % i n 2022 to 9.6 million units from a year ago. “Headsets are still in the early days. Time, \nhard work and investments by device manufacturers will fix this problem,” says Shannon. Most experts ET Prime \nspoke to are of the view that the metaverse is still in its early years of development. It's just a matter of time. As \nShannon says, “We are looking at the caterpillar, the butterfly comes later.” A BRIDGE CALLED B2B According to a \nJune 2023 research report by EY and Nokia, the metaverse is highly futuristic Though the initial impression of \nmetaverse is of an immersive virtual environment focused on gaming, social networking and commerce, that is only \na small part of the larger theme. The report categorises metaverse into three broad categories — consumer \nmetaverse, enterprise metaverse and industrial metaverse. The report forecasts enterprise and industrial metaverse \nto progress more quickly and provide more tangible value than consumer metaverse where most of the attention is \ncurrently focused on. Enterprise metaverse is mostly driven by the demand for better digital communication and \nvirtual collaboration. Industrial metaverse is the fusion of physical  and digital worlds along with human \naugmentation. The industrial applications are expected to deliver beyond expectations. Supporting technologies, \ntoo, need to mature for the broader metaverse ecosystem to evolve. These include non-fungible tokens (NFTs), \ntransactions via cryptocurrencies, spatial computing, avatars and digital humans. Hence, getting consumers hooked \nto the metaverse is going to be a challenge as the ecosystem is expensive. Given the high costs and user \nexperience challenges in the consumer space, B2B (enterprise and industrial metaverse) might be a better place to \nstart metaverse. B2B metaverse can avoid the pitfalls of B2C in several ways, including goals, services offered, \nrevenue models and data-privacy concerns. It serves enterprise customers, helping them save time and money by \noffering virtual tours (of, say, factories), virtual product demonstrations, collaborations, transactions and so on. \nWhile the B2C metaverse ecosystem focuses on providing immersive and entertaining experiences for users, the \nB2B metaverse is designed to provide functional and efficient solutions for businesses. Solutions include training, \neducation, better remote work solutions and other specialised services. B2B metaverse use cases will help iron out \nglitches and make B2C adoption easier in the long run. Though AI has stolen the limelight for now, the metaverse \ncan use the technology to improve its own development and offerings. AI can help create metaverse experiences, \nthough the technology itself needs improvement to deliver reliable results. Vasu of UnearthInsight explains that \nREALITY CHECK FOR METAVERSE\ngenerative AI is viewed as an implementable technology solution for companies with strong internal databases \nacross operations, finance and HR. “It is seen as a productivity improvement tool for banks, content/media, edtech, \nfinancial services and more. The metaverse, meanwhile, is a larger ecosystem play. Companies are looking at \nshort-term margin improvement solutions now. Hence the metaverse will take a back seat for at least 12 months,” \nhe says. Vasu sees the metaverse making a comeback as devices become affordable, interest rates fall and \ninflation eases, consequently pushing up discretionary spending. Meanwhile, Rakuten's Gopinath sees metaverse \nadoption happening in three to five y ears. “ For rich 3D content, 5G networks have to become ubiquitous. Once \nsmartphones reach a level where they are good enough to render 3D, that's when you start seeing escape velocity \nfor the metaverse,” he says. Besides tech challenges, the metaverse has to address multiple non-tech issues such \nas virtual harassment and impact on mental health due to long hours spent in the virtual world. The good thing is \nthat while the hype is over the vision remains intact.  “All of our glory days lie ahead,” says Shannon. shelley .singh \n1@timesinternet.in\nLoad-Date: July 17, 2023"
    },
    {
        "file_name": "What_to_know_Feb2024",
        "header": "OpenAI, Chat GPT creator, unveils Sora to turn writing prompts into videos:",
        "media": "What to know",
        "time": "February 16, 2024",
        "section": "TECH LATEST",
        "length": "1085 words",
        "byline": "Julia Gomez, USA TODAY",
        "story_text": "OpenAI, Chat GPT creator, unveils Sora to turn writing prompts into videos: \nWhat to know\nUSA Today Online\nFebruary 16, 2024\nCopyright 2024 Gannett Media Corp  All Rights Reserved\nSection: TECH LATEST\nLength: 1085 words\nByline: Julia Gomez, USA TODAY\nBody\nOpenAI, the creator of Chat GPT, has unveiled Sora, the latest upgrade in generative artificial intelligence. It's a \ntool that makes short videos from prompts written by users.\nThe San Francisco-based company announced the news on Thursday and showed videos created by the new text-\nto-video generator on their website. \n\"We’re teaching AI to understand and simulate the physical world in motion with the goal of training models that \nhelp people solve problems that require real-world interaction,\" states OpenAI's website. \nFootage of California during the gold rush, tiny pandas running around a petri dish and a gnome creating patterns in \nthe zen garden of his snow globe enclosure are just some of the examples of what Sora, OpenAI's video creation \ntool, can make.\n\"We’re sharing our research progress early to start working with and getting feedback from people outside of \nOpenAI and to give the public a sense of what AI capabilities are on the horizon,\" states OpenAI on its website.\nhere is sora, our video generation model:https://t.co/CDr4DdCrh1\ntoday \nwe \nare \nstarting \nred-teaming \nand \noffering \naccess \nto \na \nlimited \nnumber \nof \ncreators.@_tim_brooks @billpeeb @model_mechanic are really incredible; amazing work by them and the team.\nremarkable moment.\n— Sam Altman (@sama)\nFebruary 15, 2024\nIn an announcement tweeted by Sam Altman, OpenAI's CEO, he said a limited number of people will be able to use \nthe new program right now. It's not publicly available just yet.\n\"We are starting red-teaming and offering access to a limited number of creators,\" said Altman in the post.\nAI: Find out who's calling, use AI and more with 15 smart tech tips\nYouTube star puts Sora, new OpenAI tool, to the test\nYouTube's biggest star, Jimmy Donaldson, AKA, MrBeast, replied to Altman's post the two engaged in some playful \nbanter about the new tool.\nOpenAI, Chat GPT creator, unveils Sora to turn writing prompts into videos: What to know\nTo that, Altman said he'd make the YouTuber a video. He just needed to give Altman a prompt.\nDonaldson asked for a video of a \"monkey playing chess in a park,\" and Altman delivered.\npic.twitter.com/vb9giSg9np\n— Sam Altman (@sama)\nFebruary 15, 2024\nHow do I use Sora?\nAccording to the announcement posted to OpenAI's website, Sora is going to be similar to OpenAI's text-to-image \ngenerator. Users just need to type out a prompt, and the program will give them a video of what they requested.\nHowever, it can only be accessed by red teamers who will assess \"critical areas for harms or risks\" for the company \nand \"a number of visual artists, designers, and filmmakers to gain feedback on how to advance the model to be \nmost helpful for creative professionals.\"\n It isn't available to the public, and there is no word on when the layman will be able to use it.\nWhat can Sora do?\nThe program uses its \"deep understanding of language\" to interpret prompts and then create videos with \"complex \nscenes\" that are up to a minute long, with multiple characters and camera shots, as well as specific types of motion \nand accurate details. \nThe examples OpenAI gives range from animated a monster and kangaroo to realistic videos of people, like a \nwoman walking down a street in Tokyo or a cinematic movie trailer of a spaceman on a salt desert.\n        Embedded content: https://cdn.openai.com/sora/videos/monster-with-melting-candle.mp4            \n\"Animated scene features a close-up of a short fluffy monster kneeling beside a melting red candle,\" in the first \nsentence of the prompt that created the 3D video above.\nAccording to OpenAI, the videos displayed on its announcement page were all created by Sora.\nChallenges that Sora faces\nOpenAI states the program may struggle with the following:\n• Accurately simulating the physics of a complex scene\n• Understanding instances of cause and effect. An example it gives is someone might bite into a cookie, but the \ncookie doesn't have a bite mark after.\n• Confusing spatial details of a prompt, like mixing up left and right.\n• Precise descriptions of events over time.\n        Embedded content: https://cdn.openai.com/sora/videos/grandma-birthday.mp4            \nOne of the examples of what can go wrong is a video of a grandma blowing candles out on her birthday. But as she \nblows them out, the candles don't extinguish.\nPrompt given for the video:\nA grandmother with neatly combed grey hair stands behind a colorful birthday cake with numerous candles at a \nwood dining room table, expression is one of pure joy and happiness, with a happy glow in her eye. She leans \nOpenAI, Chat GPT creator, unveils Sora to turn writing prompts into videos: What to know\nforward and blows out the candles with a gentle puff, the cake has pink frosting and sprinkles and the candles \ncease to flicker, the grandmother wears a light blue blouse adorned with floral patterns, several happy friends and \nfamily sitting at the table can be seen celebrating, out of focus. The scene is beautifully captured, cinematic, \nshowing a 3/4 view of the grandmother and the dining room. Warm color tones and soft lighting enhance the mood.\nWhat's wrong with it? Well, according to OpenAI, \"simulating complex interactions between objects and multiple \ncharacters is often challenging for the model, sometimes resulting in humorous generations.\"\nEthical and societal implications of AI\nFolks have been bringing up the ethics behind AI since the program became popular. Situations involving high-\nranking officials, like when AI mimicked the president in phone calls and encouraged people not to vote, have \nalready happened.\nBut OpenAI says they're working on taking safety steps before Sora becomes available to the public.\n“We are working with red teamers  —  domain experts in areas like misinformation, hateful content, and bias  —  who \nwill be adversarially testing the model,” the company said in its statement. “We’re also building tools to help detect \nmisleading content, such as a detection classifier that can tell when a video was generated by Sora.”\nIt says it's creating new techniques while also making sure existing safety precautions that already apply to its other \nprogram, DALL·E 3, are applicable to Sora.\nFor example, \"our text classifier will check and reject text input prompts that are in violation of our usage policies, \nlike those that request extreme violence, sexual content, hateful imagery, celebrity likeness or the IP of others,\" \nstates the company. \"We’ve also developed robust image classifiers that are used to review the frames of every \nvideo generated to help ensure that it adheres to our usage policies, before it’s shown to the user.\"\nThis article originally appeared on USA TODAY: OpenAI, Chat GPT creator, unveils Sora to turn writing prompts \ninto videos: What to know\nLoad-Date: February 16, 2024"
    },
    {
        "file_name": "The_New_York_Times_-_International_Edition_May2023",
        "header": "Will a Chatbot Write the Next 'Succession'?",
        "media": "The New York Times - International Edition",
        "time": "May 5, 2023",
        "section": "BUSINESS",
        "length": "1742 words",
        "byline": "Noam Scheiber and John Koblin",
        "story_text": "Will a Chatbot Write the Next 'Succession'?\nThe New York Times - International Edition\nMay 6, 2023 Saturday\nCopyright 2023 International Herald Tribune All Rights Reserved\nSection: BUSINESS\nLength: 1742 words\nByline: Noam Scheiber and John Koblin\nBody\nABSTRACT\nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.\nFULL TEXT\n         April 29,2023, Saturday         Online Correction:              \nThis article has been revised to reflect the following correction: An earlier version of this article misstated John \nAugust's affiliation. He is on the Writers Guild negotiating committee, not a member of the Writers Guild board. \nCORRECTION APPENDED \nAs labor contract negotiations heat up in Hollywood, unions representing writers and actors seek limits on artificial \nintelligence.       \nWhen the union representing Hollywood writers laid out its list of objectives for contract negotiations with studios \nthis spring, it included familiar language on compensation, which the writers say has either stagnated or dropped \namid an explosion of new shows.       \nBut far down, the document added a distinctly 2023 twist. Under a section titled \"Professional Standards and \nProtection in the Employment of Writers,\" the union wrote that it aimed to \"regulate use of material produced using \nartificial intelligence or similar technologies.\"       \nTo the mix of computer programmers, marketing copywriters, travel advisers, lawyers and comic illustrators \nsuddenly alarmed by the rising prowess of generative A.I., one can now add screenwriters.       \n\"It is not out of the realm of possibility that before 2026, which is the next time we will negotiate with these \ncompanies, they might just go, 'you know what, we're good,'\" said Mike Schur, the creator of \"The Good Place\" and \nco-creator of \"Parks and Recreation.\"       \n\"We don't need you,\" he imagines hearing from the other side. \"We have a bunch of A.I.s that are creating a bunch \nof entertainment that people are kind of OK with.\"       \nIn their attempts to push back, the writers have what a lot of other white-collar workers don't: a labor union.       \nWill a Chatbot Write the Next 'Succession'?\nMr. Schur, who serves on the bargaining committee of the Writers Guild of America as it seeks to avert a strike \nbefore its contract expires on Monday, said the union hopes to \"draw a line in the sand right now and say, 'Writers \nare human beings.'\"       \nBut unions, historians say, have generally failed to rein in new technologies that enable automation or the \nreplacement of skilled labor with less-skilled labor. \"I'm at a loss to think of a union that managed to be plucky and \nmake a go of it,\" said Jason Resnikoff, an assistant professor of history at the University of Groningen in the \nNetherlands, who studies labor and automation.       \nThe fortunes of the writers, actors and directors negotiating new contracts this year may say a lot about whether the \npattern will continue into the era of artificial intelligence.       \nIn December, Apple introduced a service allowing book publishers to use human-sounding A.I. narrators, an \ninnovation that could displace hundreds of voice actors who make a living performing audiobooks. The company's \nwebsite says the service will benefit independent authors and small publishers.       \n\"I know someone always has to get there first, some company,\" said Chris Ciulla, who estimates that he has made \n$100,000 to $130,000 annually over the past five years narrating books under union contracts. \"But for individuals \nnot to understand how that can affect the pail-carrying narrator out there eventually is disappointing.\"       \nOther actors fear that studios will use A.I. to replicate their voices while cutting them out of the process. \"We've \nseen this happening - there are websites that have popped up with databases of characters' voices from video \ngames and animation,\" said Linsay Rousseau, an actress who makes her living doing voice work.       \nOn-camera actors point out that studios already use motion capture or performance capture to replicate artists' \nmovements or facial expressions. The 2018 blockbuster \"Black Panther\" relied on this technology for scenes that \ndepicted hundreds of tribespeople on cliffs, mimicking the movements of dancers hired to perform for the film.       \nSome actors worry that newer versions of the technology will allow studios to effectively steal their movements, \n\"creating new performance in the style of a wushu master or karate master and using that person's style without \nconsent,\" said Zeke Alton, a voice and screen actor who sits on the board of his union local, SAG-AFTRA, in Los \nAngeles.       \nAnd Hollywood writers have grown increasingly anxious as ChatGPT has become adept at mimicking the style of \nprolific authors.       \n\"Early on in the conversations with the guild, we talked about what I call the Nora Ephron problem,\" said John \nAugust, who is on the Writers Guild negotiating committee.\"Which is basically: What happens if you feed all of Nora \nEphron's scripts into a system and generate an A.I. that can create a Nora Ephron-sounding script?\"       \nMr. August, a screenwriter for movies like \"Charlie's Angels\" and \"Charlie and the Chocolate Factory,\" said that \nwhile artificial intelligence had taken a back seat to compensation in the Writers Guild negotiation, the union was \nmaking two key demands on the subject of automation.       \nIt wants to ensure that no literary material - scripts, treatments, outlines or even discrete scenes - can be written or \nrewritten by chatbots. \"A terrible case of like, 'Oh, I read through your scripts, I didn't like the scene, so I had \nChatGPT rewrite the scene' - that's the nightmare scenario,\" Mr. August said.       \nThe guild also wants to ensure that studios can't use chatbots to generate source material that is adapted to the \nscreen by humans, the way they might adapt a novel or a magazine story.       \nSAG-AFTRA, the actors' union, says more of its members are flagging contracts for individual jobs in which studios \nappear to claim the right to use their voices to generate new performances.       \nA recent Netflix contract sought to grant the company free use of a simulation of an actor's voice \"by all \ntechnologies and processes now known or hereafter developed, throughout the universe and in perpetuity.\"       \nWill a Chatbot Write the Next 'Succession'?\nNetflix said the language had been in place for several years and allowed the company to make the voice of one \nactor sound more like the voice of another in case of a casting change between seasons of an animated production.       \nThe union has said that its members are not bound by contract provisions that would allow a producer to simulate \nnew performances without compensating actors, though it has sometimes intervened to strike them from contracts \nnonetheless.       \nDuncan Crabtree-Ireland, SAG-AFTRA's executive director, said such contracts posed a much bigger risk to \nnonunion actors, who can become unwitting accomplices in their own obsolescence. \"It only takes one or a few \ninstances of signing away your rights on a lifetime basis to really potentially have a negative impact on your career \nprospects,\" Mr. Crabtree-Ireland said.       \nThe Alliance of Motion Picture and Television Producers, which bargains with the various unions that represent \nwriters, actors and directors on behalf of the major Hollywood studios, declined to comment.       \nWhen professionals have fended off obsolescence at the hands of technology, the outcome has often reflected their \noccupation's status and prestige.       \nThat appears to have been the case to some extent with airplane pilots, whose crew sizes had dropped to two on \nmost domestic commercial flights by the late 1990s, but have largely been level since then, even as automated \ntechnology has become far more sophisticated and the industry has explored further reductions.       \n\"The safety net you have when you're high off the ground - the one that keeps you from hitting the ground - is two \nhighly trained, experienced, rested pilots,\" said Capt. Dennis Tajer, a spokesman for the Allied Pilots Association, \nwhich represents pilots for American Airlines. To this day, flight times longer than nine hours require at least three \npilots.       \nThe replacement of certain doctors by artificial intelligence, which some experts predicted was imminent in fields \nlike radiology, has also failed to materialize. That's partly because of the limits of the technology, and because of \nthe stature of the doctors, who have inserted themselves into high-stakes conversations about the safety and \ndeployment of A.I. The American College of Radiology created a Data Science Institute partly for this purpose \nseveral years ago.       \nWhether screenwriters find similar success will depend at least in part on if there are inherent limits to the machines \nthat purport to do their jobs. Some writers and actors speak of a so-called uncanny valley that algorithms may never \nentirely escape.       \n\"Artists look at everything ever created and find a flash of newness,\" said Javier Grillo-Marxuach, a writer and \nproducer for \"Lost\" and \"Dark Crystal: Age of Resistance.\" \"What the machine is doing is recombining.\"       \nHowever sophisticated the algorithms, the fate of writers and actors will also depend on how well they protect their \nstatus. How good are they at convincing audiences that they should care whether a human is involved?       \nThe unions are pressing their case. Mr. August says that it falls to the Writers Guild and not the studio to determine \nwho receives a writer's credit on a project, and that the union will guard this rite jealously. \"We want to make sure \nthat an A.I. is never one of those writers in the chain of title for a project,\" he said.       \nThe unions also have legal cards to play, Mr. Crabtree-Ireland of SAG-AFTRA said, like the U.S. Copyright Office's \npronouncement in March that content created entirely by algorithm is not eligible for copyright protection. It is harder \nto monetize a production if there is no legal obstacle to copying it.       \nPerhaps more important, he said, is what you might call the Us Weekly factor - the tendency of audiences to be as \ninterested in the human behind the role as in the performance. Fans want to hear Hollywood celebrities discuss \ntheir method in interviews. They want to gawk at actors' fashion sensibilities and keep up with whom they're dating.       \nWill a Chatbot Write the Next 'Succession'?\n\"If you look at culture in general, the audience is generally interested in the real lives of our members,\" Mr. \nCrabtree-Ireland said. \"A.I. is not in a position to substitute for key elements of that.\"       \nAudio produced by Sarah Diamond.       \nAudio produced by Sarah Diamond. \nLoad-Date: May 5, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Sep2023",
        "header": "Can AI Actors Dethrone Superstars?",
        "media": "Economic Times (E-Paper Edition)",
        "time": "September 16, 2023",
        "section": "BREAKING IDEAS",
        "length": "819 words",
        "byline": "Anil Nair",
        "story_text": "Can AI Actors Dethrone Superstars?\nEconomic Times (E-Paper Edition)\nSeptember 16, 2023 Saturday\nDelhi Edition\nCopyright 2023 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: BREAKING IDEAS\nLength: 819 words\nByline: Anil Nair\nBody\nThe Independence Day weekend saw `390 crore in gross box-office collections, a record for Indian cinema in over \n100 years. Rajinikanth's Jailer, Sunny Deol's Gadar 2, Akshay Kumar's OMG 2 and Chiranjeevi's Bhola Shankar did \nexceptional business across languages, multiplexes and single-screen halls. And Atlee's SRKstarring Jawan, of \ncourse, reinforced the trend with first-day collections of `74.5 crore. With generative AI becoming pervasive, will \ndeepfakes replace actors?\n Or bring deceased actors back to life? The current turmoil in Hollywood could well be the trigger. The US Screen \nActors Guild and American Federation of Television and Radio Artists (SAG-AFTRA) struck work on July 14, joining \nthe Writers Guild of America (WGA), who've been protesting since May 2, demanding higher pay, job security and \nmore parity across the industry. The impasse has lasted over 130 days, and estimates put the economic impact at \n$2-3 billion. There is uncertainty about when this strike will end and how big the hole will be. While streamers like \nNetflix and Amazon can source content, including movies, series, events and sport, from the rest of the world, and \nthe TV industry will chug along  till they have inventory, studios are aware that losses are in the offing. The strike in \nHollywood is hurting other sectors too, including clothiers, prop-makers, caterers, transportation companies, hotels \nand cinema theatres. And that's why thoughts about a new, more robust valuechain hover. Generative AI and CGI \nare poised to impact the film business extraordinarily. For instance, creativity could be automated for the most part, \nwith human intervention limited to coursecorrection. Scripts, sets and costume design, storyboards, and visual \neffects are par for the course. Actors can be de-aged, as director James Mangold did in Indiana Jones and the Dial \nof Destiny recently, when 80-year-old Harrison Ford had to look 35 years younger in two action sequences. \nDirectors can now create new virtual characters, perfectly matching their imagined roles. Film companies would be \nspared the pain of hard negotiations over rates or matching the calendars of actors, while slashing costs \ndramatically, including on overruns. AI-powered tools are increasingly being used for editing and postproduction \nwork, whether to obliterate irksome objects or  transform footage with natural language prompts. They will \nunshackle the imagination of filmmakers, reined in now by hurdles, such as permissions, costs, access, facilities \nand actors. Image-generation models are evoking a lot of interest and are rapidly becoming sophisticated. For \ninstance, Runway Research released Latent Diffusion in 2021, which could be prompted to generate realistic \nimages. Stable Diffusion, released in 2022, had more advanced image generation. Then came Gen 1, which \nenabled the generation of new video content from a simple video — stylising footage, converting mock-ups into \nanimated shots, modifying objects in a picture entirely, or rendering them differently to create new scenes. Now, \nRunway's Gen 2 takes a huge technological leap, and, though nascent, can generate short videos from mere text \nprompts. Adobe's After Effects is used extensively in film and TV post-production. Its newly launched Firefly, an \nembedded generative AI model, in March, can recommend shots after gleaning the script, generate a background \nscore and even different backdrops for different countries.  Adobe is promising that commercial use of Firefly will be \nlegally safe. Importantly, the process of democratisation is underway. Small creative houses can now think big with \nsuch tools. Some recent Indian films that have used AI are Paan Singh Tomar (2012), Ghazi Attack (2017), Kesari \nCan AI Actors Dethrone Superstars?\n(2019), and Uri (2019). Like most countries, India has no specific laws to address the issue of deepfakes. Various \nsections of the Indian Penal Code 1860, Indian Evidence Act 1872, Copyright Act 1957, and the IT Act 2000 would \napply in the case of fake images inserted in synthetic media. India's landmark Digital Personal Data Protection Bill \n2023, passed by Parliament last month, could've changed that. That the debate in each House lasted less than an \nhour is telling. Various sections could've dealt with deepfake-related issues more specifically, for instance, sections \npertaining to information relating to a living individual, prohibiting processing personal data that is unfair, deceptive \nor intrusive; the section that calls for responsible data fiduciaries or the removal of violative information. Areas of \nconcern include wide ranging governmental exemptions and worse, that the Data Protection Board of India will \nhave only government nominees. The autonomy of this board will determine how well the Bill serves and protects \ndata principals — stars and people like us, even from our digital doppelgngers. The writer is senior fellow, Portulans \nInstitute, Washington DC\nLoad-Date: September 16, 2023"
    },
    {
        "file_name": "The_New_York_Times_Feb2023",
        "header": "Don’t Ban ChatGPT in Schools. Teach With It.; The Shift",
        "media": "The New York Times",
        "time": "February 23, 2023",
        "section": "TECHNOLOGY",
        "length": "1735 words",
        "byline": "Kevin Roose",
        "story_text": "Don’t Ban ChatGPT in Schools. Teach With It.; The Shift\nThe New York Times \nJanuary 12, 2023 Thursday 16:56 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: TECHNOLOGY\nLength: 1735 words\nByline: Kevin Roose\nHighlight: OpenAI’s new chatbot is raising fears of cheating on homework, but its potential as an educational tool \noutweighs its risks.\nBody\nOpenAI’s new chatbot is raising fears of cheating on homework, but its potential as an educational tool outweighs \nits risks.\nRecently, I gave a talk to a group of K-12 teachers and public school administrators in New York. The topic was \nartificial intelligence, and how schools would need to adapt to prepare students for a future filled with all kinds of \ncapable A.I. tools.\nBut it turned out that my audience cared about only one A.I. tool: ChatGPT, the buzzy chatbot developed by \nOpenAI that is capable of writing cogent essays, solving science and math problems and producing working \ncomputer code.\nChatGPT is new — it was released in late November — but it has already sent many educators into a panic. \nStudents are using it to write their assignments, passing off A.I.-generated essays and problem sets as their own. \nTeachers and school administrators have been scrambling to catch students using the tool to cheat, and they are \nfretting about the havoc ChatGPT could wreak on their lesson plans. (Some publications have declared, perhaps a \nbit prematurely, that ChatGPT has killed homework altogether.)\nCheating is the immediate, practical fear, along with the bot’s propensity to spit out wrong or misleading answers. \nBut there are existential worries, too. One high school teacher told me that he used ChatGPT to evaluate a few of \nhis students’ papers, and that the app had provided more detailed and useful feedback on them than he would \nhave, in a tiny fraction of the time.\n“Am I even necessary now?” he asked me, only half joking.\nSome schools have responded to ChatGPT by cracking down. New York City public schools, for example, recently \nblocked ChatGPT access on school computers and networks, citing “concerns about negative impacts on student \nlearning, and concerns regarding the safety and accuracy of content.” Schools in other cities, including Seattle, \nhave also restricted access. (Tim Robinson, a spokesman for Seattle Public Schools, told me that ChatGPT was \nblocked on school devices in December, “along with five other cheating tools.”)\nIt’s easy to understand why educators feel threatened. ChatGPT is a freakishly capable tool that landed in their \nmidst with no warning, and it performs reasonably well across a wide variety of tasks and academic subjects. There \nare legitimate questions about the ethics of A.I.-generated writing, and concerns about whether the answers \nChatGPT gives are accurate. (Often, they’re not.) And I’m sympathetic to teachers who feel that they have enough \nto worry about, without adding A.I.-generated homework to the mix.\nDon’t Ban ChatGPT in Schools. Teach With It. The Shift\nBut after talking with dozens of educators over the past few weeks, I’ve come around to the view that banning \nChatGPT from the classroom is the wrong move.\nInstead, I believe schools should thoughtfully embrace ChatGPT as a teaching aid — one that could unlock student \ncreativity, offer personalized tutoring, and better prepare students to work alongside A.I. systems as adults. Here’s \nwhy.\nIt won’t work\nThe first reason not to ban ChatGPT in schools is that, to be blunt, it’s not going to work.\nSure, a school can block the ChatGPT website on school networks and school-owned devices. But students have \nphones, laptops and any number of other ways of accessing it outside of class. (Just for kicks, I asked ChatGPT \nhow a student who was intent on using the app might evade a schoolwide ban. It came up with five answers, all \ntotally plausible, including using a VPN to disguise the student’s web traffic.)\nSome teachers have high hopes for tools such as GPTZero, a program built by a Princeton student that claims to \nbe able to detect A.I.-generated writing. But these tools aren’t reliably accurate, and it’s relatively easy to fool them \nby changing a few words, or using a different A.I. program to paraphrase certain passages.\nA.I. chatbots could be programmed to watermark their outputs in some way, so teachers would have an easier time \nspotting A.I.-generated text. But this, too, is a flimsy defense. Right now, ChatGPT is the only free, easy-to-use \nchatbot of its caliber. But there will be others, and students will soon be able to take their pick, probably including \napps with no A.I. fingerprints.\nEven if it were technically possible to block ChatGPT, do teachers want to spend their nights and weekends \nkeeping up with the latest A.I. detection software? Several educators I spoke with said that while they found the \nidea of ChatGPT-assisted cheating annoying, policing it sounded even worse.\n“I don’t want to be in an adversarial relationship with my students,” said Gina Parnaby, the chair of the English \ndepartment at the Marist School, an independent school for grades seven through 12 outside Atlanta. “If our mind-\nset approaching this is that we have to build a better mousetrap to catch kids cheating, I just think that’s the wrong \napproach, because the kids are going to figure something out.”\nInstead of starting an endless game of whack-a-mole against an ever-expanding army of A.I. chatbots, here’s a \nsuggestion: For the rest of the academic year, schools should treat ChatGPT the way they treat calculators — \nallowing it for some assignments, but not others, and assuming that unless students are being supervised in person \nwith their devices stashed away, they’re probably using one.\nThen, over the summer, teachers can modify their lesson plans — replacing take-home exams with in-class tests or \ngroup discussions, for example — to try to keep cheaters at bay.\nChatGPT can be a teacher’s best friend\nThe second reason not to ban ChatGPT from the classroom is that, with the right approach, it can be an effective \nteaching tool.\nCherie Shields, a high school English teacher in Oregon, told me that she had recently assigned students in one of \nher classes to use ChatGPT to create outlines for their essays comparing and contrasting two 19th-century short \nstories that touch on themes of gender and mental health: “The Story of an Hour,” by Kate Chopin, and “The Yellow \nWallpaper,” by Charlotte Perkins Gilman. Once the outlines were generated, her students put their laptops away \nand wrote their essays longhand.\nThe process, she said, had not only deepened students’ understanding of the stories. It had also taught them about \ninteracting with A.I. models, and how to coax a helpful response out of one.\nDon’t Ban ChatGPT in Schools. Teach With It. The Shift\n“They have to understand, ‘I need this to produce an outline about X, Y and Z,’ and they have to think very carefully \nabout it,” Ms. Shields said. “And if they don’t get the result that they want, they can always revise it.”\nCreating outlines is just one of the many ways that ChatGPT could be used in class. It could write personalized \nlesson plans for each student (“explain Newton’s laws of motion to a visual-spatial learner”) and generate ideas for \nclassroom activities (“write a script for a ‘Friends’ episode that takes place at the Constitutional Convention”). It \ncould serve as an after-hours tutor (“explain the Doppler effect, using language an eighth grader could understand”) \nor a debate sparring partner (“convince me that animal testing should be banned”). It could be used as a starting \npoint for in-class exercises, or a tool for English language learners to improve their basic writing skills. (The \nteaching blog Ditch That Textbook has a long list of possible classroom uses for ChatGPT.)\nEven ChatGPT’s flaws — such as the fact that its answers to factual questions are often wrong — can become \nfodder for a critical thinking exercise. Several teachers told me that they had instructed students to try to trip up \nChatGPT, or evaluate its responses the way a teacher would evaluate a student’s.\nChatGPT can also help teachers save time preparing for class. Jon Gold, an eighth grade history teacher at Moses \nBrown School, a pre-K through 12th grade Quaker school in Providence, R.I., said that he had experimented with \nusing ChatGPT to generate quizzes. He fed the bot an article about Ukraine, for example, and asked it to generate \n10 multiple-choice questions that could be used to test students’ understanding of the article. (Of those 10 \nquestions, he said, six were usable.)\nUltimately, Mr. Gold said, ChatGPT wasn’t a threat to student learning as long as teachers paired it with \nsubstantive, in-class discussions.\n“Any tool that lets students refine their thinking before they come to class, and practice their ideas, is only going to \nmake our discussions richer,” he said.\nChatGPT teaches students about the world they’ll inhabit\nNow, I’ll take off my tech columnist hat for a second, and confess that writing this piece has made me a little sad. I \nloved school, and it pains me, on some level, to think that instead of sharpening their skills by writing essays about \n“The Sun Also Rises” or straining to factor a trigonometric expression, today’s students might simply ask an A.I. \nchatbot to do it for them.\nI also don’t believe that educators who are reflexively opposed to ChatGPT are being irrational. This type of A.I. \nreally is (if you’ll excuse the buzzword) disruptive — to classroom routines, to longstanding pedagogical practices, \nand to the basic principle that the work students turn in should reflect cogitation happening inside their brains, rather \nthan in the latent space of a machine learning model hosted on a distant supercomputer.\nBut the barricade has fallen. Tools like ChatGPT aren’t going anywhere; they’re only going to improve, and barring \nsome major regulatory intervention, this particular form of machine intelligence is now a fixture of our society.\n“Large language models aren’t going to get less capable in the next few years,” said Ethan Mollick, a professor at \nthe Wharton School of the University of Pennsylvania. “We need to figure out a way to adjust to these tools, and not \njust ban them.”\nThat’s the biggest reason not to ban it from the classroom, in fact — because today’s students will graduate into a \nworld full of generative A.I. programs. They’ll need to know their way around these tools — their strengths and \nweaknesses, their hallmarks and blind spots — in order to work alongside them. To be good citizens, they’ll need \nhands-on experience to understand how this type of A.I. works, what types of bias it contains, and how it can be \nmisused and weaponized.\nThis adjustment won’t be easy. Sudden technological shifts rarely are. But who better to guide students into this \nstrange new world than their teachers?\nThis article appeared in print on page B1, B5.\nDon’t Ban ChatGPT in Schools. Teach With It. The Shift\nLoad-Date: February 23, 2023"
    },
    {
        "file_name": "Economic_Times_(E-Paper_Edition)_Mar2024",
        "header": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation",
        "media": "Economic Times (E-Paper Edition)",
        "time": "March 30, 2024",
        "section": "ECONOMY & COMPANIES",
        "length": "377 words",
        "byline": "Ishaan.Gera@timesgroup.com",
        "story_text": "Adobe India MD Calls for Need to Balance AI Innovation & Regulation\nEconomic Times (E-Paper Edition)\nMarch 30, 2024 Saturday\nDelhi Edition\nCopyright 2024 Bennett Coleman & Co. Ltd. All Rights Reserved\nSection: ECONOMY & COMPANIES\nLength: 377 words\nByline: Ishaan.Gera@timesgroup.com\nBody\nLas Vegas: India needs a regulator for artificial intelligence (AI), but it also needs to balance innovation and \nregulation, Prativa Mohapatra, managing director of Adobe India told ET. “We have long advocated for a risk-based \napproach to AI regulation. It is important to regulate high-risk AI for the safety of everyone, and it is equally \nimportant to allow innovation to flourish by allowing low-risk AI tools to be deployed quickly and without excessive \ncompliance regulations,” Mohapatra said in an interview on the sidelines of the Adobe Summit 2024. The company \nhas also been collaborating with other companies to create industry standards for establishing trust. \nLast year, Adobe announced the release of its generative AI model called Firefly, which focuses on generating \nimages and text. At this year’s conference, the company announced the integration of its AI tool with other \nmarketing applications and the expansion of Firefly to audio, video and 3D modelling. Mohapatra said India will be \nan essential market for the company. “India is on a very positive trajectory. It's part of Adobe's global strategy of \ninternational expansion,” she said, adding that the company has witnessed double-digit growth here. “India is a \nmarket that we are very focused on, and the growth is good.  We are calling India a hypergrowth market.” Adobe \ncounts banking and financial services, and aviation among its biggest clients in India but also sees scope for \nexpansion. “I think companies' digital transformation journeys have just started,” Mohapatra said, pointing out that \nAdobe is looking to aid many other businesses, especially small and medium enterprises. However, she said the \ncompany is more cautious about its approach than during the Covid years. “Three years back, during Covid, many \nSMEs went to our commerce platform. Everybody wanted to sell digitally. But now they're going more cautiously \ninto commerce and analytics,” Mohapatra said. Mohapatra lauded the government’s effort to ensure skilling begins \nfrom a young age, but said it is important to see how this can be embedded in the curriculum and how engineering \ncolleges and others adapt to new skill requirements. (The reporter is in the US to cover Adobe Summit 2024 at the \ninvitation of Adobe)\nLoad-Date: March 30, 2024"
    },
    {
        "file_name": "The_New_York_Times_Sep2023",
        "header": "Amazon Invests Up to $4 Billion In A.I. Start-Up",
        "media": "The New York Times",
        "time": "September 26, 2023",
        "section": "Section B; Column 0; Business/Financial Desk; Pg. 4",
        "length": "650 words",
        "byline": "By Adam Satariano and Cade Metz",
        "story_text": "Amazon Invests Up to $4 Billion In A.I. Start-Up\nThe New York Times\nSeptember 26, 2023 Tuesday\nLate Edition - Final\nCopyright 2023 The New York Times Company\nSection: Section B; Column 0; Business/Financial Desk; Pg. 4\nLength: 650 words\nByline: By Adam Satariano and Cade Metz\nBody\nWith its investment of up to $4 billion, Amazon is seeking a bigger footprint in A.I. development, one already \nestablished by rivals like Microsoft and Google.\nAmazon said on Monday that it would invest up to $4 billion in the artificial intelligence start-up Anthropic, as the \nworld's biggest technology companies race to benefit from A.I. breakthroughs that could reshape parts of their \nbusinesses -- and the economy as a whole. \n  Amazon is trying to keep pace with rivals such as Microsoft and Google, which have each poured billions of dollars \ninto A.I. research. Anthropic, seen as one of the most promising of a batch of A.I. start-ups, will use Amazon's data \ncenters, cloud-computing platform and A.I. chips.\n  The deal underscores the frenzy to be at the forefront of A.I., a technology that has seized the public's imagination \nand has the power to potentially transform the way people work and live. As part of that race, tech giants have been \nteaming with up-and-coming A.I. start-ups by providing them with computing power and cash to help them develop \nnew models and applications. Google has also invested in Anthropic, while Microsoft has poured $13 billion into \nOpenAI, the maker of ChatGPT.\n  Amazon's investment of up to $4 billion would give it a minority stake in Anthropic, it said.\n  Like OpenAI, Anthropic is a developer of so-called generative A.I., the technology capable of learning from vast \namounts of data to create humanlike texts and images. These tools are seen as possessing the potential to \nautomate many tasks, reshaping aspects of the global economy.\n  Anthropic, which operates a chatbot called Claude, has sought to position itself as one of the industry's more \nresponsible actors. Its executives have warned that A.I. could cause tremendous damage to society if not \ndeveloped carefully. The company's co-founder Jack Clark attended a recent meeting on Capitol Hill to discuss A.I. \npolicy, including the risks and potential of the rapidly evolving technology.\n  Working with Anthropic also helps Amazon, which is competing against Microsoft and Google in cloud computing \nand has been trying to establish itself more deeply in artificial intelligence. Amazon is also battling Nvidia as a \nprovider of the chips needed to run complex A.I. systems. \n  The huge amounts of money and computing power needed to run A.I. models have made it nearly impossible for \nsmaller companies to remain independent from established tech giants with deep pockets.\n  Anthropic's partnership with Amazon is also another example of a new kind of circular business arrangement that \ncan be mutually beneficial to both cloud computing companies and A.I. start-ups.\nAmazon Invests Up to $4 Billion In A.I. Start-Up\n  Anthropic will pump much of the money it's raising from Amazon back into the company as it pays for time on the \nmassive clusters of computer servers operated by the Seattle tech giant. So while Amazon is making a strategic \ninvestment in a start-up, it is also feeding its own cloud-computing business, which now accounts for more than 70 \npercent of its profits.\n  Microsoft first created this kind of deal with OpenAI in 2019. In recent months, other cloud computing companies, \nincluding Google and Oracle, have made similar arrangements with ambitious A.I. start-ups.\n  While Microsoft and Google have also launched their own online chatbots in the months since OpenAI unveiled \nChatGPT, Amazon has not followed suit. Instead, it has worked to provide various tools for companies and \nindependent developers looking to build their own chatbots and other A.I. technologies.\n  In addition to boosting its cloud computing revenues, Amazon's agreement with Anthropic could raise its profile in \nthe field and fuel the development of new A.I. technologies inside the tech giant.\n  ''We can help improve many customer experiences, short- and long-term, through our deeper collaboration,'' Andy \nJassy, Amazon's chief executive, said in a statement.\nhttps://www.nytimes.com/2023/09/25/technology/amazon-anthropic-ai-deal.html\nGraphic\n \nPHOTO: Anthropic is seen as one of the most promising of a batch of A.I. start-ups. (PHOTOGRAPH BY MARISSA \nLESHNOV FOR THE NEW YORK TIMES) This article appeared in print on page B4.               \nLoad-Date: September 26, 2023"
    },
    {
        "file_name": "chaos;_The_ousted_leader_of_ChatGPT_maker_OpenAI_is_returning_to_the_Nov2023",
        "header": "OpenAI brings back Sam Altman as CEO just days after his firing unleashed",
        "media": "chaos; The ousted leader of ChatGPT maker OpenAI is returning to the",
        "time": "November 23, 2023",
        "section": "NATION WORLD",
        "length": "1169 words",
        "byline": "MATT O'BRIEN and HALELUYA HADERO",
        "story_text": "OpenAI brings back Sam Altman as CEO just days after his firing unleashed \nchaos; The ousted leader of ChatGPT maker OpenAI is returning to the \ncompany that fired him just days ago\nDayton Daily News (Ohio)\nNovember 22, 2023 Wednesday\nDistributed by Newsbank, Inc. All Rights Reserved\nCopyright 2023 Cox Ohio Publishing. \nSection: NATION WORLD\nLength: 1169 words\nByline: MATT O'BRIEN and HALELUYA HADERO\nBody\nThe ousted leader of ChatGPT maker OpenAI will return to the company that fired him just days ago, concluding a \nshort but chaotic power struggle that shocked the tech industry and underscored the conflicts around how to safely \nbuild artificial intelligence.\nThe San Francisco-based company said late Tuesday that it \"reached an agreement in principle\" for co-founder \nSam Altman to return as CEO under a different board of directors. \nThe agreement followed intense negotiations that began Saturday between Altman's side and the board members \nwho pushed him out. The discussions included disagreements about Altman's future role and who would stay on \nthe board, according to a person familiar with the talks who spoke on condition of anonymity because they were not \nallowed to speak publicly about such sensitive matters. \nAn independent investigation into Altman and the events that led to his ouster, announced earlier this week, will \ncontinue, according to the person, who described board members' slow erosion of trust in the OpenAI leader \nwithout pointing to any serious wrongdoing. The company previously made unspecified allegations that Altman had \nnot been candid with the board. \nThe lack of transparency surrounding Altman's firing led to a weekend of internal conflict at the company and \ngrowing outside pressure from the startup's investors, particularly Microsoft, which on Monday hired Altman and a \nkey ally, OpenAI co-founder and president Greg Brockman, and opened its doors to any of the other more than 700 \nemployees who wanted to join them. \nThe turmoil accentuated the differences between Altman  who has become the face of generative AI's rapid \ncommercialization since ChatGPT's arrival a year ago  and board members who have expressed deep reservations \nabout the safety risks posed by AI as it gets more advanced. \nOne of the four board members who participated in Altman's ouster, OpenAI co-founder and chief scientist Ilya \nSutskever, was involved in the negotiations over the weekend. But that changed when he publicly expressed regret \nabout the decision Monday morning and joined the call for the board's resignation. \nThe person familiar with the talks said board members did not want the company to tank or employees to defect to \nMicrosoft. At the same time, they did not want to acquiesce to demands that they all step down, nor did they want to \nreinstate Altman and Brockman on the board or install new members who might not stand up to them, the person \nsaid. \nOpenAI brings back Sam Altman as CEO just days after his firing unleashed chaos The ousted leader of \nChatGPT maker OpenAI is returning to the company that fired....\nIn the end, most of them did step down. \nThe new board will be led by former Salesforce co-CEO Bret Taylor, who chaired Twitter's board before Elon Musk \ntook over the platform last year. The other members will be former U.S. Treasury Secretary Larry Summers and \nQuora CEO Adam D'Angelo, the only member of the previous board to stay on. \n\"The OpenAI episode shows how fragile the AI ecosystem is right now, including addressing AI's risks,\" said \nJohann Laux, an expert at the Oxford Internet Institute focusing on human oversight of artificial intelligence. \nBefore the board was replaced, venture capitalist Vinod Khosla, a vocal Altman supporter whose firm is an OpenAI \ninvestor, wrote in an opinion column at The Information that board members had set back the \"tremendous \nbenefits\" of AI by misapplying their \"religion of 'effective altruism.'\" \nSome of OpenAI's board members over the years have had ties to effective altruism, the philanthropic social \nmovement that prioritizes donating to projects that will have the greatest impact on the largest number of people, \nincluding humans in the future. \nWhile many effective altruists believe AI could offer powerful benefits, they also advocate for mitigating the \ntechnology's potential risks. \nHelping to drive Altman's return and the installation of a new board was Microsoft, which has invested billions of \ndollars in OpenAI and has rights to its existing technology. \nWhile promising to welcome OpenAI's fleeing workforce, Microsoft CEO Satya Nadella also made clear in a series \nof interviews Monday that he was open to the possibility of Altman returning to OpenAI as long as the startup's \ngovernance problems were solved. \n\"We are encouraged by the changes to the OpenAI board,\" Nadella posted on X late Tuesday. \"We believe this is a \nfirst essential step on a path to more stable, well-informed and effective governance.\" \nIn his own post, Altman said that with the new board and with Satya's support, he was \"looking forward to returning \nto OpenAI and building on our strong partnership\" with Microsoft. \nGone from the OpenAI board are its only two women: tech entrepreneur Tasha McCauley and Helen Toner, a \npolicy expert at Georgetown's Center for Security and Emerging Technology, both of whom have expressed \nconcerns about AI safety risks. \nThe leadership drama offers a glimpse into how big tech companies are taking the lead in governing AI and its \nrisks, while governments scramble to catch up. The European Union is working to finalize the world's first \ncomprehensive AI rules. \nIn the absence of regulations, \"companies decide how a technology is rolled out,\" said Oxford's Laux. \nCo-founded by Altman as a nonprofit with a mission to safely build AI that outperforms humans and benefits \nhumanity, OpenAI later became a for-profit business  but one still run by its nonprofit board of directors. \nThis was not OpenAI's first experience with executive turmoil. Past examples including a 2018 falling out between \nboard co-chairs Altman and Musk that led to Musk's exit, and a later exodus of top leaders who started the \ncompetitor Anthropic. \nIt's not clear yet if the board's structure will change with its new members. \nUnder the current structure, all profit beyond a certain cap is supposed to go back to its mission of helping \nhumanity. The board is also tasked with deciding when AI systems have become so advanced that they are better \nOpenAI brings back Sam Altman as CEO just days after his firing unleashed chaos The ousted leader of \nChatGPT maker OpenAI is returning to the company that fired....\nthan humans \"at most economically valuable work.\" At that point, Microsoft's intellectual property licenses no longer \napply. \n\"We are collaborating to figure out the details,\" OpenAI posted on social media. \"Thank you so much for your \npatience through this.\" \nNadella said Brockman, who was OpenAI's board chairman until Altman's firing, also will have a key role to play in \nensuring the group \"continues to thrive and build on its mission.\" \nAs for OpenAI's short-lived interim CEO Emmett Shear, the second temporary leader in the days since Altman's \nouster, he posted on X that he was \"deeply pleased by this result\" after about 72 \"very intense hours of work.\" \n\"Coming into OpenAI, I wasn't sure what the right path would be,\" wrote Shear, the former head of Twitch. \"This \nwas the pathway that maximized safety alongside doing right by all stakeholders involved. I'm glad to have been a \npart of the solution.\" \nThe Associated Press and OpenAI have a licensing and technology agreement allowing OpenAI access to part of \nthe AP's text archives. \nAssociated Press writers Kelvin Chan in London and Thalia Beaty in New York contributed to this report.\nGraphic\n \nFILE - Open AI CEO Sam Altman participates in a discussion during the Asia-Pacific Economic Cooperation \n(APEC) CEO Summit, Nov. 16, 2023, in San Francisco. Altman, the ousted leader of ChatGPT-maker OpenAI, is \nreturning to the company that fired him late last week, the latest in a saga that has shocked the artificial intelligence \nindustry. San Francisco-based OpenAI said in a statement late Tuesday, Nov. 21: \"We have reached an agreement \nin principle for Sam Altman to return to OpenAI as CEO with a new initial board of Bret Taylor (Chair), Larry \nSummers, and Adam D'Angelo.\" (AP Photo/Eric Risberg, File)\nLoad-Date: November 23, 2023"
    },
    {
        "file_name": "The_New_York_Times_May2023",
        "header": "Ukraine and China Will Dominate G7 Summit, but a New Threat Lurks: A.I.",
        "media": "The New York Times",
        "time": "May 19, 2023",
        "section": "WORLD; asia",
        "length": "1424 words",
        "byline": "David E. Sanger",
        "story_text": "Ukraine and China Will Dominate G7 Summit, but a New Threat Lurks: A.I.\nThe New York Times \nMay 18, 2023 Thursday 12:36 EST\nCopyright 2023 The New York Times Company All Rights Reserved\nSection: WORLD; asia\nLength: 1424 words\nByline: David E. Sanger\nHighlight: The leaders are expected to hold their first talks on a common regulatory approach to generative \nartificial intelligence.\nBody\nThe leaders are expected to hold their first talks on a common regulatory approach to generative artificial \nintelligence.\nPresident Biden began his foreshortened Asia trip on Thursday in Hiroshima, a city that devotes itself to reminding \nthe world of what happens when a brutal war escalates into a nuclear one. There he prepared for discussions with \nhis closest allies on two crucial issues: how to better arm Ukraine as it enters its counteroffensive against the \nRussian invaders, and how to slow, or halt, the downward spiral in relations with China.\nBoth are now familiar topics to the leaders of the Group of 7 nations, who have grown far tighter, and have \nremained surprisingly unified, since Russia began its assault on Ukraine 15 months ago. But at some point over \nthree days of discussions, the G7 leaders are also expected to venture into new territory: the first conversations \namong the world’s largest democratic economies about a common approach to regulating the use of generative \nartificial intelligence programs like GPT-4.\nArtificial intelligence was not on the early agenda as Prime Minister Fumio Kishida invited the other six leaders — \njoined by Prime Minister Narendra Modi of India and, via video or in person, President Volodymyr Zelensky of \nUkraine — to the Japanese prefecture where he got his political start.\nBut as the new artificial intelligence language model from OpenAI made nations around the world focus for the first \ntime on the possibilities for disinformation, chaos and the physical destruction of critical infrastructure, Mr. Biden’s \nnational security adviser, Jake Sullivan, began calling counterparts to seek a common discussion.\nIt is far from clear that this group of leaders — the G7 also includes Germany, Britain, France, Canada and Italy — \ncan sustain a conversation on a technology that appeared to burst on the scene so quickly, even if it was years in \nthe making. Past efforts to get the group to take up far more straightforward cybersecurity issues usually descended \ninto platitudes about “public-private partnerships,” and there has never been serious discussion of rules to guide the \nuse of offensive cyberweapons.\nAmerican officials say that in the case of chatbots, even a vague foundational discussion may help in establishing \nsome shared principles: that the corporations that bring products using the large-language models will be primarily \nresponsible for their safety, and that there must be transparency rules that make it clear what kind of data each \nsystem was trained on. That will enable lower-level aides to discuss details of what those first regulations would \nlook like, the officials said.\nUkraine and China Will Dominate G7 Summit, but a New Threat Lurks: A.I.\nBut as the G7 leaders convene starting on Friday, it will be Ukraine that will dominate the conversation, at a critical \nmoment for Mr. Zelensky, for Ukraine and for the core Western democracies now seized with an urgent mission of \nbringing about what Mr. Biden calls the “strategic defeat of Russia in Ukraine.”\nMr. Biden often says that Russia is already defeated. But the fear permeating the seven large democracies here is \nthat unless the counteroffensive proves highly successful, Ukraine will settle into a bloody, frozen conflict in which \nthe best hope would be an armistice, reminiscent of the one that brought a halt to fighting on the Korean Peninsula \n70 years ago this summer.\nSuch a confrontation seemed almost impossible to imagine in 1997, when President Bill Clinton and Prime Minister \nTony Blair of Britain invited Russia to become a full member of the group, expanding it — for nearly two decades — \ninto the G8. Russia was “suspended” after its annexation of Crimea in 2014, and it withdrew from the group three \nyears later.\nNow, with his troops already seeking to destroy Russian weapons depots ahead of the counteroffensive, Mr. \nZelensky just completed a series of rapid-fire visits to European capitals to shore up support for continued heavy \nspending on armaments and aid. He is expected to address the leaders in Hiroshima virtually, but there have been \nbehind-the-scenes conversations about whether to take the risk of bringing him personally to the other side of the \nworld to make his case.\nEither way, he will have a large audience. In addition to India, the leaders of Australia, South Korea, Brazil, \nIndonesia and Vietnam will all be present as guests. It is part of a broader strategy by Mr. Biden and his allies to \ndraw in nations that, to varying degrees, have been fence sitters on the Ukraine war, refusing to condemn Russia \ntoo harshly, to enthusiastically enforce sanctions, or to supply weapons to Ukraine.\nSome of the core members are seeking to arm Mr. Zelensky in ways that may outpace Mr. Biden’s willingness. \nWhen he was in Britain, Rishi Sunak, the prime minister, embraced Mr. Zelensky in a bear hug and told reporters, \n“They need the sustained support of the international community to defend against the barrage of unrelenting and \nindiscriminate attacks that have been their daily reality for over a year. We must not let them down.”\nBritain and the Netherlands have been pressing Washington to allow Ukraine to begin training on the use of F-16 \nfighter jets. But just as Mr. Biden was at first reluctant to turn over HIMARS and Patriot missile batteries and other \ntechnologies, he has been cautious about the F-16, a plane that could easily reach, and hit, the Kremlin.\nSo the United States seems likely to argue in Hiroshima that the fighter jets, while symbolically impressive, would \nbe so expensive that they would come at the price of sending far more useful, inexpensive systems, including the \nair defenses that have proven surprisingly successful in taking down incoming Russian missiles. The apparent \ndamage of at least part of a new Patriot missile battery in Kyiv this week has underscored the fact that such \nsystems are precious.\nMr. Biden has consistently been cautious — overcautious in the minds of Mr. Zelensky and some NATO allies — \nabout giving Ukraine weapons that he believes might lead to rapid escalation of the war and renewed threats by the \nRussian leader, Vladimir V. Putin, to use a tactical nuclear weapon. \nBritain has just begun giving Ukraine another precision weapon with greater reach than the American-provided \nHIMARS, a missile system called Storm Shadow.  Britain’s foreign secretary, James Cleverly, told reporters in \nWashington last week that Mr. Putin’s threats of escalation now ring more hollow, and that these “are gateways to \nwhich they are going to have to pass.”\nFor Mr. Kishida, the host, navigating the nuclear issues will be unusually tricky. The summit will open with a visit by \nMr. Biden to the landmark atomic dome, making him the second American president to see the site of the atomic \nbombing ordered by President Harry S. Truman. (President Obama came in 2016, and Mr. Kishida was one of his \nguides to the site.)\nUkraine and China Will Dominate G7 Summit, but a New Threat Lurks: A.I.\nLike many Japanese political leaders, Mr. Kishida has pressed throughout his career for the gradual elimination of \nnuclear weapons. But he and other Japanese politicians also concede that Mr. Putin’s threats have made American \n“extended deterrence” under its nuclear umbrella more vital to Japan’s strategy now than it has been for years.\nG7 officials will also be grappling with the downward spiral in relations between China and the United States. Mr. \nSullivan, the national security adviser, spent two days in Vienna last week with Wang Yi, China’s top foreign affairs \nofficial, in what was widely described as an effort to get communications going again after the U.S. decision to \nshoot down a Chinese surveillance balloon off the coast of South Carolina.\nOfficials have said little about the meeting, but it appears that China told Mr. Sullivan they are open again to visits \nfrom Commerce Secretary Gina Raimondo, Treasury Secretary Janet Yellen and, ultimately, Secretary of State \nAntony J. Blinken.\nMr. Biden, who on Tuesday canceled additional stops on this trip in Papua New Guinea and Australia so he can \nreturn on Sunday to the United States to deal with debt ceiling negotiations, said on Wednesday he was trying to \nmeet again with the Chinese leader, Xi Jinping. That is a sign that the freeze in relations in recent months may be \nbeginning to let up, even if the fundamental dynamic between the United States and China, a growing nuclear \npower, has yet to change.\nPHOTO: President Biden walking into a bilateral meeting with Prime Minister Fumio Kishida of Japan on Thursday \nin Hiroshima, Japan. (PHOTOGRAPH BY KENNY HOLSTON/THE NEW YORK TIMES) This article appeared in \nprint on page A7.\nLoad-Date: May 19, 2023"
    }
]